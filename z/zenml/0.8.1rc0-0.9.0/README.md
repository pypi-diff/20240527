# Comparing `tmp/zenml-0.8.1rc0.tar.gz` & `tmp/zenml-0.9.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "zenml-0.8.1rc0.tar", max compression
+gzip compressed data, was "zenml-0.9.0.tar", max compression
```

## Comparing `zenml-0.8.1rc0.tar` & `zenml-0.9.0.tar`

### file list

```diff
@@ -1,338 +1,356 @@
--rw-r--r--   0        0        0    11654 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/CLA.md
--rw-r--r--   0        0        0     5496 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/CODE-OF-CONDUCT.md
--rw-r--r--   0        0        0     5854 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/CONTRIBUTING.md
--rw-r--r--   0        0        0    11359 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/LICENSE
--rw-r--r--   0        0        0    15139 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/README.md
--rw-r--r--   0        0        0    69697 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/RELEASE_NOTES.md
--rw-r--r--   0        0        0      407 2022-05-24 13:32:14.926789 zenml-0.8.1rc0/ROADMAP.md
--rw-r--r--   0        0        0     5716 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/pyproject.toml
--rw-r--r--   0        0        0     2170 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/README.md
--rw-r--r--   0        0        0        8 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/VERSION
--rw-r--r--   0        0        0     1051 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/__init__.py
--rw-r--r--   0        0        0     1473 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifact_stores/__init__.py
--rw-r--r--   0        0        0     8387 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifact_stores/base_artifact_store.py
--rw-r--r--   0        0        0     6037 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifact_stores/local_artifact_store.py
--rw-r--r--   0        0        0     1856 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/__init__.py
--rw-r--r--   0        0        0     4389 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/base_artifact.py
--rw-r--r--   0        0        0      692 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/constants.py
--rw-r--r--   0        0        0      973 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/data_analysis_artifact.py
--rw-r--r--   0        0        0      783 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/data_artifact.py
--rw-r--r--   0        0        0      786 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/model_artifact.py
--rw-r--r--   0        0        0      789 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/schema_artifact.py
--rw-r--r--   0        0        0      792 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/service_artifact.py
--rw-r--r--   0        0        0      801 2022-05-24 13:32:14.978789 zenml-0.8.1rc0/src/zenml/artifacts/statistics_artifact.py
--rw-r--r--   0        0        0     3751 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/artifacts/type_registry.py
--rw-r--r--   0        0        0    22209 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/__init__.py
--rw-r--r--   0        0        0     9493 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/base.py
--rw-r--r--   0        0        0     4424 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/cli.py
--rw-r--r--   0        0        0    18601 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/config.py
--rw-r--r--   0        0        0    26019 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/example.py
--rw-r--r--   0        0        0     3227 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/feature.py
--rw-r--r--   0        0        0     5795 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/formatter.py
--rw-r--r--   0        0        0     8087 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/integration.py
--rw-r--r--   0        0        0     8311 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/pipeline.py
--rw-r--r--   0        0        0    15508 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/secret.py
--rw-r--r--   0        0        0    10365 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/served_models.py
--rw-r--r--   0        0        0     5784 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/server.py
--rw-r--r--   0        0        0    28217 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/stack.py
--rw-r--r--   0        0        0    33783 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/stack_components.py
--rw-r--r--   0        0        0     2340 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/text_utils.py
--rw-r--r--   0        0        0    14584 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/user_management.py
--rw-r--r--   0        0        0    22822 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/utils.py
--rw-r--r--   0        0        0     3584 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/cli/version.py
--rw-r--r--   0        0        0     1442 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/config/__init__.py
--rw-r--r--   0        0        0     2589 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/config/base_config.py
--rw-r--r--   0        0        0     3130 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/config/config_keys.py
--rw-r--r--   0        0        0    20534 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/config/global_config.py
--rw-r--r--   0        0        0     6994 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/config/profile_config.py
--rw-r--r--   0        0        0     1125 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/console.py
--rw-r--r--   0        0        0     4670 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/constants.py
--rw-r--r--   0        0        0     2213 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/__init__.py
--rw-r--r--   0        0        0      976 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/azure_container_registry.py
--rw-r--r--   0        0        0     2437 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/base_container_registry.py
--rw-r--r--   0        0        0      990 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/default_container_registry.py
--rw-r--r--   0        0        0      988 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/dockerhub_container_registry.py
--rw-r--r--   0        0        0      970 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/gcp_container_registry.py
--rw-r--r--   0        0        0      979 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/github_container_registry.py
--rw-r--r--   0        0        0      979 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/container_registries/gitlab_container_registry.py
--rw-r--r--   0        0        0      754 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/entrypoints/__init__.py
--rw-r--r--   0        0        0     2183 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/entrypoints/step_entrypoint.py
--rw-r--r--   0        0        0    26364 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/entrypoints/step_entrypoint_configuration.py
--rw-r--r--   0        0        0     2794 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/enums.py
--rw-r--r--   0        0        0    13951 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/environment.py
--rw-r--r--   0        0        0     7383 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/exceptions.py
--rw-r--r--   0        0        0     1118 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/experiment_trackers/__init__.py
--rw-r--r--   0        0        0      984 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/experiment_trackers/base_experiment_tracker.py
--rw-r--r--   0        0        0     1344 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/feature_stores/__init__.py
--rw-r--r--   0        0        0     2107 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/feature_stores/base_feature_store.py
--rw-r--r--   0        0        0     2813 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/__init__.py
--rw-r--r--   0        0        0     1747 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/airflow/__init__.py
--rw-r--r--   0        0        0      812 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/airflow/orchestrators/__init__.py
--rw-r--r--   0        0        0    14596 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/airflow/orchestrators/airflow_orchestrator.py
--rw-r--r--   0        0        0     2070 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/__init__.py
--rw-r--r--   0        0        0      731 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/container_registries/__init__.py
--rw-r--r--   0        0        0     3760 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/container_registries/aws_container_registry.py
--rw-r--r--   0        0        0      767 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/secret_schemas/__init__.py
--rw-r--r--   0        0        0     1011 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/secret_schemas/aws_secret_schema.py
--rw-r--r--   0        0        0      776 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/secrets_managers/__init__.py
--rw-r--r--   0        0        0     5404 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/aws/secrets_managers/aws_secrets_manager.py
--rw-r--r--   0        0        0     1707 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azure/__init__.py
--rw-r--r--   0        0        0      724 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azure/artifact_stores/__init__.py
--rw-r--r--   0        0        0     8366 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azure/artifact_stores/azure_artifact_store.py
--rw-r--r--   0        0        0     1615 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azureml/__init__.py
--rw-r--r--   0        0        0      727 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azureml/step_operators/__init__.py
--rw-r--r--   0        0        0     8172 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/azureml/step_operators/azureml_step_operator.py
--rw-r--r--   0        0        0     1230 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/constants.py
--rw-r--r--   0        0        0     1018 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/dash/__init__.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.982789 zenml-0.8.1rc0/src/zenml/integrations/dash/visualizers/__init__.py
--rw-r--r--   0        0        0    14751 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/dash/visualizers/pipeline_run_lineage_visualizer.py
--rw-r--r--   0        0        0     1323 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/evidently/__init__.py
--rw-r--r--   0        0        0      737 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/evidently/steps/__init__.py
--rw-r--r--   0        0        0     5611 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/evidently/steps/evidently_profile.py
--rw-r--r--   0        0        0      717 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/evidently/visualizers/__init__.py
--rw-r--r--   0        0        0     2443 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/evidently/visualizers/evidently_visualizer.py
--rw-r--r--   0        0        0     1266 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/facets/__init__.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/__init__.py
--rw-r--r--   0        0        0     3791 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/facet_statistics_visualizer.py
--rw-r--r--   0        0        0     1284 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/stats.html
--rw-r--r--   0        0        0     1706 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/feast/__init__.py
--rw-r--r--   0        0        0     1217 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/feast/feature_stores/__init__.py
--rw-r--r--   0        0        0     6190 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/feast/feature_stores/feast_feature_store.py
--rw-r--r--   0        0        0     1737 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp/__init__.py
--rw-r--r--   0        0        0      717 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp/artifact_stores/__init__.py
--rw-r--r--   0        0        0     6954 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp/artifact_stores/gcp_artifact_store.py
--rw-r--r--   0        0        0     1793 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/__init__.py
--rw-r--r--   0        0        0      918 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/secrets_manager/__init__.py
--rw-r--r--   0        0        0     8865 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/secrets_manager/gcp_secrets_manager.py
--rw-r--r--   0        0        0      964 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/graphviz/__init__.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/graphviz/visualizers/__init__.py
--rw-r--r--   0        0        0     2901 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/graphviz/visualizers/pipeline_run_dag_visualizer.py
--rw-r--r--   0        0        0     1106 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/__init__.py
--rw-r--r--   0        0        0     1104 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/__init__.py
--rw-r--r--   0        0        0     1861 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_datasets_materializer.py
--rw-r--r--   0        0        0     2153 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_pt_model_materializer.py
--rw-r--r--   0        0        0     2170 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_tf_model_materializer.py
--rw-r--r--   0        0        0     1965 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_tokenizer_materializer.py
--rw-r--r--   0        0        0     3182 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/integration.py
--rw-r--r--   0        0        0     2015 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/__init__.py
--rw-r--r--   0        0        0      762 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/metadata_stores/__init__.py
--rw-r--r--   0        0        0    10609 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/metadata_stores/kubeflow_metadata_store.py
--rw-r--r--   0        0        0      728 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/__init__.py
--rw-r--r--   0        0        0     2933 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_entrypoint_configuration.py
--rw-r--r--   0        0        0    44677 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_orchestrator.py
--rw-r--r--   0        0        0    14185 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/local_deployment_utils.py
--rw-r--r--   0        0        0    11196 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/utils.py
--rw-r--r--   0        0        0     1079 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/lightgbm/__init__.py
--rw-r--r--   0        0        0      871 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/__init__.py
--rw-r--r--   0        0        0     2398 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/lightgbm_booster_materializer.py
--rw-r--r--   0        0        0     2345 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/lightgbm_dataset_materializer.py
--rw-r--r--   0        0        0     2242 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/__init__.py
--rw-r--r--   0        0        0      680 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/experiment_trackers/__init__.py
--rw-r--r--   0        0        0     9986 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/experiment_trackers/mlflow_experiment_tracker.py
--rw-r--r--   0        0        0     4962 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/mlflow_step_decorator.py
--rw-r--r--   0        0        0     2280 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/mlflow_utils.py
--rw-r--r--   0        0        0      668 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/model_deployers/__init__.py
--rw-r--r--   0        0        0    17455 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/model_deployers/mlflow_model_deployer.py
--rw-r--r--   0        0        0      746 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/services/__init__.py
--rw-r--r--   0        0        0     6713 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/services/mlflow_deployment.py
--rw-r--r--   0        0        0      761 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/steps/__init__.py
--rw-r--r--   0        0        0     7977 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/mlflow/steps/mlflow_deployer.py
--rw-r--r--   0        0        0     1176 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/__init__.py
--rw-r--r--   0        0        0      744 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/materializers/__init__.py
--rw-r--r--   0        0        0     2030 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/materializers/neural_prophet_materializer.py
--rw-r--r--   0        0        0      907 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/plotly/__init__.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/plotly/visualizers/__init__.py
--rw-r--r--   0        0        0     2255 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/plotly/visualizers/pipeline_lineage_visualizer.py
--rw-r--r--   0        0        0     1122 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch/__init__.py
--rw-r--r--   0        0        0      869 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/__init__.py
--rw-r--r--   0        0        0     2050 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/pytorch_dataloader_materializer.py
--rw-r--r--   0        0        0     2579 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/pytorch_module_materializer.py
--rw-r--r--   0        0        0     1117 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/__init__.py
--rw-r--r--   0        0        0      754 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/materializers/__init__.py
--rw-r--r--   0        0        0     1762 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/materializers/pytorch_lightning_materializer.py
--rw-r--r--   0        0        0     4545 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/registry.py
--rw-r--r--   0        0        0     1567 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/s3/__init__.py
--rw-r--r--   0        0        0      715 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/s3/artifact_stores/__init__.py
--rw-r--r--   0        0        0    10048 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/s3/artifact_stores/s3_artifact_store.py
--rw-r--r--   0        0        0     1634 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/sagemaker/__init__.py
--rw-r--r--   0        0        0      733 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/sagemaker/step_operators/__init__.py
--rw-r--r--   0        0        0     5252 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/sagemaker/step_operators/sagemaker_step_operator.py
--rw-r--r--   0        0        0     1051 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/scipy/__init__.py
--rw-r--r--   0        0        0      720 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/scipy/materializers/__init__.py
--rw-r--r--   0        0        0     1727 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/scipy/materializers/sparse_materializer.py
--rw-r--r--   0        0        0     1895 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/seldon/__init__.py
--rw-r--r--   0        0        0      725 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/seldon/model_deployers/__init__.py
--rw-r--r--   0        0        0    19692 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/seldon/model_deployers/seldon_model_deployer.py
--rw-r--r--   0        0        0     1245 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/seldon/secret_schemas/__init__.py
--rw-r--r--   0        0        0     4792 2022-05-24 13:32:14.986789 zenml-0.8.1rc0/src/zenml/integrations/seldon/secret_schemas/secret_schemas.py
--rw-r--r--   0        0        0    36810 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/seldon/seldon_client.py
--rw-r--r--   0        0        0      746 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/seldon/services/__init__.py
--rw-r--r--   0        0        0    13598 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/seldon/services/seldon_deployment.py
--rw-r--r--   0        0        0      739 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/seldon/steps/__init__.py
--rw-r--r--   0        0        0     7378 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/seldon/steps/seldon_deployer.py
--rw-r--r--   0        0        0     1070 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/__init__.py
--rw-r--r--   0        0        0        0 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/helpers/__init__.py
--rw-r--r--   0        0        0     1605 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/helpers/digits.py
--rw-r--r--   0        0        0      724 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/materializers/__init__.py
--rw-r--r--   0        0        0     2758 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/materializers/sklearn_materializer.py
--rw-r--r--   0        0        0      978 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/__init__.py
--rw-r--r--   0        0        0     2030 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_evaluator.py
--rw-r--r--   0        0        0     2767 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_splitter.py
--rw-r--r--   0        0        0     3762 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_standard_scaler.py
--rw-r--r--   0        0        0     1359 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/__init__.py
--rw-r--r--   0        0        0      851 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/__init__.py
--rw-r--r--   0        0        0     2239 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/keras_materializer.py
--rw-r--r--   0        0        0     1611 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/tf_dataset_materializer.py
--rw-r--r--   0        0        0      749 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/services/__init__.py
--rw-r--r--   0        0        0     4184 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/services/tensorboard_service.py
--rw-r--r--   0        0        0      755 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/steps/__init__.py
--rw-r--r--   0        0        0     3178 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/steps/tensorflow_trainer.py
--rw-r--r--   0        0        0      785 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/visualizers/__init__.py
--rw-r--r--   0        0        0     7682 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/tensorflow/visualizers/tensorboard_visualizer.py
--rw-r--r--   0        0        0     2381 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/utils.py
--rw-r--r--   0        0        0     1633 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/__init__.py
--rw-r--r--   0        0        0     1195 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/constants.py
--rw-r--r--   0        0        0      724 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/orchestrator/__init__.py
--rw-r--r--   0        0        0     2791 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/orchestrator/vertex_ai_orchestrator.py
--rw-r--r--   0        0        0      724 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/step_operators/__init__.py
--rw-r--r--   0        0        0    11897 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/vertex/step_operators/vertex_step_operator.py
--rw-r--r--   0        0        0     1685 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/wandb/__init__.py
--rw-r--r--   0        0        0      677 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/wandb/experiment_trackers/__init__.py
--rw-r--r--   0        0        0     3183 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/wandb/experiment_trackers/wandb_experiment_tracker.py
--rw-r--r--   0        0        0     6626 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/wandb/wandb_step_decorator.py
--rw-r--r--   0        0        0     1199 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/__init__.py
--rw-r--r--   0        0        0      723 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/materializers/__init__.py
--rw-r--r--   0        0        0     2303 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/materializers/whylogs_materializer.py
--rw-r--r--   0        0        0      758 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/steps/__init__.py
--rw-r--r--   0        0        0     4430 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/steps/whylogs_profiler.py
--rw-r--r--   0        0        0      736 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/visualizers/__init__.py
--rw-r--r--   0        0        0     5096 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/visualizers/whylogs_visualizer.py
--rw-r--r--   0        0        0     4851 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/whylogs_context.py
--rw-r--r--   0        0        0     5089 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/whylogs/whylogs_step_decorator.py
--rw-r--r--   0        0        0     1072 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/xgboost/__init__.py
--rw-r--r--   0        0        0      865 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/__init__.py
--rw-r--r--   0        0        0     2412 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/xgboost_booster_materializer.py
--rw-r--r--   0        0        0     2333 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/xgboost_dmatrix_materializer.py
--rw-r--r--   0        0        0      843 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/io/__init__.py
--rw-r--r--   0        0        0     1893 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/io/fileio.py
--rw-r--r--   0        0        0     5719 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/io/utils.py
--rw-r--r--   0        0        0     6854 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/logger.py
--rw-r--r--   0        0        0     1241 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/__init__.py
--rw-r--r--   0        0        0     5127 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/base_materializer.py
--rw-r--r--   0        0        0     1722 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/beam_materializer.py
--rw-r--r--   0        0        0     2109 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/built_in_materializer.py
--rw-r--r--   0        0        0     4749 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/default_materializer_registry.py
--rw-r--r--   0        0        0     2506 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/numpy_materializer.py
--rw-r--r--   0        0        0     2501 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/pandas_materializer.py
--rw-r--r--   0        0        0     2193 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/materializers/service_materializer.py
--rw-r--r--   0        0        0     1305 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/metadata_stores/__init__.py
--rw-r--r--   0        0        0    15104 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/metadata_stores/base_metadata_store.py
--rw-r--r--   0        0        0     5615 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/metadata_stores/mysql_metadata_store.py
--rw-r--r--   0        0        0     1039 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/metadata_stores/mysql_secret_schema.py
--rw-r--r--   0        0        0     1855 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/metadata_stores/sqlite_metadata_store.py
--rw-r--r--   0        0        0     1661 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/model_deployers/__init__.py
--rw-r--r--   0        0        0     9175 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/model_deployers/base_model_deployer.py
--rw-r--r--   0        0        0     1273 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/__init__.py
--rw-r--r--   0        0        0    17317 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/base_orchestrator.py
--rw-r--r--   0        0        0     4690 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/context_utils.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/local/__init__.py
--rw-r--r--   0        0        0     2234 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/local/local_orchestrator.py
--rw-r--r--   0        0        0     4023 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/orchestrators/utils.py
--rw-r--r--   0        0        0     1523 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/__init__.py
--rw-r--r--   0        0        0    20783 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/base_pipeline.py
--rw-r--r--   0        0        0      694 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/builtin_pipelines/__init__.py
--rw-r--r--   0        0        0     2588 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/builtin_pipelines/training_pipeline.py
--rw-r--r--   0        0        0     4564 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/pipeline_decorator.py
--rw-r--r--   0        0        0     2190 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/pipelines/schedule.py
--rw-r--r--   0        0        0     1184 2022-05-24 13:32:14.990789 zenml-0.8.1rc0/src/zenml/post_execution/__init__.py
--rw-r--r--   0        0        0     6682 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/post_execution/artifact.py
--rw-r--r--   0        0        0     5900 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/post_execution/pipeline.py
--rw-r--r--   0        0        0     6305 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/post_execution/pipeline_run.py
--rw-r--r--   0        0        0     7356 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/post_execution/step.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/py.typed
--rw-r--r--   0        0        0    45174 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/repository.py
--rw-r--r--   0        0        0     2261 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/runtime_configuration.py
--rw-r--r--   0        0        0     1628 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secret/__init__.py
--rw-r--r--   0        0        0     1887 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secret/arbitrary_secret_schema.py
--rw-r--r--   0        0        0     2208 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secret/base_secret.py
--rw-r--r--   0        0        0     4004 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secret/secret_schema_class_registry.py
--rw-r--r--   0        0        0      879 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secrets_managers/__init__.py
--rw-r--r--   0        0        0     2153 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secrets_managers/base_secrets_manager.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secrets_managers/local/__init__.py
--rw-r--r--   0        0        0     7210 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/secrets_managers/local/local_secrets_manager.py
--rw-r--r--   0        0        0     2434 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/__init__.py
--rw-r--r--   0        0        0      613 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/local/__init__.py
--rw-r--r--   0        0        0     2432 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/local/local_daemon_entrypoint.py
--rw-r--r--   0        0        0    15188 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/local/local_service.py
--rw-r--r--   0        0        0     4863 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/local/local_service_endpoint.py
--rw-r--r--   0        0        0    14485 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service.py
--rw-r--r--   0        0        0     6017 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service_endpoint.py
--rw-r--r--   0        0        0     7091 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service_monitor.py
--rw-r--r--   0        0        0     6588 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service_registry.py
--rw-r--r--   0        0        0     2520 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service_status.py
--rw-r--r--   0        0        0     1101 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/service_type.py
--rw-r--r--   0        0        0     2747 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/services/utils.py
--rw-r--r--   0        0        0     1119 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/stack/__init__.py
--rw-r--r--   0        0        0     4065 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/stack/flavor_registry.py
--rw-r--r--   0        0        0    21321 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/stack/stack.py
--rw-r--r--   0        0        0     9392 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/stack/stack_component.py
--rw-r--r--   0        0        0     3002 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/stack/stack_validator.py
--rw-r--r--   0        0        0     1035 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/step_operators/__init__.py
--rw-r--r--   0        0        0     1918 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/step_operators/base_step_operator.py
--rw-r--r--   0        0        0     5735 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/step_operators/entrypoint.py
--rw-r--r--   0        0        0     9134 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/step_operators/step_executor_operator.py
--rw-r--r--   0        0        0     1744 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/__init__.py
--rw-r--r--   0        0        0    30489 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/base_step.py
--rw-r--r--   0        0        0      753 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/base_step_config.py
--rw-r--r--   0        0        0      827 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/builtin_steps/__init__.py
--rw-r--r--   0        0        0     2175 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/builtin_steps/pandas_analyzer.py
--rw-r--r--   0        0        0     1746 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/builtin_steps/pandas_datasource.py
--rw-r--r--   0        0        0     1807 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/restrict_step_access_decorator.py
--rw-r--r--   0        0        0     7624 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_context.py
--rw-r--r--   0        0        0     3900 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_decorator.py
--rw-r--r--   0        0        0     2467 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_environment.py
--rw-r--r--   0        0        0     1795 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/__init__.py
--rw-r--r--   0        0        0     1360 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_analyzer_step.py
--rw-r--r--   0        0        0     1212 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_datasource_step.py
--rw-r--r--   0        0        0     1336 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_drift_detection_step.py
--rw-r--r--   0        0        0     1278 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_evaluator_step.py
--rw-r--r--   0        0        0     1607 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_preprocessor_step.py
--rw-r--r--   0        0        0     1335 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_split_step.py
--rw-r--r--   0        0        0     1289 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_trainer_step.py
--rw-r--r--   0        0        0     1192 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/step_output.py
--rw-r--r--   0        0        0    19372 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/steps/utils.py
--rw-r--r--   0        0        0      762 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/__init__.py
--rw-r--r--   0        0        0     7392 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/analytics_utils.py
--rw-r--r--   0        0        0     9852 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/daemon.py
--rw-r--r--   0        0        0    13464 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/docker_utils.py
--rw-r--r--   0        0        0     1140 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/enum_utils.py
--rw-r--r--   0        0        0     4242 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/filesync_model.py
--rw-r--r--   0        0        0     2773 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/networking_utils.py
--rw-r--r--   0        0        0     2178 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/secrets_manager_utils.py
--rw-r--r--   0        0        0     1831 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/singleton.py
--rw-r--r--   0        0        0    16570 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/source_utils.py
--rw-r--r--   0        0        0     1604 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/string_utils.py
--rw-r--r--   0        0        0     4145 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/typed_model.py
--rw-r--r--   0        0        0     3988 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/utils/yaml_utils.py
--rw-r--r--   0        0        0     1325 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/visualizers/__init__.py
--rw-r--r--   0        0        0     1136 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/visualizers/base_pipeline_run_visualizer.py
--rw-r--r--   0        0        0     1104 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/visualizers/base_pipeline_visualizer.py
--rw-r--r--   0        0        0     1084 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/visualizers/base_step_visualizer.py
--rw-r--r--   0        0        0      945 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/visualizers/base_visualizer.py
--rw-r--r--   0        0        0     1222 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/zen_server/__init__.py
--rw-r--r--   0        0        0     5466 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/zen_server/zen_server.py
--rw-r--r--   0        0        0    19332 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/zen_server/zen_server_api.py
--rw-r--r--   0        0        0     1016 2022-05-24 13:32:14.994789 zenml-0.8.1rc0/src/zenml/zen_stores/__init__.py
--rw-r--r--   0        0        0    37175 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/base_zen_store.py
--rw-r--r--   0        0        0    36041 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/local_zen_store.py
--rw-r--r--   0        0        0     1243 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/__init__.py
--rw-r--r--   0        0        0     2151 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/component_wrapper.py
--rw-r--r--   0        0        0     3624 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/flavor_wrapper.py
--rw-r--r--   0        0        0     3898 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/pipeline_models.py
--rw-r--r--   0        0        0     2181 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/stack_wrapper.py
--rw-r--r--   0        0        0     4460 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/user_management_models.py
--rw-r--r--   0        0        0     4626 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/models/zen_store_model.py
--rw-r--r--   0        0        0    34185 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/rest_zen_store.py
--rw-r--r--   0        0        0    50438 2022-05-24 13:32:14.998789 zenml-0.8.1rc0/src/zenml/zen_stores/sql_zen_store.py
--rw-r--r--   0        0        0    20643 2022-05-24 13:32:31.867643 zenml-0.8.1rc0/setup.py
--rw-r--r--   0        0        0    17083 2022-05-24 13:32:31.868884 zenml-0.8.1rc0/PKG-INFO
+-rw-r--r--   0        0        0    11654 2022-06-14 08:26:03.219813 zenml-0.9.0/CLA.md
+-rw-r--r--   0        0        0     5496 2022-06-14 08:26:03.219813 zenml-0.9.0/CODE-OF-CONDUCT.md
+-rw-r--r--   0        0        0     9522 2022-06-14 08:26:03.219813 zenml-0.9.0/CONTRIBUTING.md
+-rw-r--r--   0        0        0    11359 2022-06-14 08:26:03.219813 zenml-0.9.0/LICENSE
+-rw-r--r--   0        0        0    16527 2022-06-14 08:26:03.219813 zenml-0.9.0/README.md
+-rw-r--r--   0        0        0    78330 2022-06-14 08:26:03.219813 zenml-0.9.0/RELEASE_NOTES.md
+-rw-r--r--   0        0        0      407 2022-06-14 08:26:03.219813 zenml-0.9.0/ROADMAP.md
+-rw-r--r--   0        0        0     5931 2022-06-14 08:26:03.267814 zenml-0.9.0/pyproject.toml
+-rw-r--r--   0        0        0     2170 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/README.md
+-rw-r--r--   0        0        0        5 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/VERSION
+-rw-r--r--   0        0        0     1244 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/__init__.py
+-rw-r--r--   0        0        0     1002 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/alerter/__init__.py
+-rw-r--r--   0        0        0     3178 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/alerter/alerter_step.py
+-rw-r--r--   0        0        0     2112 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/alerter/base_alerter.py
+-rw-r--r--   0        0        0     1531 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifact_stores/__init__.py
+-rw-r--r--   0        0        0    10987 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifact_stores/base_artifact_store.py
+-rw-r--r--   0        0        0     8163 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifact_stores/local_artifact_store.py
+-rw-r--r--   0        0        0     1856 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/__init__.py
+-rw-r--r--   0        0        0     4633 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/base_artifact.py
+-rw-r--r--   0        0        0      729 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/constants.py
+-rw-r--r--   0        0        0     1024 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/data_analysis_artifact.py
+-rw-r--r--   0        0        0      825 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/data_artifact.py
+-rw-r--r--   0        0        0      829 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/model_artifact.py
+-rw-r--r--   0        0        0      818 2022-06-14 08:26:03.267814 zenml-0.9.0/src/zenml/artifacts/schema_artifact.py
+-rw-r--r--   0        0        0      838 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/artifacts/service_artifact.py
+-rw-r--r--   0        0        0      840 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/artifacts/statistics_artifact.py
+-rw-r--r--   0        0        0     3791 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/artifacts/type_registry.py
+-rw-r--r--   0        0        0    23426 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/__init__.py
+-rw-r--r--   0        0        0    10010 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/base.py
+-rw-r--r--   0        0        0     4887 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/cli.py
+-rw-r--r--   0        0        0    19158 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/config.py
+-rw-r--r--   0        0        0    30112 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/example.py
+-rw-r--r--   0        0        0     3710 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/feature.py
+-rw-r--r--   0        0        0     6453 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/formatter.py
+-rw-r--r--   0        0        0     8876 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/integration.py
+-rw-r--r--   0        0        0     8541 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/pipeline.py
+-rw-r--r--   0        0        0    16759 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/secret.py
+-rw-r--r--   0        0        0    12413 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/served_models.py
+-rw-r--r--   0        0        0     7276 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/server.py
+-rw-r--r--   0        0        0    33759 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/stack.py
+-rw-r--r--   0        0        0    42044 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/stack_components.py
+-rw-r--r--   0        0        0     2555 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/text_utils.py
+-rw-r--r--   0        0        0    16224 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/user_management.py
+-rw-r--r--   0        0        0    23629 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/utils.py
+-rw-r--r--   0        0        0     3635 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/cli/version.py
+-rw-r--r--   0        0        0     1440 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/config/__init__.py
+-rw-r--r--   0        0        0     2644 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/config/base_config.py
+-rw-r--r--   0        0        0     3167 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/config/config_keys.py
+-rw-r--r--   0        0        0    22415 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/config/global_config.py
+-rw-r--r--   0        0        0     7393 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/config/profile_config.py
+-rw-r--r--   0        0        0     1161 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/console.py
+-rw-r--r--   0        0        0     5057 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/constants.py
+-rw-r--r--   0        0        0     2269 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/__init__.py
+-rw-r--r--   0        0        0     1036 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/azure_container_registry.py
+-rw-r--r--   0        0        0     3603 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/base_container_registry.py
+-rw-r--r--   0        0        0     1051 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/default_container_registry.py
+-rw-r--r--   0        0        0     1051 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/dockerhub_container_registry.py
+-rw-r--r--   0        0        0     1027 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/gcp_container_registry.py
+-rw-r--r--   0        0        0     1432 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/github_container_registry.py
+-rw-r--r--   0        0        0     1039 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/container_registries/gitlab_container_registry.py
+-rw-r--r--   0        0        0      806 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/entrypoints/__init__.py
+-rw-r--r--   0        0        0     2299 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/entrypoints/step_entrypoint.py
+-rw-r--r--   0        0        0    27633 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/entrypoints/step_entrypoint_configuration.py
+-rw-r--r--   0        0        0     2909 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/enums.py
+-rw-r--r--   0        0        0    15479 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/environment.py
+-rw-r--r--   0        0        0     8106 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/exceptions.py
+-rw-r--r--   0        0        0     1119 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/experiment_trackers/__init__.py
+-rw-r--r--   0        0        0     1037 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/experiment_trackers/base_experiment_tracker.py
+-rw-r--r--   0        0        0     1415 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/feature_stores/__init__.py
+-rw-r--r--   0        0        0     2148 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/feature_stores/base_feature_store.py
+-rw-r--r--   0        0        0     3643 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/README.md
+-rw-r--r--   0        0        0     2670 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/__init__.py
+-rw-r--r--   0        0        0     1871 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/airflow/__init__.py
+-rw-r--r--   0        0        0      810 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/airflow/orchestrators/__init__.py
+-rw-r--r--   0        0        0    16264 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/airflow/orchestrators/airflow_orchestrator.py
+-rw-r--r--   0        0        0     2583 2022-06-14 08:26:03.271814 zenml-0.9.0/src/zenml/integrations/aws/__init__.py
+-rw-r--r--   0        0        0      791 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/container_registries/__init__.py
+-rw-r--r--   0        0        0     4079 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/container_registries/aws_container_registry.py
+-rw-r--r--   0        0        0      773 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/secrets_managers/__init__.py
+-rw-r--r--   0        0        0     5859 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/secrets_managers/aws_secrets_manager.py
+-rw-r--r--   0        0        0      780 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/step_operators/__init__.py
+-rw-r--r--   0        0        0     5416 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/aws/step_operators/sagemaker_step_operator.py
+-rw-r--r--   0        0        0     2745 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/__init__.py
+-rw-r--r--   0        0        0      786 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/artifact_stores/__init__.py
+-rw-r--r--   0        0        0     9876 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/artifact_stores/azure_artifact_store.py
+-rw-r--r--   0        0        0      790 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/secrets_managers/__init__.py
+-rw-r--r--   0        0        0     8969 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/secrets_managers/azure_secrets_manager.py
+-rw-r--r--   0        0        0      784 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/step_operators/__init__.py
+-rw-r--r--   0        0        0     8460 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/azure/step_operators/azureml_step_operator.py
+-rw-r--r--   0        0        0     1304 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/constants.py
+-rw-r--r--   0        0        0     1065 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/dash/__init__.py
+-rw-r--r--   0        0        0      666 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/dash/visualizers/__init__.py
+-rw-r--r--   0        0        0    15315 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/dash/visualizers/pipeline_run_lineage_visualizer.py
+-rw-r--r--   0        0        0     1350 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/evidently/__init__.py
+-rw-r--r--   0        0        0      791 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/evidently/steps/__init__.py
+-rw-r--r--   0        0        0     5867 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/evidently/steps/evidently_profile.py
+-rw-r--r--   0        0        0      764 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/evidently/visualizers/__init__.py
+-rw-r--r--   0        0        0     2588 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/evidently/visualizers/evidently_visualizer.py
+-rw-r--r--   0        0        0     1292 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/facets/__init__.py
+-rw-r--r--   0        0        0      660 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/facets/visualizers/__init__.py
+-rw-r--r--   0        0        0     4029 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/facets/visualizers/facet_statistics_visualizer.py
+-rw-r--r--   0        0        0     1284 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/facets/visualizers/stats.html
+-rw-r--r--   0        0        0     1837 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/feast/__init__.py
+-rw-r--r--   0        0        0     1236 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/feast/feature_stores/__init__.py
+-rw-r--r--   0        0        0     6266 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/feast/feature_stores/feast_feature_store.py
+-rw-r--r--   0        0        0     3261 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/__init__.py
+-rw-r--r--   0        0        0      766 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/artifact_stores/__init__.py
+-rw-r--r--   0        0        0     8280 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/artifact_stores/gcp_artifact_store.py
+-rw-r--r--   0        0        0     1241 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/constants.py
+-rw-r--r--   0        0        0     1959 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/google_credentials_mixin.py
+-rw-r--r--   0        0        0      771 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/orchestrators/__init__.py
+-rw-r--r--   0        0        0     2311 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/orchestrators/vertex_entrypoint_configuration.py
+-rw-r--r--   0        0        0    22554 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/orchestrators/vertex_orchestrator.py
+-rw-r--r--   0        0        0      926 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/secrets_manager/__init__.py
+-rw-r--r--   0        0        0     9224 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/secrets_manager/gcp_secrets_manager.py
+-rw-r--r--   0        0        0      774 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/step_operators/__init__.py
+-rw-r--r--   0        0        0    12064 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/gcp/step_operators/vertex_step_operator.py
+-rw-r--r--   0        0        0     2071 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/__init__.py
+-rw-r--r--   0        0        0      827 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/orchestrators/__init__.py
+-rw-r--r--   0        0        0     2269 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/orchestrators/github_actions_entrypoint_configuration.py
+-rw-r--r--   0        0        0    22624 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/orchestrators/github_actions_orchestrator.py
+-rw-r--r--   0        0        0      810 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/secrets_managers/__init__.py
+-rw-r--r--   0        0        0    14465 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/github/secrets_managers/github_secrets_manager.py
+-rw-r--r--   0        0        0     1015 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/graphviz/__init__.py
+-rw-r--r--   0        0        0      659 2022-06-14 08:26:03.275814 zenml-0.9.0/src/zenml/integrations/graphviz/visualizers/__init__.py
+-rw-r--r--   0        0        0     3255 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/graphviz/visualizers/pipeline_run_dag_visualizer.py
+-rw-r--r--   0        0        0     1160 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/__init__.py
+-rw-r--r--   0        0        0     1156 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/materializers/__init__.py
+-rw-r--r--   0        0        0     2058 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_datasets_materializer.py
+-rw-r--r--   0        0        0     2346 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_pt_model_materializer.py
+-rw-r--r--   0        0        0     2356 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_tf_model_materializer.py
+-rw-r--r--   0        0        0     2158 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_tokenizer_materializer.py
+-rw-r--r--   0        0        0     3607 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/integration.py
+-rw-r--r--   0        0        0     2162 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/__init__.py
+-rw-r--r--   0        0        0      825 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/metadata_stores/__init__.py
+-rw-r--r--   0        0        0    11960 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/metadata_stores/kubeflow_metadata_store.py
+-rw-r--r--   0        0        0      785 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/__init__.py
+-rw-r--r--   0        0        0     3790 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_entrypoint_configuration.py
+-rw-r--r--   0        0        0    47805 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_orchestrator.py
+-rw-r--r--   0        0        0    15391 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/local_deployment_utils.py
+-rw-r--r--   0        0        0    11492 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/utils.py
+-rw-r--r--   0        0        0     1130 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/lightgbm/__init__.py
+-rw-r--r--   0        0        0      929 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/__init__.py
+-rw-r--r--   0        0        0     2586 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/lightgbm_booster_materializer.py
+-rw-r--r--   0        0        0     2526 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/lightgbm_dataset_materializer.py
+-rw-r--r--   0        0        0     2394 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/__init__.py
+-rw-r--r--   0        0        0      736 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/experiment_trackers/__init__.py
+-rw-r--r--   0        0        0    10926 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/experiment_trackers/mlflow_experiment_tracker.py
+-rw-r--r--   0        0        0     5203 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/mlflow_step_decorator.py
+-rw-r--r--   0        0        0     2322 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/mlflow_utils.py
+-rw-r--r--   0        0        0      721 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/model_deployers/__init__.py
+-rw-r--r--   0        0        0    18318 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/model_deployers/mlflow_model_deployer.py
+-rw-r--r--   0        0        0      791 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/services/__init__.py
+-rw-r--r--   0        0        0     7853 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/services/mlflow_deployment.py
+-rw-r--r--   0        0        0      822 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/steps/__init__.py
+-rw-r--r--   0        0        0     8080 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/mlflow/steps/mlflow_deployer.py
+-rw-r--r--   0        0        0     1232 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/neural_prophet/__init__.py
+-rw-r--r--   0        0        0      802 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/neural_prophet/materializers/__init__.py
+-rw-r--r--   0        0        0     2155 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/neural_prophet/materializers/neural_prophet_materializer.py
+-rw-r--r--   0        0        0      956 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/plotly/__init__.py
+-rw-r--r--   0        0        0      660 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/plotly/visualizers/__init__.py
+-rw-r--r--   0        0        0     2593 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/plotly/visualizers/pipeline_lineage_visualizer.py
+-rw-r--r--   0        0        0     1171 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch/__init__.py
+-rw-r--r--   0        0        0      920 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch/materializers/__init__.py
+-rw-r--r--   0        0        0     2185 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch/materializers/pytorch_dataloader_materializer.py
+-rw-r--r--   0        0        0     2716 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch/materializers/pytorch_module_materializer.py
+-rw-r--r--   0        0        0     1177 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch_lightning/__init__.py
+-rw-r--r--   0        0        0      814 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch_lightning/materializers/__init__.py
+-rw-r--r--   0        0        0     1893 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/pytorch_lightning/materializers/pytorch_lightning_materializer.py
+-rw-r--r--   0        0        0     5520 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/registry.py
+-rw-r--r--   0        0        0     1698 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/s3/__init__.py
+-rw-r--r--   0        0        0      762 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/s3/artifact_stores/__init__.py
+-rw-r--r--   0        0        0    12170 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/s3/artifact_stores/s3_artifact_store.py
+-rw-r--r--   0        0        0     1099 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/scipy/__init__.py
+-rw-r--r--   0        0        0      770 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/scipy/materializers/__init__.py
+-rw-r--r--   0        0        0     1912 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/scipy/materializers/sparse_materializer.py
+-rw-r--r--   0        0        0     2030 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/__init__.py
+-rw-r--r--   0        0        0      777 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/model_deployers/__init__.py
+-rw-r--r--   0        0        0    19866 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/model_deployers/seldon_model_deployer.py
+-rw-r--r--   0        0        0     1265 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/secret_schemas/__init__.py
+-rw-r--r--   0        0        0     4839 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/secret_schemas/secret_schemas.py
+-rw-r--r--   0        0        0    37053 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/seldon_client.py
+-rw-r--r--   0        0        0      789 2022-06-14 08:26:03.279814 zenml-0.9.0/src/zenml/integrations/seldon/services/__init__.py
+-rw-r--r--   0        0        0    13933 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/seldon/services/seldon_deployment.py
+-rw-r--r--   0        0        0      778 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/seldon/steps/__init__.py
+-rw-r--r--   0        0        0     7540 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/seldon/steps/seldon_deployer.py
+-rw-r--r--   0        0        0     1120 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/__init__.py
+-rw-r--r--   0        0        0      687 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/helpers/__init__.py
+-rw-r--r--   0        0        0     1815 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/helpers/digits.py
+-rw-r--r--   0        0        0      775 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/materializers/__init__.py
+-rw-r--r--   0        0        0     2919 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/materializers/sklearn_materializer.py
+-rw-r--r--   0        0        0     1030 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/steps/__init__.py
+-rw-r--r--   0        0        0     2108 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_evaluator.py
+-rw-r--r--   0        0        0     2967 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_splitter.py
+-rw-r--r--   0        0        0     3832 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_standard_scaler.py
+-rw-r--r--   0        0        0     1721 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/slack/__init__.py
+-rw-r--r--   0        0        0      696 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/slack/alerters/__init__.py
+-rw-r--r--   0        0        0     7310 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/slack/alerters/slack_alerter.py
+-rw-r--r--   0        0        0     1410 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/__init__.py
+-rw-r--r--   0        0        0      906 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/__init__.py
+-rw-r--r--   0        0        0     2349 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/keras_materializer.py
+-rw-r--r--   0        0        0     1876 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/tf_dataset_materializer.py
+-rw-r--r--   0        0        0      796 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/services/__init__.py
+-rw-r--r--   0        0        0     4455 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/services/tensorboard_service.py
+-rw-r--r--   0        0        0      807 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/steps/__init__.py
+-rw-r--r--   0        0        0     3270 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/steps/tensorflow_trainer.py
+-rw-r--r--   0        0        0      833 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/visualizers/__init__.py
+-rw-r--r--   0        0        0     7999 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/tensorflow/visualizers/tensorboard_visualizer.py
+-rw-r--r--   0        0        0     2726 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/utils.py
+-rw-r--r--   0        0        0     1834 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/wandb/__init__.py
+-rw-r--r--   0        0        0      733 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/wandb/experiment_trackers/__init__.py
+-rw-r--r--   0        0        0     3273 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/wandb/experiment_trackers/wandb_experiment_tracker.py
+-rw-r--r--   0        0        0     7217 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/wandb/wandb_step_decorator.py
+-rw-r--r--   0        0        0     1244 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/__init__.py
+-rw-r--r--   0        0        0      774 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/materializers/__init__.py
+-rw-r--r--   0        0        0     2421 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/materializers/whylogs_materializer.py
+-rw-r--r--   0        0        0      801 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/steps/__init__.py
+-rw-r--r--   0        0        0     4445 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/steps/whylogs_profiler.py
+-rw-r--r--   0        0        0      784 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/visualizers/__init__.py
+-rw-r--r--   0        0        0     5364 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/visualizers/whylogs_visualizer.py
+-rw-r--r--   0        0        0     4922 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/whylogs_context.py
+-rw-r--r--   0        0        0     5327 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/whylogs/whylogs_step_decorator.py
+-rw-r--r--   0        0        0     1122 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/xgboost/__init__.py
+-rw-r--r--   0        0        0      917 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/xgboost/materializers/__init__.py
+-rw-r--r--   0        0        0     2596 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/xgboost/materializers/xgboost_booster_materializer.py
+-rw-r--r--   0        0        0     2533 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/integrations/xgboost/materializers/xgboost_dmatrix_materializer.py
+-rw-r--r--   0        0        0      843 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/io/__init__.py
+-rw-r--r--   0        0        0     1955 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/io/fileio.py
+-rw-r--r--   0        0        0     7119 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/logger.py
+-rw-r--r--   0        0        0     1280 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/__init__.py
+-rw-r--r--   0        0        0     5823 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/base_materializer.py
+-rw-r--r--   0        0        0     1863 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/beam_materializer.py
+-rw-r--r--   0        0        0     2348 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/built_in_materializer.py
+-rw-r--r--   0        0        0     5131 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/default_materializer_registry.py
+-rw-r--r--   0        0        0     2684 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/numpy_materializer.py
+-rw-r--r--   0        0        0     3092 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/pandas_materializer.py
+-rw-r--r--   0        0        0     2361 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/materializers/service_materializer.py
+-rw-r--r--   0        0        0     1348 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/metadata_stores/__init__.py
+-rw-r--r--   0        0        0    16786 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/metadata_stores/base_metadata_store.py
+-rw-r--r--   0        0        0     6018 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/metadata_stores/mysql_metadata_store.py
+-rw-r--r--   0        0        0     1118 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/metadata_stores/mysql_secret_schema.py
+-rw-r--r--   0        0        0     2249 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/metadata_stores/sqlite_metadata_store.py
+-rw-r--r--   0        0        0     1661 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/model_deployers/__init__.py
+-rw-r--r--   0        0        0     9461 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/model_deployers/base_model_deployer.py
+-rw-r--r--   0        0        0     1313 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/orchestrators/__init__.py
+-rw-r--r--   0        0        0    17544 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/orchestrators/base_orchestrator.py
+-rw-r--r--   0        0        0     5413 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/orchestrators/context_utils.py
+-rw-r--r--   0        0        0      662 2022-06-14 08:26:03.283814 zenml-0.9.0/src/zenml/orchestrators/local/__init__.py
+-rw-r--r--   0        0        0     2592 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/orchestrators/local/local_orchestrator.py
+-rw-r--r--   0        0        0     3126 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/orchestrators/utils.py
+-rw-r--r--   0        0        0     1507 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/__init__.py
+-rw-r--r--   0        0        0    22608 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/base_pipeline.py
+-rw-r--r--   0        0        0      745 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/builtin_pipelines/__init__.py
+-rw-r--r--   0        0        0     2640 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/builtin_pipelines/training_pipeline.py
+-rw-r--r--   0        0        0     4565 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/pipeline_decorator.py
+-rw-r--r--   0        0        0     4188 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/pipelines/schedule.py
+-rw-r--r--   0        0        0     1230 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/post_execution/__init__.py
+-rw-r--r--   0        0        0     7622 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/post_execution/artifact.py
+-rw-r--r--   0        0        0     6704 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/post_execution/pipeline.py
+-rw-r--r--   0        0        0     7294 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/post_execution/pipeline_run.py
+-rw-r--r--   0        0        0     8681 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/post_execution/step.py
+-rw-r--r--   0        0        0      613 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/py.typed
+-rw-r--r--   0        0        0    45822 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/repository.py
+-rw-r--r--   0        0        0     2433 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/runtime_configuration.py
+-rw-r--r--   0        0        0     1671 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/__init__.py
+-rw-r--r--   0        0        0     1985 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/arbitrary_secret_schema.py
+-rw-r--r--   0        0        0     2368 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/base_secret.py
+-rw-r--r--   0        0        0     1054 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/schemas/__init__.py
+-rw-r--r--   0        0        0     1041 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/schemas/aws_secret_schema.py
+-rw-r--r--   0        0        0     1220 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/schemas/azure_secret_schema.py
+-rw-r--r--   0        0        0     1165 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/schemas/basic_auth_secret_schema.py
+-rw-r--r--   0        0        0     1769 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/schemas/gcp_secret_schema.py
+-rw-r--r--   0        0        0     4437 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secret/secret_schema_class_registry.py
+-rw-r--r--   0        0        0      908 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secrets_managers/__init__.py
+-rw-r--r--   0        0        0     2199 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secrets_managers/base_secrets_manager.py
+-rw-r--r--   0        0        0      670 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secrets_managers/local/__init__.py
+-rw-r--r--   0        0        0     7672 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secrets_managers/local/local_secrets_manager.py
+-rw-r--r--   0        0        0     2241 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/secrets_managers/utils.py
+-rw-r--r--   0        0        0     2479 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/__init__.py
+-rw-r--r--   0        0        0      660 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/local/__init__.py
+-rw-r--r--   0        0        0     2904 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/local/local_daemon_entrypoint.py
+-rw-r--r--   0        0        0    15637 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/local/local_service.py
+-rw-r--r--   0        0        0     4911 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/local/local_service_endpoint.py
+-rw-r--r--   0        0        0    16050 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service.py
+-rw-r--r--   0        0        0     6253 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service_endpoint.py
+-rw-r--r--   0        0        0     7700 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service_monitor.py
+-rw-r--r--   0        0        0     7366 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service_registry.py
+-rw-r--r--   0        0        0     2633 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service_status.py
+-rw-r--r--   0        0        0     1152 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/service_type.py
+-rw-r--r--   0        0        0     2841 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/services/utils.py
+-rw-r--r--   0        0        0     1153 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/__init__.py
+-rw-r--r--   0        0        0     2751 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/authentication_mixin.py
+-rw-r--r--   0        0        0     4417 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/flavor_registry.py
+-rw-r--r--   0        0        0    24223 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/stack.py
+-rw-r--r--   0        0        0    11175 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/stack_component.py
+-rw-r--r--   0        0        0     3111 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/stack/stack_validator.py
+-rw-r--r--   0        0        0     1096 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/step_operators/__init__.py
+-rw-r--r--   0        0        0     1961 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/step_operators/base_step_operator.py
+-rw-r--r--   0        0        0     6218 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/step_operators/entrypoint.py
+-rw-r--r--   0        0        0     9512 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/step_operators/step_executor_operator.py
+-rw-r--r--   0        0        0     1773 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/steps/__init__.py
+-rw-r--r--   0        0        0    32396 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/steps/base_step.py
+-rw-r--r--   0        0        0      777 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/steps/base_step_config.py
+-rw-r--r--   0        0        0      868 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/steps/builtin_steps/__init__.py
+-rw-r--r--   0        0        0     2208 2022-06-14 08:26:03.287814 zenml-0.9.0/src/zenml/steps/builtin_steps/pandas_analyzer.py
+-rw-r--r--   0        0        0     1782 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/builtin_steps/pandas_datasource.py
+-rw-r--r--   0        0        0     1872 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/restrict_step_access_decorator.py
+-rw-r--r--   0        0        0     7932 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_context.py
+-rw-r--r--   0        0        0     3802 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_decorator.py
+-rw-r--r--   0        0        0     2720 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_environment.py
+-rw-r--r--   0        0        0     2000 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/__init__.py
+-rw-r--r--   0        0        0     1394 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_alerter_step.py
+-rw-r--r--   0        0        0     1630 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_analyzer_step.py
+-rw-r--r--   0        0        0     1400 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_datasource_step.py
+-rw-r--r--   0        0        0     1657 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_drift_detection_step.py
+-rw-r--r--   0        0        0     1545 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_evaluator_step.py
+-rw-r--r--   0        0        0     2057 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_preprocessor_step.py
+-rw-r--r--   0        0        0     1569 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_split_step.py
+-rw-r--r--   0        0        0     1581 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_interfaces/base_trainer_step.py
+-rw-r--r--   0        0        0     1402 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/step_output.py
+-rw-r--r--   0        0        0    20680 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/steps/utils.py
+-rw-r--r--   0        0        0      797 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/__init__.py
+-rw-r--r--   0        0        0     8331 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/analytics_utils.py
+-rw-r--r--   0        0        0    10222 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/daemon.py
+-rw-r--r--   0        0        0    13873 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/docker_utils.py
+-rw-r--r--   0        0        0     1368 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/enum_utils.py
+-rw-r--r--   0        0        0     4435 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/filesync_model.py
+-rw-r--r--   0        0        0     6022 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/io_utils.py
+-rw-r--r--   0        0        0     2872 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/networking_utils.py
+-rw-r--r--   0        0        0     2179 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/singleton.py
+-rw-r--r--   0        0        0    18002 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/source_utils.py
+-rw-r--r--   0        0        0     2512 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/string_utils.py
+-rw-r--r--   0        0        0     4690 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/typed_model.py
+-rw-r--r--   0        0        0     4762 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/utils/yaml_utils.py
+-rw-r--r--   0        0        0     1367 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/visualizers/__init__.py
+-rw-r--r--   0        0        0     1359 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/visualizers/base_pipeline_run_visualizer.py
+-rw-r--r--   0        0        0     1320 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/visualizers/base_pipeline_visualizer.py
+-rw-r--r--   0        0        0     1292 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/visualizers/base_step_visualizer.py
+-rw-r--r--   0        0        0     1173 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/visualizers/base_visualizer.py
+-rw-r--r--   0        0        0     1252 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_server/__init__.py
+-rw-r--r--   0        0        0     6516 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_server/zen_server.py
+-rw-r--r--   0        0        0    25850 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_server/zen_server_api.py
+-rw-r--r--   0        0        0     1015 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/__init__.py
+-rw-r--r--   0        0        0    36805 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/base_zen_store.py
+-rw-r--r--   0        0        0    35908 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/local_zen_store.py
+-rw-r--r--   0        0        0     1293 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/__init__.py
+-rw-r--r--   0        0        0     2274 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/component_wrapper.py
+-rw-r--r--   0        0        0     3928 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/flavor_wrapper.py
+-rw-r--r--   0        0        0     4303 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/pipeline_models.py
+-rw-r--r--   0        0        0     2506 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/stack_wrapper.py
+-rw-r--r--   0        0        0     4748 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/user_management_models.py
+-rw-r--r--   0        0        0     5131 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/models/zen_store_model.py
+-rw-r--r--   0        0        0    35313 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/rest_zen_store.py
+-rw-r--r--   0        0        0    52566 2022-06-14 08:26:03.291814 zenml-0.9.0/src/zenml/zen_stores/sql_zen_store.py
+-rw-r--r--   0        0        0    22156 2022-06-14 08:26:23.729873 zenml-0.9.0/setup.py
+-rw-r--r--   0        0        0    18486 2022-06-14 08:26:23.731572 zenml-0.9.0/PKG-INFO
```

### Comparing `zenml-0.8.1rc0/CLA.md` & `zenml-0.9.0/CLA.md`

 * *Files identical despite different names*

### Comparing `zenml-0.8.1rc0/CODE-OF-CONDUCT.md` & `zenml-0.9.0/CODE-OF-CONDUCT.md`

 * *Files identical despite different names*

### Comparing `zenml-0.8.1rc0/LICENSE` & `zenml-0.9.0/LICENSE`

 * *Files identical despite different names*

### Comparing `zenml-0.8.1rc0/README.md` & `zenml-0.9.0/README.md`

 * *Files 5% similar despite different names*

```diff
@@ -1,40 +1,48 @@
 <div align="center">
-    <img src="https://zenml.io/assets/social/github.svg">
+    <img src="docs/book/assets/oss-header.svg">
 </div>
 
-# ⏲️ Join the ZenML team on the MLOps Day
+# :family_man_woman_boy_boy: ZenML: Meet the Team
 
-We are hosting a MLOps day where we'll be building a vendor-agnostic MLOps pipeline from scratch.
-
-Sign up [here](https://www.eventbrite.com/e/zenml-mlops-day-join-us-in-building-a-vendor-agnostic-mlops-pipeline-tickets-336331515617) to join the entire ZenML team in showcasing the latest release, answering the community's questions, and live-coding vendor agnostic MLOps features with the ZenML framework!
+Hi ZenCommunity! Did you ever have a question that's too hard to express on our Slack? Is it just too much effort to say everything on a 
+long GitHub issue? Or are you just curious what ZenML has been up to in the past week? Well, register now for the ZenML Office 
+(Half) Hour to get your answers and more!
+
+Every week, part of the ZenML core team will pop in for 30 minutes to interact directly with the community. Sometimes we'll be presenting a 
+feature, other times just taking questions, and having fun. Join us if you are curious about ZenML, or just want to talk shop about MLOps.
+
+We will host the gathering every Wednesday 8:30AM PT (5:30PM CET). Register now through [this link](https://www.eventbrite.com/e/zenml-meet-the-community-tickets-354426688767), 
+or subscribe to the [public events calendar](https://calendar.google.com/calendar/u/0/r?cid=Y19iaDJ0Zm44ZzdodXBlbnBzaWplY3UwMmNjZ0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t) to get notified 
+before every community gathering.
 
 # 👀 What is ZenML?
 
-**ZenML** is an extensible, open-source MLOps framework to create
-production-ready machine learning pipelines. Built for data scientists, it has a
-simple, flexible syntax, is cloud- and tool-agnostic, and has
-interfaces/abstractions that are catered towards ML workflows.
+**ZenML** is an extensible, open-source MLOps framework for creating 
+portable, production-ready MLOps pipelines. Built to enable collaboration among data scientists, ML Engineers, and MLOps Developers,
+it has a simple, flexible syntax, is **cloud-** and 
+**tool-agnostic**, and has interfaces/abstractions that are thoughtfully designed for 
+ML workflows. 
 
 At its core, **ZenML pipelines execute ML-specific workflows** from sourcing
-data to splitting, preprocessing, training, all the way to the evaluation of
-results and even serving. There are many built-in batteries to support common ML
-development tasks. ZenML is not here to replace the great tools that solve these
-individual problems. Rather, it offers an **extensible framework** and a
+data to splitting, preprocessing, training, all the way to serving and monitoring 
+ML models in production. There are many built-in features to support
+common ML development tasks. ZenML is not here to replace the great tools that
+solve these individual problems. Rather, it offers an **extensible framework** and a
 standard abstraction to write and build your workflows.
 
-🎉 **Version 0.8.0 out now!** [Check out the release notes
+🎉 **Version 0.9.0 out now!** [Check out the release notes
 here](https://github.com/zenml-io/zenml/releases).
 
 [![PyPI - Python
 Version](https://img.shields.io/pypi/pyversions/zenml)](https://pypi.org/project/zenml/)
 [![PyPI Status](https://pepy.tech/badge/zenml)](https://pepy.tech/project/zenml)
 ![GitHub](https://img.shields.io/github/license/zenml-io/zenml)
 [![Codecov](https://codecov.io/gh/zenml-io/zenml/branch/main/graph/badge.svg)](https://codecov.io/gh/zenml-io/zenml)
-[![Interrogate](docs/interrogate.svg)](https://interrogate.readthedocs.io/en/latest/)
+[![Interrogate](docs/book/assets/interrogate.svg)](https://interrogate.readthedocs.io/en/latest/)
 [![Main Workflow
 Tests](https://github.com/zenml-io/zenml/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/zenml-io/zenml/actions/workflows/ci.yml)
 
 <div align="center">
 Join our <a href="https://zenml.io/slack-invite" target="_blank">
     <img width="25" src="https://cdn3.iconfinder.com/data/icons/logos-and-brands-adobe/512/306_Slack-512.png" alt="Slack"/>
 <b>Slack Community</b> </a> and become part of the ZenML family
@@ -68,15 +76,15 @@
 # 📖 Learn More
 
 | ZenML Resources | Description |
 | ------------- | - |
 | 🧘‍♀️ **[ZenML 101]** | New to ZenML? Here's everything you need to know! |
 | ⚛️ **[Core Concepts]** | Some key terms and concepts we use. |
 | 🗃 **[Functional API Guide]** | Build production ML pipelines with simple functions. |
-| 🚀 **[New in v0.8.0]** | New features, bug fixes. |
+| 🚀 **[New in v0.9.0]** | New features, bug fixes. |
 | 🗳 **[Vote for Features]** | Pick what we work on next! |
 | 📓 **[Docs]** | Full documentation for creating your own ZenML pipelines. |
 | 📒 **[API Reference]** | The detailed reference for ZenML's API. |
 | 🍰 **[ZenBytes]** | A guided and in-depth tutorial on MLOps and ZenML. |
 | 🗂️️ **[ZenFiles]** | End-to-end projects using ZenML. |
 | ⚽️ **[Examples]** | Learn best through examples where ZenML is used? We've got you covered. |
 | 📬 **[Blog]** | Use cases of ZenML and technical deep dives on how we built it. |
@@ -85,15 +93,15 @@
 | 💬 **[Join Slack]** | Need help with your specific use case? Say hi on Slack! |
 | 🗺 **[Roadmap]** | See where ZenML is working to build new features. |
 | 🙋‍♀️ **[Contribute]** | How to contribute to the ZenML project and code base. |
 
 [ZenML 101]: https://docs.zenml.io/
 [Core Concepts]: https://docs.zenml.io/core-concepts
 [Functional API Guide]: https://docs.zenml.io/v/docs/guides/functional-api
-[New in v0.8.0]: https://github.com/zenml-io/zenml/releases
+[New in v0.9.0]: https://github.com/zenml-io/zenml/releases
 [Vote for Features]: https://zenml.io/discussion
 [Docs]: https://docs.zenml.io/
 [API Reference]: https://apidocs.zenml.io/
 [ZenBytes]: https://github.com/zenml-io/zenbytes
 [ZenFiles]: https://github.com/zenml-io/zenfiles
 [Examples]: https://github.com/zenml-io/zenml/tree/main/examples
 [Blog]: https://blog.zenml.io/
@@ -184,15 +192,15 @@
 
 Read more about CT/CD in ZenML [here](https://blog.zenml.io/ci-ct-cd-with-zenml/).
 
 # 🤸 Getting Started
 
 ## 💾 Install ZenML
 
-*Requirements*: ZenML supports Python 3.7 and 3.8.
+*Requirements*: ZenML supports Python 3.7, 3.8, and 3.9.
 
 ZenML is available for easy installation into your environment via PyPI:
 
 ```bash
 pip install zenml
 ```
 
@@ -207,14 +215,23 @@
 [DockerHub](https://hub.docker.com/r/zenmldocker/zenml). Use the following
 command to get started in a bash environment:
 
 ```shell
 docker run -it zenmldocker/zenml /bin/bash
 ```
 
+### 🐛 Known installation issues for M1 Mac Users
+
+If you have a M1 Mac machine and you are encountering an error while trying to install ZenML, 
+please try to setup `brew` and `pyenv` with Rosetta 2 and then install ZenML. The issue arises because some of the dependencies 
+aren’t fully compatible with the vanilla ARM64 Architecture. The following links may be helpful (Thank you @Reid Falconer) :
+
+- [Pyenv with Apple Silicon](http://sixty-north.com/blog/pyenv-apple-silicon.html)
+- [Install Python Under Rosetta 2](https://medium.com/thinknum/how-to-install-python-under-rosetta-2-f98c0865e012)
+
 ## 🚅 Quickstart
 
 The quickest way to get started is to create a simple pipeline.
 
 #### Step 1: Initialize a ZenML repo
 
 ```bash
@@ -301,14 +318,16 @@
 ZenML is built to support teams working together. The underlying infrastructure
 on which your ML workflows run can be shared, as can the data, assets and
 artifacts that you need to enable your work. ZenML Profiles offer an easy way to
 manage and switch between your stacks. The ZenML Server handles all the
 interaction and sharing and you can host it wherever you'd like.
 
 ```
+# Make sure to install ZenML with all necessary requirements for the ZenServer
+pip install zenml[server]
 zenml server up
 ```
 
 Read more about collaboration in ZenML [here](https://docs.zenml.io/collaborate/collaborate).
 
 # 🍰 ZenBytes
```

#### html2text {}

```diff
@@ -1,34 +1,43 @@
-                  [https://zenml.io/assets/social/github.svg]
-# â²ï¸ Join the ZenML team on the MLOps Day We are hosting a MLOps day where
-we'll be building a vendor-agnostic MLOps pipeline from scratch. Sign up [here]
-(https://www.eventbrite.com/e/zenml-mlops-day-join-us-in-building-a-vendor-
-agnostic-mlops-pipeline-tickets-336331515617) to join the entire ZenML team in
-showcasing the latest release, answering the community's questions, and live-
-coding vendor agnostic MLOps features with the ZenML framework! # ð What is
-ZenML? **ZenML** is an extensible, open-source MLOps framework to create
-production-ready machine learning pipelines. Built for data scientists, it has
-a simple, flexible syntax, is cloud- and tool-agnostic, and has interfaces/
-abstractions that are catered towards ML workflows. At its core, **ZenML
-pipelines execute ML-specific workflows** from sourcing data to splitting,
-preprocessing, training, all the way to the evaluation of results and even
-serving. There are many built-in batteries to support common ML development
-tasks. ZenML is not here to replace the great tools that solve these individual
-problems. Rather, it offers an **extensible framework** and a standard
-abstraction to write and build your workflows. ð **Version 0.8.0 out now!**
-[Check out the release notes here](https://github.com/zenml-io/zenml/releases).
-[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/zenml)](https:
-//pypi.org/project/zenml/) [![PyPI Status](https://pepy.tech/badge/zenml)]
-(https://pepy.tech/project/zenml) ![GitHub](https://img.shields.io/github/
-license/zenml-io/zenml) [![Codecov](https://codecov.io/gh/zenml-io/zenml/
-branch/main/graph/badge.svg)](https://codecov.io/gh/zenml-io/zenml) [!
-[Interrogate](docs/interrogate.svg)](https://interrogate.readthedocs.io/en/
-latest/) [![Main Workflow Tests](https://github.com/zenml-io/zenml/actions/
-workflows/ci.yml/badge.svg?branch=main)](https://github.com/zenml-io/zenml/
-actions/workflows/ci.yml)
+                       [docs/book/assets/oss-header.svg]
+# :family_man_woman_boy_boy: ZenML: Meet the Team Hi ZenCommunity! Did you ever
+have a question that's too hard to express on our Slack? Is it just too much
+effort to say everything on a long GitHub issue? Or are you just curious what
+ZenML has been up to in the past week? Well, register now for the ZenML Office
+(Half) Hour to get your answers and more! Every week, part of the ZenML core
+team will pop in for 30 minutes to interact directly with the community.
+Sometimes we'll be presenting a feature, other times just taking questions, and
+having fun. Join us if you are curious about ZenML, or just want to talk shop
+about MLOps. We will host the gathering every Wednesday 8:30AM PT (5:30PM CET).
+Register now through [this link](https://www.eventbrite.com/e/zenml-meet-the-
+community-tickets-354426688767), or subscribe to the [public events calendar]
+(https://calendar.google.com/calendar/u/0/
+r?cid=Y19iaDJ0Zm44ZzdodXBlbnBzaWplY3UwMmNjZ0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t)
+to get notified before every community gathering. # ð What is ZenML?
+**ZenML** is an extensible, open-source MLOps framework for creating portable,
+production-ready MLOps pipelines. Built to enable collaboration among data
+scientists, ML Engineers, and MLOps Developers, it has a simple, flexible
+syntax, is **cloud-** and **tool-agnostic**, and has interfaces/abstractions
+that are thoughtfully designed for ML workflows. At its core, **ZenML pipelines
+execute ML-specific workflows** from sourcing data to splitting, preprocessing,
+training, all the way to serving and monitoring ML models in production. There
+are many built-in features to support common ML development tasks. ZenML is not
+here to replace the great tools that solve these individual problems. Rather,
+it offers an **extensible framework** and a standard abstraction to write and
+build your workflows. ð **Version 0.9.0 out now!** [Check out the release
+notes here](https://github.com/zenml-io/zenml/releases). [![PyPI - Python
+Version](https://img.shields.io/pypi/pyversions/zenml)](https://pypi.org/
+project/zenml/) [![PyPI Status](https://pepy.tech/badge/zenml)](https://
+pepy.tech/project/zenml) ![GitHub](https://img.shields.io/github/license/zenml-
+io/zenml) [![Codecov](https://codecov.io/gh/zenml-io/zenml/branch/main/graph/
+badge.svg)](https://codecov.io/gh/zenml-io/zenml) [![Interrogate](docs/book/
+assets/interrogate.svg)](https://interrogate.readthedocs.io/en/latest/) [![Main
+Workflow Tests](https://github.com/zenml-io/zenml/actions/workflows/ci.yml/
+badge.svg?branch=main)](https://github.com/zenml-io/zenml/actions/workflows/
+ci.yml)
       Join our _[_S_l_a_c_k_]_SS_ll_aa_cc_kk_ _CC_oo_mm_mm_uu_nn_ii_tt_yy_ and become part of the ZenML family
                 Give us a [Slack]GGiittHHuubb ssttaarr to show your love
                   NNEEWW:: _[_V_o_t_e_]_VV_oo_tt_ee on the next ZenML features
 
 # ð¤ Why use ZenML? ZenML pipelines are designed to be written early on the
 development lifecycle. Data scientists can explore their pipelines as they
 develop towards production, switching stacks from local to cloud deployments
@@ -40,30 +49,30 @@
 pipeline in code - **Batteries-included integrations**: bring all your favorite
 tools together - Easy switch between local and cloud stacks - Painless
 **deployment and configuration** of infrastructure # ð Learn More | ZenML
 Resources | Description | | ------------- | - | | ð§ââï¸ **[ZenML 101]**
 | New to ZenML? Here's everything you need to know! | | âï¸ **[Core
 Concepts]** | Some key terms and concepts we use. | | ð **[Functional API
 Guide]** | Build production ML pipelines with simple functions. | | ð **[New
-in v0.8.0]** | New features, bug fixes. | | ð³ **[Vote for Features]** | Pick
+in v0.9.0]** | New features, bug fixes. | | ð³ **[Vote for Features]** | Pick
 what we work on next! | | ð **[Docs]** | Full documentation for creating
 your own ZenML pipelines. | | ð **[API Reference]** | The detailed reference
 for ZenML's API. | | ð° **[ZenBytes]** | A guided and in-depth tutorial on
 MLOps and ZenML. | | ðï¸ï¸ **[ZenFiles]** | End-to-end projects using
 ZenML. | | â½ï¸ **[Examples]** | Learn best through examples where ZenML is
 used? We've got you covered. | | ð¬ **[Blog]** | Use cases of ZenML and
 technical deep dives on how we built it. | | ð **[Podcast]** | Conversations
 with leaders in ML, released every 2 weeks. | | ð£ **[Newsletter]** | We
 build ZenML in public. Subscribe to learn how we work. | | ð¬ **[Join
 Slack]** | Need help with your specific use case? Say hi on Slack! | | ðº **
 [Roadmap]** | See where ZenML is working to build new features. | |
 ðââï¸ **[Contribute]** | How to contribute to the ZenML project and
 code base. | [ZenML 101]: https://docs.zenml.io/ [Core Concepts]: https://
 docs.zenml.io/core-concepts [Functional API Guide]: https://docs.zenml.io/v/
-docs/guides/functional-api [New in v0.8.0]: https://github.com/zenml-io/zenml/
+docs/guides/functional-api [New in v0.9.0]: https://github.com/zenml-io/zenml/
 releases [Vote for Features]: https://zenml.io/discussion [Docs]: https://
 docs.zenml.io/ [API Reference]: https://apidocs.zenml.io/ [ZenBytes]: https://
 github.com/zenml-io/zenbytes [ZenFiles]: https://github.com/zenml-io/zenfiles
 [Examples]: https://github.com/zenml-io/zenml/tree/main/examples [Blog]: https:
 //blog.zenml.io/ [Podcast]: https://podcast.zenml.io/ [Newsletter]: https://
 zenml.io/newsletter/ [Join Slack]: https://zenml.io/slack-invite/ [Roadmap]:
 https://zenml.io/roadmap [Contribute]: https://github.com/zenml-io/zenml/blob/
@@ -110,27 +119,35 @@
 Deployers and Services you can create end-to-end ML workflows with Continuous
 Training and Deployment that deploys your model in a local environment with
 MLFlow integration or even in a production-grade environment like Kubernetes
 with our Seldon Core integration. You can also listed served models with the
 CLI: ![CI/CD/CT in ZenML](docs/book/assets/ct_cd_zenml.gif) ``` zenml served-
 models list ``` Read more about CT/CD in ZenML [here](https://blog.zenml.io/ci-
 ct-cd-with-zenml/). # ð¤¸ Getting Started ## ð¾ Install ZenML
-*Requirements*: ZenML supports Python 3.7 and 3.8. ZenML is available for easy
-installation into your environment via PyPI: ```bash pip install zenml ```
+*Requirements*: ZenML supports Python 3.7, 3.8, and 3.9. ZenML is available for
+easy installation into your environment via PyPI: ```bash pip install zenml ```
 Alternatively, if youâre feeling brave, feel free to install the bleeding
 edge: **NOTE:** Do so on your own risk, no guarantees given! ```bash pip
 install git+https://github.com/zenml-io/zenml.git@main --upgrade ``` ZenML is
 also available as a Docker image hosted publicly on [DockerHub](https://
 hub.docker.com/r/zenmldocker/zenml). Use the following command to get started
 in a bash environment: ```shell docker run -it zenmldocker/zenml /bin/bash ```
-## ð Quickstart The quickest way to get started is to create a simple
-pipeline. #### Step 1: Initialize a ZenML repo ```bash zenml init zenml
-integration install sklearn -y # we use scikit-learn for this example ``` ####
-Step 2: Assemble, run, and evaluate your pipeline locally ```python import
-numpy as np from sklearn.base import ClassifierMixin from
+### ð Known installation issues for M1 Mac Users If you have a M1 Mac
+machine and you are encountering an error while trying to install ZenML, please
+try to setup `brew` and `pyenv` with Rosetta 2 and then install ZenML. The
+issue arises because some of the dependencies arenât fully compatible with
+the vanilla ARM64 Architecture. The following links may be helpful (Thank you
+@Reid Falconer) : - [Pyenv with Apple Silicon](http://sixty-north.com/blog/
+pyenv-apple-silicon.html) - [Install Python Under Rosetta 2](https://
+medium.com/thinknum/how-to-install-python-under-rosetta-2-f98c0865e012) ## ð
+Quickstart The quickest way to get started is to create a simple pipeline. ####
+Step 1: Initialize a ZenML repo ```bash zenml init zenml integration install
+sklearn -y # we use scikit-learn for this example ``` #### Step 2: Assemble,
+run, and evaluate your pipeline locally ```python import numpy as np from
+sklearn.base import ClassifierMixin from
 zenml.integrations.sklearn.helpers.digits import get_digits, get_digits_model
 from zenml.pipelines import pipeline from zenml.steps import step, Output @step
 def importer() -> Output( X_train=np.ndarray, X_test=np.ndarray,
 y_train=np.ndarray, y_test=np.ndarray ): """Loads the digits array as normal
 numpy arrays.""" X_train, X_test, y_train, y_test = get_digits() return
 X_train, X_test, y_train, y_test @step def trainer( X_train: np.ndarray,
 y_train: np.ndarray, ) -> ClassifierMixin: """Train a simple sklearn classifier
@@ -148,43 +165,45 @@
 via pip as described above and type: ```shell zenml go ``` This will spin up a
 Jupyter notebook that showcases the above example plus more on how to use and
 extend ZenML. # ð­ Collaborate with your team ZenML is built to support teams
 working together. The underlying infrastructure on which your ML workflows run
 can be shared, as can the data, assets and artifacts that you need to enable
 your work. ZenML Profiles offer an easy way to manage and switch between your
 stacks. The ZenML Server handles all the interaction and sharing and you can
-host it wherever you'd like. ``` zenml server up ``` Read more about
-collaboration in ZenML [here](https://docs.zenml.io/collaborate/collaborate). #
-ð° ZenBytes [ZenBytes](https://github.com/zenml-io/zenbytes) is a series of
-short practical MLOps lessons through ZenML and its various integrations. It is
-intended for people looking to learn about MLOps generally, and also for ML
-practitioners who want to get started with ZenML. After you've run and
-understood the simple example above, your next port of call is probably either
-the [fully-fleshed-out quickstart example](https://github.com/zenml-io/zenml/
-tree/main/examples/quickstart) and then to look at [the ZenBytes repository]
-(https://github.com/zenml-io/zenbytes) and notebooks. # ðï¸ ZenFiles
-ZenFiles are production-grade ML use-cases powered by ZenML. They are fully
-fleshed out, end-to-end, projects that showcase ZenML's capabilities. They can
-also serve as a template from which to start similar projects. The ZenFiles
-project is fully maintained and can be viewed as a sister repository of ZenML.
-Check it out [here](https://github.com/zenml-io/zenfiles). # ðº Roadmap ZenML
-is being built in public. The [roadmap](https://zenml.io/roadmap) is a
-regularly updated source of truth for the ZenML community to understand where
-the product is going in the short, medium, and long term. ZenML is managed by a
-[core team](https://zenml.io/team) of developers that are responsible for
-making key decisions and incorporating feedback from the community. The team
-oversees feedback via various channels, and you can directly influence the
-roadmap as follows: - Vote on your most wanted feature on our [Discussion
-board](https://zenml.io/discussion). You can also request for new features
-here. - Start a thread in our [Slack channel](https://zenml.io/slack-invite). #
-ðââï¸ Contributing & Community We would love to develop ZenML together
-with our community! Best way to get started is to select any issue from the
-[`good-first-issue` label](https://github.com/zenml-io/zenml/labels/
-good%20first%20issue). If you would like to contribute, please review our
-[Contributing Guide](CONTRIBUTING.md) for all relevant details.
+host it wherever you'd like. ``` # Make sure to install ZenML with all
+necessary requirements for the ZenServer pip install zenml[server] zenml server
+up ``` Read more about collaboration in ZenML [here](https://docs.zenml.io/
+collaborate/collaborate). # ð° ZenBytes [ZenBytes](https://github.com/zenml-
+io/zenbytes) is a series of short practical MLOps lessons through ZenML and its
+various integrations. It is intended for people looking to learn about MLOps
+generally, and also for ML practitioners who want to get started with ZenML.
+After you've run and understood the simple example above, your next port of
+call is probably either the [fully-fleshed-out quickstart example](https://
+github.com/zenml-io/zenml/tree/main/examples/quickstart) and then to look at
+[the ZenBytes repository](https://github.com/zenml-io/zenbytes) and notebooks.
+# ðï¸ ZenFiles ZenFiles are production-grade ML use-cases powered by ZenML.
+They are fully fleshed out, end-to-end, projects that showcase ZenML's
+capabilities. They can also serve as a template from which to start similar
+projects. The ZenFiles project is fully maintained and can be viewed as a
+sister repository of ZenML. Check it out [here](https://github.com/zenml-io/
+zenfiles). # ðº Roadmap ZenML is being built in public. The [roadmap](https:/
+/zenml.io/roadmap) is a regularly updated source of truth for the ZenML
+community to understand where the product is going in the short, medium, and
+long term. ZenML is managed by a [core team](https://zenml.io/team) of
+developers that are responsible for making key decisions and incorporating
+feedback from the community. The team oversees feedback via various channels,
+and you can directly influence the roadmap as follows: - Vote on your most
+wanted feature on our [Discussion board](https://zenml.io/discussion). You can
+also request for new features here. - Start a thread in our [Slack channel]
+(https://zenml.io/slack-invite). # ðââï¸ Contributing & Community We
+would love to develop ZenML together with our community! Best way to get
+started is to select any issue from the [`good-first-issue` label](https://
+github.com/zenml-io/zenml/labels/good%20first%20issue). If you would like to
+contribute, please review our [Contributing Guide](CONTRIBUTING.md) for all
+relevant details.
 ![Repobeats analytics image](https://repobeats.axiom.co/api/embed/
 635c57b743efe649cadceba6a2e6a956663f96dd.svg "Repobeats analytics image") #
 ð Where to get help First point of call should be [our Slack group](https://
 zenml.io/slack-invite/). Ask your questions about bugs or specific use cases
 and someone from the core team will respond. # ð License ZenML is
 distributed under the terms of the Apache License Version 2.0. A complete
 version of the license is available in the [LICENSE.md](LICENSE.md) in this
```

### Comparing `zenml-0.8.1rc0/RELEASE_NOTES.md` & `zenml-0.9.0/RELEASE_NOTES.md`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,106 @@
+# 0.9.0
+
+It's been a couple of weeks, so it's time for a new release! 0.9.0 brings two whole new orchestrators, one of which was contributed by a community member just one day after we unveiled new documentation for orchestrator extensibility! The release also includes a new secrets manager, a Slack integration and a bunch of other smaller changes across the codebase. (Our new orchestrators are exciting enough that they'll get their own blog posts to showcase their strengths in due course.)
+
+Beyond this, as usual we included a number of smaller bugfixes and documentation changes to cumulatively improve experience of using ZenML as a user.
+
+## What's Changed
+* Pass secret to release linting workflow by @schustmi in https://github.com/zenml-io/zenml/pull/642
+* Fix typo in example by @anencore94 in https://github.com/zenml-io/zenml/pull/644
+* Added `SecretExistsError` in `register_secret()` method by @hectorLop in https://github.com/zenml-io/zenml/pull/648
+* Fix broken GCP Secrets example CLI command by @strickvl in https://github.com/zenml-io/zenml/pull/649
+* Upgrade to `ml-pipelines-sdk` v1.8.0 by @strickvl in https://github.com/zenml-io/zenml/pull/651
+* Fix example list CLI command name by @schustmi in https://github.com/zenml-io/zenml/pull/647
+* Fix README by @strickvl in https://github.com/zenml-io/zenml/pull/657
+* Fix broken links in docs by @safoinme in https://github.com/zenml-io/zenml/pull/652
+* Add `VertexOrchestrator` implementation by @gabrielmbmb in https://github.com/zenml-io/zenml/pull/640
+* Fix index page links and Heading links. by @safoinme in https://github.com/zenml-io/zenml/pull/661
+* Add docstring checks to `pre-commit` script by @strickvl in https://github.com/zenml-io/zenml/pull/481
+* Pin MLflow to <1.26.0 to prevent issues when matplotlib is not installed by @fa9r in https://github.com/zenml-io/zenml/pull/666
+* Making `utils` more consistent by @strickvl in https://github.com/zenml-io/zenml/pull/658
+* Fix linting failures on `develop` by @strickvl in https://github.com/zenml-io/zenml/pull/669
+* Add docstrings for `config` module by @strickvl in https://github.com/zenml-io/zenml/pull/668
+* Miscellaneous bugfixes by @schustmi in https://github.com/zenml-io/zenml/pull/660
+* Make ZenServer dependencies optional by @schustmi in https://github.com/zenml-io/zenml/pull/665
+* Implement Azure Secrets Manager integration by @strickvl in https://github.com/zenml-io/zenml/pull/654
+* Replace `codespell` with `pyspelling` by @strickvl in https://github.com/zenml-io/zenml/pull/663
+* Add Community Event to README by @htahir1 in https://github.com/zenml-io/zenml/pull/674
+* Fix failing integration tests by @strickvl in https://github.com/zenml-io/zenml/pull/677
+* Add `io` and `model_deployers` docstring checks by @strickvl in https://github.com/zenml-io/zenml/pull/675
+* Update `zenml stack down` to use --force flag by @schustmi in https://github.com/zenml-io/zenml/pull/673
+* Fix class resolving on windows by @schustmi in https://github.com/zenml-io/zenml/pull/678
+* Added `pipelines` docstring checks by @strickvl in https://github.com/zenml-io/zenml/pull/676
+* Docstring checks for `cli` module by @strickvl in https://github.com/zenml-io/zenml/pull/680
+* Docstring fixes for `entrypoints` and `experiment_trackers` modules by @strickvl in https://github.com/zenml-io/zenml/pull/672
+* Clearer Contributing.md by @htahir1 in https://github.com/zenml-io/zenml/pull/681
+* How to access secrets within step added to docs by @AlexejPenner in https://github.com/zenml-io/zenml/pull/653
+* FIX: Log a warning instead of raising an `AssertionError` by @ketangangal in https://github.com/zenml-io/zenml/pull/628
+* Reviewer Reminder by @htahir1 in https://github.com/zenml-io/zenml/pull/683
+* Fix some docs phrasings and headers by @strickvl in https://github.com/zenml-io/zenml/pull/670
+* Implement `SlackAlerter.ask()` by @fa9r in https://github.com/zenml-io/zenml/pull/662
+* Extending Alerters Docs by @fa9r in https://github.com/zenml-io/zenml/pull/690
+* Sane defaults for MySQL by @htahir1 in https://github.com/zenml-io/zenml/pull/691
+* pd.Series materializer by @Reed-Schimmel in https://github.com/zenml-io/zenml/pull/684
+* Add docstrings for `materializers` and `metadata_stores` by @strickvl in https://github.com/zenml-io/zenml/pull/694
+* Docstrings for the `integrations` module(s) by @strickvl in https://github.com/zenml-io/zenml/pull/692
+* Add remaining docstrings by @strickvl in https://github.com/zenml-io/zenml/pull/696
+* Allow enabling mlflow/wandb/whylogs with the class-based api by @schustmi in https://github.com/zenml-io/zenml/pull/697
+* GitHub Actions orchestrator by @schustmi in https://github.com/zenml-io/zenml/pull/685
+* Created MySQL docs, Vertex AI docs, and step.entrypoint() by @AlexejPenner in https://github.com/zenml-io/zenml/pull/698
+* Update ignored words by @strickvl in https://github.com/zenml-io/zenml/pull/701
+* Stack Component registering made easier by @AlexejPenner in https://github.com/zenml-io/zenml/pull/695
+* Cleaning up the docs after the revamp by @bcdurak in https://github.com/zenml-io/zenml/pull/699
+* Add model deployer to CLI docs by @safoinme in https://github.com/zenml-io/zenml/pull/702
+* Merge Cloud Integrations and create a Vertex AI Example by @AlexejPenner in https://github.com/zenml-io/zenml/pull/693
+* GitHub actions orchestrator example by @schustmi in https://github.com/zenml-io/zenml/pull/703
+
+## New Contributors
+* @anencore94 made their first contribution in https://github.com/zenml-io/zenml/pull/644
+* @hectorLop made their first contribution in https://github.com/zenml-io/zenml/pull/648
+* @gabrielmbmb made their first contribution in https://github.com/zenml-io/zenml/pull/640
+* @ketangangal made their first contribution in https://github.com/zenml-io/zenml/pull/628
+* @Reed-Schimmel made their first contribution in https://github.com/zenml-io/zenml/pull/684
+
+**Full Changelog**: https://github.com/zenml-io/zenml/compare/0.8.1...0.9.0
+
+# 0.8.1
+
+ZenML 0.8.1 is here and it comes with support for Python 3.9 🎉. It also includes major updates to our 
+documentation, fixes some broken links in our examples and improves the `zenml go` command which helps 
+you get started with ZenML.
+
+## What's Changed
+* Hotfix/fix failing release by @AlexejPenner in https://github.com/zenml-io/zenml/pull/611
+* Remove autocomplete + alerter from documentation by @strickvl in https://github.com/zenml-io/zenml/pull/612
+* Support Python 3.9 by @htahir1 in https://github.com/zenml-io/zenml/pull/605
+* Revert README by @htahir1 in https://github.com/zenml-io/zenml/pull/624
+* Don't build cuda image on release by @schustmi in https://github.com/zenml-io/zenml/pull/623
+* Update quickstart for `zenml go` by @fa9r in https://github.com/zenml-io/zenml/pull/625
+* Improve kubeflow manual setup logs by @schustmi in https://github.com/zenml-io/zenml/pull/622
+* Added missing space to error message by @AlexejPenner in https://github.com/zenml-io/zenml/pull/614
+* Added --set flag to register stack command by @AlexejPenner in https://github.com/zenml-io/zenml/pull/613
+* Fixes for multiple examples by @schustmi in https://github.com/zenml-io/zenml/pull/626
+* Bring back the `served_model` format to the keras materializer by @stefannica in https://github.com/zenml-io/zenml/pull/629
+* Fix broken example links by @schustmi in https://github.com/zenml-io/zenml/pull/630
+* FAQ edits by @strickvl in https://github.com/zenml-io/zenml/pull/634
+* Fix version parsing by @schustmi in https://github.com/zenml-io/zenml/pull/633
+* Completed Best Practices Page by @AlexejPenner in https://github.com/zenml-io/zenml/pull/635
+* Comments on Issues should no longer trigger gh actions by @AlexejPenner in https://github.com/zenml-io/zenml/pull/636
+* Revise `CONTRIBUTING.md` by @strickvl in https://github.com/zenml-io/zenml/pull/615
+* Alerter Component for Slack Integration by @fa9r in https://github.com/zenml-io/zenml/pull/586
+* Update `zenml go` to open quickstart/notebooks. by @fa9r in https://github.com/zenml-io/zenml/pull/631
+* Update examples by @schustmi in https://github.com/zenml-io/zenml/pull/638
+* More detailed instructions on creating an integration by @AlexejPenner in https://github.com/zenml-io/zenml/pull/639
+* Added publish api docs to release workflow by @AlexejPenner in https://github.com/zenml-io/zenml/pull/641
+* Added *.md to ignore paths by @AlexejPenner in https://github.com/zenml-io/zenml/pull/637
+* Update README and Docs with new messaging and fix broken links by @htahir1 in https://github.com/zenml-io/zenml/pull/632
+
+**Full Changelog**: https://github.com/zenml-io/zenml/compare/0.8.0...0.8.1
+
 # 0.8.0
 
 ## 🧘‍♀️ Extensibility is our middle name
 
 * The ability to register custom stack component flavors (and renaming types to
   flavor (Registering custom stack component flavors by @bcdurak in
   https://github.com/zenml-io/zenml/pull/541)
```

### Comparing `zenml-0.8.1rc0/pyproject.toml` & `zenml-0.9.0/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "zenml"
-version = "0.8.1rc0"
+version = "0.9.0"
 packages = [
     { include = "zenml", from = "src" },
 ]
 description = "ZenML: Write production-ready ML code."
 authors = ["ZenML GmbH <info@zenml.io>"]
 readme = "README.md"
 homepage = "https://zenml.io"
@@ -46,35 +46,38 @@
 ]
 
 [tool.poetry.scripts]
 zenml = "zenml.cli.cli:cli"
 
 [tool.poetry.dependencies]
 python = ">=3.7.1,<3.10"
-ml-pipelines-sdk = "1.8.0rc1"
+ml-pipelines-sdk = "1.8.0"
 pandas = "^1.1.5"
 apache-beam = "^2.30.0"
 pyyaml = "^5.4.1"
 python-dateutil = "^2.8.1"
 gitpython = "^3.1.18"
 click = "^8.0.1"
 click-params = "^0.3.0"
 pydantic = "^1.9.0"
 analytics-python = "^1.4.0"
 distro = "^1.6.0"
 rich = {extras = ["jupyter"], version = "^12.0.0"}
 httplib2 = "<0.20,>=0.19.1"
 pyparsing = "<3,>=2.4.0"
 sqlmodel = "~0.0.6"
-fastapi = "~0.75.0"
-uvicorn = { extras = ["standard"], version = "~0.17.5" }
-semver = "^2.13.0"
 markupsafe = "1.1.1"
 nbconvert = "6.4.4"
 
+# Optional dependencies for the ZenServer
+fastapi = { version = "~0.75.0", optional = true }
+uvicorn = { extras = ["standard"], version = "~0.17.5" , optional = true}
+
+[tool.poetry.extras]
+server = ["fastapi", "uvicorn"]
 
 [tool.poetry.dev-dependencies]
 pytest = "^6.2.4"
 mypy = "^0.931"
 flake8 = "^3.9.2"
 black = "^22.3.0"
 interrogate = "^1.4.0"
@@ -85,25 +88,27 @@
 pyment = "^0.3.3"
 tox = "^3.24.3"
 hypothesis = "^6.43.1"
 typing-extensions = ">=3.7.4"
 
 # pytest dev dependencies
 pytest-randomly = "^3.10.1"
+pytest-mock = "^3.6.1"
+codespell = "^2.1.0"
+darglint = "^1.8.1"
 pytest-clarity = "^1.0.1"
 
 # mkdocs including plugins
 mkdocs="^1.2.3"
 mkdocs-material="^8.1.7"
 mkdocs-awesome-pages-plugin="^2.6.1"
 mkdocstrings="^0.17.0"
 pydocstyle="^6.1.1"
 mike="^1.1.2"
 
-
 # mypy type stubs
 types-certifi = "^2021.10.8.0"
 types-croniter = "^1.0.2"
 types-futures = "^3.3.1"
 types-Markdown = "^3.3.6"
 types-protobuf = "^3.18.0"
 types-PyMySQL = "^1.0.4"
@@ -112,16 +117,15 @@
 types-PyYAML = "^6.0.0"
 types-redis = "^4.1.19"
 types-requests = "^2.27.11"
 types-setuptools = "^57.4.2"
 types-six = "^1.16.2"
 types-termcolor = "^1.1.2"
 types-psutil = "^5.8.13"
-pytest-mock = "^3.6.1"
-codespell = "^2.1.0"
+flake8-docstrings = "^1.6.0"
 
 [build-system]
 requires = ["poetry-core"]
 build-backend = "poetry.core.masonry.api"
 
 [tool.poetry-version-plugin]
 source = "init"
@@ -234,14 +238,16 @@
     "neuralprophet.*",
     "wandb.*",
     "lightgbm.*",
     "scipy.*",
     "boto3.*",
     "botocore.*",
     "jupyter_dash.*",
+    "slack_sdk.*",
+    "azure-keyvault-keys.*"
 ]
 ignore_missing_imports = true
 
 [tool.black]
 line-length = 80
 include = '\.pyi?$'
 exclude = '''
@@ -253,14 +259,15 @@
 | \.venv
 | _build
 | buck-out
 | build
 )/
 '''
 
+
 [tool.interrogate]
 ignore-init-method = true
 ignore-init-module = true
 ignore-magic = false
 ignore-semiprivate = false
 ignore-private = false
 ignore-property-decorators = false
```

### Comparing `zenml-0.8.1rc0/src/zenml/README.md` & `zenml-0.9.0/src/zenml/README.md`

 * *Files identical despite different names*

### Comparing `zenml-0.8.1rc0/src/zenml/__init__.py` & `zenml-0.9.0/src/zenml/integrations/azure/step_operators/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,18 @@
-#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of AzureML Step Operator integration."""
 
-import os
-
-ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
-
-with open(os.path.join(ROOT_DIR, "VERSION")) as version_file:
-    __version__: str = version_file.read().strip()
-
-from zenml.logger import init_logging  # noqa
-
-init_logging()
-
-# Import ZenServer here because it needs to be registered in the service registry
-# early on in order to be available for use in other modules.
-from zenml.zen_server.zen_server import ZenServer
+from zenml.integrations.azure.step_operators.azureml_step_operator import (  # noqa
+    AzureMLStepOperator,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifact_stores/__init__.py` & `zenml-0.9.0/src/zenml/artifact_stores/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""ZenML's artifact store stores artifacts in a file system.
+
 In ZenML, the inputs and outputs which go through any step is treated as an
 artifact and as its name suggests, an `ArtifactStore` is a place where these
 artifacts get stored.
 
 Out of the box, ZenML comes with the `BaseArtifactStore` and
 `LocalArtifactStore` implementations. While the `BaseArtifactStore` establishes
 an interface for people who want to extend it to their needs, the
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifact_stores/local_artifact_store.py` & `zenml-0.9.0/src/zenml/artifact_stores/local_artifact_store.py`

 * *Files 19% similar despite different names*

```diff
@@ -21,14 +21,20 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""The local artifact store is a local implementation of the artifact store.
+
+In ZenML, the inputs and outputs which go through any step is treated as an
+artifact and as its name suggests, an `ArtifactStore` is a place where these
+artifacts get stored.
+"""
 
 import glob
 import os
 import shutil
 from typing import (
     Any,
     Callable,
@@ -54,116 +60,205 @@
 
     # Class Configuration
     FLAVOR: ClassVar[str] = "local"
     SUPPORTED_SCHEMES: ClassVar[Set[str]] = {""}
 
     @property
     def local_path(self) -> str:
-        """Path to the local directory where the artifacts are stored."""
+        """Path to the local directory where the artifacts are stored.
+
+        Returns:
+            str: The path to the local directory where the artifacts are stored.
+        """
         return self.path
 
     @staticmethod
     def open(name: PathType, mode: str = "r") -> Any:
-        """Open a file at the given path."""
+        """Open a file at the given path.
+
+        Args:
+            name: The path to the file.
+            mode: The mode to open the file.
+
+        Returns:
+            Any: The file object.
+        """
         return open(name, mode=mode)
 
     @staticmethod
     def copyfile(src: PathType, dst: PathType, overwrite: bool = False) -> None:
-        """Copy a file from the source to the destination."""
+        """Copy a file from the source to the destination.
+
+        Args:
+            src: The source path.
+            dst: The destination path.
+            overwrite: Whether to overwrite the destination file if it exists.
+
+        Raises:
+            FileExistsError: If the destination file exists and overwrite is
+                False.
+        """
         if not overwrite and os.path.exists(dst):
             raise FileExistsError(
                 f"Destination file {str(dst)} already exists and argument "
                 f"`overwrite` is false."
             )
         shutil.copyfile(src, dst)  # type: ignore[type-var, arg-type]
 
     @staticmethod
     def exists(path: PathType) -> bool:
-        """Returns `True` if the given path exists."""
+        """Returns `True` if the given path exists.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            bool: Whether the path exists.
+        """
         return os.path.exists(path)
 
     @staticmethod
     def glob(pattern: PathType) -> List[PathType]:
-        """Return the paths that match a glob pattern."""
+        """Return the paths that match a glob pattern.
+
+        Args:
+            pattern: The glob pattern.
+
+        Returns:
+            List[PathType]: The paths that match the glob pattern.
+        """
         return glob.glob(pattern)  # type: ignore[type-var]
 
     @staticmethod
     def isdir(path: PathType) -> bool:
-        """Returns whether the given path points to a directory."""
+        """Returns whether the given path points to a directory.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            bool: Whether the path points to a directory.
+        """
         return os.path.isdir(path)
 
     @staticmethod
     def listdir(path: PathType) -> List[PathType]:
-        """Returns a list of files under a given directory in the filesystem."""
+        """Returns a list of files under a given directory in the filesystem.
+
+        Args:
+            path: The path to the directory.
+
+        Returns:
+            List[PathType]: The list of files under the given directory.
+        """
         return os.listdir(path)  # type:ignore[return-value]
 
     @staticmethod
     def makedirs(path: PathType) -> None:
-        """Make a directory at the given path, recursively creating parents."""
+        """Make a directory at the given path, recursively creating parents.
+
+        Args:
+            path: The path to the directory.
+        """
         os.makedirs(path, exist_ok=True)
 
     @staticmethod
     def mkdir(path: PathType) -> None:
-        """Make a directory at the given path; parent directory must exist."""
+        """Make a directory at the given path; parent directory must exist.
+
+        Args:
+            path: The path to the directory.
+        """
         os.mkdir(path)
 
     @staticmethod
     def remove(path: PathType) -> None:
-        """Remove the file at the given path. Dangerous operation."""
+        """Remove the file at the given path. Dangerous operation.
+
+        Args:
+            path: The path to the file.
+        """
         os.remove(path)
 
     @staticmethod
     def rename(src: PathType, dst: PathType, overwrite: bool = False) -> None:
         """Rename source file to destination file.
+
         Args:
             src: The path of the file to rename.
             dst: The path to rename the source file to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True`
+
+        Raises:
+            FileExistsError: If the destination file exists and overwrite is
+                False.
         """
         if not overwrite and os.path.exists(dst):
             raise FileExistsError(
                 f"Destination path {str(dst)} already exists and argument "
                 f"`overwrite` is false."
             )
         os.rename(src, dst)
 
     @staticmethod
     def rmtree(path: PathType) -> None:
-        """Deletes dir recursively. Dangerous operation."""
+        """Deletes dir recursively. Dangerous operation.
+
+        Args:
+            path: The path to the directory.
+        """
         shutil.rmtree(path)
 
     @staticmethod
     def stat(path: PathType) -> Any:
-        """Return the stat descriptor for a given file path."""
+        """Return the stat descriptor for a given file path.
+
+        Args:
+            path: The path to the file.
+
+        Returns:
+            Any: The stat descriptor for the file.
+        """
         return os.stat(path)
 
     @staticmethod
     def walk(
         top: PathType,
         topdown: bool = True,
         onerror: Optional[Callable[..., None]] = None,
     ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:
         """Return an iterator that walks the contents of the given directory.
+
         Args:
             top: Path of directory to walk.
             topdown: Whether to walk directories topdown or bottom-up.
             onerror: Callable that gets called if an error occurs.
-        Returns:
+
+        Yields:
             An Iterable of Tuples, each of which contain the path of the
             current directory path, a list of directories inside the
             current directory and a list of files inside the current
             directory.
         """
         yield from os.walk(top, topdown=topdown, onerror=onerror)  # type: ignore[type-var, misc]
 
     @validator("path")
     def ensure_path_local(cls, path: str) -> str:
-        """Pydantic validator which ensures that the given path is a local
-        path"""
+        """Pydantic validator which ensures that the given path is a local path.
+
+        Args:
+            path: The path to validate.
+
+        Returns:
+            str: The validated (local) path.
+
+        Raises:
+            ArtifactStoreInterfaceError: If the given path is not a local path.
+        """
         remote_prefixes = ["gs://", "hdfs://", "s3://", "az://", "abfs://"]
         if any(path.startswith(prefix) for prefix in remote_prefixes):
             raise ArtifactStoreInterfaceError(
                 f"The path:{path} you defined for your local artifact store "
                 f"start with one of the remote prefixes."
             )
         return path
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/__init__.py` & `zenml-0.9.0/src/zenml/artifacts/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,29 +7,29 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-Artifacts are the data that power your experimentation and model training. It is
-actually steps that produce artifacts, which are then stored in the artifact
-store. Artifacts are written in the signature of a step like so:
+"""Artifacts are the data that power your experimentation and model training.
+
+It is actually steps that produce artifacts, which are then stored in the
+artifact store. Artifacts are written in the signature of a step like so:
 
 ```python
     def my_step(first_artifact: int, second_artifact: torch.nn.Module -> int:
         # first_artifact is an integer
         # second_artifact is a torch.nn.Module
         return 1
 ```
 Artifacts can be serialized and deserialized (i.e. written and read from the
-Artifact Store) in various ways like ``TFRecords`` or saved model
-pickles, depending on what the step produces.The serialization and
-deserialization logic of artifacts is defined by the appropriate Materializer.
+Artifact Store) in various ways like ``TFRecords`` or saved model pickles,
+depending on what the step produces.The serialization and deserialization logic
+of artifacts is defined by the appropriate Materializer.
 """
 
 from zenml.artifacts.data_analysis_artifact import DataAnalysisArtifact
 from zenml.artifacts.data_artifact import DataArtifact
 from zenml.artifacts.model_artifact import ModelArtifact
 from zenml.artifacts.schema_artifact import SchemaArtifact
 from zenml.artifacts.service_artifact import ServiceArtifact
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/base_artifact.py` & `zenml-0.9.0/src/zenml/artifacts/base_artifact.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,16 +21,18 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""The below code is copied from the TFX source repo with minor changes.
-All credits go to the TFX team for the core implementation"""
+"""Base class for ZenML artifacts.
+
+The below code is copied from the TFX source repo with minor changes. All credits go to the TFX team for the core implementation.
+"""
 from typing import Any, Dict
 
 from ml_metadata.proto import metadata_store_pb2
 from tfx.types.artifact import Artifact, Property, PropertyType
 
 from zenml.artifacts.constants import (
     DATATYPE_PROPERTY_KEY,
@@ -57,21 +59,30 @@
     PROPERTIES: Dict[str, Property] = {  # type: ignore[assignment]
         MATERIALIZER_PROPERTY_KEY: MATERIALIZER_PROPERTY,
         DATATYPE_PROPERTY_KEY: DATATYPE_PROPERTY,
     }
     _MLMD_ARTIFACT_TYPE: Any = None
 
     def __init__(self, *args: Any, **kwargs: Any) -> None:
-        """Init method for BaseArtifact"""
+        """Init method for BaseArtifact.
+
+        Args:
+            *args: Positional arguments.
+            **kwargs: Keyword arguments.
+        """
         self.set_zenml_artifact_type()
         super(BaseArtifact, self).__init__(*args, **kwargs)
 
     @classmethod
     def set_zenml_artifact_type(cls) -> None:
-        """Set the type of the artifact."""
+        """Set the type of the artifact.
+
+        Raises:
+            ValueError: If the artifact type is not a string or dictionary.
+        """
         type_name = cls.TYPE_NAME
         if not (type_name and isinstance(type_name, str)):
             raise ValueError(
                 (
                     "The Artifact subclass %s must override the TYPE_NAME attribute "
                     "with a string type name identifier (got %r instead)."
                 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/constants.py` & `zenml-0.9.0/src/zenml/integrations/dash/visualizers/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,10 +7,8 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
-DATATYPE_PROPERTY_KEY = "datatype"
-MATERIALIZER_PROPERTY_KEY = "materializer"
+"""Initialization of the Pipeline Run Visualizer."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/data_analysis_artifact.py` & `zenml-0.9.0/src/zenml/artifacts/data_analysis_artifact.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for all ZenML data analysis artifacts."""
 
 from zenml.artifacts.base_artifact import BaseArtifact
 
 
 class DataAnalysisArtifact(BaseArtifact):
     """Class for all ZenML data analysis artifacts.
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/data_artifact.py` & `zenml-0.9.0/src/zenml/artifacts/schema_artifact.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Schema artifact class."""
 
 from zenml.artifacts.base_artifact import BaseArtifact
 
 
-class DataArtifact(BaseArtifact):
-    """Class for all ZenML data artifacts."""
+class SchemaArtifact(BaseArtifact):
+    """Class for all ZenML schema artifacts."""
 
-    TYPE_NAME = "DataArtifact"
+    TYPE_NAME = "SchemaArtifact"
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/model_artifact.py` & `zenml-0.9.0/src/zenml/artifacts/service_artifact.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,23 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for all ZenML service artifacts."""
+
 
 from zenml.artifacts.base_artifact import BaseArtifact
 
 
-class ModelArtifact(BaseArtifact):
-    """Class for all ZenML model artifacts."""
+class ServiceArtifact(BaseArtifact):
+    """Class for all ZenML service artifacts."""
 
-    TYPE_NAME = "ModelArtifact"
+    TYPE_NAME = "ServiceArtifact"
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/schema_artifact.py` & `zenml-0.9.0/src/zenml/artifacts/data_artifact.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for all ZenML data artifacts."""
 
 from zenml.artifacts.base_artifact import BaseArtifact
 
 
-class SchemaArtifact(BaseArtifact):
-    """Class for all ZenML schema artifacts."""
+class DataArtifact(BaseArtifact):
+    """Class for all ZenML data artifacts."""
 
-    TYPE_NAME = "SchemaArtifact"
+    TYPE_NAME = "DataArtifact"
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/service_artifact.py` & `zenml-0.9.0/src/zenml/integrations/gcp/artifact_stores/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the GCP Artifact Store."""
 
-from zenml.artifacts.base_artifact import BaseArtifact
-
-
-class ServiceArtifact(BaseArtifact):
-    """Class for all ZenML service artifacts."""
-
-    TYPE_NAME = "ServiceArtifact"
+from zenml.integrations.gcp.artifact_stores.gcp_artifact_store import (  # noqa
+    GCPArtifactStore,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/statistics_artifact.py` & `zenml-0.9.0/src/zenml/integrations/azure/artifact_stores/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Azure Artifact Store integration."""
 
-from zenml.artifacts.base_artifact import BaseArtifact
-
-
-class StatisticsArtifact(BaseArtifact):
-    """Class for all ZenML statistics artifacts."""
-
-    TYPE_NAME = "StatisticsArtifact"
+from zenml.integrations.azure.artifact_stores.azure_artifact_store import (  # noqa
+    AzureArtifactStore,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/artifacts/type_registry.py` & `zenml-0.9.0/src/zenml/artifacts/type_registry.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,52 +7,52 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for artifact type registry."""
 
 from typing import TYPE_CHECKING, Any, Dict, Iterable, Tuple, Type
 
 from zenml.exceptions import StepInterfaceError
 from zenml.logger import get_logger
 
 logger = get_logger(__name__)
 
 if TYPE_CHECKING:
     from zenml.artifacts.base_artifact import BaseArtifact
 
 
 class ArtifactTypeRegistry(object):
-    """A registry to keep track of which datatypes map to which artifact
-    types"""
+    """A registry to keep track of which datatypes map to which artifact types."""
 
     def __init__(self) -> None:
-        """Initialization with an empty registry"""
+        """Initialization with an empty registry."""
         self._artifact_types: Dict[
             Type[Any], Tuple[Type["BaseArtifact"], ...]
         ] = {}
 
     def register_integration(
         self, key: Type[Any], type_: Iterable[Type["BaseArtifact"]]
     ) -> None:
-        """Method to register an integration within the registry
+        """Method to register an integration within the registry.
 
         Args:
             key: any datatype
             type_: the list of artifact type that the given datatypes is
                 associated with
         """
         self._artifact_types[key] = tuple(type_)
 
     def get_artifact_type(
         self, key: Type[Any]
     ) -> Tuple[Type["BaseArtifact"], ...]:
-        """Method to extract the list of artifact types given the data type
+        """Method to extract the list of artifact types given the data type.
 
         Args:
             key: Indicates the type of object.
 
         Returns:
             A list of `Artifact` types that was registered for this key.
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/__init__.py` & `zenml-0.9.0/src/zenml/cli/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,17 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-ZenML CLI
-==================
+"""ZenML CLI.
 
 The ZenML CLI tool is usually downloaded and installed via PyPI and a
 ``pip install zenml`` command. Please see the Installation & Setup
 section above for more information about that process.
 
 How to use the CLI
 ------------------
@@ -357,15 +355,15 @@
 different from the default one used by your active orchestrator. One example
 use-case is to run a training step of your pipeline in an environment with GPUs
 available. By default, a default ZenML local stack will not register a step
 operator. If you wish to register a new step operator, do so with the
 `register` command:
 
 ```bash
-zenml step-operator register STEP_OPERATOR_NAME --type STEP_OPERATOR_FLAVOR [--STEP_OPERATOR_OPTIONS]
+zenml step-operator register STEP_OPERATOR_NAME --flavor STEP_OPERATOR_FLAVOR [--STEP_OPERATOR_OPTIONS]
 ```
 
 If you want the name of the current step operator, use the `get` command:
 
 ```bash
 zenml step-operator get
 ```
@@ -734,14 +732,57 @@
 ```
 
 You can see a list of all current role assignments by running:
 
 ```bash
 zenml role assignment list
 ```
+
+Interacting with Model Deployers
+-----------------------------------------
+
+Model deployers are stack components responsible for online model serving.
+They are responsible for deploying models to a remote server. Model deployers
+also act as a registry for models that are served with ZenML. 
+
+If you wish to register a new model deployer, do so with the
+`register` command:
+
+```bash
+zenml model-deployer register MODEL_DEPLOYER_NAME --flavor=MODEL_DEPLOYER_FLAVOR [--OPTIONS]
+```
+
+If you wish to list the model-deployers that have already been registered
+within your ZenML project / repository, type:
+
+```bash
+zenml model-deployer list
+```
+
+If you wish to get more detailed information about a particular model deployer
+within your ZenML project / repository, type:
+
+```bash
+zenml model-deployer describe MODEL_DEPLOYER_NAME
+```
+
+If you wish to delete a particular model deployer, pass the name of the
+model deployers into the CLI with the following command:
+
+```bash
+zenml model-deployer delete MODEL_DEPLOYER_NAME
+```
+
+If you wish to retrieve logs corresponding to a particular model deployer, pass the name
+of the model deployer into the CLI with the following command:
+
+```bash
+zenml model-deployer logs MODEL_DEPLOYER_NAME
+```
+
 """
 
 from zenml.cli.base import *  # noqa
 from zenml.cli.config import *  # noqa
 from zenml.cli.example import *  # noqa
 from zenml.cli.feature import *  # noqa
 from zenml.cli.integration import *  # noqa
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/base.py` & `zenml-0.9.0/src/zenml/cli/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,37 +7,40 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base functionality for the CLI."""
+
 import os
 import subprocess
 import tempfile
 from pathlib import Path
 from typing import Optional
 
 import click
 
+from zenml import __version__ as zenml_version
 from zenml.cli.cli import cli
 from zenml.cli.utils import confirmation, declare, error, warning
 from zenml.config.global_config import GlobalConfiguration
 from zenml.console import console
 from zenml.constants import REPOSITORY_DIRECTORY_NAME
 from zenml.exceptions import GitNotFoundError, InitializationException
 from zenml.io import fileio
-from zenml.io.utils import copy_dir, get_global_config_directory
 from zenml.logger import get_logger
 from zenml.repository import Repository
 from zenml.utils.analytics_utils import (
     AnalyticsEvent,
     identify_user,
     track_event,
 )
+from zenml.utils.io_utils import copy_dir, get_global_config_directory
 
 logger = get_logger(__name__)
 # WT_SESSION is a Windows Terminal specific environment variable. If it
 # exists, we are on the latest Windows Terminal that supports emojis
 _SHOW_EMOJIS = not os.name == "nt" or os.environ.get("WT_SESSION")
 
 TUTORIAL_REPO = "https://github.com/zenml-io/zenml"
@@ -50,18 +53,15 @@
         exists=True, file_okay=False, dir_okay=True, path_type=Path
     ),
 )
 def init(path: Optional[Path]) -> None:
     """Initialize ZenML on given path.
 
     Args:
-      path: Path to the repository.
-
-    Raises:
-        InitializationException: If the repo is already initialized.
+        path: Path to the repository.
     """
     if path is None:
         path = Path.cwd()
 
     with console.status(f"Initializing ZenML repository at {path}.\n"):
         try:
             Repository.initialize(root=path)
@@ -81,15 +81,16 @@
     )
 
 
 def _delete_local_files(force_delete: bool = False) -> None:
     """Delete local files corresponding to the active stack.
 
     Args:
-      force_delete: Whether to force delete the files."""
+        force_delete: Whether to force delete the files.
+    """
     if not force_delete:
         confirm = confirmation(
             "DANGER: This will completely delete metadata, artifacts and so on associated with all active stack components. \n\n"
             "Are you sure you want to proceed?"
         )
         if not confirm:
             declare("Aborting clean.")
@@ -127,16 +128,16 @@
 )
 def clean(yes: bool = False, local: bool = False) -> None:
     """Delete all ZenML metadata, artifacts, profiles and stacks.
 
     This is a destructive operation, primarily intended for use in development.
 
     Args:
-      yes (flag; default value = False): If you don't want a confirmation prompt.
-      local (flag; default value = False): If you want to delete local files associated with the active stack.
+        yes: If you don't want a confirmation prompt.
+        local: If you want to delete local files associated with the active stack.
     """
     if local:
         _delete_local_files(force_delete=yes)
         return
 
     if not yes:
         confirm = confirmation(
@@ -175,15 +176,19 @@
 
     else:
         declare("Aborting clean.")
 
 
 @cli.command("go")
 def go() -> None:
-    """Quickly explore ZenML with this walkthrough."""
+    """Quickly explore ZenML with this walkthrough.
+
+    Raises:
+        GitNotFoundError: If git is not installed.
+    """
     from zenml.cli.text_utils import (
         zenml_go_notebook_tutorial_message,
         zenml_go_privacy_message,
         zenml_go_welcome_message,
     )
     from zenml.config.global_config import GlobalConfiguration
 
@@ -218,34 +223,49 @@
             raise GitNotFoundError(e)
 
         with tempfile.TemporaryDirectory() as tmpdirname:
             tmp_cloned_dir = os.path.join(tmpdirname, "zenml_repo")
             with console.status(
                 "Cloning tutorial. This sometimes takes a minute..."
             ):
-                Repo.clone_from(TUTORIAL_REPO, tmp_cloned_dir)
+                Repo.clone_from(
+                    TUTORIAL_REPO,
+                    tmp_cloned_dir,
+                    branch=f"release/{zenml_version}",
+                )
             example_dir = os.path.join(tmp_cloned_dir, "examples/quickstart")
             copy_dir(example_dir, zenml_tutorial_path)
     else:
         logger.warning(
             f"{zenml_tutorial_path} already exists! Continuing without cloning."
         )
 
-    ipynb_files = [
-        fi for fi in os.listdir(zenml_tutorial_path) if fi.endswith(".ipynb")
-    ]
+    # get list of all .ipynb files in zenml_tutorial_path
+    ipynb_files = []
+    for dirpath, _, filenames in os.walk(zenml_tutorial_path):
+        for filename in filenames:
+            if filename.endswith(".ipynb"):
+                ipynb_files.append(os.path.join(dirpath, filename))
+
     ipynb_files.sort()
     console.print(zenml_go_notebook_tutorial_message(ipynb_files), width=80)
     input("Press ENTER to continue...")
-    subprocess.check_call(["jupyter", "notebook"], cwd=zenml_tutorial_path)
+    notebook_path = os.path.join(zenml_tutorial_path, "notebooks")
+    subprocess.check_call(["jupyter", "notebook"], cwd=notebook_path)
 
 
 def _prompt_email(gc: GlobalConfiguration) -> bool:
-    """Ask the user to give their email address. Returns
-    True if email is given, else False."""
+    """Ask the user to give their email address.
+
+    Args:
+        gc (GlobalConfiguration): The global configuration object.
+
+    Returns:
+        bool: True if the user gave an email address, False otherwise.
+    """
     from zenml.cli.text_utils import (
         zenml_go_email_prompt,
         zenml_go_thank_you_message,
     )
 
     console.print(zenml_go_email_prompt, width=80)
 
@@ -257,9 +277,9 @@
             warning("That doesn't look like an email. Skipping ...")
         else:
 
             console.print(zenml_go_thank_you_message, width=80)
 
             gc.user_metadata = {"email": email}
             identify_user({"email": email})
-        return True
+            return True
     return False
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/cli.py` & `zenml-0.9.0/src/zenml/cli/cli.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,83 +7,96 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Core CLI functionality."""
 
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
 
 import click
 import rich
 from click import Command, Context, formatting
 
 from zenml import __version__
 from zenml.cli.formatter import ZenFormatter
 from zenml.enums import CliCategories
 from zenml.logger import set_root_verbosity
 
 
 class TagGroup(click.Group):
-    """
-    Override the default click Group to add a tag.
+    """Override the default click Group to add a tag.
+
     The tag is used to group commands and groups of
     commands in the help output.
     """
 
     def __init__(
         self,
         name: Optional[str] = None,
         tag: Optional[CliCategories] = None,
         commands: Optional[
             Union[Dict[str, click.Command], Sequence[click.Command]]
         ] = None,
         **kwargs: Dict[str, Any],
     ) -> None:
+        """Initialize the Tag group.
+
+        Args:
+            name: The name of the group.
+            tag: The tag of the group.
+            commands: The commands of the group.
+            kwargs: Additional keyword arguments.
+        """
         super(TagGroup, self).__init__(name, commands, **kwargs)
         self.tag = tag or CliCategories.OTHER_COMMANDS
 
 
 class ZenContext(click.Context):
-    """
-    Override the default click Context to add the new Formatter.
-    """
+    """Override the default click Context to add the new Formatter."""
 
     formatter_class = ZenFormatter
 
 
 class ZenMLCLI(click.Group):
-    """
-    Override the default click Group to create a custom
-    format command help output.
-    """
+    """Override the default click Group to create a custom format command help output."""
 
     context_class = ZenContext
 
     def get_help(self, ctx: Context) -> str:
         """Formats the help into a string and returns it.
 
         Calls :meth:`format_help` internally.
+
+        Args:
+            ctx: The click context.
+
+        Returns:
+            The formatted help string.
         """
         formatter = ctx.make_formatter()
         self.format_help(ctx, formatter)
         # TODO [ENG-862]: Find solution for support console.pager and color support in print
         rich.print(formatter.getvalue().rstrip("\n"))
         return ""
 
     def format_commands(
         self, ctx: click.Context, formatter: formatting.HelpFormatter
     ) -> None:
-        """
-        Extra format methods for multi methods that adds all the commands
-        after the options.
-        This custom format commands is used to retrive the commands and
+        """Extra format methods for multi methods that adds all the commands after the options.
+
+        This custom format_commands method is used to retrieve the commands and
         groups of commands with a tag. In order to call the new custom format
-        method, the command must be added to the ZenMLCLI class.
+        method, the command must be added to the ZenML CLI class.
+
+        Args:
+            ctx: The click context.
+            formatter: The click formatter.
         """
         commands: List[Tuple[CliCategories, str, Union[Command, TagGroup]]] = []
         for subcommand in self.list_commands(ctx):
             cmd = self.get_command(ctx, subcommand)
             # What is this, the tool lied about a command.  Ignore it
             if cmd is None or cmd.hidden:
                 continue
@@ -123,13 +136,13 @@
                 with formatter.section(colored_section_title):
                     formatter.write_dl(rows)  # type: ignore[arg-type]
 
 
 @click.group(cls=ZenMLCLI)
 @click.version_option(__version__, "--version", "-v")
 def cli() -> None:
-    """ZenML"""
+    """CLI base command for ZenML."""
     set_root_verbosity()
 
 
 if __name__ == "__main__":
     cli()
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/config.py` & `zenml-0.9.0/src/zenml/cli/config.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 """CLI for manipulating ZenML local and global config file."""
+
 from typing import TYPE_CHECKING, Optional
 
 import click
 from rich.markdown import Markdown
 
 from zenml.cli import utils as cli_utils
 from zenml.cli.cli import TagGroup, cli
@@ -45,26 +46,26 @@
     """Check whether user is opt-in or opt-out of analytics."""
     gc = GlobalConfiguration()
     cli_utils.declare(f"Analytics opt-in: {gc.analytics_opt_in}")
 
 
 @analytics.command("opt-in", context_settings=dict(ignore_unknown_options=True))
 def opt_in() -> None:
-    """Opt-in to analytics"""
+    """Opt-in to analytics."""
     gc = GlobalConfiguration()
     gc.analytics_opt_in = True
     cli_utils.declare("Opted in to analytics.")
     track_event(AnalyticsEvent.OPT_IN_ANALYTICS)
 
 
 @analytics.command(
     "opt-out", context_settings=dict(ignore_unknown_options=True)
 )
 def opt_out() -> None:
-    """Opt-out to analytics"""
+    """Opt-out of analytics."""
     gc = GlobalConfiguration()
     gc.analytics_opt_in = False
     cli_utils.declare("Opted out of analytics.")
     track_event(AnalyticsEvent.OPT_OUT_ANALYTICS)
 
 
 # Logging
@@ -78,15 +79,22 @@
 @click.argument(
     "verbosity",
     type=click.Choice(
         list(map(lambda x: x.name, LoggingLevels)), case_sensitive=False
     ),
 )
 def set_logging_verbosity(verbosity: str) -> None:
-    """Set logging level"""
+    """Set logging level.
+
+    Args:
+        verbosity: The logging level.
+
+    Raises:
+        KeyError: If the logging level is not supported.
+    """
     verbosity = verbosity.upper()
     if verbosity not in LoggingLevels.__members__:
         raise KeyError(
             f"Verbosity must be one of {list(LoggingLevels.__members__.keys())}"
         )
     cli_utils.declare(f"Set verbosity to: {verbosity}")
 
@@ -131,16 +139,22 @@
 )
 def create_profile_command(
     name: str,
     url: Optional[str],
     store_type: Optional[StoreType],
     user_name: Optional[str],
 ) -> None:
-    """Create a new configuration profile."""
+    """Create a new configuration profile.
 
+    Args:
+        name: The name of the profile.
+        url: The URL of the store.
+        store_type: The store type.
+        user_name: The username that is used to authenticate with the ZenServer.
+    """
     cli_utils.print_active_profile()
 
     cfg = GlobalConfiguration()
 
     if cfg.get_profile(name):
         cli_utils.error(f"Profile '{name}' already exists.")
         return
@@ -156,15 +170,14 @@
     cfg.add_or_update_profile(profile)
     cli_utils.declare(f"Profile '{name}' successfully created.")
 
 
 @profile.command("list")
 def list_profiles_command() -> None:
     """List configuration profiles."""
-
     cli_utils.print_active_profile()
 
     cfg = GlobalConfiguration()
     repo = Repository()
 
     profiles = cfg.profiles
 
@@ -196,15 +209,19 @@
 )
 @click.argument(
     "name",
     type=click.STRING,
     required=False,
 )
 def describe_profile(name: Optional[str]) -> None:
-    """Show details about a named profile or the active profile."""
+    """Show details about a named profile or the active profile.
+
+    Args:
+        name: The name of the profile.
+    """
     cli_utils.print_active_profile()
 
     repo = Repository()
     name = name or repo.active_profile_name
 
     profile = GlobalConfiguration().get_profile(name)
     if not profile:
@@ -219,14 +236,17 @@
 
 @profile.command("delete")
 @click.argument("name", type=str)
 def delete_profile(name: str) -> None:
     """Delete a profile.
 
     If the profile is currently active, it cannot be deleted.
+
+    Args:
+        name: The name of the profile.
     """
     cli_utils.print_active_profile()
 
     with console.status(f"Deleting profile '{name}'...\n"):
 
         cfg = GlobalConfiguration()
         repo = Repository()
@@ -263,14 +283,18 @@
     help="Set the global active profile",
 )
 def set_active_profile(name: str, global_profile: bool = False) -> None:
     """Set a profile as active.
 
     If the '--global' flag is set, the profile will be set as the global
     active profile, otherwise as the repository local active profile.
+
+    Args:
+        name: The name of the profile.
+        global_profile: Set the profile as the global active profile.
     """
     cli_utils.print_active_profile()
     scope = " global" if global_profile else ""
 
     with console.status(f"Setting the{scope} active profile to '{name}'..."):
 
         cfg: BaseConfiguration = (
@@ -303,15 +327,14 @@
             f"Active profile is: {Repository().active_profile_name}"
         )
 
 
 @profile.command("explain")
 def explain_profile() -> None:
     """Explains the concept of ZenML profiles."""
-
     with console.pager():
         console.print(
             Markdown(
                 """
 Profiles are configuration contexts that can be used to manage multiple
 individual ZenML global configurations on the same machine. ZenML Stacks and
 Stack Components, as well as the active Stack can be configured for a Profile
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/example.py` & `zenml-0.9.0/src/zenml/cli/example.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,115 +7,138 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to handle downloading ZenML examples via the CLI."""
 
 import os
 import shutil
 import subprocess
 import sys
 from pathlib import Path
 from typing import List, Optional, cast
 
 import click
 from packaging.version import Version, parse
 from rich.markdown import Markdown
 from rich.text import Text
 
-import zenml.io.utils
 from zenml import __version__ as zenml_version_installed
 from zenml.cli.cli import TagGroup, cli
 from zenml.cli.utils import confirmation, declare, error, print_table, warning
 from zenml.console import console
 from zenml.constants import GIT_REPO_URL
 from zenml.exceptions import GitNotFoundError
 from zenml.io import fileio
 from zenml.logger import get_logger
+from zenml.utils import io_utils
 from zenml.utils.analytics_utils import AnalyticsEvent, track_event
 
 logger = get_logger(__name__)
 
 EXCLUDED_EXAMPLE_DIRS = ["add_your_own"]
 EXAMPLES_GITHUB_REPO = "zenml_examples"
 EXAMPLES_RUN_SCRIPT = "run_example.sh"
 SHELL_EXECUTABLE = "SHELL_EXECUTABLE"
 
 
 class LocalExample:
-    """Class to encapsulate all properties and methods of the local example
-    that can be run from the CLI"""
+    """Class to encapsulate the local example that can be run from the CLI."""
 
     def __init__(self, path: Path, name: str) -> None:
         """Create a new LocalExample instance.
 
         Args:
             name: The name of the example, specifically the name of the folder
                   on git
             path: Path at which the example is installed
         """
         self.name = name
         self.path = path
 
     @property
     def python_files_in_dir(self) -> List[str]:
-        """List of all python files in the drectl in local example directory
-        the __init__.py file is excluded from this list"""
-        py_in_dir = zenml.io.utils.find_files(str(self.path), "*.py")
+        """List of all Python files in the local example directory.
+
+        The `__init__.py` file is excluded from this list.
+
+        Returns:
+            List of Python files in the local example directory.
+        """
+        py_in_dir = io_utils.find_files(str(self.path), "*.py")
         py_files = []
         for file in py_in_dir:
             # Make sure only files directly in dir are considered, not files
             # in sub dirs
             if self.path == Path(file).parent:
                 if Path(file).name != "__init__.py":
                     py_files.append(file)
 
         return py_files
 
     @property
     def has_single_python_file(self) -> bool:
-        """Boolean that states if only one python file is present"""
+        """Boolean that states if only one Python file is present.
+
+        Returns:
+            Whether only one Python file is present.
+        """
         return len(self.python_files_in_dir) == 1
 
     @property
     def has_any_python_file(self) -> bool:
-        """Boolean that states if any python file is present"""
+        """Boolean that states if any python file is present.
+
+        Returns:
+            Whether any Python file is present.
+        """
         return len(self.python_files_in_dir) > 0
 
     @property
     def run_dot_py_file(self) -> Optional[str]:
-        """Returns the path to the run.py file in case one exists"""
+        """Returns the path to the run.py file in case one exists.
+
+        Returns:
+            Path to the run.py file in case one exists.
+        """
         for file in self.python_files_in_dir:
             # Make sure only files directly in dir are considered, not files
             # in sub dirs
             if self.path == Path(file).parent:
                 if Path(file).name == "run.py":
                     return file
         return None
 
     @property
     def needs_manual_user_setup(self) -> bool:
-        """Checks if a setup.sh file exist in the example dir, signifying the
-        possibility to run the example without any user input. Examples with no
-        setup.sh file need the user to setup infrastructure and/or connect
-        to tools/service providers
+        """Checks if a setup.sh file exists in the example dir.
+
+        This indicates the possibility to run the example without any user
+        input. Examples with no setup.sh file need the user to setup
+        infrastructure and/or connect to tools/service providers.
 
         Returns:
             True if no setup.sh file in self.path, False else
         """
-        return not zenml.io.fileio.exists(
-            os.path.join(str(self.path), "setup.sh")
-        )
+        return not fileio.exists(os.path.join(str(self.path), "setup.sh"))
 
     @property
     def executable_python_example(self) -> str:
-        """Return the Python file for the example"""
+        """Return the Python file for the example.
 
+        Returns:
+            The Python file for the example.
+
+        Raises:
+            RuntimeError: If no runner script is present in the example.
+            NotImplementedError: If the examples needs manual user setup.
+        """
         if self.needs_manual_user_setup:
             raise NotImplementedError(
                 "This example currently does not support being run from the "
                 "CLI as user specific setup is required. Consult the README.md "
                 "of the example to find out more."
             )
         elif self.has_single_python_file:
@@ -131,32 +154,40 @@
         else:
             raise RuntimeError(
                 "No pipeline runner script found in example. "
                 f"Files found: {self.python_files_in_dir}"
             )
 
     def is_present(self) -> bool:
-        """Checks if the example exists at the given path."""
+        """Checks if the example exists at the given path.
+
+        Returns:
+            True if the example exists at the given path, else False.
+        """
         return fileio.exists(str(self.path)) and fileio.isdir(str(self.path))
 
     def run_example(
         self,
         example_runner: List[str],
         force: bool,
         prevent_stack_setup: bool = False,
     ) -> None:
-        """Run the local example using the bash script at the supplied
-        location
+        """Run the local example using the bash script at the supplied location.
 
         Args:
             example_runner: Sequence of locations of executable file(s)
                             to run the example
             force: Whether to force the install
             prevent_stack_setup: Prevents the example from setting up a custom
                 stack.
+
+        Raises:
+            NotImplementedError: If the example hasn't been implement yet.
+            FileNotFoundError: If the example runner script is not found.
+            subprocess.CalledProcessError: If the example runner script fails.
         """
         if all(map(fileio.exists, example_runner)):
             call = (
                 example_runner
                 + ["--executable", self.executable_python_example]
                 + ["-y"] * force
                 + ["--no-stack-setup"] * prevent_stack_setup
@@ -206,15 +237,23 @@
                   folder.
         """
         self.name = name
         self.path_in_repo = path_in_repo
 
     @property
     def readme_content(self) -> str:
-        """Returns the readme content associated with a particular example."""
+        """Returns the README content associated with a particular example.
+
+        Returns:
+            The README content associated with a particular example.
+
+        Raises:
+            ValueError: If the README file is not found.
+            FileNotFoundError: If the README file is not one of the options.
+        """
         readme_file = os.path.join(self.path_in_repo, "README.md")
         try:
             with open(readme_file) as readme:
                 readme_content = readme.read()
             return readme_content
         except FileNotFoundError:
             if fileio.exists(str(self.path_in_repo)) and fileio.isdir(
@@ -232,15 +271,22 @@
                 )
 
 
 class ExamplesRepo:
     """Class for the examples repository object."""
 
     def __init__(self, cloning_path: Path) -> None:
-        """Create a new ExamplesRepo instance."""
+        """Create a new ExamplesRepo instance.
+
+        Args:
+            cloning_path: Path to the local examples repository.
+
+        Raises:
+            GitNotFoundError: If git is not installed.
+        """
         self.cloning_path = cloning_path
 
         try:
             from git.exc import InvalidGitRepositoryError, NoSuchPathError
             from git.repo.base import Repo
         except ImportError as e:
             logger.error(
@@ -258,111 +304,142 @@
                 "Automatically cloning the examples."
             )
             self.clone()
             self.checkout_latest_release()
 
     @property
     def active_version(self) -> Optional[str]:
-        """In case a release branch is checked out, this property returns
-        that version, else `None` is returned"""
+        """Returns the active version of the examples repository.
+
+        In case a release branch is checked out, this property returns
+        that version as a string, else `None` is returned.
+
+        Returns:
+            The active version of the examples repository.
+        """
         for branch in self.repo.heads:
             branch_name = cast(str, branch.name)
             if (
                 branch_name.startswith("release/")
                 and branch.commit == self.repo.head.commit
             ):
                 return branch_name[len("release/") :]
 
         return None
 
     @property
     def latest_release_branch(self) -> str:
-        """Returns the name of the latest release branch."""
+        """Returns the name of the latest release branch.
+
+        Returns:
+            The name of the latest release branch.
+        """
         tags = sorted(
             self.repo.tags,
             key=lambda t: t.commit.committed_datetime,  # type: ignore
         )
         latest_tag = parse(tags[-1].name)
         if type(latest_tag) is not Version:
             return "main"
 
         latest_release_version: str = tags[-1].name
         return f"release/{latest_release_version}"
 
     @property
     def is_cloned(self) -> bool:
-        """Returns whether we have already cloned the examples repository."""
+        """Returns whether we have already cloned the examples repository.
+
+        Returns:
+            Whether we have already cloned the examples repository.
+        """
         return self.cloning_path.exists()
 
     @property
     def examples_dir(self) -> str:
-        """Returns the path for the examples directory."""
+        """Returns the path for the examples directory.
+
+        Returns:
+            The path for the examples directory.
+        """
         return os.path.join(self.cloning_path, "examples")
 
     @property
     def examples_run_bash_script(self) -> str:
-        """Path to the bash script that runs the example."""
+        """Path to the bash script that runs the example.
+
+        Returns:
+            Path to the bash script that runs the example.
+        """
         return os.path.join(self.examples_dir, EXAMPLES_RUN_SCRIPT)
 
     def clone(self) -> None:
         """Clones repo to `cloning_path`.
 
         If you break off the operation with a `KeyBoardInterrupt` before the
         cloning is completed, this method will delete whatever was partially
-        downloaded from your system."""
+        downloaded from your system.
+        """
         self.cloning_path.mkdir(parents=True, exist_ok=False)
         try:
             from git.repo.base import Repo
 
             logger.info(f"Cloning repo {GIT_REPO_URL} to {self.cloning_path}")
             self.repo = Repo.clone_from(
                 GIT_REPO_URL, self.cloning_path, branch="main"
             )
         except KeyboardInterrupt:
             self.delete()
             logger.error("Canceled download of repository.. Rolled back.")
 
     def delete(self) -> None:
-        """Delete `cloning_path` if it exists."""
+        """Delete `cloning_path` if it exists.
+
+        Raises:
+            AssertionError: If `cloning_path` does not exist.
+        """
         if self.cloning_path.exists():
             shutil.rmtree(self.cloning_path)
         else:
             raise AssertionError(
                 f"Cannot delete the examples repository from "
                 f"{self.cloning_path} as it does not exist."
             )
 
     def checkout(self, branch: str) -> None:
         """Checks out a specific branch or tag of the examples repository.
 
-        Raises:
-            GitCommandError: if branch doesn't exist.
+        Args:
+            branch: The name of the branch or tag to check out.
         """
         logger.info(f"Checking out branch: {branch}")
         self.repo.git.checkout(branch)
 
     def checkout_latest_release(self) -> None:
         """Checks out the latest release of the examples repository."""
         self.checkout(branch=self.latest_release_branch)
 
 
 class GitExamplesHandler(object):
     """Class for the `GitExamplesHandler` that interfaces with the CLI tool."""
 
     def __init__(self) -> None:
         """Create a new GitExamplesHandler instance."""
-        self.repo_dir = zenml.io.utils.get_global_config_directory()
+        self.repo_dir = io_utils.get_global_config_directory()
         self.examples_dir = Path(
             os.path.join(self.repo_dir, EXAMPLES_GITHUB_REPO)
         )
         self.examples_repo = ExamplesRepo(self.examples_dir)
 
     @property
     def examples(self) -> List[Example]:
-        """Property that contains a list of examples."""
+        """Property that contains a list of examples.
+
+        Returns:
+            A list of examples.
+        """
         return [
             Example(
                 name, Path(os.path.join(self.examples_repo.examples_dir, name))
             )
             for name in sorted(os.listdir(self.examples_repo.examples_dir))
             if (
                 not name.startswith(".")
@@ -370,33 +447,50 @@
                 and not name.startswith("README")
                 and not name.endswith(".sh")
             )
         ]
 
     @property
     def is_matching_versions(self) -> bool:
-        """Returns a boolean whether the checked out examples are on the
-        same code version as zenml"""
+        """Whether the checked out examples are on the same code version as ZenML.
+
+        Returns:
+            Whether the checked out examples are on the same code version as ZenML.
+        """
         return zenml_version_installed == str(self.examples_repo.active_version)
 
     def is_example(self, example_name: Optional[str] = None) -> bool:
-        """Checks if the supplied example_name corresponds to an example"""
+        """Checks if the supplied example_name corresponds to an example.
+
+        Args:
+            example_name: The name of the example to check.
+
+        Returns:
+            Whether the supplied example_name corresponds to an example.
+        """
         example_dict = {e.name: e for e in self.examples}
         if example_name:
             if example_name in example_dict.keys():
                 return True
 
         return False
 
     def get_examples(self, example_name: Optional[str] = None) -> List[Example]:
-        """Method that allows you to get an example by name. If no example is
-        supplied,  all examples are returned
+        """Method that allows you to get an example by name.
+
+        If no example is supplied,  all examples are returned.
 
         Args:
-          example_name: Name of an example.
+            example_name: Name of an example.
+
+        Returns:
+            A list of examples.
+
+        Raises:
+            KeyError: If the supplied example_name is not found.
         """
         example_dict = {
             e.name: e
             for e in self.examples
             if e.name not in EXCLUDED_EXAMPLE_DIRS
         }
         if example_name:
@@ -411,17 +505,22 @@
             return self.examples
 
     def pull(
         self,
         branch: str,
         force: bool = False,
     ) -> None:
+        """Pulls the examples from the main git examples repository.
+
+        Args:
+            branch: The name of the branch to pull from.
+            force: Whether to force the pull.
+        """
         from git.exc import GitCommandError
 
-        """Pulls the examples from the main git examples repository."""
         if not self.examples_repo.is_cloned:
             self.examples_repo.clone()
         elif force:
             self.examples_repo.delete()
             self.examples_repo.clone()
 
         try:
@@ -434,36 +533,44 @@
             self.examples_repo.checkout_latest_release()
 
     def pull_latest_examples(self) -> None:
         """Pulls the latest examples from the examples repository."""
         self.pull(branch=self.examples_repo.latest_release_branch, force=True)
 
     def copy_example(self, example: Example, destination_dir: str) -> None:
-        """Copies an example to the destination_dir."""
-        zenml.io.utils.create_dir_if_not_exists(destination_dir)
-        zenml.io.utils.copy_dir(
+        """Copies an example to the destination_dir.
+
+        Args:
+            example: The example to copy.
+            destination_dir: The destination directory to copy the example to.
+        """
+        io_utils.create_dir_if_not_exists(destination_dir)
+        io_utils.copy_dir(
             str(example.path_in_repo), destination_dir, overwrite=True
         )
 
     def clean_current_examples(self) -> None:
-        """Deletes the ZenML examples directory from your current working
-        directory."""
+        """Deletes the ZenML examples directory from your current working directory."""
         examples_directory = os.path.join(os.getcwd(), "zenml_examples")
         shutil.rmtree(examples_directory)
 
 
 pass_git_examples_handler = click.make_pass_decorator(
     GitExamplesHandler, ensure=True
 )
 
 
 def check_for_version_mismatch(
     git_examples_handler: GitExamplesHandler,
 ) -> None:
-    """Prints a warning if the example version and ZenML version don't match."""
+    """Prints a warning if the example version and ZenML version don't match.
+
+    Args:
+        git_examples_handler: The GitExamplesHandler instance.
+    """
     if git_examples_handler.is_matching_versions:
         return
     else:
         if git_examples_handler.examples_repo.active_version:
             warning(
                 "The examples you have installed are installed with Version "
                 f"{git_examples_handler.examples_repo.active_version} "
@@ -481,18 +588,22 @@
 
 
 @cli.group(cls=TagGroup)
 def example() -> None:
     """Access all ZenML examples."""
 
 
-@example.command(help="List the available examples.")
+@example.command(name="list", help="List the available examples.")
 @pass_git_examples_handler
 def list_examples(git_examples_handler: GitExamplesHandler) -> None:
-    """List all available examples."""
+    """List all available examples.
+
+    Args:
+        git_examples_handler: The GitExamplesHandler instance.
+    """
     check_for_version_mismatch(git_examples_handler)
     examples = [
         {"example_name": example.name}
         for example in git_examples_handler.get_examples()
     ]
     print_table(examples)
 
@@ -507,16 +618,20 @@
     type=click.STRING,
     default="zenml_examples",
     help="Relative path at which you want to clean the example(s)",
 )
 @example.command(help="Deletes the ZenML examples directory.")
 @pass_git_examples_handler
 def clean(git_examples_handler: GitExamplesHandler, path: str) -> None:
-    """Deletes the ZenML examples directory from your current working
-    directory."""
+    """Deletes the ZenML examples directory from your current working directory.
+
+    Args:
+        git_examples_handler: The GitExamplesHandler instance.
+        path: The path at which you want to clean the example(s).
+    """
     examples_directory = os.path.join(os.getcwd(), path)
     if (
         fileio.exists(examples_directory)
         and fileio.isdir(examples_directory)
         and confirmation(
             "Do you wish to delete the ZenML examples directory? \n"
             f"{examples_directory}"
@@ -537,16 +652,22 @@
         )
 
 
 @example.command(help="Find out more about an example.")
 @pass_git_examples_handler
 @click.argument("example_name")
 def info(git_examples_handler: GitExamplesHandler, example_name: str) -> None:
-    """Find out more about an example. Outputs a pager view of the example's
-    README.md file."""
+    """Find out more about an example.
+
+    Outputs a pager view of the example's README.md file.
+
+    Args:
+        git_examples_handler: The GitExamplesHandler instance.
+        example_name: The name of the example.
+    """
     check_for_version_mismatch(git_examples_handler)
 
     try:
         example_obj = git_examples_handler.get_examples(example_name)[0]
 
     except KeyError as e:
         error(str(e))
@@ -607,29 +728,44 @@
     force: bool,
     old_force: bool,
     version: str,
     path: str,
     branch: Optional[str],
 ) -> None:
     """Pull examples straight into your current working directory.
+
     Add the flag --yes or -y to redownload all the examples afresh.
     Use the flag --version or -v and the version number to specify
-    which version of ZenML you wish to use for the examples."""
+    which version of ZenML you wish to use for the examples.
+
+    Args:
+        git_examples_handler: The GitExamplesHandler instance.
+        example_name: The name of the example.
+        force: Force the redownload of the examples folder to the ZenML config
+            folder.
+        old_force: DEPRECATED: Force the redownload of the examples folder to
+            the ZenML config folder.
+        version: The version of ZenML to use for the force-redownloaded
+            examples.
+        path: The path at which you want to install the example(s).
+        branch: The branch of the ZenML repo to use for the force-redownloaded
+            examples.
+    """
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or "
             "`-y` instead."
         )
 
     branch = branch.strip() if branch else f"release/{version}"
     git_examples_handler.pull(branch=branch, force=force)
 
     examples_dir = os.path.join(os.getcwd(), path)
-    zenml.io.utils.create_dir_if_not_exists(examples_dir)
+    io_utils.create_dir_if_not_exists(examples_dir)
     try:
         examples = git_examples_handler.get_examples(example_name)
 
     except KeyError as e:
         error(str(e))
 
     else:
@@ -646,15 +782,15 @@
                     fileio.rmtree(destination_dir)
                 else:
                     warning(f"Example {example.name} not overwritten.")
                     continue
 
             declare(f"Pulling example {example.name}...")
 
-            zenml.io.utils.create_dir_if_not_exists(destination_dir)
+            io_utils.create_dir_if_not_exists(destination_dir)
             git_examples_handler.copy_example(example, destination_dir)
             declare(f"Example pulled in directory: {destination_dir}")
             track_event(
                 AnalyticsEvent.PULL_EXAMPLE, {"example_name": example.name}
             )
 
 
@@ -706,16 +842,27 @@
     example_name: str,
     path: str,
     force: bool,
     old_force: bool,
     shell_executable: Optional[str],
 ) -> None:
     """Run the example at the specified relative path.
+
     `zenml example pull EXAMPLE_NAME` has to be called with the same relative
     path before the run command.
+
+    Args:
+        ctx: The click context.
+        git_examples_handler: The GitExamplesHandler instance.
+        example_name: The name of the example.
+        path: The path at which you want to install the example(s).
+        force: Force the run of the example.
+        old_force: DEPRECATED: Force the run of the example.
+        shell_executable: Manually specify the path to the executable that
+            runs .sh files.
     """
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or "
             "`-y` instead."
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/feature.py` & `zenml-0.9.0/src/zenml/cli/feature.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to interact with features accessed via a registered Feature Store."""
 
 # TODO [ENG-795]: Generalize these commands to all feature stores.
 
 from typing import TYPE_CHECKING
 
 import click
 
@@ -28,15 +29,19 @@
     from zenml.feature_stores.base_feature_store import BaseFeatureStore
 
 
 # Features
 @cli.group(cls=TagGroup)
 @click.pass_context
 def feature(ctx: click.Context) -> None:
-    """Features as obtained from a feature store."""
+    """Features as obtained from a feature store.
+
+    Args:
+        ctx: The click context.
+    """
     repo = Repository()
     active_stack = repo.zen_store.get_stack(name=repo.active_stack_name)
     feature_store_wrapper = active_stack.get_component_wrapper(
         StackComponentType.FEATURE_STORE
     )
     if feature_store_wrapper is None:
         error(
@@ -46,50 +51,74 @@
         return
     ctx.obj = feature_store_wrapper.to_component()
 
 
 @feature.command("get-data-sources")
 @click.pass_obj
 def get_data_sources(feature_store: "BaseFeatureStore") -> None:
-    """Get all data sources from the feature store."""
+    """Get all data sources from the feature store.
+
+    Args:
+        feature_store: The feature store.
+    """
     data_sources = feature_store.get_data_sources()
     declare(f"Data sources: {data_sources}")
 
 
 @feature.command("get-entities")
 @click.pass_obj
 def get_entities(feature_store: "BaseFeatureStore") -> None:
-    """Get all entities from the feature store."""
+    """Get all entities from the feature store.
+
+    Args:
+        feature_store: The feature store.
+    """
     entities = feature_store.get_entities()
     declare(f"Entities: {entities}")
 
 
 @feature.command("get-feature-services")
 @click.pass_obj
 def get_feature_services(feature_store: "BaseFeatureStore") -> None:
-    """Get all feature services from the feature store."""
+    """Get all feature services from the feature store.
+
+    Args:
+        feature_store: The feature store.
+    """
     feature_services = feature_store.get_feature_services()
     declare(f"Feature services: {feature_services}")
 
 
 @feature.command("get-feature-views")
 @click.pass_obj
 def get_feature_views(feature_store: "BaseFeatureStore") -> None:
-    """Get all feature views from the feature store."""
+    """Get all feature views from the feature store.
+
+    Args:
+        feature_store: The feature store.
+    """
     feature_views = feature_store.get_feature_views()
     declare(f"Feature views: {feature_views}")
 
 
 @feature.command("get-project")
 @click.pass_obj
 def get_project(feature_store: "BaseFeatureStore") -> None:
-    """Get the current project name from the feature store."""
+    """Get the current project name from the feature store.
+
+    Args:
+        feature_store: The feature store.
+    """
     project = feature_store.get_project()
     declare(f"Project name: {project}")
 
 
 @feature.command("get-feast-version")
 @click.pass_obj
 def get_feast_version(feature_store: "BaseFeatureStore") -> None:
-    """Get the current Feast version being used."""
+    """Get the current Feast version being used.
+
+    Args:
+        feature_store: The feature store.
+    """
     version = feature_store.get_feast_version()
     declare(f"Feast version: {version}")
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/formatter.py` & `zenml-0.9.0/src/zenml/cli/formatter.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,79 +7,100 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Helper functions to format output for CLI."""
 
 from typing import Dict, Iterable, Iterator, Optional, Sequence, Tuple
 
 from click import formatting
 from click._compat import term_len
 
 
 def measure_table(rows: Iterable[Tuple[str, ...]]) -> Tuple[int, ...]:
-    """
-    Measure the width of each column in a table.
+    """Measure the width of each column in a table.
+
+    Args:
+        rows: The rows of the table.
+
+    Returns:
+        A tuple of the width of each column.
     """
     widths: Dict[int, int] = {}
     for row in rows:
         for idx, col in enumerate(row):
             widths[idx] = max(widths.get(idx, 0), term_len(col))
 
     return tuple(y for x, y in sorted(widths.items()))
 
 
 def iter_rows(
     rows: Iterable[Tuple[str, ...]],
     col_count: int,
 ) -> Iterator[Tuple[str, ...]]:
-    """
-    Iterate over rows of a table.
+    """Iterate over rows of a table.
+
+    Args:
+        rows: The rows of the table.
+        col_count: The number of columns in the table.
+
+    Yields:
+        An iterator over the rows of the table.
     """
     for row in rows:
         yield row + ("",) * (col_count - len(row))
 
 
 class ZenFormatter(formatting.HelpFormatter):
-    """
-    Override the default HelpFormatter to add a custom
-    format for the help command output.
-    """
+    """Override the default HelpFormatter to add a custom format for the help command output."""
 
     def __init__(
         self,
         indent_increment: int = 2,
         width: Optional[int] = None,
         max_width: Optional[int] = None,
     ) -> None:
+        """Initialize the formatter.
+
+        Args:
+            indent_increment: The number of spaces to indent each level of
+                nesting.
+            width: The maximum width of the help output.
+            max_width: The maximum width of the help output.
+        """
         super(ZenFormatter, self).__init__(indent_increment, width, max_width)
         self.current_indent = 0
 
     def write_dl(
         self,
         rows: Sequence[Tuple[str, ...]],
         col_max: int = 30,
         col_spacing: int = 2,
     ) -> None:
-        """Writes a definition list into the buffer.  This is how options
-        and commands are usually formatted.
+        """Writes a definition list into the buffer.
+
+        This is how options and commands are usually formatted.
 
         Arguments:
             rows: a list of items as tuples for the terms and values.
             col_max: the maximum width of the first column.
             col_spacing: the number of spaces between the first and
                             second column (and third).
 
         The default behavior is to format the rows in a definition list
         with rows of 2 columns following the format ``(term, value)``.
         But for new CLI commands, we want to format the rows in a definition
         list with rows of 3 columns following the format the format
                             ``(term, value, description)``.
+
+        Raises:
+            TypeError: if the number of columns is not 2 or 3.
         """
         rows = list(rows)
         widths = measure_table(rows)
 
         if len(widths) == 2:
             first_col = min(widths[0], col_max) + col_spacing
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/integration.py` & `zenml-0.9.0/src/zenml/cli/integration.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to install or uninstall ZenML integrations via the CLI."""
 
 from typing import Optional, Tuple
 
 import click
 from rich.progress import track
 
 from zenml.cli.cli import TagGroup, cli
@@ -61,15 +62,20 @@
 
 
 @integration.command(
     name="requirements", help="List all requirements for an integration."
 )
 @click.argument("integration_name", required=False, default=None)
 def get_requirements(integration_name: Optional[str] = None) -> None:
-    """List all requirements for the chosen integration."""
+    """List all requirements for the chosen integration.
+
+    Args:
+        integration_name: The name of the integration to list the requirements
+            for.
+    """
     from zenml.integrations.registry import integration_registry
 
     try:
         requirements = integration_registry.select_integration_requirements(
             integration_name
         )
     except KeyError as e:
@@ -116,17 +122,26 @@
 )
 def install(
     integrations: Tuple[str],
     ignore_integration: Tuple[str],
     force: bool = False,
     old_force: bool = False,
 ) -> None:
-    """Installs the required packages for a given integration. If no integration
-    is specified all required packages for all integrations are installed
-    using pip"""
+    """Installs the required packages for a given integration.
+
+    If no integration is specified all required packages for all integrations
+    are installed using pip.
+
+    Args:
+        integrations: The name of the integration to install the requirements
+            for.
+        ignore_integration: List of integrations to ignore explicitly.
+        force: Force the installation of the required packages.
+        old_force: DEPRECATED: Force the installation of the required packages.
+    """
     from zenml.integrations.registry import integration_registry
 
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or "
             "`-y` instead."
@@ -199,17 +214,26 @@
     is_flag=True,
     help="DEPRECATED: Force the uninstallation of the required packages. "
     "This will skip the confirmation step. Use `-y/--yes` instead.",
 )
 def uninstall(
     integrations: Tuple[str], force: bool = False, old_force: bool = False
 ) -> None:
-    """Installs the required packages for a given integration. If no integration
-    is specified all required packages for all integrations are installed
-    using pip"""
+    """Installs the required packages for a given integration.
+
+    If no integration is specified all required packages for all integrations
+    are installed using pip.
+
+    Args:
+        integrations: The name of the integration to install the requirements
+            for.
+        force: Force the uninstallation of the required packages.
+        old_force: DEPRECATED: Force the uninstallation of the required
+            packages.
+    """
     from zenml.integrations.registry import integration_registry
 
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` "
             "or `-y` instead."
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/pipeline.py` & `zenml-0.9.0/src/zenml/cli/pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""CLI to interact with pipelines."""
+"""CLI functionality to interact with pipelines."""
+
 import os.path
 import textwrap
 import types
 from typing import Any, Dict
 
 import click
 
@@ -32,27 +33,32 @@
 
 logger = get_logger(__name__)
 
 
 def _load_class_from_module(
     module: types.ModuleType, config_item: Dict[str, str]
 ) -> Any:
-    """Based on a config item from the config yaml the corresponding module
-    attribute is loaded.
+    """Load a class from a module.
+
+    The corresponding module attribute is loaded based on a config item from the
+    config yaml.
 
     Args:
         module: Base module to use for import if only a function/class name is
                 supplied
         config_item: Config item loaded from the config yaml
                         - it will have a function/class name and
                         optionally a relative filepath
                         (e.g {`file`: `steps/steps.py`, `name`: `step_name`}
 
     Returns:
-         imported function/class
+        The imported function/class
+
+    Raises:
+        PipelineConfigurationError: If you passed in the wrong value type.
     """
     if isinstance(config_item, dict):
         if SourceConfigurationKeys.FILE_ in config_item:
             module = source_utils.import_python_file(
                 config_item[SourceConfigurationKeys.FILE_]
             )
 
@@ -121,14 +127,17 @@
 @click.argument("python_file")
 def run_pipeline(python_file: str, config_path: str) -> None:
     """Runs pipeline specified by the given config YAML object.
 
     Args:
         python_file: Path to the python file that defines the pipeline.
         config_path: Path to configuration YAML file.
+
+    Raises:
+        PipelineConfigurationError: If the pipeline configuration is invalid.
     """
     # If the file was run with `python run.py, this would happen automatically.
     #  In order to allow seamless switching between running directly and through
     #  zenml, this is done at this point
     with source_utils.prepend_python_path(
         os.path.abspath(os.path.dirname(python_file))
     ):
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/secret.py` & `zenml-0.9.0/src/zenml/cli/secret.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to manage or use your secrets via a SecretsManager stack component."""
 
 import getpass
 from typing import TYPE_CHECKING, List
 
 import click
 from pydantic import ValidationError
 
@@ -36,15 +37,19 @@
     from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
 
 
 # Secrets
 @cli.group(cls=TagGroup, tag=CliCategories.IDENTITY_AND_SECURITY)
 @click.pass_context
 def secret(ctx: click.Context) -> None:
-    """List and manage your secrets."""
+    """List and manage your secrets.
+
+    Args:
+        ctx: Click context.
+    """
     repo = Repository()
     active_stack = repo.zen_store.get_stack(name=repo.active_stack_name)
     secrets_manager_wrapper = active_stack.get_component_wrapper(
         StackComponentType.SECRETS_MANAGER
     )
     if secrets_manager_wrapper is None:
         error(
@@ -105,15 +110,14 @@
 
         zenml secret register my_secret --username=zenml --password=@@password
 
     will interpret the value of the field `password` as the literal string
     `@password`.
 
     Examples:
-
     - register a secret with the name `secret_one` and configure its values
     interactively:
 
         zenml secret register secret_one -i
 
     - register a secret with the name `secret_two` and configure its values
     via command line arguments:
@@ -134,28 +138,35 @@
 
         zenml integration install aws
         zenml secret register secret_four --schema=aws \
             --aws_access_key_id=1234567890 \
             --aws_secret_access_key=abcdefghij \
             --aws_session_token=@/path/to/token.txt
 
+    Args:
+        secrets_manager: The secrets manager to use.
+        name: The name of the secret to register.
+        secret_schema_type: The schema to use for validation.
+        interactive: Whether to use interactive mode to enter the secret values.
+        args: Command line arguments.
     """
     # flake8: noqa: C901
 
     # TODO [ENG-871]: Formatting for `zenml secret register --help` currently
     #  broken.
     # TODO [ENG-725]: Allow passing in json/dict when registering a secret as an
     #   additional option for the user on top of the interactive
     try:
         parsed_args = parse_unknown_options(args, expand_args=True)
     except AssertionError as e:
         error(str(e))
-        return
 
-    if name == "name":
+    if "name" in parsed_args:
+        error("You can't use 'name' as the key for one of your secrets.")
+    elif name == "name":
         error("Secret names cannot be named 'name'.")
 
     if name.startswith("--"):
         error(
             "Secret names cannot start with '--' The first argument must be."
             "the secret name."
         )
@@ -244,29 +255,38 @@
 @secret.command("get")
 @click.argument("name", type=click.STRING)
 @click.pass_obj
 def get_secret(
     secrets_manager: "BaseSecretsManager",
     name: str,
 ) -> None:
-    """Get a secret, given its name."""
+    """Get a secret, given its name.
+
+    Args:
+        secrets_manager: The secrets manager to use.
+        name: The name of the secret to get.
+    """
     try:
         secret = secrets_manager.get_secret(secret_name=name)
         pretty_print_secret(secret, hide_secret=False)
     except KeyError as e:
         error(
             f"Secret with name `{name}` does not exist or could not be loaded: "
             f"{str(e)}."
         )
 
 
 @secret.command("list")
 @click.pass_obj
 def list_secret(secrets_manager: "BaseSecretsManager") -> None:
-    """List all secrets tracked by your Secrets Manager."""
+    """List all secrets tracked by your Secrets Manager.
+
+    Args:
+        secrets_manager: The secrets manager to use.
+    """
     with console.status("Getting secret names..."):
         secret_names = secrets_manager.get_all_secret_keys()
         print_secrets(secret_names)
 
 
 @secret.command("update", context_settings={"ignore_unknown_options": True})
 @click.argument("name", type=click.STRING)
@@ -281,15 +301,15 @@
 @click.argument("args", nargs=-1, type=click.UNPROCESSED)
 @click.pass_obj
 def update_secret(
     secrets_manager: "BaseSecretsManager",
     name: str,
     interactive: bool,
     args: List[str],
-) -> None:  # sourcery skip: use-named-expression
+) -> None:
     """Update a secret with a given name.
 
     Use this command to update the information stored in an existing ZenML
     secret. The secret's key-value pairs can be updated interactively
     (if the `--interactive` option is set) or via command line arguments.
     If a schema is associated with the existing secret, the updated secret
     key-value pairs will be validated against the schema.
@@ -308,29 +328,33 @@
 
         zenml secret update my_secret --username=zenml --password=@@password
 
     will interpret the value of the field `password` as the literal string
     `@password`.
 
     Examples:
-
     - update a secret with the name `secret_one` and configure its values
     interactively:
 
         zenml secret update secret_one -i
 
     - update a secret with the name `secret_two` from command line arguments
     and load the value for the field `secret_token` from a
     local file:
 
         zenml secret update secret_four \
             --aws_access_key_id=1234567890 \
             --aws_secret_access_key=abcdefghij \
             --aws_session_token=@/path/to/token.txt
 
+    Args:
+        secrets_manager: The secrets manager to use.
+        name: The name of the secret to update.
+        interactive: Use interactive mode to update the secret values.
+        args: The command line arguments to use to update the secret.
     """
     # TODO [ENG-726]: allow users to pass in dict or json
 
     with console.status(f"Getting secret `{name}`..."):
         try:
             secret = secrets_manager.get_secret(secret_name=name)
         except KeyError as e:
@@ -406,15 +430,21 @@
 )
 @click.pass_obj
 def delete_secret_set(
     secrets_manager: "BaseSecretsManager",
     name: str,
     yes: bool = False,
 ) -> None:
-    """Delete a secret identified by its name."""
+    """Delete a secret identified by its name.
+
+    Args:
+        secrets_manager: The secrets manager to use.
+        name: The name of the secret to delete.
+        yes: Skip asking for confirmation.
+    """
     if not yes:
         confirmation_response = confirmation(
             f"This will delete all data associated with the `{name}` secret. "
             "Are you sure you want to proceed?"
         )
         if not confirmation_response:
             console.print("Aborting secret deletion...")
@@ -451,14 +481,19 @@
     secrets_manager: "BaseSecretsManager", force: bool, old_force: bool
 ) -> None:
     """Delete all secrets tracked by your Secrets Manager.
 
     Use the --yes flag to specify if force should be applied when deleting all
     secrets. This might have differing implications depending on the underlying
     secrets manager
+
+    Args:
+        secrets_manager: The secrets manager to use.
+        force: Force the deletion of all secrets.
+        old_force: DEPRECATED: Force the deletion of all secrets.
     """
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or `-y` "
             "instead."
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/served_models.py` & `zenml-0.9.0/src/zenml/cli/served_models.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to interact with models served by ZenML."""
+
 import uuid
 from typing import TYPE_CHECKING, Optional
 
 import click
 
 from zenml.cli.cli import TagGroup, cli
 from zenml.cli.utils import (
@@ -34,16 +36,18 @@
 
 @cli.group(
     cls=TagGroup,
     tag=CliCategories.MODEL_DEPLOYMENT,
 )
 @click.pass_context
 def served_models(ctx: click.Context) -> None:
-    """List and manage served models with the active model
-    deployer.
+    """List and manage served models with the active model deployer.
+
+    Args:
+        ctx: The click context.
     """
     repo = Repository()
     active_stack = repo.zen_store.get_stack(name=repo.active_stack_name)
     model_deployer_wrapper = active_stack.get_component_wrapper(
         StackComponentType.MODEL_DEPLOYER
     )
     if model_deployer_wrapper is None:
@@ -97,16 +101,26 @@
     model_deployer: "BaseModelDeployer",
     pipeline: Optional[str],
     step: Optional[str],
     pipeline_run: Optional[str],
     model: Optional[str],
     running: bool,
 ) -> None:
-    """Get a list of all served models within the model-deployer stack
-    component.
+    """Get a list of all served models within the model-deployer stack component.
+
+    Args:
+        model_deployer: The model-deployer stack component.
+        pipeline: Show only served models that were deployed by the indicated
+            pipeline.
+        step: Show only served models that were deployed by the indicated
+            pipeline step.
+        pipeline_run: Show only served models that were deployed by the
+            indicated pipeline run.
+        model: Show only served model versions for the given model name.
+        running: Show only model servers that are currently running.
     """
     services = model_deployer.find_model_server(
         running=running,
         pipeline_name=pipeline,
         pipeline_run_id=pipeline_run,
         pipeline_step_name=step,
         model_name=model,
@@ -122,16 +136,20 @@
 
 @served_models.command("describe")
 @click.argument("served_model_uuid", type=click.STRING)
 @click.pass_obj
 def describe_model(
     model_deployer: "BaseModelDeployer", served_model_uuid: str
 ) -> None:
-    """Describe a specified served model."""
+    """Describe a specified served model.
 
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+    """
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
     )
     if served_models:
         print_served_model_configuration(served_models[0], model_deployer)
         return
     warning(f"No model with uuid: '{served_model_uuid}' could be found.")
@@ -140,15 +158,20 @@
 
 @served_models.command("get-url")
 @click.argument("served_model_uuid", type=click.STRING)
 @click.pass_obj
 def get_url(
     model_deployer: "BaseModelDeployer", served_model_uuid: str
 ) -> None:
-    """Return the prediction URL to a specified model server."""
+    """Return the prediction URL to a specified model server.
+
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+    """
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
     )
     if served_models:
         try:
             prediction_url = model_deployer.get_model_server_info(
                 served_models[0]
@@ -176,16 +199,21 @@
     "immediately after telling the server to start, without waiting for it to "
     "become fully active (default: 300s).",
 )
 @click.pass_obj
 def start_model_service(
     model_deployer: "BaseModelDeployer", served_model_uuid: str, timeout: int
 ) -> None:
-    """Start a specified model server."""
+    """Start a specified model server.
 
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+        timeout: Time in seconds to wait for the model to start.
+    """
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
     )
     if served_models:
         model_deployer.start_model_server(
             served_models[0].uuid, timeout=timeout
         )
@@ -229,15 +257,23 @@
 def stop_model_service(
     model_deployer: "BaseModelDeployer",
     served_model_uuid: str,
     timeout: int,
     force: bool,
     old_force: bool,
 ) -> None:
-    """Stop a specified model server."""
+    """Stop a specified model server.
+
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+        timeout: Time in seconds to wait for the model to stop.
+        force: Force the model server to stop.
+        old_force: DEPRECATED: Force the model server to stop.
+    """
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or `-y` instead."
         )
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
@@ -286,15 +322,23 @@
 def delete_model_service(
     model_deployer: "BaseModelDeployer",
     served_model_uuid: str,
     timeout: int,
     force: bool,
     old_force: bool,
 ) -> None:
-    """Delete a specified model server."""
+    """Delete a specified model server.
+
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+        timeout: Time in seconds to wait for the model to be deleted.
+        force: Force the model server to stop and delete.
+        old_force: DEPRECATED: Force the model server to stop and delete.
+    """
     if old_force:
         force = old_force
         warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or `-y` instead."
         )
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
@@ -335,16 +379,23 @@
 def get_model_service_logs(
     model_deployer: "BaseModelDeployer",
     served_model_uuid: str,
     follow: bool,
     tail: Optional[int],
     raw: bool,
 ) -> None:
-    """Display the logs for a model server."""
+    """Display the logs for a model server.
 
+    Args:
+        model_deployer: The model-deployer stack component.
+        served_model_uuid: The UUID of the served model.
+        follow: Continue to output new log data as it becomes available.
+        tail: Only show the last NUM lines of log output.
+        raw: Show raw log contents (don't pretty-print logs).
+    """
     served_models = model_deployer.find_model_server(
         service_uuid=uuid.UUID(served_model_uuid)
     )
     if not served_models:
         warning(f"No model with uuid: '{served_model_uuid}' could be found.")
         return
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/server.py` & `zenml-0.9.0/src/zenml/cli/server.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,157 +8,194 @@
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 """CLI for manipulating ZenML local and global config file."""
+
 import ipaddress
 import os
 import shutil
 import textwrap
 from importlib import import_module
 from json import JSONDecodeError
 from typing import Optional, Union
 
 import click
 from click_params import IP_ADDRESS  # type: ignore[import]
 from rich.markdown import Markdown
 
+import zenml
 from zenml.cli import utils as cli_utils
 from zenml.cli.cli import TagGroup, cli
 from zenml.config.global_config import GlobalConfiguration
 from zenml.console import console
 from zenml.enums import CliCategories
-from zenml.io.utils import get_global_config_directory
 from zenml.logger import get_logger
+from zenml.utils.io_utils import get_global_config_directory
 
 logger = get_logger(__name__)
 GLOBAL_ZENML_SERVER_CONFIG_PATH = os.path.join(
     get_global_config_directory(),
     "zen_server",
 )
 ZENML_SERVER_CONFIG_FILENAME = os.path.join(
     GLOBAL_ZENML_SERVER_CONFIG_PATH, "service.json"
 )
 
+help_message = "Commands for managing the ZenServer."
+
+try:
+    # Make sure all ZenServer dependencies are installed
+    import fastapi  # noqa
+
+    from zenml.zen_server import ZenServer, ZenServerConfig  # noqa
+
+    server_installed = True
+except ImportError:
+    # Unable to import the ZenServer dependencies. Include a help message in
+    # the `zenml server` CLI group and don't add any subcommands that would
+    # just fail.
+    server_installed = False
+    help_message += (
+        "\n\n**Note**: The ZenServer seems to be unavailable on your machine. "
+        "This is probably because ZenML was installed without the optional "
+        "ZenServer dependencies. To install the missing dependencies "
+        f"run `pip install zenml=={zenml.__version__}[server]`."
+    )
+
 
 @cli.group(
     cls=TagGroup,
     tag=CliCategories.MANAGEMENT_TOOLS,
+    help=help_message,
 )
 def server() -> None:
     """Commands for managing the ZenServer."""
 
 
-@server.command("explain", help="Explain the ZenServer concept.")
-def explain_server() -> None:
-    """Explain the ZenServer concept."""
-    component_module = import_module("zenml.zen_server")
-
-    if component_module.__doc__ is not None:
-        md = Markdown(component_module.__doc__)
-        console.print(md)
-
+if server_installed:
 
-@server.command("up", help="Start a daemon service running the ZenServer.")
-@click.option(
-    "--ip-address", type=IP_ADDRESS, default="127.0.0.1", show_default=True
-)
-@click.option("--port", type=int, default=8000, show_default=True)
-@click.option("--profile", type=str, default=None)
-def up_server(
-    ip_address: Union[ipaddress.IPv4Address, ipaddress.IPv6Address],
-    port: int,
-    profile: Optional[str],
-) -> None:
-    """Provisions resources for the ZenServer."""
-    from zenml.services import ServiceRegistry
-    from zenml.zen_server.zen_server import ZenServer, ZenServerConfig
-
-    service_config = ZenServerConfig(
-        root_runtime_path=GLOBAL_ZENML_SERVER_CONFIG_PATH,
-        singleton=True,
-        ip_address=str(ip_address),
-        port=port,
+    @server.command("explain", help="Explain the ZenServer concept.")
+    def explain_server() -> None:
+        """Explain the ZenServer concept."""
+        component_module = import_module("zenml.zen_server")
+
+        if component_module.__doc__ is not None:
+            md = Markdown(component_module.__doc__)
+            console.print(md)
+
+    @server.command("up", help="Start a daemon service running the ZenServer.")
+    @click.option(
+        "--ip-address", type=IP_ADDRESS, default="127.0.0.1", show_default=True
     )
-    if profile is not None:
-        if GlobalConfiguration().get_profile(profile) is None:
-            raise ValueError(f"Could not find profile of name {profile}.")
-        service_config.profile_name = profile
-
-    try:
-        with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
-            zen_server = ServiceRegistry().load_service_from_json(f.read())
-            cli_utils.declare(
-                "An existing ZenServer local instance was found. To start a "
-                "fresh instance, shut down the current one by running `zenml "
-                "server down`. Reusing the existing ZenServer instance...",
+    @click.option("--port", type=int, default=8000, show_default=True)
+    @click.option("--profile", type=str, default=None)
+    def up_server(
+        ip_address: Union[ipaddress.IPv4Address, ipaddress.IPv6Address],
+        port: int,
+        profile: Optional[str],
+    ) -> None:
+        """Provisions resources for the ZenServer.
+
+        Args:
+            ip_address: The IP address to bind the server to.
+            port: The port to bind the server to.
+            profile: The profile to use for the server.
+
+        Raises:
+            ValueError: If the profile name wasn't found.
+        """
+        from zenml.services import ServiceRegistry
+
+        service_config = ZenServerConfig(
+            root_runtime_path=GLOBAL_ZENML_SERVER_CONFIG_PATH,
+            singleton=True,
+            ip_address=str(ip_address),
+            port=port,
+        )
+        if profile is not None:
+            if GlobalConfiguration().get_profile(profile) is None:
+                raise ValueError(f"Could not find profile of name {profile}.")
+            service_config.profile_name = profile
+
+        try:
+            with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
+                zen_server = ServiceRegistry().load_service_from_json(f.read())
+                cli_utils.declare(
+                    "An existing ZenServer local instance was found. To start a "
+                    "fresh instance, shut down the current one by running `zenml "
+                    "server down`. Reusing the existing ZenServer instance...",
+                )
+        except (
+            JSONDecodeError,
+            FileNotFoundError,
+            ModuleNotFoundError,
+            TypeError,
+        ):
+            zen_server = ZenServer(service_config)
+            cli_utils.declare("Starting a new ZenServer local instance.")
+
+        zen_server.start(timeout=30)
+
+        # won't happen for ZenServer, but mypy complains otherwise
+        assert zen_server.endpoint is not None
+
+        if zen_server.endpoint.status.port != port:
+            cli_utils.warning(
+                textwrap.dedent(
+                    f"""
+                    You specified port={port}, but the current ZenServer is running
+                    at '{zen_server.endpoint.status.uri}'. This can happen in the
+                    case the specified port is in use or if the server was already
+                    running on port {zen_server.endpoint.status.port}.
+                    In case you want to change to port {port}, shut down the server
+                    with `zenml server down` and restart it with a free port of your
+                    choice.
+                    """
+                )
             )
-    except (JSONDecodeError, FileNotFoundError, ModuleNotFoundError, TypeError):
-        zen_server = ZenServer(service_config)
-        cli_utils.declare("Starting a new ZenServer local instance.")
-
-    zen_server.start(timeout=30)
-
-    # won't happen for ZenServer, but mypy complains otherwise
-    assert zen_server.endpoint is not None
-
-    if zen_server.endpoint.status.port != port:
-        cli_utils.warning(
-            textwrap.dedent(
-                f"""
-                You specified port={port}, but the current ZenServer is running
-                at '{zen_server.endpoint.status.uri}'. This can happen in the
-                case the specified port is in use or if the server was already
-                running on port {zen_server.endpoint.status.port}.
-                In case you want to change to port {port}, shut down the server
-                with `zenml server down` and restart it with a free port of your
-                choice.
-                """
+        else:
+            cli_utils.declare(
+                f"ZenServer running at '{zen_server.endpoint.status.uri}'."
             )
-        )
-    else:
-        cli_utils.declare(
-            f"ZenServer running at '{zen_server.endpoint.status.uri}'."
-        )
-
-
-@server.command("status")
-def status_server() -> None:
-    """Get the status of the ZenServer."""
-    from zenml.services import ServiceRegistry, ServiceState
-
-    try:
-        with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
-            zervice = ServiceRegistry().load_service_from_json(f.read())
-    except FileNotFoundError:
-        cli_utils.warning("No ZenServer instance found locally!")
-    else:
-        zen_server_status = zervice.check_status()
-
-        running = (
-            f" and running at {zervice.endpoint.status.uri}."
-            if zen_server_status[0] == ServiceState.ACTIVE and zervice.endpoint
-            else ""
-        )
 
-        cli_utils.declare(
-            f"The ZenServer status is {zen_server_status[0]}{running}."
-        )
+    @server.command("status")
+    def status_server() -> None:
+        """Get the status of the ZenServer."""
+        from zenml.services import ServiceRegistry, ServiceState
+
+        try:
+            with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
+                zervice = ServiceRegistry().load_service_from_json(f.read())
+        except FileNotFoundError:
+            cli_utils.warning("No ZenServer instance found locally!")
+        else:
+            zen_server_status = zervice.check_status()
+
+            running = (
+                f" and running at {zervice.endpoint.status.uri}."
+                if zen_server_status[0] == ServiceState.ACTIVE
+                and zervice.endpoint
+                else ""
+            )
 
+            cli_utils.declare(
+                f"The ZenServer status is {zen_server_status[0]}{running}."
+            )
 
-@server.command("down")
-def down_server() -> None:
-    """Shut down the local ZenServer instance."""
-    from zenml.services import ServiceRegistry
-
-    try:
-        with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
-            zervice = ServiceRegistry().load_service_from_json(f.read())
-    except FileNotFoundError:
-        cli_utils.error("No ZenServer instance found locally!")
-    else:
-        cli_utils.declare("Shutting down the local ZenService instance.")
-        zervice.stop()
+    @server.command("down")
+    def down_server() -> None:
+        """Shut down the local ZenServer instance."""
+        from zenml.services import ServiceRegistry
+
+        try:
+            with open(ZENML_SERVER_CONFIG_FILENAME, "r") as f:
+                zervice = ServiceRegistry().load_service_from_json(f.read())
+        except FileNotFoundError:
+            cli_utils.error("No ZenServer instance found locally!")
+        else:
+            cli_utils.declare("Shutting down the local ZenService instance.")
+            zervice.stop()
 
-        shutil.rmtree(GLOBAL_ZENML_SERVER_CONFIG_PATH)
+            shutil.rmtree(GLOBAL_ZENML_SERVER_CONFIG_PATH)
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/stack.py` & `zenml-0.9.0/src/zenml/cli/stack.py`

 * *Files 14% similar despite different names*

```diff
@@ -115,14 +115,22 @@
     "--experiment_tracker",
     "experiment_tracker_name",
     help="Name of the experiment tracker for this stack.",
     type=str,
     required=False,
 )
 @click.option(
+    "-al",
+    "--alerter",
+    "alerter_name",
+    help="Name of the alerter for this stack.",
+    type=str,
+    required=False,
+)
+@click.option(
     "--set",
     "set_stack",
     is_flag=True,
     help="Immediately set this stack as active.",
     type=click.BOOL,
 )
 def register_stack(
@@ -132,17 +140,33 @@
     orchestrator_name: str,
     container_registry_name: Optional[str] = None,
     secrets_manager_name: Optional[str] = None,
     step_operator_name: Optional[str] = None,
     feature_store_name: Optional[str] = None,
     model_deployer_name: Optional[str] = None,
     experiment_tracker_name: Optional[str] = None,
+    alerter_name: Optional[str] = None,
     set_stack: bool = False,
 ) -> None:
-    """Register a stack."""
+    """Register a stack.
+
+    Args:
+        stack_name: Unique name of the stack
+        metadata_store_name: Name of the metadata store for this stack.
+        artifact_store_name: Name of the artifact store for this stack.
+        orchestrator_name: Name of the orchestrator for this stack.
+        container_registry_name: Name of the container registry for this stack.
+        secrets_manager_name: Name of the secrets manager for this stack.
+        step_operator_name: Name of the step operator for this stack.
+        feature_store_name: Name of the feature store for this stack.
+        model_deployer_name: Name of the model deployer for this stack.
+        experiment_tracker_name: Name of the experiment tracker for this stack.
+        alerter_name: Name of the alerter for this stack.
+        set_stack: Immediately set this stack as active.
+    """
     cli_utils.print_active_profile()
 
     with console.status(f"Registering stack '{stack_name}'...\n"):
         repo = Repository()
 
         stack_components = {
             StackComponentType.METADATA_STORE: repo.get_stack_component(
@@ -199,14 +223,22 @@
             stack_components[
                 StackComponentType.EXPERIMENT_TRACKER
             ] = repo.get_stack_component(
                 StackComponentType.EXPERIMENT_TRACKER,
                 name=experiment_tracker_name,
             )
 
+        if alerter_name:
+            stack_components[
+                StackComponentType.ALERTER
+            ] = repo.get_stack_component(
+                StackComponentType.ALERTER,
+                name=alerter_name,
+            )
+
         stack_ = Stack.from_components(
             name=stack_name, components=stack_components
         )
         repo.register_stack(stack_)
         cli_utils.declare(f"Stack '{stack_name}' successfully registered!")
 
     if set_stack:
@@ -269,41 +301,66 @@
     "feature_store_name",
     help="Name of the new feature store for this stack.",
     type=str,
     required=False,
 )
 @click.option(
     "-d",
-    "--model-deployer",
+    "--model_deployer",
     "model_deployer_name",
     help="Name of the new model deployer for this stack.",
     type=str,
     required=False,
 )
 @click.option(
     "-e",
     "--experiment_tracker",
     "experiment_tracker_name",
     help="Name of the new experiment tracker for this stack.",
     type=str,
     required=False,
 )
+@click.option(
+    "-al",
+    "--alerter",
+    "alerter_name",
+    help="Name of the new alerter for this stack.",
+    type=str,
+    required=False,
+)
 def update_stack(
     stack_name: Optional[str],
     metadata_store_name: Optional[str] = None,
     artifact_store_name: Optional[str] = None,
     orchestrator_name: Optional[str] = None,
     container_registry_name: Optional[str] = None,
     step_operator_name: Optional[str] = None,
     secrets_manager_name: Optional[str] = None,
     feature_store_name: Optional[str] = None,
     model_deployer_name: Optional[str] = None,
     experiment_tracker_name: Optional[str] = None,
+    alerter_name: Optional[str] = None,
 ) -> None:
-    """Update a stack."""
+    """Update a stack.
+
+    Args:
+        stack_name: Name of the stack to update.
+        metadata_store_name: Name of the new metadata store for this stack.
+        artifact_store_name: Name of the new artifact store for this stack.
+        orchestrator_name: Name of the new orchestrator for this stack.
+        container_registry_name: Name of the new container registry for this
+            stack.
+        step_operator_name: Name of the new step operator for this stack.
+        secrets_manager_name: Name of the new secrets manager for this stack.
+        feature_store_name: Name of the new feature store for this stack.
+        model_deployer_name: Name of the new model deployer for this stack.
+        experiment_tracker_name: Name of the new experiment tracker for this
+            stack.
+        alerter_name: Name of the new alerter for this stack.
+    """
     cli_utils.print_active_profile()
 
     repo = Repository()
 
     active_stack_name = repo.active_stack_name
     stack_name = stack_name or active_stack_name
 
@@ -382,14 +439,22 @@
             stack_components[
                 StackComponentType.EXPERIMENT_TRACKER
             ] = repo.get_stack_component(
                 StackComponentType.EXPERIMENT_TRACKER,
                 name=experiment_tracker_name,
             )
 
+        if alerter_name:
+            stack_components[
+                StackComponentType.ALERTER
+            ] = repo.get_stack_component(
+                StackComponentType.ALERTER,
+                name=alerter_name,
+            )
+
         stack_ = Stack.from_components(
             name=stack_name, components=stack_components
         )
         repo.update_stack(stack_name, stack_)
         cli_utils.declare(f"Stack `{stack_name}` successfully updated!")
 
 
@@ -450,16 +515,25 @@
     container_registry_flag: Optional[bool] = False,
     step_operator_flag: Optional[bool] = False,
     secrets_manager_flag: Optional[bool] = False,
     feature_store_flag: Optional[bool] = False,
     model_deployer_flag: Optional[bool] = False,
     experiment_tracker_flag: Optional[bool] = False,
 ) -> None:
-    """Remove stack components from a stack."""
+    """Remove stack components from a stack.
 
+    Args:
+        stack_name: Name of the stack to remove components from.
+        container_registry_flag: To remove the container registry from this stack.
+        step_operator_flag: To remove the step operator from this stack.
+        secrets_manager_flag: To remove the secrets manager from this stack.
+        feature_store_flag: To remove the feature store from this stack.
+        model_deployer_flag: To remove the model deployer from this stack.
+        experiment_tracker_flag: To remove the experiment tracker from this stack.
+    """
     cli_utils.print_active_profile()
 
     repo = Repository()
 
     active_stack_name = repo.active_stack_name
     stack_name = stack_name or active_stack_name
 
@@ -501,15 +575,20 @@
 @stack.command("rename")
 @click.argument("current_stack_name", type=str, required=True)
 @click.argument("new_stack_name", type=str, required=True)
 def rename_stack(
     current_stack_name: str,
     new_stack_name: str,
 ) -> None:
-    """Rename a stack."""
+    """Rename a stack.
+
+    Args:
+        current_stack_name: Name of the stack to rename.
+        new_stack_name: New name of the stack.
+    """
     with console.status(f"Renaming stack `{current_stack_name}`...\n"):
         repo = Repository()
         try:
             current_stack = repo.get_stack(current_stack_name)
         except KeyError:
             cli_utils.error(
                 f"Stack `{current_stack_name}` cannot be renamed as it does "
@@ -569,15 +648,19 @@
 )
 @click.argument(
     "stack_name",
     type=click.STRING,
     required=False,
 )
 def describe_stack(stack_name: Optional[str]) -> None:
-    """Show details about a named stack or the active stack."""
+    """Show details about a named stack or the active stack.
+
+    Args:
+        stack_name: Name of the stack to describe.
+    """
     cli_utils.print_active_profile()
 
     repo = Repository()
 
     stack_configurations = repo.stack_configurations
     if len(stack_configurations) == 0:
         cli_utils.error("No stacks registered.")
@@ -604,15 +687,23 @@
 @stack.command("delete")
 @click.argument("stack_name", type=str)
 @click.option("--yes", "-y", is_flag=True, required=False)
 @click.option("--force", "-f", "old_force", is_flag=True, required=False)
 def delete_stack(
     stack_name: str, yes: bool = False, old_force: bool = False
 ) -> None:
-    """Delete a stack."""
+    """Delete a stack.
+
+    Args:
+        stack_name: Name of the stack to delete.
+        yes: Stack will be deleted without prompting for
+            confirmation.
+        old_force: Stack will be deleted without prompting for
+            confirmation.
+    """
     if old_force:
         yes = old_force
         cli_utils.warning(
             "The `--force` flag will soon be deprecated. Use `--yes` or "
             "`-y` instead."
         )
     cli_utils.print_active_profile()
@@ -658,14 +749,18 @@
 def set_active_stack_command(
     stack_name: str, global_profile: bool = False
 ) -> None:
     """Sets a stack as active.
 
     If the '--global' flag is set, the global active stack will be set,
     otherwise the repository active stack takes precedence.
+
+    Args:
+        stack_name: Name of the stack to set as active.
+        global_profile: Set the active stack globally.
     """
     set_active_stack(stack_name, global_profile)
 
 
 def set_active_stack(stack_name: str, global_profile: bool = False) -> None:
     """Sets a stack as active.
 
@@ -716,33 +811,39 @@
         cli_utils.error(str(e))
 
 
 @stack.command("down")
 @click.option(
     "--yes",
     "-y",
-    "force",
+    "old_force",
     is_flag=True,
-    help="Deprovisions local resources instead of suspending them.",
+    help="DEPRECATED: Deprovisions local resources instead of suspending "
+    "them. Use `-f/--force` instead.",
 )
 @click.option(
     "--force",
     "-f",
-    "old_force",
+    "force",
     is_flag=True,
-    help="DEPRECATED: Deprovisions local resources instead of suspending "
-    "them. Use `-y/--yes` instead.",
+    help="Deprovisions local resources instead of suspending them.",
 )
 def down_stack(force: bool = False, old_force: bool = False) -> None:
-    """Suspends resources of the active stack deployment."""
+    """Suspends resources of the active stack deployment.
+
+    Args:
+        force: Deprovisions local resources instead of suspending them.
+        old_force: DEPRECATED: Deprovisions local resources instead of
+            suspending them. Use `-y/--yes` instead.
+    """
     if old_force:
         force = old_force
         cli_utils.warning(
-            "The `--force` flag will soon be deprecated. Use `--yes` "
-            "or `-y` instead."
+            "The `--yes` flag will soon be deprecated. Use `--force` "
+            "or `-f` instead."
         )
     cli_utils.print_active_profile()
 
     stack_ = Repository().active_stack
 
     if force:
         cli_utils.declare(
@@ -755,15 +856,23 @@
         )
         stack_.suspend()
 
 
 def _get_component_as_dict(
     component_type: StackComponentType, component_name: str
 ) -> Dict[str, str]:
-    """Return a dict represention of a component's key config values"""
+    """Return a dict representation of a component's key config values.
+
+    Args:
+        component_type: The type of component to get.
+        component_name: The name of the component to get.
+
+    Returns:
+        A dict representation of the component's key config values.
+    """
     repo = Repository()
     component = repo.get_stack_component(component_type, name=component_name)
     component_dict = {
         key: value
         for key, value in json.loads(component.json()).items()
         if key != "uuid" and value is not None
     }
@@ -771,15 +880,20 @@
     return component_dict
 
 
 @stack.command("export")
 @click.argument("stack_name", type=str, required=True)
 @click.argument("filename", type=str, required=False)
 def export_stack(stack_name: str, filename: Optional[str]) -> None:
-    """Export a stack to YAML."""
+    """Export a stack to YAML.
+
+    Args:
+        stack_name: The name of the stack to export.
+        filename: The filename to export the stack to.
+    """
     track_event(AnalyticsEvent.EXPORT_STACK)
 
     # Get configuration of given stack
     # TODO [ENG-893]: code duplicate with describe_stack()
     repo = Repository()
 
     stack_configurations = repo.stack_configurations
@@ -808,15 +922,23 @@
     write_yaml(filename, yaml_data)
     cli_utils.declare(f"Exported stack '{stack_name}' to file '{filename}'.")
 
 
 def _import_stack_component(
     component_type: StackComponentType, component_config: Dict[str, str]
 ) -> str:
-    """import a single stack component with given type/config"""
+    """Import a single stack component with given type/config.
+
+    Args:
+        component_type: The type of component to import.
+        component_config: The config of the component to import.
+
+    Returns:
+        The name of the imported component.
+    """
     component_type = StackComponentType(component_type)
     component_name = component_config.pop("name")
     component_flavor = component_config.pop("flavor")
 
     # make sure component can be registered, otherwise ask for new name
     while True:
         # check if component already exists
@@ -862,15 +984,21 @@
 @stack.command("import")
 @click.argument("stack_name", type=str, required=True)
 @click.argument("filename", type=str, required=False)
 @click.pass_context
 def import_stack(
     ctx: click.Context, stack_name: str, filename: Optional[str]
 ) -> None:
-    """Import a stack from YAML."""
+    """Import a stack from YAML.
+
+    Args:
+        ctx: The click context.
+        stack_name: The name of the stack to import.
+        filename: The filename to import the stack from.
+    """
     track_event(AnalyticsEvent.IMPORT_STACK)
 
     # handle 'zenml stack import file.yaml' calls
     if stack_name.endswith(".yaml") and filename is None:
         filename = stack_name
         data = read_yaml(filename)
         stack_name = data["stack_name"]  # read stack_name from export
@@ -891,16 +1019,15 @@
             f"The stack was created using ZenML version "
             f"{data['zenml_version']}, you have version "
             f"{zenml.__version__} installed."
         )
 
     # ask user for new stack_name if current one already exists
     repo = Repository()
-    registered_stacks = {stack_.name for stack_ in repo.stacks}
-    while stack_name in registered_stacks:
+    while stack_name in repo.stack_configurations:
         stack_name = click.prompt(
             f"Stack `{stack_name}` already exists. "
             f"Please choose a different name.",
             type=str,
         )
 
     # import stack components
@@ -910,7 +1037,40 @@
             component_type=component_type,
             component_config=component_config,
         )
         component_names[component_type + "_name"] = component_name
 
     # register new stack
     ctx.invoke(register_stack, stack_name=stack_name, **component_names)
+
+
+@stack.command(
+    "copy",
+    help="SOURCE_NAME: The name of the stack to copy.\n\nTARGET_NAME: Name of the copied stack.",
+)
+@click.argument("source_name", type=str, required=True)
+@click.argument("target_name", type=str, required=True)
+def copy_stack(source_name: str, target_name: str) -> None:
+    """Copy a stack.
+
+    Args:
+        source_name: The name of the stack to copy.
+        target_name: Name of the copied stack.
+    """
+    track_event(AnalyticsEvent.COPIED_STACK)
+
+    with console.status(f"Copying stack `{source_name}`...\n"):
+        repo = Repository()
+        try:
+            stack_ = repo.get_stack(source_name)
+        except KeyError:
+            cli_utils.error(
+                f"Stack `{source_name}` cannot be copied as it does not exist."
+            )
+
+        if target_name in repo.stack_configurations:
+            cli_utils.error(
+                f"Can't copy stack as a stack with the name '{target_name}' "
+                "already exists."
+            )
+        stack_._name = target_name
+        Repository().register_stack(stack_)
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/stack_components.py` & `zenml-0.9.0/src/zenml/cli/stack_components.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to generate stack component CLI commands."""
+
 import time
 from importlib import import_module
 from typing import Any, Callable, List, Optional, Sequence, Tuple, Type
 
 import click
 from pydantic import ValidationError
 from rich.markdown import Markdown
@@ -31,50 +33,82 @@
 from zenml.utils.source_utils import validate_flavor_source
 from zenml.zen_stores.models.component_wrapper import ComponentWrapper
 
 
 def _get_required_attributes(
     component_class: Type[StackComponent],
 ) -> List[str]:
-    """Gets the required properties for a stack component."""
+    """Gets the required properties for a stack component.
+
+    Args:
+        component_class: Class of the component to get the required properties
+            for.
+
+    Returns:
+        A list of the required properties for the given component class.
+    """
     return [
         field_name
         for field_name, field in component_class.__fields__.items()
         if (field.required is True)
         and field_name not in MANDATORY_COMPONENT_ATTRIBUTES
     ]
 
 
 def _get_available_attributes(
     component_class: Type[StackComponent],
 ) -> List[str]:
-    """Gets the available non-mandatory properties for a stack component."""
+    """Gets the available non-mandatory properties for a stack component.
+
+    Args:
+        component_class: Class of the component to get the available
+            properties for.
+
+    Returns:
+        A list of the available properties for the given component class.
+    """
     return [
         field_name
         for field_name, _ in component_class.__fields__.items()
         if field_name not in MANDATORY_COMPONENT_ATTRIBUTES
     ]
 
 
 def _get_optional_attributes(
     component_class: Type[StackComponent],
 ) -> List[str]:
-    """Gets the optional properties for a stack component."""
+    """Gets the optional properties for a stack component.
+
+    Args:
+        component_class: Class of the component to get the optional properties
+            for.
+
+    Returns:
+        A list of the optional properties for the given component class.
+    """
     return [
         field_name
         for field_name, field in component_class.__fields__.items()
         if field.required is False
         and field_name not in MANDATORY_COMPONENT_ATTRIBUTES
     ]
 
 
 def _component_display_name(
     component_type: StackComponentType, plural: bool = False
 ) -> str:
-    """Human-readable name for a stack component."""
+    """Human-readable name for a stack component.
+
+    Args:
+        component_type: Type of the component to get the display name for.
+        plural: Whether the display name should be plural or not.
+
+    Returns:
+        A human-readable name for the given stack component type.
+    """
     name = component_type.plural if plural else component_type.value
     return name.replace("_", " ")
 
 
 def _get_stack_component_wrapper(
     component_type: StackComponentType,
     component_name: Optional[str] = None,
@@ -87,15 +121,14 @@
             component of the active stack gets returned.
 
     Returns:
         A stack component of the given type and name, or None, if no stack
         component is registered for the given name and type, and a boolean
         indicating whether the component is active or not.
     """
-
     singular_display_name = _component_display_name(component_type)
     plural_display_name = _component_display_name(component_type, plural=True)
 
     repo = Repository()
 
     components = repo.zen_store.get_stack_components(component_type)
     if len(components) == 0:
@@ -130,19 +163,25 @@
         cli_utils.error(f"No {singular_display_name} in active stack.")
     return None, False
 
 
 def generate_stack_component_get_command(
     component_type: StackComponentType,
 ) -> Callable[[], None]:
-    """Generates a `get` command for the specific stack component type."""
+    """Generates a `get` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     def get_stack_component_command() -> None:
         """Prints the name of the active component."""
-
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         active_stack = Repository().active_stack
         component = active_stack.components.get(component_type, None)
         display_name = _component_display_name(component_type)
         if component:
@@ -155,26 +194,34 @@
 
     return get_stack_component_command
 
 
 def generate_stack_component_describe_command(
     component_type: StackComponentType,
 ) -> Callable[[Optional[str]], None]:
-    """Generates a `describe` command for the specific stack component type."""
+    """Generates a `describe` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     @click.argument(
         "name",
         type=str,
         required=False,
     )
     def describe_stack_component_command(name: Optional[str]) -> None:
         """Prints details about the active/specified component.
 
         Args:
-            name: Name of the component to describe."""
+            name: Name of the component to describe.
+        """
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         singular_display_name = _component_display_name(component_type)
         component_wrapper, is_active = _get_stack_component_wrapper(
             component_type, component_name=name
         )
@@ -187,19 +234,25 @@
 
     return describe_stack_component_command
 
 
 def generate_stack_component_list_command(
     component_type: StackComponentType,
 ) -> Callable[[], None]:
-    """Generates a `list` command for the specific stack component type."""
+    """Generates a `list` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     def list_stack_components_command() -> None:
         """Prints a table of stack components."""
-
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         repo = Repository()
 
         components = repo.zen_store.get_stack_components(component_type)
         display_name = _component_display_name(component_type, plural=True)
@@ -221,27 +274,41 @@
 
 def _register_stack_component(
     component_type: StackComponentType,
     component_name: str,
     component_flavor: str,
     **kwargs: Any,
 ) -> None:
-    """Register a stack component."""
+    """Register a stack component.
+
+    Args:
+        component_type: Type of the component to register.
+        component_name: Name of the component to register.
+        component_flavor: Flavor of the component to register.
+        **kwargs: Additional arguments to pass to the component.
+    """
     repo = Repository()
     flavor_class = repo.get_flavor(
         name=component_flavor, component_type=component_type
     )
     component = flavor_class(name=component_name, **kwargs)
     Repository().register_stack_component(component)
 
 
 def generate_stack_component_register_command(
     component_type: StackComponentType,
-) -> Callable[[str, str, str, List[str]], None]:
-    """Generates a `register` command for the specific stack component type."""
+) -> Callable[[str, str, str, bool, List[str]], None]:
+    """Generates a `register` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
     display_name = _component_display_name(component_type)
 
     @click.argument(
         "name",
         type=str,
         required=True,
     )
@@ -255,19 +322,39 @@
     @click.option(
         "--type",
         "-t",
         "old_flavor",
         help=f"DEPRECATED: The flavor of the {display_name} to register.",
         type=str,
     )
+    @click.option(
+        "--interactive",
+        "-i",
+        "interactive",
+        is_flag=True,
+        help="Use interactive mode to update the secret values.",
+        type=click.BOOL,
+    )
     @click.argument("args", nargs=-1, type=click.UNPROCESSED)
     def register_stack_component_command(
-        name: str, flavor: str, old_flavor: str, args: List[str]
+        name: str,
+        flavor: str,
+        old_flavor: str,
+        interactive: bool,
+        args: List[str],
     ) -> None:
-        """Registers a stack component."""
+        """Registers a stack component.
+
+        Args:
+            name: Name of the component to register.
+            flavor: Flavor of the component to register.
+            old_flavor: DEPRECATED: The flavor of the component to register.
+            interactive: Use interactive mode to fill missing values.
+            args: Additional arguments to pass to the component.
+        """
         cli_utils.print_active_profile()
 
         if flavor or old_flavor:
             if old_flavor:
                 if flavor:
                     cli_utils.error(
                         f"You have used both '--type': {old_flavor} and a "
@@ -283,60 +370,140 @@
                 )
         else:
             cli_utils.error(
                 "Please use the option to specify '--flavor'/'-f' of the "
                 f"{display_name} you want to register."
             )
 
-        with console.status(f"Registering {display_name} '{name}'...\n"):
-            try:
-                parsed_args = cli_utils.parse_unknown_options(args)
-            except AssertionError as e:
-                cli_utils.error(str(e))
-                return
+        try:
+            parsed_args = cli_utils.parse_unknown_options(args)
+        except AssertionError as e:
+            cli_utils.error(str(e))
+            return
 
-            try:
+        try:
+            with console.status(f"Registering {display_name} '{name}'...\n"):
                 _register_stack_component(
                     component_type=component_type,
                     component_name=name,
                     component_flavor=flavor,
                     **parsed_args,
                 )
-            except ValidationError as e:
+        except ValidationError as e:
+            if not interactive:
                 cli_utils.error(
                     f"When you are registering a new {display_name} with the "
                     f"flavor `{flavor}`, make sure that you are utilizing "
                     f"the right attributes. Current problems:\n\n{e}"
                 )
-            except Exception as e:
-                cli_utils.error(str(e))
+                return
+            else:
+                cli_utils.warning(
+                    f"You did not set all required fields for a "
+                    f"{flavor} {display_name}. You'll be guided through the "
+                    f"missing fields now. You'll be able to skip optional "
+                    f"fields by just pressing enter. To cancel simply interrupt"
+                    f" with CTRL+C."
+                )
+
+                repo = Repository()
+                flavor_class = repo.get_flavor(
+                    name=flavor, component_type=component_type
+                )
+                missing_fields = {
+                    k: v.required
+                    for k, v in flavor_class.__fields__.items()
+                    if v.name not in ["name", "uuid", *parsed_args.keys()]
+                }
+
+                completed_fields = parsed_args.copy()
+                for field, field_req in missing_fields.items():
+                    if field_req:
+                        user_input = click.prompt(f"{field}")
+                    else:
+                        prompt = f"{field} (Optional)'"
+                        user_input = click.prompt(prompt, default="")
+                    if user_input:
+                        completed_fields[field] = user_input
+
+                try:
+                    with console.status(
+                        f"Registering {display_name} '{name}'" f"...\n"
+                    ):
+
+                        _register_stack_component(
+                            component_type=component_type,
+                            component_name=name,
+                            component_flavor=flavor,
+                            **completed_fields,
+                        )
+                except Exception as e:
+                    cli_utils.error(str(e))
+
+        except Exception as e:
+            cli_utils.error(str(e))
 
         cli_utils.declare(f"Successfully registered {display_name} `{name}`.")
 
     return register_stack_component_command
 
 
 def generate_stack_component_flavor_register_command(
     component_type: StackComponentType,
 ) -> Callable[[str], None]:
-    """Generates a `register` command for the flavors of a stack component."""
+    """Generates a `register` command for the flavors of a stack component.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     @click.argument(
         "source",
         type=str,
         required=True,
     )
     def register_stack_component_flavor_command(source: str) -> None:
-        """Adds a flavor for a stack component type"""
+        """Adds a flavor for a stack component type.
+
+        Args:
+            source: The source file to read the flavor from.
+        """
         cli_utils.print_active_profile()
 
         # Check whether the module exists and is the right type
-        component_class = validate_flavor_source(
-            source=source, component_type=component_type
-        )
+        try:
+            component_class = validate_flavor_source(
+                source=source, component_type=component_type
+            )
+        except ValueError as e:
+            error_message = str(e) + "\n\n"
+            repo_root = Repository().root
+
+            if repo_root:
+                error_message += (
+                    "Please make sure your source is either importable from an "
+                    "installed package or specified relative to your ZenML "
+                    f"repository root '{repo_root}'."
+                )
+
+            else:
+                error_message += (
+                    "Please make sure your source is either importable from an "
+                    "installed package or create a ZenML repository by running "
+                    "`zenml init` and specify the source relative to the "
+                    "repository directory. Check out "
+                    "https://docs.zenml.io/developer-guide/repo-and-config"
+                    "#the-zenml-repository "
+                    "for more information."
+                )
+
+            cli_utils.error(error_message)
 
         # Register the flavor in the given source
         try:
             Repository().zen_store.create_flavor(
                 name=component_class.FLAVOR,
                 stack_component_type=component_class.TYPE,
                 source=source,
@@ -352,18 +519,25 @@
 
     return register_stack_component_flavor_command
 
 
 def generate_stack_component_flavor_list_command(
     component_type: StackComponentType,
 ) -> Callable[[], None]:
-    """Generates a `list` command for the flavors of a stack component."""
+    """Generates a `list` command for the flavors of a stack component.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     def list_stack_component_flavor_command() -> None:
-        """Adds a flavor for a stack component type"""
+        """Adds a flavor for a stack component type."""
         cli_utils.print_active_profile()
 
         from zenml.stack.flavor_registry import flavor_registry
 
         # List all the flavors of the component type
         zenml_flavors = [
             f
@@ -382,27 +556,39 @@
 
     return list_stack_component_flavor_command
 
 
 def generate_stack_component_update_command(
     component_type: StackComponentType,
 ) -> Callable[[str, List[str]], None]:
-    """Generates an `update` command for the specific stack component type."""
+    """Generates an `update` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
     display_name = _component_display_name(component_type)
 
     @click.argument(
         "name",
         type=str,
         required=False,
     )
     @click.argument("args", nargs=-1, type=click.UNPROCESSED)
     def update_stack_component_command(
         name: Optional[str], args: Sequence[str]
     ) -> None:
-        """Updates a stack component."""
+        """Updates a stack component.
+
+        Args:
+            name: The name of the stack component to update.
+            args: Additional arguments to pass to the update command.
+        """
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         kwargs = list(args)
         if name and name.startswith("--"):
             kwargs.append(name)
             name = None
@@ -466,28 +652,39 @@
 
     return update_stack_component_command
 
 
 def generate_stack_component_remove_attribute_command(
     component_type: StackComponentType,
 ) -> Callable[[str, List[str]], None]:
-    """Generates an `remove_attribute` command for the specific stack
-    component type."""
+    """Generates `remove_attribute` command for a specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
     display_name = _component_display_name(component_type)
 
     @click.argument(
         "name",
         type=str,
         required=True,
     )
     @click.argument("args", nargs=-1, type=click.UNPROCESSED)
     def remove_attribute_stack_component_command(
         name: str, args: List[str]
     ) -> None:
-        """Removes one or more attributes from a stack component."""
+        """Removes one or more attributes from a stack component.
+
+        Args:
+            name: The name of the stack component to remove the attribute from.
+            args: Additional arguments to pass to the remove_attribute command.
+        """
         cli_utils.print_active_profile()
         with console.status(f"Updating {display_name} '{name}'...\n"):
             repo = Repository()
             current_component = repo.get_stack_component(component_type, name)
             if current_component is None:
                 cli_utils.error(f"No {display_name} found for name '{name}'.")
 
@@ -533,29 +730,41 @@
 
     return remove_attribute_stack_component_command
 
 
 def generate_stack_component_rename_command(
     component_type: StackComponentType,
 ) -> Callable[[str, str], None]:
-    """Generates a `rename` command for the specific stack component type."""
+    """Generates a `rename` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
     display_name = _component_display_name(component_type)
 
     @click.argument(
         "name",
         type=str,
         required=True,
     )
     @click.argument(
         "new_name",
         type=str,
         required=True,
     )
     def rename_stack_component_command(name: str, new_name: str) -> None:
-        """Rename a stack component."""
+        """Rename a stack component.
+
+        Args:
+            name: The name of the stack component to rename.
+            new_name: The new name of the stack component.
+        """
         cli_utils.print_active_profile()
         with console.status(f"Renaming {display_name} '{name}'...\n"):
             repo = Repository()
             current_component = repo.get_stack_component(component_type, name)
             if current_component is None:
                 cli_utils.error(f"No {display_name} found for name '{name}'.")
 
@@ -586,20 +795,31 @@
 
     return rename_stack_component_command
 
 
 def generate_stack_component_delete_command(
     component_type: StackComponentType,
 ) -> Callable[[str], None]:
-    """Generates a `delete` command for the specific stack component type."""
+    """Generates a `delete` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
     display_name = _component_display_name(component_type)
 
     @click.argument("name", type=str)
     def delete_stack_component_command(name: str) -> None:
-        """Deletes a stack component."""
+        """Deletes a stack component.
+
+        Args:
+            name: The name of the stack component to delete.
+        """
         cli_utils.print_active_profile()
 
         with console.status(f"Deleting {display_name} '{name}'...\n"):
             Repository().deregister_stack_component(
                 component_type=component_type,
                 name=name,
             )
@@ -607,19 +827,30 @@
 
     return delete_stack_component_command
 
 
 def generate_stack_component_up_command(
     component_type: StackComponentType,
 ) -> Callable[[Optional[str]], None]:
-    """Generates a `up` command for the specific stack component type."""
+    """Generates a `up` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     @click.argument("name", type=str, required=False)
     def up_stack_component_command(name: Optional[str] = None) -> None:
-        """Deploys a stack component locally."""
+        """Deploys a stack component locally.
+
+        Args:
+            name: The name of the stack component to deploy.
+        """
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         component_wrapper, _ = _get_stack_component_wrapper(
             component_type, component_name=name
         )
         if component_wrapper is None:
@@ -657,15 +888,22 @@
 
     return up_stack_component_command
 
 
 def generate_stack_component_down_command(
     component_type: StackComponentType,
 ) -> Callable[[Optional[str], bool], None]:
-    """Generates a `down` command for the specific stack component type."""
+    """Generates a `down` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     @click.argument("name", type=str, required=False)
     @click.option(
         "--yes",
         "-y",
         "force",
         is_flag=True,
@@ -676,17 +914,26 @@
         "-f",
         "old_force",
         is_flag=True,
         help="DEPRECATED: Deprovisions local resources instead of suspending "
         "them. Use `-y/--yes` instead.",
     )
     def down_stack_component_command(
-        name: Optional[str] = None, force: bool = False, old_force: bool = False
+        name: Optional[str] = None,
+        force: bool = False,
+        old_force: bool = False,
     ) -> None:
-        """Stops/Tears down the local deployment of a stack component."""
+        """Stops/Tears down the local deployment of a stack component.
+
+        Args:
+            name: The name of the stack component to stop/deprovision.
+            force: Deprovision local resources instead of suspending them.
+            old_force: DEPRECATED: Deprovision local resources instead of
+                suspending them. Use `-y/--yes` instead.
+        """
         if old_force:
             force = old_force
             cli_utils.warning(
                 "The `--force` flag will soon be deprecated. Use `--yes` "
                 "or `-y` instead."
             )
         cli_utils.print_active_profile()
@@ -736,27 +983,40 @@
 
     return down_stack_component_command
 
 
 def generate_stack_component_logs_command(
     component_type: StackComponentType,
 ) -> Callable[[Optional[str], bool], None]:
-    """Generates a `logs` command for the specific stack component type."""
+    """Generates a `logs` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     @click.argument("name", type=str, required=False)
     @click.option(
         "--follow",
         "-f",
         is_flag=True,
         help="Follow the log file instead of just displaying the current logs.",
     )
     def stack_component_logs_command(
         name: Optional[str] = None, follow: bool = False
     ) -> None:
-        """Displays stack component logs."""
+        """Displays stack component logs.
+
+        Args:
+            name: The name of the stack component to display logs for.
+            follow: Follow the log file instead of just displaying the current
+                logs.
+        """
         cli_utils.print_active_profile()
         cli_utils.print_active_stack()
 
         component_wrapper, _ = _get_stack_component_wrapper(
             component_type, component_name=name
         )
         if component_wrapper is None:
@@ -794,19 +1054,25 @@
 
     return stack_component_logs_command
 
 
 def generate_stack_component_explain_command(
     component_type: StackComponentType,
 ) -> Callable[[], None]:
-    """Generates an `explain` command for the specific stack component type."""
+    """Generates an `explain` command for the specific stack component type.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+
+    Returns:
+        A function that can be used as a `click` command.
+    """
 
     def explain_stack_components_command() -> None:
         """Explains the concept of the stack component."""
-
         component_module = import_module(f"zenml.{component_type.plural}")
 
         if component_module.__doc__ is not None:
             md = Markdown(component_module.__doc__)
             console.print(md)
         else:
             console.print(
@@ -818,15 +1084,20 @@
 
     return explain_stack_components_command
 
 
 def register_single_stack_component_cli_commands(
     component_type: StackComponentType, parent_group: click.Group
 ) -> None:
-    """Registers all basic stack component CLI commands."""
+    """Registers all basic stack component CLI commands.
+
+    Args:
+        component_type: Type of the component to generate the command for.
+        parent_group: The parent group to register the commands to.
+    """
     command_name = component_type.value.replace("_", "-")
     singular_display_name = _component_display_name(component_type)
     plural_display_name = _component_display_name(component_type, plural=True)
 
     @parent_group.group(
         command_name,
         cls=TagGroup,
@@ -865,16 +1136,15 @@
     )(register_command)
 
     # zenml stack-component flavor
     @command_group.group(
         "flavor", help=f"Commands to interact with {plural_display_name}."
     )
     def flavor_group() -> None:
-        """Group commands for handling the flavors of single stack component
-        type."""
+        """Group commands to handle flavors for a stack component type."""
 
     # zenml stack-component flavor register
     register_flavor_command = generate_stack_component_flavor_register_command(
         component_type=component_type
     )
     flavor_group.command(
         "register",
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/text_utils.py` & `zenml-0.9.0/src/zenml/cli/text_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utilities for CLI output."""
+
 from typing import List
 
 from rich.markdown import Markdown
 
 zenml_go_welcome_message = Markdown(
     """
 # ⛩  Welcome to ZenML!
@@ -54,15 +56,22 @@
     """
 🙏  Thank you!
 """
 )
 
 
 def zenml_go_notebook_tutorial_message(ipynb_files: List[str]) -> Markdown:
+    """Outputs a message to the user about the `zenml go` tutorial.
+
+    Args:
+        ipynb_files: A list of IPython Notebook files.
 
+    Returns:
+        A Markdown object.
+    """
     ipynb_files = [f"- {fi} \n" for fi in ipynb_files]
     return Markdown(
         f"""
 ## 🧑‍🏫 Get started with ZenML
 
 The ZenML tutorial repository was cloned to your current working directory.
 Within the repository you can get started on one of these notebooks:
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/user_management.py` & `zenml-0.9.0/src/zenml/cli/user_management.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to administer users of the ZenML CLI and server."""
 
 from typing import Optional, Tuple
 
 import click
 
 from zenml.cli import utils as cli_utils
 from zenml.cli.cli import TagGroup, cli
@@ -34,15 +35,19 @@
     cli_utils.print_active_profile()
     cli_utils.declare(f"Active user: '{Repository().active_user_name}'")
 
 
 @user.command("set")
 @click.argument("user_name", type=str)
 def set_user(user_name: str) -> None:
-    """Set the active user."""
+    """Set the active user.
+
+    Args:
+        user_name: The name of the user to set as active.
+    """
     cli_utils.print_active_profile()
     repo = Repository()
     try:
         repo.zen_store.get_user(user_name)
     except KeyError:
         cli_utils.error(f"No user with name {user_name}.")
 
@@ -65,23 +70,31 @@
 
 
 @user.command("create")
 @click.argument("user_name", type=str, required=True)
 # @click.option("--email", type=str, required=True)
 # @click.password_option("--password", type=str, required=True)
 def create_user(user_name: str) -> None:
-    """Create a new user."""
+    """Create a new user.
+
+    Args:
+        user_name: The name of the user to create.
+    """
     cli_utils.print_active_profile()
     Repository().zen_store.create_user(user_name=user_name)
 
 
 @user.command("delete")
 @click.argument("user_name", type=str, required=True)
 def delete_user(user_name: str) -> None:
-    """Delete a user."""
+    """Delete a user.
+
+    Args:
+        user_name: The name of the user to delete.
+    """
     cli_utils.print_active_profile()
     try:
         Repository().zen_store.delete_user(user_name=user_name)
     except KeyError:
         cli_utils.warning(f"No user found for name '{user_name}'.")
 
 
@@ -101,50 +114,67 @@
 
     cli_utils.print_pydantic_models(teams)
 
 
 @team.command("describe")
 @click.argument("team_name", type=str, required=True)
 def describe_team(team_name: str) -> None:
-    """Print details of a team."""
+    """Print details of a team.
+
+    Args:
+        team_name: The name of the team to describe.
+    """
     cli_utils.print_active_profile()
     try:
         users = Repository().zen_store.get_users_for_team(team_name=team_name)
     except KeyError:
         cli_utils.warning(f"No team found for name '{team_name}'.")
     else:
         cli_utils.declare(
             f"TEAM: {team_name}, USERS: {set(user_.name for user_ in users)}"
         )
 
 
 @team.command("create")
 @click.argument("team_name", type=str, required=True)
 def create_team(team_name: str) -> None:
-    """Create a new team."""
+    """Create a new team.
+
+    Args:
+        team_name: Name of the team to create.
+    """
     cli_utils.print_active_profile()
     Repository().zen_store.create_team(team_name=team_name)
 
 
 @team.command("delete")
 @click.argument("team_name", type=str, required=True)
 def delete_team(team_name: str) -> None:
-    """Delete a team."""
+    """Delete a team.
+
+    Args:
+        team_name (str): The name of the team to delete.
+    """
     cli_utils.print_active_profile()
     try:
         Repository().zen_store.delete_team(team_name=team_name)
     except KeyError:
         cli_utils.warning(f"No team found for name '{team_name}'.")
 
 
 @team.command("add")
 @click.argument("team_name", type=str, required=True)
 @click.option("--user", "user_names", type=str, required=True, multiple=True)
 def add_users(team_name: str, user_names: Tuple[str]) -> None:
-    """Add users to a team."""
+    """Add users to a team.
+
+    Args:
+        team_name: Name of the team.
+        user_names: Names of the users to add to the team.
+    """
     cli_utils.print_active_profile()
     for user_name in user_names:
         cli_utils.declare(f"Adding user '{user_name}' to team '{team_name}'.")
         try:
             Repository().zen_store.add_user_to_team(
                 team_name=team_name, user_name=user_name
             )
@@ -154,15 +184,20 @@
             )
 
 
 @team.command("remove")
 @click.argument("team_name", type=str, required=True)
 @click.option("--user", "user_names", type=str, required=True, multiple=True)
 def remove_users(team_name: str, user_names: Tuple[str]) -> None:
-    """Remove users from a team."""
+    """Remove users from a team.
+
+    Args:
+        team_name: Name of the team.
+        user_names: Names of the users.
+    """
     cli_utils.print_active_profile()
     for user_name in user_names:
         cli_utils.declare(
             f"Removing user '{user_name}' from team '{team_name}'."
         )
         try:
             Repository().zen_store.remove_user_from_team(
@@ -201,15 +236,20 @@
 
 @project.command("create")
 @click.argument("project_name", type=str, required=True)
 @click.option("--description", "-d", type=str, required=False)
 def create_project(
     project_name: str, description: Optional[str] = None
 ) -> None:
-    """Create a new project."""
+    """Create a new project.
+
+    Args:
+        project_name: The name of the project.
+        description: A description of the project.
+    """
     cli_utils.print_active_profile()
     try:
         Repository().zen_store.create_project(
             project_name=project_name, description=description
         )
     except EntityExistsError:
         cli_utils.error(
@@ -243,15 +283,19 @@
             "repository with an existing project."
         )
 
 
 @project.command("set")
 @click.argument("project_name", type=str, required=True)
 def set_project(project_name: str) -> None:
-    """Set the project for the current repository."""
+    """Set the project for the current repository.
+
+    Args:
+        project_name: The name of the project to set as active.
+    """
     cli_utils.print_active_profile()
     if Repository.find_repository() is None:
         cli_utils.error(
             "Must be in a local ZenML repository to set an active project. "
             "Make sure you are in the right directory, or first run "
             "`zenml init` to initialize a ZenML repository."
         )
@@ -265,15 +309,15 @@
             "project found in the store. If you want to create it, run:"
             f"`zenml project create {project_name}`."
         )
 
 
 @project.command("unset")
 def unset_project() -> None:
-    """Unset the active project from current repository"""
+    """Unset the active project from current repository."""
     cli_utils.print_active_profile()
     if not Repository.find_repository():
         cli_utils.error(
             "Must be in a local ZenML repository to unset an active project. "
             "Make sure you are in the right directory, or first run "
             "`zenml init` to initialize a ZenML repository."
         )
@@ -284,15 +328,21 @@
 @project.command("delete")
 @click.argument(
     "project_name",
     type=str,
     required=True,
 )
 def delete_project(project_name: str) -> None:
-    """Delete a project. If name isn't specified, delete current project."""
+    """Delete a project.
+
+    If name isn't specified, delete current project.
+
+    Args:
+        project_name (str): Name of project to delete.
+    """
     cli_utils.print_active_profile()
     active_project = Repository().active_project
 
     cli_utils.confirmation(
         f"Are you sure you want to delete project `{project_name}`?"
     )
 
@@ -319,23 +369,31 @@
 
     cli_utils.print_pydantic_models(roles)
 
 
 @role.command("create")
 @click.argument("role_name", type=str, required=True)
 def create_role(role_name: str) -> None:
-    """Create a new role."""
+    """Create a new role.
+
+    Args:
+        role_name: Name of the role to create.
+    """
     cli_utils.print_active_profile()
     Repository().zen_store.create_role(role_name=role_name)
 
 
 @role.command("delete")
 @click.argument("role_name", type=str, required=True)
 def delete_role(role_name: str) -> None:
-    """Delete a role."""
+    """Delete a role.
+
+    Args:
+        role_name (str): Name of the role to delete.
+    """
     cli_utils.print_active_profile()
     try:
         Repository().zen_store.delete_role(role_name=role_name)
     except KeyError:
         cli_utils.warning(f"No role found for name '{role_name}'.")
 
 
@@ -346,15 +404,22 @@
 @click.option("--project", "project_name", type=str, required=False)
 def assign_role(
     role_name: str,
     user_names: Tuple[str],
     team_names: Tuple[str],
     project_name: Optional[str] = None,
 ) -> None:
-    """Assign a role."""
+    """Assign a role.
+
+    Args:
+        role_name (str): Name of the role to assign.
+        user_names (Tuple[str]): Names of users to assign the role to.
+        team_names (Tuple[str]): Names of teams to assign the role to.
+        project_name (Optional[str]): Name of the project to assign the role to.
+    """
     cli_utils.print_active_profile()
     for user_name in user_names:
         cli_utils.declare(
             f"Assigning role '{role_name}' to user '{user_name}'."
         )
         try:
             Repository().zen_store.assign_role(
@@ -394,15 +459,22 @@
 @click.option("--project", "project_name", type=str, required=False)
 def revoke_role(
     role_name: str,
     user_names: Tuple[str],
     team_names: Tuple[str],
     project_name: Optional[str] = None,
 ) -> None:
-    """Revoke a role."""
+    """Revoke a role.
+
+    Args:
+        role_name: Name of the role to revoke.
+        user_names: Names of the users to revoke the role from.
+        team_names: Names of the teams to revoke the role from.
+        project_name: Name of the project to revoke the role from.
+    """
     cli_utils.print_active_profile()
     for user_name in user_names:
         cli_utils.declare(
             f"Revoking role '{role_name}' from user '{user_name}'."
         )
         try:
             Repository().zen_store.revoke_role(
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/utils.py` & `zenml-0.9.0/src/zenml/cli/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions for the CLI."""
+
 import base64
 import datetime
 import os
 import subprocess
 import sys
 from typing import (
     TYPE_CHECKING,
@@ -22,14 +24,15 @@
     Callable,
     Dict,
     List,
     NoReturn,
     Optional,
     Sequence,
     Tuple,
+    Type,
     TypeVar,
     Union,
 )
 
 import click
 import yaml
 from dateutil import tz
@@ -45,37 +48,37 @@
 from zenml.logger import get_logger
 
 logger = get_logger(__name__)
 
 if TYPE_CHECKING:
     from zenml.config.profile_config import ProfileConfiguration
     from zenml.enums import StackComponentType
-    from zenml.integrations.integration import IntegrationMeta
+    from zenml.integrations.integration import Integration
     from zenml.model_deployers import BaseModelDeployer
     from zenml.secret import BaseSecretSchema
     from zenml.services import BaseService
     from zenml.zen_stores.models import ComponentWrapper, FlavorWrapper
 
 
 def title(text: str) -> None:
     """Echo a title formatted string on the CLI.
 
     Args:
-      text: Input text string.
+        text: Input text string.
     """
     console.print(text.upper(), style=zenml_style_defaults["title"])
 
 
 def confirmation(text: str, *args: Any, **kwargs: Any) -> bool:
     """Echo a confirmation string on the CLI.
 
     Args:
-      text: Input text string.
-      *args: Args to be passed to click.confirm().
-      **kwargs: Kwargs to be passed to click.confirm().
+        text: Input text string.
+        *args: Args to be passed to click.confirm().
+        **kwargs: Kwargs to be passed to click.confirm().
 
     Returns:
         Boolean based on user response.
     """
     return Confirm.ask(text, console=console)
 
 
@@ -96,18 +99,18 @@
     console.print(text, style=style)
 
 
 def error(text: str) -> NoReturn:
     """Echo an error string on the CLI.
 
     Args:
-      text: Input text string.
+        text: Input text string.
 
     Raises:
-        click.ClickException: when called.
+        ClickException: when called.
     """
     raise click.ClickException(message=click.style(text, fg="red", bold=True))
 
 
 def warning(
     text: str,
     bold: Optional[bool] = None,
@@ -125,30 +128,32 @@
     console.print(text, style=style)
 
 
 def pretty_print(obj: Any) -> None:
     """Pretty print an object on the CLI using `rich.print`.
 
     Args:
-      obj: Any object with a __str__ method defined.
+        obj: Any object with a __str__ method defined.
+
     # TODO: [LOW] check whether this needs to be converted to a string first
     # TODO: [LOW] use rich prettyprint for this instead
     """
     console.print(obj)
 
 
 def print_table(obj: List[Dict[str, Any]], **columns: table.Column) -> None:
-    """Prints the list of dicts in a table format. The input object should be a
-    List of Dicts. Each item in that list represent a line in the Table. Each
-    dict should have the same keys. The keys of the dict will be used as
-    headers of the resulting table.
+    """Prints the list of dicts in a table format.
+
+    The input object should be a List of Dicts. Each item in that list represent
+    a line in the Table. Each dict should have the same keys. The keys of the
+    dict will be used as headers of the resulting table.
 
     Args:
-      obj: A List containing dictionaries.
-      columns: Optional column configurations to be used in the table.
+        obj: A List containing dictionaries.
+        columns: Optional column configurations to be used in the table.
     """
     column_keys = {key: None for dict_ in obj for key in dict_}
     column_names = [columns.get(key, key.upper()) for key in column_keys]
     rich_table = table.Table(box=box.HEAVY_EDGE, show_lines=True)
     for col_name in column_names:
         if isinstance(col_name, str):
             rich_table.add_column(str(col_name), overflow="fold")
@@ -179,25 +184,32 @@
     columns: Optional[Sequence[str]] = None,
     exclude_columns: Sequence[str] = (),
     is_active: Optional[Callable[[M], bool]] = None,
 ) -> None:
     """Prints the list of Pydantic models in a table.
 
     Args:
-        models: List of pydantic models that will be represented as a row in
+        models: List of Pydantic models that will be represented as a row in
             the table.
         columns: Optionally specify subset and order of columns to display.
         exclude_columns: Optionally specify columns to exclude. (Note: `columns`
             takes precedence over `exclude_columns`.)
         is_active: Optional function that marks as row as active.
 
     """
 
     def __dictify(model: M) -> Dict[str, str]:
-        """Helper function to map over the list to turn Models into dicts."""
+        """Helper function to map over the list to turn Models into dicts.
+
+        Args:
+            model: Pydantic model.
+
+        Returns:
+            Dict of model attributes.
+        """
         items = (
             {
                 key: str(value)
                 for key, value in model.dict().items()
                 if key not in exclude_columns
             }
             if columns is None
@@ -210,26 +222,36 @@
             else items
         )
 
     print_table([__dictify(model) for model in models])
 
 
 def format_integration_list(
-    integrations: List[Tuple[str, "IntegrationMeta"]]
+    integrations: List[Tuple[str, Type["Integration"]]]
 ) -> List[Dict[str, str]]:
-    """Formats a list of integrations into a List of Dicts. This list of dicts
-    can then be printed in a table style using cli_utils.print_table."""
+    """Formats a list of integrations into a List of Dicts.
+
+    This list of dicts can then be printed in a table style using
+    cli_utils.print_table.
+
+    Args:
+        integrations: List of tuples containing the name of the integration and
+            the integration metadata.
+
+    Returns:
+        List of Dicts containing the name of the integration and the integration
+    """
     list_of_dicts = []
     for name, integration_impl in integrations:
-        is_installed = integration_impl.check_installation()  # type: ignore[attr-defined]
+        is_installed = integration_impl.check_installation()
         list_of_dicts.append(
             {
                 "INSTALLED": ":white_check_mark:" if is_installed else ":x:",
                 "INTEGRATION": name,
-                "REQUIRED_PACKAGES": ", ".join(integration_impl.REQUIREMENTS),  # type: ignore[attr-defined]
+                "REQUIRED_PACKAGES": ", ".join(integration_impl.REQUIREMENTS),
             }
         )
     return list_of_dicts
 
 
 def print_stack_component_list(
     components: List["ComponentWrapper"],
@@ -263,15 +285,21 @@
         configurations.append(component_config)
     print_table(configurations)
 
 
 def print_stack_configuration(
     config: Dict["StackComponentType", str], active: bool, stack_name: str
 ) -> None:
-    """Prints the configuration options of a stack."""
+    """Prints the configuration options of a stack.
+
+    Args:
+        config: Configuration options of the stack.
+        active: Whether the stack is active.
+        stack_name: Name of the stack.
+    """
     stack_caption = f"'{stack_name}' stack"
     if active:
         stack_caption += " (ACTIVE)"
     rich_table = table.Table(
         box=box.HEAVY_EDGE,
         title="Stack Configuration",
         caption=stack_caption,
@@ -290,15 +318,20 @@
     console.print(rich_table)
 
 
 def print_flavor_list(
     flavors: List["FlavorWrapper"],
     component_type: "StackComponentType",
 ) -> None:
-    """Prints the list of flavors."""
+    """Prints the list of flavors.
+
+    Args:
+        flavors: List of flavors to print.
+        component_type: Type of component the flavors belong to.
+    """
     from zenml.integrations.registry import integration_registry
     from zenml.utils.source_utils import validate_flavor_source
 
     flavor_table = []
     for f in flavors:
         reachable = False
 
@@ -341,15 +374,21 @@
         "path (also shown in the list)."
     )
 
 
 def print_stack_component_configuration(
     component: "ComponentWrapper", display_name: str, active_status: bool
 ) -> None:
-    """Prints the configuration options of a stack component."""
+    """Prints the configuration options of a stack component.
+
+    Args:
+        component: The stack component to print.
+        display_name: The name of the stack component.
+        active_status: Whether the stack component is active.
+    """
     title = f"{component.type.value.upper()} Component Configuration"
     if active_status:
         title += " (ACTIVE)"
     rich_table = table.Table(
         box=box.HEAVY_EDGE,
         title=title,
         show_lines=True,
@@ -430,16 +469,16 @@
 
 def format_date(
     dt: datetime.datetime, format: str = "%Y-%m-%d %H:%M:%S"
 ) -> str:
     """Format a date into a string.
 
     Args:
-      dt: Datetime object to be formatted.
-      format: The format in string you want the datetime formatted to.
+        dt: Datetime object to be formatted.
+        format: The format in string you want the datetime formatted to.
 
     Returns:
         Formatted string according to specification.
     """
     if dt is None:
         return ""
     # make sure this is UTC
@@ -455,16 +494,15 @@
     return dt.strftime(format)
 
 
 MAX_ARGUMENT_VALUE_SIZE = 10240
 
 
 def _expand_argument_value_from_file(name: str, value: str) -> str:
-    """Expands the value of an argument pointing to a file into the contents of
-    that file.
+    """Expands the value of an argument pointing to a file into the contents of that file.
 
     Args:
         name: Name of the argument. Used solely for logging purposes.
         value: The value of the argument. This is to be interpreted as a
             filename if it begins with a `@` character.
 
     Returns:
@@ -523,36 +561,33 @@
     warning_message = (
         "Please provide args with a proper "
         "identifier as the key and the following structure: "
         '--custom_argument="value"'
     )
 
     assert all(a.startswith("--") for a in args), warning_message
-    assert all(len(a.split("=")) == 2 for a in args), warning_message
-
-    p_args = [a.lstrip("--").split("=") for a in args]
+    assert all("=" in a for a in args), warning_message
 
-    assert all(k.isidentifier() for k, _ in p_args), warning_message
-
-    r_args = {k: _expand_argument_value_from_file(k, v) for k, v in p_args}
-    assert len(p_args) == len(r_args), "Replicated arguments!"
+    args_dict = dict(a[2:].split("=", maxsplit=1) for a in args)
+    assert all(k.isidentifier() for k in args_dict), warning_message
 
     if expand_args:
-        r_args = {
-            k: _expand_argument_value_from_file(k, v) for k, v in r_args.items()
+        args_dict = {
+            k: _expand_argument_value_from_file(k, v)
+            for k, v in args_dict.items()
         }
 
-    return r_args
+    return args_dict
 
 
 def parse_unknown_component_attributes(args: List[str]) -> List[str]:
     """Parse unknown options from the CLI.
 
     Args:
-      args: A list of strings from the CLI.
+        args: A list of strings from the CLI.
 
     Returns:
         List of parsed args.
     """
     warning_message = (
         "Please provide args with a proper "
         "identifier as the key and the following structure: "
@@ -562,28 +597,36 @@
     assert all(a.startswith("--") for a in args), warning_message
     p_args = [a.lstrip("-") for a in args]
     assert all(v.isidentifier() for v in p_args), warning_message
     return p_args
 
 
 def install_packages(packages: List[str]) -> None:
-    """Installs pypi packages into the current environment with pip"""
+    """Installs pypi packages into the current environment with pip.
+
+    Args:
+        packages: List of packages to install.
+    """
     command = [sys.executable, "-m", "pip", "install"] + packages
 
     if not IS_DEBUG_ENV:
         command += [
             "-qqq",
             "--no-warn-conflicts",
         ]
 
     subprocess.check_call(command)
 
 
 def uninstall_package(package: str) -> None:
-    """Uninstalls pypi package from the current environment with pip"""
+    """Uninstalls pypi package from the current environment with pip.
+
+    Args:
+        package: The package to uninstall.
+    """
     subprocess.check_call(
         [
             sys.executable,
             "-m",
             "pip",
             "uninstall",
             "-qqq",
@@ -592,15 +635,15 @@
         ]
     )
 
 
 def pretty_print_secret(
     secret: "BaseSecretSchema", hide_secret: bool = True
 ) -> None:
-    """Given a secret set print all key value pairs associated with the secret
+    """Given a secret set, print all key-value pairs associated with the secret.
 
     Args:
         secret: Secret of type BaseSecretSchema
         hide_secret: boolean that configures if the secret values are shown
             on the CLI
     """
 
@@ -659,16 +702,15 @@
         return ":heavy_exclamation_mark:"
     return ":hourglass_not_done:"
 
 
 def pretty_print_model_deployer(
     model_services: List["BaseService"], model_deployer: "BaseModelDeployer"
 ) -> None:
-    """Given a list of served_models print all key value pairs associated with
-    the secret
+    """Given a list of served_models, print all key-value pairs associated with the secret.
 
     Args:
         model_services: list of model deployment services
         model_deployer: Active model deployer
     """
     model_service_dicts = []
     for model_service in model_services:
```

### Comparing `zenml-0.8.1rc0/src/zenml/cli/version.py` & `zenml-0.9.0/src/zenml/cli/version.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""CLI command to show installed ZenML version."""
 
 import random
 
 import click
 
 from zenml import __version__
 from zenml.cli.cli import cli
```

### Comparing `zenml-0.8.1rc0/src/zenml/config/__init__.py` & `zenml-0.9.0/src/zenml/config/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,17 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The ``config`` module contains classes and functions that manage user-specific
-configuration. ZenML's configuration is stored in a file called
+"""The `config` module contains classes and functions that manage user-specific configuration.
+
+ZenML's configuration is stored in a file called
 ``config.yaml``, located on the user's directory for configuration files.
 (The exact location differs from operating system to operating system.)
 
 The ``GlobalConfiguration`` class is the main class in this module. It provides
 a Pydantic configuration object that is used to store and retrieve
 configuration. This ``GlobalConfiguration`` object handles the serialization and
 deserialization of the configuration options that are stored in the file in
```

### Comparing `zenml-0.8.1rc0/src/zenml/config/base_config.py` & `zenml-0.9.0/src/zenml/config/base_config.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base class for global configuration management."""
 
 from abc import ABC, abstractmethod
 from typing import TYPE_CHECKING, Optional
 
 if TYPE_CHECKING:
     from zenml.config.profile_config import ProfileConfiguration
 
@@ -27,15 +28,15 @@
     Both the GlobalConfiguration and Repository classes implement this class,
     since they share similarities concerning the management of active profiles
     and stacks.
     """
 
     @abstractmethod
     def activate_profile(self, profile_name: str) -> None:
-        """Set the active profile
+        """Set the active profile.
 
         Args:
             profile_name: The name of the profile to set as active.
 
         Raises:
             KeyError: If the profile with the given name does not exist.
         """
```

### Comparing `zenml-0.8.1rc0/src/zenml/config/config_keys.py` & `zenml-0.9.0/src/zenml/config/config_keys.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Validates global configuration values."""
 
 from typing import Any, Dict, List, Tuple
 
 
 class ConfigKeys:
     """Class to validate dictionary configurations."""
 
@@ -38,16 +39,15 @@
         required = [v for k, v in keys.items() if not k.endswith("_")]
         optional = [v for k, v in keys.items() if k.endswith("_")]
 
         return required, optional
 
     @classmethod
     def key_check(cls, config: Dict[str, Any]) -> None:
-        """Checks whether a configuration dict contains all required keys
-        and no unknown keys.
+        """Checks whether a configuration dict contains all required keys and no unknown keys.
 
         Args:
             config: The configuration dict to verify.
 
         Raises:
             TypeError: If no config dictionary is passed.
             ValueError: If required keys are missing or unknown keys are found.
```

### Comparing `zenml-0.8.1rc0/src/zenml/config/global_config.py` & `zenml-0.9.0/src/zenml/config/global_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to support ZenML GlobalConfiguration."""
+
 import json
 import logging
 import os
 import uuid
 from typing import Any, Dict, Optional, cast
 
 from packaging import version
@@ -23,17 +25,17 @@
 
 from zenml import __version__
 from zenml.config.base_config import BaseConfiguration
 from zenml.config.profile_config import (
     DEFAULT_PROFILE_NAME,
     ProfileConfiguration,
 )
-from zenml.io import fileio, utils
+from zenml.io import fileio
 from zenml.logger import disable_logging, get_logger
-from zenml.utils import yaml_utils
+from zenml.utils import io_utils, yaml_utils
 from zenml.utils.analytics_utils import AnalyticsEvent, track_event
 
 logger = get_logger(__name__)
 
 
 LEGACY_CONFIG_FILE_NAME = ".zenglobal.json"
 CONFIG_ENV_VAR_PREFIX = "ZENML_"
@@ -50,25 +52,37 @@
     * an empty default profile is added to the global config on initialization
     if no other profiles are configured yet.
     * the GlobalConfiguration undergoes a schema migration if the version of the
     config file is older than the current version of the ZenML package.
     """
 
     def __init__(cls, *args: Any, **kwargs: Any) -> None:
-        """Initialize a singleton class."""
+        """Initialize a singleton class.
+
+        Args:
+            *args: positional arguments
+            **kwargs: keyword arguments
+        """
         super().__init__(*args, **kwargs)
         cls._global_config: Optional["GlobalConfiguration"] = None
 
     def __call__(cls, *args: Any, **kwargs: Any) -> "GlobalConfiguration":
         """Create or return the default global config instance.
 
         If the GlobalConfiguration constructor is called with custom arguments,
         the singleton functionality of the metaclass is bypassed: a new
         GlobalConfiguration instance is created and returned immediately and
         without saving it as the global GlobalConfiguration singleton.
+
+        Args:
+            *args: positional arguments
+            **kwargs: keyword arguments
+
+        Returns:
+            The global GlobalConfiguration instance.
         """
         if args or kwargs:
             return cast(
                 "GlobalConfiguration", super().__call__(*args, **kwargs)
             )
 
         if not cls._global_config:
@@ -107,16 +121,15 @@
     activated_profile: Optional[str]
     profiles: Dict[str, ProfileConfiguration] = Field(default_factory=dict)
     _config_path: str
 
     def __init__(
         self, config_path: Optional[str] = None, **kwargs: Any
     ) -> None:
-        """Initializes a GlobalConfiguration object using values from the config
-        file.
+        """Initializes a GlobalConfiguration object using values from the config file.
 
         GlobalConfiguration is a singleton class: only one instance can exist.
         Calling this constructor multiple times will always yield the same
         instance (see the exception below).
 
         The `config_path` argument is only meant for internal use and testing
         purposes. User code must never pass it to the constructor. When a custom
@@ -130,14 +143,15 @@
 
         Args:
             config_path: (internal use) custom config file path. When not
                 specified, the default global configuration path is used and the
                 global configuration singleton instance is returned. Only used
                 to create configuration copies for transfer to different
                 runtime environments.
+            **kwargs: keyword arguments
         """
         self._config_path = config_path or self.default_config_directory()
         config_values = self._read_config()
         config_values.update(**kwargs)
         super().__init__(**config_values)
 
         if not fileio.exists(self._config_file(config_path)):
@@ -166,63 +180,82 @@
                 singleton. If None, the global GlobalConfiguration singleton is
                 reset to an empty value.
         """
         cls._global_config = config
 
     @validator("version")
     def _validate_version(cls, v: Optional[str]) -> Optional[str]:
-        """Validate the version attribute."""
+        """Validate the version attribute.
+
+        Args:
+            v: The version attribute value.
+
+        Returns:
+            The version attribute value.
+
+        Raises:
+            RuntimeError: If the version parsing fails.
+        """
         if v is None:
             return v
 
         if not isinstance(version.parse(v), version.Version):
             # If the version parsing fails, it returns a `LegacyVersion` instead.
             # Check to make sure it's an actual `Version` object which represents
             # a valid version.
             raise RuntimeError(f"Invalid version in global configuration: {v}.")
 
         return v
 
     def __setattr__(self, key: str, value: Any) -> None:
-        """Sets an attribute on the config and persists the new value in the
-        global configuration."""
+        """Sets an attribute on the config and persists the new value in the global configuration.
+
+        Args:
+            key: The attribute name.
+            value: The attribute value.
+        """
         super().__setattr__(key, value)
         if key.startswith("_"):
             return
         self._write_config()
 
     def __getattribute__(self, key: str) -> Any:
         """Gets an attribute value for a specific key.
 
         If a value for this attribute was specified using an environment
         variable called `$(CONFIG_ENV_VAR_PREFIX)$(ATTRIBUTE_NAME)` and its
         value can be parsed to the attribute type, the value from this
         environment variable is returned instead.
+
+        Args:
+            key: The attribute name.
+
+        Returns:
+            The attribute value.
         """
         value = super().__getattribute__(key)
         if key.startswith("_"):
             return value
 
         environment_variable_name = f"{CONFIG_ENV_VAR_PREFIX}{key.upper()}"
         try:
             environment_variable_value = os.environ[environment_variable_name]
-            # set the environment variable value to leverage pydantics type
+            # set the environment variable value to leverage Pydantic's type
             # conversion and validation
             super().__setattr__(key, environment_variable_value)
             return_value = super().__getattribute__(key)
             # set back the old value as we don't want to permanently store
             # the environment variable value here
             super().__setattr__(key, value)
             return return_value
         except (ValidationError, KeyError, TypeError):
             return value
 
     def _migrate_config(self) -> None:
         """Migrates the global config to the latest version."""
-
         curr_version = version.parse(__version__)
         if self.version is None:
             logger.info(
                 "Initializing the ZenML global configuration version to %s",
                 curr_version,
             )
         else:
@@ -260,14 +293,17 @@
         self.version = __version__
 
     def _read_config(self) -> Dict[str, Any]:
         """Reads configuration options from disk.
 
         If the config file doesn't exist yet, this method falls back to reading
         options from a legacy config file or returns an empty dictionary.
+
+        Returns:
+            A dictionary containing the configuration options.
         """
         legacy_config_file = os.path.join(
             self.config_directory, LEGACY_CONFIG_FILE_NAME
         )
 
         config_values = {}
         if fileio.exists(self._config_file()):
@@ -290,41 +326,47 @@
                 global configuration path is used.
         """
         config_file = self._config_file(config_path)
         yaml_dict = json.loads(self.json())
         logger.debug(f"Writing config to {config_file}")
 
         if not fileio.exists(config_file):
-            utils.create_dir_recursive_if_not_exists(
+            io_utils.create_dir_recursive_if_not_exists(
                 config_path or self.config_directory
             )
 
         yaml_utils.write_yaml(config_file, yaml_dict)
 
     @staticmethod
     def default_config_directory() -> str:
-        """Path to the default global configuration directory."""
-        return utils.get_global_config_directory()
+        """Path to the default global configuration directory.
+
+        Returns:
+            The default global configuration directory.
+        """
+        return io_utils.get_global_config_directory()
 
     def _config_file(self, config_path: Optional[str] = None) -> str:
         """Path to the file where global configuration options are stored.
 
         Args:
-            config_path: custom config file path. When not specified, the default
-                global configuration path is used.
+            config_path: custom config file path. When not specified, the
+                default global configuration path is used.
+
+        Returns:
+            The path to the global configuration file.
         """
         return os.path.join(config_path or self._config_path, "config.yaml")
 
     def copy_active_configuration(
         self,
         config_path: str,
         load_config_path: Optional[str] = None,
     ) -> "GlobalConfiguration":
-        """Create a copy of the global config, the active repository profile
-        and the active stack using a different configuration path.
+        """Create a copy of the global config, the active repository profile and the active stack using a different configuration path.
 
         This method is used to extract the active slice of the current state
         (consisting only of the global configuration, the active profile and the
         active stack) and store it in a different configuration path, where it
         can be loaded in the context of a new environment, such as a container
         image.
 
@@ -332,14 +374,18 @@
             config_path: path where the active configuration copy should be saved
             load_config_path: path that will be used to load the configuration
                 copy. This can be set to a value different from `config_path`
                 if the configuration copy will be loaded from a different
                 path, e.g. when the global config copy is copied to a
                 container image. This will be reflected in the paths and URLs
                 encoded in the profile copy.
+
+        Returns:
+            A new global configuration object with the active configuration
+            copied to the specified path.
         """
         from zenml.repository import Repository
 
         self._write_config(config_path)
 
         config_copy = GlobalConfiguration(config_path=config_path)
         config_copy.profiles = {}
@@ -351,42 +397,60 @@
         )
 
         profile._config = config_copy
         # circumvent the profile initialization done in the
         # ProfileConfiguration and the Repository classes to avoid triggering
         # the analytics and interact directly with the store creation
         config_copy.profiles[profile.name] = profile
-        # We dont need to track analytics here
+        # We don't need to track analytics here
         store = Repository.create_store(
             profile,
             skip_default_registrations=True,
             track_analytics=False,
             skip_migration=True,
         )
-        # transfer the active stack to the new store. we disable logs for this
-        # call so there is no confusion about newly registered stacks/stack
-        # components
+        # transfer the active stack and all necessary flavors to the new store.
+        # we disable logs for this call so there is no confusion about newly registered
+        # stacks/components/flavors
         with disable_logging(logging.INFO):
-            store.register_stack(
-                repo.zen_store.get_stack(repo.active_stack_name)
-            )
+            active_stack = repo.zen_store.get_stack(repo.active_stack_name)
+            store.register_stack(active_stack)
+
+            for component in active_stack.components:
+                try:
+                    flavor = repo.zen_store.get_flavor_by_name_and_type(
+                        flavor_name=component.flavor,
+                        component_type=component.type,
+                    )
+                    store.create_flavor(
+                        source=flavor.source,
+                        name=flavor.name,
+                        stack_component_type=flavor.type,
+                    )
+                except KeyError:
+                    # not a custom flavor, no need to register anything
+                    pass
 
         # if a custom load config path is specified, use it to replace the
         # current store local path in the profile URL
         if load_config_path:
             profile.store_url = store.url.replace(
                 str(config_copy.config_directory), load_config_path
             )
 
         config_copy._write_config()
         return config_copy
 
     @property
     def config_directory(self) -> str:
-        """Directory where the global configuration file is located."""
+        """Directory where the global configuration file is located.
+
+        Returns:
+            The directory where the global configuration file is located.
+        """
         return self._config_path
 
     def add_or_update_profile(
         self, profile: ProfileConfiguration
     ) -> ProfileConfiguration:
         """Adds or updates a profile in the global configuration.
 
@@ -443,22 +507,20 @@
             raise KeyError(f"Profile '{profile_name}' not found.")
         self.activated_profile = profile_name
         self._write_config()
 
     def _add_and_activate_default_profile(
         self,
     ) -> Optional[ProfileConfiguration]:
-        """Creates and activates the default configuration profile if no
-        profiles are configured.
+        """Creates and activates the default configuration profile if no profiles are configured.
 
         Returns:
             The newly created default profile or None if other profiles are
             configured.
         """
-
         if self.profiles:
             return None
         logger.info("Creating default profile...")
         default_profile = ProfileConfiguration(
             name=DEFAULT_PROFILE_NAME,
         )
         self.add_or_update_profile(default_profile)
```

### Comparing `zenml-0.8.1rc0/src/zenml/config/profile_config.py` & `zenml-0.9.0/src/zenml/config/profile_config.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to support ZenML Profile configuration."""
 
 import os
 from typing import TYPE_CHECKING, Any, Dict, Optional
 
 import requests
 from pydantic import BaseModel, Field, root_validator
 
@@ -87,22 +88,25 @@
                 BaseModel constructor.
         """
         self._config = config
         super().__init__(**kwargs)
 
     @property
     def config_directory(self) -> str:
-        """Directory where the profile configuration is stored."""
+        """Directory where the profile configuration is stored.
+
+        Returns:
+            The directory where the profile configuration is stored.
+        """
         return os.path.join(
             self.global_config.config_directory, "profiles", self.name
         )
 
     def initialize(self) -> None:
         """Initialize the profile."""
-
         # import here to avoid circular dependency
         from zenml.repository import Repository
 
         logger.info("Initializing profile `%s`...", self.name)
 
         # Create and initialize the profile using a special repository instance.
         # This also validates and updates the store URL configuration and
@@ -121,15 +125,19 @@
     def cleanup(self) -> None:
         """Cleanup the profile directory."""
         if fileio.isdir(self.config_directory):
             fileio.rmtree(self.config_directory)
 
     @property
     def global_config(self) -> "GlobalConfiguration":
-        """Return the global configuration to which this profile belongs."""
+        """Return the global configuration to which this profile belongs.
+
+        Returns:
+            The global configuration to which this profile belongs.
+        """
         from zenml.config.global_config import GlobalConfiguration
 
         return self._config or GlobalConfiguration()
 
     def get_active_stack(self) -> Optional[str]:
         """Get the active stack for the profile.
 
@@ -161,14 +169,20 @@
         cls, attributes: Dict[str, Any]
     ) -> Dict[str, Any]:
         """Ensures that an active user is set for this profile.
 
         If the active user is missing and the profile specifies a local store,
         a default user is used as fallback.
 
+        Args:
+            attributes: attributes of the profile configuration
+
+        Returns:
+            attributes of the profile configuration
+
         Raises:
             RuntimeError: If the active user is missing for a profile with a
                 REST ZenStore.
         """
         store_type = attributes.get("store_type") or get_default_store_type()
 
         if (
```

### Comparing `zenml-0.8.1rc0/src/zenml/console.py` & `zenml-0.9.0/src/zenml/console.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""ZenML console implementation."""
 
 
 from rich.console import Console
 from rich.style import Style
 from rich.theme import Theme
 
 zenml_style_defaults = {
```

### Comparing `zenml-0.8.1rc0/src/zenml/constants.py` & `zenml-0.9.0/src/zenml/constants.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,33 +7,50 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""ZenML constants."""
 
 import os
 from typing import Optional
 
 from zenml import __version__
 
 
 def handle_bool_env_var(var: str, default: bool = False) -> bool:
-    """Converts normal env var to boolean"""
+    """Converts normal env var to boolean.
+
+    Args:
+        var: The environment variable to convert.
+        default: The default value to return if the env var is not set.
+
+    Returns:
+        The converted value.
+    """
     value = os.getenv(var)
     if value in ["1", "y", "yes", "True", "true"]:
         return True
     elif value in ["0", "n", "no", "False", "false"]:
         return False
     return default
 
 
 def handle_int_env_var(var: str, default: int = 0) -> int:
-    """Converts normal env var to int"""
+    """Converts normal env var to int.
+
+    Args:
+        var: The environment variable to convert.
+        default: The default value to return if the env var is not set.
+
+    Returns:
+        The converted value.
+    """
     value = os.getenv(var, "")
     try:
         return int(value)
     except (ValueError, TypeError):
         return default
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/__init__.py` & `zenml-0.9.0/src/zenml/container_registries/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization for ZenML's container registries module.
+
 A container registry is a store for (Docker) containers. A ZenML workflow
 involving a container registry would automatically containerize your code to
 be transported across stacks running remotely. As part of the deployment to
 the cluster, the ZenML base image would be downloaded (from a cloud container
 registry) and used as the basis for the deployed 'run'.
 
 For instance, when you are running a local container-based stack, you would
@@ -48,10 +49,10 @@
 
 __all__ = [
     "BaseContainerRegistry",
     "DefaultContainerRegistry",
     "AzureContainerRegistry",
     "DockerHubContainerRegistry",
     "GCPContainerRegistry",
-    "GitLabContainerRegistry",
     "GitHubContainerRegistry",
+    "GitLabContainerRegistry",
 ]
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/azure_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/azure_container_registry.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of an Azure Container Registry class."""
+
 from typing import ClassVar
 
 from zenml.container_registries.base_container_registry import (
     BaseContainerRegistry,
 )
 from zenml.enums import ContainerRegistryFlavor
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/base_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/base_container_registry.py`

 * *Files 20% similar despite different names*

```diff
@@ -7,53 +7,89 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a base container registry class."""
+
 import re
-from typing import ClassVar
+from typing import ClassVar, Optional, Tuple
 
 from pydantic import validator
 
 from zenml.enums import StackComponentType
+from zenml.secret.schemas import BasicAuthSecretSchema
 from zenml.stack import StackComponent
+from zenml.stack.authentication_mixin import AuthenticationMixin
 from zenml.utils import docker_utils
 
 
-class BaseContainerRegistry(StackComponent):
+class BaseContainerRegistry(StackComponent, AuthenticationMixin):
     """Base class for all ZenML container registries.
 
     Attributes:
         uri: The URI of the container registry.
     """
 
     uri: str
 
     # Class Configuration
     TYPE: ClassVar[StackComponentType] = StackComponentType.CONTAINER_REGISTRY
 
     @validator("uri")
     def strip_trailing_slash(cls, uri: str) -> str:
-        """Removes trailing slashes from the URI."""
+        """Removes trailing slashes from the URI.
+
+        Args:
+            uri: The URI to be stripped.
+
+        Returns:
+            The URI without trailing slashes.
+        """
         return uri.rstrip("/")
 
     @property
+    def requires_authentication(self) -> bool:
+        """Returns whether the container registry requires authentication.
+
+        Returns:
+            `True` if the container registry requires authentication,
+            `False` otherwise.
+        """
+        return bool(self.authentication_secret)
+
+    @property
+    def credentials(self) -> Optional[Tuple[str, str]]:
+        """Username and password to authenticate with this container registry.
+
+        Returns:
+            Tuple with username and password if this container registry
+            requires authentication, `None` otherwise.
+        """
+        secret = self.get_authentication_secret(
+            expected_schema_type=BasicAuthSecretSchema
+        )
+        if secret:
+            return secret.username, secret.password
+
+        return None
+
+    @property
     def is_local(self) -> bool:
         """Returns whether the container registry is local or not.
 
         Returns:
             True if the container registry is local, False otherwise.
         """
         return bool(re.fullmatch(r"localhost:[0-9]{4,5}", self.uri))
 
     def prepare_image_push(self, image_name: str) -> None:
-        """Method that subclasses can overwrite to do any necessary checks or
-        preparations before an image gets pushed.
+        """Method that subclasses can overwrite to do any necessary checks or preparations before an image gets pushed.
 
         Args:
             image_name: Name of the docker image that will be pushed.
         """
 
     def push_image(self, image_name: str) -> None:
         """Pushes a docker image.
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/default_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/dockerhub_container_registry.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,20 +7,22 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a DockerHub Container Registry class."""
+
 from typing import ClassVar
 
 from zenml.container_registries.base_container_registry import (
     BaseContainerRegistry,
 )
 from zenml.enums import ContainerRegistryFlavor
 
 
-class DefaultContainerRegistry(BaseContainerRegistry):
-    """Class for default ZenML container registries."""
+class DockerHubContainerRegistry(BaseContainerRegistry):
+    """Class for DockerHub Container Registry."""
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.DEFAULT.value
+    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.DOCKERHUB.value
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/dockerhub_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/default_container_registry.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,20 +7,22 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a default container registry class."""
+
 from typing import ClassVar
 
 from zenml.container_registries.base_container_registry import (
     BaseContainerRegistry,
 )
 from zenml.enums import ContainerRegistryFlavor
 
 
-class DockerHubContainerRegistry(BaseContainerRegistry):
-    """Class for DockerHub Container Registry."""
+class DefaultContainerRegistry(BaseContainerRegistry):
+    """Class for default ZenML container registries."""
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.DOCKERHUB.value
+    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.DEFAULT.value
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/gcp_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/gcp_container_registry.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a GCP Container Registry class."""
+
 from typing import ClassVar
 
 from zenml.container_registries.base_container_registry import (
     BaseContainerRegistry,
 )
 from zenml.enums import ContainerRegistryFlavor
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/github_container_registry.py` & `zenml-0.9.0/src/zenml/container_registries/gitlab_container_registry.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,20 +7,22 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a GitLab Container Registry class."""
+
 from typing import ClassVar
 
 from zenml.container_registries.base_container_registry import (
     BaseContainerRegistry,
 )
 from zenml.enums import ContainerRegistryFlavor
 
 
-class GitHubContainerRegistry(BaseContainerRegistry):
-    """Class for GitHub Container Registry."""
+class GitLabContainerRegistry(BaseContainerRegistry):
+    """Class for GitLab Container Registry."""
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.GITHUB.value
+    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.GITLAB.value
```

### Comparing `zenml-0.8.1rc0/src/zenml/container_registries/gitlab_container_registry.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/helpers/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,26 +1,14 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from typing import ClassVar
-
-from zenml.container_registries.base_container_registry import (
-    BaseContainerRegistry,
-)
-from zenml.enums import ContainerRegistryFlavor
-
-
-class GitLabContainerRegistry(BaseContainerRegistry):
-    """Class for GitLab Container Registry."""
-
-    # Class Configuration
-    FLAVOR: ClassVar[str] = ContainerRegistryFlavor.GITLAB.value
+"""Initialization for helper functions for the sklearn digits dataset."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/entrypoints/__init__.py` & `zenml-0.9.0/src/zenml/integrations/plotly/visualizers/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,14 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
-from zenml.entrypoints.step_entrypoint_configuration import (
-    StepEntrypointConfiguration,
-)
-
-__all__ = ["StepEntrypointConfiguration"]
+"""Initialization of the Plotly Visualizer."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/entrypoints/step_entrypoint.py` & `zenml-0.9.0/src/zenml/entrypoints/step_entrypoint.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality to run ZenML steps."""
+
 import argparse
 
 from zenml.entrypoints.step_entrypoint_configuration import (
     ENTRYPOINT_CONFIG_SOURCE_OPTION,
     StepEntrypointConfiguration,
 )
 from zenml.utils import source_utils
@@ -24,14 +26,17 @@
     """Runs the ZenML step defined by the command line arguments.
 
     This main logic for running the step is not implemented in this file,
     instead it simply creates an object of a
     `zenml.entrypoints.StepEntrypointConfiguration` subclass (the concrete
     implementation can be specified using the command line arguments) and calls
     its `run()` method.
+
+    Raises:
+        TypeError: If the command line arguments are invalid.
     """
     # Read the source for the entrypoint configuration class from the command
     # line arguments
     parser = argparse.ArgumentParser()
     parser.add_argument(f"--{ENTRYPOINT_CONFIG_SOURCE_OPTION}", required=True)
     args, remaining_args = parser.parse_known_args()
```

### Comparing `zenml-0.8.1rc0/src/zenml/entrypoints/step_entrypoint_configuration.py` & `zenml-0.9.0/src/zenml/entrypoints/step_entrypoint_configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Abstract base class for entrypoint configurations that run a single step."""
+
 import argparse
 import importlib
 import json
 import logging
 import sys
 from abc import ABC, abstractmethod
 from typing import Any, Dict, List, NoReturn, Optional, Set, Type
@@ -28,15 +30,15 @@
 from zenml.artifacts.base_artifact import BaseArtifact
 from zenml.artifacts.type_registry import type_registry
 from zenml.integrations.registry import integration_registry
 from zenml.materializers.base_materializer import BaseMaterializer
 from zenml.repository import Repository
 from zenml.steps import BaseStep
 from zenml.steps import utils as step_utils
-from zenml.utils import source_utils
+from zenml.utils import source_utils, string_utils
 
 DEFAULT_SINGLE_STEP_CONTAINER_ENTRYPOINT_COMMAND = [
     "python",
     "-m",
     "zenml.entrypoints.step_entrypoint",
 ]
 # Constants for all the ZenML default entrypoint options
@@ -127,22 +129,24 @@
         Args:
             arguments: Command line arguments to configure this object.
         """
         self.entrypoint_args = self._parse_arguments(arguments)
 
     @classmethod
     def get_custom_entrypoint_options(cls) -> Set[str]:
-        """Custom options for this entrypoint configuration that are
-        required in addition to the default ZenML ones.
+        """Custom options for this entrypoint in addition to what's needed by default.
 
         The options returned by this method should be strings like "my_option"
         (no "--" prefix). When the entrypoint is executed, it will parse the
         command line arguments and expect all options to be passed in the form
         "--my_option my_value". You'll be able to retrieve the argument
         value by calling `self.entrypoint_args["my_option"]`.
+
+        Returns:
+            A set of strings with the custom options.
         """
         return set()
 
     @classmethod
     def get_custom_entrypoint_arguments(
         cls, step: BaseStep, **kwargs: Any
     ) -> List[str]:
@@ -153,14 +157,19 @@
         `["--some_option", "some_value"]` or `["--some_option=some_value"]`).
         It needs to provide values for all options returned by the
         `get_custom_entrypoint_options()` method of this class.
 
         Args:
             step: The step that the entrypoint should run using the arguments
                 returned by this method.
+            **kwargs: Additional keyword arguments that are passed to the
+                `get_custom_entrypoint_options()` method.
+
+        Returns:
+            A list of strings with the arguments.
         """
         return []
 
     @abstractmethod
     def get_run_name(self, pipeline_name: str) -> str:
         """Returns the run name.
 
@@ -172,19 +181,24 @@
             concept to a pipeline run, you can use that as the run name. E.g.
             Kubeflow Pipelines sets a run id as environment variable in all
             pods which we can reuse: `return os.environ["KFP_RUN_ID"]`
         * If that isn't possible, you could pass a unique value as an argument
             to the entrypoint (make sure to also return it from
             `get_custom_entrypoint_options()`) and use it like this:
             `return self.entrypoint_args["run_name_option"]`
+
+        Args:
+            pipeline_name: The name of the pipeline.
+
+        Returns:
+            The run name.
         """
 
     def setup(self, pipeline_name: str, step_name: str) -> None:
-        """Runs setup code that needs to run before any user code is imported
-        or the step is executed.
+        """Code that needs to run before user code is imported or the step is executed.
 
         Subclasses should overwrite this method if they need to perform any
         additional setup, but should in most cases include a
         `super().setup(...)` call so the ZenML setup code will still be
         executed.
 
         Args:
@@ -223,50 +237,56 @@
         This entrypoint module must execute a ZenML step when called. If
         subclasses don't overwrite this method, it will default to running the
         `zenml.entrypoints.step_entrypoint` module.
 
         **Note**: This command won't work on its own but needs to be called with
             the arguments returned by the `get_entrypoint_arguments(...)`
             method of this class.
+
+        Returns:
+            A list of strings with the command.
         """
         return DEFAULT_SINGLE_STEP_CONTAINER_ENTRYPOINT_COMMAND
 
     @classmethod
     def get_entrypoint_options(cls) -> Set[str]:
-        """Gets all the options that are required when running an entrypoint
-        with this configuration.
+        """Gets all options required for running an entrypoint with this configuration.
 
         **Note**: Subclasses should implement the
             `get_custom_entrypoint_options()` class method instead of this
             one if they require custom options.
+
+        Returns:
+            A set of strings with all required options.
         """
         zenml_options = {
             # Importable source pointing to the entrypoint configuration class
             # that should be used inside the entrypoint.
             ENTRYPOINT_CONFIG_SOURCE_OPTION,
-            # Json representation of the parent pipeline of the step that
-            # will be executed. This is needed in order to create the tfx
-            # launcher in the entrypoint that will run the ZenML step.
-            PIPELINE_JSON_OPTION,
             # Importable source pointing to the python module that was executed
             # to run a pipeline. This will be imported inside the entrypoint to
             # make sure all custom materializer/artifact types are registered.
             MAIN_MODULE_SOURCE_OPTION,
             # Importable source pointing to the ZenML step class that should be
             # run inside the entrypoint. This will be used to recreate the tfx
             # executor class that is required to run the step function.
             STEP_SOURCE_OPTION,
-            # Dictionary mapping the step input names to importable sources
-            # pointing to `zenml.artifacts.base_artifact.BaseArtifact`
-            # subclasses. These classes are needed to recreate the tfx executor
+            # Base64 encoded json representation of the parent pipeline of
+            # the step that will be executed. This is needed in order to create
+            # the tfx launcher in the entrypoint that will run the ZenML step.
+            PIPELINE_JSON_OPTION,
+            # Base64 encoded json dictionary mapping the step input names to
+            # importable sources pointing to
+            # `zenml.artifacts.base_artifact.BaseArtifact` subclasses.
+            # These classes are needed to recreate the tfx executor
             # class and can't be inferred as we do not have access to the
             # output artifacts from previous steps.
             INPUT_ARTIFACT_SOURCES_OPTION,
-            # Dictionary mapping the step output names to importable sources
-            # pointing to
+            # Base64 encoded json dictionary mapping the step output names to
+            # importable sources pointing to
             # `zenml.materializers.base_materializer.BaseMaterializer`
             # subclasses. These classes are needed to recreate the tfx executor
             # class if custom materializers were specified for the step.
             MATERIALIZER_SOURCES_OPTION,
         }
         custom_options = cls.get_custom_entrypoint_options()
         return zenml_options.union(custom_options)
@@ -294,17 +314,16 @@
             step: The step that the entrypoint should run using the arguments
                 returned by this method.
             pb2_pipeline: The protobuf representation of the pipeline to which
                 the `step` belongs.
             **kwargs: Custom options that will be passed to
                 `get_custom_entrypoint_arguments()`.
 
-        Raises:
-            ValueError: If the argument format is incorrect or one of the
-                options is missing.
+        Returns:
+            A list of strings with the arguments.
         """
         # Get an importable source of the user main module. If the `__main__`
         # module is not the actual module that a user executed (e.g. if we're
         # in some docker container entrypoint) use the ZenML constant that
         # points to the actual user main module. If not resolve the `__main__`
         # module to something that can be imported during entrypoint execution.
         main_module_source = (
@@ -312,29 +331,37 @@
             or source_utils.get_module_source_from_module(
                 sys.modules["__main__"]
             )
         )
 
         # TODO [ENG-887]: Move this method to source utils
         def _resolve_class(class_: Type[Any]) -> str:
-            """Resolves the input class in a way that it is importable inside
-            the entrypoint.
+            """Resolves the input class so it is importable inside the entrypoint.
+
+            Args:
+                class_: The class to resolve.
+
+            Returns:
+                The importable source of the class.
             """
             source = source_utils.resolve_class(class_)
             module_source, class_source = source.rsplit(".", 1)
             if module_source == "__main__":
                 # If the class is defined inside the `__main__` module it will
                 # not be importable in the entrypoint (The `__main__` module
                 # there will be the actual entrypoint module). We therefore
                 # replace the module source by the importable main module
                 # source computed above.
                 module_source = main_module_source
 
             return f"{module_source}.{class_source}"
 
+        # Resolve the entrypoint config source
+        entrypoint_config_source = _resolve_class(cls)
+
         # Resolve the step class
         step_source = _resolve_class(step.__class__)
 
         # Resolve the input artifact classes
         input_artifact_sources = {
             input_name: _resolve_class(input_type)
             for input_name, input_type in step.INPUT_SPEC.items()
@@ -347,25 +374,27 @@
             for output_name, materializer_class in materializer_classes.items()
         }
 
         # See `get_entrypoint_options()` for an in -depth explanation of all
         # these arguments.
         zenml_arguments = [
             f"--{ENTRYPOINT_CONFIG_SOURCE_OPTION}",
-            source_utils.resolve_class(cls),
-            f"--{PIPELINE_JSON_OPTION}",
-            json_format.MessageToJson(pb2_pipeline),
+            entrypoint_config_source,
             f"--{MAIN_MODULE_SOURCE_OPTION}",
             main_module_source,
             f"--{STEP_SOURCE_OPTION}",
             step_source,
+            # Base64 encode the json strings to make sure there are no issues
+            # when passing these arguments
+            f"--{PIPELINE_JSON_OPTION}",
+            string_utils.b64_encode(json_format.MessageToJson(pb2_pipeline)),
             f"--{INPUT_ARTIFACT_SOURCES_OPTION}",
-            json.dumps(input_artifact_sources),
+            string_utils.b64_encode(json.dumps(input_artifact_sources)),
             f"--{MATERIALIZER_SOURCES_OPTION}",
-            json.dumps(materializer_sources),
+            string_utils.b64_encode(json.dumps(materializer_sources)),
         ]
 
         custom_arguments = cls.get_custom_entrypoint_arguments(
             step=step, **kwargs
         )
         all_arguments = zenml_arguments + custom_arguments
 
@@ -390,17 +419,17 @@
                 `argparse.ArgumentParser.parse_args(...)` can handle (e.g.
                 `["--some_option", "some_value"]` or
                 `["--some_option=some_value"]`).
 
         Returns:
             Dictionary of the parsed arguments.
 
+        # noqa: DAR402
         Raises:
-            ValueError: If the parsing failed because the argument format is
-                incorrect or one of the options is missing.
+            ValueError: If the arguments are not valid.
         """
         # Argument parser subclass that suppresses some argparse logs and
         # raises an exception instead of the `sys.exit()` call
         class _CustomParser(argparse.ArgumentParser):
             def error(self, message: str) -> NoReturn:
                 raise ValueError(
                     f"Failed to parse entrypoint arguments: {message}"
@@ -429,14 +458,18 @@
 
         Args:
             step: The step for which the executor class should be created.
             input_artifact_sources: Dictionary mapping step input names to a
                 source strings of the artifact class to use for that input.
             materializer_sources: Dictionary mapping step output names to a
                 source string of the materializer class to use for that output.
+
+        Raises:
+            TypeError: If the step does not have a valid input or output
+                specification.
         """
         # Import the input artifact classes from the given sources
         input_spec = {}
         for input_name, source in input_artifact_sources.items():
             artifact_class = source_utils.load_source_path_class(source)
             if not issubclass(artifact_class, BaseArtifact):
                 raise TypeError(
@@ -481,34 +514,43 @@
         """Runs a single ZenML step.
 
         Subclasses should in most cases not need to overwrite this method and
         implement their custom logic in the `setup(...)` and `post_run(...)`
         methods instead. If you still need to customize the functionality of
         this method, make sure to still include all the existing logic as your
         step won't be executed properly otherwise.
+
+        Raises:
+            TypeError: If the arguments passed to the entrypoint are invalid.
         """
         # Make sure this entrypoint does not run an entire pipeline when
         # importing user modules. This could happen if the `pipeline.run()` call
         # is not wrapped in a function or an `if __name__== "__main__":` check)
         constants.SHOULD_PREVENT_PIPELINE_EXECUTION = True
 
         # Extract and parse all the entrypoint arguments required to execute
         # the step. See `get_entrypoint_options()` for an in-depth explanation
         # of all these arguments.
-        pb2_pipeline_json = self.entrypoint_args[PIPELINE_JSON_OPTION]
         pb2_pipeline = Pb2Pipeline()
+        pb2_pipeline_json = string_utils.b64_decode(
+            self.entrypoint_args[PIPELINE_JSON_OPTION]
+        )
         json_format.Parse(pb2_pipeline_json, pb2_pipeline)
 
         main_module_source = self.entrypoint_args[MAIN_MODULE_SOURCE_OPTION]
         step_source = self.entrypoint_args[STEP_SOURCE_OPTION]
         input_artifact_sources = json.loads(
-            self.entrypoint_args[INPUT_ARTIFACT_SOURCES_OPTION]
+            string_utils.b64_decode(
+                self.entrypoint_args[INPUT_ARTIFACT_SOURCES_OPTION]
+            )
         )
         materializer_sources = json.loads(
-            self.entrypoint_args[MATERIALIZER_SOURCES_OPTION]
+            string_utils.b64_decode(
+                self.entrypoint_args[MATERIALIZER_SOURCES_OPTION]
+            )
         )
 
         # Get some common values that will be used throughout the remainder of
         # this method
         pipeline_name = pb2_pipeline.pipeline_info.id
         if "@" in step_source:
             # Get rid of potential ZenML version pins if the source looks like
```

### Comparing `zenml-0.8.1rc0/src/zenml/enums.py` & `zenml-0.9.0/src/zenml/enums.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""ZenML enums."""
 
 import logging
 from enum import Enum
 
 from zenml.utils.enum_utils import StrEnum
 
 
@@ -37,42 +38,47 @@
     DEBUG = logging.DEBUG
     CRITICAL = logging.CRITICAL
 
 
 class StackComponentType(StrEnum):
     """All possible types a `StackComponent` can have."""
 
+    ALERTER = "alerter"
     ORCHESTRATOR = "orchestrator"
     METADATA_STORE = "metadata_store"
     ARTIFACT_STORE = "artifact_store"
     CONTAINER_REGISTRY = "container_registry"
     STEP_OPERATOR = "step_operator"
     FEATURE_STORE = "feature_store"
     SECRETS_MANAGER = "secrets_manager"
     MODEL_DEPLOYER = "model_deployer"
     EXPERIMENT_TRACKER = "experiment_tracker"
 
     @property
     def plural(self) -> str:
-        """Returns the plural of the enum value."""
+        """Returns the plural of the enum value.
+
+        Returns:
+            The plural of the enum value.
+        """
         if self == StackComponentType.CONTAINER_REGISTRY:
             return "container_registries"
 
         return f"{self.value}s"
 
 
 class MetadataContextTypes(Enum):
-    """All possible types that contexts can have within pipeline nodes"""
+    """All possible types that contexts can have within pipeline nodes."""
 
     STACK = "stack"
     PIPELINE_REQUIREMENTS = "pipeline_requirements"
 
 
 class StoreType(StrEnum):
-    """Repository Store Backend Types"""
+    """Repository Store Backend Types."""
 
     LOCAL = "local"
     SQL = "sql"
     REST = "rest"
 
 
 class ContainerRegistryFlavor(StrEnum):
@@ -84,14 +90,15 @@
     GCP = "gcp"
     AZURE = "azure"
     GITLAB = "gitlab"
 
 
 class CliCategories(StrEnum):
     """All possible categories for CLI commands.
+
     Note: The order of the categories is important. The same
     order is used to sort the commands in the CLI help output.
     """
 
     STACK_COMPONENTS = "Stack Components"
     MODEL_DEPLOYMENT = "Model Deployment"
     INTEGRATIONS = "Integrations"
```

### Comparing `zenml-0.8.1rc0/src/zenml/environment.py` & `zenml-0.9.0/src/zenml/environment.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Environment implementation."""
+
 import os
 import platform
 from importlib.util import find_spec
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, Dict, Optional, Tuple, Type, cast
 
 import distro
@@ -27,29 +29,38 @@
     from zenml.steps import StepEnvironment
 
 logger = get_logger(__name__)
 
 
 def get_environment() -> str:
     """Returns a string representing the execution environment of the pipeline.
-    Currently, one of `docker`, `paperspace`, 'colab', or `native`"""
+
+    Currently, one of `docker`, `paperspace`, 'colab', or `native`.
+
+    Returns:
+        str: the execution environment
+    """
     if Environment.in_docker():
         return "docker"
     elif Environment.in_google_colab():
         return "colab"
     elif Environment.in_paperspace_gradient():
         return "paperspace"
     elif Environment.in_notebook():
         return "notebook"
     else:
         return "native"
 
 
 def get_system_details() -> str:
-    """Returns OS, python and ZenML information."""
+    """Returns OS, python and ZenML information.
+
+    Returns:
+        str: OS, python and ZenML information
+    """
     from zenml.integrations.registry import integration_registry
 
     info = {
         "ZenML version": __version__,
         "Install path": Path(__file__).resolve().parent,
         "Python version": Environment.python_version(),
         "Platform information": Environment.get_system_info(),
@@ -77,24 +88,32 @@
         only get called once. All following `Environment()` calls will return
         the previously initialized instance.
         """
         self._components: Dict[str, "BaseEnvironmentComponent"] = {}
 
     @property
     def step_is_running(self) -> bool:
-        """Returns if a step is currently running."""
+        """Returns if a step is currently running.
+
+        Returns:
+            `True` if a step is currently running, `False` otherwise.
+        """
         from zenml.steps import STEP_ENVIRONMENT_NAME
 
         # A step is considered to be running if there is an active step
         # environment
         return self.has_component(STEP_ENVIRONMENT_NAME)
 
     @staticmethod
     def get_system_info() -> Dict[str, Any]:
-        """Information about the operating system."""
+        """Information about the operating system.
+
+        Returns:
+            A dictionary containing information about the operating system.
+        """
         system = platform.system()
 
         if system == "Windows":
             release, version, csd, ptype = platform.win32_ver()
 
             return {
                 "os": "windows",
@@ -116,55 +135,79 @@
             }
 
         # We don't collect data for any other system.
         return {"os": "unknown"}
 
     @staticmethod
     def python_version() -> str:
-        """Returns the python version of the running interpreter."""
+        """Returns the python version of the running interpreter.
+
+        Returns:
+            str: the python version
+        """
         return platform.python_version()
 
     @staticmethod
     def in_docker() -> bool:
-        """If the current python process is running in a docker container."""
+        """If the current python process is running in a docker container.
+
+        Returns:
+            `True` if the current python process is running in a docker
+            container, `False` otherwise.
+        """
         # TODO [ENG-167]: Make this more reliable and add test.
         try:
             with open("/proc/1/cgroup", "rt") as ifh:
                 info = ifh.read()
                 return "docker" in info or "kubepod" in info
         except (FileNotFoundError, Exception):
             return False
 
     @staticmethod
     def in_google_colab() -> bool:
-        """If the current Python process is running in a Google Colab."""
+        """If the current Python process is running in a Google Colab.
+
+        Returns:
+            `True` if the current Python process is running in a Google Colab,
+            `False` otherwise.
+        """
         try:
             import google.colab  # noqa
 
             return True
 
         except ModuleNotFoundError:
             return False
 
     @staticmethod
     def in_notebook() -> bool:
-        """If the current Python process is running in a notebook."""
+        """If the current Python process is running in a notebook.
+
+        Returns:
+            `True` if the current Python process is running in a notebook,
+            `False` otherwise.
+        """
         if find_spec("IPython") is not None:
             from IPython import get_ipython  # type: ignore
 
             if get_ipython().__class__.__name__ in [
                 "TerminalInteractiveShell",
                 "ZMQInteractiveShell",
             ]:
                 return True
         return False
 
     @staticmethod
     def in_paperspace_gradient() -> bool:
-        """If the current Python process is running in Paperspace Gradient."""
+        """If the current Python process is running in Paperspace Gradient.
+
+        Returns:
+            `True` if the current Python process is running in Paperspace
+            Gradient, `False` otherwise.
+        """
         return "PAPERSPACE_NOTEBOOK_REPO_ID" in os.environ
 
     def register_component(
         self, component: "BaseEnvironmentComponent"
     ) -> "BaseEnvironmentComponent":
         """Registers an environment component.
 
@@ -215,44 +258,45 @@
             or None if no such component is registered.
         """
         return self._components.get(name)
 
     def get_components(
         self,
     ) -> Dict[str, "BaseEnvironmentComponent"]:
-        """Get all registered environment components."""
+        """Get all registered environment components.
+
+        Returns:
+            A dictionary containing all registered environment components.
+        """
         return self._components.copy()
 
     def has_component(self, name: str) -> bool:
-        """Check if the environment component with a known name is currently
-        available.
+        """Check if the environment component with a known name is currently available.
 
         Args:
             name: the environment component name.
 
         Returns:
             `True` if an environment component with the given name is
             currently registered for the given name, `False` otherwise.
-
         """
         return name in self._components
 
     def __getitem__(self, name: str) -> "BaseEnvironmentComponent":
         """Get the environment component with the given name.
 
         Args:
             name: the environment component name.
 
         Returns:
             `BaseEnvironmentComponent` instance that was registered for the
             given name.
 
         Raises:
-            KeyError: if no environment component is registered for the given
-            name.
+            KeyError: if no environment component is registered for the given name.
         """
         if name in self._components:
             return self._components[name]
         else:
             raise KeyError(
                 f"No environment component with name {name} is currently "
                 f"registered. This could happen for example if you're trying "
@@ -276,21 +320,29 @@
         return cast(StepEnvironment, self[STEP_ENVIRONMENT_NAME])
 
 
 _BASE_ENVIRONMENT_COMPONENT_NAME = "base_environment_component"
 
 
 class EnvironmentComponentMeta(type):
-    """Metaclass responsible for registering different EnvironmentComponent
-    instances in the global Environment"""
+    """Metaclass responsible for registering different EnvironmentComponent instances in the global Environment."""
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "EnvironmentComponentMeta":
-        """Hook into creation of an BaseEnvironmentComponent class."""
+        """Hook into creation of an BaseEnvironmentComponent class.
+
+        Args:
+            name: the name of the class being created.
+            bases: the base classes of the class being created.
+            dct: the dictionary of attributes of the class being created.
+
+        Returns:
+            The newly created class.
+        """
         cls = cast(
             Type["BaseEnvironmentComponent"],
             super().__new__(mcs, name, bases, dct),
         )
         if name != "BaseEnvironmentComponent":
             assert (
                 cls.NAME and cls.NAME != _BASE_ENVIRONMENT_COMPONENT_NAME
@@ -378,51 +430,58 @@
     NAME: str = _BASE_ENVIRONMENT_COMPONENT_NAME
 
     def __init__(self) -> None:
         """Initialize an environment component."""
         self._active = False
 
     def activate(self) -> None:
-        """Activate the environment component and register it in the global
-        Environment.
+        """Activate the environment component and register it in the global Environment.
 
         Raises:
             RuntimeError: if the component is already active.
         """
         if self._active:
             raise RuntimeError(
                 f"Environment component {self.NAME} is already active."
             )
         Environment().register_component(self)
         self._active = True
 
     def deactivate(self) -> None:
-        """Deactivate the environment component and deregister it from the
-        global Environment.
+        """Deactivate the environment component and deregister it from the global Environment.
 
         Raises:
             RuntimeError: if the component is not active.
         """
         if not self._active:
             raise RuntimeError(
                 f"Environment component {self.NAME} is not active."
             )
         Environment().deregister_component(self)
         self._active = False
 
     @property
     def active(self) -> bool:
-        """Check if the environment component is currently active."""
+        """Check if the environment component is currently active.
+
+        Returns:
+            `True` if the environment component is currently active, `False`
+            otherwise.
+        """
         return self._active
 
     def __enter__(self) -> "BaseEnvironmentComponent":
         """Environment component context entry point.
 
         Returns:
             The BaseEnvironmentComponent instance.
         """
         self.activate()
         return self
 
     def __exit__(self, *args: Any) -> None:
-        """Environment component context exit point."""
+        """Environment component context exit point.
+
+        Args:
+            *args: the arguments passed to the context exit point.
+        """
         self.deactivate()
```

### Comparing `zenml-0.8.1rc0/src/zenml/exceptions.py` & `zenml-0.9.0/src/zenml/exceptions.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""ZenML specific exception definitions"""
+"""ZenML specific exception definitions."""
+
 import textwrap
 from typing import TYPE_CHECKING, List, Optional, Type
 
 if TYPE_CHECKING:
     from zenml.steps import BaseStepConfig
 
 
@@ -23,15 +24,15 @@
     """Base exception for all ZenML Exceptions."""
 
     def __init__(
         self,
         message: Optional[str] = None,
         url: Optional[str] = None,
     ):
-        """BaseException used to format messages displayed to the user.
+        """The BaseException used to format messages displayed to the user.
 
         Args:
             message: Message with details of exception. This message
                      will be appended with another message directing user to
                      `url` for more information. If `None`, then default
                      Exception behavior is used.
             url: URL to point to in exception message. If `None`, then no url
@@ -40,122 +41,134 @@
         if message:
             if url:
                 message += f" For more information, visit {url}."
         super().__init__(message)
 
 
 class InitializationException(ZenMLBaseException):
-    """Raised when an error occurred during initialization of a ZenML
-    repository."""
+    """Raised when an error occurred during initialization of a ZenML repository."""
 
 
 class ForbiddenRepositoryAccessError(ZenMLBaseException, RuntimeError):
-    """Raised when trying to access a ZenML repository instance while a step
-    is executed."""
+    """Raised when trying to access a ZenML repository instance while a step is executed."""
 
 
 class DoesNotExistException(ZenMLBaseException):
-    """Raises exception when the entity does not exist in the system but an
-    action is being done that requires it to be present."""
+    """Raises exception when the entity does not exist in the system but an action is being done that requires it to be present."""
 
     def __init__(self, message: str):
+        """Initializes the exception.
+
+        Args:
+            message: Message with details of exception.
+        """
         super().__init__(message)
 
 
 class AlreadyExistsException(ZenMLBaseException):
-    """Raises exception when the `name` already exist in the system but an
-    action is trying to create a resource with the same name."""
+    """Raises exception when the `name` already exists in the system.
+
+    This happens when an action is trying to create a resource with the same
+    name.
+    """
 
     def __init__(
         self,
         message: Optional[str] = None,
         name: str = "",
         resource_type: str = "",
     ):
+        """Initializes the exception.
+
+        Args:
+            message: Message with details of exception.
+            name: Name of the resource that already exists.
+            resource_type: Type of the resource that already exists.
+        """
         if message is None:
             message = f"{resource_type} `{name}` already exists!"
         super().__init__(message)
 
 
 class PipelineNotSucceededException(ZenMLBaseException):
-    """Raises exception when trying to fetch artifacts from a not succeeded
-    pipeline."""
+    """Raises exception when trying to fetch artifacts from a not succeeded pipeline."""
 
     def __init__(
         self,
         name: str = "",
         message: str = "{} is not yet completed successfully.",
     ):
+        """Initializes the exception.
+
+        Args:
+            name: Name of the pipeline.
+            message: Message with details of exception.
+        """
         super().__init__(message.format(name))
 
 
 class GitException(ZenMLBaseException):
     """Raises exception when a problem occurs in git resolution."""
 
     def __init__(
         self,
         message: str = "There is a problem with git resolution. "
         "Please make sure that all relevant files "
         "are committed.",
     ):
+        """Initializes the exception.
+
+        Args:
+            message: Message with details of exception.
+        """
         super().__init__(message)
 
 
 class StepInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the Step interface
-    in an unsupported way."""
+    """Raises exception when interacting with the Step interface in an unsupported way."""
 
 
 class MaterializerInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the Materializer interface
-    in an unsupported way."""
+    """Raises exception when interacting with the Materializer interface in an unsupported way."""
 
 
 class StepContextError(ZenMLBaseException):
-    """Raises exception when interacting with a StepContext
-    in an unsupported way."""
+    """Raises exception when interacting with a StepContext in an unsupported way."""
 
 
 class PipelineInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the Pipeline interface
-    in an unsupported way."""
+    """Raises exception when interacting with the Pipeline interface in an unsupported way."""
 
 
 class ArtifactInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the Artifact interface
-    in an unsupported way."""
+    """Raises exception when interacting with the Artifact interface in an unsupported way."""
 
 
 class StackComponentInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the stack components
-    in an unsupported way."""
+    """Raises exception when interacting with the stack components in an unsupported way."""
 
 
 class ArtifactStoreInterfaceError(ZenMLBaseException):
-    """Raises exception when interacting with the Artifact Store interface
-    in an unsupported way."""
+    """Raises exception when interacting with the Artifact Store interface in an unsupported way."""
 
 
 class PipelineConfigurationError(ZenMLBaseException):
-    """Raises exceptions when a pipeline configuration contains
-    invalid values."""
+    """Raises exceptions when a pipeline configuration contains invalid values."""
 
 
 class MissingStepParameterError(ZenMLBaseException):
-    """Raises exceptions when a step parameter is missing when running a
-    pipeline."""
+    """Raises exceptions when a step parameter is missing when running a pipeline."""
 
     def __init__(
         self,
         step_name: str,
         missing_parameters: List[str],
         config_class: Type["BaseStepConfig"],
     ):
-        """
-        Initializes a MissingStepParameterError object.
+        """Initializes a MissingStepParameterError object.
 
         Args:
             step_name: Name of the step for which one or more parameters
                        are missing.
             missing_parameters: Names of all parameters which are missing.
             config_class: Class of the configuration object for which
                           the parameters are missing.
@@ -185,46 +198,45 @@
     """Raises exception when a run with the same name already exists."""
 
     def __init__(
         self,
         message: str = "Unable to run a pipeline with a run name that "
         "already exists.",
     ):
+        """Initializes the exception.
+
+        Args:
+            message: Message with details of exception.
+        """
         super().__init__(message)
 
 
 class StackExistsError(ZenMLBaseException):
-    """Raised when trying to register a stack with a name that already
-    exists."""
+    """Raised when trying to register a stack with a name that already exists."""
 
 
 class StackComponentExistsError(ZenMLBaseException):
-    """Raised when trying to register a stack component with a name that
-    already exists."""
+    """Raised when trying to register a stack component with a name that already exists."""
 
 
 class EntityExistsError(ZenMLBaseException):
-    """Raised when trying to register a user-management entity with a name that
-    already exists."""
+    """Raised when trying to register a user-management entity with a name that already exists."""
 
 
 class SecretExistsError(ZenMLBaseException):
-    """Raised when trying to register a secret with a name that
-    already exists."""
+    """Raised when trying to register a secret with a name that already exists."""
 
 
 class StackValidationError(ZenMLBaseException):
     """Raised when a stack configuration is not valid."""
 
 
 class ProvisioningError(ZenMLBaseException):
-    """Raised when an error occurs when provisioning resources for a
-    StackComponent."""
+    """Raised when an error occurs when provisioning resources for a StackComponent."""
 
 
 class GitNotFoundError(ImportError):
-    """Raised when ZenML CLI is used to interact with examples on a machine
-    with no git installation"""
+    """Raised when ZenML CLI is used to interact with examples on a machine with no git installation."""
 
 
 class DuplicatedConfigurationError(ZenMLBaseException):
-    """Raised when a configuration parameter is set twice"""
+    """Raised when a configuration parameter is set twice."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/experiment_trackers/__init__.py` & `zenml-0.9.0/src/zenml/experiment_trackers/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,20 +7,20 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-Experiment trackers let you track your ML experiments by logging the parameters
-and allowing you to compare between runs. In the ZenML world, every pipeline
-run is considered an experiment, and ZenML facilitates the storage of experiment
-results through ExperimentTracker stack components. This establishes a clear
-link between pipeline runs and experiments.
+"""Experiment trackers let you track your ML experiments.
+
+They log the parameters used and allow you to compare between runs. In the ZenML
+world, every pipeline run is considered an experiment, and ZenML facilitates the
+storage of experiment results through ExperimentTracker stack components. This
+establishes a clear link between pipeline runs and experiments.
 """
 
 from zenml.experiment_trackers.base_experiment_tracker import (
     BaseExperimentTracker,
 )
 
 __all__ = [
```

### Comparing `zenml-0.8.1rc0/src/zenml/experiment_trackers/base_experiment_tracker.py` & `zenml-0.9.0/src/zenml/experiment_trackers/base_experiment_tracker.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base class for all ZenML experiment trackers."""
+
 from abc import ABC
 from typing import ClassVar
 
 from zenml.enums import StackComponentType
 from zenml.stack import StackComponent
```

### Comparing `zenml-0.8.1rc0/src/zenml/feature_stores/__init__.py` & `zenml-0.9.0/src/zenml/feature_stores/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""A feature store enables an offline and online serving of feature data.
+
 Feature stores allow data teams to serve data via an offline store and an online
 low-latency store where data is kept in sync between the two. It also offers a
 centralized registry where features (and feature schemas) are stored for use
 within a team or wider organization.
 
 As a data scientist working on training your model, your requirements for how
 you access your batch / 'offline' data will almost certainly be different from
```

### Comparing `zenml-0.8.1rc0/src/zenml/feature_stores/base_feature_store.py` & `zenml-0.9.0/src/zenml/feature_stores/base_feature_store.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""The base class for feature stores."""
 
 from abc import ABC, abstractmethod
 from typing import Any, ClassVar, Dict, List, Union
 
 import pandas as pd
 
 from zenml.enums import StackComponentType
@@ -33,15 +34,15 @@
         entity_df: Union[pd.DataFrame, str],
         features: List[str],
         full_feature_names: bool = False,
     ) -> pd.DataFrame:
         """Returns the historical features for training or batch scoring.
 
         Args:
-            entity_df: The entity dataframe or entity name.
+            entity_df: The entity DataFrame or entity name.
             features: The features to retrieve.
             full_feature_names: Whether to return the full feature names.
 
         Returns:
             The historical features as a Pandas DataFrame.
         """
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/__init__.py` & `zenml-0.9.0/src/zenml/integrations/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,46 +7,43 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""ZenML integrations module.
+
 The ZenML integrations module contains sub-modules for each integration that we
 support. This includes orchestrators like Apache Airflow, visualization tools
 like the ``facets`` library, as well as deep learning libraries like PyTorch.
 """
 
 from zenml.integrations.airflow import AirflowIntegration  # noqa
 from zenml.integrations.aws import AWSIntegration  # noqa
 from zenml.integrations.azure import AzureIntegration  # noqa
-from zenml.integrations.azureml import AzureMLIntegration  # noqa
 from zenml.integrations.dash import DashIntegration  # noqa
 from zenml.integrations.evidently import EvidentlyIntegration  # noqa
 from zenml.integrations.facets import FacetsIntegration  # noqa
 from zenml.integrations.feast import FeastIntegration  # noqa
 from zenml.integrations.gcp import GcpIntegration  # noqa
-from zenml.integrations.gcp_secrets_manager import (  # noqa
-    GcpSecretManagerIntegration,
-)
+from zenml.integrations.github import GitHubIntegration  # noqa
 from zenml.integrations.graphviz import GraphvizIntegration  # noqa
 from zenml.integrations.huggingface import HuggingfaceIntegration  # noqa
 from zenml.integrations.kubeflow import KubeflowIntegration  # noqa
 from zenml.integrations.lightgbm import LightGBMIntegration  # noqa
 from zenml.integrations.mlflow import MlflowIntegration  # noqa
 from zenml.integrations.neural_prophet import NeuralProphetIntegration  # noqa
 from zenml.integrations.plotly import PlotlyIntegration  # noqa
 from zenml.integrations.pytorch import PytorchIntegration  # noqa
 from zenml.integrations.pytorch_lightning import (  # noqa
     PytorchLightningIntegration,
 )
 from zenml.integrations.s3 import S3Integration  # noqa
-from zenml.integrations.sagemaker import SagemakerIntegration  # noqa
 from zenml.integrations.scipy import ScipyIntegration  # noqa
 from zenml.integrations.seldon import SeldonIntegration  # noqa
 from zenml.integrations.sklearn import SklearnIntegration  # noqa
+from zenml.integrations.slack import SlackIntegration  # noqa
 from zenml.integrations.tensorflow import TensorflowIntegration  # noqa
-from zenml.integrations.vertex import VertexIntegration  # noqa
 from zenml.integrations.wandb import WandbIntegration  # noqa
 from zenml.integrations.whylogs import WhylogsIntegration  # noqa
 from zenml.integrations.xgboost import XgboostIntegration  # noqa
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/airflow/__init__.py` & `zenml-0.9.0/src/zenml/integrations/airflow/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Airflow integration for ZenML.
+
 The Airflow integration sub-module powers an alternative to the local
 orchestrator. You can enable it by registering the Airflow orchestrator with
 the CLI tool, then bootstrap using the ``zenml orchestrator up`` command.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
@@ -30,15 +31,19 @@
     """Definition of Airflow Integration for ZenML."""
 
     NAME = AIRFLOW
     REQUIREMENTS = ["apache-airflow==2.2.0"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Airflow integration."""
+        """Declare the stack component flavors for the Airflow integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
                 name=AIRFLOW_ORCHESTRATOR_FLAVOR,
                 source="zenml.integrations.airflow.orchestrators.AirflowOrchestrator",
                 type=StackComponentType.ORCHESTRATOR,
                 integration=cls.NAME,
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/airflow/orchestrators/__init__.py` & `zenml-0.9.0/src/zenml/integrations/airflow/orchestrators/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The Airflow integration enables the use of Airflow as a pipeline orchestrator.
-"""
+"""The Airflow integration enables the use of Airflow as a pipeline orchestrator."""
 
 from zenml.integrations.airflow.orchestrators.airflow_orchestrator import (  # noqa
     AirflowOrchestrator,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/airflow/orchestrators/airflow_orchestrator.py` & `zenml-0.9.0/src/zenml/integrations/airflow/orchestrators/airflow_orchestrator.py`

 * *Files 10% similar despite different names*

```diff
@@ -24,32 +24,32 @@
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 
 # Minor parts of the  `prepare_or_run_pipeline()` method of this file are
 # inspired by the airflow dag runner implementation of tfx
+"""Implementation of Airflow orchestrator integration."""
 
 import datetime
 import functools
 import os
 import time
 from typing import TYPE_CHECKING, Any, ClassVar, Dict, List, Optional
 
 from pydantic import root_validator
 from tfx.proto.orchestration.pipeline_pb2 import Pipeline as Pb2Pipeline
 
-import zenml.io.utils
 from zenml.integrations.airflow import AIRFLOW_ORCHESTRATOR_FLAVOR
 from zenml.io import fileio
 from zenml.logger import get_logger
 from zenml.orchestrators import BaseOrchestrator
 from zenml.pipelines import Schedule
 from zenml.steps import BaseStep
-from zenml.utils import daemon
+from zenml.utils import daemon, io_utils
 from zenml.utils.source_utils import get_source_root_path
 
 logger = get_logger(__name__)
 
 if TYPE_CHECKING:
     from zenml.pipelines.base_pipeline import BasePipeline
     from zenml.runtime_configuration import RuntimeConfiguration
@@ -64,40 +64,52 @@
 
     airflow_home: str = ""
 
     # Class Configuration
     FLAVOR: ClassVar[str] = AIRFLOW_ORCHESTRATOR_FLAVOR
 
     def __init__(self, **values: Any):
-        """Sets environment variables to configure airflow."""
+        """Sets environment variables to configure airflow.
+
+        Args:
+            **values: Values to set in the orchestrator.
+        """
         super().__init__(**values)
         self._set_env()
 
     @staticmethod
     def _translate_schedule(
         schedule: Optional[Schedule] = None,
     ) -> Dict[str, Any]:
-        """Convert ZenML schedule into airflow schedule which uses slightly
-        different naming and needs some default entries for execution without a
-        schedule.
+        """Convert ZenML schedule into Airflow schedule.
+
+        The Airflow schedule uses slightly different naming and needs some
+        default entries for execution without a schedule.
 
         Args:
             schedule: Containing the interval, start and end date and
                 a boolean flag that defines if past runs should be caught up
                 on
+
         Returns:
             Airflow configuration dict.
         """
         if schedule:
-            return {
-                "schedule_interval": schedule.interval_second,
-                "start_date": schedule.start_time,
-                "end_date": schedule.end_time,
-                "catchup": schedule.catchup,
-            }
+            if schedule.cron_expression:
+                return {
+                    "schedule_interval": schedule.cron_expression,
+                }
+            else:
+                return {
+                    "schedule_interval": schedule.interval_second,
+                    "start_date": schedule.start_time,
+                    "end_date": schedule.end_time,
+                    "catchup": schedule.catchup,
+                }
+
         return {
             "schedule_interval": "@once",
             # set the a start time in the past and disable catchup so airflow runs the dag immediately
             "start_date": datetime.datetime.now() - datetime.timedelta(7),
             "catchup": False,
         }
 
@@ -105,32 +117,42 @@
         self,
         sorted_steps: List[BaseStep],
         pipeline: "BasePipeline",
         pb2_pipeline: Pb2Pipeline,
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> Any:
-        """Create an airflow dag as the intermediate representation for the
-        pipeline. This dag will be loaded by airflow in the target environment
+        """Creates an Airflow DAG as the intermediate representation for the pipeline.
+
+        This DAG will be loaded by airflow in the target environment
         and used for orchestration of the pipeline.
 
         How it works:
         -------------
         A new airflow_dag is instantiated with the pipeline name and among
         others things the run schedule.
 
         For each step of the pipeline a callable is created. This callable
         uses the run_step() method to execute the step. The parameters of
         this callable are pre-filled and an airflow step_operator is created
         within the dag. The dependencies to upstream steps are then
         configured.
 
         Finally, the dag is fully complete and can be returned.
-        """
 
+        Args:
+            sorted_steps: List of steps in the pipeline.
+            pipeline: The pipeline to be executed.
+            pb2_pipeline: The pipeline as a protobuf message.
+            stack: The stack on which the pipeline will be deployed.
+            runtime_configuration: The runtime configuration.
+
+        Returns:
+            The Airflow DAG.
+        """
         import airflow
         from airflow.operators import python as airflow_python
 
         # Instantiate and configure airflow Dag with name and schedule
         airflow_dag = airflow.DAG(
             dag_id=pipeline.name,
             is_paused_upon_creation=False,
@@ -176,63 +198,86 @@
                 )
 
         # Return the finished airflow dag
         return airflow_dag
 
     @root_validator(skip_on_failure=True)
     def set_airflow_home(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        """Sets airflow home according to orchestrator UUID."""
+        """Sets Airflow home according to orchestrator UUID.
+
+        Args:
+            values: Dictionary containing all orchestrator attributes values.
+
+        Returns:
+            Dictionary containing all orchestrator attributes values and the airflow home.
+
+        Raises:
+            ValueError: If the orchestrator UUID is not set.
+        """
         if "uuid" not in values:
             raise ValueError("`uuid` needs to exist for AirflowOrchestrator.")
         values["airflow_home"] = os.path.join(
-            zenml.io.utils.get_global_config_directory(),
+            io_utils.get_global_config_directory(),
             AIRFLOW_ROOT_DIR,
             str(values["uuid"]),
         )
         return values
 
     @property
     def dags_directory(self) -> str:
-        """Returns path to the airflow dags directory."""
+        """Returns path to the airflow dags directory.
+
+        Returns:
+            Path to the airflow dags directory.
+        """
         return os.path.join(self.airflow_home, "dags")
 
     @property
     def pid_file(self) -> str:
-        """Returns path to the daemon PID file."""
+        """Returns path to the daemon PID file.
+
+        Returns:
+            Path to the daemon PID file.
+        """
         return os.path.join(self.airflow_home, "airflow_daemon.pid")
 
     @property
     def log_file(self) -> str:
-        """Returns path to the airflow log file."""
+        """Returns path to the airflow log file.
+
+        Returns:
+            str: Path to the airflow log file.
+        """
         return os.path.join(self.airflow_home, "airflow_orchestrator.log")
 
     @property
     def password_file(self) -> str:
-        """Returns path to the webserver password file."""
+        """Returns path to the webserver password file.
+
+        Returns:
+            Path to the webserver password file.
+        """
         return os.path.join(self.airflow_home, "standalone_admin_password.txt")
 
     def _set_env(self) -> None:
         """Sets environment variables to configure airflow."""
         os.environ["AIRFLOW_HOME"] = self.airflow_home
         os.environ["AIRFLOW__CORE__DAGS_FOLDER"] = self.dags_directory
         os.environ["AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE"] = "false"
         os.environ["AIRFLOW__CORE__LOAD_EXAMPLES"] = "false"
         # check the DAG folder every 10 seconds for new files
         os.environ["AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL"] = "10"
 
     def _copy_to_dag_directory_if_necessary(self, dag_filepath: str) -> None:
-        """Copies the DAG module to the airflow DAGs directory if it's not
-        already located there.
+        """Copies DAG module to the Airflow DAGs directory if not already present.
 
         Args:
             dag_filepath: Path to the file in which the DAG is defined.
         """
-        dags_directory = zenml.io.utils.resolve_relative_path(
-            self.dags_directory
-        )
+        dags_directory = io_utils.resolve_relative_path(self.dags_directory)
 
         if dags_directory == os.path.dirname(dag_filepath):
             logger.debug("File is already in airflow DAGs directory.")
         else:
             logger.debug(
                 "Copying dag file '%s' to DAGs directory.", dag_filepath
             )
@@ -262,28 +307,36 @@
         logger.info(
             "To inspect your DAGs, login to http://0.0.0.0:8080 "
             "with username: admin password: %s",
             password,
         )
 
     def runtime_options(self) -> Dict[str, Any]:
-        """Runtime options for the airflow orchestrator."""
+        """Runtime options for the airflow orchestrator.
+
+        Returns:
+            Runtime options dictionary.
+        """
         return {DAG_FILEPATH_OPTION_KEY: None}
 
     def prepare_pipeline_deployment(
         self,
         pipeline: "BasePipeline",
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> None:
-        """Checks whether airflow is running and copies the DAG file to the
-        airflow DAGs directory.
+        """Checks Airflow is running and copies DAG file to the Airflow DAGs directory.
+
+        Args:
+            pipeline: Pipeline to be deployed.
+            stack: Stack to be deployed.
+            runtime_configuration: Runtime configuration for the pipeline.
 
         Raises:
-            RuntimeError: If airflow is not running or no DAG filepath runtime
+            RuntimeError: If Airflow is not running or no DAG filepath runtime
                           option is provided.
         """
         if not self.is_running:
             raise RuntimeError(
                 "Airflow orchestrator is currently not running. Run `zenml "
                 "stack up` to provision resources for the active stack."
             )
@@ -297,15 +350,22 @@
                 f"option (key: '{DAG_FILEPATH_OPTION_KEY}')."
             )
 
         self._copy_to_dag_directory_if_necessary(dag_filepath=dag_filepath)
 
     @property
     def is_running(self) -> bool:
-        """Returns whether the airflow daemon is currently running."""
+        """Returns whether the airflow daemon is currently running.
+
+        Returns:
+            True if the daemon is running, False otherwise.
+
+        Raises:
+            RuntimeError: If port 8080 is occupied.
+        """
         from airflow.cli.commands.standalone_command import StandaloneCommand
         from airflow.jobs.triggerer_job import TriggererJob
 
         daemon_running = daemon.check_if_daemon_is_running(self.pid_file)
 
         command = StandaloneCommand()
         webserver_port_open = command.port_open(8080)
@@ -328,28 +388,30 @@
         airflow_running = webserver_port_open and command.job_running(
             TriggererJob
         )
         return airflow_running
 
     @property
     def is_provisioned(self) -> bool:
-        """Returns whether the airflow daemon is currently running."""
+        """Returns whether the airflow daemon is currently running.
+
+        Returns:
+            True if the airflow daemon is running, False otherwise.
+        """
         return self.is_running
 
     def provision(self) -> None:
         """Ensures that Airflow is running."""
         if self.is_running:
             logger.info("Airflow is already running.")
             self._log_webserver_credentials()
             return
 
         if not fileio.exists(self.dags_directory):
-            zenml.io.utils.create_dir_recursive_if_not_exists(
-                self.dags_directory
-            )
+            io_utils.create_dir_recursive_if_not_exists(self.dags_directory)
 
         from airflow.cli.commands.standalone_command import StandaloneCommand
 
         try:
             command = StandaloneCommand()
             # Run the daemon with a working directory inside the current
             # zenml repo so the same repo will be used to run the DAGs
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/__init__.py` & `zenml-0.9.0/src/zenml/integrations/aws/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,54 +7,65 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Integrates multiple AWS Tools as Stack Components.
+
 The AWS integration provides a way for our users to manage their secrets
-through AWS.
+through AWS, a way to use the aws container registry. Additionally, the
+Sagemaker integration submodule provides a way to run ZenML steps in
+Sagemaker.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
 from zenml.integrations.constants import AWS
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
 
 AWS_SECRET_MANAGER_FLAVOR = "aws"
 AWS_CONTAINER_REGISTRY_FLAVOR = "aws"
+AWS_SAGEMAKER_STEP_OPERATOR_FLAVOR = "sagemaker"
 
 
 class AWSIntegration(Integration):
     """Definition of AWS integration for ZenML."""
 
     NAME = AWS
-    REQUIREMENTS = ["boto3==1.21.21"]
-
-    @classmethod
-    def activate(cls) -> None:
-        """Activates the integration."""
-        from zenml.integrations.aws import secret_schemas  # noqa
+    REQUIREMENTS = ["boto3==1.21.21", "sagemaker==2.82.2"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the AWS integration."""
+        """Declare the stack component flavors for the AWS integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
                 name=AWS_SECRET_MANAGER_FLAVOR,
                 source="zenml.integrations.aws.secrets_managers"
                 ".AWSSecretsManager",
                 type=StackComponentType.SECRETS_MANAGER,
                 integration=cls.NAME,
             ),
             FlavorWrapper(
                 name=AWS_CONTAINER_REGISTRY_FLAVOR,
-                source="zenml.integrations.aws.container_registries.AWSContainerRegistry",
+                source="zenml.integrations.aws.container_registries"
+                ".AWSContainerRegistry",
                 type=StackComponentType.CONTAINER_REGISTRY,
                 integration=cls.NAME,
             ),
+            FlavorWrapper(
+                name=AWS_SAGEMAKER_STEP_OPERATOR_FLAVOR,
+                source="zenml.integrations.aws.step_operators"
+                ".SagemakerStepOperator",
+                type=StackComponentType.STEP_OPERATOR,
+                integration=cls.NAME,
+            ),
         ]
 
 
 AWSIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/container_registries/__init__.py` & `zenml-0.9.0/src/zenml/integrations/aws/container_registries/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of AWS Container Registry integration."""
 
 from zenml.integrations.aws.container_registries.aws_container_registry import (  # noqa
     AWSContainerRegistry,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/container_registries/aws_container_registry.py` & `zenml-0.9.0/src/zenml/integrations/aws/container_registries/aws_container_registry.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the AWS container registry integration."""
+
 import re
 from typing import ClassVar, List, Optional
 
 import boto3
 from botocore.exceptions import ClientError
 from pydantic import validator
 
@@ -31,26 +33,35 @@
     """Class for AWS Container Registry."""
 
     # Class Configuration
     FLAVOR: ClassVar[str] = AWS_CONTAINER_REGISTRY_FLAVOR
 
     @validator("uri")
     def validate_aws_uri(cls, uri: str) -> str:
-        """Validates that the URI is in the correct format."""
+        """Validates that the URI is in the correct format.
+
+        Args:
+            uri: URI to validate.
+
+        Returns:
+            URI in the correct format.
+
+        Raises:
+            ValueError: If the URI contains a slash character.
+        """
         if "/" in uri:
             raise ValueError(
                 "Property `uri` can not contain a `/`. An example of a valid "
                 "URI is: `715803424592.dkr.ecr.us-east-1.amazonaws.com`"
             )
 
         return uri
 
     def prepare_image_push(self, image_name: str) -> None:
-        """Logs a warning message if trying to push an image for which no
-        repository exists.
+        """Logs warning message if trying to push an image for which no repository exists.
 
         Args:
             image_name: Name of the docker image that will be pushed.
 
         Raises:
             ValueError: If the docker image name is invalid.
         """
@@ -79,16 +90,19 @@
                 f"repositories: {repo_uris}. We will try to push anyway, but "
                 f"in case it fails you need to create a repository named "
                 f"`{repo_name}`."
             )
 
     @property
     def post_registration_message(self) -> Optional[str]:
-        """Optional message that will be printed after the stack component is
-        registered."""
+        """Optional message printed after the stack component is registered.
+
+        Returns:
+            Info message regarding docker repositories in AWS.
+        """
         return (
             "Amazon ECR requires you to create a repository before you can "
             "push an image to it. If you want to for example run a pipeline "
             "using our Kubeflow orchestrator, ZenML will automatically build a "
             f"docker image called `{self.uri}/zenml-kubeflow:<PIPELINE_NAME>` "
             f"and try to push it. This will fail unless you create the "
             f"repository `zenml-kubeflow` inside your amazon registry."
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/secret_schemas/__init__.py` & `zenml-0.9.0/src/zenml/secrets_managers/local/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,17 +7,8 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Secret Schema
-
-...
-"""
-from zenml.integrations.aws.secret_schemas.aws_secret_schema import (
-    AWSSecretSchema,
-)
-
-__all__ = ["AWSSecretSchema"]
+"""Initialization of the ZenML local secrets manager."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/secret_schemas/aws_secret_schema.py` & `zenml-0.9.0/src/zenml/integrations/gcp/secrets_manager/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,23 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from typing import ClassVar, Optional
+"""ZenML integration for GCP Secrets Manager.
 
-from zenml.secret import register_secret_schema_class
-from zenml.secret.base_secret import BaseSecretSchema
+The GCP Secrets Manager allows your pipeline to directly access the GCP
+secrets manager and use the secrets within during runtime.
+"""
+from zenml.integrations.gcp.secrets_manager.gcp_secrets_manager import (
+    GCPSecretsManager,
+)
 
-AWS_SECRET_SCHEMA_TYPE = "aws"
-
-
-@register_secret_schema_class
-class AWSSecretSchema(BaseSecretSchema):
-
-    TYPE: ClassVar[str] = AWS_SECRET_SCHEMA_TYPE
-
-    aws_access_key_id: str
-    aws_secret_access_key: str
-    aws_session_token: Optional[str]
+__all__ = ["GCPSecretsManager"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/secrets_managers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/gcp/orchestrators/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,18 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Secret Manager
+"""Initialization for the VertexAI orchestrator."""
 
-...
-"""
-from zenml.integrations.aws.secrets_managers.aws_secrets_manager import (
-    AWSSecretsManager,
+from zenml.integrations.gcp.orchestrators.vertex_orchestrator import (  # noqa
+    VertexOrchestrator,
 )
-
-__all__ = ["AWSSecretsManager"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/aws/secrets_managers/aws_secrets_manager.py` & `zenml-0.9.0/src/zenml/integrations/aws/secrets_managers/aws_secrets_manager.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,35 +7,39 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the AWS Secrets Manager integration."""
+
 import json
 from typing import Any, ClassVar, Dict, List
 
 import boto3
 
+from zenml.exceptions import SecretExistsError
 from zenml.integrations.aws import AWS_SECRET_MANAGER_FLAVOR
 from zenml.logger import get_logger
 from zenml.secret.base_secret import BaseSecretSchema
 from zenml.secret.secret_schema_class_registry import SecretSchemaClassRegistry
 from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
 
 logger = get_logger(__name__)
 
 DEFAULT_AWS_REGION = "us-east-1"
 ZENML_SCHEMA_NAME = "zenml_schema_name"
 
 
 def jsonify_secret_contents(secret: BaseSecretSchema) -> str:
-    """Adds the secret type to the secret contents to persist the schema
-    type in the secrets backend, so that the correct SecretSchema can be
-    retrieved when the secret is queried from the backend.
+    """Adds the secret type to the secret contents.
+
+    This persists the schema type in the secrets backend, so that the correct
+    SecretSchema can be retrieved when the secret is queried from the backend.
 
     Args:
         secret: should be a subclass of the BaseSecretSchema class
 
     Returns:
         jsonified dictionary containing all key-value pairs and the ZenML schema
         type
@@ -52,45 +56,59 @@
 
     # Class configuration
     FLAVOR: ClassVar[str] = AWS_SECRET_MANAGER_FLAVOR
     CLIENT: ClassVar[Any] = None
 
     @classmethod
     def _ensure_client_connected(cls, region_name: str) -> None:
+        """Ensure that the client is connected to the AWS secrets manager.
+
+        Args:
+            region_name: the AWS region name
+        """
         if cls.CLIENT is None:
             # Create a Secrets Manager client
             session = boto3.session.Session()
             cls.CLIENT = session.client(
                 service_name="secretsmanager", region_name=region_name
             )
 
     def register_secret(self, secret: BaseSecretSchema) -> None:
         """Registers a new secret.
 
         Args:
-            secret: the secret to register"""
+            secret: the secret to register
+
+        Raises:
+            SecretExistsError: if the secret already exists
+        """
         self._ensure_client_connected(self.region_name)
         secret_value = jsonify_secret_contents(secret)
 
+        if secret.name in self.get_all_secret_keys():
+            raise SecretExistsError(
+                f"A Secret with the name {secret.name} already exists"
+            )
+
         kwargs = {"Name": secret.name, "SecretString": secret_value}
-        # TODO [ENG-872]: Catch error if secret name already exists and use
-        #  SecretExistsError instead.
+
         self.CLIENT.create_secret(**kwargs)
 
     def get_secret(self, secret_name: str) -> BaseSecretSchema:
         """Gets a secret.
 
         Args:
             secret_name: the name of the secret to get
 
         Returns:
             The secret.
 
         Raises:
-            RuntimeError: if the secret does not exist"""
+            RuntimeError: if the secret does not exist
+        """
         self._ensure_client_connected(self.region_name)
         get_secret_value_response = self.CLIENT.get_secret_value(
             SecretId=secret_name
         )
         if "SecretString" not in get_secret_value_response:
             raise RuntimeError(f"No secrets found within the {secret_name}")
         secret_contents: Dict[str, str] = json.loads(
@@ -105,49 +123,53 @@
         )
         return secret_schema(**secret_contents)
 
     def get_all_secret_keys(self) -> List[str]:
         """Get all secret keys.
 
         Returns:
-            A list of all secret keys."""
+            A list of all secret keys
+        """
         self._ensure_client_connected(self.region_name)
 
         # TODO [ENG-720]: Deal with pagination in the aws secret manager when
         #  listing all secrets
         # TODO [ENG-721]: take out this magic maxresults number
         response = self.CLIENT.list_secrets(MaxResults=100)
         return [secret["Name"] for secret in response["SecretList"]]
 
     def update_secret(self, secret: BaseSecretSchema) -> None:
         """Update an existing secret.
 
         Args:
-            secret: the secret to update"""
+            secret: the secret to update
+        """
         self._ensure_client_connected(self.region_name)
 
         secret_value = jsonify_secret_contents(secret)
 
         kwargs = {"SecretId": secret.name, "SecretString": secret_value}
 
         self.CLIENT.put_secret_value(**kwargs)
 
     def delete_secret(self, secret_name: str) -> None:
         """Delete an existing secret.
 
         Args:
-            secret_name: the name of the secret to delete"""
+            secret_name: the name of the secret to delete
+        """
         self._ensure_client_connected(self.region_name)
         self.CLIENT.delete_secret(
             SecretId=secret_name, ForceDeleteWithoutRecovery=False
         )
 
     def delete_all_secrets(self, force: bool = False) -> None:
         """Delete all existing secrets.
 
         Args:
-            force: whether to force delete all secrets"""
+            force: whether to force delete all secrets
+        """
         self._ensure_client_connected(self.region_name)
         for secret_name in self.get_all_secret_keys():
             self.CLIENT.delete_secret(
                 SecretId=secret_name, ForceDeleteWithoutRecovery=force
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azure/__init__.py` & `zenml-0.9.0/src/zenml/integrations/s3/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,42 +7,46 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The Azure integration submodule provides a way to run ZenML pipelines in a cloud
-environment. Specifically, it allows the use of cloud artifact stores,
-and an `io` module to handle file operations on Azure Blob Storage.
+"""Initialization of the S3 integration.
+
+The S3 integration allows the use of cloud artifact stores and file
+operations on S3 buckets.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
-from zenml.integrations.constants import AZURE
+from zenml.integrations.constants import S3
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
 
-AZURE_ARTIFACT_STORE_FLAVOR = "azure"
+S3_ARTIFACT_STORE_FLAVOR = "s3"
 
 
-class AzureIntegration(Integration):
-    """Definition of Azure integration for ZenML."""
+class S3Integration(Integration):
+    """Definition of S3 integration for ZenML."""
 
-    NAME = AZURE
-    REQUIREMENTS = ["adlfs==2021.10.0"]
+    NAME = S3
+    REQUIREMENTS = ["s3fs==2022.3.0"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declares the flavors for the integration."""
+        """Declare the stack component flavors for the s3 integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
-                name=AZURE_ARTIFACT_STORE_FLAVOR,
-                source="zenml.integrations.azure.artifact_stores.AzureArtifactStore",
+                name=S3_ARTIFACT_STORE_FLAVOR,
+                source="zenml.integrations.s3.artifact_stores.S3ArtifactStore",
                 type=StackComponentType.ARTIFACT_STORE,
                 integration=cls.NAME,
             )
         ]
 
 
-AzureIntegration.check_installation()
+S3Integration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azure/artifact_stores/__init__.py` & `zenml-0.9.0/src/zenml/integrations/s3/artifact_stores/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the S3 Artifact Store."""
 
-from zenml.integrations.azure.artifact_stores.azure_artifact_store import (  # noqa
-    AzureArtifactStore,
+from zenml.integrations.s3.artifact_stores.s3_artifact_store import (  # noqa
+    S3ArtifactStore,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azure/artifact_stores/azure_artifact_store.py` & `zenml-0.9.0/src/zenml/integrations/gcp/artifact_stores/gcp_artifact_store.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,222 +1,244 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the GCP Artifact Store."""
 
 from typing import (
     Any,
     Callable,
     ClassVar,
     Dict,
     Iterable,
     List,
     Optional,
     Set,
     Tuple,
     Union,
-    cast,
 )
 
-import adlfs
+import gcsfs
 
 from zenml.artifact_stores import BaseArtifactStore
-from zenml.integrations.azure import AZURE_ARTIFACT_STORE_FLAVOR
-from zenml.io.utils import convert_to_str
+from zenml.integrations.gcp import GCP_ARTIFACT_STORE_FLAVOR
+from zenml.secret.schemas import GCPSecretSchema
+from zenml.stack.authentication_mixin import AuthenticationMixin
+from zenml.utils.io_utils import convert_to_str
 
 PathType = Union[bytes, str]
 
 
-class AzureArtifactStore(BaseArtifactStore):
-    """Artifact Store for Microsoft Azure based artifacts."""
+class GCPArtifactStore(BaseArtifactStore, AuthenticationMixin):
+    """Artifact Store for Google Cloud Storage based artifacts."""
 
-    _filesystem: Optional[adlfs.AzureBlobFileSystem] = None
+    _filesystem: Optional[gcsfs.GCSFileSystem] = None
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = AZURE_ARTIFACT_STORE_FLAVOR
-    SUPPORTED_SCHEMES: ClassVar[Set[str]] = {"abfs://", "az://"}
+    FLAVOR: ClassVar[str] = GCP_ARTIFACT_STORE_FLAVOR
+    SUPPORTED_SCHEMES: ClassVar[Set[str]] = {"gs://"}
 
     @property
-    def filesystem(self) -> adlfs.AzureBlobFileSystem:
-        """The adlfs filesystem to access this artifact store."""
+    def filesystem(self) -> gcsfs.GCSFileSystem:
+        """The gcsfs filesystem to access this artifact store.
+
+        Returns:
+            The gcsfs filesystem to access this artifact store.
+        """
         if not self._filesystem:
-            self._filesystem = adlfs.AzureBlobFileSystem(
-                anon=False,
-                use_listings_cache=False,
+            secret = self.get_authentication_secret(
+                expected_schema_type=GCPSecretSchema
             )
-        return self._filesystem
+            token = secret.get_credential_dict() if secret else None
+            self._filesystem = gcsfs.GCSFileSystem(token=token)
 
-    @classmethod
-    def _split_path(cls, path: PathType) -> Tuple[str, str]:
-        """Splits a path into the filesystem prefix and remainder.
-
-        Example:
-        ```python
-        prefix, remainder = ZenAzure._split_path("az://my_container/test.txt")
-        print(prefix, remainder)  # "az://" "my_container/test.txt"
-        ```
-        """
-        path = convert_to_str(path)
-        prefix = ""
-        for potential_prefix in cls.SUPPORTED_SCHEMES:
-            if path.startswith(potential_prefix):
-                prefix = potential_prefix
-                path = path[len(potential_prefix) :]
-                break
-
-        return prefix, path
+        return self._filesystem
 
     def open(self, path: PathType, mode: str = "r") -> Any:
         """Open a file at the given path.
+
         Args:
             path: Path of the file to open.
             mode: Mode in which to open the file. Currently, only
                 'rb' and 'wb' to read and write binary files are supported.
+
+        Returns:
+            A file-like object that can be used to read or write to the file.
         """
         return self.filesystem.open(path=path, mode=mode)
 
     def copyfile(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Copy a file.
+
         Args:
             src: The path to copy from.
             dst: The path to copy to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to copy to destination '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to copy anyway."
             )
-
         # TODO [ENG-151]: Check if it works with overwrite=True or if we need to
         #  manually remove it first
         self.filesystem.copy(path1=src, path2=dst)
 
     def exists(self, path: PathType) -> bool:
-        """Check whether a path exists."""
+        """Check whether a path exists.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path exists, False otherwise.
+        """
         return self.filesystem.exists(path=path)  # type: ignore[no-any-return]
 
     def glob(self, pattern: PathType) -> List[PathType]:
         """Return all paths that match the given glob pattern.
+
         The glob pattern may include:
         - '*' to match any number of characters
         - '?' to match a single character
         - '[...]' to match one of the characters inside the brackets
         - '**' as the full name of a path component to match to search
           in subdirectories of any depth (e.g. '/some_dir/**/some_file)
+
         Args:
             pattern: The glob pattern to match, see details above.
+
         Returns:
             A list of paths that match the given glob pattern.
         """
-        prefix, _ = self._split_path(pattern)
-        return [
-            f"{prefix}{path}" for path in self.filesystem.glob(path=pattern)
-        ]
+        return self.filesystem.glob(path=pattern)  # type: ignore[no-any-return]
 
     def isdir(self, path: PathType) -> bool:
-        """Check whether a path is a directory."""
+        """Check whether a path is a directory.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path is a directory, False otherwise.
+        """
         return self.filesystem.isdir(path=path)  # type: ignore[no-any-return]
 
     def listdir(self, path: PathType) -> List[PathType]:
-        """Return a list of files in a directory."""
-        _, path = self._split_path(path)
+        """Return a list of files in a directory.
 
-        def _extract_basename(file_dict: Dict[str, Any]) -> str:
-            """Extracts the basename from a file info dict returned by the Azure
-            filesystem."""
-            file_path = cast(str, file_dict["name"])
-            base_name = file_path[len(path) :]
-            return base_name.lstrip("/")
-
-        return [
-            _extract_basename(dict_)
-            for dict_ in self.filesystem.listdir(path=path)
-        ]
+        Args:
+            path: The path of the directory to list.
+
+        Returns:
+            A list of paths of files in the directory.
+        """
+        return self.filesystem.listdir(path=path)  # type: ignore[no-any-return]
 
     def makedirs(self, path: PathType) -> None:
-        """Create a directory at the given path. If needed also
-        create missing parent directories."""
+        """Create a directory at the given path.
+
+        If needed also create missing parent directories.
+
+        Args:
+            path: The path of the directory to create.
+        """
         self.filesystem.makedirs(path=path, exist_ok=True)
 
     def mkdir(self, path: PathType) -> None:
-        """Create a directory at the given path."""
+        """Create a directory at the given path.
+
+        Args:
+            path: The path of the directory to create.
+        """
         self.filesystem.makedir(path=path)
 
     def remove(self, path: PathType) -> None:
-        """Remove the file at the given path."""
+        """Remove the file at the given path.
+
+        Args:
+            path: The path of the file to remove.
+        """
         self.filesystem.rm_file(path=path)
 
     def rename(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Rename source file to destination file.
+
         Args:
             src: The path of the file to rename.
             dst: The path to rename the source file to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to rename file to '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to rename anyway."
             )
 
         # TODO [ENG-152]: Check if it works with overwrite=True or if we need
         #  to manually remove it first
         self.filesystem.rename(path1=src, path2=dst)
 
     def rmtree(self, path: PathType) -> None:
-        """Remove the given directory."""
+        """Remove the given directory.
+
+        Args:
+            path: The path of the directory to remove.
+        """
         self.filesystem.delete(path=path, recursive=True)
 
     def stat(self, path: PathType) -> Dict[str, Any]:
-        """Return stat info for the given path."""
+        """Return stat info for the given path.
+
+        Args:
+            path: the path to get stat info for.
+
+        Returns:
+            A dictionary with the stat info.
+        """
         return self.filesystem.stat(path=path)  # type: ignore[no-any-return]
 
     def walk(
         self,
         top: PathType,
         topdown: bool = True,
         onerror: Optional[Callable[..., None]] = None,
     ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:
         """Return an iterator that walks the contents of the given directory.
+
         Args:
             top: Path of directory to walk.
             topdown: Unused argument to conform to interface.
             onerror: Unused argument to conform to interface.
+
         Returns:
             An Iterable of Tuples, each of which contain the path of the current
             directory path, a list of directories inside the current directory
             and a list of files inside the current directory.
         """
         # TODO [ENG-153]: Additional params
-        prefix, _ = self._split_path(top)
-        for (
-            directory,
-            subdirectories,
-            files,
-        ) in self.filesystem.walk(path=top):
-            yield f"{prefix}{directory}", subdirectories, files
+        return self.filesystem.walk(path=top)  # type: ignore[no-any-return]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azureml/__init__.py` & `zenml-0.9.0/src/zenml/integrations/seldon/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,40 +7,54 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The AzureML integration submodule provides a way to run ZenML steps in AzureML.
+"""Initialization of the Seldon integration.
+
+The Seldon Core integration allows you to use the Seldon Core model serving
+platform to implement continuous model deployment.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
-from zenml.integrations.constants import AZUREML
+from zenml.integrations.constants import SELDON
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
 
-AZUREML_STEP_OPERATOR_FLAVOR = "azureml"
+SELDON_MODEL_DEPLOYER_FLAVOR = "seldon"
 
 
-class AzureMLIntegration(Integration):
-    """Definition of AzureML integration for ZenML."""
+class SeldonIntegration(Integration):
+    """Definition of Seldon Core integration for ZenML."""
 
-    NAME = AZUREML
-    REQUIREMENTS = ["azureml-core==1.39.0.post1"]
+    NAME = SELDON
+    REQUIREMENTS = [
+        "kubernetes==18.20.0",
+    ]
+
+    @classmethod
+    def activate(cls) -> None:
+        """Activate the Seldon Core integration."""
+        from zenml.integrations.seldon import secret_schemas  # noqa
+        from zenml.integrations.seldon import services  # noqa
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the AzureML integration."""
+        """Declare the stack component flavors for the Seldon Core.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
-                name=AZUREML_STEP_OPERATOR_FLAVOR,
-                source="zenml.integrations.azureml.step_operators.AzureMLStepOperator",
-                type=StackComponentType.STEP_OPERATOR,
+                name=SELDON_MODEL_DEPLOYER_FLAVOR,
+                source="zenml.integrations.seldon.model_deployers.SeldonModelDeployer",
+                type=StackComponentType.MODEL_DEPLOYER,
                 integration=cls.NAME,
             )
         ]
 
 
-AzureMLIntegration.check_installation()
+SeldonIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azureml/step_operators/__init__.py` & `zenml-0.9.0/src/zenml/integrations/gcp/step_operators/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for the VertexAI Step Operator."""
 
-from zenml.integrations.azureml.step_operators.azureml_step_operator import (  # noqa
-    AzureMLStepOperator,
+from zenml.integrations.gcp.step_operators.vertex_step_operator import (  # noqa
+    VertexStepOperator,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/azureml/step_operators/azureml_step_operator.py` & `zenml-0.9.0/src/zenml/integrations/azure/step_operators/azureml_step_operator.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML AzureML Step Operator."""
 
 import os
 from typing import ClassVar, List, Optional
 
 from azureml.core import (
     ComputeTarget,
     Environment,
@@ -27,15 +28,15 @@
     ServicePrincipalAuthentication,
 )
 from azureml.core.conda_dependencies import CondaDependencies
 
 from zenml.config.global_config import GlobalConfiguration
 from zenml.constants import ENV_ZENML_CONFIG_PATH
 from zenml.environment import Environment as ZenMLEnvironment
-from zenml.integrations.azureml import AZUREML_STEP_OPERATOR_FLAVOR
+from zenml.integrations.azure import AZUREML_STEP_OPERATOR_FLAVOR
 from zenml.io import fileio
 from zenml.step_operators import BaseStepOperator
 from zenml.utils.docker_utils import CONTAINER_ZENML_CONFIG_DIR
 from zenml.utils.source_utils import get_source_root_path
 
 
 class AzureMLStepOperator(BaseStepOperator):
@@ -77,14 +78,19 @@
     service_principal_id: Optional[str] = None
     service_principal_password: Optional[str] = None
 
     # Class Configuration
     FLAVOR: ClassVar[str] = AZUREML_STEP_OPERATOR_FLAVOR
 
     def _get_authentication(self) -> Optional[AbstractAuthentication]:
+        """Returns the authentication object for the AzureML environment.
+
+        Returns:
+            The authentication object for the AzureML environment.
+        """
         if (
             self.tenant_id
             and self.service_principal_id
             and self.service_principal_password
         ):
             return ServicePrincipalAuthentication(
                 tenant_id=self.tenant_id,
@@ -102,14 +108,17 @@
             workspace: The AzureML Workspace that has configuration
                 for a storage account, container registry among other
                 things.
             requirements: The list of requirements to be installed
                 in the environment.
             run_name: The name of the pipeline run that can be used
                 for naming environments and runs.
+
+        Returns:
+            The AzureML Environment object.
         """
         if self.environment_name:
             environment = Environment.get(
                 workspace=workspace, name=self.environment_name
             )
             if not environment.python.conda_dependencies:
                 environment.python.conda_dependencies = (
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/constants.py` & `zenml-0.9.0/src/zenml/integrations/constants.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,37 +7,40 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Constants for ZenML integrations."""
 
 AIRFLOW = "airflow"
 AWS = "aws"
 AZURE = "azure"
 AZUREML = "azureml"
 DASH = "dash"
 EVIDENTLY = "evidently"
 FACETS = "facets"
 FEAST = "feast"
 GCP = "gcp"
 GCP_SECRETS_MANAGER = "gcp_secrets_manager"
+GITHUB = "github"
 GRAPHVIZ = "graphviz"
 KUBEFLOW = "kubeflow"
 LIGHTGBM = "lightgbm"
 MLFLOW = "mlflow"
 PLOTLY = "plotly"
 PYTORCH = "pytorch"
 PYTORCH_L = "pytorch_lightning"
 S3 = "s3"
 SAGEMAKER = "sagemaker"
 SCIPY = "scipy"
 SELDON = "seldon"
 SKLEARN = "sklearn"
+SLACK = "slack"
 TENSORFLOW = "tensorflow"
 VAULT = "vault"
 WHYLOGS = "whylogs"
 WANDB = "wandb"
 VERTEX = "vertex"
 NEURAL_PROPHET = "neural_prophet"
 HUGGINGFACE = "huggingface"
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/dash/__init__.py` & `zenml-0.9.0/src/zenml/integrations/dash/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Dash integration."""
+
 from zenml.integrations.constants import DASH
 from zenml.integrations.integration import Integration
 
 
 class DashIntegration(Integration):
     """Definition of Dash integration for ZenML."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/dash/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/services/local/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of a local ZenML service."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/dash/visualizers/pipeline_run_lineage_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/dash/visualizers/pipeline_run_lineage_visualizer.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,23 +7,25 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the pipeline run lineage visualizer."""
 
 from typing import Any, Collection, Dict, List, Union
 
 import dash
 import dash_bootstrap_components as dbc
 import dash_cytoscape as cyto
 from dash import dcc, html
 from dash.dependencies import Input, Output
 
+from zenml.cli import utils as cli_utils
 from zenml.enums import ExecutionStatus
 from zenml.environment import Environment
 from zenml.logger import get_logger
 from zenml.post_execution import PipelineRunView
 from zenml.visualizers import BasePipelineRunVisualizer
 
 logger = get_logger(__name__)
@@ -92,17 +94,15 @@
     },
     {"selector": ".solid", "style": {"line-style": "solid"}},
     {"selector": ".dashed", "style": {"line-style": "dashed"}},
 ]
 
 
 class PipelineRunLineageVisualizer(BasePipelineRunVisualizer):
-    """Implementation of a lineage diagram via the [dash](
-    https://plotly.com/dash/) and [dash-cyctoscape](
-    https://dash.plotly.com/cytoscape) library."""
+    """Implementation of a lineage diagram via the dash and dash-cytoscape libraries."""
 
     ARTIFACT_PREFIX = "artifact_"
     STEP_PREFIX = "step_"
     STATUS_CLASS_MAPPING = {
         ExecutionStatus.CACHED: "green",
         ExecutionStatus.FAILED: "red",
         ExecutionStatus.RUNNING: "yellow",
@@ -112,16 +112,26 @@
     def visualize(
         self,
         object: PipelineRunView,
         magic: bool = False,
         *args: Any,
         **kwargs: Any,
     ) -> dash.Dash:
-        """Method to visualize pipeline runs via the Dash library. The layout
-        puts every layer of the dag in a column.
+        """Method to visualize pipeline runs via the Dash library.
+
+        The layout puts every layer of the dag in a column.
+
+        Args:
+            object: The pipeline run to visualize.
+            magic: If True, the visualization is rendered in a magic mode.
+            *args: Additional positional arguments.
+            **kwargs: Additional keyword arguments.
+
+        Returns:
+            The Dash application.
         """
         external_stylesheets = [
             dbc.themes.BOOTSTRAP,
             dbc.icons.BOOTSTRAP,
         ]
         if magic:
             if Environment.in_notebook:
@@ -132,16 +142,15 @@
 
                 app = JupyterDash(
                     __name__,
                     external_stylesheets=external_stylesheets,
                 )
                 mode = "inline"
             else:
-                # TODO [ENG-895]: Refactor this to raise a warning instead.
-                raise AssertionError(
+                cli_utils.warning(
                     "Cannot set magic flag in non-notebook environments."
                 )
         else:
             app = dash.Dash(
                 __name__,
                 external_stylesheets=external_stylesheets,
             )
@@ -319,15 +328,22 @@
         )
 
         @app.callback(  # type: ignore[misc]
             Output("markdown-selected-node-data", "children"),
             Input("cytoscape", "selectedNodeData"),
         )
         def display_data(data_list: List[Dict[str, Any]]) -> str:
-            """Callback for the text area below the graph"""
+            """Callback for the text area below the graph.
+
+            Args:
+                data_list: The selected node data.
+
+            Returns:
+                str: The selected node data.
+            """
             if data_list is None:
                 return "Click on a node in the diagram."
 
             text = ""
             for data in data_list:
                 text += f'## {data["execution_id"]} / {data["name"]}' + "\n\n"
                 if data["type"] == "artifact":
@@ -354,15 +370,22 @@
         @app.callback(  # type: ignore[misc]
             [Output("cytoscape", "zoom"), Output("cytoscape", "elements")],
             [Input("bt-reset", "n_clicks")],
         )
         def reset_layout(
             n_clicks: int,
         ) -> List[Union[int, List[Dict[str, Collection[str]]]]]:
-            """Resets the layout"""
+            """Resets the layout.
+
+            Args:
+                n_clicks: The number of clicks on the reset button.
+
+            Returns:
+                The zoom and the elements.
+            """
             logger.debug(n_clicks, "clicked in reset button.")
             return [1, edges + nodes]
 
         if mode is not None:
             app.run_server(mode=mode)
         app.run_server()
         return app
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/evidently/__init__.py` & `zenml-0.9.0/src/zenml/integrations/evidently/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,30 +7,30 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of the Evidently integration.
+
 The Evidently integration provides a way to monitor your models in production.
 It includes a way to detect data drift and different kinds of model performance
 issues.
 
 The results of Evidently calculations can either be exported as an interactive
 dashboard (visualized as an html file or in your Jupyter notebook), or as a JSON
 file.
 """
 
 from zenml.integrations.constants import EVIDENTLY
 from zenml.integrations.integration import Integration
 
 
 class EvidentlyIntegration(Integration):
-    """Definition of [Evidently](https://github.com/evidentlyai/evidently) integration
-    for ZenML."""
+    """[Evidently](https://github.com/evidentlyai/evidently) integration for ZenML."""
 
     NAME = EVIDENTLY
     REQUIREMENTS = ["evidently==v0.1.41.dev0"]
 
 
 EvidentlyIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/evidently/steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/evidently/steps/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,12 +7,13 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Evidently Standard Steps."""
 
 from zenml.integrations.evidently.steps.evidently_profile import (
     EvidentlyProfileConfig,
     EvidentlyProfileStep,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/evidently/steps/evidently_profile.py` & `zenml-0.9.0/src/zenml/integrations/evidently/steps/evidently_profile.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Evidently Profile Step."""
+
 from typing import List, Optional, Sequence, Tuple
 
 import pandas as pd
 from evidently.dashboard import Dashboard  # type: ignore
 from evidently.dashboard.tabs import (  # type: ignore
     CatTargetDriftTab,
     ClassificationPerformanceTab,
@@ -63,28 +65,36 @@
     "probabilisticmodelperformance": ProbClassificationPerformanceTab,
 }
 
 
 class EvidentlyProfileConfig(BaseDriftDetectionConfig):
     """Config class for Evidently profile steps.
 
-    column_mapping: properties of the dataframe's columns used
+    column_mapping: properties of the DataFrame's columns used
     profile_section: a string that identifies the profile section to be used.
         The following are valid options supported by Evidently:
         - "datadrift"
         - "categoricaltargetdrift"
         - "numericaltargetdrift"
         - "classificationmodelperformance"
         - "regressionmodelperformance"
         - "probabilisticmodelperformance"
     """
 
     def get_profile_sections_and_tabs(
         self,
     ) -> Tuple[List[ProfileSection], List[Tab]]:
+        """Get the profile sections and tabs to be used in the dashboard.
+
+        Returns:
+            A tuple of two lists of profile sections and tabs.
+
+        Raises:
+            ValueError: if the profile_section is not supported.
+        """
         try:
             return (
                 [
                     profile_mapper[profile]()
                     for profile in self.profile_sections
                 ],
                 [
@@ -101,36 +111,34 @@
             )
 
     column_mapping: Optional[ColumnMapping]
     profile_sections: Sequence[str]
 
 
 class EvidentlyProfileStep(BaseDriftDetectionStep):
-    """Simple step implementation which implements Evidently's functionality for
-    creating a profile."""
+    """Step implementation implementing an Evidently Profile Step."""
 
     OUTPUT_SPEC = {
         "profile": DataAnalysisArtifact,
         "dashboard": DataAnalysisArtifact,
     }
 
     def entrypoint(  # type: ignore[override]
         self,
         reference_dataset: pd.DataFrame,
         comparison_dataset: pd.DataFrame,
         config: EvidentlyProfileConfig,
     ) -> Output(  # type:ignore[valid-type]
         profile=dict, dashboard=str
     ):
-        """Main entrypoint for the Evidently categorical target drift detection
-        step.
+        """Main entrypoint for the Evidently categorical target drift detection step.
 
         Args:
-            reference_dataset: a Pandas dataframe
-            comparison_dataset: a Pandas dataframe of new data you wish to
+            reference_dataset: a Pandas DataFrame
+            comparison_dataset: a Pandas DataFrame of new data you wish to
                 compare against the reference data
             config: the configuration for the step
 
         Returns:
             profile: dictionary report extracted from an Evidently Profile
               generated for the data drift
             dashboard: HTML report extracted from an Evidently Dashboard
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/evidently/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/evidently/visualizers/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for Evidently visualizer."""
 
 from zenml.integrations.evidently.visualizers.evidently_visualizer import (
     EvidentlyVisualizer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/evidently/visualizers/evidently_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/evidently/visualizers/evidently_visualizer.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Evidently visualizer."""
 
 import tempfile
 import webbrowser
 from abc import abstractmethod
 from typing import Any
 
 from zenml.artifacts import DataAnalysisArtifact
@@ -27,30 +28,32 @@
 
 
 class EvidentlyVisualizer(BaseStepVisualizer):
     """The implementation of an Evidently Visualizer."""
 
     @abstractmethod
     def visualize(self, object: StepView, *args: Any, **kwargs: Any) -> None:
-        """Method to visualize components
+        """Method to visualize components.
 
         Args:
             object: StepView fetched from run.get_step().
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
         """
         for artifact_view in object.outputs.values():
             # filter out anything but data analysis artifacts
             if (
                 artifact_view.type == DataAnalysisArtifact.__name__
                 and artifact_view.data_type == "builtins.str"
             ):
                 artifact = artifact_view.read()
                 self.generate_facet(artifact)
 
     def generate_facet(self, html_: str) -> None:
-        """Generate a Facet Overview
+        """Generate a Facet Overview.
 
         Args:
             html_: HTML represented as a string.
         """
         if Environment.in_notebook() or Environment.in_google_colab():
             from IPython.core.display import HTML, display
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/facets/__init__.py` & `zenml-0.9.0/src/zenml/integrations/facets/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,27 +7,27 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Facets integration for ZenML.
+
 The Facets integration provides a simple way to visualize post-execution objects
 like `PipelineView`, `PipelineRunView` and `StepView`. These objects can be
 extended using the `BaseVisualization` class. This integration requires
 `facets-overview` be installed in your Python environment.
 """
 
 from zenml.integrations.constants import FACETS
 from zenml.integrations.integration import Integration
 
 
 class FacetsIntegration(Integration):
-    """Definition of [Facet](https://pair-code.github.io/facets/) integration
-    for ZenML."""
+    """Definition of [Facet](https://pair-code.github.io/facets/) integration for ZenML."""
 
     NAME = FACETS
     REQUIREMENTS = ["facets-overview>=1.0.0", "IPython"]
 
 
 FacetsIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/orchestrators/local/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for the local orchestrator."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/facet_statistics_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/facets/visualizers/facet_statistics_visualizer.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,99 +7,105 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Facet Statistics Visualizer."""
 
 import base64
 import os
 import tempfile
 import webbrowser
 from abc import abstractmethod
 from typing import Any, Dict, List, Text
 
 import pandas as pd
 from facets_overview.generic_feature_statistics_generator import (
     GenericFeatureStatisticsGenerator,
 )
 from IPython.core.display import HTML, display
 
-import zenml.io.utils
 from zenml.environment import Environment
 from zenml.logger import get_logger
 from zenml.post_execution import StepView
+from zenml.utils import io_utils
 from zenml.visualizers import BaseStepVisualizer
 
 logger = get_logger(__name__)
 
 
 class FacetStatisticsVisualizer(BaseStepVisualizer):
     """The base implementation of a ZenML Visualizer."""
 
     @abstractmethod
     def visualize(
         self, object: StepView, magic: bool = False, *args: Any, **kwargs: Any
     ) -> None:
-        """Method to visualize components
+        """Method to visualize components.
 
         Args:
             object: StepView fetched from run.get_step().
             magic: Whether to render in a Jupyter notebook or not.
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
         """
         datasets = []
         for output_name, artifact_view in object.outputs.items():
             df = artifact_view.read()
             if type(df) is not pd.DataFrame:
                 logger.warning(
                     "`%s` is not a pd.DataFrame. You can only visualize "
-                    "statistics of steps that output pandas dataframes. "
+                    "statistics of steps that output pandas DataFrames. "
                     "Skipping this output.." % output_name
                 )
             else:
                 datasets.append({"name": output_name, "table": df})
         h = self.generate_html(datasets)
         self.generate_facet(h, magic)
 
     def generate_html(self, datasets: List[Dict[Text, pd.DataFrame]]) -> str:
         """Generates html for facet.
 
         Args:
-            datasets: List of dicts of dataframes to be visualized as stats.
+            datasets: List of dicts of DataFrames to be visualized as stats.
 
         Returns:
             HTML template with proto string embedded.
         """
         proto = GenericFeatureStatisticsGenerator().ProtoFromDataFrames(
             datasets
         )
         protostr = base64.b64encode(proto.SerializeToString()).decode("utf-8")
 
         template = os.path.join(
             os.path.abspath(os.path.dirname(__file__)),
             "stats.html",
         )
-        html_template = zenml.io.utils.read_file_contents_as_string(template)
+        html_template = io_utils.read_file_contents_as_string(template)
 
         html_ = html_template.replace("protostr", protostr)
         return html_
 
     def generate_facet(self, html_: str, magic: bool = False) -> None:
-        """Generate a Facet Overview
+        """Generate a Facet Overview.
 
         Args:
             html_: HTML represented as a string.
             magic: Whether to magically materialize facet in a notebook.
+
+        Raises:
+            EnvironmentError: If magic is True and not in a notebook.
         """
         if magic:
             if not Environment.in_notebook() or Environment.in_google_colab():
                 raise EnvironmentError(
                     "The magic functions are only usable in a Jupyter notebook."
                 )
             display(HTML(html_))
         else:
             with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
-                zenml.io.utils.write_file_contents_as_string(f.name, html_)
+                io_utils.write_file_contents_as_string(f.name, html_)
                 url = f"file:///{f.name}"
                 logger.info("Opening %s in a new browser.." % f.name)
                 webbrowser.open(url, new=2)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/facets/visualizers/stats.html` & `zenml-0.9.0/src/zenml/integrations/facets/visualizers/stats.html`

 * *Files identical despite different names*

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/feast/__init__.py` & `zenml-0.9.0/src/zenml/integrations/feast/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization for Feast integration.
+
 The Feast integration offers a way to connect to a Feast Feature Store. ZenML
 implements a dedicated stack component that you can access as part of your ZenML
 steps in the usual ways.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
@@ -30,15 +31,19 @@
     """Definition of Feast integration for ZenML."""
 
     NAME = FEAST
     REQUIREMENTS = ["feast[redis]>=0.19.4", "redis-server"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Feast integration."""
+        """Declare the stack component flavors for the Feast integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
                 name=FEAST_FEATURE_STORE_FLAVOR,
                 source="zenml.integrations.feast.feature_store.FeastFeatureStore",
                 type=StackComponentType.FEATURE_STORE,
                 integration=cls.NAME,
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/feast/feature_stores/__init__.py` & `zenml-0.9.0/src/zenml/integrations/feast/feature_stores/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,16 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Feast Feature Store
+"""Feast Feature Store integration for ZenML.
 
 Feature stores allow data teams to serve data via an offline store and an online
 low-latency store where data is kept in sync between the two. It also offers a
 centralized registry where features (and feature schemas) are stored for use
 within a team or wider organization. Feature stores are a relatively recent
 addition to commonly-used machine learning stacks. Feast is a leading
 open-source feature store, first developed by Gojek in collaboration with
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/feast/feature_stores/feast_feature_store.py` & `zenml-0.9.0/src/zenml/integrations/feast/feature_stores/feast_feature_store.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Feast Feature Store for ZenML."""
 
 from typing import Any, ClassVar, Dict, List, Union
 
 import pandas as pd
 import redis
 from feast import FeatureStore  # type: ignore[import]
 from feast.registry import Registry  # type: ignore[import]
@@ -35,15 +36,15 @@
     online_port: int = 6379
     feast_repo: str
 
     def _validate_connection(self) -> None:
         """Validates the connection to the feature store.
 
         Raises:
-            RuntimeError: If the online component (Redis) is not available.
+            ConnectionError: If the online component (Redis) is not available.
         """
         client = redis.Redis(host=self.online_host, port=self.online_port)
         try:
             client.ping()
         except redis.exceptions.ConnectionError as e:
             raise redis.exceptions.ConnectionError(
                 "Could not connect to feature store's online component. "
@@ -55,15 +56,15 @@
         entity_df: Union[pd.DataFrame, str],
         features: List[str],
         full_feature_names: bool = False,
     ) -> pd.DataFrame:
         """Returns the historical features for training or batch scoring.
 
         Args:
-            entity_df: The entity dataframe or entity name.
+            entity_df: The entity DataFrame or entity name.
             features: The features to retrieve.
             full_feature_names: Whether to return the full feature names.
 
         Raise:
             ConnectionError: If the online component (Redis) is not available.
 
         Returns:
@@ -174,15 +175,15 @@
 
         Raise:
             ConnectionError: If the online component (Redis) is not available.
 
         Returns:
             The registry.
         """
-        fs = FeatureStore(repo_path=self.feast_repo)
+        fs: FeatureStore = FeatureStore(repo_path=self.feast_repo)
         return fs.registry
 
     def get_feast_version(self) -> str:
         """Returns the version of Feast used.
 
         Raise:
             ConnectionError: If the online component (Redis) is not available.
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp/__init__.py` & `zenml-0.9.0/src/zenml/integrations/wandb/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,44 +7,46 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The GCP integration submodule provides a way to run ZenML pipelines in a cloud
-environment. Specifically, it allows the use of cloud artifact stores, metadata
-stores, and an `io` module to handle file operations on Google Cloud Storage
-(GCS).
-"""
+"""Initialization for the wandb integration.
 
+The wandb integrations currently enables you to use wandb tracking as a
+convenient way to visualize your experiment runs within the wandb ui.
+"""
 from typing import List
 
 from zenml.enums import StackComponentType
-from zenml.integrations.constants import GCP
+from zenml.integrations.constants import WANDB
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
 
-GCP_ARTIFACT_STORE_FLAVOR = "gcp"
+WANDB_EXPERIMENT_TRACKER_FLAVOR = "wandb"
 
 
-class GcpIntegration(Integration):
-    """Definition of Google Cloud Platform integration for ZenML."""
+class WandbIntegration(Integration):
+    """Definition of Plotly integration for ZenML."""
 
-    NAME = GCP
-    REQUIREMENTS = ["gcsfs"]
+    NAME = WANDB
+    REQUIREMENTS = ["wandb>=0.12.12", "Pillow>=9.1.0"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the GCP integration."""
+        """Declare the stack component flavors for the Weights and Biases integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
-                name=GCP_ARTIFACT_STORE_FLAVOR,
-                source="zenml.integrations.gcp.artifact_stores.GCPArtifactStore",
-                type=StackComponentType.ARTIFACT_STORE,
+                name=WANDB_EXPERIMENT_TRACKER_FLAVOR,
+                source="zenml.integrations.wandb.experiment_trackers.WandbExperimentTracker",
+                type=StackComponentType.EXPERIMENT_TRACKER,
                 integration=cls.NAME,
             )
         ]
 
 
-GcpIntegration.check_installation()
+WandbIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp/artifact_stores/__init__.py` & `zenml-0.9.0/src/zenml/artifacts/constants.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,10 +7,11 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.gcp.artifact_stores.gcp_artifact_store import (  # noqa
-    GCPArtifactStore,
-)
+"""Constants for ZenML artifacts."""
+
+DATATYPE_PROPERTY_KEY = "datatype"
+MATERIALIZER_PROPERTY_KEY = "materializer"
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp/artifact_stores/gcp_artifact_store.py` & `zenml-0.9.0/src/zenml/integrations/azure/artifact_stores/azure_artifact_store.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,177 +1,303 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
+"""Implementation of the Azure Artifact Store integration."""
 
 from typing import (
     Any,
     Callable,
     ClassVar,
     Dict,
     Iterable,
     List,
     Optional,
     Set,
     Tuple,
     Union,
+    cast,
 )
 
-import gcsfs
+import adlfs
 
 from zenml.artifact_stores import BaseArtifactStore
-from zenml.integrations.gcp import GCP_ARTIFACT_STORE_FLAVOR
-from zenml.io.utils import convert_to_str
+from zenml.integrations.azure import AZURE_ARTIFACT_STORE_FLAVOR
+from zenml.secret.schemas import AzureSecretSchema
+from zenml.stack.authentication_mixin import AuthenticationMixin
+from zenml.utils.io_utils import convert_to_str
 
 PathType = Union[bytes, str]
 
 
-class GCPArtifactStore(BaseArtifactStore):
-    """Artifact Store for Google Cloud Storage based artifacts."""
+class AzureArtifactStore(BaseArtifactStore, AuthenticationMixin):
+    """Artifact Store for Microsoft Azure based artifacts."""
 
-    _filesystem: Optional[gcsfs.GCSFileSystem] = None
+    _filesystem: Optional[adlfs.AzureBlobFileSystem] = None
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = GCP_ARTIFACT_STORE_FLAVOR
-    SUPPORTED_SCHEMES: ClassVar[Set[str]] = {"gs://"}
+    FLAVOR: ClassVar[str] = AZURE_ARTIFACT_STORE_FLAVOR
+    SUPPORTED_SCHEMES: ClassVar[Set[str]] = {"abfs://", "az://"}
 
     @property
-    def filesystem(self) -> gcsfs.GCSFileSystem:
-        """The gcsfs filesystem to access this artifact store."""
+    def filesystem(self) -> adlfs.AzureBlobFileSystem:
+        """The adlfs filesystem to access this artifact store.
+
+        Returns:
+            The adlfs filesystem to access this artifact store.
+        """
         if not self._filesystem:
-            self._filesystem = gcsfs.GCSFileSystem()
+            secret = self.get_authentication_secret(
+                expected_schema_type=AzureSecretSchema
+            )
+            credentials = secret.content if secret else {}
+
+            self._filesystem = adlfs.AzureBlobFileSystem(
+                **credentials,
+                anon=False,
+                use_listings_cache=False,
+            )
         return self._filesystem
 
+    @classmethod
+    def _split_path(cls, path: PathType) -> Tuple[str, str]:
+        """Splits a path into the filesystem prefix and remainder.
+
+        Example:
+        ```python
+        prefix, remainder = ZenAzure._split_path("az://my_container/test.txt")
+        print(prefix, remainder)  # "az://" "my_container/test.txt"
+        ```
+
+        Args:
+            path: The path to split.
+
+        Returns:
+            A tuple of the filesystem prefix and the remainder.
+        """
+        path = convert_to_str(path)
+        prefix = ""
+        for potential_prefix in cls.SUPPORTED_SCHEMES:
+            if path.startswith(potential_prefix):
+                prefix = potential_prefix
+                path = path[len(potential_prefix) :]
+                break
+
+        return prefix, path
+
     def open(self, path: PathType, mode: str = "r") -> Any:
         """Open a file at the given path.
+
         Args:
             path: Path of the file to open.
             mode: Mode in which to open the file. Currently, only
                 'rb' and 'wb' to read and write binary files are supported.
+
+        Returns:
+            A file-like object.
         """
         return self.filesystem.open(path=path, mode=mode)
 
     def copyfile(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Copy a file.
+
         Args:
             src: The path to copy from.
             dst: The path to copy to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to copy to destination '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to copy anyway."
             )
+
         # TODO [ENG-151]: Check if it works with overwrite=True or if we need to
         #  manually remove it first
         self.filesystem.copy(path1=src, path2=dst)
 
     def exists(self, path: PathType) -> bool:
-        """Check whether a path exists."""
+        """Check whether a path exists.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path exists, False otherwise.
+        """
         return self.filesystem.exists(path=path)  # type: ignore[no-any-return]
 
     def glob(self, pattern: PathType) -> List[PathType]:
         """Return all paths that match the given glob pattern.
+
         The glob pattern may include:
         - '*' to match any number of characters
         - '?' to match a single character
         - '[...]' to match one of the characters inside the brackets
         - '**' as the full name of a path component to match to search
-          in subdirectories of any depth (e.g. '/some_dir/**/some_file)
+            in subdirectories of any depth (e.g. '/some_dir/**/some_file)
+
         Args:
             pattern: The glob pattern to match, see details above.
+
         Returns:
             A list of paths that match the given glob pattern.
         """
-        return self.filesystem.glob(path=pattern)  # type: ignore[no-any-return]
+        prefix, _ = self._split_path(pattern)
+        return [
+            f"{prefix}{path}" for path in self.filesystem.glob(path=pattern)
+        ]
 
     def isdir(self, path: PathType) -> bool:
-        """Check whether a path is a directory."""
+        """Check whether a path is a directory.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path is a directory, False otherwise.
+        """
         return self.filesystem.isdir(path=path)  # type: ignore[no-any-return]
 
     def listdir(self, path: PathType) -> List[PathType]:
-        """Return a list of files in a directory."""
-        return self.filesystem.listdir(path=path)  # type: ignore[no-any-return]
+        """Return a list of files in a directory.
+
+        Args:
+            path: The path to list.
+
+        Returns:
+            A list of files in the given directory.
+        """
+        _, path = self._split_path(path)
+
+        def _extract_basename(file_dict: Dict[str, Any]) -> str:
+            """Extracts the basename from a dictionary returned by the Azure filesystem.
+
+            Args:
+                file_dict: A dictionary returned by the Azure filesystem.
+
+            Returns:
+                The basename of the file.
+            """
+            file_path = cast(str, file_dict["name"])
+            base_name = file_path[len(path) :]
+            return base_name.lstrip("/")
+
+        return [
+            _extract_basename(dict_)
+            for dict_ in self.filesystem.listdir(path=path)
+        ]
 
     def makedirs(self, path: PathType) -> None:
-        """Create a directory at the given path. If needed also
-        create missing parent directories."""
+        """Create a directory at the given path.
+
+        If needed also create missing parent directories.
+
+        Args:
+            path: The path to create.
+        """
         self.filesystem.makedirs(path=path, exist_ok=True)
 
     def mkdir(self, path: PathType) -> None:
-        """Create a directory at the given path."""
+        """Create a directory at the given path.
+
+        Args:
+            path: The path to create.
+        """
         self.filesystem.makedir(path=path)
 
     def remove(self, path: PathType) -> None:
-        """Remove the file at the given path."""
+        """Remove the file at the given path.
+
+        Args:
+            path: The path to remove.
+        """
         self.filesystem.rm_file(path=path)
 
     def rename(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Rename source file to destination file.
+
         Args:
             src: The path of the file to rename.
             dst: The path to rename the source file to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to rename file to '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to rename anyway."
             )
 
         # TODO [ENG-152]: Check if it works with overwrite=True or if we need
         #  to manually remove it first
         self.filesystem.rename(path1=src, path2=dst)
 
     def rmtree(self, path: PathType) -> None:
-        """Remove the given directory."""
+        """Remove the given directory.
+
+        Args:
+            path: The path of the directory to remove.
+        """
         self.filesystem.delete(path=path, recursive=True)
 
     def stat(self, path: PathType) -> Dict[str, Any]:
-        """Return stat info for the given path."""
+        """Return stat info for the given path.
+
+        Args:
+            path: The path to get stat info for.
+
+        Returns:
+            Stat info.
+        """
         return self.filesystem.stat(path=path)  # type: ignore[no-any-return]
 
     def walk(
         self,
         top: PathType,
         topdown: bool = True,
         onerror: Optional[Callable[..., None]] = None,
     ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:
         """Return an iterator that walks the contents of the given directory.
+
         Args:
             top: Path of directory to walk.
             topdown: Unused argument to conform to interface.
             onerror: Unused argument to conform to interface.
-        Returns:
+
+        Yields:
             An Iterable of Tuples, each of which contain the path of the current
             directory path, a list of directories inside the current directory
             and a list of files inside the current directory.
         """
         # TODO [ENG-153]: Additional params
-        return self.filesystem.walk(path=top)  # type: ignore[no-any-return]
+        prefix, _ = self._split_path(top)
+        for (
+            directory,
+            subdirectories,
+            files,
+        ) in self.filesystem.walk(path=top):
+            yield f"{prefix}{directory}", subdirectories, files
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/__init__.py` & `zenml-0.9.0/src/zenml/integrations/pytorch/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,43 +7,27 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The GCP secrets manager integration submodule provides a way to access the gcp secrets manager
-from within you ZenML Pipeline runs.
-"""
-from typing import List
+"""Initialization of the PyTorch integration."""
 
-from zenml.enums import StackComponentType
-from zenml.integrations.constants import GCP_SECRETS_MANAGER
+from zenml.integrations.constants import PYTORCH
 from zenml.integrations.integration import Integration
-from zenml.zen_stores.models import FlavorWrapper
+from zenml.utils.source_utils import import_class_by_path
 
-GCP_SECRETS_MANAGER_FLAVOR = "gcp_secrets_manager"
 
+class PytorchIntegration(Integration):
+    """Definition of PyTorch integration for ZenML."""
 
-class GcpSecretManagerIntegration(Integration):
-    """Definition of the Secrets Manager for the Google Cloud Platform
-    integration with ZenML."""
-
-    NAME = GCP_SECRETS_MANAGER
-    REQUIREMENTS = ["google-cloud-secret-manager"]
+    NAME = PYTORCH
+    REQUIREMENTS = ["torch"]
 
     @classmethod
-    def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the GCP integration."""
-        return [
-            FlavorWrapper(
-                name=GCP_SECRETS_MANAGER_FLAVOR,
-                source="zenml.integrations.gcp_secrets_manager.secrets_manager."
-                "GCPSecretsManager",
-                type=StackComponentType.SECRETS_MANAGER,
-                integration=cls.NAME,
-            )
-        ]
+    def activate(cls) -> None:
+        """Activates the integration."""
+        from zenml.integrations.pytorch import materializers  # noqa
 
 
-GcpSecretManagerIntegration.check_installation()
+PytorchIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/secrets_manager/__init__.py` & `zenml-0.9.0/src/zenml/secrets_managers/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,17 +7,18 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Secrets Manager
-The GCP Secrets Manager allows your pipeline to directly access the GCP
-secrets manager and use the secrets within during runtime.
-"""
-from zenml.integrations.gcp_secrets_manager.secrets_manager.gcp_secrets_manager import (
-    GCPSecretsManager,
+"""Initialization for the ZenML secrets manager module."""
+
+from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
+from zenml.secrets_managers.local.local_secrets_manager import (
+    LocalSecretsManager,
 )
 
-__all__ = ["GCPSecretsManager"]
+__all__ = [
+    "BaseSecretsManager",
+    "LocalSecretsManager",
+]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/gcp_secrets_manager/secrets_manager/gcp_secrets_manager.py` & `zenml-0.9.0/src/zenml/integrations/gcp/secrets_manager/gcp_secrets_manager.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,51 +7,59 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the GCP Secrets Manager."""
+
 from typing import Any, ClassVar, Dict, List
 
 from google.cloud import secretmanager
 
 from zenml.exceptions import SecretExistsError
-from zenml.integrations.gcp_secrets_manager import GCP_SECRETS_MANAGER_FLAVOR
+from zenml.integrations.gcp import GCP_SECRETS_MANAGER_FLAVOR
 from zenml.logger import get_logger
 from zenml.secret.base_secret import BaseSecretSchema
 from zenml.secret.secret_schema_class_registry import SecretSchemaClassRegistry
 from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
 
 logger = get_logger(__name__)
 
 ZENML_SCHEMA_NAME = "zenml-schema-name"
 ZENML_GROUP_KEY = "zenml-group-key"
 
 
 def prepend_group_name_to_keys(secret: BaseSecretSchema) -> Dict[str, str]:
-    """This function adds the secret group name to the keys of each
-    secret key-value pair to allow using the same key across multiple
-    secrets.
+    """Adds the secret group name to the keys of each secret key-value pair.
+
+    This allows using the same key across multiple secrets.
 
     Args:
         secret: The ZenML Secret schema
+
+    Returns:
+        A dictionary with the keys prepended with the group name
     """
     return {f"{secret.name}_{k}": v for k, v in secret.content.items()}
 
 
 def remove_group_name_from_key(combined_key_name: str, group_name: str) -> str:
-    """This function serves to remove the secret group name from the secret
-    key.
+    """Removes the secret group name from the secret key.
 
     Args:
         combined_key_name: Full name as it is within the gcp secrets manager
         group_name: Group name (the ZenML Secret name)
+
     Returns:
         The cleaned key
+
+    Raises:
+        RuntimeError: If the group name is not found in the key
     """
     if combined_key_name.startswith(group_name + "_"):
         return combined_key_name[len(group_name + "_") :]
     else:
         raise RuntimeError(
             f"Key-name `{combined_key_name}` does not have the "
             f"prefix `{group_name}`. Key could not be "
@@ -77,22 +85,30 @@
     @classmethod
     def _ensure_client_connected(cls) -> None:
         if cls.CLIENT is None:
             cls.CLIENT = secretmanager.SecretManagerServiceClient()
 
     @property
     def parent_name(self) -> str:
-        """Construct the GCP parent path to the secret manager"""
+        """Construct the GCP parent path to the secret manager.
+
+        Returns:
+            The parent path to the secret manager
+        """
         return f"projects/{self.project_id}"
 
     def register_secret(self, secret: BaseSecretSchema) -> None:
         """Registers a new secret.
 
         Args:
-            secret: the secret to register"""
+            secret: the secret to register
+
+        Raises:
+            SecretExistsError: if the secret already exists
+        """
         self._ensure_client_connected()
 
         if secret.name in self.get_all_secret_keys():
             raise SecretExistsError(
                 f"A Secret with the name {secret.name} already exists."
             )
 
@@ -131,15 +147,16 @@
         Args:
             secret_name: the name of the secret to get
 
         Returns:
             The secret.
 
         Raises:
-            RuntimeError: if the secret does not exist"""
+            RuntimeError: if the secret does not exist
+        """
         self._ensure_client_connected()
 
         secret_contents = {}
         zenml_schema_name = ""
 
         # List all secrets.
         for secret in self.CLIENT.list_secrets(
@@ -176,15 +193,16 @@
         )
         return secret_schema(**secret_contents)
 
     def get_all_secret_keys(self) -> List[str]:
         """Get all secret keys.
 
         Returns:
-            A list of all secret keys."""
+            A list of all secret keys
+        """
         self._ensure_client_connected()
 
         set_of_secrets = set()
 
         # List all secrets.
         for secret in self.CLIENT.list_secrets(
             request={"parent": self.parent_name}
@@ -192,19 +210,19 @@
             if ZENML_GROUP_KEY in secret.labels:
                 group_key = secret.labels[ZENML_GROUP_KEY]
                 set_of_secrets.add(group_key)
 
         return list(set_of_secrets)
 
     def update_secret(self, secret: BaseSecretSchema) -> None:
-        """Update an existing secret by creating new versions of the existing
-        secrets.
+        """Update an existing secret by creating new versions of the existing secrets.
 
         Args:
-            secret: the secret to update"""
+            secret: the secret to update
+        """
         self._ensure_client_connected()
 
         adjusted_content = prepend_group_name_to_keys(secret)
 
         for k, v in adjusted_content.items():
             # Create the secret, this only creates an empty secret with the
             #  supplied name.
@@ -212,21 +230,24 @@
             payload = {"data": str(v).encode()}
 
             self.CLIENT.add_secret_version(
                 request={"parent": version_parent, "payload": payload}
             )
 
     def delete_secret(self, secret_name: str) -> None:
-        """Delete an existing secret. by name. In GCP a secret is a single k-v
+        """Delete an existing secret by name.
+
+        In GCP a secret is a single k-v
         pair. Within ZenML a secret is a collection of k-v pairs. As such,
         deleting a secret will iterate through all secrets and delete the ones
         with the secret_name as label.
 
         Args:
-            secret_name: the name of the secret to delete"""
+            secret_name: the name of the secret to delete
+        """
         self._ensure_client_connected()
 
         # Go through all gcp secrets and delete the ones with the secret_name
         #  as label.
         for secret in self.CLIENT.list_secrets(
             request={"parent": self.parent_name}
         ):
@@ -236,15 +257,16 @@
             ):
                 self.CLIENT.delete_secret(request={"name": secret.name})
 
     def delete_all_secrets(self, force: bool = False) -> None:
         """Delete all existing secrets.
 
         Args:
-            force: whether to force delete all secrets"""
+            force: whether to force delete all secrets
+        """
         self._ensure_client_connected()
 
         # List all secrets.
         for secret in self.CLIENT.list_secrets(
             request={"parent": self.parent_name}
         ):
             if (
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/graphviz/__init__.py` & `zenml-0.9.0/src/zenml/integrations/graphviz/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Graphviz integration."""
+
 from zenml.integrations.constants import GRAPHVIZ
 from zenml.integrations.integration import Integration
 
 
 class GraphvizIntegration(Integration):
     """Definition of Graphviz integration for ZenML."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/graphviz/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/aws/step_operators/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,13 +1,18 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Sagemaker Step Operator."""
+
+from zenml.integrations.aws.step_operators.sagemaker_step_operator import (  # noqa
+    SagemakerStepOperator,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/graphviz/visualizers/pipeline_run_dag_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/graphviz/visualizers/pipeline_run_dag_visualizer.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Graphviz pipeline run DAG visualizer."""
 
 import tempfile
 from abc import abstractmethod
 from typing import Any
 
 import graphviz
 
@@ -40,15 +41,24 @@
     STEP_PREFIX = "step_"
     FONT = "Roboto"
 
     @abstractmethod
     def visualize(
         self, object: PipelineRunView, *args: Any, **kwargs: Any
     ) -> graphviz.Digraph:
-        """Creates a pipeline lineage diagram using graphviz."""
+        """Creates a pipeline lineage diagram using graphviz.
+
+        Args:
+            object: The pipeline run view to visualize.
+            *args: Additional arguments to pass to the visualization.
+            **kwargs: Additional keyword arguments to pass to the visualization.
+
+        Returns:
+            A graphviz digraph object.
+        """
         logger.warning(
             "This integration is not completed yet. Results might be unexpected."
         )
 
         dot = graphviz.Digraph(comment=object.name)
 
         # link the steps together
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/__init__.py` & `zenml-0.9.0/src/zenml/integrations/xgboost/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,24 +7,26 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.constants import HUGGINGFACE
+"""Initialization of the XGBoost integration."""
+
+from zenml.integrations.constants import XGBOOST
 from zenml.integrations.integration import Integration
 
 
-class HuggingfaceIntegration(Integration):
-    """Definition of Huggingface integration for ZenML."""
+class XgboostIntegration(Integration):
+    """Definition of xgboost integration for ZenML."""
 
-    NAME = HUGGINGFACE
-    REQUIREMENTS = ["transformers", "datasets"]
+    NAME = XGBOOST
+    REQUIREMENTS = ["xgboost>=1.0.0"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        from zenml.integrations.huggingface import materializers  # noqa
+        from zenml.integrations.xgboost import materializers  # noqa
 
 
-HuggingfaceIntegration.check_installation()
+XgboostIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/materializers/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of Huggingface materializers."""
+
 from zenml.integrations.huggingface.materializers.huggingface_datasets_materializer import (
     HFDatasetMaterializer,
 )
 from zenml.integrations.huggingface.materializers.huggingface_pt_model_materializer import (
     HFPTModelMaterializer,
 )
 from zenml.integrations.huggingface.materializers.huggingface_tf_model_materializer import (
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_datasets_materializer.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_datasets_materializer.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,47 +7,56 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Huggingface datasets materializer."""
 
 import os
 from tempfile import TemporaryDirectory
 from typing import Any, Type
 
 from datasets import Dataset, load_from_disk  # type: ignore[attr-defined]
 from datasets.dataset_dict import DatasetDict
 
 from zenml.artifacts import DataArtifact
-from zenml.io import utils as fileio_utils
 from zenml.materializers.base_materializer import BaseMaterializer
+from zenml.utils import io_utils
 
 DEFAULT_DATASET_DIR = "hf_datasets"
 
 
 class HFDatasetMaterializer(BaseMaterializer):
     """Materializer to read data to and from huggingface datasets."""
 
     ASSOCIATED_TYPES = (Dataset, DatasetDict)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> Dataset:
-        """Reads Dataset"""
+        """Reads Dataset.
+
+        Args:
+            data_type: The type of the dataset to read.
+
+        Returns:
+            The dataset read from the specified dir.
+        """
         super().handle_input(data_type)
 
         return load_from_disk(
             os.path.join(self.artifact.uri, DEFAULT_DATASET_DIR)
         )
 
     def handle_return(self, ds: Type[Any]) -> None:
         """Writes a Dataset to the specified dir.
+
         Args:
-            Dataset: The Dataset to write.
+            ds: The Dataset to write.
         """
         super().handle_return(ds)
         temp_dir = TemporaryDirectory()
         ds.save_to_disk(temp_dir.name)
-        fileio_utils.copy_dir(
+        io_utils.copy_dir(
             temp_dir.name, os.path.join(self.artifact.uri, DEFAULT_DATASET_DIR)
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_pt_model_materializer.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_pt_model_materializer.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,37 +7,45 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Huggingface PyTorch model materializer."""
 
 import importlib
 import os
 from tempfile import TemporaryDirectory
 from typing import Any, Type
 
 from transformers import AutoConfig, PreTrainedModel
 
 from zenml.artifacts import ModelArtifact
-from zenml.io import utils as fileio_utils
 from zenml.materializers.base_materializer import BaseMaterializer
+from zenml.utils import io_utils
 
 DEFAULT_PT_MODEL_DIR = "hf_pt_model"
 
 
 class HFPTModelMaterializer(BaseMaterializer):
     """Materializer to read torch model to and from huggingface pretrained model."""
 
     ASSOCIATED_TYPES = (PreTrainedModel,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> PreTrainedModel:
-        """Reads HFModel"""
+        """Reads HFModel.
+
+        Args:
+            data_type: The type of the model to read.
+
+        Returns:
+            The model read from the specified dir.
+        """
         super().handle_input(data_type)
 
         config = AutoConfig.from_pretrained(
             os.path.join(self.artifact.uri, DEFAULT_PT_MODEL_DIR)
         )
         architecture = config.architectures[0]
         model_cls = getattr(
@@ -45,17 +53,18 @@
         )
         return model_cls.from_pretrained(
             os.path.join(self.artifact.uri, DEFAULT_PT_MODEL_DIR)
         )
 
     def handle_return(self, model: Type[Any]) -> None:
         """Writes a Model to the specified dir.
+
         Args:
-            PreTrainedModel: The Torch Model to write.
+            model: The Torch Model to write.
         """
         super().handle_return(model)
         temp_dir = TemporaryDirectory()
         model.save_pretrained(temp_dir.name)
-        fileio_utils.copy_dir(
+        io_utils.copy_dir(
             temp_dir.name,
             os.path.join(self.artifact.uri, DEFAULT_PT_MODEL_DIR),
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_tf_model_materializer.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_tf_model_materializer.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,37 +7,45 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Huggingface TF model materializer."""
 
 import importlib
 import os
 from tempfile import TemporaryDirectory
 from typing import Any, Type
 
 from transformers import AutoConfig, TFPreTrainedModel
 
 from zenml.artifacts import ModelArtifact
-from zenml.io import utils as fileio_utils
 from zenml.materializers.base_materializer import BaseMaterializer
+from zenml.utils import io_utils
 
 DEFAULT_TF_MODEL_DIR = "hf_tf_model"
 
 
 class HFTFModelMaterializer(BaseMaterializer):
-    """Materializer to read tensorflow model to and from huggingface pretrained model."""
+    """Materializer to read Tensorflow model to and from huggingface pretrained model."""
 
     ASSOCIATED_TYPES = (TFPreTrainedModel,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> TFPreTrainedModel:
-        """Reads HFModel"""
+        """Reads HFModel.
+
+        Args:
+            data_type: The type of the model to read.
+
+        Returns:
+            The model read from the specified dir.
+        """
         super().handle_input(data_type)
 
         config = AutoConfig.from_pretrained(
             os.path.join(self.artifact.uri, DEFAULT_TF_MODEL_DIR)
         )
         architecture = "TF" + config.architectures[0]
         model_cls = getattr(
@@ -45,17 +53,18 @@
         )
         return model_cls.from_pretrained(
             os.path.join(self.artifact.uri, DEFAULT_TF_MODEL_DIR)
         )
 
     def handle_return(self, model: Type[Any]) -> None:
         """Writes a Model to the specified dir.
+
         Args:
-            TFPreTrainedModel: The TF Model to write.
+            model: The TF Model to write.
         """
         super().handle_return(model)
         temp_dir = TemporaryDirectory()
         model.save_pretrained(temp_dir.name)
-        fileio_utils.copy_dir(
+        io_utils.copy_dir(
             temp_dir.name,
             os.path.join(self.artifact.uri, DEFAULT_TF_MODEL_DIR),
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/huggingface/materializers/huggingface_tokenizer_materializer.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/materializers/huggingface_tokenizer_materializer.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,48 +7,57 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Huggingface tokenizer materializer."""
 
 import os
 from tempfile import TemporaryDirectory
 from typing import Any, Type
 
 from transformers import AutoTokenizer
 from transformers.tokenization_utils_base import PreTrainedTokenizerBase
 
 from zenml.artifacts import ModelArtifact
-from zenml.io import utils as fileio_utils
 from zenml.materializers.base_materializer import BaseMaterializer
+from zenml.utils import io_utils
 
 DEFAULT_TOKENIZER_DIR = "hf_tokenizer"
 
 
 class HFTokenizerMaterializer(BaseMaterializer):
     """Materializer to read tokenizer to and from huggingface tokenizer."""
 
     ASSOCIATED_TYPES = (PreTrainedTokenizerBase,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> PreTrainedTokenizerBase:
-        """Reads Tokenizer"""
+        """Reads Tokenizer.
+
+        Args:
+            data_type: The type of the tokenizer to read.
+
+        Returns:
+            The tokenizer read from the specified dir.
+        """
         super().handle_input(data_type)
 
         return AutoTokenizer.from_pretrained(
             os.path.join(self.artifact.uri, DEFAULT_TOKENIZER_DIR)
         )
 
     def handle_return(self, tokenizer: Type[Any]) -> None:
         """Writes a Tokenizer to the specified dir.
+
         Args:
-            PreTrainedTokenizerBase: The HFTokenizer to write.
+            tokenizer: The HFTokenizer to write.
         """
         super().handle_return(tokenizer)
         temp_dir = TemporaryDirectory()
         tokenizer.save_pretrained(temp_dir.name)
-        fileio_utils.copy_dir(
+        io_utils.copy_dir(
             temp_dir.name,
             os.path.join(self.artifact.uri, DEFAULT_TOKENIZER_DIR),
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/integration.py` & `zenml-0.9.0/src/zenml/integrations/integration.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,52 +7,66 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base and meta classes for ZenML integrations."""
+
 import shutil
 from typing import Any, Dict, List, Tuple, Type, cast
 
 import pkg_resources
 
 from zenml.integrations.registry import integration_registry
 from zenml.logger import get_logger
 from zenml.zen_stores.models import FlavorWrapper
 
 logger = get_logger(__name__)
 
 
 class IntegrationMeta(type):
-    """Metaclass responsible for registering different Integration
-    subclasses"""
+    """Metaclass responsible for registering different Integration subclasses."""
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "IntegrationMeta":
-        """Hook into creation of an Integration class."""
+        """Hook into creation of an Integration class.
+
+        Args:
+            name: The name of the class being created.
+            bases: The base classes of the class being created.
+            dct: The dictionary of attributes of the class being created.
+
+        Returns:
+            The newly created class.
+        """
         cls = cast(Type["Integration"], super().__new__(mcs, name, bases, dct))
         if name != "Integration":
             integration_registry.register_integration(cls.NAME, cls)
         return cls
 
 
 class Integration(metaclass=IntegrationMeta):
-    """Base class for integration in ZenML"""
+    """Base class for integration in ZenML."""
 
     NAME = "base_integration"
 
     REQUIREMENTS: List[str] = []
 
     SYSTEM_REQUIREMENTS: Dict[str, str] = {}
 
     @classmethod
     def check_installation(cls) -> bool:
-        """Method to check whether the required packages are installed"""
+        """Method to check whether the required packages are installed.
+
+        Returns:
+            True if all required packages are installed, False otherwise.
+        """
         try:
             for requirement, command in cls.SYSTEM_REQUIREMENTS.items():
                 result = shutil.which(command)
 
                 if result is None:
                     logger.debug(
                         "Unable to find the required packages for %s on your "
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/__init__.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of the Kubeflow integration for ZenML.
+
 The Kubeflow integration sub-module powers an alternative to the local
 orchestrator. You can enable it by registering the Kubeflow orchestrator with
 the CLI tool.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
@@ -31,15 +32,19 @@
     """Definition of Kubeflow Integration for ZenML."""
 
     NAME = KUBEFLOW
     REQUIREMENTS = ["kfp==1.8.9"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Kubeflow integration."""
+        """Declare the stack component flavors for the Kubeflow integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
                 name=KUBEFLOW_METADATA_STORE_FLAVOR,
                 source="zenml.integrations.kubeflow.metadata_stores.KubeflowMetadataStore",
                 type=StackComponentType.METADATA_STORE,
                 integration=cls.NAME,
             ),
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/metadata_stores/__init__.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/metadata_stores/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,13 +7,14 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Kubeflow metadata store for ZenML."""
 
 from zenml.integrations.kubeflow.metadata_stores.kubeflow_metadata_store import (
     KubeflowMetadataStore,
 )
 
 __all__ = ["KubeflowMetadataStore"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/metadata_stores/kubeflow_metadata_store.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/metadata_stores/kubeflow_metadata_store.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Kubeflow metadata store."""
+
 import os
 import subprocess
 import sys
 import time
 from typing import ClassVar, Optional, Tuple, Union, cast
 
 from kubernetes import config as k8s_config
@@ -34,15 +36,19 @@
 from zenml.stack.stack import Stack
 from zenml.utils import networking_utils
 
 logger = get_logger(__name__)
 
 
 def inside_kfp_pod() -> bool:
-    """Returns if the current python process is running inside a KFP Pod."""
+    """Returns if the current python process is running inside a KFP Pod.
+
+    Returns:
+        True if the current python process is running inside a KFP Pod, False otherwise.
+    """
     if "KFP_POD_NAME" not in os.environ:
         return False
 
     try:
         k8s_config.load_incluster_config()
         return True
     except k8s_config.ConfigException:
@@ -61,15 +67,19 @@
     port: int = DEFAULT_KFP_METADATA_GRPC_PORT
 
     # Class Configuration
     FLAVOR: ClassVar[str] = KUBEFLOW_METADATA_STORE_FLAVOR
 
     @property
     def validator(self) -> Optional[StackValidator]:
-        """Validates that the stack contains a KFP orchestrator."""
+        """Validates that the stack contains a KFP orchestrator.
+
+        Returns:
+            The stack validator.
+        """
 
         def _ensure_kfp_orchestrator(stack: Stack) -> Tuple[bool, str]:
             return (
                 stack.orchestrator.FLAVOR == KUBEFLOW,
                 "The Kubeflow metadata store can only be used with a Kubeflow "
                 "orchestrator.",
             )
@@ -80,15 +90,22 @@
 
     def get_tfx_metadata_config(
         self,
     ) -> Union[
         metadata_store_pb2.ConnectionConfig,
         metadata_store_pb2.MetadataStoreClientConfig,
     ]:
-        """Return tfx metadata config for the kubeflow metadata store."""
+        """Return tfx metadata config for the kubeflow metadata store.
+
+        Returns:
+            The tfx metadata config for the kubeflow metadata store.
+
+        Raises:
+            RuntimeError: If the metadata store is not running.
+        """
         connection_config = metadata_store_pb2.MetadataStoreClientConfig()
         if inside_kfp_pod():
             connection_config.host = os.environ["METADATA_GRPC_SERVICE_HOST"]
             connection_config.port = int(
                 os.environ["METADATA_GRPC_SERVICE_PORT"]
             )
         else:
@@ -100,61 +117,91 @@
                 )
             connection_config.host = self.host
             connection_config.port = self.port
         return connection_config
 
     @property
     def kfp_orchestrator(self) -> KubeflowOrchestrator:
-        """Returns the Kubeflow orchestrator in the active stack."""
+        """Returns the Kubeflow orchestrator in the active stack.
+
+        Returns:
+            The Kubeflow orchestrator in the active stack.
+        """
         repo = Repository(skip_repository_check=True)  # type: ignore[call-arg]
         return cast(KubeflowOrchestrator, repo.active_stack.orchestrator)
 
     @property
     def kubernetes_context(self) -> str:
-        """Returns the kubernetes context to the cluster where the Kubeflow
-        Pipelines services are running."""
+        """Returns the kubernetes context.
+
+        This is returned to the cluster where the Kubeflow Pipelines services
+        are running.
+
+        Returns:
+            The kubernetes context.
+        """
         kubernetes_context = self.kfp_orchestrator.kubernetes_context
 
         # will never happen, but mypy doesn't know that
         assert kubernetes_context is not None
         return kubernetes_context
 
     @property
     def root_directory(self) -> str:
-        """Returns path to the root directory for all files concerning
-        this KFP metadata store.
+        """Returns path to the root directory.
+
+        This is for all files concerning this KFP metadata store.
 
         Note: the root directory for the KFP metadata store is relative to the
         root directory of the KFP orchestrator, because it is a sub-component
         of it.
+
+        Returns:
+            Path to the root directory.
         """
         return os.path.join(
             self.kfp_orchestrator.root_directory,
             "metadata-store",
             str(self.uuid),
         )
 
     @property
     def _pid_file_path(self) -> str:
-        """Returns path to the daemon PID file."""
+        """Returns path to the daemon PID file.
+
+        Returns:
+            Path to the daemon PID file.
+        """
         return os.path.join(self.root_directory, "kubeflow_daemon.pid")
 
     @property
     def _log_file(self) -> str:
-        """Path of the daemon log file."""
+        """Path of the daemon log file.
+
+        Returns:
+            Path to the daemon log file.
+        """
         return os.path.join(self.root_directory, "kubeflow_daemon.log")
 
     @property
     def is_provisioned(self) -> bool:
-        """If the component provisioned resources to run locally."""
+        """If the component provisioned resources to run locally.
+
+        Returns:
+            True if the component provisioned resources to run locally.
+        """
         return fileio.exists(self.root_directory)
 
     @property
     def is_running(self) -> bool:
-        """If the component is running locally."""
+        """If the component is running locally.
+
+        Returns:
+            True if the component is running locally, False otherwise.
+        """
         if sys.platform != "win32":
             from zenml.utils.daemon import check_if_daemon_is_running
 
             if not check_if_daemon_is_running(self._pid_file_path):
                 return False
         else:
             # Daemon functionality is not supported on Windows, so the PID
@@ -167,15 +214,14 @@
     def provision(self) -> None:
         """Provisions resources to run the component locally."""
         logger.info("Provisioning local Kubeflow Pipelines deployment...")
         fileio.makedirs(self.root_directory)
 
     def deprovision(self) -> None:
         """Deprovisions all local resources of the component."""
-
         if fileio.exists(self._log_file):
             fileio.remove(self._log_file)
 
         logger.info("Local kubeflow pipelines deployment deprovisioned.")
 
     def resume(self) -> None:
         """Resumes the local k3d cluster."""
@@ -191,17 +237,22 @@
         if not self.is_running:
             logger.info("Local kubeflow pipelines deployment not running.")
             return
 
         self.stop_kfp_metadata_daemon()
 
     def start_kfp_metadata_daemon(self) -> None:
-        """Starts a daemon process that forwards ports so the Kubeflow Pipelines
-        Metadata MySQL database is accessible on the localhost."""
+        """Starts a daemon process that forwards ports.
+
+        This is so the Kubeflow Pipelines Metadata MySQL database is accessible
+        on the localhost.
 
+        Raises:
+            ProvisioningError: if the daemon fails to start.
+        """
         command = [
             "kubectl",
             "--context",
             self.kubernetes_context,
             "--namespace",
             "kubeflow",
             "port-forward",
@@ -257,16 +308,26 @@
 
                 daemon.stop_daemon(self._pid_file_path)
                 fileio.remove(self._pid_file_path)
 
     def wait_until_metadata_store_ready(
         self, timeout: int = DEFAULT_KFP_METADATA_DAEMON_TIMEOUT
     ) -> None:
-        """Waits until the metadata store connection is ready, an irrecoverable
-        error occurs or the timeout expires."""
+        """Waits until the metadata store connection is ready.
+
+        Potentially an irrecoverable error could occur or the timeout could
+        expire, so it checks for this.
+
+        Args:
+            timeout: The maximum time to wait for the metadata store to be
+                ready.
+
+        Raises:
+            RuntimeError: if the metadata store is not ready after the timeout
+        """
         logger.info(
             "Waiting for the Kubeflow metadata store to be ready (this might "
             "take a few minutes)."
         )
         while True:
             try:
                 # it doesn't matter what we call here as long as it exercises
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/__init__.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Kubeflow ZenML orchestrator."""
 
 from zenml.integrations.kubeflow.orchestrators.kubeflow_orchestrator import (  # noqa
     KubeflowOrchestrator,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_entrypoint_configuration.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_entrypoint_configuration.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Kubeflow entrypoint configuration."""
 
 import os
 from typing import Any, List, Optional, Set
 
 import kfp
 from kubernetes import config as k8s_config
 from tfx.orchestration.portable import data_types
@@ -37,40 +38,69 @@
     def get_custom_entrypoint_options(cls) -> Set[str]:
         """Kubeflow specific entrypoint options.
 
         The metadata ui path option expects a path where the markdown file
         that will be displayed in the kubeflow UI should be written. The same
         path needs to be added as an output artifact called
         `mlpipeline-ui-metadata` for the corresponding `kfp.dsl.ContainerOp`.
+
+        Returns:
+            The set of custom entrypoint options.
         """
         return {METADATA_UI_PATH_OPTION}
 
     @classmethod
     def get_custom_entrypoint_arguments(
         cls, step: BaseStep, *args: Any, **kwargs: Any
     ) -> List[str]:
-        """Sets the metadata ui path argument to the value passed in via the
-        keyword args.
+        """Sets the metadata ui path argument to the value passed in via the keyword args.
+
+        Args:
+            step: The step that is being executed.
+            *args: The positional arguments passed to the step.
+            **kwargs: The keyword arguments passed to the step.
+
+        Returns:
+            A list of strings that will be used as arguments to the step.
         """
-        return [f"--{METADATA_UI_PATH_OPTION}", kwargs[METADATA_UI_PATH_OPTION]]
+        return [
+            f"--{METADATA_UI_PATH_OPTION}",
+            kwargs[METADATA_UI_PATH_OPTION],
+        ]
 
     def get_run_name(self, pipeline_name: str) -> str:
-        """Returns the Kubeflow pipeline run name."""
+        """Returns the Kubeflow pipeline run name.
+
+        Args:
+            pipeline_name: The name of the pipeline.
+
+        Returns:
+            The Kubeflow pipeline run name.
+        """
         k8s_config.load_incluster_config()
         run_id = os.environ["KFP_RUN_ID"]
         return kfp.Client().get_run(run_id).run.name  # type: ignore[no-any-return]
 
     def post_run(
         self,
         pipeline_name: str,
         step_name: str,
         pipeline_node: Pb2PipelineNode,
         execution_info: Optional[data_types.ExecutionInfo] = None,
     ) -> None:
-        """Writes a markdown file that will display information about the step
-        execution and input/output artifacts in the KFP UI."""
+        """Writes a markdown file that will display information.
+
+        This will be about the step execution and input/output artifacts in the
+        KFP UI.
+
+        Args:
+            pipeline_name: The name of the pipeline.
+            step_name: The name of the step.
+            pipeline_node: The pipeline node that is being executed.
+            execution_info: The execution info of the step.
+        """
         if execution_info:
             utils.dump_ui_metadata(
                 node=pipeline_node,
                 execution_info=execution_info,
                 metadata_ui_path=self.entrypoint_args[METADATA_UI_PATH_OPTION],
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_orchestrator.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/kubeflow_orchestrator.py`

 * *Files 7% similar despite different names*

```diff
@@ -24,14 +24,15 @@
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 
 # Minor parts of the `prepare_or_run_pipeline()` method of this file are
 # inspired by the kubeflow dag runner implementation of tfx
+"""Implementation of the Kubeflow orchestrator."""
 
 import os
 import re
 import sys
 from typing import TYPE_CHECKING, Any, ClassVar, Dict, List, Optional, Tuple
 from uuid import UUID
 
@@ -41,15 +42,14 @@
 from kfp.compiler import Compiler as KFPCompiler
 from kfp_server_api.exceptions import ApiException
 from kubernetes import client as k8s_client
 from kubernetes import config as k8s_config
 from pydantic import root_validator
 from tfx.proto.orchestration.pipeline_pb2 import Pipeline as Pb2Pipeline
 
-import zenml.io.utils
 from zenml.artifact_stores import LocalArtifactStore
 from zenml.enums import StackComponentType
 from zenml.environment import Environment
 from zenml.exceptions import ProvisioningError
 from zenml.integrations.kubeflow import KUBEFLOW_ORCHESTRATOR_FLAVOR
 from zenml.integrations.kubeflow.orchestrators import (
     local_deployment_utils,
@@ -59,27 +59,27 @@
     METADATA_UI_PATH_OPTION,
     KubeflowEntrypointConfiguration,
 )
 from zenml.integrations.kubeflow.orchestrators.local_deployment_utils import (
     KFP_VERSION,
 )
 from zenml.io import fileio
-from zenml.io.utils import get_global_config_directory
 from zenml.logger import get_logger
 from zenml.orchestrators import BaseOrchestrator
 from zenml.repository import Repository
-from zenml.stack import Stack, StackValidator
-from zenml.steps import BaseStep
-from zenml.utils import networking_utils
+from zenml.stack import StackValidator
+from zenml.utils import io_utils, networking_utils
 from zenml.utils.docker_utils import get_image_digest
 from zenml.utils.source_utils import get_source_root_path
 
 if TYPE_CHECKING:
     from zenml.pipelines.base_pipeline import BasePipeline
     from zenml.runtime_configuration import RuntimeConfiguration
+    from zenml.stack import Stack
+    from zenml.steps import BaseStep
 
 logger = get_logger(__name__)
 
 DEFAULT_KFP_UI_PORT = 8080
 KFP_POD_LABELS = {
     "add-pod-env": "true",
     "pipelines.kubeflow.org/pipeline-sdk-type": "zenml",
@@ -126,34 +126,47 @@
     skip_ui_daemon_provisioning: bool = False
 
     # Class Configuration
     FLAVOR: ClassVar[str] = KUBEFLOW_ORCHESTRATOR_FLAVOR
 
     @staticmethod
     def _get_k3d_cluster_name(uuid: UUID) -> str:
-        """Returns the k3d cluster name corresponding to the orchestrator
-        UUID."""
+        """Returns the k3d cluster name corresponding to the orchestrator UUID.
+
+        Args:
+            uuid: The UUID of the orchestrator.
+
+        Returns:
+            The k3d cluster name.
+        """
         # k3d only allows cluster names with up to 32 characters; use the
         # first 8 chars of the orchestrator UUID as identifier
         return f"zenml-kubeflow-{str(uuid)[:8]}"
 
     @staticmethod
     def _get_k3d_kubernetes_context(uuid: UUID) -> str:
-        """Returns the name of the kubernetes context associated with the k3d
-        cluster managed locally by ZenML corresponding to the orchestrator
-        UUID."""
+        """Gets the k3d kubernetes context.
+
+        Args:
+            uuid: The UUID of the orchestrator.
+
+        Returns:
+            The name of the kubernetes context associated with the k3d
+                cluster managed locally by ZenML corresponding to the orchestrator UUID.
+        """
         return f"k3d-{KubeflowOrchestrator._get_k3d_cluster_name(uuid)}"
 
     @root_validator(skip_on_failure=True)
     def set_default_kubernetes_context(
         cls, values: Dict[str, Any]
     ) -> Dict[str, Any]:
-        """Pydantic root_validator that sets the default `kubernetes_context`
-        value to the value that is used to create the locally managed k3d
-        cluster, if not explicitly set.
+        """Pydantic root_validator.
+
+        This sets the default `kubernetes_context` value to the value that is
+        used to create the locally managed k3d cluster, if not explicitly set.
 
         Args:
             values: Values passed to the object constructor
 
         Returns:
             Values passed to the Pydantic constructor
         """
@@ -163,16 +176,19 @@
             values["kubernetes_context"] = cls._get_k3d_kubernetes_context(
                 values["uuid"]
             )
 
         return values
 
     def get_kubernetes_contexts(self) -> Tuple[List[str], str]:
-        """Get the list of configured Kubernetes contexts and the active
-        context.
+        """Get the list of configured Kubernetes contexts and the active context.
+
+        Returns:
+            A tuple containing the list of configured Kubernetes contexts and
+            the active context.
 
         Raises:
             RuntimeError: if the Kubernetes configuration cannot be loaded
         """
         try:
             contexts, active_context = k8s_config.list_kube_config_contexts()
         except k8s_config.config_exception.ConfigException as e:
@@ -182,18 +198,23 @@
 
         context_names = [c["name"] for c in contexts]
         active_context_name = active_context["name"]
         return context_names, active_context_name
 
     @property
     def validator(self) -> Optional[StackValidator]:
-        """Validates that the stack contains a container registry and that
-        requirements are met for local components."""
+        """Validates that the stack contains a container registry.
+
+        Also check that requirements are met for local components.
+
+        Returns:
+            A `StackValidator` instance.
+        """
 
-        def _validate_local_requirements(stack: Stack) -> Tuple[bool, str]:
+        def _validate_local_requirements(stack: "Stack") -> Tuple[bool, str]:
 
             container_registry = stack.container_registry
 
             # should not happen, because the stack validation takes care of
             # this, but just in case
             assert container_registry is not None
 
@@ -311,58 +332,79 @@
 
         return StackValidator(
             required_components={StackComponentType.CONTAINER_REGISTRY},
             custom_validation_function=_validate_local_requirements,
         )
 
     def get_docker_image_name(self, pipeline_name: str) -> str:
-        """Returns the full docker image name including registry and tag."""
+        """Returns the full docker image name including registry and tag.
 
+        Args:
+            pipeline_name: The name of the pipeline.
+
+        Returns:
+            The full docker image name including registry and tag.
+        """
         base_image_name = f"zenml-kubeflow:{pipeline_name}"
         container_registry = Repository().active_stack.container_registry
 
         if container_registry:
             registry_uri = container_registry.uri.rstrip("/")
             return f"{registry_uri}/{base_image_name}"
         else:
             return base_image_name
 
     @property
     def is_local(self) -> bool:
-        """Returns `True` if the KFP orchestrator is running locally (i.e. in
-        the local k3d cluster managed by ZenML).
+        """Checks if the KFP orchestrator is running locally.
+
+        Returns:
+            `True` if the KFP orchestrator is running locally (i.e. in
+            the local k3d cluster managed by ZenML).
         """
         return self.kubernetes_context == self._get_k3d_kubernetes_context(
             self.uuid
         )
 
     @property
     def root_directory(self) -> str:
-        """Returns path to the root directory for all files concerning
-        this orchestrator."""
+        """Returns path to the root directory for all files concerning this orchestrator.
+
+        Returns:
+            Path to the root directory.
+        """
         return os.path.join(
-            zenml.io.utils.get_global_config_directory(),
+            io_utils.get_global_config_directory(),
             "kubeflow",
             str(self.uuid),
         )
 
     @property
     def pipeline_directory(self) -> str:
-        """Returns path to a directory in which the kubeflow pipeline files
-        are stored."""
+        """Returns path to a directory in which the kubeflow pipeline files are stored.
+
+        Returns:
+            Path to the pipeline directory.
+        """
         return os.path.join(self.root_directory, "pipelines")
 
     def prepare_pipeline_deployment(
         self,
         pipeline: "BasePipeline",
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> None:
-        """Builds a docker image for the current environment and uploads it to
-        a container registry if configured.
+        """Builds a docker image for the current environment.
+
+        This function also uploads it to a container registry if configured.
+
+        Args:
+            pipeline: The pipeline to be deployed.
+            stack: The stack to be deployed.
+            runtime_configuration: The runtime configuration to be used.
         """
         from zenml.utils import docker_utils
 
         image_name = self.get_docker_image_name(pipeline.name)
 
         requirements = {*stack.requirements(), *pipeline.requirements}
 
@@ -385,22 +427,25 @@
         # Store the docker image digest in the runtime configuration so it gets
         # tracked in the ZenStore
         image_digest = docker_utils.get_image_digest(image_name) or image_name
         runtime_configuration["docker_image"] = image_digest
 
     @staticmethod
     def _configure_container_op(container_op: dsl.ContainerOp) -> None:
-        """Performs a few important changes in place to the configuration of the
-        container op.
+        """Makes changes in place to the configuration of the container op.
+
         Configures persistent mounted volumes for each stack component that
-        writes to a local path.
-        Adds some labels to the container_op and applies some functions to ir.
+        writes to a local path. Adds some labels to the container_op and applies
+        some functions to ir.
 
         Args:
             container_op: The kubeflow container operation to configure.
+
+        Raises:
+            ValueError: If the local path is not in the global config directory.
         """
         # Path to a metadata file that will be displayed in the KFP UI
         # This metadata file needs to be in a mounted emptyDir to avoid
         # sporadic failures with the (not mature) PNS executor
         # See these links for more information about limitations of PNS +
         # security context:
         # https://www.kubeflow.org/docs/components/pipelines/installation/localcluster-deployment/#deploying-kubeflow-pipelines
@@ -411,15 +456,15 @@
         volumes: Dict[str, k8s_client.V1Volume] = {
             "/outputs": k8s_client.V1Volume(
                 name="outputs", empty_dir=k8s_client.V1EmptyDirVolumeSource()
             ),
         }
 
         stack = Repository().active_stack
-        global_cfg_dir = get_global_config_directory()
+        global_cfg_dir = io_utils.get_global_config_directory()
 
         # go through all stack components and identify those that advertise
         # a local path where they persist information that they need to be
         # available when running pipelines. For those that do, mount them
         # into the Kubeflow container.
         has_local_repos = False
         for stack_comp in stack.components.values():
@@ -495,23 +540,24 @@
             container_op.add_pod_label(k, v)
 
         # Mounts configmap containing Metadata gRPC server configuration.
         container_op.apply(utils.mount_config_map_op("metadata-grpc-configmap"))
 
     def prepare_or_run_pipeline(
         self,
-        sorted_steps: List[BaseStep],
+        sorted_steps: List["BaseStep"],
         pipeline: "BasePipeline",
         pb2_pipeline: Pb2Pipeline,
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> Any:
-        """
-        Creates a kfp yaml file as intermediary representation of the
-        pipeline which is then deployed to the kubeflow pipelines instance.
+        """Creates a kfp yaml file.
+
+        This functions as an intermediary representation of the pipeline which
+        is then deployed to the kubeflow pipelines instance.
 
         How it works:
         -------------
         Before this method is called the `prepare_pipeline_deployment()`
         method builds a docker image that contains the code for the
         pipeline, all steps the context around these files.
 
@@ -523,16 +569,26 @@
         container_op by pointing at the downstream steps.
 
         This callable is then compiled into a kfp yaml file that is used as
         the intermediary representation of the kubeflow pipeline.
 
         This file, together with some metadata, runtime configurations is
         then uploaded into the kubeflow pipelines cluster for execution.
-        """
 
+        Args:
+            sorted_steps: A list of steps sorted by their order in the
+                pipeline.
+            pipeline: The pipeline object.
+            pb2_pipeline: The pipeline object in protobuf format.
+            stack: The stack object.
+            runtime_configuration: The runtime configuration object.
+
+        Raises:
+            RuntimeError: If you try to run the pipelines in a notebook environment.
+        """
         # First check whether the code running in a notebook
         if Environment.in_notebook():
             raise RuntimeError(
                 "The Kubeflow orchestrator cannot run pipelines in a notebook "
                 "environment. The reason is that it is non-trivial to create "
                 "a Docker image of a notebook. Please consider refactoring "
                 "your notebook cells into separate scripts in a Python module "
@@ -541,26 +597,26 @@
             )
 
         image_name = self.get_docker_image_name(pipeline.name)
         image_name = get_image_digest(image_name) or image_name
 
         # Create a callable for future compilation into a dsl.Pipeline.
         def _construct_kfp_pipeline() -> None:
-            """Create a container_op for each step which contains the name
-            of the docker image and configures the entrypoint of the docker
-            image to run the step.
+            """Create a container_op for each step.
+
+            This should contain the name of the docker image and configures the
+            entrypoint of the docker image to run the step.
 
             Additionally, this gives each container_op information about its
             direct downstream steps.
 
             If this callable is passed to the `_create_and_write_workflow()`
             method of a KFPCompiler all dsl.ContainerOp instances will be
             automatically added to a singular dsl.Pipeline instance.
             """
-
             # Dictionary of container_ops index by the associated step name
             step_name_to_container_op: Dict[str, dsl.ContainerOp] = {}
 
             for step in sorted_steps:
                 # The command will be needed to eventually call the python step
                 # within the docker container
                 command = (
@@ -677,22 +733,28 @@
                     )
                 logger.info(
                     "You can see all recurring runs under the '%s' experiment.'",
                     pipeline_name,
                 )
 
                 schedule = runtime_configuration.schedule
+                interval_seconds = (
+                    schedule.interval_second.seconds
+                    if schedule.interval_second
+                    else None
+                )
                 result = client.create_recurring_run(
                     experiment_id=experiment.id,
                     job_name=runtime_configuration.run_name,
                     pipeline_package_path=pipeline_file_path,
                     enable_caching=enable_cache,
+                    cron_expression=schedule.cron_expression,
                     start_time=schedule.utc_start_time,
                     end_time=schedule.utc_end_time,
-                    interval_second=schedule.interval_second.seconds,
+                    interval_second=interval_seconds,
                     no_catchup=not schedule.catchup,
                 )
 
                 logger.info("Started recurring run with ID '%s'.", result.id)
             else:
                 logger.info(
                     "No schedule detected. Creating a one-off pipeline run.."
@@ -720,63 +782,95 @@
                 f"{self.kubernetes_context} kubernetes context is configured "
                 f"correctly.",
                 error,
             )
 
     @property
     def _pid_file_path(self) -> str:
-        """Returns path to the daemon PID file."""
+        """Returns path to the daemon PID file.
+
+        Returns:
+            Path to the daemon PID file.
+        """
         return os.path.join(self.root_directory, "kubeflow_daemon.pid")
 
     @property
     def log_file(self) -> str:
-        """Path of the daemon log file."""
+        """Path of the daemon log file.
+
+        Returns:
+            Path of the daemon log file.
+        """
         return os.path.join(self.root_directory, "kubeflow_daemon.log")
 
     @property
     def _k3d_cluster_name(self) -> str:
-        """Returns the K3D cluster name."""
+        """Returns the K3D cluster name.
+
+        Returns:
+            The K3D cluster name.
+        """
         return self._get_k3d_cluster_name(self.uuid)
 
     def _get_k3d_registry_name(self, port: int) -> str:
-        """Returns the K3D registry name."""
+        """Returns the K3D registry name.
+
+        Args:
+            port: Port of the registry.
+
+        Returns:
+            The registry name.
+        """
         return f"k3d-zenml-kubeflow-registry.localhost:{port}"
 
     @property
     def _k3d_registry_config_path(self) -> str:
-        """Returns the path to the K3D registry config yaml."""
+        """Returns the path to the K3D registry config yaml.
+
+        Returns:
+            str: Path to the K3D registry config yaml.
+        """
         return os.path.join(self.root_directory, "k3d_registry.yaml")
 
     def _get_kfp_ui_daemon_port(self) -> int:
-        """Port to use for the KFP UI daemon."""
+        """Port to use for the KFP UI daemon.
+
+        Returns:
+            Port to use for the KFP UI daemon.
+        """
         port = self.kubeflow_pipelines_ui_port
         if port == DEFAULT_KFP_UI_PORT and not networking_utils.port_available(
             port
         ):
             # if the user didn't specify a specific port and the default
             # port is occupied, fallback to a random open port
             port = networking_utils.find_available_port()
         return port
 
     def list_manual_setup_steps(
         self, container_registry_name: str, container_registry_path: str
     ) -> None:
-        """Logs manual steps needed to setup the Kubeflow local orchestrator."""
+        """Logs manual steps needed to setup the Kubeflow local orchestrator.
+
+        Args:
+            container_registry_name: Name of the container registry.
+            container_registry_path: Path to the container registry.
+        """
         if not self.is_local:
             # Make sure we're not telling users to deploy Kubeflow on their
             # remote clusters
             logger.warning(
                 "This Kubeflow orchestrator is configured to use a non-local "
                 f"Kubernetes context {self.kubernetes_context}. Manually "
                 f"deploying Kubeflow Pipelines is only possible for local "
                 f"Kubeflow orchestrators."
             )
             return
 
-        global_config_dir_path = zenml.io.utils.get_global_config_directory()
+        global_config_dir_path = io_utils.get_global_config_directory()
         kubeflow_commands = [
             f"> k3d cluster create {self._k3d_cluster_name} --image {local_deployment_utils.K3S_IMAGE_NAME} --registry-create {container_registry_name} --registry-config {container_registry_path} --volume {global_config_dir_path}:{global_config_dir_path}\n",
             f"> kubectl --context {self.kubernetes_context} apply -k github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref={KFP_VERSION}&timeout=5m",
             f"> kubectl --context {self.kubernetes_context} wait --timeout=60s --for condition=established crd/applications.app.k8s.io",
             f"> kubectl --context {self.kubernetes_context} apply -k github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref={KFP_VERSION}&timeout=5m",
             f"> kubectl --context {self.kubernetes_context} --namespace kubeflow port-forward svc/ml-pipeline-ui {self.kubeflow_pipelines_ui_port}:80",
         ]
@@ -785,96 +879,119 @@
             "If you wish to spin up this Kubeflow local orchestrator manually, "
             "please enter the following commands:\n"
         )
         logger.info("\n".join(kubeflow_commands))
 
     @property
     def is_provisioned(self) -> bool:
-        """Returns if a local k3d cluster for this orchestrator exists."""
+        """Returns if a local k3d cluster for this orchestrator exists.
+
+        Returns:
+            True if a local k3d cluster exists, False otherwise.
+        """
         if not local_deployment_utils.check_prerequisites(
             skip_k3d=self.skip_cluster_provisioning or not self.is_local,
             skip_kubectl=self.skip_cluster_provisioning
             and self.skip_ui_daemon_provisioning,
         ):
             # if any prerequisites are missing there is certainly no
             # local deployment running
             return False
 
         return self.is_cluster_provisioned
 
     @property
     def is_running(self) -> bool:
-        """Returns if the local k3d cluster and the UI daemon for this
-        orchestrator are both running."""
+        """Checks if the local k3d cluster and UI daemon are both running.
+
+        Returns:
+            True if the local k3d cluster and UI daemon for this orchestrator are both running.
+        """
         return (
             self.is_provisioned
             and self.is_cluster_running
             and self.is_daemon_running
         )
 
     @property
     def is_suspended(self) -> bool:
-        """Returns if the local k3d cluster and the UI daemon for this
-        orchestrator are both stopped."""
+        """Checks if the local k3d cluster and UI daemon are both stopped.
+
+        Returns:
+            True if the cluster and daemon for this orchestrator are both stopped, False otherwise.
+        """
         return (
             self.is_provisioned
             and (self.skip_cluster_provisioning or not self.is_cluster_running)
             and (self.skip_ui_daemon_provisioning or not self.is_daemon_running)
         )
 
     @property
     def is_cluster_provisioned(self) -> bool:
         """Returns if the local k3d cluster for this orchestrator is provisioned.
 
         For remote (i.e. not managed by ZenML) Kubeflow Pipelines installations,
         this always returns True.
+
+        Returns:
+            True if the local k3d cluster is provisioned, False otherwise.
         """
         if self.skip_cluster_provisioning or not self.is_local:
             return True
         return local_deployment_utils.k3d_cluster_exists(
             cluster_name=self._k3d_cluster_name
         )
 
     @property
     def is_cluster_running(self) -> bool:
         """Returns if the local k3d cluster for this orchestrator is running.
 
         For remote (i.e. not managed by ZenML) Kubeflow Pipelines installations,
         this always returns True.
+
+        Returns:
+            True if the local k3d cluster is running, False otherwise.
         """
         if self.skip_cluster_provisioning or not self.is_local:
             return True
         return local_deployment_utils.k3d_cluster_running(
             cluster_name=self._k3d_cluster_name
         )
 
     @property
     def is_daemon_running(self) -> bool:
-        """Returns if the local Kubeflow UI daemon for this orchestrator is
-        running."""
+        """Returns if the local Kubeflow UI daemon for this orchestrator is running.
+
+        Returns:
+            True if the daemon is running, False otherwise.
+        """
         if self.skip_ui_daemon_provisioning:
             return True
 
         if sys.platform != "win32":
             from zenml.utils.daemon import check_if_daemon_is_running
 
             return check_if_daemon_is_running(self._pid_file_path)
         else:
             return True
 
     def provision(self) -> None:
-        """Provisions a local Kubeflow Pipelines deployment."""
+        """Provisions a local Kubeflow Pipelines deployment.
+
+        Raises:
+            ProvisioningError: If the provisioning fails.
+        """
         if self.skip_cluster_provisioning:
             return
 
         if self.is_running:
             logger.info(
                 "Found already existing local Kubeflow Pipelines deployment. "
                 "If there are any issues with the existing deployment, please "
-                "run 'zenml stack down --yes' to delete it."
+                "run 'zenml stack down --force' to delete it."
             )
             return
 
         if not local_deployment_utils.check_prerequisites():
             raise ProvisioningError(
                 "Unable to provision local Kubeflow Pipelines deployment: "
                 "Please install 'k3d' and 'kubectl' and try again."
@@ -954,15 +1071,19 @@
 
             logger.info("Local kubeflow pipelines deployment deprovisioned.")
 
         if fileio.exists(self.log_file):
             fileio.remove(self.log_file)
 
     def resume(self) -> None:
-        """Resumes the local k3d cluster."""
+        """Resumes the local k3d cluster.
+
+        Raises:
+            ProvisioningError: If the k3d cluster is not provisioned.
+        """
         if self.is_running:
             logger.info("Local kubeflow pipelines deployment already running.")
             return
 
         if not self.is_provisioned:
             raise ProvisioningError(
                 "Unable to resume local kubeflow pipelines deployment: No "
@@ -1025,15 +1146,16 @@
         Args:
             secrets: List of secrets provided by the user.
 
         Returns:
             A dictionary of key-value pairs.
 
         Raises:
-            ProvisioningError: If the stack has no secrets manager."""
+            ProvisioningError: If the stack has no secrets manager.
+        """
         environment_vars: Dict[str, str] = {}
         secret_manager = Repository().active_stack.secrets_manager
         if secrets and secret_manager:
             for secret in secrets:
                 secret_schema = secret_manager.get_secret(secret)
                 environment_vars.update(secret_schema.content)
         elif secrets and not secret_manager:
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/local_deployment_utils.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/local_deployment_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,47 @@
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#
+#  Licensed under the Apache License, Version 2.0 (the "License");
+#  you may not use this file except in compliance with the License.
+#  You may obtain a copy of the License at:
+#
+#       https://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+#  or implied. See the License for the specific language governing
+#  permissions and limitations under the License.
+"""Utils for the local Kubeflow deployment behaviors."""
+
 import json
 import shutil
 import subprocess
 import sys
 import time
 
-import zenml.io.utils
 from zenml.io import fileio
 from zenml.logger import get_logger
-from zenml.utils import networking_utils, yaml_utils
+from zenml.utils import io_utils, networking_utils, yaml_utils
 
 KFP_VERSION = "1.8.1"
 # Name of the K3S image to use for the local K3D cluster.
 # The version (e.g. v1.23.5) refers to a specific kubernetes release and is
 # fixed as KFP doesn't support the newest releases immediately.
 K3S_IMAGE_NAME = "rancher/k3s:v1.23.5-k3s1"
 
 logger = get_logger(__name__)
 
 
 def check_prerequisites(
     skip_k3d: bool = False, skip_kubectl: bool = False
 ) -> bool:
-    """Checks whether all prerequisites for a local kubeflow pipelines
-    deployment are installed.
+    """Checks prerequisites for a local kubeflow pipelines deployment.
+
+    It makes sure they are installed.
 
     Args:
         skip_k3d: Whether to skip the check for the k3d command.
         skip_kubectl: Whether to skip the check for the kubectl command.
 
     Returns:
         Whether all prerequisites are installed.
@@ -54,27 +69,41 @@
     yaml_content = {
         "mirrors": {registry_uri: {"endpoint": [f"http://{registry_name}"]}}
     }
     yaml_utils.write_yaml(yaml_path, yaml_content)
 
 
 def k3d_cluster_exists(cluster_name: str) -> bool:
-    """Checks whether there exists a K3D cluster with the given name."""
+    """Checks whether there exists a K3D cluster with the given name.
+
+    Args:
+        cluster_name: Name of the cluster to check.
+
+    Returns:
+        Whether the cluster exists.
+    """
     output = subprocess.check_output(
         ["k3d", "cluster", "list", "--output", "json"]
     )
     clusters = json.loads(output)
     for cluster in clusters:
         if cluster["name"] == cluster_name:
             return True
     return False
 
 
 def k3d_cluster_running(cluster_name: str) -> bool:
-    """Checks whether the K3D cluster with the given name is running."""
+    """Checks whether the K3D cluster with the given name is running.
+
+    Args:
+        cluster_name: Name of the cluster to check.
+
+    Returns:
+        Whether the cluster is running.
+    """
     output = subprocess.check_output(
         ["k3d", "cluster", "list", "--output", "json"]
     )
     clusters = json.loads(output)
     for cluster in clusters:
         if cluster["name"] == cluster_name:
             server_count: int = cluster["serversCount"]
@@ -90,15 +119,15 @@
 
     Args:
         cluster_name: Name of the cluster to create.
         registry_name: Name of the registry to create for this cluster.
         registry_config_path: Path to the registry config file.
     """
     logger.info("Creating local K3D cluster '%s'.", cluster_name)
-    global_config_dir_path = zenml.io.utils.get_global_config_directory()
+    global_config_dir_path = io_utils.get_global_config_directory()
     subprocess.check_call(
         [
             "k3d",
             "cluster",
             "create",
             cluster_name,
             "--image",
@@ -111,37 +140,52 @@
             f"{global_config_dir_path}:{global_config_dir_path}",
         ]
     )
     logger.info("Finished K3D cluster creation.")
 
 
 def start_k3d_cluster(cluster_name: str) -> None:
-    """Starts a K3D cluster with the given name."""
+    """Starts a K3D cluster with the given name.
+
+    Args:
+        cluster_name: Name of the cluster to start.
+    """
     subprocess.check_call(["k3d", "cluster", "start", cluster_name])
     logger.info("Started local k3d cluster '%s'.", cluster_name)
 
 
 def stop_k3d_cluster(cluster_name: str) -> None:
-    """Stops a K3D cluster with the given name."""
+    """Stops a K3D cluster with the given name.
+
+    Args:
+        cluster_name: Name of the cluster to stop.
+    """
     subprocess.check_call(["k3d", "cluster", "stop", cluster_name])
     logger.info("Stopped local k3d cluster '%s'.", cluster_name)
 
 
 def delete_k3d_cluster(cluster_name: str) -> None:
-    """Deletes a K3D cluster with the given name."""
+    """Deletes a K3D cluster with the given name.
+
+    Args:
+        cluster_name: Name of the cluster to delete.
+    """
     subprocess.check_call(["k3d", "cluster", "delete", cluster_name])
     logger.info("Deleted local k3d cluster '%s'.", cluster_name)
 
 
 def kubeflow_pipelines_ready(kubernetes_context: str) -> bool:
     """Returns whether all Kubeflow Pipelines pods are ready.
 
     Args:
         kubernetes_context: The kubernetes context in which the pods
             should be checked.
+
+    Returns:
+        Whether all Kubeflow Pipelines pods are ready.
     """
     try:
         subprocess.check_call(
             [
                 "kubectl",
                 "--context",
                 kubernetes_context,
@@ -238,19 +282,20 @@
     wait_until_kubeflow_pipelines_ready(kubernetes_context=kubernetes_context)
     logger.info("Finished Kubeflow Pipelines setup.")
 
 
 def add_hostpath_to_kubeflow_pipelines(
     kubernetes_context: str, local_path: str
 ) -> None:
-    """Patches the Kubeflow Pipelines deployment to mount a local folder as
-    a hostpath for visualization purposes.
+    """Patches the Kubeflow Pipelines deployment to mount a local folder.
+
+    This folder serves as a hostpath for visualization purposes.
 
     This function reconfigures the Kubeflow pipelines deployment to use a
-    shared local folder to support loading the Tensorboard viewer and other
+    shared local folder to support loading the TensorBoard viewer and other
     pipeline visualization results from a local artifact store, as described
     here:
 
     https://github.com/kubeflow/pipelines/blob/master/docs/config/volume-support.md
 
     Args:
         kubernetes_context: The kubernetes context on which Kubeflow Pipelines
@@ -364,16 +409,17 @@
 
 def start_kfp_ui_daemon(
     pid_file_path: str,
     log_file_path: str,
     port: int,
     kubernetes_context: str,
 ) -> None:
-    """Starts a daemon process that forwards ports so the Kubeflow Pipelines
-    UI is accessible in the browser.
+    """Starts a daemon process that forwards ports.
+
+    This is so the Kubeflow Pipelines UI is accessible in the browser.
 
     Args:
         pid_file_path: Path where the file with the daemons process ID should
             be written.
         log_file_path: Path to a file where the daemon logs should be written.
         port: Port on which the UI should be accessible.
         kubernetes_context: The kubernetes context for the cluster where
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/kubeflow/orchestrators/utils.py` & `zenml-0.9.0/src/zenml/integrations/kubeflow/orchestrators/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 
 # This file is copied in large parts from the tfx kubeflow entrypoint.
-
+"""Utils for ZenML Kubeflow orchestrators implementation."""
 import json
 import os
 import textwrap
 from typing import Callable, Dict, List, MutableMapping, Optional
 
 from kfp import dsl
 from kubernetes import client as k8s_client
@@ -48,35 +48,49 @@
 from zenml.repository import Repository
 
 
 def mount_config_map_op(
     config_map_name: str,
 ) -> Callable[[dsl.ContainerOp], None]:
     """Mounts all key-value pairs found in the named Kubernetes ConfigMap.
+
     All key-value pairs in the ConfigMap are mounted as environment variables.
+
     Args:
-      config_map_name: The name of the ConfigMap resource.
+        config_map_name: The name of the ConfigMap resource.
+
     Returns:
-      An OpFunc for mounting the ConfigMap.
+        An OpFunc for mounting the ConfigMap.
     """
 
     def mount_config_map(container_op: dsl.ContainerOp) -> None:
-        """Mounts all key-value pairs found in the Kubernetes ConfigMap."""
+        """Mounts all key-value pairs found in the Kubernetes ConfigMap.
+
+        Args:
+            container_op: The container op to mount the ConfigMap.
+        """
         config_map_ref = k8s_client.V1ConfigMapEnvSource(
             name=config_map_name, optional=True
         )
         container_op.container.add_env_from(
             k8s_client.V1EnvFromSource(config_map_ref=config_map_ref)
         )
 
     return mount_config_map
 
 
 def _sanitize_underscore(name: str) -> Optional[str]:
-    """Sanitize the underscore in pythonic name for markdown visualization."""
+    """Sanitize the underscore in pythonic name for markdown visualization.
+
+    Args:
+        name: the name to be sanitized.
+
+    Returns:
+        the sanitized name.
+    """
     if name:
         return str(name).replace("_", "\\_")
     else:
         return None
 
 
 def _render_channel_as_mdstr(input_channel: channel.Channel) -> str:
@@ -86,20 +100,19 @@
     **Artifact: artifact1**
     **Properties**:
     **key1**: value1
     **key2**: value2
     ......
 
     Args:
-      input_channel: the channel to be rendered.
+        input_channel: the channel to be rendered.
 
     Returns:
-      a md-formatted string representation of the channel.
+        a md-formatted string representation of the channel.
     """
-
     md_str = "**Type**: {}\n\n".format(
         _sanitize_underscore(input_channel.type_name)
     )
     rendered_artifacts = []
     # List all artifacts in the channel.
     for single_artifact in input_channel.get():
         rendered_artifacts.append(_render_artifact_as_mdstr(single_artifact))
@@ -114,18 +127,18 @@
     **Artifact: artifact1**
     **Properties**:
     **key1**: value1
     **key2**: value2
     ......
 
     Args:
-      single_artifact: the artifact to be rendered.
+        single_artifact: the artifact to be rendered.
 
     Returns:
-      a md-formatted string representation of the artifact.
+        a md-formatted string representation of the artifact.
     """
     span_str = "None"
     split_names_str = "None"
     if single_artifact.PROPERTIES:
         if "span" in single_artifact.PROPERTIES:
             span_str = str(single_artifact.span)
         if "split_names" in single_artifact.PROPERTIES:
@@ -173,21 +186,21 @@
     node: PipelineNode,
     execution_info: data_types.ExecutionInfo,
     metadata_ui_path: str,
 ) -> None:
     """Dump KFP UI metadata json file for visualization purpose.
 
     For general components we just render a simple Markdown file for
-      exec_properties/inputs/outputs.
+        exec_properties/inputs/outputs.
 
     Args:
-      node: associated TFX node.
-      execution_info: runtime execution info for this component, including
-        materialized inputs/outputs/execution properties and id.
-      metadata_ui_path: path to dump ui metadata.
+        node: associated TFX node.
+        execution_info: runtime execution info for this component, including
+            materialized inputs/outputs/execution properties and id.
+        metadata_ui_path: path to dump ui metadata.
     """
     exec_properties_list = [
         "**{}**: {}".format(
             _sanitize_underscore(name), _sanitize_underscore(exec_property)
         )
         for name, exec_property in execution_info.exec_properties.items()
     ]
@@ -198,19 +211,19 @@
     def _dump_input_populated_artifacts(
         node_inputs: MutableMapping[str, InputSpec],
         name_to_artifacts: Dict[str, List[artifact.Artifact]],
     ) -> List[str]:
         """Dump artifacts markdown string for inputs.
 
         Args:
-          node_inputs: maps from input name to input sepc proto.
-          name_to_artifacts: maps from input key to list of populated artifacts.
+            node_inputs: maps from input name to input sepc proto.
+            name_to_artifacts: maps from input key to list of populated    artifacts.
 
         Returns:
-          A list of dumped markdown string, each of which represents a channel.
+            A list of dumped markdown string, each of which represents a channel.
         """
         rendered_list = []
         for name, spec in node_inputs.items():
             # Need to look for materialized artifacts in the execution decision.
             rendered_artifacts = "".join(
                 [
                     _render_artifact_as_mdstr(single_artifact)
@@ -233,20 +246,20 @@
     def _dump_output_populated_artifacts(
         node_outputs: MutableMapping[str, OutputSpec],
         name_to_artifacts: Dict[str, List[artifact.Artifact]],
     ) -> List[str]:
         """Dump artifacts markdown string for outputs.
 
         Args:
-          node_outputs: maps from output name to output sepc proto.
-          name_to_artifacts: maps from output key to list of populated
-          artifacts.
+            node_outputs: maps from output name to output sepc proto.
+            name_to_artifacts: maps from output key to list of populated
+                artifacts.
 
         Returns:
-          A list of dumped markdown string, each of which represents a channel.
+            A list of dumped markdown string, each of which represents a channel.
         """
         rendered_list = []
         for name, spec in node_outputs.items():
             # Need to look for materialized artifacts in the execution decision.
             rendered_artifacts = "".join(
                 [
                     _render_artifact_as_mdstr(single_artifact)
@@ -293,15 +306,15 @@
                 exec_properties=src_str_exec_properties,
                 inputs=src_str_inputs,
                 outputs=src_str_outputs,
             ),
             "type": "markdown",
         }
     ]
-    # Add Tensorboard view for ModelRun outputs.
+    # Add TensorBoard view for ModelRun outputs.
     for name, spec in node.outputs.outputs.items():
         if (
             spec.artifact_spec.type.name
             == standard_artifacts.ModelRun.TYPE_NAME
             or spec.artifact_spec.type.name == ModelArtifact.TYPE_NAME
         ):
             output_model = execution_info.output_dict[name][0]
@@ -309,15 +322,15 @@
 
             # For local artifact repository, use a path that is relative to
             # the point where the local artifact folder is mounted as a volume
             artifact_store = Repository().active_stack.artifact_store
             if isinstance(artifact_store, LocalArtifactStore):
                 source = os.path.relpath(source, artifact_store.path)
                 source = f"volume://local-artifact-store/{source}"
-            # Add Tensorboard view.
+            # Add TensorBoard view.
             tensorboard_output = {
                 "type": "tensorboard",
                 "source": source,
             }
             outputs.append(tensorboard_output)
 
     metadata_dict = {"outputs": outputs}
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/lightgbm/__init__.py` & `zenml-0.9.0/src/zenml/integrations/lightgbm/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the LightGBM integration."""
+
 from zenml.integrations.constants import LIGHTGBM
 from zenml.integrations.integration import Integration
 
 
 class LightGBMIntegration(Integration):
     """Definition of lightgbm integration for ZenML."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/materializers/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.lightgbm.materializers.lightgbm_booster_materializer import (  # noqa
-    LightGBMBoosterMaterializer,
-)
-from zenml.integrations.lightgbm.materializers.lightgbm_dataset_materializer import (  # noqa
-    LightGBMDatasetMaterializer,
+"""Initialization of the whylogs materializer."""
+
+from zenml.integrations.whylogs.materializers.whylogs_materializer import (  # noqa
+    WhylogsMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/lightgbm_booster_materializer.py` & `zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/lightgbm_booster_materializer.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the LightGBM booster materializer."""
 
 import os
 import tempfile
 from typing import Any, Type
 
 import lightgbm as lgb
 
@@ -28,15 +29,22 @@
 class LightGBMBoosterMaterializer(BaseMaterializer):
     """Materializer to read data to and from lightgbm.Booster."""
 
     ASSOCIATED_TYPES = (lgb.Booster,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> lgb.Booster:
-        """Reads a lightgbm Booster model from a serialized JSON file."""
+        """Reads a lightgbm Booster model from a serialized JSON file.
+
+        Args:
+            data_type: A lightgbm Booster type.
+
+        Returns:
+            A lightgbm Booster object.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
         # Create a temporary folder
         temp_dir = tempfile.mkdtemp(prefix="zenml-temp-")
         temp_file = os.path.join(str(temp_dir), DEFAULT_FILENAME)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/lightgbm/materializers/lightgbm_dataset_materializer.py` & `zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/lightgbm_dataset_materializer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the LightGBM materializer."""
 
 import os
 import tempfile
 from typing import Any, Type
 
 import lightgbm as lgb
 
@@ -22,21 +23,28 @@
 from zenml.io import fileio
 from zenml.materializers.base_materializer import BaseMaterializer
 
 DEFAULT_FILENAME = "data.binary"
 
 
 class LightGBMDatasetMaterializer(BaseMaterializer):
-    """Materializer to read data to and from lightgbm.Dataset"""
+    """Materializer to read data to and from lightgbm.Dataset."""
 
     ASSOCIATED_TYPES = (lgb.Dataset,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> lgb.Dataset:
-        """Reads a lightgbm.Dataset binary file and loads it."""
+        """Reads a lightgbm.Dataset binary file and loads it.
+
+        Args:
+            data_type: A lightgbm.Dataset type.
+
+        Returns:
+            A lightgbm.Dataset object.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
         # Create a temporary folder
         temp_dir = tempfile.mkdtemp(prefix="zenml-temp-")
         temp_file = os.path.join(str(temp_dir), DEFAULT_FILENAME)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/__init__.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,17 +7,18 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The mlflow integrations currently enables you to use mlflow tracking as a
-convenient way to visualize your experiment runs within the mlflow ui
+"""Initialization for the ZenML MLflow integration.
+
+The MLflow integrations currently enables you to use MLflow tracking as a
+convenient way to visualize your experiment runs within the MLflow UI.
 """
 from typing import List
 
 from zenml.enums import StackComponentType
 from zenml.integrations.constants import MLFLOW
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
@@ -27,27 +28,31 @@
 
 
 class MlflowIntegration(Integration):
     """Definition of MLflow integration for ZenML."""
 
     NAME = MLFLOW
     REQUIREMENTS = [
-        "mlflow>=1.2.0",
+        "mlflow>=1.2.0,<1.26.0",
         "mlserver>=0.5.3",
         "mlserver-mlflow>=0.5.3",
     ]
 
     @classmethod
     def activate(cls) -> None:
         """Activate the MLflow integration."""
         from zenml.integrations.mlflow import services  # noqa
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the MLflow integration"""
+        """Declare the stack component flavors for the MLflow integration.
+
+        Returns:
+            List of stack component flavors for this integration.
+        """
         return [
             FlavorWrapper(
                 name=MLFLOW_MODEL_DEPLOYER_FLAVOR,
                 source="zenml.integrations.mlflow.model_deployers.MLFlowModelDeployer",
                 type=StackComponentType.MODEL_DEPLOYER,
                 integration=cls.NAME,
             ),
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/experiment_trackers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/experiment_trackers/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -5,10 +5,12 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the MLflow experiment tracker."""
+
 from zenml.integrations.mlflow.experiment_trackers.mlflow_experiment_tracker import (  # noqa
     MLFlowExperimentTracker,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/experiment_trackers/mlflow_experiment_tracker.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/experiment_trackers/mlflow_experiment_tracker.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the MLflow experiment tracker for ZenML."""
+
 import os
 from typing import Any, ClassVar, Dict, Optional
 
 import mlflow  # type: ignore[import]
 from mlflow.entities import Experiment  # type: ignore[import]
 from mlflow.store.db.db_types import DATABASE_ENGINES  # type: ignore[import]
 from pydantic import root_validator, validator
@@ -82,15 +84,25 @@
     # Class Configuration
     FLAVOR: ClassVar[str] = MLFLOW_MODEL_EXPERIMENT_TRACKER_FLAVOR
 
     @validator("tracking_uri")
     def _ensure_valid_tracking_uri(
         cls, tracking_uri: Optional[str] = None
     ) -> Optional[str]:
-        """Ensures that the tracking uri is a valid mlflow tracking uri."""
+        """Ensures that the tracking uri is a valid mlflow tracking uri.
+
+        Args:
+            tracking_uri: The tracking uri to validate.
+
+        Returns:
+            The tracking uri if it is valid.
+
+        Raises:
+            ValueError: If the tracking uri is not valid.
+        """
         if tracking_uri:
             valid_schemes = DATABASE_ENGINES + ["http", "https", "file"]
             if not any(
                 tracking_uri.startswith(scheme) for scheme in valid_schemes
             ):
                 raise ValueError(
                     f"MLflow tracking uri does not start with one of the valid "
@@ -100,16 +112,27 @@
                 )
         return tracking_uri
 
     @root_validator(skip_on_failure=True)
     def _ensure_authentication_if_necessary(
         cls, values: Dict[str, Any]
     ) -> Dict[str, Any]:
-        """Ensures that credentials or a token for authentication exist when
-        running MLflow tracking with a remote backend."""
+        """Ensures that credentials or a token for authentication exist.
+
+        We make this check when running MLflow tracking with a remote backend.
+
+        Args:
+            values: The values to validate.
+
+        Returns:
+            The validated values.
+
+        Raises:
+            ValueError: If neither credentials nor a token are provided.
+        """
         tracking_uri = values.get("tracking_uri")
 
         if tracking_uri and cls.is_remote_tracking_uri(tracking_uri):
             # we need either username + password or a token to authenticate to
             # the remote backend
             basic_auth = values.get("tracking_username") and values.get(
                 "tracking_password"
@@ -129,37 +152,47 @@
                     f"username and password or token."
                 )
 
         return values
 
     @staticmethod
     def is_remote_tracking_uri(tracking_uri: str) -> bool:
-        """Checks whether the given tracking uri is remote or not."""
+        """Checks whether the given tracking uri is remote or not.
+
+        Args:
+            tracking_uri: The tracking uri to check.
+
+        Returns:
+            `True` if the tracking uri is remote, `False` otherwise.
+        """
         return any(
             tracking_uri.startswith(prefix)
             for prefix in ["http://", "https://"]
         )
 
     @staticmethod
     def _local_mlflow_backend() -> str:
-        """Returns the local MLflow backend inside the ZenML artifact
-        repository directory
+        """Gets the local MLflow backend inside the ZenML artifact repository directory.
 
         Returns:
             The MLflow tracking URI for the local MLflow backend.
         """
         repo = Repository(skip_repository_check=True)  # type: ignore[call-arg]
         artifact_store = repo.active_stack.artifact_store
         local_mlflow_backend_uri = os.path.join(artifact_store.path, "mlruns")
         if not os.path.exists(local_mlflow_backend_uri):
             os.makedirs(local_mlflow_backend_uri)
         return "file:" + local_mlflow_backend_uri
 
     def get_tracking_uri(self) -> str:
-        """Returns the configured tracking URI or a local fallback."""
+        """Returns the configured tracking URI or a local fallback.
+
+        Returns:
+            The tracking URI.
+        """
         return self.tracking_uri or self._local_mlflow_backend()
 
     def configure_mlflow(self) -> None:
         """Configures the MLflow tracking URI and any additional credentials."""
         mlflow.set_tracking_uri(self.get_tracking_uri())
 
         if self.tracking_username:
@@ -178,16 +211,19 @@
 
     def cleanup_step_run(self) -> None:
         """Resets the MLflow tracking uri."""
         mlflow.set_tracking_uri("")
 
     @property
     def validator(self) -> Optional["StackValidator"]:
-        """Validates that the stack has a `LocalArtifactStore` if no tracking
-        uri was specified."""
+        """Checks the stack has a `LocalArtifactStore` if no tracking uri was specified.
+
+        Returns:
+            An optional `StackValidator`.
+        """
         if self.tracking_uri:
             # user specified a tracking uri, do nothing
             return None
         else:
             # try to fall back to a tracking uri inside the zenml artifact
             # store. this only works in case of a local artifact store, so we
             # make sure to prevent stack with other artifact stores for now
@@ -197,27 +233,35 @@
                     "MLflow experiment tracker without a specified tracking "
                     "uri only works with a local artifact store.",
                 )
             )
 
     @property
     def active_experiment(self) -> Optional[Experiment]:
-        """Returns the currently active MLflow experiment."""
+        """Returns the currently active MLflow experiment.
+
+        Returns:
+            The active experiment or `None` if no experiment is active.
+        """
         step_env = Environment().step_environment
 
         if not step_env:
             # we're not inside a step
             return None
 
         mlflow.set_experiment(experiment_name=step_env.pipeline_name)
         return mlflow.get_experiment_by_name(step_env.pipeline_name)
 
     @property
     def active_run(self) -> Optional[mlflow.ActiveRun]:
-        """Returns the currently active MLflow run."""
+        """Returns the currently active MLflow run.
+
+        Returns:
+            The active MLflow run.
+        """
         step_env = Environment().step_environment
 
         if not self.active_experiment or not step_env:
             return None
 
         experiment_id = self.active_experiment.experiment_id
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/mlflow_step_decorator.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/mlflow_step_decorator.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the MLflow StepDecorator."""
+
 import functools
 from typing import Any, Callable, Optional, Type, TypeVar, Union, cast, overload
 
 from zenml.integrations.mlflow.experiment_trackers.mlflow_experiment_tracker import (
     MLFlowExperimentTracker,
 )
 from zenml.integrations.mlflow.mlflow_utils import (
@@ -35,21 +37,19 @@
 S = TypeVar("S", bound=Type[BaseStep])
 
 
 @overload
 def enable_mlflow(
     _step: S,
 ) -> S:
-    """Type annotations for mlflow step decorator in case of no arguments."""
     ...
 
 
 @overload
 def enable_mlflow() -> Callable[[S], S]:
-    """Type annotations for mlflow step decorator in case of arguments."""
     ...
 
 
 def enable_mlflow(
     _step: Optional[S] = None,
 ) -> Union[S, Callable[[S], S]]:
     """Decorator to enable mlflow for a step function.
@@ -69,14 +69,28 @@
         model: tf.keras.Model,
     ) -> float:
         _, test_acc = model.evaluate(x_test, y_test, verbose=2)
         mlflow.log_metric("val_accuracy", test_acc)
         return test_acc
     ```
 
+    You can also use this decorator with our class-based API like so:
+
+    ```
+    @enable_mlflow
+    class TFEvaluator(BaseStep):
+        def entrypoint(
+            self,
+            x_test: np.ndarray,
+            y_test: np.ndarray,
+            model: tf.keras.Model,
+        ) -> float:
+            ...
+    ```
+
     All MLflow artifacts and metrics logged from all the steps in a pipeline
     run are by default grouped under a single experiment named after the
     pipeline. To log MLflow artifacts and metrics from a step in a separate
     MLflow experiment, pass a custom `experiment_name` argument value to the
     decorator.
 
     Args:
@@ -94,27 +108,22 @@
         )
         if not issubclass(_step, BaseStep):
             raise RuntimeError(
                 "The `enable_mlflow` decorator can only be applied to a ZenML "
                 "`step` decorated function or a BaseStep subclass."
             )
         source_fn = getattr(_step, STEP_INNER_FUNC_NAME)
-        return cast(
-            S,
-            type(  # noqa
-                _step.__name__,
-                (_step,),
-                {
-                    STEP_INNER_FUNC_NAME: staticmethod(
-                        mlflow_step_entrypoint()(source_fn)
-                    ),
-                    "__module__": _step.__module__,
-                },
-            ),
-        )
+        new_entrypoint = mlflow_step_entrypoint()(source_fn)
+        if _step._created_by_functional_api():
+            # If the step was created by the functional API, the old entrypoint
+            # was a static method -> make sure the new one is as well
+            new_entrypoint = staticmethod(new_entrypoint)
+
+        setattr(_step, STEP_INNER_FUNC_NAME, new_entrypoint)
+        return _step
 
     if _step is None:
         return inner_decorator
     else:
         return inner_decorator(_step)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/mlflow_utils.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/mlflow_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of utils specific to the MLflow integration."""
 
 from mlflow import (  # type: ignore[import]
     ActiveRun,
     get_experiment_by_name,
     search_runs,
     set_experiment,
     set_tracking_uri,
@@ -28,37 +29,37 @@
 from zenml.logger import get_logger
 from zenml.repository import Repository
 
 logger = get_logger(__name__)
 
 
 def get_missing_mlflow_experiment_tracker_error() -> ValueError:
-    """Returns a detailed error that describes how to add an MLflow experiment
-    tracker component to your stack."""
+    """Returns description of how to add an MLflow experiment tracker to your stack.
+
+    Returns:
+        ValueError: If no MLflow experiment tracker is registered in the active stack.
+    """
     return ValueError(
         "The active stack needs to have a MLflow experiment tracker "
         "component registered to be able to track experiments using "
         "MLflow. You can create a new stack with a MLflow experiment "
         "tracker component or update your existing stack to add this "
         "component, e.g.:\n\n"
         "  'zenml experiment-tracker register mlflow_tracker "
         "--type=mlflow'\n"
         "  'zenml stack register stack-name -e mlflow_tracker ...'\n"
     )
 
 
 def get_tracking_uri() -> str:
-    """Gets the MLflow tracking URI from the active experiment tracking stack
-    component.
+    """Gets the MLflow tracking URI from the active experiment tracking stack component.
+
+    # noqa: DAR401
 
     Returns:
         MLflow tracking URI.
-
-    Raises:
-        ValueError: If the active stack contains no MLflow experiment tracking
-            component.
     """
     tracker = Repository().active_stack.experiment_tracker
     if tracker is None or not isinstance(tracker, MLFlowExperimentTracker):
         raise get_missing_mlflow_experiment_tracker_error()
 
     return tracker.get_tracking_uri()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/model_deployers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/model_deployers/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -5,10 +5,12 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the MLflow model deployers."""
+
 from zenml.integrations.mlflow.model_deployers.mlflow_model_deployer import (  # noqa
     MLFlowModelDeployer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/model_deployers/mlflow_model_deployer.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/model_deployers/mlflow_model_deployer.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the MLflow model deployer."""
+
 import os
 import shutil
 import uuid
 from pathlib import Path
 from typing import Any, ClassVar, Dict, List, Optional, cast
 from uuid import UUID
 
@@ -25,58 +27,65 @@
     LOCAL_STORES_DIRECTORY_NAME,
 )
 from zenml.integrations.mlflow import MLFLOW_MODEL_DEPLOYER_FLAVOR
 from zenml.integrations.mlflow.services.mlflow_deployment import (
     MLFlowDeploymentConfig,
     MLFlowDeploymentService,
 )
-from zenml.io.utils import (
-    create_dir_recursive_if_not_exists,
-    get_global_config_directory,
-)
 from zenml.logger import get_logger
 from zenml.model_deployers.base_model_deployer import BaseModelDeployer
 from zenml.repository import Repository
 from zenml.services import ServiceRegistry
 from zenml.services.local.local_service import SERVICE_DAEMON_CONFIG_FILE_NAME
 from zenml.services.service import BaseService, ServiceConfig
+from zenml.utils.io_utils import (
+    create_dir_recursive_if_not_exists,
+    get_global_config_directory,
+)
 
 logger = get_logger(__name__)
 
 
 class MLFlowModelDeployer(BaseModelDeployer):
-    """MLflow implementation of the BaseModelDeployer
+    """MLflow implementation of the BaseModelDeployer.
 
     Attributes:
         service_path: the path where the local MLflow deployment service
         configuration, PID and log files are stored.
     """
 
     service_path: str = ""
 
     # Class Configuration
     FLAVOR: ClassVar[str] = MLFLOW_MODEL_DEPLOYER_FLAVOR
 
     @root_validator(skip_on_failure=True)
     def set_service_path(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        """Sets the service_path attribute value according to the component
-        UUID."""
+        """Sets the service_path attribute value according to the component UUID.
+
+        Args:
+            values: the dictionary of values to be validated.
+
+        Returns:
+            The validated dictionary of values.
+        """
         if values.get("service_path"):
             return values
 
         # not likely to happen, due to Pydantic validation, but mypy complains
         assert "uuid" in values
 
         values["service_path"] = cls.get_service_path(values["uuid"])
         return values
 
     @staticmethod
     def get_service_path(uuid: uuid.UUID) -> str:
-        """Get the path the path where the local MLflow deployment service
-        configuration, PID and log files are stored.
+        """Get the path where local MLflow service information is stored.
+
+        This includes the deployment service configuration, PID and log files are stored.
 
         Args:
             uuid: The UUID of the MLflow model deployer.
 
         Returns:
             The service path.
         """
@@ -86,52 +95,55 @@
             str(uuid),
         )
         create_dir_recursive_if_not_exists(service_path)
         return service_path
 
     @property
     def local_path(self) -> str:
-        """
-        Returns the path to the root directory where all configurations for
-        MLflow deployment daemon processes are stored.
+        """Returns the path to the root directory.
+
+        This is where all configurations for MLflow deployment daemon processes are stored.
 
         Returns:
             The path to the local service root directory.
         """
         return self.service_path
 
     @staticmethod
     def get_model_server_info(  # type: ignore[override]
         service_instance: "MLFlowDeploymentService",
     ) -> Dict[str, Optional[str]]:
-        """Return implementation specific information that might be relevant
-        to the user.
+        """Return implementation specific information relevant to the user.
 
         Args:
             service_instance: Instance of a SeldonDeploymentService
-        """
 
+        Returns:
+            A dictionary containing the information.
+        """
         return {
             "PREDICTION_URL": service_instance.endpoint.prediction_url,
             "MODEL_URI": service_instance.config.model_uri,
             "MODEL_NAME": service_instance.config.model_name,
             "SERVICE_PATH": service_instance.status.runtime_path,
             "DAEMON_PID": str(service_instance.status.pid),
         }
 
     @staticmethod
     def get_active_model_deployer() -> "MLFlowModelDeployer":
-        """
-        Returns the MLFlowModelDeployer component of the active stack.
+        """Returns the MLFlowModelDeployer component of the active stack.
 
         Args:
             None
 
         Returns:
             The MLFlowModelDeployer component of the active stack.
+
+        Raises:
+            TypeError: If the active stack does not contain an MLFlowModelDeployer component.
         """
         model_deployer = Repository(  # type: ignore[call-arg]
             skip_repository_check=True
         ).active_stack.model_deployer
 
         if not model_deployer or not isinstance(
             model_deployer, MLFlowModelDeployer
@@ -149,16 +161,17 @@
 
     def deploy_model(
         self,
         config: ServiceConfig,
         replace: bool = False,
         timeout: int = DEFAULT_SERVICE_START_STOP_TIMEOUT,
     ) -> BaseService:
-        """Create a new MLflow deployment service or update an existing one to
-        serve the supplied model and deployment configuration.
+        """Create a new MLflow deployment service or update an existing one.
+
+        This should serve the supplied model and deployment configuration.
 
         This method has two modes of operation, depending on the `replace`
         argument value:
 
           * if `replace` is False, calling this method will create a new MLflow
             deployment server to reflect the model and other configuration
             parameters specified in the supplied MLflow service `config`.
@@ -189,20 +202,14 @@
                 to be provisioned and successfully started or updated. If set
                 to 0, the method will return immediately after the MLflow
                 server is provisioned, without waiting for it to fully start.
 
         Returns:
             The ZenML MLflow deployment service object that can be used to
             interact with the MLflow model server.
-
-        Raises:
-            RuntimeError: if `timeout` is set to a positive value that is
-                exceeded while waiting for the MLflow deployment server
-                to start, or if an operational failure is encountered before
-                it reaches a ready state.
         """
         config = cast(MLFlowDeploymentConfig, config)
         service = None
 
         # if replace is True, remove all existing services
         if replace is True:
             existing_services = self.find_model_server(
@@ -260,16 +267,25 @@
 
     # the step will receive a config from the user that mentions the number
     # of workers etc.the step implementation will create a new config using
     # all values from the user and add values like pipeline name, model_uri
     def _create_new_service(
         self, timeout: int, config: MLFlowDeploymentConfig
     ) -> MLFlowDeploymentService:
-        """Creates a new MLFlowDeploymentService."""
+        """Creates a new MLFlowDeploymentService.
 
+        Args:
+            timeout: the timeout in seconds to wait for the MLflow server
+                to be provisioned and successfully started or updated.
+            config: the configuration of the model to be deployed with MLflow.
+
+        Returns:
+            The MLFlowDeploymentService object that can be used to interact
+            with the MLflow model server.
+        """
         # set the root runtime path with the stack component's UUID
         config.root_runtime_path = self.local_path
         # create a new service for the new model
         service = MLFlowDeploymentService(config)
         service.start(timeout=timeout)
 
         return service
@@ -281,37 +297,38 @@
         pipeline_name: Optional[str] = None,
         pipeline_run_id: Optional[str] = None,
         pipeline_step_name: Optional[str] = None,
         model_name: Optional[str] = None,
         model_uri: Optional[str] = None,
         model_type: Optional[str] = None,
     ) -> List[BaseService]:
-        """Method to find one or more model servers that match the
-        given criteria.
+        """Finds one or more model servers that match the given criteria.
 
         Args:
             running: If true, only running services will be returned.
             service_uuid: The UUID of the service that was originally used
                 to deploy the model.
             pipeline_name: Name of the pipeline that the deployed model was part
-            of.
+                of.
             pipeline_run_id: ID of the pipeline run which the deployed model
                 was part of.
             pipeline_step_name: The name of the pipeline model deployment step
                 that deployed the model.
             model_name: Name of the deployed model.
             model_uri: URI of the deployed model.
             model_type: Type/format of the deployed model. Not used in this
                 MLflow case.
 
         Returns:
             One or more Service objects representing model servers that match
             the input search criteria.
-        """
 
+        Raises:
+            TypeError: if any of the input arguments are of an invalid type.
+        """
         services = []
         config = MLFlowDeploymentConfig(
             model_name=model_name or "",
             model_uri=model_uri or "",
             pipeline_name=pipeline_name or "",
             pipeline_run_id=pipeline_run_id or "",
             pipeline_step_name=pipeline_step_name or "",
@@ -349,27 +366,30 @@
         return services
 
     def _matches_search_criteria(
         self,
         existing_service: MLFlowDeploymentService,
         config: MLFlowDeploymentConfig,
     ) -> bool:
-        """Returns true if a service matches the input criteria. If any of
-        the values in the input criteria are None, they are ignored. This
-        allows listing services just by common pipeline names or step names,
-        etc.
+        """Returns true if a service matches the input criteria.
+
+        If any of the values in the input criteria are None, they are ignored.
+        This allows listing services just by common pipeline names or step
+        names, etc.
 
         Args:
             existing_service: The materialized Service instance derived from
                 the config of the older (existing) service
             config: The MLFlowDeploymentConfig object passed to the
                 deploy_model function holding parameters of the new service
                 to be created.
-        """
 
+        Returns:
+            True if the service matches the input criteria.
+        """
         existing_service_config = existing_service.config
 
         # check if the existing service matches the input criteria
         if (
             (
                 not config.pipeline_name
                 or existing_service_config.pipeline_name == config.pipeline_name
@@ -416,14 +436,15 @@
     def start_model_server(
         self, uuid: UUID, timeout: int = DEFAULT_SERVICE_START_STOP_TIMEOUT
     ) -> None:
         """Method to start a model server.
 
         Args:
             uuid: UUID of the model server to start.
+            timeout: Timeout in seconds to wait for the service to start.
         """
         # get list of all services
         existing_services = self.find_model_server(service_uuid=uuid)
 
         # if the service exists, start it
         if existing_services:
             existing_services[0].start(timeout=timeout)
@@ -434,14 +455,16 @@
         timeout: int = DEFAULT_SERVICE_START_STOP_TIMEOUT,
         force: bool = False,
     ) -> None:
         """Method to delete all configuration of a model server.
 
         Args:
             uuid: UUID of the model server to delete.
+            timeout: Timeout in seconds to wait for the service to stop.
+            force: If True, force the service to stop.
         """
         # get list of all services
         existing_services = self.find_model_server(service_uuid=uuid)
 
         # if the service exists, clean it up
         if existing_services:
             service = cast(MLFlowDeploymentService, existing_services[0])
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/services/__init__.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/services/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,11 +7,13 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the MLflow Service."""
+
 from zenml.integrations.mlflow.services.mlflow_deployment import (  # noqa
     MLFlowDeploymentConfig,
     MLFlowDeploymentService,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/services/mlflow_deployment.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/services/mlflow_deployment.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,7 +1,22 @@
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#
+#  Licensed under the Apache License, Version 2.0 (the "License");
+#  you may not use this file except in compliance with the License.
+#  You may obtain a copy of the License at:
+#
+#       http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+#  or implied. See the License for the specific language governing
+#  permissions and limitations under the License.
+"""Implementation of the MLflow deployment functionality."""
+
 from typing import TYPE_CHECKING, Any, Dict, Optional, Union
 
 import numpy as np
 import requests
 from mlflow.pyfunc.backend import PyFuncBackend  # type: ignore [import]
 from mlflow.version import VERSION as MLFLOW_VERSION  # type: ignore [import]
 
@@ -48,14 +63,19 @@
     """
 
     config: MLFlowDeploymentEndpointConfig
     monitor: HTTPEndpointHealthMonitor
 
     @property
     def prediction_url(self) -> Optional[str]:
+        """Gets the prediction URL for the endpoint.
+
+        Returns:
+            the prediction URL for the endpoint
+        """
         uri = self.status.uri
         if not uri:
             return None
         return f"{uri}{self.config.prediction_url_path}"
 
 
 class MLFlowDeploymentConfig(LocalDaemonServiceConfig):
@@ -73,16 +93,15 @@
     model_uri: str
     model_name: str
     workers: int = 1
     mlserver: bool = False
 
 
 class MLFlowDeploymentService(LocalDaemonService):
-    """MLFlow deployment service that can be used to start a local prediction
-    server for MLflow models.
+    """MLflow deployment service used to start a local prediction server for MLflow models.
 
     Attributes:
         SERVICE_TYPE: a service type descriptor with information describing
             the MLflow deployment service class
         config: service configuration
         endpoint: optional service endpoint
     """
@@ -98,14 +117,20 @@
     endpoint: MLFlowDeploymentEndpoint
 
     def __init__(
         self,
         config: Union[MLFlowDeploymentConfig, Dict[str, Any]],
         **attrs: Any,
     ) -> None:
+        """Initialize the MLflow deployment service.
+
+        Args:
+            config: service configuration
+            attrs: additional attributes to set on the service
+        """
         # ensure that the endpoint is created before the service is initialized
         # TODO [ENG-700]: implement a service factory or builder for MLflow
         #   deployment services
         if (
             isinstance(config, MLFlowDeploymentConfig)
             and "endpoint" not in attrs
         ):
@@ -130,14 +155,15 @@
                     )
                 ),
             )
             attrs["endpoint"] = endpoint
         super().__init__(config=config, **attrs)
 
     def run(self) -> None:
+        """Start the service."""
         logger.info(
             "Starting MLflow prediction service as blocking "
             "process... press CTRL+C once to stop it."
         )
 
         self.endpoint.prepare_for_start()
 
@@ -182,14 +208,18 @@
         """Make a prediction using the service.
 
         Args:
             request: a numpy array representing the request
 
         Returns:
             A numpy array representing the prediction returned by the service.
+
+        Raises:
+            Exception: if the service is not running
+            ValueError: if the prediction endpoint is unknown.
         """
         if not self.is_running:
             raise Exception(
                 "MLflow prediction service is not running. "
                 "Please start the service before making predictions."
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/seldon/steps/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -7,13 +7,13 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for Seldon steps."""
 
-from zenml.integrations.mlflow.steps.mlflow_deployer import (
-    MLFlowDeployerConfig,
-    mlflow_deployer_step,
-    mlflow_model_deployer_step,
+from zenml.integrations.seldon.steps.seldon_deployer import (
+    SeldonDeployerStepConfig,
+    seldon_model_deployer_step,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/mlflow/steps/mlflow_deployer.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/steps/mlflow_deployer.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the MLflow model deployer pipeline step."""
 
 from typing import Optional, Type, cast
 
 from mlflow import get_artifact_uri  # type: ignore[import]
 from mlflow.tracking import MlflowClient  # type: ignore[import]
 
 from zenml.artifacts.model_artifact import ModelArtifact
@@ -44,15 +45,15 @@
     step,
 )
 
 logger = get_logger(__name__)
 
 
 class MLFlowDeployerConfig(BaseStepConfig):
-    """MLflow model deployer step configuration
+    """Model deployer step configuration for MLflow.
 
     Attributes:
         model_name: the name of the MLflow model logged in the MLflow artifact
             store for the current pipeline.
         workers: number of workers to use for the prediction service
         mlserver: set to True to use the MLflow MLServer backend (see
             https://github.com/SeldonIO/MLServer). If False, the
@@ -70,15 +71,17 @@
 @enable_mlflow
 @step(enable_cache=False)
 def mlflow_model_deployer_step(
     deploy_decision: bool,
     model: ModelArtifact,
     config: MLFlowDeployerConfig,
 ) -> MLFlowDeploymentService:
-    """MLflow model deployer pipeline step
+    """Model deployer pipeline step for MLflow.
+
+    # noqa: DAR401
 
     Args:
         deploy_decision: whether to deploy the model or not
         model: the model artifact to deploy
         config: configuration for the deployer step
 
     Returns:
@@ -194,23 +197,23 @@
     return new_service
 
 
 def mlflow_deployer_step(
     enable_cache: bool = True,
     name: Optional[str] = None,
 ) -> Type[BaseStep]:
-    """Shortcut function to create a pipeline step to deploy a given ML model
-    with a local MLflow prediction server.
+    """Creates a pipeline step to deploy a given ML model with a local MLflow prediction server.
 
     The returned step can be used in a pipeline to implement continuous
     deployment for an MLflow model.
 
     Args:
         enable_cache: Specify whether caching is enabled for this step. If no
             value is passed, caching is enabled by default
+        name: Name of the step.
 
     Returns:
         an MLflow model deployer pipeline step
     """
     logger.warning(
         "The `mlflow_deployer_step` function is deprecated. Please "
         "use the built-in `mlflow_model_deployer_step` step instead."
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/__init__.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the sklearn integration."""
 
-from zenml.integrations.constants import NEURAL_PROPHET
+from zenml.integrations.constants import SKLEARN
 from zenml.integrations.integration import Integration
-from zenml.utils.source_utils import import_class_by_path
 
 
-class NeuralProphetIntegration(Integration):
-    """Definition of NeuralProphet integration for ZenML."""
+class SklearnIntegration(Integration):
+    """Definition of sklearn integration for ZenML."""
 
-    NAME = NEURAL_PROPHET
-    REQUIREMENTS = ["neuralprophet>=0.3.2"]
+    NAME = SKLEARN
+    REQUIREMENTS = ["scikit-learn"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        from zenml.integrations.neural_prophet import materializers  # noqa
+        from zenml.integrations.sklearn import materializers  # noqa
 
 
-NeuralProphetIntegration.check_installation()
+SklearnIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/neural_prophet/materializers/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,10 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Neural Prophet materializer."""
+
 from zenml.integrations.neural_prophet.materializers.neural_prophet_materializer import (  # noqa
     NeuralProphetMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/neural_prophet/materializers/neural_prophet_materializer.py` & `zenml-0.9.0/src/zenml/integrations/neural_prophet/materializers/neural_prophet_materializer.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Neural Prophet materializer."""
 
 import os
 from typing import Any, Type
 
 import torch
 from neuralprophet import NeuralProphet
 
@@ -34,14 +35,17 @@
 
     ASSOCIATED_TYPES = (NeuralProphet,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> NeuralProphet:
         """Reads and returns a NeuralProphet model.
 
+        Args:
+            data_type: A NeuralProphet model object.
+
         Returns:
             A loaded NeuralProphet model.
         """
         super().handle_input(data_type)
         return torch.load(  # type: ignore[no-untyped-call]
             os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         )  # noqa
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/plotly/__init__.py` & `zenml-0.9.0/src/zenml/integrations/plotly/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Plotly integration."""
+
 from zenml.integrations.constants import PLOTLY
 from zenml.integrations.integration import Integration
 
 
 class PlotlyIntegration(Integration):
     """Definition of Plotly integration for ZenML."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/plotly/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/facets/visualizers/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,7 +7,8 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Intitialization of the Facet Visualizer."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/plotly/visualizers/pipeline_lineage_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/plotly/visualizers/pipeline_lineage_visualizer.py`

 * *Files 25% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Plotly Pipeline Lineage Visualizer."""
 
 from abc import abstractmethod
 from typing import Any
 
 import pandas as pd
 import plotly.express as px
 from plotly.graph_objs import Figure
@@ -32,15 +33,24 @@
 class PipelineLineageVisualizer(BasePipelineVisualizer):
     """Visualize the lineage of runs in a pipeline using plotly."""
 
     @abstractmethod
     def visualize(
         self, object: PipelineView, *args: Any, **kwargs: Any
     ) -> Figure:
-        """Creates a pipeline lineage diagram using plotly."""
+        """Creates a pipeline lineage diagram using plotly.
+
+        Args:
+            object: The pipeline view to visualize.
+            *args: Additional arguments to pass to the visualization.
+            **kwargs: Additional keyword arguments to pass to the visualization.
+
+        Returns:
+            A plotly figure.
+        """
         logger.warning(
             "This integration is not completed yet. Results might be unexpected."
         )
 
         category_dict = {}
         dimensions = ["run"]
         for run in object.runs:
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch/__init__.py` & `zenml-0.9.0/src/zenml/integrations/pytorch_lightning/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,26 +7,26 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the PyTorch Lightning integration."""
 
-from zenml.integrations.constants import PYTORCH
+from zenml.integrations.constants import PYTORCH_L
 from zenml.integrations.integration import Integration
-from zenml.utils.source_utils import import_class_by_path
 
 
-class PytorchIntegration(Integration):
-    """Definition of PyTorch integration for ZenML."""
+class PytorchLightningIntegration(Integration):
+    """Definition of PyTorch Lightning integration for ZenML."""
 
-    NAME = PYTORCH
-    REQUIREMENTS = ["torch"]
+    NAME = PYTORCH_L
+    REQUIREMENTS = ["pytorch_lightning"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        from zenml.integrations.pytorch import materializers  # noqa
+        from zenml.integrations.pytorch_lightning import materializers  # noqa
 
 
-PytorchIntegration.check_installation()
+PytorchLightningIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,13 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.pytorch.materializers.pytorch_dataloader_materializer import (  # noqa
-    PyTorchDataLoaderMaterializer,
+"""Initialization for the TensorFlow materializers."""
+
+from zenml.integrations.tensorflow.materializers.keras_materializer import (  # noqa
+    KerasMaterializer,
 )
-from zenml.integrations.pytorch.materializers.pytorch_module_materializer import (  # noqa
-    PyTorchModuleMaterializer,
+from zenml.integrations.tensorflow.materializers.tf_dataset_materializer import (  # noqa
+    TensorflowDatasetMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/pytorch_dataloader_materializer.py` & `zenml-0.9.0/src/zenml/integrations/pytorch/materializers/pytorch_dataloader_materializer.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the PyTorch DataLoader materializer."""
 
 import os
 from typing import Any, Type, cast
 
 import torch
 from torch.utils.data.dataloader import DataLoader
 
@@ -23,22 +24,25 @@
 from zenml.materializers.base_materializer import BaseMaterializer
 
 DEFAULT_FILENAME = "entire_dataloader.pt"
 CHECKPOINT_FILENAME = "checkpoint.pt"
 
 
 class PyTorchDataLoaderMaterializer(BaseMaterializer):
-    """Materializer to read/write Pytorch dataloaders."""
+    """Materializer to read/write PyTorch dataloaders."""
 
     ASSOCIATED_TYPES = (DataLoader,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> DataLoader[Any]:
         """Reads and returns a PyTorch dataloader.
 
+        Args:
+            data_type: The type of the dataloader to load.
+
         Returns:
             A loaded PyTorch dataloader.
         """
         super().handle_input(data_type)
         with fileio.open(
             os.path.join(self.artifact.uri, DEFAULT_FILENAME), "rb"
         ) as f:
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch/materializers/pytorch_module_materializer.py` & `zenml-0.9.0/src/zenml/integrations/pytorch/materializers/pytorch_module_materializer.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the PyTorch Module materializer."""
 
 import os
 from typing import Any, Type
 
 import torch
 from torch.nn import Module  # type: ignore[attr-defined]
 
@@ -23,23 +24,30 @@
 from zenml.materializers.base_materializer import BaseMaterializer
 
 DEFAULT_FILENAME = "entire_model.pt"
 CHECKPOINT_FILENAME = "checkpoint.pt"
 
 
 class PyTorchModuleMaterializer(BaseMaterializer):
-    """Materializer to read/write Pytorch models. Inspired by the guide:
-    https://pytorch.org/tutorials/beginner/saving_loading_models.html"""
+    """Materializer to read/write Pytorch models.
+
+    Inspired by the guide:
+    https://pytorch.org/tutorials/beginner/saving_loading_models.html
+    """
 
     ASSOCIATED_TYPES = (Module,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> Module:
-        """Reads and returns a PyTorch model. Only loads the model, not
-        the checkpoint.
+        """Reads and returns a PyTorch model.
+
+        Only loads the model, not the checkpoint.
+
+        Args:
+            data_type: The type of the model to load.
 
         Returns:
             A loaded pytorch model.
         """
         super().handle_input(data_type)
         with fileio.open(
             os.path.join(self.artifact.uri, DEFAULT_FILENAME), "rb"
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/__init__.py` & `zenml-0.9.0/src/zenml/integrations/scipy/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,24 +7,26 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.constants import PYTORCH_L
+"""Initialization of the Scipy integration."""
+
+from zenml.integrations.constants import SCIPY
 from zenml.integrations.integration import Integration
 
 
-class PytorchLightningIntegration(Integration):
-    """Definition of PyTorch Lightning integration for ZenML."""
+class ScipyIntegration(Integration):
+    """Definition of scipy integration for ZenML."""
 
-    NAME = PYTORCH_L
-    REQUIREMENTS = ["pytorch_lightning"]
+    NAME = SCIPY
+    REQUIREMENTS = ["scipy"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        from zenml.integrations.pytorch_lightning import materializers  # noqa
+        from zenml.integrations.scipy import materializers  # noqa
 
 
-PytorchLightningIntegration.check_installation()
+ScipyIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/scipy/materializers/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -7,11 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Scipy materializers."""
 
-from zenml.integrations.pytorch_lightning.materializers.pytorch_lightning_materializer import (  # noqa
-    PyTorchLightningMaterializer,
+from zenml.integrations.scipy.materializers.sparse_materializer import (  # noqa
+    SparseMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/pytorch_lightning/materializers/pytorch_lightning_materializer.py` & `zenml-0.9.0/src/zenml/integrations/pytorch_lightning/materializers/pytorch_lightning_materializer.py`

 * *Files 20% similar despite different names*

```diff
@@ -7,35 +7,39 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the PyTorch Lightning Materializer."""
 
 import os
 from typing import Any, Type
 
 from pytorch_lightning.trainer import Trainer
 
 from zenml.artifacts import ModelArtifact
 from zenml.materializers.base_materializer import BaseMaterializer
 
 CHECKPOINT_NAME = "final_checkpoint.ckpt"
 
 
 class PyTorchLightningMaterializer(BaseMaterializer):
-    """Materializer to read/write Pytorch models."""
+    """Materializer to read/write PyTorch models."""
 
     ASSOCIATED_TYPES = (Trainer,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> Trainer:
         """Reads and returns a PyTorch Lightning trainer.
 
+        Args:
+            data_type: The type of the trainer to load.
+
         Returns:
             A PyTorch Lightning trainer object.
         """
         super().handle_input(data_type)
         return Trainer(
             resume_from_checkpoint=os.path.join(
                 self.artifact.uri, CHECKPOINT_NAME
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/registry.py` & `zenml-0.9.0/src/zenml/integrations/registry.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,78 +7,103 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a registry to track ZenML integrations."""
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type
 
 from zenml.exceptions import IntegrationError
 from zenml.logger import get_logger
 
 if TYPE_CHECKING:
     from zenml.integrations.integration import Integration
 
 logger = get_logger(__name__)
 
 
 class IntegrationRegistry(object):
-    """Registry to keep track of ZenML Integrations"""
+    """Registry to keep track of ZenML Integrations."""
 
     def __init__(self) -> None:
-        """Initializing the integration registry"""
+        """Initializing the integration registry."""
         self._integrations: Dict[str, Type["Integration"]] = {}
 
     @property
     def integrations(self) -> Dict[str, Type["Integration"]]:
         """Method to get integrations dictionary.
 
         Returns:
             A dict of integration key to type of `Integration`.
         """
         return self._integrations
 
     @integrations.setter
     def integrations(self, i: Any) -> None:
-        """Setter method for the integrations property"""
+        """Setter method for the integrations property.
+
+        Args:
+            i: Value to set the integrations property to.
+
+        Raises:
+            IntegrationError: If you try to manually set the integrations property.
+        """
         raise IntegrationError(
             "Please do not manually change the integrations within the "
             "registry. If you would like to register a new integration "
             "manually, please use "
             "`integration_registry.register_integration()`."
         )
 
     def register_integration(
         self, key: str, type_: Type["Integration"]
     ) -> None:
-        """Method to register an integration with a given name"""
+        """Method to register an integration with a given name.
+
+        Args:
+            key: Name of the integration.
+            type_: Type of the integration.
+        """
         self._integrations[key] = type_
 
     def activate_integrations(self) -> None:
-        """Method to activate the integrations with are registered in the
-        registry"""
+        """Method to activate the integrations with are registered in the registry."""
         for name, integration in self._integrations.items():
             if integration.check_installation():
                 integration.activate()
                 logger.debug(f"Integration `{name}` is activated.")
             else:
                 logger.debug(f"Integration `{name}` could not be activated.")
 
     @property
     def list_integration_names(self) -> List[str]:
-        """Get a list of all possible integrations"""
+        """Get a list of all possible integrations.
+
+        Returns:
+            A list of all possible integrations.
+        """
         return [name for name in self._integrations]
 
     def select_integration_requirements(
         self, integration_name: Optional[str] = None
     ) -> List[str]:
-        """Select the requirements for a given integration
-        or all integrations"""
+        """Select the requirements for a given integration or all integrations.
+
+        Args:
+            integration_name: Name of the integration to check.
+
+        Returns:
+            List of requirements for the integration.
+
+        Raises:
+            KeyError: If the integration is not found.
+        """
         if integration_name:
             if integration_name in self.list_integration_names:
                 return self._integrations[integration_name].REQUIREMENTS
             else:
                 raise KeyError(
                     f"Version {integration_name} does not exist. "
                     f"Currently the following integrations are implemented. "
@@ -88,15 +113,25 @@
             return [
                 requirement
                 for name in self.list_integration_names
                 for requirement in self._integrations[name].REQUIREMENTS
             ]
 
     def is_installed(self, integration_name: Optional[str] = None) -> bool:
-        """Checks if all requirements for an integration are installed"""
+        """Checks if all requirements for an integration are installed.
+
+        Args:
+            integration_name: Name of the integration to check.
+
+        Returns:
+            True if all requirements are installed, False otherwise.
+
+        Raises:
+            KeyError: If the integration is not found.
+        """
         if integration_name in self.list_integration_names:
             return self._integrations[integration_name].check_installation()
         elif not integration_name:
             all_installed = [
                 self._integrations[item].check_installation()
                 for item in self.list_integration_names
             ]
@@ -105,15 +140,19 @@
             raise KeyError(
                 f"Integration '{integration_name}' not found. "
                 f"Currently the following integrations are available: "
                 f"{self.list_integration_names}"
             )
 
     def get_installed_integrations(self) -> List[str]:
-        """Returns list of installed integrations."""
+        """Returns list of installed integrations.
+
+        Returns:
+            List of installed integrations.
+        """
         return [
             name
             for name, integration in integration_registry.integrations.items()
             if integration.check_installation()
         ]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/s3/artifact_stores/__init__.py` & `zenml-0.9.0/src/zenml/pipelines/builtin_pipelines/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for ZenML builtin pipelines."""
 
-from zenml.integrations.s3.artifact_stores.s3_artifact_store import (  # noqa
-    S3ArtifactStore,
-)
+from zenml.pipelines.builtin_pipelines.training_pipeline import TrainingPipeline
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/s3/artifact_stores/s3_artifact_store.py` & `zenml-0.9.0/src/zenml/integrations/s3/artifact_stores/s3_artifact_store.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
+"""Implementation of the S3 Artifact Store."""
 
 import json
 from typing import (
     Any,
     Callable,
     ClassVar,
     Dict,
@@ -29,20 +29,22 @@
 )
 
 import s3fs
 from pydantic import validator
 
 from zenml.artifact_stores import BaseArtifactStore
 from zenml.integrations.s3 import S3_ARTIFACT_STORE_FLAVOR
-from zenml.io.utils import convert_to_str
+from zenml.secret.schemas import AWSSecretSchema
+from zenml.stack.authentication_mixin import AuthenticationMixin
+from zenml.utils.io_utils import convert_to_str
 
 PathType = Union[bytes, str]
 
 
-class S3ArtifactStore(BaseArtifactStore):
+class S3ArtifactStore(BaseArtifactStore, AuthenticationMixin):
     """Artifact Store for S3 based artifacts.
 
     All attributes of this class except `path` will be passed to the
     `s3fs.S3FileSystem` initialization. See
     [here](https://s3fs.readthedocs.io/en/latest/) for more information on how
     to use those configuration options to connect to any S3-compatible storage.
 
@@ -69,16 +71,21 @@
 
     @validator(
         "client_kwargs", "config_kwargs", "s3_additional_kwargs", pre=True
     )
     def _convert_json_string(
         cls, value: Union[None, str, Dict[str, Any]]
     ) -> Optional[Dict[str, Any]]:
-        """Converts potential JSON strings passed via the CLI to
-        dictionaries.
+        """Converts potential JSON strings passed via the CLI to dictionaries.
+
+        Args:
+            value: The value to convert.
+
+        Returns:
+            The converted value.
 
         Raises:
             TypeError: If the value is not a `str`, `Dict` or `None`.
             ValueError: If the value is an invalid json string or a json string
                 that does not decode into a dictionary.
         """
         if isinstance(value, str):
@@ -94,166 +101,258 @@
 
             return dict_
         elif isinstance(value, Dict) or value is None:
             return value
         else:
             raise TypeError(f"{value} is not a json string or a dictionary.")
 
+    def _get_credentials(
+        self,
+    ) -> Tuple[Optional[str], Optional[str], Optional[str]]:
+        """Gets authentication credentials.
+
+        If an authentication secret is configured, the secret values are
+        returned. Otherwise we fallback to the plain text component attributes.
+
+        Returns:
+            Tuple (key, secret, token) of credentials used to authenticate with
+            the S3 filesystem.
+        """
+        secret = self.get_authentication_secret(
+            expected_schema_type=AWSSecretSchema
+        )
+        if secret:
+            return (
+                secret.aws_access_key_id,
+                secret.aws_secret_access_key,
+                secret.aws_session_token,
+            )
+        else:
+            return self.key, self.secret, self.token
+
     @property
     def filesystem(self) -> s3fs.S3FileSystem:
-        """The s3 filesystem to access this artifact store."""
+        """The s3 filesystem to access this artifact store.
+
+        Returns:
+            The s3 filesystem.
+        """
         if not self._filesystem:
+            key, secret, token = self._get_credentials()
+
             self._filesystem = s3fs.S3FileSystem(
-                key=self.key,
-                secret=self.secret,
-                token=self.token,
+                key=key,
+                secret=secret,
+                token=token,
                 client_kwargs=self.client_kwargs,
                 config_kwargs=self.config_kwargs,
                 s3_additional_kwargs=self.s3_additional_kwargs,
             )
         return self._filesystem
 
     def open(self, path: PathType, mode: str = "r") -> Any:
         """Open a file at the given path.
+
         Args:
             path: Path of the file to open.
             mode: Mode in which to open the file. Currently, only
                 'rb' and 'wb' to read and write binary files are supported.
+
+        Returns:
+            A file-like object.
         """
         return self.filesystem.open(path=path, mode=mode)
 
     def copyfile(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Copy a file.
+
         Args:
             src: The path to copy from.
             dst: The path to copy to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to copy to destination '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to copy anyway."
             )
 
         # TODO [ENG-151]: Check if it works with overwrite=True or if we need to
         #  manually remove it first
         self.filesystem.copy(path1=src, path2=dst)
 
     def exists(self, path: PathType) -> bool:
-        """Check whether a path exists."""
+        """Check whether a path exists.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path exists, False otherwise.
+        """
         return self.filesystem.exists(path=path)  # type: ignore[no-any-return]
 
     def glob(self, pattern: PathType) -> List[PathType]:
         """Return all paths that match the given glob pattern.
+
         The glob pattern may include:
         - '*' to match any number of characters
         - '?' to match a single character
         - '[...]' to match one of the characters inside the brackets
         - '**' as the full name of a path component to match to search
-          in subdirectories of any depth (e.g. '/some_dir/**/some_file)
+            in subdirectories of any depth (e.g. '/some_dir/**/some_file)
+
         Args:
             pattern: The glob pattern to match, see details above.
+
         Returns:
             A list of paths that match the given glob pattern.
         """
         return [f"s3://{path}" for path in self.filesystem.glob(path=pattern)]
 
     def isdir(self, path: PathType) -> bool:
-        """Check whether a path is a directory."""
+        """Check whether a path is a directory.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if the path is a directory, False otherwise.
+        """
         return self.filesystem.isdir(path=path)  # type: ignore[no-any-return]
 
     def listdir(self, path: PathType) -> List[PathType]:
-        """Return a list of files in a directory."""
+        """Return a list of files in a directory.
+
+        Args:
+            path: The path to list.
+
+        Returns:
+            A list of paths that are files in the given directory.
+        """
         # remove s3 prefix if given, so we can remove the directory later as
         # this method is expected to only return filenames
         path = convert_to_str(path)
         if path.startswith("s3://"):
             path = path[5:]
 
         def _extract_basename(file_dict: Dict[str, Any]) -> str:
-            """Extracts the basename from a file info dict returned by the S3
-            filesystem."""
+            """Extracts the basename from a file info dict returned by the S3 filesystem.
+
+            Args:
+                file_dict: A file info dict returned by the S3 filesystem.
+
+            Returns:
+                The basename of the file.
+            """
             file_path = cast(str, file_dict["Key"])
             base_name = file_path[len(path) :]
             return base_name.lstrip("/")
 
         return [
             _extract_basename(dict_)
             for dict_ in self.filesystem.listdir(path=path)
             # s3fs.listdir also returns the root directory, so we filter
             # it out here
             if _extract_basename(dict_)
         ]
 
     def makedirs(self, path: PathType) -> None:
-        """Create a directory at the given path. If needed also
-        create missing parent directories."""
+        """Create a directory at the given path.
+
+        If needed also create missing parent directories.
+
+        Args:
+            path: The path to create.
+        """
         self.filesystem.makedirs(path=path, exist_ok=True)
 
     def mkdir(self, path: PathType) -> None:
-        """Create a directory at the given path."""
+        """Create a directory at the given path.
+
+        Args:
+            path: The path to create.
+        """
         self.filesystem.makedir(path=path)
 
     def remove(self, path: PathType) -> None:
-        """Remove the file at the given path."""
+        """Remove the file at the given path.
+
+        Args:
+            path: The path of the file to remove.
+        """
         self.filesystem.rm_file(path=path)
 
     def rename(
         self, src: PathType, dst: PathType, overwrite: bool = False
     ) -> None:
         """Rename source file to destination file.
+
         Args:
             src: The path of the file to rename.
             dst: The path to rename the source file to.
             overwrite: If a file already exists at the destination, this
                 method will overwrite it if overwrite=`True` and
                 raise a FileExistsError otherwise.
+
         Raises:
-            FileNotFoundError: If the source file does not exist.
             FileExistsError: If a file already exists at the destination
                 and overwrite is not set to `True`.
         """
         if not overwrite and self.filesystem.exists(dst):
             raise FileExistsError(
                 f"Unable to rename file to '{convert_to_str(dst)}', "
                 f"file already exists. Set `overwrite=True` to rename anyway."
             )
 
         # TODO [ENG-152]: Check if it works with overwrite=True or if we need
         #  to manually remove it first
         self.filesystem.rename(path1=src, path2=dst)
 
     def rmtree(self, path: PathType) -> None:
-        """Remove the given directory."""
+        """Remove the given directory.
+
+        Args:
+            path: The path of the directory to remove.
+        """
         self.filesystem.delete(path=path, recursive=True)
 
     def stat(self, path: PathType) -> Dict[str, Any]:
-        """Return stat info for the given path."""
+        """Return stat info for the given path.
+
+        Args:
+            path: The path to get stat info for.
+
+        Returns:
+            A dictionary containing the stat info.
+        """
         return self.filesystem.stat(path=path)  # type: ignore[no-any-return]
 
     def walk(
         self,
         top: PathType,
         topdown: bool = True,
         onerror: Optional[Callable[..., None]] = None,
     ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:
         """Return an iterator that walks the contents of the given directory.
+
         Args:
             top: Path of directory to walk.
             topdown: Unused argument to conform to interface.
             onerror: Unused argument to conform to interface.
-        Returns:
+
+        Yields:
             An Iterable of Tuples, each of which contain the path of the current
-            directory path, a list of directories inside the current directory
-            and a list of files inside the current directory.
+                directory path, a list of directories inside the current directory
+                and a list of files inside the current directory.
         """
         # TODO [ENG-153]: Additional params
         for directory, subdirectories, files in self.filesystem.walk(path=top):
             yield f"s3://{directory}", subdirectories, files
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sagemaker/__init__.py` & `zenml-0.9.0/src/zenml/integrations/huggingface/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,49 +1,32 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The Sagemaker integration submodule provides a way to run ZenML steps in
-Sagemaker.
-"""
+"""Initialization of the Huggingface integration."""
 
-
-from typing import List
-
-from zenml.enums import StackComponentType
-from zenml.integrations.constants import SAGEMAKER
+from zenml.integrations.constants import HUGGINGFACE
 from zenml.integrations.integration import Integration
-from zenml.zen_stores.models import FlavorWrapper
-
-SAGEMAKER_STEP_OPERATOR_FLAVOR = "sagemaker"
 
 
-class SagemakerIntegration(Integration):
-    """Definition of Sagemaker integration for ZenML."""
+class HuggingfaceIntegration(Integration):
+    """Definition of Huggingface integration for ZenML."""
 
-    NAME = SAGEMAKER
-    REQUIREMENTS = ["sagemaker==2.82.2"]
+    NAME = HUGGINGFACE
+    REQUIREMENTS = ["transformers", "datasets"]
 
     @classmethod
-    def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Sagemaker integration."""
-        return [
-            FlavorWrapper(
-                name=SAGEMAKER_STEP_OPERATOR_FLAVOR,
-                source="zenml.integrations.sagemaker.step_operators.SagemakerStepOperator",
-                type=StackComponentType.STEP_OPERATOR,
-                integration=cls.NAME,
-            )
-        ]
+    def activate(cls) -> None:
+        """Activates the integration."""
+        from zenml.integrations.huggingface import materializers  # noqa
 
 
-SagemakerIntegration.check_installation()
+HuggingfaceIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sagemaker/step_operators/__init__.py` & `zenml-0.9.0/src/zenml/integrations/seldon/model_deployers/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 #  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the Seldon Model Deployer."""
 
-from zenml.integrations.sagemaker.step_operators.sagemaker_step_operator import (  # noqa
-    SagemakerStepOperator,
+from zenml.integrations.seldon.model_deployers.seldon_model_deployer import (  # noqa
+    SeldonModelDeployer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sagemaker/step_operators/sagemaker_step_operator.py` & `zenml-0.9.0/src/zenml/integrations/aws/step_operators/sagemaker_step_operator.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,21 +7,22 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Sagemaker Step Operator."""
 
 from typing import ClassVar, List, Optional, Tuple
 
 import sagemaker
 
 from zenml.enums import StackComponentType
-from zenml.integrations.sagemaker import SAGEMAKER_STEP_OPERATOR_FLAVOR
+from zenml.integrations.aws import AWS_SAGEMAKER_STEP_OPERATOR_FLAVOR
 from zenml.repository import Repository
 from zenml.stack import Stack, StackValidator
 from zenml.step_operators import BaseStepOperator
 from zenml.utils import docker_utils
 from zenml.utils.source_utils import get_source_root_path
 
 
@@ -49,19 +50,23 @@
     instance_type: str
 
     base_image: Optional[str] = None
     bucket: Optional[str] = None
     experiment_name: Optional[str] = None
 
     # Class Configuration
-    FLAVOR: ClassVar[str] = SAGEMAKER_STEP_OPERATOR_FLAVOR
+    FLAVOR: ClassVar[str] = AWS_SAGEMAKER_STEP_OPERATOR_FLAVOR
 
     @property
     def validator(self) -> Optional[StackValidator]:
-        """Validates that the stack contains a container registry."""
+        """Validates that the stack contains a container registry.
+
+        Returns:
+            A validator that checks that the stack contains a container registry.
+        """
 
         def _ensure_local_orchestrator(stack: Stack) -> Tuple[bool, str]:
             return (
                 stack.orchestrator.FLAVOR == "local",
                 "Local orchestrator is required",
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/scipy/__init__.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,30 +1,33 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.constants import SCIPY
+"""Initialization of the whylogs integration."""
+
+from zenml.integrations.constants import WHYLOGS
 from zenml.integrations.integration import Integration
 
 
-class ScipyIntegration(Integration):
-    """Definition of scipy integration for ZenML."""
+class WhylogsIntegration(Integration):
+    """Definition of [whylogs](https://github.com/whylabs/whylogs) integration for ZenML."""
 
-    NAME = SCIPY
-    REQUIREMENTS = ["scipy"]
+    NAME = WHYLOGS
+    REQUIREMENTS = ["whylogs<=0.7.9", "pybars3>=0.9.7"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        from zenml.integrations.scipy import materializers  # noqa
+        from zenml.integrations.whylogs import materializers  # noqa
+        from zenml.integrations.whylogs import visualizers  # noqa
 
 
-ScipyIntegration.check_installation()
+WhylogsIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/scipy/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/mlflow/steps/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,16 +1,20 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.scipy.materializers.sparse_materializer import (  # noqa
-    SparseMaterializer,
+"""Initialization of the MLflow standard interface steps."""
+
+from zenml.integrations.mlflow.steps.mlflow_deployer import (
+    MLFlowDeployerConfig,
+    mlflow_deployer_step,
+    mlflow_model_deployer_step,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/scipy/materializers/sparse_materializer.py` & `zenml-0.9.0/src/zenml/integrations/scipy/materializers/sparse_materializer.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Scipy Sparse Materializer."""
 
 import os
 from typing import Any, Type
 
 from scipy.sparse import load_npz, save_npz, spmatrix
 
 from zenml.artifacts import DataArtifact
@@ -27,15 +28,22 @@
 class SparseMaterializer(BaseMaterializer):
     """Materializer to read and write scipy sparse matrices."""
 
     ASSOCIATED_TYPES = (spmatrix,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> spmatrix:
-        """Reads spmatrix from npz file."""
+        """Reads spmatrix from npz file.
+
+        Args:
+            data_type: The type of the spmatrix to load.
+
+        Returns:
+            A spmatrix object.
+        """
         super().handle_input(data_type)
         with fileio.open(
             os.path.join(self.artifact.uri, DATA_FILENAME), "rb"
         ) as f:
             mat = load_npz(f)
         return mat
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/__init__.py` & `zenml-0.9.0/src/zenml/integrations/slack/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,49 +7,46 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The Seldon Core integration allows you to use the Seldon Core model serving
-platform to implement continuous model deployment.
-"""
+"""Slack integration for alerter components."""
+
 from typing import List
 
 from zenml.enums import StackComponentType
-from zenml.integrations.constants import SELDON
+from zenml.integrations.constants import SLACK
 from zenml.integrations.integration import Integration
 from zenml.zen_stores.models import FlavorWrapper
 
-SELDON_MODEL_DEPLOYER_FLAVOR = "seldon"
+SLACK_ALERTER_FLAVOR = "slack"
 
 
-class SeldonIntegration(Integration):
-    """Definition of Seldon Core integration for ZenML."""
+class SlackIntegration(Integration):
+    """Definition of a Slack integration for ZenML.
 
-    NAME = SELDON
-    REQUIREMENTS = [
-        "kubernetes==18.20.0",
-    ]
+    Implemented using [Slack SDK](https://pypi.org/project/slack-sdk/).
+    """
 
-    @classmethod
-    def activate(cls) -> None:
-        """Activate the Seldon Core integration."""
-        from zenml.integrations.seldon import secret_schemas  # noqa
-        from zenml.integrations.seldon import services  # noqa
+    NAME = SLACK
+    REQUIREMENTS = ["slack-sdk>=3.16.1", "aiohttp>=3.8.1"]
 
     @classmethod
     def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Seldon Core."""
+        """Declare the stack component flavors for the Slack integration.
+
+        Returns:
+            List of new flavors defined by the Slack integration.
+        """
         return [
             FlavorWrapper(
-                name=SELDON_MODEL_DEPLOYER_FLAVOR,
-                source="zenml.integrations.seldon.model_deployers.SeldonModelDeployer",
-                type=StackComponentType.MODEL_DEPLOYER,
+                name=SLACK_ALERTER_FLAVOR,
+                source="zenml.integrations.slack.alerters.slack_alerter.SlackAlerter",
+                type=StackComponentType.ALERTER,
                 integration=cls.NAME,
             )
         ]
 
 
-SeldonIntegration.check_installation()
+SlackIntegration.check_installation()
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/model_deployers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/azure/secrets_managers/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 #  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.seldon.model_deployers.seldon_model_deployer import (  # noqa
-    SeldonModelDeployer,
+"""Initialization of the Azure Secrets Manager integration."""
+
+from zenml.integrations.azure.secrets_managers.azure_secrets_manager import (  # noqa
+    AzureSecretsManager,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/model_deployers/seldon_model_deployer.py` & `zenml-0.9.0/src/zenml/integrations/seldon/model_deployers/seldon_model_deployer.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Seldon Model Deployer."""
 
 import re
 from datetime import datetime
 from typing import ClassVar, Dict, List, Optional, cast
 from uuid import UUID
 
 from zenml.integrations.seldon import SELDON_MODEL_DEPLOYER_FLAVOR
@@ -69,34 +70,36 @@
     # private attributes
     _client: Optional[SeldonClient] = None
 
     @staticmethod
     def get_model_server_info(  # type: ignore[override]
         service_instance: "SeldonDeploymentService",
     ) -> Dict[str, Optional[str]]:
-        """ "Return implementation specific information that might be relevant
-        to the user.
+        """Return implementation specific information that might be relevant to the user.
 
         Args:
             service_instance: Instance of a SeldonDeploymentService
-        """
 
+        Returns:
+            Model server information.
+        """
         return {
             "PREDICTION_URL": service_instance.prediction_url,
             "MODEL_URI": service_instance.config.model_uri,
             "MODEL_NAME": service_instance.config.model_name,
             "SELDON_DEPLOYMENT": service_instance.seldon_deployment_name,
         }
 
     @staticmethod
     def get_active_model_deployer() -> "SeldonModelDeployer":
         """Get the Seldon Core model deployer registered in the active stack.
 
         Returns:
             The Seldon Core model deployer registered in the active stack.
+
         Raises:
             TypeError: if the Seldon Core model deployer is not available.
         """
         model_deployer = Repository(  # type: ignore [call-arg]
             skip_repository_check=True
         ).active_stack.model_deployer
         if not model_deployer or not isinstance(
@@ -117,18 +120,14 @@
 
     @property
     def seldon_client(self) -> SeldonClient:
         """Get the Seldon Core client associated with this model deployer.
 
         Returns:
             The Seldon Core client.
-
-        Raises:
-            SeldonClientError: if the Kubernetes client configuration cannot be
-                found.
         """
         if not self._client:
             self._client = SeldonClient(
                 context=self.kubernetes_context,
                 namespace=self.kubernetes_namespace,
             )
         return self._client
@@ -151,23 +150,24 @@
         return (
             re.sub(r"[^0-9a-zA-Z-]+", "-", f"zenml-seldon-core-{self.secret}")
             .strip("-")
             .lower()
         )
 
     def _create_or_update_kubernetes_secret(self) -> Optional[str]:
-        """Create or update a Kubernetes secret with the information stored in
-        the ZenML secret configured for the model deployer.
+        """Create or update a Kubernetes secret.
+
+        Uses the information stored in the ZenML secret configured for the model deployer.
 
         Returns:
             The name of the Kubernetes secret that was created or updated, or
             None if no secret was configured.
 
         Raises:
-            SeldonClientError: if the secret cannot be created or updated.
+            RuntimeError: if the secret cannot be created or updated.
         """
         # if a ZenML secret was configured in the model deployer,
         # create a Kubernetes secret as a means to pass this information
         # to the Seldon Core deployment
         if self.secret:
 
             secret_manager = Repository(  # type: ignore [call-arg]
@@ -197,19 +197,17 @@
             self.seldon_client.create_or_update_secret(
                 self.kubernetes_secret_name, zenml_secret
             )
 
         return self.kubernetes_secret_name
 
     def _delete_kubernetes_secret(self) -> None:
-        """Delete the Kubernetes secret associated with this model deployer
-        if no Seldon Core deployments are using it.
+        """Delete the Kubernetes secret associated with this model deployer.
 
-        Raises:
-            SeldonClientError: if the secret cannot be deleted.
+        Do this if no Seldon Core deployments are using it.
         """
         if self.kubernetes_secret_name:
 
             # fetch all the Seldon Core deployments that currently
             # configured to use this secret
             services = self.find_model_server()
             for service in services:
@@ -220,16 +218,19 @@
 
     def deploy_model(
         self,
         config: ServiceConfig,
         replace: bool = False,
         timeout: int = DEFAULT_SELDON_DEPLOYMENT_START_STOP_TIMEOUT,
     ) -> BaseService:
-        """Create a new Seldon Core deployment or update an existing one to
-        serve the supplied model and deployment configuration.
+        """Create a new Seldon Core deployment or update an existing one.
+
+        # noqa: DAR402
+
+        This should serve the supplied model and deployment configuration.
 
         This method has two modes of operation, depending on the `replace`
         argument value:
 
           * if `replace` is False, calling this method will create a new Seldon
             Core deployment server to reflect the model and other configuration
             parameters specified in the supplied Seldon deployment `config`.
@@ -330,16 +331,15 @@
         pipeline_name: Optional[str] = None,
         pipeline_run_id: Optional[str] = None,
         pipeline_step_name: Optional[str] = None,
         model_name: Optional[str] = None,
         model_uri: Optional[str] = None,
         model_type: Optional[str] = None,
     ) -> List[BaseService]:
-        """Find one or more Seldon Core model services that match th given
-        criteria.
+        """Find one or more Seldon Core model services that match the given criteria.
 
         The Seldon Core deployment services that meet the search criteria are
         returned sorted in descending order of their creation time (i.e. more
         recent deployments first).
 
         Args:
             running: if true, only running services will be returned.
@@ -410,14 +410,18 @@
     ) -> None:
         """Stop a Seldon Core model server.
 
         Args:
             uuid: UUID of the model server to stop.
             timeout: timeout in seconds to wait for the service to stop.
             force: if True, force the service to stop.
+
+        Raises:
+            NotImplementedError: stopping Seldon Core model servers is not
+                supported.
         """
         raise NotImplementedError(
             "Stopping Seldon Core model servers is not implemented. Try "
             "deleting the Seldon Core model server instead."
         )
 
     def start_model_server(
@@ -429,14 +433,18 @@
 
         Args:
             uuid: UUID of the model server to start.
             timeout: timeout in seconds to wait for the service to become
                 active. . If set to 0, the method will return immediately after
                 provisioning the service, without waiting for it to become
                 active.
+
+        Raises:
+            NotImplementedError: since we don't support starting Seldon Core
+                model servers
         """
         raise NotImplementedError(
             "Starting Seldon Core model servers is not implemented"
         )
 
     def delete_model_server(
         self,
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/secret_schemas/__init__.py` & `zenml-0.9.0/src/zenml/integrations/seldon/secret_schemas/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,16 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Seldon Secret Schemas
+"""Initialization for the Seldon secret schemas.
 
 These are secret schemas that can be used to authenticate Seldon to the
 Artifact Store used to store served ML models.
 """
 from zenml.integrations.seldon.secret_schemas.secret_schemas import (
     SELDON_AZUREBLOB_SECRET_SCHEMA_TYPE,
     SELDON_GS_SECRET_SCHEMA_TYPE,
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/secret_schemas/secret_schemas.py` & `zenml-0.9.0/src/zenml/integrations/seldon/secret_schemas/secret_schemas.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation for Seldon secret schemas."""
+
 from typing import ClassVar, Optional
 
 from typing_extensions import Literal
 
 from zenml.secret import register_secret_schema_class
 from zenml.secret.base_secret import BaseSecretSchema
 
@@ -59,15 +61,14 @@
 @register_secret_schema_class
 class SeldonGSSecretSchema(BaseSecretSchema):
     """Seldon GCS credentials.
 
     Based on: https://rclone.org/googlecloudstorage/
 
     Attributes:
-
         rclone_config_gs_type: the rclone config type. Must be set to "google
             cloud storage" for this schema.
         rclone_config_gs_client_id: OAuth client id.
         rclone_config_gs_client_secret: OAuth client secret.
         rclone_config_gs_token: OAuth Access Token as a JSON blob.
         rclone_config_gs_project_number: project number.
         rclone_config_gs_service_account_credentials: service account
@@ -96,15 +97,14 @@
 @register_secret_schema_class
 class SeldonAzureSecretSchema(BaseSecretSchema):
     """Seldon Azure Blob Storage credentials.
 
     Based on: https://rclone.org/azureblob/
 
     Attributes:
-
         rclone_config_azureblob_type: the rclone config type. Must be set to
             "azureblob" for this schema.
         rclone_config_azureblob_account: storage Account Name. Leave blank to
             use SAS URL or MSI.
         rclone_config_azureblob_key: storage Account Key. Leave blank to
             use SAS URL or MSI.
         rclone_config_azureblob_sas_url: SAS URL for container level access
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/seldon_client.py` & `zenml-0.9.0/src/zenml/integrations/seldon/seldon_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Seldon client for ZenML."""
 
 import base64
 import json
 import re
 import time
 from typing import Dict, Generator, List, Optional
 
@@ -173,15 +174,14 @@
     url: str
 
 
 class SeldonDeploymentStatusCondition(BaseModel):
     """The Kubernetes status condition entry for a Seldon Deployment.
 
     Attributes:
-
         type: Type of runtime condition.
         status: Status of the condition.
         reason: Brief CamelCase string containing reason for the condition's
             last transition.
         message: Human-readable message indicating details about last
             transition.
     """
@@ -243,14 +243,19 @@
     metadata: SeldonDeploymentMetadata = Field(
         default_factory=SeldonDeploymentMetadata
     )
     spec: SeldonDeploymentSpec = Field(default_factory=SeldonDeploymentSpec)
     status: Optional[SeldonDeploymentStatus]
 
     def __str__(self) -> str:
+        """Returns a string representation of the Seldon Deployment.
+
+        Returns:
+            A string representation of the Seldon Deployment.
+        """
         return json.dumps(self.dict(exclude_none=True), indent=4)
 
     @classmethod
     def build(
         cls,
         name: Optional[str] = None,
         model_uri: Optional[str] = None,
@@ -275,15 +280,14 @@
             annotations: A dictionary of annotations to apply to the Seldon
                 Deployment.
 
         Returns:
             A minimal SeldonDeployment object built from the provided
             parameters.
         """
-
         if not name:
             name = f"zenml-{time.time()}"
 
         if labels is None:
             labels = {}
         if annotations is None:
             annotations = {}
@@ -385,16 +389,15 @@
             None.
         """
         if self.status and self.is_failed():
             return self.status.description
         return None
 
     def get_pending_message(self) -> Optional[str]:
-        """Get a message describing the pending conditions of the Seldon
-        Deployment.
+        """Get a message describing the pending conditions of the Seldon Deployment.
 
         Returns:
             A message describing the pending condition of the Seldon
             Deployment, or None, if no conditions are pending.
         """
         if not self.status or not self.status.conditions:
             return None
@@ -417,42 +420,45 @@
 
 
 class SeldonClientError(Exception):
     """Base exception class for all exceptions raised by the SeldonClient."""
 
 
 class SeldonClientTimeout(SeldonClientError):
-    """Raised when the Seldon client timed out while waiting for a resource
-    to reach the expected status."""
+    """Raised when the Seldon client timed out while waiting for a resource to reach the expected status."""
 
 
 class SeldonDeploymentExistsError(SeldonClientError):
-    """Raised when a SeldonDeployment resource cannot be created because a
-    resource with the same name already exists."""
+    """Raised when a SeldonDeployment resource cannot be created because a resource with the same name already exists."""
 
 
 class SeldonDeploymentNotFoundError(SeldonClientError):
-    """Raised when a particular SeldonDeployment resource is not found or is
-    not managed by ZenML."""
+    """Raised when a particular SeldonDeployment resource is not found or is not managed by ZenML."""
 
 
 class SeldonClient:
+    """A client for interacting with Seldon Deployments."""
+
     def __init__(self, context: Optional[str], namespace: Optional[str]):
         """Initialize a Seldon Core client.
 
         Args:
             context: the Kubernetes context to use.
             namespace: the Kubernetes namespace to use.
         """
         self._context = context
         self._namespace = namespace
         self._initialize_k8s_clients()
 
     def _initialize_k8s_clients(self) -> None:
-        """Initialize the Kubernetes clients."""
+        """Initialize the Kubernetes clients.
+
+        Raises:
+            SeldonClientError: if Kubernetes configuration could not be loaded
+        """
         try:
             k8s_config.load_incluster_config()
             if not self._namespace:
                 # load the namespace in the context of which the
                 # current pod is running
                 self._namespace = open(
                     "/var/run/secrets/kubernetes.io/serviceaccount/namespace"
@@ -474,15 +480,19 @@
         self._core_api = k8s_client.CoreV1Api()
         self._custom_objects_api = k8s_client.CustomObjectsApi()
 
     @staticmethod
     def sanitize_labels(labels: Dict[str, str]) -> None:
         """Update the label values to be valid Kubernetes labels.
 
-        See: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set
+        See:
+        https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set
+
+        Args:
+            labels: the labels to sanitize.
         """
         for key, value in labels.items():
             # Kubernetes labels must be alphanumeric, no longer than
             # 63 characters, and must begin and end with an alphanumeric
             # character ([a-z0-9A-Z])
             labels[key] = re.sub(r"[^0-9a-zA-Z-_\.]+", "_", value)[:63].strip(
                 "-_."
@@ -490,14 +500,17 @@
 
     @property
     def namespace(self) -> str:
         """Returns the Kubernetes namespace in use by the client.
 
         Returns:
             The Kubernetes namespace in use by the client.
+
+        Raises:
+            RuntimeError: if the namespace has not been configured.
         """
         if not self._namespace:
             # shouldn't happen if the client is initialized, but we need to
             # appease the mypy type checker
             raise RuntimeError("The Kubernetes namespace is not configured")
         return self._namespace
 
@@ -518,16 +531,14 @@
 
         Returns:
             the created Seldon Core deployment resource with updated status.
 
         Raises:
             SeldonDeploymentExistsError: if a deployment with the same name
                 already exists.
-            SeldonDeploymentNotFoundError: if the newly created deployment
-                resource cannot be found.
             SeldonClientError: if an unknown error occurs during the creation of
                 the deployment.
         """
         try:
             logger.debug(f"Creating SeldonDeployment resource: {deployment}")
 
             # mark the deployment as managed by ZenML, to differentiate
@@ -581,16 +592,14 @@
             poll_timeout: the maximum time to wait for the deployment to be
                 deleted. If set to 0, the function will return immediately
                 without checking the deployment status. If a timeout
                 occurs and the deployment still exists, this method will
                 return and no exception will be raised.
 
         Raises:
-            SeldonDeploymentNotFoundError: if the deployment resource cannot be
-                found or is not managed by ZenML.
             SeldonClientError: if an unknown error occurs during the deployment
                 removal.
         """
         try:
             logger.debug(f"Deleting SeldonDeployment resource: {name}")
 
             # call `get_deployment` to check that the deployment exists
@@ -641,16 +650,14 @@
                 occurs and the deployment is still pending creation, it will
                 be returned anyway and no exception will be raised.
 
         Returns:
             the updated Seldon Core deployment resource with updated status.
 
         Raises:
-            SeldonDeploymentNotFoundError: if deployment resource with the given
-                name cannot be found.
             SeldonClientError: if an unknown error occurs while updating the
                 deployment.
         """
         try:
             logger.debug(
                 f"Updating SeldonDeployment resource: {deployment.name}"
             )
@@ -703,15 +710,14 @@
 
         Raises:
             SeldonDeploymentNotFoundError: if the deployment resource cannot
                 be found or is not managed by ZenML.
             SeldonClientError: if an unknown error occurs while fetching
                 the deployment.
         """
-
         try:
             logger.debug(f"Retrieving SeldonDeployment resource: {name}")
 
             response = self._custom_objects_api.get_namespaced_custom_object(
                 group="machinelearning.seldon.io",
                 version="v1",
                 namespace=self._namespace,
@@ -755,16 +761,15 @@
 
     def find_deployments(
         self,
         name: Optional[str] = None,
         labels: Optional[Dict[str, str]] = None,
         fields: Optional[Dict[str, str]] = None,
     ) -> List[SeldonDeployment]:
-        """Find all ZenML managed Seldon Core deployment resources that match
-        the given criteria.
+        """Find all ZenML-managed Seldon Core deployment resources matching the given criteria.
 
         Args:
             name: optional name of the deployment resource to find.
             fields: optional selector to restrict the list of returned
                 Seldon deployments by their fields. Defaults to everything.
             labels: optional selector to restrict the list of returned
                 Seldon deployments by their labels. Defaults to everything.
@@ -839,15 +844,18 @@
 
         Args:
             name: the name of the Seldon Core deployment to get logs for.
             follow: if True, the logs will be streamed as they are written
             tail: only retrieve the last NUM lines of log output.
 
         Returns:
-            A generator that can be acccessed to get the service logs.
+            A generator that can be accessed to get the service logs.
+
+        Yields:
+            The next log line.
 
         Raises:
             SeldonClientError: if an unknown error occurs while fetching
                 the logs.
         """
         logger.debug(f"Retrieving logs for SeldonDeployment resource: {name}")
         try:
@@ -916,25 +924,27 @@
             response.release_conn()
 
     def create_or_update_secret(
         self,
         name: str,
         secret: BaseSecretSchema,
     ) -> None:
-        """Create or update a Kubernetes Secret resource with the information
-        contained in a ZenML secret.
+        """Create or update a Kubernetes Secret resource.
+
+        Uses the information contained in a ZenML secret.
 
         Args:
             name: the name of the Secret resource to create.
             secret: a ZenML secret with key-values that should be
                 stored in the Secret resource.
 
         Raises:
             SeldonClientError: if an unknown error occurs during the creation of
                 the secret.
+            k8s_client.rest.ApiException: unexpected error.
         """
         try:
             logger.debug(f"Creating Secret resource: {name}")
 
             secret_data = {
                 k.upper(): base64.b64encode(str(v).encode("utf-8")).decode(
                     "ascii"
@@ -985,14 +995,15 @@
         self,
         name: str,
     ) -> None:
         """Delete a Kubernetes Secret resource managed by ZenML.
 
         Args:
             name: the name of the Kubernetes Secret resource to delete.
+
         Raises:
             SeldonClientError: if an unknown error occurs during the removal
                 of the secret.
         """
         try:
             logger.debug(f"Deleting Secret resource: {name}")
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/services/__init__.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/services/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -7,11 +7,13 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.seldon.services.seldon_deployment import (  # noqa
-    SeldonDeploymentConfig,
-    SeldonDeploymentService,
+"""Initialization for TensorFlow services."""
+
+from zenml.integrations.tensorflow.services.tensorboard_service import (  # noqa
+    TensorboardService,
+    TensorboardServiceConfig,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/services/seldon_deployment.py` & `zenml-0.9.0/src/zenml/integrations/seldon/services/seldon_deployment.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation for the Seldon Deployment step."""
 
 import os
 from typing import TYPE_CHECKING, Any, Dict, Generator, Optional, Tuple
 from uuid import UUID
 
 import numpy as np
 import requests
@@ -61,16 +62,15 @@
     implementation: str
     replicas: int = 1
     secret_name: Optional[str]
     model_metadata: Dict[str, Any] = Field(default_factory=dict)
     extra_args: Dict[str, Any] = Field(default_factory=dict)
 
     def get_seldon_deployment_labels(self) -> Dict[str, str]:
-        """Generate the labels for the Seldon Core deployment from the
-        service configuration.
+        """Generate labels for the Seldon Core deployment from the service configuration.
 
         These labels are attached to the Seldon Core deployment resource
         and may be used as label selectors in lookup operations.
 
         Returns:
             The labels for the Seldon Core deployment.
         """
@@ -87,16 +87,15 @@
             labels["zenml.model_uri"] = self.model_uri
         if self.implementation:
             labels["zenml.model_type"] = self.implementation
         SeldonClient.sanitize_labels(labels)
         return labels
 
     def get_seldon_deployment_annotations(self) -> Dict[str, str]:
-        """Generate the annotations for the Seldon Core deployment from the
-        service configuration.
+        """Generate annotations for the Seldon Core deployment from the service configuration.
 
         The annotations are used to store additional information about the
         Seldon Core service that is associated with the deployment that is
         not available in the labels. One annotation particularly important
         is the serialized Service configuration itself, which is used to
         recreate the service configuration from a remote Seldon deployment.
 
@@ -149,15 +148,14 @@
 class SeldonDeploymentServiceStatus(ServiceStatus):
     """Seldon Core deployment service status."""
 
 
 class SeldonDeploymentService(BaseService):
     """A service that represents a Seldon Core deployment server.
 
-
     Attributes:
         config: service configuration.
         status: service status.
     """
 
     SERVICE_TYPE = ServiceType(
         name="seldon-deployment",
@@ -183,16 +181,15 @@
             SeldonModelDeployer,
         )
 
         model_deployer = SeldonModelDeployer.get_active_model_deployer()
         return model_deployer.seldon_client
 
     def check_status(self) -> Tuple[ServiceState, str]:
-        """Check the the current operational state of the Seldon Core
-        deployment.
+        """Check the the current operational state of the Seldon Core deployment.
 
         Returns:
             The operational state of the Seldon Core deployment and a message
             providing additional information about that state (e.g. a
             description of the error, if one is encountered).
         """
         client = self._get_client()
@@ -219,62 +216,68 @@
         return (
             ServiceState.PENDING_STARTUP,
             "Seldon Core deployment is being created: " + pending_message,
         )
 
     @property
     def seldon_deployment_name(self) -> str:
-        """Get the name of the Seldon Core deployment that uniquely
-        corresponds to this service instance
+        """Get the name of the Seldon Core deployment.
+
+        It should return the one that uniquely corresponds to this service instance.
 
         Returns:
             The name of the Seldon Core deployment.
         """
         return f"zenml-{str(self.uuid)}"
 
     def _get_seldon_deployment_labels(self) -> Dict[str, str]:
-        """Generate the labels for the Seldon Core deployment from the
-        service configuration.
+        """Generate the labels for the Seldon Core deployment from the service configuration.
 
         Returns:
             The labels for the Seldon Core deployment.
         """
         labels = self.config.get_seldon_deployment_labels()
         labels["zenml.service_uuid"] = str(self.uuid)
         SeldonClient.sanitize_labels(labels)
         return labels
 
     @classmethod
     def create_from_deployment(
         cls, deployment: SeldonDeployment
     ) -> "SeldonDeploymentService":
-        """Recreate a Seldon Core service from a Seldon Core
-        deployment resource and update their operational status.
+        """Recreate a Seldon Core service from a Seldon Core deployment resource.
+
+        It should then update their operational status.
 
         Args:
             deployment: the Seldon Core deployment resource.
 
         Returns:
             The Seldon Core service corresponding to the given
             Seldon Core deployment resource.
+
+        Raises:
+            ValueError: if the given deployment resource does not contain
+                the expected service_uuid label.
         """
         config = SeldonDeploymentConfig.create_from_deployment(deployment)
         uuid = deployment.metadata.labels.get("zenml.service_uuid")
         if not uuid:
             raise ValueError(
                 f"The given deployment resource does not contain a valid "
                 f"'zenml.service_uuid' label: {deployment}"
             )
         service = cls(uuid=UUID(uuid), config=config)
         service.update_status()
         return service
 
     def provision(self) -> None:
-        """Provision or update the remote Seldon Core deployment instance to
-        match the current configuration.
+        """Provision or update remote Seldon Core deployment instance.
+
+        This should then match the current configuration.
         """
         client = self._get_client()
 
         name = self.seldon_deployment_name
 
         deployment = SeldonDeployment.build(
             name=name,
@@ -319,15 +322,15 @@
         """Get the logs of a Seldon Core model deployment.
 
         Args:
             follow: if True, the logs will be streamed as they are written
             tail: only retrieve the last NUM lines of log output.
 
         Returns:
-            A generator that can be acccessed to get the service logs.
+            A generator that can be accessed to get the service logs.
         """
         return self._get_client().get_deployment_logs(
             self.seldon_deployment_name,
             follow=follow,
             tail=tail,
         )
 
@@ -359,14 +362,18 @@
         """Make a prediction using the service.
 
         Args:
             request: a numpy array representing the request
 
         Returns:
             A numpy array representing the prediction returned by the service.
+
+        Raises:
+            Exception: if the service is not yet ready.
+            ValueError: if the prediction_url is not set.
         """
         if not self.is_running:
             raise Exception(
                 "Seldon prediction service is not running. "
                 "Please start the service before making predictions."
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/steps/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,18 +1,19 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for TensorFlow standard steps."""
 
-from zenml.integrations.seldon.steps.seldon_deployer import (
-    SeldonDeployerStepConfig,
-    seldon_model_deployer_step,
+from zenml.integrations.tensorflow.steps.tensorflow_trainer import (
+    TensorflowBinaryClassifier,
+    TensorflowBinaryClassifierConfig,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/seldon/steps/seldon_deployer.py` & `zenml-0.9.0/src/zenml/integrations/seldon/steps/seldon_deployer.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Seldon Deployer step."""
 
 import os
 from typing import cast
 
 from zenml.artifacts.model_artifact import ModelArtifact
 from zenml.environment import Environment
 from zenml.integrations.seldon.model_deployers.seldon_model_deployer import (
@@ -22,29 +23,29 @@
     SeldonModelDeployer,
 )
 from zenml.integrations.seldon.services.seldon_deployment import (
     SeldonDeploymentConfig,
     SeldonDeploymentService,
 )
 from zenml.io import fileio
-from zenml.io import utils as io_utils
 from zenml.logger import get_logger
 from zenml.steps import (
     STEP_ENVIRONMENT_NAME,
     BaseStepConfig,
     StepEnvironment,
     step,
 )
 from zenml.steps.step_context import StepContext
+from zenml.utils import io_utils
 
 logger = get_logger(__name__)
 
 
 class SeldonDeployerStepConfig(BaseStepConfig):
-    """Seldon model deployer step configuration
+    """Seldon model deployer step configuration.
 
     Attributes:
         service_config: Seldon Core deployment service configuration.
         secrets: a list of ZenML secrets containing additional configuration
             parameters for the Seldon Core deployment (e.g. credentials to
             access the Artifact Store where the models are stored). If supplied,
             the information fetched from these secrets is passed to the Seldon
@@ -58,23 +59,24 @@
 @step(enable_cache=False)
 def seldon_model_deployer_step(
     deploy_decision: bool,
     config: SeldonDeployerStepConfig,
     context: StepContext,
     model: ModelArtifact,
 ) -> SeldonDeploymentService:
-    """Seldon Core model deployer pipeline step
+    """Seldon Core model deployer pipeline step.
 
     This step can be used in a pipeline to implement continuous
     deployment for a ML model with Seldon Core.
 
     Args:
         deploy_decision: whether to deploy the model or not
         config: configuration for the deployer step
         model: the model artifact to deploy
+        context: the step context
 
     Returns:
         Seldon Core deployment service
     """
     model_deployer = SeldonModelDeployer.get_active_model_deployer()
 
     # get pipeline name, step name and run id
@@ -85,26 +87,30 @@
 
     # update the step configuration with the real pipeline runtime information
     config.service_config.pipeline_name = pipeline_name
     config.service_config.pipeline_run_id = pipeline_run_id
     config.service_config.pipeline_step_name = step_name
 
     def prepare_service_config(model_uri: str) -> SeldonDeploymentConfig:
-        """Prepare the model files for model serving and create and return a
-        Seldon service configuration for the model.
+        """Prepare the model files for model serving.
+
+        This creates and returns a Seldon service configuration for the model.
 
         This function ensures that the model files are in the correct format
         and file structure required by the Seldon Core server implementation
         used for model serving.
 
         Args:
             model_uri: the URI of the model artifact being served
 
         Returns:
             The URL to the model ready for serving.
+
+        Raises:
+            RuntimeError: if the model files were not found
         """
         served_model_uri = os.path.join(
             context.get_output_artifact_uri(), "seldon"
         )
         fileio.makedirs(served_model_uri)
 
         # TODO [ENG-773]: determine how to formalize how models are organized into
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/__init__.py` & `zenml-0.9.0/src/zenml/integrations/pytorch_lightning/materializers/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -7,24 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.constants import SKLEARN
-from zenml.integrations.integration import Integration
+"""Initialization of the PyTorch Lightning Materializer."""
 
-
-class SklearnIntegration(Integration):
-    """Definition of sklearn integration for ZenML."""
-
-    NAME = SKLEARN
-    REQUIREMENTS = ["scikit-learn"]
-
-    @classmethod
-    def activate(cls) -> None:
-        """Activates the integration."""
-        from zenml.integrations.sklearn import materializers  # noqa
-
-
-SklearnIntegration.check_installation()
+from zenml.integrations.pytorch_lightning.materializers.pytorch_lightning_materializer import (  # noqa
+    PyTorchLightningMaterializer,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/helpers/digits.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/helpers/digits.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Helper functions for the sklearn digits dataset."""
 
 from typing import TYPE_CHECKING, Tuple
 
 import numpy as np
 from sklearn.base import ClassifierMixin
 from sklearn.datasets import load_digits
 from sklearn.model_selection import train_test_split
@@ -26,24 +27,31 @@
 
 def get_digits() -> Tuple[
     "NDArray[np.float64]",
     "NDArray[np.float64]",
     "NDArray[np.int64]",
     "NDArray[np.int64]",
 ]:
-    """Returns the digits dataset in the form of a tuple of numpy
-    arrays."""
+    """Returns the digits dataset in the form of a tuple of numpy arrays.
+
+    Returns:
+        Tuple of (training_images, testing_images, training_labels, testing_labels)
+    """
     digits = load_digits()
     # flatten the images
     n_samples = len(digits.images)
     data = digits.images.reshape((n_samples, -1))
 
     # Split data into 50% train and 50% test subsets
     X_train, X_test, y_train, y_test = train_test_split(
         data, digits.target, test_size=0.5, shuffle=False
     )
     return X_train, X_test, y_train, y_test
 
 
 def get_digits_model() -> ClassifierMixin:
-    """Creates a support vector classifier for digits dataset."""
+    """Creates a support vector classifier for digits dataset.
+
+    Returns:
+        A support vector classifier.
+    """
     return SVC(gamma=0.001)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/materializers/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,10 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the sklearn materializer."""
+
 from zenml.integrations.sklearn.materializers.sklearn_materializer import (  # noqa
     SklearnMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/materializers/sklearn_materializer.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/materializers/sklearn_materializer.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the sklearn materializer."""
 
 import os
 import pickle
 from typing import Any, Type, Union
 
 from sklearn.base import (
     BaseEstimator,
@@ -63,15 +64,22 @@
         OutlierMixin,
         RegressorMixin,
         MetaEstimatorMixin,
         MultiOutputMixin,
         DensityMixin,
         TransformerMixin,
     ]:
-        """Reads a base sklearn model from a pickle file."""
+        """Reads a base sklearn model from a pickle file.
+
+        Args:
+            data_type: The type of the model.
+
+        Returns:
+            The model.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         with fileio.open(filepath, "rb") as fid:
             clf = pickle.load(fid)
         return clf
 
     def handle_return(
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/steps/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the sklearn standard steps."""
 
 from zenml.integrations.sklearn.steps.sklearn_evaluator import (
     SklearnEvaluator,
     SklearnEvaluatorConfig,
 )
 from zenml.integrations.sklearn.steps.sklearn_splitter import (
     SklearnSplitter,
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_evaluator.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_evaluator.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,47 +7,52 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the sklearn evaluator step."""
 
 import pandas as pd
 from sklearn.base import BaseEstimator
 from sklearn.metrics import classification_report
 
 from zenml.steps.step_interfaces.base_evaluator_step import (
     BaseEvaluatorConfig,
     BaseEvaluatorStep,
 )
 
 
 class SklearnEvaluatorConfig(BaseEvaluatorConfig):
-    """Config class for the sklearn evaluator"""
+    """Config class for the sklearn evaluator."""
 
     label_class_column: str
 
 
 class SklearnEvaluator(BaseEvaluatorStep):
-    """A simple step implementation which utilizes sklearn to evaluate the
-    performance of a given model on a given test dataset"""
+    """Simple sklearn evaluator step implementation.
+
+    This uses sklearn to evaluate the performance of a given model on a given
+    test dataset.
+    """
 
     def entrypoint(  # type: ignore[override]
         self,
         dataset: pd.DataFrame,
         model: BaseEstimator,
         config: SklearnEvaluatorConfig,
     ) -> dict:  # type: ignore[type-arg]
-        """Method which is responsible for the computation of the evaluation
+        """Method which is responsible for the computation of the evaluation.
 
         Args:
-            dataset: a pandas Dataframe which represents the test dataset
+            dataset: a pandas DataFrame which represents the test dataset
             model: a trained sklearn model
             config: the configuration for the step
+
         Returns:
             a dictionary which has the evaluation report
         """
         labels = dataset.pop(config.label_class_column)
 
         predictions = model.predict(dataset)
         predicted_classes = [1 if v > 0.5 else 0 for v in predictions]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_splitter.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_splitter.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,50 +7,60 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the sklearn splitter."""
+
 from typing import Dict
 
 import pandas as pd
 from sklearn.model_selection import train_test_split
 
 from zenml.steps import Output
 from zenml.steps.step_interfaces.base_split_step import (
     BaseSplitStep,
     BaseSplitStepConfig,
 )
 
 
 class SklearnSplitterConfig(BaseSplitStepConfig):
-    """Config class for the sklearn splitter"""
+    """Config class for the sklearn splitter."""
 
     ratios: Dict[str, float]
 
 
 class SklearnSplitter(BaseSplitStep):
-    """A simple step implementation which utilizes sklearn to split a given
-    dataset into train, test and validation splits"""
+    """A simple sklearn splitter step implementation.
+
+    This uses sklearn to split a given dataset into train, test and validation
+    splits.
+    """
 
     def entrypoint(  # type: ignore[override]
         self,
         dataset: pd.DataFrame,
         config: SklearnSplitterConfig,
     ) -> Output(  # type:ignore[valid-type]
         train=pd.DataFrame, test=pd.DataFrame, validation=pd.DataFrame
     ):
-        """Method which is responsible for the splitting logic
+        """Method which is responsible for the splitting logic.
 
         Args:
-            dataset: a pandas Dataframe which entire dataset
+            dataset: a pandas DataFrame which entire dataset
             config: the configuration for the step
+
         Returns:
-            three dataframes representing the splits
+            three DataFrames representing the splits
+
+        Raises:
+            KeyError: if the wrong configuration is used
+            ValueError: if the ratios are not valid
         """
         if (
             any(
                 [
                     split not in config.ratios
                     for split in ["train", "test", "validation"]
                 ]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/sklearn/steps/sklearn_standard_scaler.py` & `zenml-0.9.0/src/zenml/integrations/sklearn/steps/sklearn_standard_scaler.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the sklearn standard scaler step."""
+
 from typing import List
 
 import pandas as pd
 from sklearn.preprocessing import StandardScaler
 
 from zenml.logger import get_logger
 from zenml.steps import Output
@@ -23,53 +25,56 @@
     BasePreprocessorStep,
 )
 
 logger = get_logger(__name__)
 
 
 class SklearnStandardScalerConfig(BasePreprocessorConfig):
-    """Config class for the sklearn standard scaler
+    """Config class for the sklearn standard scaler.
 
     ignore_columns: a list of column names which should not be scaled
     exclude_columns: a list of column names to be excluded from the dataset
     """
 
     ignore_columns: List[str] = []
     exclude_columns: List[str] = []
 
 
 class SklearnStandardScaler(BasePreprocessorStep):
-    """Simple step implementation which utilizes the StandardScaler from sklearn
-    to transform the numeric columns of a pd.DataFrame"""
+    """Simple StandardScaler step implementation.
+
+    This uses the StandardScaler from sklearn to transform the numeric columns
+    of a pd.DataFrame.
+    """
 
     def entrypoint(  # type: ignore[override]
         self,
         train_dataset: pd.DataFrame,
         test_dataset: pd.DataFrame,
         validation_dataset: pd.DataFrame,
         statistics: pd.DataFrame,
         schema: pd.DataFrame,
         config: SklearnStandardScalerConfig,
     ) -> Output(  # type:ignore[valid-type]
         train_transformed=pd.DataFrame,
         test_transformed=pd.DataFrame,
         validation_transformed=pd.DataFrame,
     ):
-        """Main entrypoint function for the StandardScaler
+        """Main entrypoint function for the StandardScaler.
 
         Args:
             train_dataset: pd.DataFrame, the training dataset
             test_dataset: pd.DataFrame, the test dataset
             validation_dataset: pd.DataFrame, the validation dataset
             statistics: pd.DataFrame, the statistics over the train dataset
             schema: pd.DataFrame, the detected schema of the dataset
             config: the configuration for the step
+
         Returns:
-             the transformed train, test and validation datasets as
-             pd.DataFrames
+            the transformed train, test and validation datasets as pd.DataFrames
         """
         schema_dict = {k: v[0] for k, v in schema.to_dict().items()}
 
         # Exclude columns
         feature_set = set(train_dataset.columns) - set(config.exclude_columns)
         for feature, feature_type in schema_dict.items():
             if feature_type != "int64" and feature_type != "float64":
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/__init__.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,28 +7,30 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for TensorFlow integration."""
+
 from zenml.integrations.constants import TENSORFLOW
 from zenml.integrations.integration import Integration
 
 
 class TensorflowIntegration(Integration):
     """Definition of Tensorflow integration for ZenML."""
 
     NAME = TENSORFLOW
     REQUIREMENTS = ["tensorflow==2.8.0", "tensorflow_io==0.24.0"]
 
     @classmethod
     def activate(cls) -> None:
         """Activates the integration."""
-        # need to import this explicitly to load the Tensoflow file IO support
+        # need to import this explicitly to load the Tensorflow file IO support
         # for S3 and other file systems
         import tensorflow_io  # type: ignore [import]
 
         from zenml.integrations.tensorflow import materializers  # noqa
         from zenml.integrations.tensorflow import services  # noqa
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/graphviz/visualizers/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,14 +7,8 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
-from zenml.integrations.tensorflow.materializers.keras_materializer import (  # noqa
-    KerasMaterializer,
-)
-from zenml.integrations.tensorflow.materializers.tf_dataset_materializer import (  # noqa
-    TensorflowDatasetMaterializer,
-)
+"""Initialization of Graphviz visualizers."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/keras_materializer.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/keras_materializer.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,44 +7,49 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the TensorFlow Keras materializer."""
+
 import tempfile
 from typing import Any, Type
 
 from tensorflow import keras
 
 from zenml.artifacts import ModelArtifact
 from zenml.io import fileio
-from zenml.io import utils as fileio_utils
 from zenml.materializers.base_materializer import BaseMaterializer
+from zenml.utils import io_utils
 
 
 class KerasMaterializer(BaseMaterializer):
     """Materializer to read/write Keras models."""
 
     ASSOCIATED_TYPES = (keras.Model,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> keras.Model:
         """Reads and returns a Keras model after copying it to temporary path.
 
+        Args:
+            data_type: The type of the data to read.
+
         Returns:
             A tf.keras.Model model.
         """
         super().handle_input(data_type)
 
         # Create a temporary directory to store the model
         temp_dir = tempfile.TemporaryDirectory()
 
         # Copy from artifact store to temporary directory
-        fileio_utils.copy_dir(self.artifact.uri, temp_dir.name)
+        io_utils.copy_dir(self.artifact.uri, temp_dir.name)
 
         # Load the model from the temporary directory
         model = keras.models.load_model(temp_dir.name)
 
         # Cleanup and return
         fileio.rmtree(temp_dir.name)
 
@@ -57,11 +62,11 @@
             model: A tf.keras.Model model.
         """
         super().handle_return(model)
 
         # Create a temporary directory to store the model
         temp_dir = tempfile.TemporaryDirectory()
         model.save(temp_dir.name)
-        fileio_utils.copy_dir(temp_dir.name, self.artifact.uri)
+        io_utils.copy_dir(temp_dir.name, self.artifact.uri)
 
         # Remove the temporary directory
         fileio.rmtree(temp_dir.name)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/materializers/tf_dataset_materializer.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/materializers/tf_dataset_materializer.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the TensorFlow dataset materializer."""
+
 import os
 from typing import Any, Type
 
 import tensorflow as tf
 
 from zenml.artifacts import DataArtifact
 from zenml.materializers.base_materializer import BaseMaterializer
@@ -25,19 +27,30 @@
 class TensorflowDatasetMaterializer(BaseMaterializer):
     """Materializer to read data to and from tf.data.Dataset."""
 
     ASSOCIATED_TYPES = (tf.data.Dataset,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> Any:
-        """Reads data into tf.data.Dataset"""
+        """Reads data into tf.data.Dataset.
+
+        Args:
+            data_type: The type of the data to read.
+
+        Returns:
+            A tf.data.Dataset object.
+        """
         super().handle_input(data_type)
         path = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         return tf.data.experimental.load(path)
 
     def handle_return(self, dataset: tf.data.Dataset) -> None:
-        """Persists a tf.data.Dataset object."""
+        """Persists a tf.data.Dataset object.
+
+        Args:
+            dataset: The dataset to persist.
+        """
         super().handle_return(dataset)
         path = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         tf.data.experimental.save(
             dataset, path, compression=None, shard_func=None
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/services/__init__.py` & `zenml-0.9.0/src/zenml/integrations/github/orchestrators/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,20 @@
 #  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.tensorflow.services.tensorboard_service import (  # noqa
-    TensorboardService,
-    TensorboardServiceConfig,
+"""Initialization of the GitHub Actions Orchestrator."""
+
+from zenml.integrations.github.orchestrators.github_actions_orchestrator import (
+    GitHubActionsOrchestrator,
 )
+
+__all__ = ["GitHubActionsOrchestrator"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/services/tensorboard_service.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/services/tensorboard_service.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the TensorBoard service."""
 
 from typing import Any, Dict, Union
 
 from tensorboard import default, program  # type: ignore [import]
 from tensorboard.uploader import uploader_subcommand  # type: ignore [import]
 
 from zenml.logger import get_logger
@@ -29,57 +30,64 @@
     ServiceType,
 )
 
 logger = get_logger(__name__)
 
 
 class TensorboardServiceConfig(LocalDaemonServiceConfig):
-    """Tensorboard service configuration.
+    """TensorBoard service configuration.
 
     Attributes:
-        logdir: location of Tensorboard log files.
+        logdir: location of TensorBoard log files.
         max_reload_threads: the max number of threads that TensorBoard can use
             to reload runs. Each thread reloads one run at a time.
         reload_interval: how often the backend should load more data, in
             seconds. Set to 0 to load just once at startup.
     """
 
     logdir: str
     max_reload_threads: int = 1
     reload_interval: int = 5
 
 
 class TensorboardService(LocalDaemonService):
-    """Tensorboard service that can be used to start a local Tensorboard server
-    for one or more models.
+    """TensorBoard service.
+
+    This can be used to start a local TensorBoard server for one or more models.
 
     Attributes:
         SERVICE_TYPE: a service type descriptor with information describing
-            the Tensorboard service class
+            the TensorBoard service class
         config: service configuration
         endpoint: optional service endpoint
     """
 
     SERVICE_TYPE = ServiceType(
         name="tensorboard",
         type="visualization",
         flavor="tensorboard",
-        description="Tensorboard visualization service",
+        description="TensorBoard visualization service",
     )
 
     config: TensorboardServiceConfig
     endpoint: LocalDaemonServiceEndpoint
 
     def __init__(
         self,
         config: Union[TensorboardServiceConfig, Dict[str, Any]],
         **attrs: Any,
     ) -> None:
+        """Initialization for TensorBoard service.
+
+        Args:
+            config: service configuration
+            **attrs: additional attributes
+        """
         # ensure that the endpoint is created before the service is initialized
-        # TODO [ENG-697]: implement a service factory or builder for Tensorboard
+        # TODO [ENG-697]: implement a service factory or builder for TensorBoard
         #   deployment services
         if (
             isinstance(config, TensorboardServiceConfig)
             and "endpoint" not in attrs
         ):
             endpoint = LocalDaemonServiceEndpoint(
                 config=LocalDaemonServiceEndpointConfig(
@@ -92,16 +100,17 @@
                     )
                 ),
             )
             attrs["endpoint"] = endpoint
         super().__init__(config=config, **attrs)
 
     def run(self) -> None:
+        """Initialize and run the TensorBoard server."""
         logger.info(
-            "Starting Tensorboard service as blocking "
+            "Starting TensorBoard service as blocking "
             "process... press CTRL+C once to stop it."
         )
 
         self.endpoint.prepare_for_start()
 
         try:
             tensorboard = program.TensorBoard(
@@ -114,9 +123,9 @@
                 host="localhost",
                 max_reload_threads=self.config.max_reload_threads,
                 reload_interval=self.config.reload_interval,
             )
             tensorboard.main()
         except KeyboardInterrupt:
             logger.info(
-                "Tensorboard service stopped. Resuming normal execution."
+                "TensorBoard service stopped. Resuming normal execution."
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/steps/__init__.py` & `zenml-0.9.0/src/zenml/io/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,12 +7,12 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""The `io` module handles file operations for the ZenML package.
 
-from zenml.integrations.tensorflow.steps.tensorflow_trainer import (
-    TensorflowBinaryClassifier,
-    TensorflowBinaryClassifierConfig,
-)
+It offers a standard interface for reading, writing and manipulating files and
+directories. It is heavily influenced and inspired by the `io` module of `tfx`.
+"""
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/steps/tensorflow_trainer.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/steps/tensorflow_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,27 +7,29 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a TensorFlow trainer step."""
+
 from typing import List, Tuple
 
 import pandas as pd
 import tensorflow as tf
 
 from zenml.steps.step_interfaces.base_trainer_step import (
     BaseTrainerConfig,
     BaseTrainerStep,
 )
 
 
 class TensorflowBinaryClassifierConfig(BaseTrainerConfig):
-    """Config class for the tensorflow trainer
+    """Config class for the tensorflow trainer.
 
     target_column: the name of the label column
     layers: the number of units in the fully connected layers
     input_shape: the shape of the input
     learning_rate: the learning rate
     metrics: the list of metrics to be computed
     epochs: the number of epochs
@@ -40,30 +42,33 @@
     learning_rate: float = 0.001
     metrics: List[str] = ["accuracy"]
     epochs: int = 50
     batch_size: int = 8
 
 
 class TensorflowBinaryClassifier(BaseTrainerStep):
-    """Simple step implementation which creates a simple tensorflow feedforward
-    neural network and trains it on a given pd.DataFrame dataset
+    """A TensorFlow binary classifier.
+
+    This simple step implementation creates a simple tensorflow feedforward
+    neural network and trains it on a given pd.DataFrame dataset.
     """
 
     def entrypoint(  # type: ignore[override]
         self,
         train_dataset: pd.DataFrame,
         validation_dataset: pd.DataFrame,
         config: TensorflowBinaryClassifierConfig,
     ) -> tf.keras.Model:
-        """Main entrypoint for the tensorflow trainer
+        """Main entrypoint for the tensorflow trainer.
 
         Args:
             train_dataset: pd.DataFrame, the training dataset
             validation_dataset: pd.DataFrame, the validation dataset
             config: the configuration of the step
+
         Returns:
             the trained tf.keras.Model
         """
         model = tf.keras.Sequential()
         model.add(tf.keras.layers.InputLayer(input_shape=config.input_shape))
         model.add(tf.keras.layers.Flatten())
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/py.typed`

 * *Files 15% similar despite different names*

```diff
@@ -1,19 +1,13 @@
 #  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
-from zenml.integrations.tensorflow.visualizers.tensorboard_visualizer import (  # noqa
-    TensorboardVisualizer,
-    stop_tensorboard_server,
-    visualize_tensorboard,
-)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/tensorflow/visualizers/tensorboard_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/tensorflow/visualizers/tensorboard_visualizer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a TensorFlow visualizer step."""
 
 import os
 import sys
 from typing import Any, Optional, cast
 
 import psutil
 from rich import print
@@ -41,67 +42,76 @@
 class TensorboardVisualizer(BaseStepVisualizer):
     """The implementation of a Whylogs Visualizer."""
 
     @classmethod
     def find_running_tensorboard_server(
         cls, logdir: str
     ) -> Optional[TensorBoardInfo]:
-        """Find a local Tensorboard server instance running for the supplied
-        logdir location and return its TCP port.
+        """Find a local TensorBoard server instance.
+
+        Finds when it is running for the supplied logdir location and return its
+        TCP port.
+
+        Args:
+            logdir: The logdir location where the TensorBoard server is running.
 
         Returns:
-            The TensorBoardInfo describing the running Tensorboard server or
+            The TensorBoardInfo describing the running TensorBoard server or
             None if no server is running for the supplied logdir location.
         """
         for server in get_all():
             if (
                 server.logdir == logdir
                 and server.pid
                 and psutil.pid_exists(server.pid)
             ):
                 return server
         return None
 
     def visualize(
         self,
         object: StepView,
-        *args: Any,
         height: int = 800,
+        *args: Any,
         **kwargs: Any,
     ) -> None:
-        """Start a Tensorboard server to visualize all models logged as
-        artifacts by the indicated step. The server will monitor and display
-        all the models logged by past and future step runs.
+        """Start a TensorBoard server.
+
+        Allows for the visualization of all models logged as artifacts by the
+        indicated step. The server will monitor and display all the models
+        logged by past and future step runs.
 
         Args:
             object: StepView fetched from run.get_step().
             height: Height of the generated visualization.
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
         """
         for _, artifact_view in object.outputs.items():
             # filter out anything but model artifacts
             if artifact_view.type == ModelArtifact.TYPE_NAME:
                 logdir = os.path.dirname(artifact_view.uri)
 
-                # first check if a Tensorboard server is already running for
+                # first check if a TensorBoard server is already running for
                 # the same logdir location and use that one
                 running_server = self.find_running_tensorboard_server(logdir)
                 if running_server:
                     self.visualize_tensorboard(running_server.port, height)
                     return
 
                 if sys.platform == "win32":
                     # Daemon service functionality is currently not supported on Windows
                     print(
                         "You can run:\n"
                         f"[italic green]    tensorboard --logdir {logdir}"
                         "[/italic green]\n"
-                        "...to visualize the Tensorboard logs for your trained model."
+                        "...to visualize the TensorBoard logs for your trained model."
                     )
                 else:
-                    # start a new Tensorboard server
+                    # start a new TensorBoard server
                     service = TensorboardService(
                         TensorboardServiceConfig(
                             logdir=logdir,
                         )
                     )
                     service.start(timeout=20)
                     if service.endpoint.status.port:
@@ -111,48 +121,47 @@
                 return
 
     def visualize_tensorboard(
         self,
         port: int,
         height: int,
     ) -> None:
-        """Generate a visualization of a Tensorboard.
+        """Generate a visualization of a TensorBoard.
 
         Args:
-            port: the TCP port where the Tensorboard server is listening for
+            port: the TCP port where the TensorBoard server is listening for
                 requests.
             height: Height of the generated visualization.
-            logdir: The logdir location for the Tensorboard server.
         """
         if Environment.in_notebook():
 
             notebook.display(port, height=height)
             return
 
         print(
             "You can visit:\n"
             f"[italic green]    http://localhost:{port}/[/italic green]\n"
-            "...to visualize the Tensorboard logs for your trained model."
+            "...to visualize the TensorBoard logs for your trained model."
         )
 
     def stop(
         self,
         object: StepView,
     ) -> None:
-        """Stop the Tensorboard server previously started for a pipeline step.
+        """Stop the TensorBoard server previously started for a pipeline step.
 
         Args:
             object: StepView fetched from run.get_step().
         """
         for _, artifact_view in object.outputs.items():
             # filter out anything but model artifacts
             if artifact_view.type == ModelArtifact.TYPE_NAME:
                 logdir = os.path.dirname(artifact_view.uri)
 
-                # first check if a Tensorboard server is already running for
+                # first check if a TensorBoard server is already running for
                 # the same logdir location and use that one
                 running_server = self.find_running_tensorboard_server(logdir)
                 if not running_server:
                     return
 
                 logger.debug(
                     "Stopping tensorboard server with PID '%d' ...",
@@ -175,14 +184,17 @@
 
     Args:
         pipeline_name: The name of the pipeline.
         step_name: The name of the step.
 
     Returns:
         The StepView for the specified pipeline and step name.
+
+    Raises:
+        RuntimeError: If the step is not found.
     """
     repo = Repository()
     pipeline = repo.get_pipeline(pipeline_name)
     if pipeline is None:
         raise RuntimeError(f"No pipeline with name `{pipeline_name}` was found")
 
     last_run = pipeline.runs[-1]
@@ -192,28 +204,30 @@
             f"No pipeline step with name `{step_name}` was found in "
             f"pipeline `{pipeline_name}`"
         )
     return cast(StepView, step)
 
 
 def visualize_tensorboard(pipeline_name: str, step_name: str) -> None:
-    """Start a Tensorboard server to visualize all models logged as output by
-    the named pipeline step. The server will monitor and display all the models
-    logged by past and future step runs.
+    """Start a TensorBoard server.
+
+    Allows for the visualization of all models logged as output by the named
+    pipeline step. The server will monitor and display all the models logged by
+    past and future step runs.
 
     Args:
         pipeline_name: the name of the pipeline
         step_name: pipeline step name
     """
     step = get_step(pipeline_name, step_name)
     TensorboardVisualizer().visualize(step)
 
 
 def stop_tensorboard_server(pipeline_name: str, step_name: str) -> None:
-    """Stop the Tensorboard server previously started for a pipeline step.
+    """Stop the TensorBoard server previously started for a pipeline step.
 
     Args:
         pipeline_name: the name of the pipeline
         step_name: pipeline step name
     """
     step = get_step(pipeline_name, step_name)
     TensorboardVisualizer().stop(step)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/utils.py` & `zenml-0.9.0/src/zenml/integrations/utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,29 +7,39 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions for the integrations module."""
+
 import importlib
 import inspect
 import sys
 from typing import List, Optional, Type, cast
 
 from zenml.integrations.integration import Integration, IntegrationMeta
 
 
-def get_integration_for_module(module_name: str) -> Optional[Type[Integration]]:
+def get_integration_for_module(
+    module_name: str,
+) -> Optional[Type[Integration]]:
     """Gets the integration class for a module inside an integration.
 
     If the module given by `module_name` is not part of a ZenML integration,
     this method will return `None`. If it is part of a ZenML integration,
     it will return the integration class found inside the integration
     __init__ file.
+
+    Args:
+        module_name: The name of the module to get the integration for.
+
+    Returns:
+        The integration class for the module.
     """
     integration_prefix = "zenml.integrations."
     if not module_name.startswith(integration_prefix):
         return None
 
     integration_module_name = ".".join(module_name.split(".", 3)[:3])
     try:
@@ -51,10 +61,16 @@
 def get_requirements_for_module(module_name: str) -> List[str]:
     """Gets requirements for a module inside an integration.
 
     If the module given by `module_name` is not part of a ZenML integration,
     this method will return an empty list. If it is part of a ZenML integration,
     it will return the list of requirements specified inside the integration
     class found inside the integration __init__ file.
+
+    Args:
+        module_name: The name of the module to get requirements for.
+
+    Returns:
+        A list of requirements for the module.
     """
     integration = get_integration_for_module(module_name)
     return integration.REQUIREMENTS if integration else []
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/vertex/__init__.py` & `zenml-0.9.0/src/zenml/steps/restrict_step_access_decorator.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,48 +1,50 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The Vertex integration submodule provides a way to run ZenML pipelines in a 
-Vertex AI environment.
-"""
+"""Decorator to restrict function from running inside a step."""
 
-from typing import List
+from typing import Any
 
-from zenml.enums import StackComponentType
-from zenml.integrations.constants import VERTEX
-from zenml.integrations.integration import Integration
-from zenml.zen_stores.models import FlavorWrapper
+from zenml.environment import Environment
+from zenml.exceptions import ForbiddenRepositoryAccessError
+from zenml.logger import get_logger
 
-VERTEX_STEP_OPERATOR_FLAVOR = "vertex"
+logger = get_logger(__name__)
 
 
-class VertexIntegration(Integration):
-    """Definition of Vertex AI integration for ZenML."""
+def restrict_step_access(_func: Any) -> Any:
+    """Decorator to restrict this function from running inside a step.
 
-    NAME = VERTEX
-    REQUIREMENTS = ["google-cloud-aiplatform>=1.11.0"]
+    Apply this decorator to a ZenML function to prevent it from being run
+    inside the context of a step.
 
-    @classmethod
-    def flavors(cls) -> List[FlavorWrapper]:
-        """Declare the stack component flavors for the Vertex integration."""
-        return [
-            FlavorWrapper(
-                name=VERTEX_STEP_OPERATOR_FLAVOR,
-                source="zenml.integrations.vertex.step_operators.VertexStepOperator",
-                type=StackComponentType.STEP_OPERATOR,
-                integration=cls.NAME,
-            )
-        ]
+    Args:
+        _func: The function to restrict access to, inside a step.
 
+    Returns:
+        The same function without any enhancements but checks the Environment
+        to see if it's running inside a step.
 
-VertexIntegration.check_installation()
+    Raises:
+        ForbiddenRepositoryAccessError: If trying to create a `Repository`
+            instance while a ZenML step is being executed.
+    """
+    if Environment().step_is_running:
+        raise ForbiddenRepositoryAccessError(
+            "Unable to access repository during step execution. If you "
+            "require access to the artifact or metadata store, please use "
+            "a `StepContext` inside your step instead.",
+            url="https://docs.zenml.io/features/step-fixtures#using-the-stepcontext",
+        )
+
+    return _func
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/vertex/constants.py` & `zenml-0.9.0/src/zenml/integrations/gcp/constants.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Constants for the VertexAI integration."""
 
 from google.cloud.aiplatform_v1.types.job_state import JobState
 
 VERTEX_ENDPOINT_SUFFIX = "-aiplatform.googleapis.com"
 POLLING_INTERVAL_IN_SECONDS = 30
 CONNECTION_ERROR_RETRY_LIMIT = 5
 _VERTEX_JOB_STATE_SUCCEEDED = JobState.JOB_STATE_SUCCEEDED
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/vertex/orchestrator/__init__.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/steps/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,20 @@
-#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the whylogs steps."""
 
-from zenml.integrations.vertex.orchestrator.vertex_ai_orchestrator import (  # noqa
-    VertexOrchestrator,
+from zenml.integrations.whylogs.steps.whylogs_profiler import (
+    WhylogsProfilerConfig,
+    WhylogsProfilerStep,
+    whylogs_profiler_step,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/vertex/step_operators/__init__.py` & `zenml-0.9.0/src/zenml/alerter/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,11 +7,21 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Alerters allow you to send alerts from within your pipeline.
 
-from zenml.integrations.vertex.step_operators.vertex_step_operator import (  # noqa
-    VertexStepOperator,
-)
+This is useful to immediately get notified when failures happen,
+and also for general monitoring / reporting.
+"""
+
+from zenml.alerter.alerter_step import alerter_ask_step, alerter_post_step
+from zenml.alerter.base_alerter import BaseAlerter
+
+__all__ = [
+    "BaseAlerter",
+    "alerter_post_step",
+    "alerter_ask_step",
+]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/vertex/step_operators/vertex_step_operator.py` & `zenml-0.9.0/src/zenml/integrations/gcp/step_operators/vertex_step_operator.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,47 +7,51 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""Code heavily inspired by TFX Implementation:
+"""Implementation of a VertexAI step operator.
+
+Code heavily inspired by TFX Implementation:
 https://github.com/tensorflow/tfx/blob/master/tfx/extensions/
-google_cloud_ai_platform/training_clients.py"""
+google_cloud_ai_platform/training_clients.py
+"""
 
 import time
 from typing import ClassVar, List, Optional, Tuple
 
-from google.auth import credentials as auth_credentials
-from google.auth import default, load_credentials_from_file
 from google.cloud import aiplatform
 from pydantic import validator as property_validator
 
 from zenml import __version__
 from zenml.enums import StackComponentType
-from zenml.integrations.vertex import VERTEX_STEP_OPERATOR_FLAVOR
-from zenml.integrations.vertex.constants import (
+from zenml.integrations.gcp import GCP_VERTEX_STEP_OPERATOR_FLAVOR
+from zenml.integrations.gcp.constants import (
     CONNECTION_ERROR_RETRY_LIMIT,
     POLLING_INTERVAL_IN_SECONDS,
     VERTEX_ENDPOINT_SUFFIX,
     VERTEX_JOB_STATES_COMPLETED,
     VERTEX_JOB_STATES_FAILED,
 )
+from zenml.integrations.gcp.google_credentials_mixin import (
+    GoogleCredentialsMixin,
+)
 from zenml.logger import get_logger
 from zenml.repository import Repository
 from zenml.stack import Stack, StackValidator
 from zenml.step_operators import BaseStepOperator
 from zenml.utils import docker_utils
 from zenml.utils.source_utils import get_source_root_path
 
 logger = get_logger(__name__)
 
 
-class VertexStepOperator(BaseStepOperator):
+class VertexStepOperator(BaseStepOperator, GoogleCredentialsMixin):
     """Step operator to run a step on Vertex AI.
 
     This class defines code that can set up a Vertex AI environment and run the
     ZenML entrypoint command in it.
 
     Attributes:
         region: Region name, e.g., `europe-west1`.
@@ -55,40 +59,37 @@
             environment.
         accelerator_type: [Optional] Accelerator type from list: https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType
         accelerator_count: [Optional] Defines number of accelerators to be
             used for the job.
         machine_type: [Optional] Machine type specified here: https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types
         base_image: [Optional] Base image for building the custom job container.
         encryption_spec_key_name: [Optional]: Encryption spec key name.
-        service_account_path: [Optional]: Path to service account file
-            specifying credentials of the GCP user. If not provided, falls back
-            to Default Credentials.
     """
 
     region: str
     project: Optional[str] = None
     accelerator_type: Optional[str] = None
     accelerator_count: int = 0
     machine_type: str = "n1-standard-4"
     base_image: Optional[str] = None
 
     # customer managed encryption key resource name
     # will be applied to all Vertex AI resources if set
     encryption_spec_key_name: Optional[str] = None
 
-    # path to google service account
-    # environment default credentials used if not set
-    service_account_path: Optional[str] = None
-
     # Class configuration
-    FLAVOR: ClassVar[str] = VERTEX_STEP_OPERATOR_FLAVOR
+    FLAVOR: ClassVar[str] = GCP_VERTEX_STEP_OPERATOR_FLAVOR
 
     @property
     def validator(self) -> Optional[StackValidator]:
-        """Validates that the stack contains a container registry."""
+        """Validates that the stack contains a container registry.
+
+        Returns:
+            StackValidator: Validator for the stack.
+        """
 
         def _ensure_local_orchestrator(stack: Stack) -> Tuple[bool, str]:
             # For now this only works on local orchestrator and GCP artifact
             #  store
             return (
                 (
                     stack.orchestrator.FLAVOR == "local"
@@ -101,39 +102,49 @@
         return StackValidator(
             required_components={StackComponentType.CONTAINER_REGISTRY},
             custom_validation_function=_ensure_local_orchestrator,
         )
 
     @property_validator("accelerator_type")
     def validate_accelerator_enum(cls, accelerator_type: Optional[str]) -> None:
+        """Validates that the accelerator type is valid.
+
+        Args:
+            accelerator_type: Accelerator type
+
+        Raises:
+            ValueError: If the accelerator type is not valid.
+        """
         accepted_vals = list(
             aiplatform.gapic.AcceleratorType.__members__.keys()
         )
         if accelerator_type and accelerator_type.upper() not in accepted_vals:
             raise ValueError(
                 f"Accelerator must be one of the following: {accepted_vals}"
             )
 
-    def _get_authentication(
-        self,
-    ) -> Tuple[Optional[auth_credentials.Credentials], Optional[str]]:
-        if self.service_account_path:
-            credentials, project_id = load_credentials_from_file(
-                self.service_account_path
-            )
-        else:
-            credentials, project_id = default()
-        return credentials, project_id
-
     def _build_and_push_docker_image(
         self,
         pipeline_name: str,
         requirements: List[str],
         entrypoint_command: List[str],
     ) -> str:
+        """Builds and pushes a docker image.
+
+        Args:
+            pipeline_name: Pipeline name
+            requirements: Requirements
+            entrypoint_command: Entrypoint command
+
+        Returns:
+            Docker image name
+
+        Raises:
+            RuntimeError: If no container registry is found in the stack.
+        """
         repo = Repository()
         container_registry = repo.active_stack.container_registry
 
         if not container_registry:
             raise RuntimeError("Missing container registry")
 
         registry_uri = container_registry.uri.rstrip("/")
@@ -162,24 +173,30 @@
             pipeline_name: Name of the pipeline which the step to be executed
                 is part of.
             run_name: Name of the pipeline run which the step to be executed
                 is part of.
             entrypoint_command: Command that executes the step.
             requirements: List of pip requirements that must be installed
                 inside the step operator environment.
+
+        Raises:
+            RuntimeError: If the run fails.
+            ConnectionError: If the run fails due to a connection error.
         """
         job_labels = {"source": f"zenml-{__version__.replace('.', '_')}"}
 
         # Step 1: Authenticate with Google
         credentials, project_id = self._get_authentication()
         if self.project:
             if self.project != project_id:
                 logger.warning(
-                    f"Authenticated with project {project_id}, but this "
-                    f"operator is configured to use project {self.project}."
+                    "Authenticated with project `%s`, but this orchestrator is "
+                    "configured to use the project `%s`.",
+                    project_id,
+                    self.project,
                 )
         else:
             self.project = project_id
 
         # Step 2: Build and push image
         image_name = self._build_and_push_docker_image(
             pipeline_name=pipeline_name,
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/wandb/experiment_trackers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/seldon/services/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,14 +1,19 @@
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.wandb.experiment_trackers.wandb_experiment_tracker import (  # noqa
-    WandbExperimentTracker,
+"""Initialization for Seldon services."""
+
+from zenml.integrations.seldon.services.seldon_deployment import (  # noqa
+    SeldonDeploymentConfig,
+    SeldonDeploymentService,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/wandb/experiment_trackers/wandb_experiment_tracker.py` & `zenml-0.9.0/src/zenml/integrations/wandb/experiment_trackers/wandb_experiment_tracker.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation for the wandb experiment tracker."""
+
 import os
 from contextlib import contextmanager
 from typing import ClassVar, Iterator, Optional, Tuple
 
 import wandb
 
 from zenml.experiment_trackers.base_experiment_tracker import (
@@ -75,14 +77,17 @@
         active will automatically log to the same wandb run configured by the
         run name passed as an argument to this function.
 
         Args:
             run_name: Name of the wandb run to create.
             tags: Tags to attach to the wandb run.
             settings: Additional settings for the wandb run.
+
+        Yields:
+            None
         """
         try:
             logger.info(
                 f"Initializing wandb with project name: {self.project_name}, "
                 f"run_name: {run_name}, entity: {self.entity}."
             )
             wandb.init(
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/wandb/wandb_step_decorator.py` & `zenml-0.9.0/src/zenml/integrations/wandb/wandb_step_decorator.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation for the wandb step decorator."""
+
 import functools
 from typing import Any, Callable, Optional, Type, TypeVar, Union, cast, overload
 
 import wandb
 
 from zenml.environment import Environment
 from zenml.integrations.wandb.experiment_trackers.wandb_experiment_tracker import (
@@ -35,23 +37,21 @@
 S = TypeVar("S", bound=Type[BaseStep])
 
 
 @overload
 def enable_wandb(
     _step: S,
 ) -> S:
-    """Type annotations for wandb step decorator in case of no arguments."""
     ...
 
 
 @overload
 def enable_wandb(
     *, settings: Optional[wandb.Settings] = None
 ) -> Callable[[S], S]:
-    """Type annotations for wandb step decorator in case of arguments."""
     ...
 
 
 def enable_wandb(
     _step: Optional[S] = None, *, settings: Optional[wandb.Settings] = None
 ) -> Union[S, Callable[[S], S]]:
     """Decorator to enable wandb for a step function.
@@ -71,91 +71,121 @@
         model: tf.keras.Model,
     ) -> float:
         _, test_acc = model.evaluate(x_test, y_test, verbose=2)
         wandb.log_metric("val_accuracy", test_acc)
         return test_acc
     ```
 
+    You can also use this decorator with our class-based API like so:
+    ```
+    @enable_wandb
+    class TFEvaluator(BaseStep):
+        def entrypoint(
+            self,
+            x_test: np.ndarray,
+            y_test: np.ndarray,
+            model: tf.keras.Model,
+        ) -> float:
+            ...
+    ```
+
     All wandb artifacts and metrics logged from all the steps in a pipeline
     run are by default grouped under a single experiment named after the
     pipeline. To log wandb artifacts and metrics from a step in a separate
     wandb experiment, pass a custom `experiment_name` argument value to the
     decorator.
 
     Args:
         _step: The decorated step class.
-        project_name: Name of project.
-        experiment_name: optional wandb experiment name to use for the step.
-            If not provided, the name of the pipeline in the context of which
-            the step is executed will be used as experiment name.
+        settings: wandb settings to use for the step.
 
     Returns:
         The inner decorator which enhances the input step class with wandb
         tracking functionality
     """
 
     def inner_decorator(_step: S) -> S:
-        """Inner decorator for step enable_wandb."""
+        """Inner decorator for step enable_wandb.
+
+        Args:
+            _step: The decorated step class.
 
+        Returns:
+            The decorated step class.
+
+        Raises:
+            RuntimeError: If the decorator is not being applied to a ZenML step
+                decorated function or a BaseStep subclass.
+        """
         logger.debug(
             "Applying 'enable_wandb' decorator to step %s", _step.__name__
         )
         if not issubclass(_step, BaseStep):
             raise RuntimeError(
                 "The `enable_wandb` decorator can only be applied to a ZenML "
                 "`step` decorated function or a BaseStep subclass."
             )
         source_fn = getattr(_step, STEP_INNER_FUNC_NAME)
-        return cast(
-            S,
-            type(  # noqa
-                _step.__name__,
-                (_step,),
-                {
-                    STEP_INNER_FUNC_NAME: staticmethod(
-                        wandb_step_entrypoint(
-                            settings=settings,
-                        )(source_fn)
-                    ),
-                    "__module__": _step.__module__,
-                },
-            ),
-        )
+        new_entrypoint = wandb_step_entrypoint(
+            settings=settings,
+        )(source_fn)
+        if _step._created_by_functional_api():
+            # If the step was created by the functional API, the old entrypoint
+            # was a static method -> make sure the new one is as well
+            new_entrypoint = staticmethod(new_entrypoint)
+
+        setattr(_step, STEP_INNER_FUNC_NAME, new_entrypoint)
+        return _step
 
     if _step is None:
         return inner_decorator
     else:
         return inner_decorator(_step)
 
 
 def wandb_step_entrypoint(
     settings: Optional[wandb.Settings] = None,
 ) -> Callable[[F], F]:
     """Decorator for a step entrypoint to enable wandb.
 
     Args:
-        project_name: Name of wandb project.
-        experiment_name: optional wandb experiment name to use for the step.
-            If not provided, the name of the pipeline in the context of which
-            the step is executed will be used as experiment name.
+        settings: wandb settings to use for the step.
 
     Returns:
         the input function enhanced with wandb profiling functionality
     """
 
     def inner_decorator(func: F) -> F:
-        """Inner decorator for step entrypoint."""
+        """Inner decorator for step entrypoint.
+
+        Args:
+            func: The decorated function.
+
+        Returns:
+            the input function enhanced with wandb profiling functionality
+        """
         logger.debug(
             "Applying 'wandb_step_entrypoint' decorator to step entrypoint %s",
             func.__name__,
         )
 
         @functools.wraps(func)
         def wrapper(*args: Any, **kwargs: Any) -> Any:  # noqa
-            """Wrapper function for decorator"""
+            """Wrapper function for decorator.
+
+            Args:
+                *args: positional arguments to the decorated function.
+                **kwargs: keyword arguments to the decorated function.
+
+            Returns:
+                The return value of the decorated function.
+
+            Raises:
+                ValueError: if the active stack has no active experiment tracker.
+            """
             logger.debug(
                 "Setting up wandb backend before running step entrypoint %s",
                 func.__name__,
             )
             step_env = Environment().step_environment
             run_name = f"{step_env.pipeline_run_id}_{step_env.step_name}"
             tags = (step_env.pipeline_name, step_env.pipeline_run_id)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/lightgbm/materializers/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,21 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.whylogs.materializers.whylogs_materializer import (  # noqa
-    WhylogsMaterializer,
+"""Initialization of the Neural Prophet materializer."""
+
+from zenml.integrations.lightgbm.materializers.lightgbm_booster_materializer import (  # noqa
+    LightGBMBoosterMaterializer,
+)
+from zenml.integrations.lightgbm.materializers.lightgbm_dataset_materializer import (  # noqa
+    LightGBMDatasetMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/materializers/whylogs_materializer.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/materializers/whylogs_materializer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the whylogs materializer."""
 
 import os
 from typing import Any, Type
 
 from whylogs import DatasetProfile  # type: ignore
 from whylogs.whylabs_client.wrapper import upload_profile  # type: ignore
 
@@ -30,14 +31,17 @@
 
     ASSOCIATED_TYPES = (DatasetProfile,)
     ASSOCIATED_ARTIFACT_TYPES = (StatisticsArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> DatasetProfile:
         """Reads and returns a whylogs DatasetProfile.
 
+        Args:
+            data_type: The type of the data to read.
+
         Returns:
             A loaded whylogs DatasetProfile.
         """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, PROFILE_FILENAME)
         with fileio.open(filepath, "rb") as f:
             protobuf = DatasetProfile.parse_delimited(f.read())[0]
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/pytorch/materializers/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,21 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       http://www.apache.org/licenses/LICENSE-2.0
+#       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the PyTorch Materializer."""
 
-from zenml.integrations.whylogs.steps.whylogs_profiler import (
-    WhylogsProfilerConfig,
-    WhylogsProfilerStep,
-    whylogs_profiler_step,
+from zenml.integrations.pytorch.materializers.pytorch_dataloader_materializer import (  # noqa
+    PyTorchDataLoaderMaterializer,
+)
+from zenml.integrations.pytorch.materializers.pytorch_module_materializer import (  # noqa
+    PyTorchModuleMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/steps/whylogs_profiler.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/steps/whylogs_profiler.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the whylogs profiler step."""
+
 import datetime
 from typing import Dict, Optional, cast
 
 import pandas as pd
 from whylogs import DatasetProfile  # type: ignore
 
 from zenml.integrations.whylogs.whylogs_context import WhylogsContext
@@ -30,15 +32,14 @@
 )
 
 
 class WhylogsProfilerConfig(BaseAnalyzerConfig):
     """Config class for the WhylogsProfiler step.
 
     Attributes:
-
         dataset_name: the name of the dataset (Optional). If not specified,
             the pipeline step name is used
         dataset_timestamp: timestamp to associate with the generated
             dataset profile (Optional). The current time is used if not
             supplied.
         tags: custom metadata tags associated with the whylogs profile
 
@@ -47,29 +48,29 @@
 
     dataset_name: Optional[str] = None
     dataset_timestamp: Optional[datetime.datetime]
     tags: Optional[Dict[str, str]] = None
 
 
 class WhylogsProfilerStep(BaseAnalyzerStep):
-    """Simple step implementation which generates a whylogs data profile from a
-    a given pd.DataFrame"""
+    """Generates a whylogs data profile from a given pd.DataFrame."""
 
     def entrypoint(  # type: ignore[override]
         self,
         dataset: pd.DataFrame,
         config: WhylogsProfilerConfig,
         context: StepContext,
     ) -> DatasetProfile:
-        """Main entrypoint function for the whylogs profiler
+        """Main entrypoint function for the whylogs profiler.
 
         Args:
             dataset: pd.DataFrame, the given dataset
             config: the configuration of the step
             context: the context of the step
+
         Returns:
             whylogs profile with statistics generated for the input dataset
         """
         whylogs_context = WhylogsContext(context)
         profile = whylogs_context.profile_dataframe(
             dataset, dataset_name=config.dataset_name, tags=config.tags
         )
@@ -94,18 +95,18 @@
             value is passed, caching is enabled by default
         dataset_name: the dataset name to be used for the whylogs profile
             (Optional). If not specified, the step name is used
         dataset_timestamp: timestamp to associate with the generated
             dataset profile (Optional). The current time is used if not
             supplied.
         tags: custom metadata tags associated with the whylogs profile
+
     Returns:
         a WhylogsProfilerStep step instance
     """
-
     # enable cache explicitly to compensate for the fact that this step
     # takes in a context object
     if enable_cache is None:
         enable_cache = True
 
     step_type = type(
         step_name,
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/visualizers/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,12 +7,13 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the whylogs visualizer."""
 
 from zenml.integrations.whylogs.visualizers.whylogs_visualizer import (  # noqa
     WhylogsPlots,
     WhylogsVisualizer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/visualizers/whylogs_visualizer.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/visualizers/whylogs_visualizer.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the whylogs visualizer step."""
 
 import tempfile
 from typing import Any, List, Optional
 
 from whylogs import DatasetProfile  # type: ignore
 from whylogs.viz import ProfileVisualizer, profile_viewer  # type: ignore
 
@@ -42,44 +43,48 @@
 
 class WhylogsVisualizer(BaseStepVisualizer):
     """The implementation of a Whylogs Visualizer."""
 
     def visualize(
         self,
         object: StepView,
-        *args: Any,
         plots: Optional[List[WhylogsPlots]] = None,
+        *args: Any,
         **kwargs: Any,
     ) -> None:
-        """Visualize all whylogs dataset profiles present as outputs in the
-        step view
+        """Visualize all whylogs dataset profiles present as outputs in the step view.
 
         Args:
             object: StepView fetched from run.get_step().
             plots: optional list of whylogs plots to visualize. Defaults to
                 using all available plot types if not set
+            *args: additional positional arguments to pass to the visualize
+                method
+            **kwargs: additional keyword arguments to pass to the visualize
+                method
         """
         whylogs_artifact_datatype = (
             f"{DatasetProfile.__module__}.{DatasetProfile.__name__}"
         )
         for artifact_name, artifact_view in object.outputs.items():
-            # filter out anything but whylog dataset profile artifacts
+            # filter out anything but whylogs dataset profile artifacts
             if artifact_view.data_type == whylogs_artifact_datatype:
                 profile = artifact_view.read()
                 # whylogs doesn't currently support visualizing multiple
                 # non-related profiles side-by-side, so we open them in
                 # separate viewers for now
                 self.visualize_profile(artifact_name, profile, plots)
 
     @staticmethod
     def _get_plot_method(
         visualizer: ProfileVisualizer, plot: WhylogsPlots
     ) -> Any:
-        """Get the Whylogs ProfileVisualizer plot method corresponding to a
-        WhylogsPlots enum value.
+        """Get the Whylogs ProfileVisualizer plot method.
+
+        This will be the one corresponding to a WhylogsPlots enum value.
 
         Args:
             visualizer: a ProfileVisualizer instance
             plot: a WhylogsPlots enum value
 
         Raises:
             ValueError: if the supplied WhylogsPlots enum value does not
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/whylogs_context.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/whylogs_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,27 +7,31 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the whylogs step context extension."""
+
 import datetime
 from typing import Dict, Optional
 
 import pandas as pd
 from whylogs import DatasetProfile  # type: ignore
 from whylogs.app import Session  # type: ignore
 
 from zenml.steps.step_context import StepContext
 
 
 class WhylogsContext:
-    """This is a step context extension that can be used to facilitate whylogs
-    data logging and profiling inside a step function.
+    """A step context extension for whylogs.
+
+    This can be used to facilitate whylogs data logging and profiling inside a
+    step function.
 
     It acts as a wrapper built around the whylogs API that transparently
     incorporates ZenML specific information into the generated whylogs dataset
     profiles that can be used to associate whylogs profiles with the
     corresponding ZenML step run that produces them.
 
     It also simplifies the whylogs profile generation process by abstracting
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/whylogs/whylogs_step_decorator.py` & `zenml-0.9.0/src/zenml/integrations/whylogs/whylogs_step_decorator.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the whylogs step decorator."""
+
 import functools
 from typing import (
     Any,
     Callable,
     Dict,
     Optional,
     Type,
@@ -36,26 +38,24 @@
 S = TypeVar("S", bound=Type[BaseStep])
 
 
 @overload
 def enable_whylogs(
     _step: S,
 ) -> S:
-    """Type annotations for whylogs step decorator in case of no arguments."""
     ...
 
 
 @overload
 def enable_whylogs(
     *,
     project: Optional[str] = None,
     pipeline: Optional[str] = None,
     tags: Optional[Dict[str, str]] = None,
 ) -> Callable[[S], S]:
-    """Type annotations for whylogs step decorator in case of arguments."""
     ...
 
 
 def enable_whylogs(
     _step: Optional[S] = None,
     *,
     project: Optional[str] = None,
@@ -78,42 +78,47 @@
         ...
         data = pd.DataFrame(...)
         profile = context.whylogs.profile_dataframe(data, dataset_name="input_data")
         ...
         return data, profile
     ```
 
+    You can also use this decorator with our class-based API like so:
+    ```
+    @enable_whylogs
+    class DataLoader(BaseStep):
+        def entrypoint(
+            self,
+            context: StepContext
+        ) -> Output(data=pd.DataFrame, profile=DatasetProfile,):
+            ...
+    ```
+
     Args:
         _step: The decorated step class.
         project: optional project name to use for the whylogs session
         pipeline: optional pipeline name to use for the whylogs session
         tags: optional list of tags to apply to all profiles generated by this
             step
 
     Returns:
         the inner decorator which enhaces the input step class with whylogs
         profiling functionality
     """
 
     def inner_decorator(_step: S) -> S:
+        source_fn = getattr(_step, STEP_INNER_FUNC_NAME)
+        new_entrypoint = whylogs_entrypoint(project, pipeline, tags)(source_fn)
+        if _step._created_by_functional_api():
+            # If the step was created by the functional API, the old entrypoint
+            # was a static method -> make sure the new one is as well
+            new_entrypoint = staticmethod(new_entrypoint)
 
-        source_fn = _step.entrypoint
-        return cast(
-            S,
-            type(  # noqa
-                _step.__name__,
-                (_step,),
-                {
-                    STEP_INNER_FUNC_NAME: staticmethod(
-                        whylogs_entrypoint(project, pipeline, tags)(source_fn)
-                    ),
-                    "__module__": _step.__module__,
-                },
-            ),
-        )
+        setattr(_step, STEP_INNER_FUNC_NAME, new_entrypoint)
+        return _step
 
     if _step is None:
         return inner_decorator
     else:
         return inner_decorator(_step)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/xgboost/__init__.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_alerter_step.py`

 * *Files 26% similar despite different names*

```diff
@@ -7,24 +7,38 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.integrations.constants import XGBOOST
-from zenml.integrations.integration import Integration
+"""Base alerter step."""
 
+from abc import abstractmethod
 
-class XgboostIntegration(Integration):
-    """Definition of xgboost integration for ZenML."""
+from zenml.steps import BaseStep, BaseStepConfig, StepContext
 
-    NAME = XGBOOST
-    REQUIREMENTS = ["xgboost>=1.0.0"]
 
-    @classmethod
-    def activate(cls) -> None:
-        """Activates the integration."""
-        from zenml.integrations.xgboost import materializers  # noqa
+class BaseAlerterStepConfig(BaseStepConfig):
+    """Step config definition for all alerters."""
 
 
-XgboostIntegration.check_installation()
+class BaseAlerterStep(BaseStep):
+    """Send a message to the configured chat service."""
+
+    @abstractmethod
+    def entrypoint(  # type: ignore[override]
+        self,
+        message: str,
+        config: BaseAlerterStepConfig,
+        context: StepContext,
+    ) -> bool:
+        """Entrypoint for an Alerter step.
+
+        Args:
+            message: The message to send.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            True if the message was sent successfully.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/__init__.py` & `zenml-0.9.0/src/zenml/integrations/xgboost/materializers/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,13 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization of the XGBoost materializers."""
+
 from zenml.integrations.xgboost.materializers.xgboost_booster_materializer import (  # noqa
     XgboostBoosterMaterializer,
 )
 from zenml.integrations.xgboost.materializers.xgboost_dmatrix_materializer import (  # noqa
     XgboostDMatrixMaterializer,
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/xgboost_booster_materializer.py` & `zenml-0.9.0/src/zenml/integrations/xgboost/materializers/xgboost_booster_materializer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of an XGBoost booster materializer."""
 
 import os
 import tempfile
 from typing import Any, Type
 
 import xgboost as xgb
 
@@ -28,15 +29,22 @@
 class XgboostBoosterMaterializer(BaseMaterializer):
     """Materializer to read data to and from xgboost.Booster."""
 
     ASSOCIATED_TYPES = (xgb.Booster,)
     ASSOCIATED_ARTIFACT_TYPES = (ModelArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> xgb.Booster:
-        """Reads a xgboost Booster model from a serialized JSON file."""
+        """Reads a xgboost Booster model from a serialized JSON file.
+
+        Args:
+            data_type: A xgboost Booster type.
+
+        Returns:
+            A xgboost Booster object.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
         # Create a temporary folder
         temp_dir = tempfile.mkdtemp(prefix="zenml-temp-")
         temp_file = os.path.join(str(temp_dir), DEFAULT_FILENAME)
```

### Comparing `zenml-0.8.1rc0/src/zenml/integrations/xgboost/materializers/xgboost_dmatrix_materializer.py` & `zenml-0.9.0/src/zenml/integrations/xgboost/materializers/xgboost_dmatrix_materializer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the XGBoost dmatrix materializer."""
 
 import os
 import tempfile
 from typing import Any, Type
 
 import xgboost as xgb
 
@@ -22,21 +23,28 @@
 from zenml.io import fileio
 from zenml.materializers.base_materializer import BaseMaterializer
 
 DEFAULT_FILENAME = "data.binary"
 
 
 class XgboostDMatrixMaterializer(BaseMaterializer):
-    """Materializer to read data to and from xgboost.DMatrix"""
+    """Materializer to read data to and from xgboost.DMatrix."""
 
     ASSOCIATED_TYPES = (xgb.DMatrix,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> xgb.DMatrix:
-        """Reads a xgboost.DMatrix binary file and loads it."""
+        """Reads a xgboost.DMatrix binary file and loads it.
+
+        Args:
+            data_type: The datatype which should be read.
+
+        Returns:
+            Materialized xgboost matrix.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
         # Create a temporary folder
         temp_dir = tempfile.mkdtemp(prefix="zenml-temp-")
         temp_file = os.path.join(str(temp_dir), DEFAULT_FILENAME)
```

### Comparing `zenml-0.8.1rc0/src/zenml/io/__init__.py` & `zenml-0.9.0/src/zenml/steps/base_step_config.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,12 +7,14 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The `io` module handles file operations for the ZenML package. It offers a
-standard interface for reading, writing and manipulating files and directories.
-It is heavily influenced and inspired by the `io` module of `tfx`.
-"""
+"""Base step config."""
+
+from pydantic import BaseModel
+
+
+class BaseStepConfig(BaseModel):
+    """Base configuration class to pass execution params into a step."""
```

### Comparing `zenml-0.8.1rc0/src/zenml/io/fileio.py` & `zenml-0.9.0/src/zenml/io/fileio.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,27 +7,29 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Functionality for reading, writing and managing files."""
+
 import sys
 from types import ModuleType
 
 # IMPORTANT: Our io module uses the `fileio` module of `tfx` and the `fileio`
 # module of `tfx` tries to import the `tensorflow_gfile` module.
 #
 # At a first glance, this seems like an unused import in the `tfx` codebase,
 # however, in reality, when someone imports this module, the module
 # checks whether `tensorflow` is installed and if it is, it creates a filesystem
 # around it and registers it to the filesystem registry (and if `tfx` is not
 # installed, it does nothing).
 #
-# The problem is that if Tensorflow is indeed installed, it takes a quite a long time
+# The problem is that if TensorFlow is indeed installed, it takes a quite a long time
 # to set it up and there is no point in the code where we are utilizing the
 # generated filesystem. That's why it is now blocked by a mock module,
 # before `tfx.fileio` gets imported.
 
 sys.modules["tfx.dsl.io.plugins.tensorflow_gfile"] = ModuleType(
     "Oops, Aria walked over my keyboard."
 )
```

### Comparing `zenml-0.8.1rc0/src/zenml/io/utils.py` & `zenml-0.9.0/src/zenml/utils/io_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Various utility functions for the io module."""
 
 import fnmatch
 import os
 from pathlib import Path
 from typing import Iterable
 
 import click
@@ -30,15 +31,19 @@
     mkdir,
     open,
     walk,
 )
 
 
 def get_global_config_directory() -> str:
-    """Returns the global config directory for ZenML."""
+    """Gets the global config directory for ZenML.
+
+    Returns:
+        The global config directory for ZenML.
+    """
     env_var_path = os.getenv(ENV_ZENML_CONFIG_PATH)
     if env_var_path:
         return str(Path(env_var_path).resolve())
     return click.get_app_dir(APP_NAME)
 
 
 def write_file_contents_as_string(file_path: str, content: str) -> None:
@@ -53,29 +58,35 @@
 
 
 def read_file_contents_as_string(file_path: str) -> str:
     """Reads contents of file.
 
     Args:
         file_path: Path to file.
+
+    Returns:
+        Contents of file.
+
+    Raises:
+        FileNotFoundError: If file does not exist.
     """
     if not exists(file_path):
         raise FileNotFoundError(f"{file_path} does not exist!")
     return open(file_path).read()  # type: ignore[no-any-return]
 
 
 def find_files(dir_path: PathType, pattern: str) -> Iterable[str]:
     """Find files in a directory that match pattern.
 
     Args:
         dir_path: Path to directory.
         pattern: pattern like *.png.
 
     Yields:
-         All matching filenames if found.
+        All matching filenames if found.
     """
     for root, dirs, files in walk(dir_path):
         for basename in files:
             if fnmatch.fnmatch(convert_to_str(basename), pattern):
                 filename = os.path.join(
                     convert_to_str(root), convert_to_str(basename)
                 )
@@ -98,15 +109,14 @@
     file_path: str, file_contents: str = "{}"
 ) -> None:
     """Creates file if it does not exist.
 
     Args:
         file_path: Local path in filesystem.
         file_contents: Contents of file.
-
     """
     full_path = Path(file_path)
     if not exists(file_path):
         create_dir_recursive_if_not_exists(str(full_path.parent))
         with open(str(full_path), "w") as f:
             f.write(file_contents)
 
@@ -131,15 +141,15 @@
         makedirs(dir_path)
 
 
 def resolve_relative_path(path: str) -> str:
     """Takes relative path and resolves it absolutely.
 
     Args:
-      path: Local path in filesystem.
+        path: Local path in filesystem.
 
     Returns:
         Resolved path.
     """
     if is_remote(path):
         return path
     return str(Path(path).resolve())
@@ -194,15 +204,22 @@
     Returns:
         Parent (stem) of the dir as a string.
     """
     return Path(dir_path).parent.stem
 
 
 def convert_to_str(path: PathType) -> str:
-    """Converts a PathType to a str using UTF-8."""
+    """Converts a PathType to a str using UTF-8.
+
+    Args:
+        path: Path to convert.
+
+    Returns:
+        Converted path.
+    """
     if isinstance(path, str):
         return path
     else:
         return path.decode("utf-8")
 
 
 def is_root(path: str) -> bool:
```

### Comparing `zenml-0.8.1rc0/src/zenml/logger.py` & `zenml-0.9.0/src/zenml/logger.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Logger implementation."""
 
 import logging
 import os
 import re
 import sys
 from contextlib import contextmanager
 from logging.handlers import TimedRotatingFileHandler
@@ -58,15 +59,15 @@
         LoggingLevels.INFO: purple,
         LoggingLevels.WARN: yellow,
         LoggingLevels.ERROR: red,
         LoggingLevels.CRITICAL: bold_red,
     }
 
     def format(self, record: logging.LogRecord) -> str:
-        """Converts a log record to a (colored) string
+        """Converts a log record to a (colored) string.
 
         Args:
             record: LogRecord generated by the code.
 
         Returns:
             A string formatted according to specifications.
         """
@@ -89,15 +90,22 @@
         return formatted_message
 
 
 LOG_FILE = f"{APP_NAME}_logs.log"
 
 
 def get_logging_level() -> LoggingLevels:
-    """Get logging level from the env variable."""
+    """Get logging level from the env variable.
+
+    Returns:
+        The logging level.
+
+    Raises:
+        KeyError: If the logging level is not found.
+    """
     verbosity = ZENML_LOGGING_VERBOSITY.upper()
     if verbosity not in LoggingLevels.__members__:
         raise KeyError(
             f"Verbosity must be one of {list(LoggingLevels.__members__.keys())}"
         )
     return LoggingLevels[verbosity]
 
@@ -116,41 +124,48 @@
     else:
         logging.disable(sys.maxsize)
         logging.getLogger().disabled = True
         get_logger(__name__).debug("Logging NOTSET")
 
 
 def get_console_handler() -> Any:
-    """Get console handler for logging."""
+    """Get console handler for logging.
+
+    Returns:
+        A console handler.
+    """
     console_handler = logging.StreamHandler(sys.stdout)
     console_handler.setFormatter(CustomFormatter())
     return console_handler
     # console_handler = RichHandler(
     #     show_path=False, omit_repeated_times=False, console=console
     # )
     # console_handler.setFormatter(CustomFormatter())
     # return console_handler
 
 
 def get_file_handler() -> Any:
-    """Return a file handler for logging."""
+    """Return a file handler for logging.
+
+    Returns:
+        A file handler.
+    """
     file_handler = TimedRotatingFileHandler(LOG_FILE, when="midnight")
     file_handler.setFormatter(CustomFormatter())
     return file_handler
 
 
 def get_logger(logger_name: str) -> logging.Logger:
     """Main function to get logger name,.
 
     Args:
-      logger_name: Name of logger to initialize.
+        logger_name: Name of logger to initialize.
 
     Returns:
         A logger object.
-
     """
     logger = logging.getLogger(logger_name)
     logger.setLevel(get_logging_level().value)
     logger.addHandler(get_console_handler())
 
     # TODO [ENG-130]: Add a file handler for persistent handling
     #  logger.addHandler(get_file_handler())
@@ -162,29 +177,29 @@
 
 def init_logging() -> None:
     """Initialize logging with default levels."""
     # Mute tensorflow cuda warnings
     os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
     set_root_verbosity()
 
-    # Enable logs if environment variable SUPRESS_ZENML_LOGS is not set to True
-    supress_zenml_logs: bool = handle_bool_env_var(
+    # Enable logs if environment variable SUPPRESS_ZENML_LOGS is not set to True
+    suppress_zenml_logs: bool = handle_bool_env_var(
         ENV_ZENML_SUPPRESS_LOGS, True
     )
-    if supress_zenml_logs:
-        # supress logger info messages
-        supressed_logger_names = [
+    if suppress_zenml_logs:
+        # suppress logger info messages
+        suppressed_logger_names = [
             "urllib3",
             "azure.core.pipeline.policies.http_logging_policy",
             "grpc",
             "requests",
             "kfp",
             "tensorflow",
         ]
-        for logger_name in supressed_logger_names:
+        for logger_name in suppressed_logger_names:
             logging.getLogger(logger_name).setLevel(logging.WARNING)
 
         # disable logger messages
         disabled_logger_names = [
             "apache_beam",
             "rdbms_metadata_access_object",
             "apache_beam.io.gcp.bigquery",
@@ -209,14 +224,17 @@
         # do something that shouldn't show DEBUG/INFO logs
         ...
     ```
 
     Args:
         log_level: All logs below this level will be disabled for the duration
             of this contextmanager.
+
+    Yields:
+        None.
     """
     old_level = logging.root.manager.disable
     try:
         logging.disable(log_level)
         yield
     finally:
         logging.disable(old_level)
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/__init__.py` & `zenml-0.9.0/src/zenml/materializers/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of ZenML materializers.
+
 Materializers are used to convert a ZenML artifact into a specific format. They
 are most often used to handle the input or output of ZenML steps, and can be
 extended by building on the `BaseMaterializer` class.
 """
 
 
 from zenml.materializers.built_in_materializer import BuiltInMaterializer
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/base_materializer.py` & `zenml-0.9.0/src/zenml/materializers/base_materializer.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,36 +7,51 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Metaclass implementation for registering ZenML BaseMaterializer subclasses."""
+
 import inspect
 from typing import TYPE_CHECKING, Any, ClassVar, Dict, Tuple, Type, cast
 
 if TYPE_CHECKING:
     from zenml.artifacts.base_artifact import BaseArtifact
 
 from zenml.artifacts.type_registry import type_registry
 from zenml.exceptions import MaterializerInterfaceError
 from zenml.materializers.default_materializer_registry import (
     default_materializer_registry,
 )
 
 
 class BaseMaterializerMeta(type):
-    """Metaclass responsible for registering different BaseMaterializer
-    subclasses for reading/writing artifacts."""
+    """Metaclass responsible for registering different BaseMaterializer subclasses.
+
+    Materializers are used for reading/writing artifacts.
+    """
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "BaseMaterializerMeta":
-        """Creates a Materializer class and registers it at
-        the `MaterializerRegistry`."""
+        """Creates a Materializer class and registers it at the `MaterializerRegistry`.
+
+        Args:
+            name: The name of the class.
+            bases: The base classes of the class.
+            dct: The dictionary of the class.
+
+        Returns:
+            The BaseMaterializerMeta class.
+
+        Raises:
+            MaterializerInterfaceError: If the class was improperly defined.
+        """
         cls = cast(
             Type["BaseMaterializer"], super().__new__(mcs, name, bases, dct)
         )
         if name != "BaseMaterializer":
             from zenml.artifacts.base_artifact import BaseArtifact
 
             if not cls.ASSOCIATED_TYPES:
@@ -81,45 +96,59 @@
 class BaseMaterializer(metaclass=BaseMaterializerMeta):
     """Base Materializer to realize artifact data."""
 
     ASSOCIATED_ARTIFACT_TYPES: ClassVar[Tuple[Type["BaseArtifact"], ...]] = ()
     ASSOCIATED_TYPES: ClassVar[Tuple[Type[Any], ...]] = ()
 
     def __init__(self, artifact: "BaseArtifact"):
-        """Initializes a materializer with the given artifact."""
+        """Initializes a materializer with the given artifact.
+
+        Args:
+            artifact: The artifact to materialize.
+        """
         self.artifact = artifact
 
     def _can_handle_type(self, data_type: Type[Any]) -> bool:
-        """Whether the materializer can read/write a certain type."""
+        """Whether the materializer can read/write a certain type.
+
+        Args:
+            data_type: The type to check.
+
+        Returns:
+            Whether the materializer can read/write the given type.
+        """
         return any(
             issubclass(data_type, associated_type)
             for associated_type in self.ASSOCIATED_TYPES
         )
 
     def handle_input(self, data_type: Type[Any]) -> Any:
         """Write logic here to handle input of the step function.
 
         Args:
             data_type: What type the input should be materialized as.
-        Returns:
-            Any object that is to be passed into the relevant artifact in the
-            step.
+
+        Raises:
+            TypeError: If the data is not of the correct type.
         """
         if not self._can_handle_type(data_type):
             raise TypeError(
                 f"Unable to handle type {data_type}. {self.__class__.__name__} "
                 f"can only read artifacts to the following types: "
                 f"{self.ASSOCIATED_TYPES}."
             )
 
     def handle_return(self, data: Any) -> None:
         """Write logic here to handle return of the step function.
 
         Args:
             data: Any object that is specified as an input artifact of the step.
+
+        Raises:
+            TypeError: If the data is not of the correct type.
         """
         data_type = type(data)
         if not self._can_handle_type(data_type):
             raise TypeError(
                 f"Unable to write {data_type}. {self.__class__.__name__} "
                 f"can only write the following types: {self.ASSOCIATED_TYPES}."
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/beam_materializer.py` & `zenml-0.9.0/src/zenml/materializers/beam_materializer.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML Apache Beam materializer."""
 
 from typing import Any, Type
 
 import apache_beam as beam
 
 from zenml.artifacts import DataArtifact
 from zenml.materializers.base_materializer import BaseMaterializer
@@ -23,22 +24,28 @@
 class BeamMaterializer(BaseMaterializer):
     """Materializer to read data to and from beam."""
 
     ASSOCIATED_TYPES = (beam.PCollection,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> Any:
-        """Reads all files inside the artifact directory and materializes them
-        as a beam compatible output."""
+        """Reads all files inside the artifact directory.
+
+        It materializes them as a beam compatible output.
+
+        Args:
+            data_type: The type of the data to read.
+        """
         # TODO [ENG-138]: Implement beam reading
         super().handle_input(data_type)
 
     def handle_return(self, pipeline: beam.Pipeline) -> None:
-        """Appends a beam.io.WriteToParquet at the end of a beam pipeline
-        and therefore persists the results.
+        """Appends a beam.io.WriteToParquet at the end of a beam pipeline.
+
+        This therefore persists the results.
 
         Args:
             pipeline: A beam.pipeline object.
         """
         # TODO [ENG-139]: Implement beam writing
         super().handle_return(pipeline)
         pipeline | beam.ParDo()
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/built_in_materializer.py` & `zenml-0.9.0/src/zenml/materializers/built_in_materializer.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of ZenML's builtin materializer."""
+
 import os
 from typing import Any, Type
 
 from zenml.artifacts import DataAnalysisArtifact, DataArtifact
 from zenml.logger import get_logger
 from zenml.materializers.base_materializer import BaseMaterializer
 from zenml.utils import yaml_utils
@@ -40,24 +42,35 @@
         float,
         list,
         tuple,
         bool,
     )
 
     def handle_input(self, data_type: Type[Any]) -> Any:
-        """Reads basic primitive types from json."""
+        """Reads basic primitive types from json.
+
+        Args:
+            data_type: The type of the data to read.
+
+        Returns:
+            The data read.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         contents = yaml_utils.read_json(filepath)
         if type(contents) != data_type:
             # TODO [ENG-142]: Raise error or try to coerce
             logger.debug(
                 f"Contents {contents} was type {type(contents)} but expected "
                 f"{data_type}"
             )
         return contents
 
     def handle_return(self, data: Any) -> None:
-        """Handles basic built-in types and stores them as json"""
+        """Handles basic built-in types and stores them as json.
+
+        Args:
+            data: The data to store.
+        """
         super().handle_return(data)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
         yaml_utils.write_json(filepath, data)
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/default_materializer_registry.py` & `zenml-0.9.0/src/zenml/materializers/default_materializer_registry.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,30 +7,32 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a default materializer registry."""
 
 from typing import TYPE_CHECKING, Any, Dict, Type
 
 from zenml.exceptions import StepInterfaceError
 from zenml.logger import get_logger
 
 logger = get_logger(__name__)
 
 if TYPE_CHECKING:
     from zenml.materializers.base_materializer import BaseMaterializer
 
 
 class MaterializerRegistry:
-    """Matches a python type to a default materializer."""
+    """Matches a Python type to a default materializer."""
 
     def __init__(self) -> None:
+        """Initialize the materializer registry."""
         self.materializer_types: Dict[Type[Any], Type["BaseMaterializer"]] = {}
 
     def register_materializer_type(
         self, key: Type[Any], type_: Type["BaseMaterializer"]
     ) -> None:
         """Registers a new materializer.
 
@@ -103,16 +105,28 @@
             f" variable.",
             url="https://docs.zenml.io/guides/index/custom-materializer",
         )
 
     def get_materializer_types(
         self,
     ) -> Dict[Type[Any], Type["BaseMaterializer"]]:
-        """Get all registered materializer types."""
+        """Get all registered materializer types.
+
+        Returns:
+            A dictionary of registered materializer types.
+        """
         return self.materializer_types
 
     def is_registered(self, key: Type[Any]) -> bool:
-        """Returns if a materializer class is registered for the given type."""
+        """Returns if a materializer class is registered for the given type.
+
+        Args:
+            key: Indicates the type of object.
+
+        Returns:
+            True if a materializer is registered for the given type, False
+            otherwise.
+        """
         return any(issubclass(key, t) for t in self.materializer_types)
 
 
 default_materializer_registry = MaterializerRegistry()
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/numpy_materializer.py` & `zenml-0.9.0/src/zenml/materializers/numpy_materializer.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML NumPy materializer."""
 
 import os
 from typing import TYPE_CHECKING, Any, Type
 
 import numpy as np
 import pyarrow as pa
 import pyarrow.parquet as pq
@@ -35,15 +36,22 @@
 class NumpyMaterializer(BaseMaterializer):
     """Materializer to read data to and from pandas."""
 
     ASSOCIATED_TYPES = (np.ndarray,)
     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> "NDArray[Any]":
-        """Reads numpy array from parquet file."""
+        """Reads numpy array from parquet file.
+
+        Args:
+            data_type: The type of the data to read.
+
+        Returns:
+            The numpy array.
+        """
         super().handle_input(data_type)
         shape_dict = yaml_utils.read_json(
             os.path.join(self.artifact.uri, SHAPE_FILENAME)
         )
         shape_tuple = tuple(shape_dict.values())
         with fileio.open(
             os.path.join(self.artifact.uri, DATA_FILENAME), "rb"
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/pandas_materializer.py` & `zenml-0.9.0/src/zenml/materializers/pandas_materializer.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,41 +7,51 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Materializer for Pandas."""
 
 import os
 import tempfile
-from typing import Any, Type
+from typing import Any, Type, Union
 
 import pandas as pd
 
 from zenml.artifacts import DataArtifact, SchemaArtifact, StatisticsArtifact
 from zenml.io import fileio
 from zenml.materializers.base_materializer import BaseMaterializer
 
 DEFAULT_FILENAME = "df.parquet.gzip"
 COMPRESSION_TYPE = "gzip"
 
 
 class PandasMaterializer(BaseMaterializer):
     """Materializer to read data to and from pandas."""
 
-    ASSOCIATED_TYPES = (pd.DataFrame,)
+    ASSOCIATED_TYPES = (pd.DataFrame, pd.Series)
     ASSOCIATED_ARTIFACT_TYPES = (
         DataArtifact,
         StatisticsArtifact,
         SchemaArtifact,
     )
 
-    def handle_input(self, data_type: Type[Any]) -> pd.DataFrame:
-        """Reads pd.Dataframe from a parquet file."""
+    def handle_input(
+        self, data_type: Type[Any]
+    ) -> Union[pd.DataFrame, pd.Series]:
+        """Reads pd.DataFrame or pd.Series from a parquet file.
+
+        Args:
+            data_type: The type of the data to read.
+
+        Returns:
+            The pandas dataframe or series.
+        """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
         # Create a temporary folder
         temp_dir = tempfile.mkdtemp(prefix="zenml-temp-")
         temp_file = os.path.join(str(temp_dir), DEFAULT_FILENAME)
 
@@ -50,25 +60,34 @@
 
         # Load the model from the temporary file
         df = pd.read_parquet(temp_file)
 
         # Cleanup and return
         fileio.rmtree(temp_dir)
 
+        if issubclass(data_type, pd.Series):
+            # Taking the first column if its a series as the assumption
+            # is that there will only be one
+            assert len(df.columns) == 1
+            df = df[df.columns[0]]
+
         return df
 
-    def handle_return(self, df: pd.DataFrame) -> None:
-        """Writes a pandas dataframe to the specified filename.
+    def handle_return(self, df: Union[pd.DataFrame, pd.Series]) -> None:
+        """Writes a pandas dataframe or series to the specified filename.
 
         Args:
-            df: The pandas dataframe to write.
+            df: The pandas dataframe or series to write.
         """
         super().handle_return(df)
         filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)
 
+        if isinstance(df, pd.Series):
+            df = df.to_frame(name="series")
+
         # Create a temporary file to store the model
         with tempfile.NamedTemporaryFile(
             mode="w", suffix=".gzip", delete=False
         ) as f:
             df.to_parquet(f.name, compression=COMPRESSION_TYPE)
             fileio.copy(f.name, filepath)
```

### Comparing `zenml-0.8.1rc0/src/zenml/materializers/service_materializer.py` & `zenml-0.9.0/src/zenml/materializers/service_materializer.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a materializer to read and write ZenML service instances."""
 
 import os
 from typing import Any, Type
 
 from zenml.artifacts import ServiceArtifact
 from zenml.io import fileio
 from zenml.materializers.base_materializer import BaseMaterializer
@@ -27,17 +28,21 @@
 class ServiceMaterializer(BaseMaterializer):
     """Materializer to read/write service instances."""
 
     ASSOCIATED_TYPES = (BaseService,)
     ASSOCIATED_ARTIFACT_TYPES = (ServiceArtifact,)
 
     def handle_input(self, data_type: Type[Any]) -> BaseService:
-        """Creates and returns a service instantiated from the serialized
-        service configuration and last known status information saved as
-        artifact.
+        """Creates and returns a service.
+
+        This service is instantiated from the serialized service configuration
+        and last known status information saved as artifact.
+
+        Args:
+            data_type: The type of the data to read.
 
         Returns:
             A ZenML service instance.
         """
         super().handle_input(data_type)
         filepath = os.path.join(self.artifact.uri, SERVICE_CONFIG_FILENAME)
         with fileio.open(filepath, "r") as f:
```

### Comparing `zenml-0.8.1rc0/src/zenml/metadata_stores/__init__.py` & `zenml-0.9.0/src/zenml/metadata_stores/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of ZenML's metadata stores.
+
 The configuration of each pipeline, step, backend, and produced artifacts are
 all tracked within the metadata store. The metadata store is an SQL database,
 and can be `sqlite` or `mysql`.
 
 Metadata are the pieces of information tracked about the pipelines, experiments
 and configurations that you are running with ZenML. Metadata are stored
 inside the metadata store.
```

### Comparing `zenml-0.8.1rc0/src/zenml/metadata_stores/base_metadata_store.py` & `zenml-0.9.0/src/zenml/metadata_stores/base_metadata_store.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base implementation of a metadata store."""
+
 import json
 from abc import ABC, abstractmethod
 from collections import OrderedDict
 from json import JSONDecodeError
 from typing import ClassVar, Dict, List, Optional, Tuple, Union
 
 from ml_metadata import proto
@@ -53,15 +55,19 @@
     TYPE: ClassVar[StackComponentType] = StackComponentType.METADATA_STORE
 
     upgrade_migration_enabled: bool = True
     _store: Optional[metadata_store.MetadataStore] = None
 
     @property
     def store(self) -> metadata_store.MetadataStore:
-        """General property that hooks into TFX metadata store."""
+        """General property that hooks into TFX metadata store.
+
+        Returns:
+            metadata_store.MetadataStore: TFX metadata store.
+        """
         if self._store is None:
             config = self.get_tfx_metadata_config()
             self._store = metadata_store.MetadataStore(
                 config,
                 enable_upgrade_migration=self.upgrade_migration_enabled
                 and isinstance(config, metadata_store_pb2.ConnectionConfig),
             )
@@ -70,31 +76,46 @@
     @abstractmethod
     def get_tfx_metadata_config(
         self,
     ) -> Union[
         metadata_store_pb2.ConnectionConfig,
         metadata_store_pb2.MetadataStoreClientConfig,
     ]:
-        """Return tfx metadata config."""
+        """Return tfx metadata config.
+
+        Returns:
+            tfx metadata config.
+        """
         raise NotImplementedError
 
     @property
     def step_type_mapping(self) -> Dict[int, str]:
-        """Maps type_id's to step names."""
+        """Maps type_ids to step names.
+
+        Returns:
+            Dict[int, str]: a mapping from type_ids to step names.
+        """
         return {
             type_.id: type_.name for type_ in self.store.get_execution_types()
         }
 
     def _check_if_executions_belong_to_pipeline(
         self,
         executions: List[proto.Execution],
         pipeline: PipelineView,
     ) -> bool:
-        """Returns `True` if the executions are associated with the pipeline
-        context."""
+        """Returns `True` if the executions are associated with the pipeline context.
+
+        Args:
+            executions: List of executions.
+            pipeline: Pipeline to check.
+
+        Returns:
+            `True` if the executions are associated with the pipeline context.
+        """
         for execution in executions:
             associated_contexts = self.store.get_contexts_by_execution(
                 execution.id
             )
             for context in associated_contexts:
                 if context.id == pipeline._id:  # noqa
                     return True
@@ -106,14 +127,17 @@
         """Get original StepView from an execution.
 
         Args:
             execution: proto.Execution object from mlmd store.
 
         Returns:
             Original `StepView` derived from the proto.Execution.
+
+        Raises:
+            KeyError: If the execution is not associated with a step.
         """
         impl_name = self.step_type_mapping[execution.type_id].split(".")[-1]
 
         step_name_property = execution.custom_properties.get(
             INTERNAL_EXECUTION_PARAMETER_PREFIX + PARAM_PIPELINE_PARAMETER_NAME,
             None,
         )
@@ -184,15 +208,19 @@
             entrypoint_name=impl_name,
             name=step_name,
             parameters=step_parameters,
             metadata_store=self,
         )
 
     def get_pipelines(self) -> List[PipelineView]:
-        """Returns a list of all pipelines stored in this metadata store."""
+        """Returns a list of all pipelines stored in this metadata store.
+
+        Returns:
+            List[PipelineView]: a list of all pipelines stored in this metadata store.
+        """
         pipelines = []
         for pipeline_context in self.store.get_contexts_by_type(
             PIPELINE_CONTEXT_TYPE_NAME
         ):
             pipeline = PipelineView(
                 id_=pipeline_context.id,
                 name=pipeline_context.name,
@@ -200,15 +228,22 @@
             )
             pipelines.append(pipeline)
 
         logger.debug("Fetched %d pipelines.", len(pipelines))
         return pipelines
 
     def get_pipeline(self, pipeline_name: str) -> Optional[PipelineView]:
-        """Returns a pipeline for the given name."""
+        """Returns a pipeline for the given name.
+
+        Args:
+            pipeline_name: Name of the pipeline.
+
+        Returns:
+            PipelineView if found, None otherwise.
+        """
         pipeline_context = self.store.get_context_by_type_and_name(
             PIPELINE_CONTEXT_TYPE_NAME, pipeline_name
         )
         if pipeline_context:
             logger.debug("Fetched pipeline with name '%s'", pipeline_name)
             return PipelineView(
                 id_=pipeline_context.id,
@@ -218,15 +253,22 @@
         else:
             logger.info("No pipelines found for name '%s'", pipeline_name)
             return None
 
     def get_pipeline_runs(
         self, pipeline: PipelineView
     ) -> Dict[str, PipelineRunView]:
-        """Gets all runs for the given pipeline."""
+        """Gets all runs for the given pipeline.
+
+        Args:
+            pipeline: a Pipeline object for which you want the runs.
+
+        Returns:
+            A dictionary of pipeline run names to PipelineRunView.
+        """
         all_pipeline_runs = self.store.get_contexts_by_type(
             PIPELINE_RUN_CONTEXT_TYPE_NAME
         )
         runs: Dict[str, PipelineRunView] = OrderedDict()
 
         for run in all_pipeline_runs:
             executions = self.store.get_executions_by_context(run.id)
@@ -248,15 +290,23 @@
         )
 
         return runs
 
     def get_pipeline_run(
         self, pipeline: PipelineView, run_name: str
     ) -> Optional[PipelineRunView]:
-        """Gets a specific run for the given pipeline."""
+        """Gets a specific run for the given pipeline.
+
+        Args:
+            pipeline: The pipeline for which to get the run.
+            run_name: The name of the run to get.
+
+        Returns:
+            The pipeline run with the given name.
+        """
         run = self.store.get_context_by_type_and_name(
             PIPELINE_RUN_CONTEXT_TYPE_NAME, run_name
         )
 
         if not run:
             # No context found for the given run name
             return None
@@ -273,15 +323,22 @@
 
         logger.info("No pipeline run found for name '%s'", run_name)
         return None
 
     def get_pipeline_run_steps(
         self, pipeline_run: PipelineRunView
     ) -> Dict[str, StepView]:
-        """Gets all steps for the given pipeline run."""
+        """Gets all steps for the given pipeline run.
+
+        Args:
+            pipeline_run: The pipeline run to get the steps for.
+
+        Returns:
+            A dictionary of step names to step views.
+        """
         steps: Dict[str, StepView] = OrderedDict()
         # reverse the executions as they get returned in reverse chronological
         # order from the metadata store
         for execution in reversed(pipeline_run._executions):  # noqa
             step = self._get_step_view_from_execution(execution)
             steps[step.name] = step
 
@@ -290,20 +347,34 @@
             len(steps),
             pipeline_run.name,
         )
 
         return steps
 
     def get_step_by_id(self, step_id: int) -> StepView:
-        """Gets a `StepView` by its ID"""
+        """Gets a `StepView` by its ID.
+
+        Args:
+            step_id (int): The ID of the step to get.
+
+        Returns:
+            StepView: The `StepView` with the given ID.
+        """
         execution = self.store.get_executions_by_id([step_id])[0]
         return self._get_step_view_from_execution(execution)
 
     def get_step_status(self, step: StepView) -> ExecutionStatus:
-        """Gets the execution status of a single step."""
+        """Gets the execution status of a single step.
+
+        Args:
+            step (StepView): The step to get the status for.
+
+        Returns:
+            ExecutionStatus: The status of the step.
+        """
         proto = self.store.get_executions_by_id([step._id])[0]  # noqa
         state = proto.last_known_state
 
         if state == proto.COMPLETE:
             return ExecutionStatus.COMPLETED
         elif state == proto.RUNNING:
             return ExecutionStatus.RUNNING
```

### Comparing `zenml-0.8.1rc0/src/zenml/metadata_stores/mysql_metadata_store.py` & `zenml-0.9.0/src/zenml/metadata_stores/mysql_metadata_store.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a MySQL metadata store."""
+
 from pathlib import Path
 from typing import Any, ClassVar, Optional, Union
 
 from ml_metadata.proto import metadata_store_pb2
 from ml_metadata.proto.metadata_store_pb2 import MySQLDatabaseConfig
 
 from zenml.config.global_config import GlobalConfiguration
@@ -22,32 +24,38 @@
 from zenml.metadata_stores import BaseMetadataStore
 from zenml.repository import Repository
 
 
 class MySQLMetadataStore(BaseMetadataStore):
     """MySQL backend for ZenML metadata store."""
 
-    username: Optional[str]
-    password: Optional[str]
+    port: int = 3306
     host: str
-    port: int
     database: str
-
-    secret: Optional[str]
+    secret: Optional[str] = None
+    username: Optional[str] = None
+    password: Optional[str] = None
 
     # Class Configuration
     FLAVOR: ClassVar[str] = "mysql"
 
     def get_tfx_metadata_config(
         self,
     ) -> Union[
         metadata_store_pb2.ConnectionConfig,
         metadata_store_pb2.MetadataStoreClientConfig,
     ]:
-        """Return tfx metadata config for MySQL metadata store."""
+        """Return tfx metadata config for MySQL metadata store.
+
+        Returns:
+            The tfx metadata config.
+
+        Raises:
+            RuntimeError: If you have configured your metadata store incorrectly.
+        """
         config = MySQLDatabaseConfig(
             host=self.host,
             port=self.port,
             database=self.database,
         )
 
         secret = self._get_mysql_secret()
@@ -112,15 +120,22 @@
 
             ssl_options = MySQLDatabaseConfig.SSLOptions(**ssl_options)
             config.ssl_options.CopyFrom(ssl_options)
 
         return metadata_store_pb2.ConnectionConfig(mysql=config)
 
     def _get_mysql_secret(self) -> Any:
-        """Method which returns a MySQL secret from the secrets manager."""
+        """Method which returns a MySQL secret from the secrets manager.
+
+        Returns:
+            Any: The MySQL secret.
+
+        Raises:
+            RuntimeError: If you don't have a secrets manager as part of your stack.
+        """
         if self.secret:
             active_stack = Repository().active_stack
             secret_manager = active_stack.secrets_manager
             if secret_manager is None:
                 raise RuntimeError(
                     f"The metadata store `{self.name}` that you are using "
                     f"requires a secret. However, your stack "
```

### Comparing `zenml-0.8.1rc0/src/zenml/metadata_stores/mysql_secret_schema.py` & `zenml-0.9.0/src/zenml/utils/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,29 +1,18 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from typing import ClassVar, Optional
+"""Initialization of the utils module.
 
-from zenml.secret.base_secret import BaseSecretSchema
-
-MYSQL_METADATA_STORE_SCHEMA_TYPE = "mysql"
-
-
-class MYSQLSecretSchema(BaseSecretSchema):
-    TYPE: ClassVar[str] = MYSQL_METADATA_STORE_SCHEMA_TYPE
-
-    user: Optional[str]
-    password: Optional[str]
-    ssl_ca: Optional[str]
-    ssl_cert: Optional[str]
-    ssl_key: Optional[str]
-    ssl_verify_server_cert: Optional[bool] = False
+The `utils` module contains utility functions handling analytics, reading and
+writing YAML data as well as other general purpose functions.
+"""
```

### Comparing `zenml-0.8.1rc0/src/zenml/metadata_stores/sqlite_metadata_store.py` & `zenml-0.9.0/src/zenml/metadata_stores/sqlite_metadata_store.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,50 +7,70 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Metadata store for SQLite."""
+
 from pathlib import Path
 from typing import ClassVar, Union
 
 from ml_metadata.proto import metadata_store_pb2
 from pydantic import validator
 from tfx.orchestration import metadata
 
-from zenml.io import utils
 from zenml.metadata_stores import BaseMetadataStore
+from zenml.utils import io_utils
 
 
 class SQLiteMetadataStore(BaseMetadataStore):
     """SQLite backend for ZenML metadata store."""
 
     uri: str
 
     # Class Configuration
     FLAVOR: ClassVar[str] = "sqlite"
 
     @property
     def local_path(self) -> str:
-        """Path to the local directory where the SQLite DB is stored."""
+        """Path to the local directory where the SQLite DB is stored.
+
+        Returns:
+            The path to the local directory where the SQLite DB is stored.
+        """
         return str(Path(self.uri).parent)
 
     def get_tfx_metadata_config(
         self,
     ) -> Union[
         metadata_store_pb2.ConnectionConfig,
         metadata_store_pb2.MetadataStoreClientConfig,
     ]:
-        """Return tfx metadata config for sqlite metadata store."""
+        """Return tfx metadata config for sqlite metadata store.
+
+        Returns:
+            The tfx metadata config.
+        """
         return metadata.sqlite_metadata_connection_config(self.uri)
 
     @validator("uri")
     def ensure_uri_is_local(cls, uri: str) -> str:
-        """Ensures that the metadata store uri is local."""
-        if utils.is_remote(uri):
+        """Ensures that the metadata store uri is local.
+
+        Args:
+            uri: The metadata store uri.
+
+        Returns:
+            The metadata store uri.
+
+        Raises:
+            ValueError: If the uri is not local.
+        """
+        if io_utils.is_remote(uri):
             raise ValueError(
                 f"Uri '{uri}' specified for SQLiteMetadataStore is not a "
                 f"local uri."
             )
 
         return uri
```

### Comparing `zenml-0.8.1rc0/src/zenml/model_deployers/__init__.py` & `zenml-0.9.0/src/zenml/model_deployers/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,16 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-Model deployers are stack components responsible for online model serving.
+"""Model deployers are stack components responsible for online model serving.
+
 Online serving is the process of hosting and loading machine-learning models as
 part of a managed web service and providing access to the models through an API
 endpoint like HTTP or GRPC. Once deployed, you can send inference requests
 to the model through the web service's API and receive fast, low-latency
 responses.
 
 Add a model deployer to your ZenML stack to be able to implement continuous
```

### Comparing `zenml-0.8.1rc0/src/zenml/model_deployers/base_model_deployer.py` & `zenml-0.9.0/src/zenml/model_deployers/base_model_deployer.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base class for all ZenML model deployers."""
+
 from abc import ABC, abstractmethod
 from typing import ClassVar, Dict, Generator, List, Optional
 from uuid import UUID
 
 from zenml.enums import StackComponentType
 from zenml.services import BaseService, ServiceConfig
 from zenml.stack import StackComponent
@@ -33,27 +35,27 @@
     configuration parameters).
 
     2. It implements the continuous deployment logic necessary to deploy models
     in a way that updates an existing model server that is already serving a
     previous version of the same model instead of creating a new model server
     for every new model version (see the `deploy_model` abstract method).
     This functionality can be consumed directly from ZenML pipeline steps, but
-    it can also be used outside of the pipeline to deploy ad-hoc models. It is
+    it can also be used outside of the pipeline to deploy ad hoc models. It is
     also usually coupled with a standard model deployer step, implemented by
     each integration, that hides the details of the deployment process away from
     the user.
 
     3. It acts as a ZenML BaseService registry, where every BaseService instance
     is used as an internal representation of a remote model server (see the
     `find_model_server` abstract method). To achieve this, it must be able to
     re-create the configuration of a BaseService from information that is
     persisted externally, alongside or even part of the remote model server
     configuration itself. For example, for model servers that are implemented as
     Kubernetes resources, the BaseService instances can be serialized and saved
-    as Kubernetes resourece annotations. This allows the model deployer to keep
+    as Kubernetes resource annotations. This allows the model deployer to keep
     track of all externally running model servers and to re-create their
     corresponding BaseService instance representations at any given time.
     The model deployer also defines methods that implement basic life-cycle
     management on remote model servers outside the coverage of a pipeline
     (see `stop_model_server`, `start_model_server` and `delete_model_server`).
     """
 
@@ -96,35 +98,36 @@
         """
 
     @staticmethod
     @abstractmethod
     def get_model_server_info(
         service: BaseService,
     ) -> Dict[str, Optional[str]]:
-        """Give implementation specific way to extract relevant model server
-        properties for the user
+        """Give implementation specific way to extract relevant model server properties for the user.
 
         Args:
             service: Integration-specific service instance
+
+        Returns:
+            A dictionary containing the relevant model server properties.
         """
 
     @abstractmethod
     def find_model_server(
         self,
         running: bool = False,
         service_uuid: Optional[UUID] = None,
         pipeline_name: Optional[str] = None,
         pipeline_run_id: Optional[str] = None,
         pipeline_step_name: Optional[str] = None,
         model_name: Optional[str] = None,
         model_uri: Optional[str] = None,
         model_type: Optional[str] = None,
     ) -> List[BaseService]:
-        """Abstract method to find one or more a model servers that match the
-        given criteria.
+        """Abstract method to find one or more a model servers that match the given criteria.
 
         Args:
             running: If true, only running services will be returned.
             service_uuid: The UUID of the service that was originally used
                 to deploy the model.
             pipeline_name: name of the pipeline that the deployed model was part
                 of.
@@ -184,15 +187,15 @@
         self,
         uuid: UUID,
         timeout: int = DEFAULT_DEPLOYMENT_START_STOP_TIMEOUT,
         force: bool = False,
     ) -> None:
         """Abstract method to delete a model server.
 
-        This operation is irreversable. A deleted model server must no longer
+        This operation is irreversible. A deleted model server must no longer
         show up in the list of model servers returned by `find_model_server`.
 
         Args:
             uuid: UUID of the model server to stop.
             timeout: timeout in seconds to wait for the service to stop. If
                 set to 0, the method will return immediately after
                 deprovisioning the service, without waiting for it to stop.
@@ -207,12 +210,18 @@
     ) -> Generator[str, bool, None]:
         """Get the logs of a model server.
 
         Args:
             uuid: UUID of the model server to get the logs of.
             follow: if True, the logs will be streamed as they are written
             tail: only retrieve the last NUM lines of log output.
+
+        Returns:
+            A generator that yields the logs of the model server.
+
+        Raises:
+            RuntimeError: if the model server is not found.
         """
         services = self.find_model_server(service_uuid=uuid)
         if len(services) == 0:
             raise RuntimeError(f"No model server found with UUID {uuid}")
         return services[0].get_logs(follow=follow, tail=tail)
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/__init__.py` & `zenml-0.9.0/src/zenml/orchestrators/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization for ZenML orchestrators.
+
 An orchestrator is a special kind of backend that manages the running of each
 step of the pipeline. Orchestrators administer the actual pipeline runs. You can
 think of it as the 'root' of any pipeline job that you run during your
 experimentation.
 
 ZenML supports a local orchestrator out of the box which allows you to run your
 pipelines in a local environment. We also support using Apache Airflow as the
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/base_orchestrator.py` & `zenml-0.9.0/src/zenml/orchestrators/base_orchestrator.py`

 * *Files 3% similar despite different names*

```diff
@@ -24,14 +24,15 @@
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 
 # The `run_step()` method of this file is a modified version of the local dag
 # runner implementation of tfx
+"""Base orchestrator class."""
 
 import json
 import time
 from abc import ABC, abstractmethod
 from typing import TYPE_CHECKING, Any, ClassVar, List, Optional
 
 from tfx.dsl.compiler.compiler import Compiler
@@ -70,17 +71,18 @@
     from zenml.runtime_configuration import RuntimeConfiguration
     from zenml.stack import Stack
 
 logger = get_logger(__name__)
 
 
 class BaseOrchestrator(StackComponent, ABC):
-    """
-    Base class for all orchestrators. In order to implement an
-    orchestrator you will need to subclass from this class.
+    """Base class for all orchestrators.
+
+    In order to implement an orchestrator you will need to subclass from this
+    class.
 
     How it works:
     -------------
     The `run()` method is the entrypoint that is executed when the
     pipeline's run method is called within the user code
     (`pipeline_instance.run()`).
 
@@ -122,81 +124,82 @@
         self,
         sorted_steps: List[BaseStep],
         pipeline: "BasePipeline",
         pb2_pipeline: Pb2Pipeline,
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> Any:
-        """
-         This method needs to be implemented by the respective orchestrator.
-         Depending on the type of orchestrator you'll have to perform slightly
-         different operations.
-
-         Simple Case:
-         ------------
-         The Steps are run directly from within the same environment in which
-         the orchestrator code is executed. In this case you will need to
-         deal with implementation-specific runtime configurations (like the
-         schedule) and then iterate through each step and finally call
-         `self.run_step()` to execute each step.
-
-         Advanced Case:
-         --------------
-         Most orchestrators will not run the steps directly. Instead, they
-         build some intermediate representation of the pipeline that is then
-         used to create and run the pipeline and its steps on the target
-         environment. For such orchestrators this method will have to build
-         this representation and either deploy it directly or return it.
-
-         Regardless of the implementation details, the orchestrator will need
-         to a way to trigger each step in the target environment. For this
-         the `run_step()` method should be used.
-
-         In case the orchestrator is using docker containers for orchestration
-         of each step, the `zenml.entrypoints.step_entrypoint` module can be
-         used as a generalized entrypoint that sets up all the necessary
-         prerequisites, parses input parameters and finally executes the step
-         using the `run_step()`method.
-
-         If the orchestrator needs to know the upstream steps for a specific
-         step to build a DAG, it can use the `get_upstream_step_names()` method
-         to get them.
-
-         Args:
-             sorted_steps: List of sorted steps
-             pipeline: Zenml Pipeline instance
-             pb2_pipeline: Protobuf Pipeline instance
-             stack: The stack the pipeline was run on
-             runtime_configuration: The Runtime configuration of the current run
+        """This method needs to be implemented by the respective orchestrator.
+
+        Depending on the type of orchestrator you'll have to perform slightly
+        different operations.
+
+        Simple Case:
+        ------------
+        The Steps are run directly from within the same environment in which
+        the orchestrator code is executed. In this case you will need to
+        deal with implementation-specific runtime configurations (like the
+        schedule) and then iterate through each step and finally call
+        `self.run_step()` to execute each step.
+
+        Advanced Case:
+        --------------
+        Most orchestrators will not run the steps directly. Instead, they
+        build some intermediate representation of the pipeline that is then
+        used to create and run the pipeline and its steps on the target
+        environment. For such orchestrators this method will have to build
+        this representation and either deploy it directly or return it.
+
+        Regardless of the implementation details, the orchestrator will need
+        to a way to trigger each step in the target environment. For this
+        the `run_step()` method should be used.
+
+        In case the orchestrator is using docker containers for orchestration
+        of each step, the `zenml.entrypoints.step_entrypoint` module can be
+        used as a generalized entrypoint that sets up all the necessary
+        prerequisites, parses input parameters and finally executes the step
+        using the `run_step()`method.
+
+        If the orchestrator needs to know the upstream steps for a specific
+        step to build a DAG, it can use the `get_upstream_step_names()` method
+        to get them.
+
+        Args:
+            sorted_steps: List of sorted steps.
+            pipeline: Zenml Pipeline instance.
+            pb2_pipeline: Protobuf Pipeline instance.
+            stack: The stack the pipeline was run on.
+            runtime_configuration: The Runtime configuration of the current run.
 
         Returns:
             The optional return value from this method will be returned by the
             `pipeline_instance.run()` call when someone is running a pipeline.
         """
 
     def run(
         self,
         pipeline: "BasePipeline",
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> Any:
-        """Runs a pipeline. To do this, a protobuf pipeline is created, the
-        context of the individual steps is expanded to include relevant data,
-        the steps are sorted into execution order and the implementation
-        specific `prepare_or_run_pipeline()` method is called.
+        """Runs a pipeline.
+
+        To do this, a protobuf pipeline is created, the context of the
+        individual steps is expanded to include relevant data, the steps are
+        sorted into execution order and the implementation specific
+        `prepare_or_run_pipeline()` method is called.
 
         Args:
             pipeline: The pipeline to run.
             stack: The stack on which the pipeline is run.
             runtime_configuration: Runtime configuration of the pipeline run.
 
-        Return:
+        Returns:
             The result of the call to `prepare_or_run_pipeline()`.
         """
-
         # Create the protobuf pipeline which will be needed for various reasons
         # in the following steps
         pb2_pipeline: Pb2Pipeline = Compiler().compile(
             create_tfx_pipeline(pipeline, stack=stack)
         )
 
         self._configure_node_context(
@@ -220,17 +223,18 @@
 
         return result
 
     @staticmethod
     def _get_sorted_steps(
         pipeline: "BasePipeline", pb2_pipeline: Pb2Pipeline
     ) -> List["BaseStep"]:
-        """Get steps sorted in the execution order. This simplifies the
-        building of a DAG at a later stage as it can be built with one iteration
-        over this sorted list of steps.
+        """Get steps sorted in the execution order.
+
+        This simplifies the building of a DAG at a later stage as it can be
+        built with one iteration over this sorted list of steps.
 
         Args:
             pipeline: The pipeline
             pb2_pipeline: The protobuf pipeline representation
 
         Returns:
             List of steps in execution order
@@ -254,14 +258,17 @@
     ) -> Optional[data_types.ExecutionInfo]:
         """This sets up a component launcher and executes the given step.
 
         Args:
             step: The step to be executed
             run_name: The unique run name
             pb2_pipeline: Protobuf Pipeline instance
+
+        Returns:
+            The execution info of the step.
         """
         # Substitute the runtime parameter to be a concrete run_id, it is
         # important for this to be unique for each run.
         runtime_parameter_utils.substitute_runtime_parameter(
             pb2_pipeline,
             {PIPELINE_RUN_ID_PARAMETER_NAME: run_name},
         )
@@ -322,23 +329,27 @@
         """Executes a tfx component.
 
         Args:
             tfx_launcher: A tfx launcher to execute the component.
 
         Returns:
             Optional execution info returned by the launcher.
+
+        Raises:
+            DuplicateRunNameError: If the run name is already in use.
         """
         step_name_param = (
             INTERNAL_EXECUTION_PARAMETER_PREFIX + PARAM_PIPELINE_PARAMETER_NAME
         )
         pipeline_step_name = tfx_launcher._pipeline_node.node_info.id
         start_time = time.time()
         logger.info(f"Step `{pipeline_step_name}` has started.")
         try:
             execution_info = tfx_launcher.launch()
+
             if execution_info and get_cache_status(execution_info):
                 if execution_info.exec_properties:
                     step_name = json.loads(
                         execution_info.exec_properties[step_name_param]
                     )
                     logger.info(
                         f"Using cached version of `{pipeline_step_name}` "
@@ -365,16 +376,15 @@
             f"{string_utils.get_human_readable_time(run_duration)}."
         )
         return execution_info
 
     def get_upstream_step_names(
         self, step: "BaseStep", pb2_pipeline: Pb2Pipeline
     ) -> List[str]:
-        """Given a step, use the associated pb2 node to find the names of all
-        upstream nodes.
+        """Given a step, use the associated pb2 node to find the names of all upstream nodes.
 
         Args:
             step: Instance of a Pipeline Step
             pb2_pipeline: Protobuf Pipeline instance
 
         Returns:
             List of step names from direct upstream steps
@@ -387,23 +397,25 @@
 
         return upstream_steps
 
     @staticmethod
     def _get_node_with_step_name(
         step_name: str, pb2_pipeline: Pb2Pipeline
     ) -> PipelineNode:
-        """Given the name of a step, return the node with that name from the
-        pb2_pipeline.
+        """Given the name of a step, return the node with that name from the pb2_pipeline.
 
         Args:
             step_name: Name of the step
             pb2_pipeline: pb2 pipeline containing nodes
 
         Returns:
             PipelineNode instance
+
+        Raises:
+            KeyError: If the step name is not found in the pipeline.
         """
         for node in pb2_pipeline.nodes:
             if (
                 node.WhichOneof("node") == "pipeline_node"
                 and node.pipeline_node.node_info.id == step_name
             ):
                 return node.pipeline_node
@@ -416,17 +428,18 @@
     @staticmethod
     def _configure_node_context(
         pipeline: "BasePipeline",
         pb2_pipeline: Pb2Pipeline,
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> None:
-        """Iterates through each node of a pb2_pipeline and attaches important
-        contexts to the nodes; namely pipeline.requirements, stack
-        information and the runtime configuration.
+        """Iterates through each node of a pb2_pipeline.
+
+        This attaches important contexts to the nodes; namely
+        pipeline.requirements, stack information and the runtime configuration.
 
         Args:
             pipeline: Zenml Pipeline instance
             pb2_pipeline: Protobuf Pipeline instance
             stack: The stack the pipeline was run on
             runtime_configuration: The Runtime configuration of the current run
         """
@@ -446,11 +459,11 @@
             context_utils.add_context_to_node(
                 pipeline_node,
                 type_=MetadataContextTypes.STACK.value,
                 name=str(hash(json.dumps(stack.dict(), sort_keys=True))),
                 properties=stack.dict(),
             )
 
-            # Add all pydantic objects from runtime_configuration to the context
+            # Add all Pydantic objects from runtime_configuration to the context
             context_utils.add_runtime_configuration_to_node(
                 pipeline_node, runtime_configuration
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/context_utils.py` & `zenml-0.9.0/src/zenml/orchestrators/context_utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utilities for the local orchestrator to help with contexts."""
+
 import json
 import logging
 import uuid
 from typing import TYPE_CHECKING, Any, Callable, Dict, Iterator, Tuple, cast
 
 from pydantic import BaseModel
 
@@ -30,16 +32,15 @@
 
 def add_context_to_node(
     pipeline_node: "pipeline_pb2.PipelineNode",
     type_: str,
     name: str,
     properties: Dict[str, str],
 ) -> None:
-    """
-    Add a new context to a TFX protobuf pipeline node.
+    """Adds a new context to a TFX protobuf pipeline node.
 
     Args:
         pipeline_node: A tfx protobuf pipeline node
         type_: The type name for the context to be added
         name: Unique key for the context
         properties: dictionary of strings as properties of the context
     """
@@ -54,27 +55,53 @@
         c_property = context.properties[key]
         c_property.field_value.string_value = value
 
 
 def serialize_pydantic_object(
     obj: BaseModel, *, skip_errors: bool = False
 ) -> Dict[str, str]:
-    """Convert a pydantic object to a dict of strings"""
+    """Convert a pydantic object to a dict of strings.
+
+    Args:
+        obj: a pydantic object.
+        skip_errors: if True, ignore errors when serializing the object.
+
+    Returns:
+        a dictionary of strings.
+    """
 
     class PydanticEncoder(json.JSONEncoder):
         def default(self, o: Any) -> Any:
+            """Default encoding for pydantic objects.
+
+            Args:
+                o: the object to encode.
+
+            Returns:
+                the encoded object.
+            """
             try:
                 return cast(Callable[[Any], str], obj.__json_encoder__)(o)
             except TypeError:
                 return super().default(o)
 
     def _inner_generator(
         dictionary: Dict[str, Any]
     ) -> Iterator[Tuple[str, str]]:
-        """Itemwise serialize each element in a dictionary."""
+        """Itemwise serialize each element in a dictionary.
+
+        Args:
+            dictionary: a dictionary.
+
+        Yields:
+            a tuple of (key, value).
+
+        Raises:
+            TypeError: if the value is not JSON serializable
+        """
         for key, item in dictionary.items():
             try:
                 yield key, json.dumps(item, cls=PydanticEncoder)
             except TypeError as e:
                 if skip_errors:
                     logging.info(
                         "Skipping adding field '%s' to metadata context as "
@@ -91,28 +118,34 @@
     return {key: value for key, value in _inner_generator(obj.dict())}
 
 
 def add_runtime_configuration_to_node(
     pipeline_node: "pipeline_pb2.PipelineNode",
     runtime_config: RuntimeConfiguration,
 ) -> None:
-    """
-    Add the runtime configuration of a pipeline run to a protobuf pipeline node.
+    """Add the runtime configuration of a pipeline run to a protobuf pipeline node.
 
     Args:
         pipeline_node: a tfx protobuf pipeline node
         runtime_config: a ZenML RuntimeConfiguration
     """
     skip_errors: bool = runtime_config.get(
         "ignore_unserializable_fields", False
     )
 
     # Determine the name of the context
     def _name(obj: "BaseModel") -> str:
-        """Compute a unique context name for a pydantic BaseModel."""
+        """Compute a unique context name for a pydantic BaseModel.
+
+        Args:
+            obj: a pydantic BaseModel
+
+        Returns:
+            a unique context name
+        """
         try:
             return str(hash(obj.json(sort_keys=True)))
         except TypeError as e:
             class_name = obj.__class__.__name__
             logging.info(
                 "Cannot convert %s to json, generating uuid instead. Error: %s",
                 class_name,
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/local/__init__.py` & `zenml-0.9.0/src/zenml/entrypoints/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,13 +1,20 @@
-#  Copyright (c) ZenML GmbH 2020. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initializations for ZenML entrypoints module."""
+
+from zenml.entrypoints.step_entrypoint_configuration import (
+    StepEntrypointConfiguration,
+)
+
+__all__ = ["StepEntrypointConfiguration"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/local/local_orchestrator.py` & `zenml-0.9.0/src/zenml/orchestrators/local/local_orchestrator.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML local orchestrator."""
 
 from typing import TYPE_CHECKING, Any, ClassVar, List
 
 from tfx.proto.orchestration.pipeline_pb2 import Pipeline as Pb2Pipeline
 
 from zenml.logger import get_logger
 from zenml.orchestrators import BaseOrchestrator
@@ -25,29 +26,39 @@
     from zenml.pipelines import BasePipeline
     from zenml.runtime_configuration import RuntimeConfiguration
 
 logger = get_logger(__name__)
 
 
 class LocalOrchestrator(BaseOrchestrator):
-    """Orchestrator responsible for running pipelines locally. This orchestrator
-    does not allow for concurrent execution of steps and also does not support
-    running on a schedule."""
+    """Orchestrator responsible for running pipelines locally.
+
+    This orchestrator does not allow for concurrent execution of steps and also
+    does not support running on a schedule.
+    """
 
     FLAVOR: ClassVar[str] = "local"
 
     def prepare_or_run_pipeline(
         self,
         sorted_steps: List[BaseStep],
         pipeline: "BasePipeline",
         pb2_pipeline: Pb2Pipeline,
         stack: "Stack",
         runtime_configuration: "RuntimeConfiguration",
     ) -> Any:
-        """This method iterates through all steps and executes them sequentially."""
+        """This method iterates through all steps and executes them sequentially.
+
+        Args:
+            sorted_steps: A list of steps in the pipeline.
+            pipeline: The pipeline object.
+            pb2_pipeline: The pipeline object in protobuf format.
+            stack: The stack object.
+            runtime_configuration: The runtime configuration object.
+        """
         if runtime_configuration.schedule:
             logger.warning(
                 "Local Orchestrator currently does not support the"
                 "use of schedules. The `schedule` will be ignored "
                 "and the pipeline will be run immediately."
             )
         assert runtime_configuration.run_name, "Run name must be set"
```

### Comparing `zenml-0.8.1rc0/src/zenml/orchestrators/utils.py` & `zenml-0.9.0/src/zenml/orchestrators/utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -7,109 +7,92 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions for the orchestrator."""
 
-import json
-from typing import TYPE_CHECKING, List, cast
+from typing import TYPE_CHECKING, List, Optional
 
 import tfx.orchestration.pipeline as tfx_pipeline
 from tfx.orchestration.portable import data_types
 from tfx.proto.orchestration.pipeline_pb2 import PipelineNode
 
 from zenml.logger import get_logger
-from zenml.repository import Repository
 from zenml.steps import BaseStep
-from zenml.steps.utils import (
-    INTERNAL_EXECUTION_PARAMETER_PREFIX,
-    PARAM_PIPELINE_PARAMETER_NAME,
-)
 
 if TYPE_CHECKING:
     from zenml.pipelines.base_pipeline import BasePipeline
     from zenml.stack import Stack
 
 logger = get_logger(__name__)
 
 
 def create_tfx_pipeline(
     zenml_pipeline: "BasePipeline", stack: "Stack"
 ) -> tfx_pipeline.Pipeline:
-    """Creates a tfx pipeline from a ZenML pipeline."""
+    """Creates a tfx pipeline from a ZenML pipeline.
+
+    Args:
+        zenml_pipeline: The ZenML pipeline.
+        stack: The stack.
+
+    Returns:
+        The tfx pipeline.
+    """
     # Connect the inputs/outputs of all steps in the pipeline
     zenml_pipeline.connect(**zenml_pipeline.steps)
 
     tfx_components = [step.component for step in zenml_pipeline.steps.values()]
 
     artifact_store = stack.artifact_store
-    metadata_store = stack.metadata_store
 
+    # We do not pass the metadata connection config here as it might not be
+    # accessible. Instead it is queried from the active stack right before a
+    # step is executed (see `BaseOrchestrator.run_step(...)`)
     return tfx_pipeline.Pipeline(
         pipeline_name=zenml_pipeline.name,
         components=tfx_components,  # type: ignore[arg-type]
         pipeline_root=artifact_store.path,
-        metadata_connection_config=metadata_store.get_tfx_metadata_config(),
         enable_cache=zenml_pipeline.enable_cache,
     )
 
 
-def get_cache_status(
-    execution_info: data_types.ExecutionInfo,
-) -> bool:
-    """Returns the caching status of a step.
+def get_step_for_node(node: PipelineNode, steps: List[BaseStep]) -> BaseStep:
+    """Finds the matching step for a tfx pipeline node.
 
     Args:
-        execution_info: The execution info of a `tfx` step.
-
-    Raises:
-        AttributeError: If the execution info is `None`.
-        KeyError: If no pipeline info is found in the `execution_info`.
+        node: The tfx pipeline node.
+        steps: The list of steps.
 
     Returns:
-        The caching status of a `tfx` step as a boolean value.
-    """
-    if execution_info is None:
-        logger.warning("No execution info found when checking cache status.")
-        return False
-
-    status = False
-    repository = Repository()
-    # TODO [ENG-706]: Get the current running stack instead of just the active
-    #   stack
-    active_stack = repository.active_stack
-    if not active_stack:
-        raise RuntimeError(
-            "No active stack is configured for the repository. Run "
-            "`zenml stack set STACK_NAME` to update the active stack."
-        )
+        The matching step.
 
-    metadata_store = active_stack.metadata_store
-
-    step_name_param = (
-        INTERNAL_EXECUTION_PARAMETER_PREFIX + PARAM_PIPELINE_PARAMETER_NAME
-    )
-    step_name = json.loads(execution_info.exec_properties[step_name_param])
-    if execution_info.pipeline_info:
-        pipeline_name = execution_info.pipeline_info.id
-    else:
-        raise KeyError(f"No pipeline info found for step `{step_name}`.")
-    pipeline_run_name = cast(str, execution_info.pipeline_run_id)
-    pipeline = metadata_store.get_pipeline(pipeline_name)
-    if pipeline is None:
-        logger.error(f"Pipeline {pipeline_name} not found in Metadata Store.")
-    else:
-        status = (
-            pipeline.get_run(pipeline_run_name).get_step(step_name).is_cached
-        )
-    return status
-
-
-def get_step_for_node(node: PipelineNode, steps: List[BaseStep]) -> BaseStep:
-    """Finds the matching step for a tfx pipeline node."""
+    Raises:
+        RuntimeError: If no matching step is found.
+    """
     step_name = node.node_info.id
     try:
         return next(step for step in steps if step.name == step_name)
     except StopIteration:
         raise RuntimeError(f"Unable to find step with name '{step_name}'.")
+
+
+def get_cache_status(
+    execution_info: Optional[data_types.ExecutionInfo],
+) -> bool:
+    """Returns whether a cached execution was used or not.
+
+    Args:
+        execution_info: The execution info.
+
+    Returns:
+        `True` if the execution was cached, `False` otherwise.
+    """
+    # An execution output URI is only provided if the step needs to be
+    # executed (= is not cached)
+    if execution_info and execution_info.execution_output_uri is None:
+        return True
+    else:
+        return False
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/__init__.py` & `zenml-0.9.0/src/zenml/pipelines/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,17 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-A ZenML pipeline is a sequence of tasks that execute in a specific order and
-yield artifacts. The artifacts are stored within the artifact store and indexed
+"""A ZenML pipeline consists of tasks that execute in order and yield artifacts.
+
+The artifacts are stored within the artifact store and indexed
 via the metadata store. Each individual task within a pipeline is known as a
 step. The standard pipelines within ZenML are designed to have easy interfaces
 to add pre-decided steps, with the order also pre-decided. Other sorts of
 pipelines can be created as well from scratch, building on the `BasePipeline` class.
 
 Pipelines can be written as simple functions. They are created by using decorators appropriate to the specific use case you have. The moment it is `run`, a pipeline is compiled and passed directly to the orchestrator.
 """
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/base_pipeline.py` & `zenml-0.9.0/src/zenml/pipelines/base_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Abstract base class for all ZenML pipelines."""
+
 import inspect
 from abc import abstractmethod
 from typing import (
     TYPE_CHECKING,
     Any,
     ClassVar,
     Dict,
@@ -38,22 +40,22 @@
 from zenml.exceptions import (
     DuplicatedConfigurationError,
     PipelineConfigurationError,
     PipelineInterfaceError,
     StackValidationError,
 )
 from zenml.integrations.registry import integration_registry
-from zenml.io import fileio, utils
+from zenml.io import fileio
 from zenml.logger import get_logger
 from zenml.pipelines.schedule import Schedule
 from zenml.repository import Repository
 from zenml.runtime_configuration import RuntimeConfiguration
 from zenml.steps import BaseStep
 from zenml.steps.base_step import BaseStepMeta
-from zenml.utils import yaml_utils
+from zenml.utils import io_utils, yaml_utils
 from zenml.utils.analytics_utils import AnalyticsEvent, track_event
 
 if TYPE_CHECKING:
     from zenml.stack import Stack
 
 logger = get_logger(__name__)
 PIPELINE_INNER_FUNC_NAME: str = "connect"
@@ -68,15 +70,24 @@
 
 class BasePipelineMeta(type):
     """Pipeline Metaclass responsible for validating the pipeline definition."""
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "BasePipelineMeta":
-        """Saves argument names for later verification purposes"""
+        """Saves argument names for later verification purposes.
+
+        Args:
+            name: The name of the class.
+            bases: The base classes of the class.
+            dct: The dictionary of the class.
+
+        Returns:
+            The class.
+        """
         cls = cast(Type["BasePipeline"], super().__new__(mcs, name, bases, dct))
 
         cls.STEP_SPEC = {}
 
         connect_spec = inspect.getfullargspec(
             inspect.unwrap(getattr(cls, PIPELINE_INNER_FUNC_NAME))
         )
@@ -110,14 +121,20 @@
     """
 
     STEP_SPEC: ClassVar[Dict[str, Any]] = None  # type: ignore[assignment]
 
     INSTANCE_CONFIGURATION: Dict[Text, Any] = {}
 
     def __init__(self, *args: BaseStep, **kwargs: Any) -> None:
+        """Initialize the BasePipeline.
+
+        Args:
+            *args: The steps to be executed by this pipeline.
+            **kwargs: The configuration for this pipeline.
+        """
         kwargs.update(getattr(self, INSTANCE_CONFIGURATION))
         self.enable_cache = kwargs.pop(PARAM_ENABLE_CACHE, True)
         self.required_integrations = kwargs.pop(PARAM_REQUIRED_INTEGRATIONS, ())
         self.requirements_file = kwargs.pop(PARAM_REQUIREMENTS_FILE, None)
         if self.requirements_file:
             logger.warning(
                 "The `requirements_file` argument has been deprecated. Please use `requirements` instead to pass in either a string path to a file listing your 'requirements' or a list of the individual requirements."
@@ -153,15 +170,24 @@
                 f"but got {len(steps) + len(kw_steps)}."
             )
 
         combined_steps = {}
         step_classes: Dict[Type[BaseStep], str] = {}
 
         def _verify_step(key: str, step: BaseStep) -> None:
-            """Verifies a single step of the pipeline."""
+            """Verifies a single step of the pipeline.
+
+            Args:
+                key: The key of the step.
+                step: The step to verify.
+
+            Raises:
+                PipelineInterfaceError: If the step is not of the correct type
+                    or is of the same class as another step.
+            """
             step_class = type(step)
 
             if isinstance(step, BaseStepMeta):
                 raise PipelineInterfaceError(
                     f"Wrong argument type (`{step_class}`) for argument "
                     f"'{key}' of pipeline '{self.name}'. "
                     f"A `BaseStep` subclass was provided instead of an "
@@ -230,24 +256,38 @@
                 f"only requires the following steps: {expected_steps}."
             )
 
         self.__steps = combined_steps
 
     @abstractmethod
     def connect(self, *args: BaseStep, **kwargs: BaseStep) -> None:
-        """Function that connects inputs and outputs of the pipeline steps."""
+        """Function that connects inputs and outputs of the pipeline steps.
+
+        Args:
+            *args: The positional arguments passed to the pipeline.
+            **kwargs: The keyword arguments passed to the pipeline.
+
+        Raises:
+            NotImplementedError: Always.
+        """
         raise NotImplementedError
 
     @property
     def requirements(self) -> Set[str]:
         """Set of Python requirements of this pipeline.
 
         This property is a combination of the requirements of
         - required integrations for this pipeline
         - the `requirements` specified for this pipeline
+
+        Returns:
+            Set of Python requirements of this pipeline.
+
+        Raises:
+            KeyError: If the requirements file could not be found.
         """
         requirements = set()
 
         for integration_name in self.required_integrations:
             try:
                 integration_requirements = (
                     integration_registry.select_integration_requirements(
@@ -311,26 +351,43 @@
                     }
                 )
 
         return requirements
 
     @property
     def steps(self) -> Dict[str, BaseStep]:
-        """Returns a dictionary of pipeline steps."""
+        """Returns a dictionary of pipeline steps.
+
+        Returns:
+            A dictionary of pipeline steps.
+        """
         return self.__steps
 
     @steps.setter
     def steps(self, steps: Dict[str, BaseStep]) -> NoReturn:
-        """Setting the steps property is not allowed. This method always
-        raises a PipelineInterfaceError.
+        """Setting the steps property is not allowed.
+
+        Args:
+            steps: The steps to set.
+
+        Raises:
+            PipelineInterfaceError: Always.
         """
         raise PipelineInterfaceError("Cannot set steps manually!")
 
     def validate_stack(self, stack: "Stack") -> None:
-        """Validates if a stack is able to run this pipeline."""
+        """Validates if a stack is able to run this pipeline.
+
+        Args:
+            stack: The stack to validate.
+
+        Raises:
+            StackValidationError: If the step operator is not configured in the
+                active stack.
+        """
         available_step_operators = (
             {stack.step_operator.name} if stack.step_operator else set()
         )
 
         for step in self.steps.values():
             if (
                 step.custom_step_operator
@@ -340,16 +397,18 @@
                     f"Step '{step.name}' requires custom step operator "
                     f"'{step.custom_step_operator}' which is not configured in "
                     f"the active stack. Available step operators: "
                     f"{available_step_operators}."
                 )
 
     def _reset_step_flags(self) -> None:
-        """Reset the _has_been_called flag at the beginning of a pipeline run,
-        to make sure a pipeline instance can be called more than once."""
+        """Reset the `_has_been_called` flag at the beginning of a pipeline run.
+
+        This ensures a pipeline instance can be called more than once.
+        """
         for step in self.steps.values():
             step._has_been_called = False
 
     def run(
         self,
         *,
         run_name: Optional[str] = None,
@@ -357,14 +416,19 @@
         **additional_parameters: Any,
     ) -> Any:
         """Runs the pipeline on the active stack of the current repository.
 
         Args:
             run_name: Name of the pipeline run.
             schedule: Optional schedule of the pipeline.
+            additional_parameters: Additional parameters to pass to the
+                pipeline.
+
+        Returns:
+            The result of the pipeline.
         """
         if constants.SHOULD_PREVENT_PIPELINE_EXECUTION:
             # An environment variable was set to stop the execution of
             # pipelines. This is done to prevent execution of module-level
             # pipeline.run() calls inside docker containers which should only
             # run a single step.
             logger.info(
@@ -386,15 +450,15 @@
         from zenml.integrations.registry import integration_registry
 
         integration_registry.activate_integrations()
 
         # Path of the file where pipeline.run() was called. This is needed by
         # the airflow orchestrator so it knows which file to copy into the DAG
         # directory
-        dag_filepath = utils.resolve_relative_path(
+        dag_filepath = io_utils.resolve_relative_path(
             inspect.currentframe().f_back.f_code.co_filename  # type: ignore[union-attr]
         )
         runtime_configuration = RuntimeConfiguration(
             run_name=run_name,
             dag_filepath=dag_filepath,
             schedule=schedule,
             **additional_parameters,
@@ -454,14 +518,20 @@
         self, steps: Dict[str, Dict[str, Any]], overwrite: bool = False
     ) -> None:
         """Reads and sets step parameters from a config file.
 
         Args:
             steps: Maps step names to dicts of parameter names and values.
             overwrite: If `True`, overwrite previously set step parameters.
+
+        Raises:
+            PipelineConfigurationError: If the configuration file contains
+                invalid data.
+            DuplicatedConfigurationError: If the configuration file contains
+                duplicate step names.
         """
         for step_name, step_dict in steps.items():
             StepConfigurationKeys.key_check(step_dict)
 
             if step_name not in self.__steps:
                 raise PipelineConfigurationError(
                     f"Found '{step_name}' step in configuration yaml but it "
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/builtin_pipelines/__init__.py` & `zenml-0.9.0/src/zenml/steps/builtin_steps/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,8 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.pipelines.builtin_pipelines.training_pipeline import TrainingPipeline
+"""Initialization for builtin steps."""
+
+from zenml.steps.builtin_steps.pandas_analyzer import (
+    PandasAnalyzer,
+    PandasAnalyzerConfig,
+)
+from zenml.steps.builtin_steps.pandas_datasource import (
+    PandasDatasource,
+    PandasDatasourceConfig,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/builtin_pipelines/training_pipeline.py` & `zenml-0.9.0/src/zenml/pipelines/builtin_pipelines/training_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,32 +7,33 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for built-in ZenML training pipeline."""
 
 from zenml.pipelines import BasePipeline
 from zenml.steps import step_interfaces
 
 
 class TrainingPipeline(BasePipeline):
-    """Class for the classic training pipeline implementation"""
+    """Class for the classic training pipeline implementation."""
 
     def connect(  # type: ignore[override]
         self,
         datasource: step_interfaces.BaseDatasourceStep,
         splitter: step_interfaces.BaseSplitStep,
         analyzer: step_interfaces.BaseAnalyzerStep,
         preprocessor: step_interfaces.BasePreprocessorStep,
         trainer: step_interfaces.BaseTrainerStep,
         evaluator: step_interfaces.BaseEvaluatorStep,
     ) -> None:
-        """Main connect method for the standard training pipelines
+        """Main connect method for the standard training pipelines.
 
         Args:
             datasource: the step responsible for the data ingestion
             splitter: the step responsible for splitting the dataset into
                 train, test, val
             analyzer: the step responsible for extracting the statistics and
                 the schema
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/pipeline_decorator.py` & `zenml-0.9.0/src/zenml/pipelines/pipeline_decorator.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Decorator function for ZenML pipelines."""
+
 from typing import (
     Callable,
     List,
     Optional,
     Sequence,
     Type,
     TypeVar,
@@ -35,81 +37,79 @@
 )
 
 F = TypeVar("F", bound=Callable[..., None])
 
 
 @overload
 def pipeline(_func: F) -> Type[BasePipeline]:
-    """Type annotations for pipeline decorator in case of no arguments."""
     ...
 
 
 @overload
 def pipeline(
     *,
     name: Optional[str] = None,
     enable_cache: bool = True,
     required_integrations: Sequence[str] = (),
     requirements_file: Optional[str] = None,
     requirements: Optional[Union[str, List[str]]] = None,
     dockerignore_file: Optional[str] = None,
     secrets: Optional[List[str]] = [],
 ) -> Callable[[F], Type[BasePipeline]]:
-    """Type annotations for step decorator in case of arguments."""
     ...
 
 
 def pipeline(
     _func: Optional[F] = None,
     *,
     name: Optional[str] = None,
     enable_cache: bool = True,
     required_integrations: Sequence[str] = (),
     requirements_file: Optional[str] = None,
     requirements: Optional[Union[str, List[str]]] = None,
     dockerignore_file: Optional[str] = None,
     secrets: Optional[List[str]] = [],
 ) -> Union[Type[BasePipeline], Callable[[F], Type[BasePipeline]]]:
-    """Outer decorator function for the creation of a ZenML pipeline
+    """Outer decorator function for the creation of a ZenML pipeline.
 
     In order to be able to work with parameters such as "name", it features a
     nested decorator structure.
 
     Args:
         _func: The decorated function.
         name: The name of the pipeline. If left empty, the name of the
             decorated function will be used as a fallback.
         enable_cache: Whether to use caching or not.
         required_integrations: Optional list of ZenML integrations that are
             required to run this pipeline. Run `zenml integration list` for
             a full list of available integrations.
         requirements_file: DEPRECATED: Optional path to a pip requirements file
-        that contains requirements to run the pipeline. Please use
-        'requirements' instead.
+            that contains requirements to run the pipeline. Please use
+            'requirements' instead.
         requirements: Optional path to a requirements file or a list of requirements.
         dockerignore_file: Optional path to a dockerignore file to use when
             building docker images for running this pipeline.
             **Note**: If you pass a file, make sure it does not include the
             `.zen` directory as it is needed to run ZenML inside the container.
+        secrets: Optional list of secrets that are required to run this pipeline.
 
     Returns:
         the inner decorator which creates the pipeline class based on the
         ZenML BasePipeline
     """
 
     def inner_decorator(func: F) -> Type[BasePipeline]:
-        """Inner decorator function for the creation of a ZenML Pipeline
+        """Inner decorator function for the creation of a ZenML pipeline.
 
         Args:
-          func: types.FunctionType, this function will be used as the
-            "connect" method of the generated Pipeline
+            func: types.FunctionType, this function will be used as the
+                "connect" method of the generated Pipeline
 
         Returns:
             the class of a newly generated ZenML Pipeline
-
         """
         return type(  # noqa
             name if name else func.__name__,
             (BasePipeline,),
             {
                 PIPELINE_INNER_FUNC_NAME: staticmethod(func),  # type: ignore[arg-type] # noqa
                 INSTANCE_CONFIGURATION: {
```

### Comparing `zenml-0.8.1rc0/src/zenml/pipelines/schedule.py` & `zenml-0.9.0/src/zenml/pipelines/schedule.py`

 * *Files 27% similar despite different names*

```diff
@@ -7,48 +7,105 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Class for defining a pipeline schedule."""
 
 import datetime
-from typing import Optional
+from typing import Any, Dict, Optional
 
-from pydantic import BaseModel
+from pydantic import BaseModel, root_validator
+
+from zenml.logger import get_logger
+
+logger = get_logger(__name__)
 
 
 class Schedule(BaseModel):
     """Class for defining a pipeline schedule.
 
     Attributes:
-        start_time: Datetime object to indicate when to start the schedule.
-        end_time: Datetime object to indicate when to end the schedule.
-        interval_second: Datetime timedelta indicating the seconds between two
+        cron_expression: Cron expression for the pipeline schedule. If a value
+            for this is set it takes precedence over the start time + interval.
+        start_time: datetime object to indicate when to start the schedule.
+        end_time: datetime object to indicate when to end the schedule.
+        interval_second: datetime timedelta indicating the seconds between two
             recurring runs for a periodic schedule.
         catchup: Whether the recurring run should catch up if behind schedule.
             For example, if the recurring run is paused for a while and
             re-enabled afterwards. If catchup=True, the scheduler will catch
             up on (backfill) each missed interval. Otherwise, it only
             schedules the latest interval if more than one interval is ready to
             be scheduled. Usually, if your pipeline handles backfill
             internally, you should turn catchup off to avoid duplicate backfill.
     """
 
-    start_time: datetime.datetime
+    cron_expression: Optional[str] = None
+    start_time: Optional[datetime.datetime] = None
     end_time: Optional[datetime.datetime] = None
-    interval_second: datetime.timedelta
+    interval_second: Optional[datetime.timedelta] = None
     catchup: bool = False
 
+    @root_validator
+    def _ensure_cron_or_periodic_schedule_configured(
+        cls, values: Dict[str, Any]
+    ) -> Dict[str, Any]:
+        """Ensures that the cron expression or start time + interval are set.
+
+        Args:
+            values: All attributes of the schedule.
+
+        Returns:
+            All schedule attributes.
+
+        Raises:
+            ValueError: If no cron expression or start time + interval were
+                provided.
+        """
+        cron_expression = values.get("cron_expression")
+        periodic_schedule = values.get("start_time") and values.get(
+            "interval_second"
+        )
+
+        if cron_expression and periodic_schedule:
+            logger.warning(
+                "This schedule was created with a cron expression as well as "
+                "values for `start_time` and `interval_seconds`. The resulting "
+                "behaviour depends on the concrete orchestrator implementation "
+                "but will usually ignore the interval and use the cron "
+                "expression."
+            )
+            return values
+        elif cron_expression or periodic_schedule:
+            return values
+        else:
+            raise ValueError(
+                "Either a cron expression or start time and interval seconds "
+                "need to be set for a valid schedule."
+            )
+
     @property
-    def utc_start_time(self) -> str:
-        """ISO-formatted string of the UTC start time."""
+    def utc_start_time(self) -> Optional[str]:
+        """Optional ISO-formatted string of the UTC start time.
+
+        Returns:
+            Optional ISO-formatted string of the UTC start time.
+        """
+        if not self.start_time:
+            return None
+
         return self.start_time.astimezone(datetime.timezone.utc).isoformat()
 
     @property
     def utc_end_time(self) -> Optional[str]:
-        """Optional ISO-formatted string of the UTC end time."""
+        """Optional ISO-formatted string of the UTC end time.
+
+        Returns:
+            Optional ISO-formatted string of the UTC end time.
+        """
         if not self.end_time:
             return None
 
         return self.end_time.astimezone(datetime.timezone.utc).isoformat()
```

### Comparing `zenml-0.8.1rc0/src/zenml/post_execution/__init__.py` & `zenml-0.9.0/src/zenml/post_execution/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization for the post-execution module.
+
 After executing a pipeline, the user needs to be able to fetch it from history
 and perform certain tasks. The post_execution submodule provides a set of
 interfaces with which the user can interact with artifacts, the pipeline, steps,
 and the post-run pipeline object.
 """
 
 from zenml.post_execution.artifact import ArtifactView
```

### Comparing `zenml-0.8.1rc0/src/zenml/post_execution/artifact.py` & `zenml-0.9.0/src/zenml/post_execution/artifact.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for the post-execution artifact class."""
 
 from typing import TYPE_CHECKING, Any, Optional, Type
 
 from zenml.logger import get_logger
 from zenml.utils import source_utils
 
 if TYPE_CHECKING:
@@ -22,16 +23,18 @@
     from zenml.metadata_stores import BaseMetadataStore
     from zenml.post_execution.step import StepView
 
 logger = get_logger(__name__)
 
 
 class ArtifactView:
-    """Post-execution artifact class which can be used to read
-    artifact data that was created during a pipeline execution.
+    """Post-execution artifact class.
+
+    This can be used to read artifact data that was created during a pipeline
+    execution.
     """
 
     def __init__(
         self,
         id_: int,
         type_: str,
         uri: str,
@@ -64,48 +67,77 @@
         self._materializer = materializer
         self._data_type = data_type
         self._metadata_store = metadata_store
         self._parent_step_id = parent_step_id
 
     @property
     def id(self) -> int:
-        """Returns the artifact id."""
+        """Returns the artifact id.
+
+        Returns:
+            The artifact id.
+        """
         return self._id
 
     @property
     def type(self) -> str:
-        """Returns the artifact type."""
+        """Returns the artifact type.
+
+        Returns:
+            The artifact type.
+        """
         return self._type
 
     @property
     def data_type(self) -> str:
-        """Returns the data type of the artifact."""
+        """Returns the data type of the artifact.
+
+        Returns:
+            The data type of the artifact.
+        """
         return self._data_type
 
     @property
     def uri(self) -> str:
-        """Returns the URI where the artifact data is stored."""
+        """Returns the URI where the artifact data is stored.
+
+        Returns:
+            The URI where the artifact data is stored.
+        """
         return self._uri
 
     @property
     def parent_step_id(self) -> int:
-        """Returns the ID of the parent step. This need not be equivalent to
-        the ID of the producer step."""
+        """Returns the ID of the parent step.
+
+        This need not be equivalent to the ID of the producer step.
+
+        Returns:
+            The ID of the parent step.
+        """
         return self._parent_step_id
 
     @property
     def producer_step(self) -> "StepView":
-        """Returns the original StepView that produced the artifact."""
+        """Returns the original StepView that produced the artifact.
+
+        Returns:
+            The original StepView that produced the artifact.
+        """
         # TODO [ENG-174]: Replace with artifact.id instead of passing self if
         #  required.
         return self._metadata_store.get_producer_step_from_artifact(self)
 
     @property
     def is_cached(self) -> bool:
-        """Returns True if artifact was cached in a previous run, else False."""
+        """Returns True if artifact was cached in a previous run, else False.
+
+        Returns:
+            True if artifact was cached in a previous run, else False.
+        """
         # self._metadata_store.
         return self.producer_step.id != self.parent_step_id
 
     def read(
         self,
         output_data_type: Optional[Type[Any]] = None,
         materializer_class: Optional[Type["BaseMaterializer"]] = None,
@@ -117,17 +149,19 @@
                 read, will be passed to the materializers `handle_input` method.
             materializer_class: The class of the materializer that should be
                 used to read the artifact data. If no materializer class is
                 given, we use the materializer that was used to write the
                 artifact during execution of the pipeline.
 
         Returns:
-              The materialized data.
-        """
+            The materialized data.
 
+        Raises:
+            ModuleNotFoundError: If the materializer class could not be found.
+        """
         if not materializer_class:
             try:
                 materializer_class = source_utils.load_source_path_class(
                     self._materializer
                 )
             except (ModuleNotFoundError, AttributeError) as e:
                 logger.error(
@@ -161,20 +195,31 @@
         # TODO [ENG-162]: passing in `self` to initialize the materializer only
         #  works because materializers only require a `.uri` property at the
         #  moment.
         materializer = materializer_class(self)  # type: ignore[arg-type]
         return materializer.handle_input(output_data_type)
 
     def __repr__(self) -> str:
-        """Returns a string representation of this artifact."""
+        """Returns a string representation of this artifact.
+
+        Returns:
+            A string representation of this artifact.
+        """
         return (
             f"{self.__class__.__qualname__}(id={self._id}, "
             f"type='{self._type}', uri='{self._uri}', "
             f"materializer='{self._materializer}')"
         )
 
     def __eq__(self, other: Any) -> bool:
-        """Returns whether the other object is referring to the
-        same artifact."""
+        """Returns whether the other object is referring to the same artifact.
+
+        Args:
+            other: The other object to compare to.
+
+        Returns:
+            True if the other object is referring to the same artifact, else
+            False.
+        """
         if isinstance(other, ArtifactView):
             return self._id == other._id and self._uri == other._uri
         return NotImplemented
```

### Comparing `zenml-0.8.1rc0/src/zenml/post_execution/pipeline.py` & `zenml-0.9.0/src/zenml/post_execution/pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the post-execution pipeline."""
 
 from typing import TYPE_CHECKING, Any, List, Optional
 
 from zenml.enums import StackComponentType
 from zenml.logger import get_logger
 from zenml.zen_stores.models.pipeline_models import PipelineRunWrapper
 
@@ -22,16 +23,17 @@
     from zenml.metadata_stores import BaseMetadataStore
     from zenml.post_execution.pipeline_run import PipelineRunView
 
 logger = get_logger(__name__)
 
 
 class PipelineView:
-    """Post-execution pipeline class which can be used to query
-    pipeline-related information from the metadata store.
+    """Post-execution pipeline class.
+
+    This can be used to query pipeline-related information from the metadata store.
     """
 
     def __init__(
         self, id_: int, name: str, metadata_store: "BaseMetadataStore"
     ):
         """Initializes a post-execution pipeline object.
 
@@ -47,46 +49,60 @@
         """
         self._id = id_
         self._name = name
         self._metadata_store = metadata_store
 
     @property
     def name(self) -> str:
-        """Returns the name of the pipeline."""
+        """Returns the name of the pipeline.
+
+        Returns:
+            The name of the pipeline.
+        """
         return self._name
 
     @property
     def runs(self) -> List["PipelineRunView"]:
         """Returns all stored runs of this pipeline.
 
         The runs are returned in chronological order, so the latest
         run will be the last element in this list.
+
+        Returns:
+            A list of all stored runs of this pipeline.
         """
         # Do not cache runs as new runs might appear during this objects
         # lifecycle
         runs = list(self._metadata_store.get_pipeline_runs(self).values())
 
         for run in runs:
             run._run_wrapper = self._get_zenstore_run(run_name=run.name)
 
         return runs
 
     def get_run_names(self) -> List[str]:
-        """Returns a list of all run names."""
+        """Returns a list of all run names.
+
+        Returns:
+            A list of all run names.
+        """
         # Do not cache runs as new runs might appear during this objects
         # lifecycle
         runs = self._metadata_store.get_pipeline_runs(self)
         return list(runs.keys())
 
     def get_run(self, name: str) -> "PipelineRunView":
         """Returns a run for the given name.
 
         Args:
             name: The name of the run to return.
 
+        Returns:
+            The run with the given name.
+
         Raises:
             KeyError: If there is no run with the given name.
         """
         run = self._metadata_store.get_pipeline_run(self, name)
 
         if not run:
             raise KeyError(
@@ -95,22 +111,25 @@
                 f"names: `{self.get_run_names()}`"
             )
 
         run._run_wrapper = self._get_zenstore_run(run_name=name)
         return run
 
     def get_run_for_completed_step(self, step_name: str) -> "PipelineRunView":
-        """This method helps you find out which pipeline run produced
-        the cached artifact of a given step.
+        """Ascertains which pipeline run produced the cached artifact of a given step.
 
         Args:
             step_name: Name of step at hand
-        Return:
+
+        Returns:
             None if no run is found that completed the given step,
-             else the original pipeline_run
+                else the original pipeline_run.
+
+        Raises:
+            LookupError: If no run is found that completed the given step
         """
         orig_pipeline_run = None
 
         for run in reversed(self.runs):
             try:
                 step = run.get_step(step_name)
                 if step.is_completed:
@@ -127,15 +146,22 @@
         return orig_pipeline_run
 
     def _get_zenstore_run(self, run_name: str) -> Optional[PipelineRunWrapper]:
         """Gets a ZenStore run for the given run name.
 
         This will filter all ZenStore runs by the pipeline name of this
         pipeline view, the run name passed in as an argument and the metadata
-        store that this pipeline run is associated with."""
+        store that this pipeline run is associated with.
+
+        Args:
+            run_name: The name of the run to get.
+
+        Returns:
+            The ZenStore run with the given name, if found.
+        """
         from zenml.repository import Repository
 
         repo = Repository(skip_repository_check=True)  # type: ignore[call-arg]
         try:
             run_wrapper = repo.zen_store.get_pipeline_run(
                 pipeline_name=self.name, run_name=run_name
             )
@@ -148,22 +174,33 @@
                 return run_wrapper
         except KeyError:
             pass
 
         return None
 
     def __repr__(self) -> str:
-        """Returns a string representation of this pipeline."""
+        """Returns a string representation of this pipeline.
+
+        Returns:
+            A string representation of this pipeline.
+        """
         return (
             f"{self.__class__.__qualname__}(id={self._id}, "
             f"name='{self._name}')"
         )
 
     def __eq__(self, other: Any) -> bool:
-        """Returns whether the other object is referring to the
-        same pipeline."""
+        """Returns whether the other object is referring to the same pipeline.
+
+        Args:
+            other: The other object to compare to.
+
+        Returns:
+            True if the other object is referring to the same pipeline,
+            False otherwise.
+        """
         if isinstance(other, PipelineView):
             return (
                 self._id == other._id
                 and self._metadata_store.uuid == other._metadata_store.uuid
             )
         return NotImplemented
```

### Comparing `zenml-0.8.1rc0/src/zenml/post_execution/pipeline_run.py` & `zenml-0.9.0/src/zenml/post_execution/pipeline_run.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the post-execution pipeline run class."""
 
 from collections import OrderedDict
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from ml_metadata import proto
 
 from zenml.enums import ExecutionStatus
@@ -26,28 +27,32 @@
 if TYPE_CHECKING:
     from zenml.metadata_stores import BaseMetadataStore
 
 logger = get_logger(__name__)
 
 
 class PipelineRunView:
-    """Post-execution pipeline run class which can be used to query
-    steps and artifact information associated with a pipeline execution.
+    """Post-execution pipeline run class.
+
+    This can be used to query steps and artifact information associated with a
+    pipeline execution.
     """
 
     def __init__(
         self,
         id_: int,
         name: str,
         executions: List[proto.Execution],
         metadata_store: "BaseMetadataStore",
     ):
         """Initializes a post-execution pipeline run object.
+
         In most cases `PipelineRunView` objects should not be created manually
         but retrieved from a `PipelineView` object instead.
+
         Args:
             id_: The context id of this pipeline run.
             name: The name of this pipeline run.
             executions: All executions associated with this pipeline run.
             metadata_store: The metadata store which should be used to fetch
                 additional information related to this pipeline run.
         """
@@ -60,50 +65,69 @@
 
         # This might be set from the parent pipeline view in case this run
         # is also tracked in the ZenStore
         self._run_wrapper: Optional[PipelineRunWrapper] = None
 
     @property
     def name(self) -> str:
-        """Returns the name of the pipeline run."""
+        """Returns the name of the pipeline run.
+
+        Returns:
+            The name of the pipeline run.
+        """
         return self._name
 
     @property
     def zenml_version(self) -> Optional[str]:
-        """Version of ZenML that this pipeline run was performed with."""
+        """Version of ZenML that this pipeline run was performed with.
+
+        Returns:
+            The version of ZenML that this pipeline run was performed with.
+        """
         if self._run_wrapper:
             return self._run_wrapper.zenml_version
         return None
 
     @property
     def git_sha(self) -> Optional[str]:
         """Git commit SHA that this pipeline run was performed on.
 
         This will only be set if the pipeline code is in a git repository and
-        there are no dirty files when running the pipeline."""
+        there are no dirty files when running the pipeline.
+
+        Returns:
+            The git commit SHA that this pipeline run was performed on.
+        """
         if self._run_wrapper:
             return self._run_wrapper.git_sha
         return None
 
     @property
     def runtime_configuration(self) -> Optional["RuntimeConfiguration"]:
         """Runtime configuration that was used for this pipeline run.
 
         This will only be set if the pipeline run was tracked in a ZenStore.
+
+        Returns:
+            The runtime configuration that was used for this pipeline run.
         """
         if self._run_wrapper:
             return RuntimeConfiguration(
                 **self._run_wrapper.runtime_configuration
             )
 
         return None
 
     @property
     def status(self) -> ExecutionStatus:
-        """Returns the current status of the pipeline run."""
+        """Returns the current status of the pipeline run.
+
+        Returns:
+            The current status of the pipeline run.
+        """
         step_statuses = (step.status for step in self.steps)
 
         if any(status == ExecutionStatus.FAILED for status in step_statuses):
             return ExecutionStatus.FAILED
         elif all(
             status == ExecutionStatus.COMPLETED
             or status == ExecutionStatus.CACHED
@@ -111,29 +135,40 @@
         ):
             return ExecutionStatus.COMPLETED
         else:
             return ExecutionStatus.RUNNING
 
     @property
     def steps(self) -> List[StepView]:
-        """Returns all steps that were executed as part of this pipeline run."""
+        """Returns all steps that were executed as part of this pipeline run.
+
+        Returns:
+            A list of all steps that were executed as part of this pipeline run.
+        """
         self._ensure_steps_fetched()
         return list(self._steps.values())
 
     def get_step_names(self) -> List[str]:
-        """Returns a list of all step names."""
+        """Returns a list of all step names.
+
+        Returns:
+            A list of all step names.
+        """
         self._ensure_steps_fetched()
         return list(self._steps.keys())
 
     def get_step(self, name: str) -> StepView:
         """Returns a step for the given name.
 
         Args:
             name: The name of the step to return.
 
+        Returns:
+            A step for the given name.
+
         Raises:
             KeyError: If there is no step with the given name.
         """
         self._ensure_steps_fetched()
         try:
             return self._steps[name]
         except KeyError:
@@ -155,22 +190,32 @@
             # If we have the run wrapper from the ZenStore, pass on the step
             # wrapper so users can access additional information about the step.
             for step_wrapper in self._run_wrapper.pipeline.steps:
                 if step_wrapper.name in self._steps:
                     self._steps[step_wrapper.name]._step_wrapper = step_wrapper
 
     def __repr__(self) -> str:
-        """Returns a string representation of this pipeline run."""
+        """Returns a string representation of this pipeline run.
+
+        Returns:
+            A string representation of this pipeline run.
+        """
         return (
             f"{self.__class__.__qualname__}(id={self._id}, "
             f"name='{self._name}')"
         )
 
     def __eq__(self, other: Any) -> bool:
-        """Returns whether the other object is referring to the same
-        pipeline run."""
+        """Returns whether the other object is referring to the same pipeline run.
+
+        Args:
+            other: The other object to compare to.
+
+        Returns:
+            True if the other object is referring to the same pipeline run.
+        """
         if isinstance(other, PipelineRunView):
             return (
                 self._id == other._id
                 and self._metadata_store.uuid == other._metadata_store.uuid
             )
         return NotImplemented
```

### Comparing `zenml-0.8.1rc0/src/zenml/post_execution/step.py` & `zenml-0.9.0/src/zenml/post_execution/step.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,28 +7,30 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a post-execution step class."""
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from zenml.enums import ExecutionStatus
 from zenml.post_execution.artifact import ArtifactView
 from zenml.zen_stores.models.pipeline_models import StepWrapper
 
 if TYPE_CHECKING:
     from zenml.metadata_stores import BaseMetadataStore
 
 
 class StepView:
-    """Post-execution step class which can be used to query
-    artifact information associated with a pipeline step.
+    """Post-execution step class.
+
+    This can be used to query artifact information associated with a pipeline step.
     """
 
     def __init__(
         self,
         id_: int,
         parents_step_ids: List[int],
         entrypoint_name: str,
@@ -62,25 +64,37 @@
 
         # This might be set from the parent pipeline run view in case the run
         # is also tracked in the ZenStore
         self._step_wrapper: Optional[StepWrapper] = None
 
     @property
     def id(self) -> int:
-        """Returns the step id."""
+        """Returns the step id.
+
+        Returns:
+            The step id.
+        """
         return self._id
 
     @property
     def parents_step_ids(self) -> List[int]:
-        """Returns a list of ID's of all parents of this step."""
+        """Returns a list of IDs of all parents of this step.
+
+        Returns:
+            A list of IDs of all parents of this step.
+        """
         return self._parents_step_ids
 
     @property
     def parent_steps(self) -> List["StepView"]:
-        """Returns a list of all parent steps of this step."""
+        """Returns a list of all parent steps of this step.
+
+        Returns:
+            A list of all parent steps of this step.
+        """
         steps = [
             self._metadata_store.get_step_by_id(s)
             for s in self.parents_step_ids
         ]
         return steps
 
     @property
@@ -94,14 +108,17 @@
             # the step entrypoint_name will be "my_step"
             @step(name="my_step")
             def my_step_function(...)
 
             # the step entrypoint_name will be "my_step_function"
             @step
             def my_step_function(...)
+
+        Returns:
+            The step entrypoint_name.
         """
         return self._entrypoint_name
 
     @property
     def name(self) -> str:
         """Returns the name as it is defined in the pipeline.
 
@@ -116,74 +133,111 @@
             def my_pipeline_function(step_a)
 
             p = my_pipeline_function(
                     step_a = my_step_function()
                 )
 
             The name will be `step_a`
+
+        Returns:
+            The name of this step.
         """
         return self._name
 
     @property
     def docstring(self) -> Optional[str]:
-        """Docstring of the step function or class."""
+        """Docstring of the step function or class.
+
+        Returns:
+            The docstring of the step function or class.
+        """
         if self._step_wrapper:
             return self._step_wrapper.docstring
         return None
 
     @property
     def parameters(self) -> Dict[str, Any]:
-        """The parameters used to run this step."""
+        """The parameters used to run this step.
+
+        Returns:
+            The parameters used to run this step.
+        """
         return self._parameters
 
     @property
     def status(self) -> ExecutionStatus:
-        """Returns the current status of the step."""
+        """Returns the current status of the step.
+
+        Returns:
+            The current status of the step.
+        """
         return self._metadata_store.get_step_status(self)
 
     @property
     def is_cached(self) -> bool:
-        """Returns whether the step is cached or not."""
+        """Returns whether the step is cached or not.
+
+        Returns:
+            True if the step is cached, False otherwise.
+        """
         return self.status == ExecutionStatus.CACHED
 
     @property
     def is_completed(self) -> bool:
-        """Returns whether the step is cached or not."""
+        """Returns whether the step is cached or not.
+
+        Returns:
+            True if the step is completed, False otherwise.
+        """
         return self.status == ExecutionStatus.COMPLETED
 
     @property
     def inputs(self) -> Dict[str, ArtifactView]:
-        """Returns all input artifacts that were used to run this step."""
+        """Returns all input artifacts that were used to run this step.
+
+        Returns:
+            A dictionary of artifact names to artifact views.
+        """
         self._ensure_inputs_outputs_fetched()
         return self._inputs
 
     @property
     def input(self) -> ArtifactView:
         """Returns the input artifact that was used to run this step.
 
+        Returns:
+            The input artifact.
+
         Raises:
             ValueError: If there were zero or multiple inputs to this step.
         """
         if len(self.inputs) != 1:
             raise ValueError(
                 "Can't use the `StepView.input` property for steps with zero "
                 "or multiple inputs, use `StepView.inputs` instead."
             )
         return next(iter(self.inputs.values()))
 
     @property
     def outputs(self) -> Dict[str, ArtifactView]:
-        """Returns all output artifacts that were written by this step."""
+        """Returns all output artifacts that were written by this step.
+
+        Returns:
+            A dictionary of artifact names to artifact views.
+        """
         self._ensure_inputs_outputs_fetched()
         return self._outputs
 
     @property
     def output(self) -> ArtifactView:
         """Returns the output artifact that was written by this step.
 
+        Returns:
+            The output artifact.
+
         Raises:
             ValueError: If there were zero or multiple step outputs.
         """
         if len(self.outputs) != 1:
             raise ValueError(
                 "Can't use the `StepView.output` property for steps with zero "
                 "or multiple outputs, use `StepView.outputs` instead."
@@ -197,22 +251,34 @@
             return
 
         self._inputs, self._outputs = self._metadata_store.get_step_artifacts(
             self
         )
 
     def __repr__(self) -> str:
-        """Returns a string representation of this step."""
+        """Returns a string representation of this step.
+
+        Returns:
+            A string representation of this step.
+        """
         return (
             f"{self.__class__.__qualname__}(id={self._id}, "
             f"name='{self.name}', entrypoint_name='{self.entrypoint_name}'"
             f"parameters={self._parameters})"
         )
 
     def __eq__(self, other: Any) -> bool:
-        """Returns whether the other object is referring to the same step."""
+        """Returns whether the other object is referring to the same step.
+
+        Args:
+            other: The other object to compare to.
+
+        Returns:
+            True if the other object is referring to the same step, False
+            otherwise.
+        """
         if isinstance(other, StepView):
             return (
                 self._id == other._id
                 and self._metadata_store.uuid == other._metadata_store.uuid
             )
         return NotImplemented
```

### Comparing `zenml-0.8.1rc0/src/zenml/py.typed` & `zenml-0.9.0/src/zenml/integrations/wandb/experiment_trackers/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,13 +1,16 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
-#
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for the wandb experiment tracker."""
+
+from zenml.integrations.wandb.experiment_trackers.wandb_experiment_tracker import (  # noqa
+    WandbExperimentTracker,
+)
```

### Comparing `zenml-0.8.1rc0/src/zenml/repository.py` & `zenml-0.9.0/src/zenml/repository.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Repository implementation."""
+
 import os
 import random
 from abc import ABCMeta
 from collections import defaultdict
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, cast
 from uuid import UUID
@@ -26,18 +28,18 @@
 from zenml.constants import ENV_ZENML_REPOSITORY_PATH, REPOSITORY_DIRECTORY_NAME
 from zenml.enums import StackComponentType, StoreType
 from zenml.environment import Environment
 from zenml.exceptions import (
     ForbiddenRepositoryAccessError,
     InitializationException,
 )
-from zenml.io import fileio, utils
+from zenml.io import fileio
 from zenml.logger import get_logger
 from zenml.stack import Stack, StackComponent
-from zenml.utils import yaml_utils
+from zenml.utils import io_utils, yaml_utils
 from zenml.utils.analytics_utils import AnalyticsEvent, track
 from zenml.utils.filesync_model import FileSyncModel
 
 if TYPE_CHECKING:
     from zenml.config.profile_config import ProfileConfiguration
     from zenml.post_execution import PipelineView
     from zenml.zen_stores import BaseZenStore
@@ -69,21 +71,30 @@
         extra = "ignore"
         # all attributes with leading underscore are private and therefore
         # are mutable and not included in serialization
         underscore_attrs_are_private = True
 
 
 class LegacyRepositoryConfig(BaseModel):
+    """Pydantic object used for serializing legacy repository configuration options."""
+
     version: str
     active_stack_name: Optional[str]
     stacks: Dict[str, Dict[StackComponentType, Optional[str]]]
     stack_components: Dict[StackComponentType, Dict[str, str]]
 
     def get_stack_data(self, config_file: str) -> "ZenStoreModel":
-        """Extract stack data from Legacy Repository file."""
+        """Extract stack data from Legacy Repository file.
+
+        Args:
+            config_file: Path to the repository config file.
+
+        Returns:
+            ZenStoreModel: ZenStoreModel object containing the stack data.
+        """
         from zenml.zen_stores.models import ZenStoreModel
 
         return ZenStoreModel(
             config_file=config_file,
             stacks={
                 name: {
                     component_type: value
@@ -106,31 +117,42 @@
     * the singleton Repository instance is created on first access to reflect
     the currently active global configuration profile.
     * the Repository mustn't be accessed from within pipeline steps
 
     """
 
     def __init__(cls, *args: Any, **kwargs: Any) -> None:
-        """Initialize the Repository class."""
+        """Initialize the Repository class.
+
+        Args:
+            *args: Positional arguments.
+            **kwargs: Keyword arguments.
+        """
         super().__init__(*args, **kwargs)
         cls._global_repository: Optional["Repository"] = None
 
     def __call__(cls, *args: Any, **kwargs: Any) -> "Repository":
         """Create or return the global Repository instance.
 
         If the Repository constructor is called with custom arguments,
         the singleton functionality of the metaclass is bypassed: a new
         Repository instance is created and returned immediately and without
         saving it as the global Repository singleton.
 
+        Args:
+            *args: Positional arguments.
+            **kwargs: Keyword arguments.
+
+        Returns:
+            Repository: The global Repository instance.
+
         Raises:
             ForbiddenRepositoryAccessError: If trying to create a `Repository`
                 instance while a ZenML step is being executed.
         """
-
         # `skip_repository_check` is a special kwarg that can be passed to
         # the Repository constructor to bypass the check that prevents the
         # Repository instance from being accessed from within pipeline steps.
         if not kwargs.pop("skip_repository_check", False):
             if Environment().step_is_running:
                 raise ForbiddenRepositoryAccessError(
                     "Unable to access repository during step execution. If you "
@@ -193,15 +215,14 @@
             profile: (internal use) custom configuration profile to use for the
                 repository. If not provided, the active profile is determined
                 from the loaded repository configuration. If no repository
                 configuration is found (i.e. repository root is not
                 initialized), the default global profile is used. Only used to
                 initialize new profiles internally.
         """
-
         self._root: Optional[Path] = None
         self._profile: Optional["ProfileConfiguration"] = None
         self.__config: Optional[RepositoryConfiguration] = None
 
         # The repository constructor is called with a custom profile only when
         # the profile needs to be initialized, in which case all matters related
         # to repository initialization, like the repository active root and the
@@ -248,16 +269,18 @@
 
         Args:
             root: The path to set as the active repository root. If not set,
                 the repository root is determined using the environment
                 variable `ZENML_REPOSITORY_PATH` (if set) and by recursively
                 searching in the parent directories of the current working
                 directory.
-        """
 
+        Raises:
+            RuntimeError: If no active configuration profile is found.
+        """
         self._root = self.find_repository(root, enable_warnings=True)
 
         global_cfg = GlobalConfiguration()
         new_profile = self._profile
 
         if not self._root:
             logger.info("Running without an active repository root.")
@@ -292,16 +315,15 @@
         # Sanitize the repository configuration to reflect the new active
         # profile
         self._sanitize_config()
 
     def _set_active_profile(
         self, profile: "ProfileConfiguration", new_profile: bool = False
     ) -> None:
-        """Set the supplied configuration profile as the active profile for
-        this repository.
+        """Set the supplied configuration profile as the active profile for this repository.
 
         This method initializes the repository store associated with the
         supplied profile and also initializes it with the default stack
         configuration, if no other stacks are configured.
 
         Args:
             profile: configuration profile to set as active.
@@ -333,16 +355,16 @@
 
         This method is called to ensure that the repository configuration
         doesn't contain outdated information, such as an active profile or an
         active stack that no longer exists.
 
         Raises:
             RuntimeError: If the repository configuration doesn't contain a
-            valid active stack and a new active stack cannot be automatically
-            determined based on the active profile and available stacks.
+                valid active stack and a new active stack cannot be automatically
+                determined based on the active profile and available stacks.
         """
         if not self.__config:
             return
 
         global_cfg = GlobalConfiguration()
 
         # Sanitize the repository active profile
@@ -393,16 +415,15 @@
             )
             self.__config.active_stack_name = backup_stack_name
 
     @staticmethod
     def _migrate_legacy_repository(
         config_file: str,
     ) -> Optional["ProfileConfiguration"]:
-        """Migrate a legacy repository configuration to the new format and
-        create a new Profile out of it.
+        """Migrate a legacy repository configuration to the new format and create a new Profile out of it.
 
         Args:
             config_file: Path to the legacy repository configuration file.
 
         Returns:
             The new Profile instance created for the legacy repository or None
             if a legacy repository configuration was not found at the supplied
@@ -462,31 +483,32 @@
             active_stack_name=legacy_config.active_stack_name,
         )
         GlobalConfiguration().add_or_update_profile(profile)
 
         return profile
 
     def _load_config(self) -> Optional[RepositoryConfiguration]:
-        """Loads the repository configuration from disk, if the repository has
-        an active root and the configuration file exists. If the configuration
-        file doesn't exist, an empty configuration is returned.
+        """Loads the repository configuration from disk.
+
+        This happens if the repository has an active root and the configuration
+        file exists. If the configuration file doesn't exist, an empty
+        configuration is returned.
 
         If a legacy repository configuration is found in the repository root,
         it is migrated to the new configuration format and a new profile is
         automatically created out of it and activated for the repository root.
 
         If the repository doesn't have an active root, no repository
         configuration is used and the active profile configuration takes
         precedence.
 
         Returns:
             Loaded repository configuration or None if the repository does not
             have an active root.
         """
-
         config_path = self._config_path()
         if not config_path:
             return None
 
         # load the repository configuration file if it exists, otherwise use
         # an empty configuration as default
         if fileio.exists(config_path):
@@ -503,15 +525,22 @@
                 "configuration."
             )
 
         return RepositoryConfiguration(config_path)
 
     @staticmethod
     def get_store_class(type: StoreType) -> Optional[Type["BaseZenStore"]]:
-        """Returns the class of the given store type."""
+        """Returns the class of the given store type.
+
+        Args:
+            type: The type of the store to get the class for.
+
+        Returns:
+            The class of the given store type or None if the type is unknown.
+        """
         from zenml.zen_stores import LocalZenStore, RestZenStore, SqlZenStore
 
         return {
             StoreType.LOCAL: LocalZenStore,
             StoreType.SQL: SqlZenStore,
             StoreType.REST: RestZenStore,
         }.get(type)
@@ -519,30 +548,34 @@
     @staticmethod
     def create_store(
         profile: "ProfileConfiguration",
         skip_default_registrations: bool = False,
         track_analytics: bool = True,
         skip_migration: bool = False,
     ) -> "BaseZenStore":
-        """Create the repository persistence back-end store from a configuration
-        profile.
+        """Create repository persistence back-end store from a configuration profile.
 
         If the configuration profile doesn't specify all necessary configuration
         options (e.g. the type or URL), a default configuration will be used.
 
         Args:
             profile: The configuration profile to use for persisting the
                 repository information.
             skip_default_registrations: If `True`, the creation of the default
                 stack and user in the store will be skipped.
             track_analytics: Only send analytics if set to `True`.
             skip_migration: If `True`, no store migration will be performed.
 
         Returns:
             The initialized repository store.
+
+        Raises:
+            RuntimeError: If the configuration is invalid.
+            ValueError: If the URL is invalid.
+
         """
         if not profile.store_type:
             raise RuntimeError(
                 f"Store type not configured in profile {profile.name}"
             )
 
         store_class = Repository.get_store_class(profile.store_type)
@@ -582,27 +615,28 @@
         root: Optional[Path] = None,
     ) -> None:
         """Initializes a new ZenML repository at the given path.
 
         Args:
             root: The root directory where the repository should be created.
                 If None, the current working directory is used.
+
         Raises:
             InitializationException: If the root directory already contains a
                 ZenML repository.
         """
         root = root or Path.cwd()
         logger.debug("Initializing new repository at path %s.", root)
         if Repository.is_repository_directory(root):
             raise InitializationException(
                 f"Found existing ZenML repository at path '{root}'."
             )
 
         config_directory = str(root / REPOSITORY_DIRECTORY_NAME)
-        utils.create_dir_recursive_if_not_exists(config_directory)
+        io_utils.create_dir_recursive_if_not_exists(config_directory)
         # Initialize the repository configuration at the custom path
         Repository(root=root)
 
     @property
     def root(self) -> Optional[Path]:
         """The root directory of this repository.
 
@@ -684,44 +718,42 @@
 
     @property
     def active_profile_name(self) -> str:
         """Return the name of the profile set as active for the repository.
 
         Returns:
             The active profile name.
-
-        Raises:
-            RuntimeError: If no profile is set as active.
         """
         return self.active_profile.name
 
     @property
     def active_user(self) -> "User":
         """The active user.
 
-        Raises:
-            KeyError: If no user exists for the active username.
+        Returns:
+            The active user.
         """
         return self.zen_store.get_user(self.active_user_name)
 
     @property
     def active_user_name(self) -> str:
         """Get the active user name set in the profile.
 
         Returns:
             The name of the active user.
-
-        Raises:
-            RuntimeError: If no profile is set as active, or no user configured.
         """
         return self.active_profile.active_user
 
     @property
     def stacks(self) -> List[Stack]:
-        """All stacks registered in this repository."""
+        """All stacks registered in this repository.
+
+        Returns:
+            A list of all stacks registered in this repository.
+        """
         return [s.to_stack() for s in self.zen_store.stacks]
 
     @property
     def stack_configurations(self) -> Dict[str, Dict[StackComponentType, str]]:
         """Configuration dicts for all stacks registered in this repository.
 
         This property is intended as a quick way to get information about the
@@ -729,39 +761,44 @@
         integrations. The contained stack configurations might be invalid if
         they were modified by hand, to ensure you get valid stacks use
         `repo.stacks()` instead.
 
         Modifying the contents of the returned dictionary does not actually
         register/deregister stacks, use `repo.register_stack(...)` or
         `repo.deregister_stack(...)` instead.
+
+        Returns:
+            A dictionary containing the configuration of all stacks registered
+            in this repository.
         """
         return self.zen_store.stack_configurations
 
     @property
     def active_stack(self) -> Stack:
         """The active stack for this repository.
 
-        Raises:
-            RuntimeError: If no active stack name is configured.
-            KeyError: If no stack was found for the configured name or one
-                of the stack components is not registered.
+        Returns:
+            The active stack for this repository.
         """
         return self.get_stack(name=self.active_stack_name)
 
     @property
     def active_stack_name(self) -> str:
         """The name of the active stack for this repository.
 
         If no active stack is configured for the repository, or if the
         repository does not have an active root, the active stack from the
         associated or global profile is used instead.
 
+        Returns:
+            The name of the active stack.
+
         Raises:
             RuntimeError: If no active stack name is set neither in the
-            repository configuration nor in the associated profile.
+                repository configuration nor in the associated profile.
         """
         stack_name = None
         if self.__config:
             stack_name = self.__config.active_stack_name
 
         if not stack_name:
             stack_name = self.active_profile.get_active_stack()
@@ -776,17 +813,14 @@
 
     @track(event=AnalyticsEvent.SET_STACK)
     def activate_stack(self, name: str) -> None:
         """Activates the stack for the given name.
 
         Args:
             name: Name of the stack to activate.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         self.zen_store.get_stack(name)  # raises KeyError
         if self.__config:
             self.__config.active_stack_name = name
 
         # set the active stack globally in the active profile only if the
         # repository doesn't have a root configured (i.e. repository root hasn't
@@ -796,49 +830,40 @@
 
     def get_stack(self, name: str) -> Stack:
         """Fetches a stack.
 
         Args:
             name: The name of the stack to fetch.
 
-        Raises:
-            KeyError: If no stack exists for the given name or one of the
-                stacks components is not registered.
+        Returns:
+            The stack with the given name.
         """
         return self.zen_store.get_stack(name).to_stack()
 
     def register_stack(self, stack: Stack) -> None:
         """Registers a stack and its components.
 
         If any of the stack's components aren't registered in the repository
         yet, this method will try to register them as well.
 
         Args:
             stack: The stack to register.
-
-        Raises:
-            StackExistsError: If a stack with the same name already exists.
-            StackComponentExistsError: If a component of the stack wasn't
-                registered and a different component with the same name
-                already exists.
         """
         from zenml.zen_stores.models import StackWrapper
 
         stack.validate()
         self.zen_store.register_stack(StackWrapper.from_stack(stack))
 
     def update_stack(self, name: str, stack: Stack) -> None:
         """Updates a stack and its components.
 
         Args:
             name: The original name of the stack.
             stack: The new stack to use as the updated version.
-
-        Raises:
-            KeyError: If no stack exists for the given name."""
+        """
         from zenml.zen_stores.models import StackWrapper
 
         stack.validate()
         self.zen_store.update_stack(name, StackWrapper.from_stack(stack))
         if self.active_stack_name == name:
             self.activate_stack(stack.name)
 
@@ -873,45 +898,50 @@
     ) -> None:
         """Updates a stack component.
 
         Args:
             name: The original name of the stack component.
             component_type: The type of the component to update.
             component: The new component to update with.
-
-        Raises:
-            KeyError: If no such stack component exists."""
+        """
         from zenml.zen_stores.models import ComponentWrapper
 
         self.zen_store.update_stack_component(
             name,
             component_type,
             ComponentWrapper.from_component(component),
         )
 
     def get_stack_components(
         self, component_type: StackComponentType
     ) -> List[StackComponent]:
-        """Fetches all registered stack components of the given type."""
+        """Fetches all registered stack components of the given type.
+
+        Args:
+            component_type: The type of the components to fetch.
+
+        Returns:
+            A list of all registered stack components of the given type.
+        """
         return [
             c.to_component()
             for c in self.zen_store.get_stack_components(component_type)
         ]
 
     def get_stack_component(
         self, component_type: StackComponentType, name: str
     ) -> StackComponent:
         """Fetches a registered stack component.
 
         Args:
             component_type: The type of the component to fetch.
             name: The name of the component to fetch.
 
-        Raises:
-            KeyError: If no stack component exists for the given type and name.
+        Returns:
+            The registered stack component.
         """
         logger.debug(
             "Fetching stack component of type '%s' with name '%s'.",
             component_type.value,
             name,
         )
         return self.zen_store.get_stack_component(
@@ -923,18 +953,14 @@
         self,
         component: StackComponent,
     ) -> None:
         """Registers a stack component.
 
         Args:
             component: The component to register.
-
-        Raises:
-            StackComponentExistsError: If a stack component with the same type
-                and name already exists.
         """
         from zenml.zen_stores.models import ComponentWrapper
 
         self.zen_store.register_stack_component(
             ComponentWrapper.from_component(component)
         )
         if component.post_registration_message:
@@ -991,15 +1017,15 @@
             self.__config.project_id = None
 
     @property
     def active_project(self) -> Optional["Project"]:
         """Get the currently active project of the local repository.
 
         Returns:
-             Project, if one is set that matches the id in the store.
+            Project, if one is set that matches the id in the store.
         """
         if not self.__config:
             return None
 
         project_name = self.__config.project_name
         if not project_name:
             return None
@@ -1027,15 +1053,14 @@
 
         Returns:
             A list of post-execution pipeline views.
 
         Raises:
             RuntimeError: If no stack name is specified and no active stack name
                 is configured.
-            KeyError: If no stack with the given name exists.
         """
         stack_name = stack_name or self.active_stack_name
         if not stack_name:
             raise RuntimeError(
                 "No active stack is configured for the repository. Run "
                 "`zenml stack set STACK_NAME` to update the active stack."
             )
@@ -1057,28 +1082,34 @@
         Returns:
             A post-execution pipeline view for the given name or `None` if
             it doesn't exist.
 
         Raises:
             RuntimeError: If no stack name is specified and no active stack name
                 is configured.
-            KeyError: If no stack with the given name exists.
         """
         stack_name = stack_name or self.active_stack_name
         if not stack_name:
             raise RuntimeError(
                 "No active stack is configured for the repository. Run "
                 "`zenml stack set STACK_NAME` to update the active stack."
             )
         metadata_store = self.get_stack(stack_name).metadata_store
         return metadata_store.get_pipeline(pipeline_name)
 
     @staticmethod
     def is_repository_directory(path: Path) -> bool:
-        """Checks whether a ZenML repository exists at the given path."""
+        """Checks whether a ZenML repository exists at the given path.
+
+        Args:
+            path: The path to check.
+
+        Returns:
+            True if a ZenML repository exists at the given path, False otherwise.
+        """
         config_dir = path / REPOSITORY_DIRECTORY_NAME
         return fileio.isdir(str(config_dir))
 
     @staticmethod
     def find_repository(
         path: Optional[Path] = None, enable_warnings: bool = False
     ) -> Optional[Path]:
@@ -1124,20 +1155,27 @@
                 f"want to use an existing repository which is in a different "
                 f"location, set the environment variable "
                 f"'{ENV_ZENML_REPOSITORY_PATH}'. If you want to create a new "
                 f"repository, run `zenml init`."
             )
 
         def _find_repo_helper(path_: Path) -> Optional[Path]:
-            """Helper function to recursively search parent directories for a
-            ZenML repository."""
+            """Helper function to recursively search parent directories for a ZenML repository.
+
+            Args:
+                path_: The path to search.
+
+            Returns:
+                Absolute path to a ZenML repository directory or None if no
+                repository directory was found.
+            """
             if Repository.is_repository_directory(path_):
                 return path_
 
-            if not search_parent_directories or utils.is_root(str(path_)):
+            if not search_parent_directories or io_utils.is_root(str(path_)):
                 return None
 
             return _find_repo_helper(path_.parent)
 
         repo_path = _find_repo_helper(path)
 
         if repo_path:
@@ -1151,14 +1189,17 @@
     ) -> Type[StackComponent]:
         """Fetches a registered flavor.
 
         Args:
             component_type: The type of the component to fetch.
             name: The name of the flavor to fetch.
 
+        Returns:
+            The registered flavor.
+
         Raises:
             KeyError: If no flavor exists for the given type and name.
         """
         logger.debug(
             "Fetching the flavor of type '%s' with name '%s'.",
             component_type.value,
             name,
```

### Comparing `zenml-0.8.1rc0/src/zenml/runtime_configuration.py` & `zenml-0.9.0/src/zenml/runtime_configuration.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Runtime configuration."""
+
 from typing import TYPE_CHECKING, Any, Dict, Optional, cast
 
 from zenml.logger import get_logger
 
 if TYPE_CHECKING:
     from zenml.pipelines import Schedule
 
@@ -50,16 +52,24 @@
         """
         runtime_options[RUN_NAME_OPTION_KEY] = run_name
         runtime_options[SCHEDULE_OPTION_KEY] = schedule
         super().__init__(runtime_options)
 
     @property
     def run_name(self) -> Optional[str]:
-        """Name of the pipeline run."""
+        """Name of the pipeline run.
+
+        Returns:
+            The name of the pipeline run.
+        """
         return cast(Optional[str], self[RUN_NAME_OPTION_KEY])
 
     @property
     def schedule(self) -> Optional["Schedule"]:
-        """Schedule of the pipeline run."""
+        """Schedule of the pipeline run.
+
+        Returns:
+            The schedule of the pipeline run.
+        """
         from zenml.pipelines import Schedule
 
         return cast(Optional[Schedule], self[SCHEDULE_OPTION_KEY])
```

### Comparing `zenml-0.8.1rc0/src/zenml/secret/__init__.py` & `zenml-0.9.0/src/zenml/secret/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of the ZenML Secret module.
+
 A ZenML Secret is a grouping of key-value pairs. These are accessed and
 administered via the ZenML Secret Manager (a stack component).
 
 Secrets are distinguished by having different schemas. An AWS SecretSchema, for
 example, has key-value pairs for `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`
 as well as an optional `AWS_SESSION_TOKEN`. If you don't specify a schema at the
 point of registration, ZenML will set the schema as `ArbitrarySecretSchema`, a
```

### Comparing `zenml-0.8.1rc0/src/zenml/secret/arbitrary_secret_schema.py` & `zenml-0.9.0/src/zenml/secret/arbitrary_secret_schema.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,35 +7,38 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a SecretSchema for arbitrary key:value pairs."""
+
 from typing import Any, ClassVar, Dict
 
 from pydantic import root_validator
 
 from zenml.secret.base_secret import BaseSecretSchema
 
 ARBITRARY_SECRET_SCHEMA_TYPE = "arbitrary"
 
 
 class ArbitrarySecretSchema(BaseSecretSchema):
-    """Schema for arbitrary collections of key value pairs with no
-    predefined schema."""
+    """Schema for arbitrary collections of key value pairs with no predefined schema."""
 
     TYPE: ClassVar[str] = ARBITRARY_SECRET_SCHEMA_TYPE
 
     arbitrary_kv_pairs: Dict[str, Any]
 
     @root_validator(pre=True)
     def build_arbitrary_kv_pairs(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        """Pydantic root_validator that takes all unused passed kwargs
-        and passes them into the arbitrary_kv_pairs attribute.
+        """Pydantic root_validator for the Secret Schemas.
+
+        It takes all unused passed kwargs and passes them into the
+        arbitrary_kv_pairs attribute.
 
         Args:
             values: Values passed to the object constructor
 
         Returns:
             Values passed to the object constructor
         """
```

### Comparing `zenml-0.8.1rc0/src/zenml/secret/base_secret.py` & `zenml-0.9.0/src/zenml/secret/base_secret.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,50 +7,56 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the Base SecretSchema class."""
+
 from abc import ABC
 from typing import Any, ClassVar, Dict, List
 
 from pydantic import BaseModel
 
 
 class BaseSecretSchema(BaseModel, ABC):
+    """Base class for all Secret Schemas."""
+
     name: str
     TYPE: ClassVar[str]
 
     @property
     def content(self) -> Dict[str, Any]:
-        """The concept of SecretSchemas supports strongly typed
-        secret schemas as well as arbitrary collections of key-value pairs.
-        This property unifies all attributes into a content dictionary.
+        """A dictionary for the content of the SecretSchema.
+
+        The concept of SecretSchemas supports strongly typed secret schemas as
+        well as arbitrary collections of key-value pairs. This property unifies
+        all attributes into a content dictionary.
 
         Returns:
             A dictionary containing the content of the SecretSchema.
         """
         fields_dict = self.dict(exclude_none=True)
         fields_dict.pop("name")
         if "arbitrary_kv_pairs" in fields_dict:
             arbitrary_kv_pairs = fields_dict.pop("arbitrary_kv_pairs")
             fields_dict.update(arbitrary_kv_pairs)
         return fields_dict
 
     @classmethod
     def get_schema_keys(cls) -> List[str]:
         """Get all attribute keys that are not part of the ignored set.
-        These schema keys can be used to define all
-        required key-value pairs of a secret schema
+
+        These schema keys can be used to define all required key-value pairs of
+        a secret schema.
 
         Returns:
             A list of all attribute keys that are not part of the ignored set.
         """
-
         ignored_keys = ["name", "arbitrary_kv_pairs"]
         return [
             schema_key
             for schema_key in cls.__fields__.keys()
             if schema_key not in ignored_keys
         ]
```

### Comparing `zenml-0.8.1rc0/src/zenml/secret/secret_schema_class_registry.py` & `zenml-0.9.0/src/zenml/secret/secret_schema_class_registry.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,20 +7,28 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML SecretSchema Class Registry."""
+
 from typing import ClassVar, Dict, Type, TypeVar
 
 from zenml.logger import get_logger
 from zenml.metadata_stores.mysql_secret_schema import MYSQLSecretSchema
 from zenml.secret import BaseSecretSchema
 from zenml.secret.arbitrary_secret_schema import ArbitrarySecretSchema
+from zenml.secret.schemas import (
+    AWSSecretSchema,
+    AzureSecretSchema,
+    BasicAuthSecretSchema,
+    GCPSecretSchema,
+)
 
 logger = get_logger(__name__)
 
 
 class SecretSchemaClassRegistry:
     """Registry for SecretSchema classes.
 
@@ -110,8 +118,12 @@
         The (unmodified) SecretSchema class to register.
     """
     SecretSchemaClassRegistry.register_class(secret=cls)
     return cls
 
 
 SecretSchemaClassRegistry.register_class(ArbitrarySecretSchema)
+SecretSchemaClassRegistry.register_class(AWSSecretSchema)
+SecretSchemaClassRegistry.register_class(AzureSecretSchema)
+SecretSchemaClassRegistry.register_class(BasicAuthSecretSchema)
+SecretSchemaClassRegistry.register_class(GCPSecretSchema)
 SecretSchemaClassRegistry.register_class(MYSQLSecretSchema)
```

### Comparing `zenml-0.8.1rc0/src/zenml/secrets_managers/__init__.py` & `zenml-0.9.0/src/zenml/artifacts/statistics_artifact.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,22 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-## Secret Manager
+"""Class for a statistics artifact."""
 
-...
-"""
-from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
-from zenml.secrets_managers.local.local_secrets_manager import (
-    LocalSecretsManager,
-)
+from zenml.artifacts.base_artifact import BaseArtifact
 
-__all__ = [
-    "BaseSecretsManager",
-    "LocalSecretsManager",
-]
+
+class StatisticsArtifact(BaseArtifact):
+    """Class for all ZenML statistics artifacts."""
+
+    TYPE_NAME = "StatisticsArtifact"
```

### Comparing `zenml-0.8.1rc0/src/zenml/secrets_managers/base_secrets_manager.py` & `zenml-0.9.0/src/zenml/secrets_managers/base_secrets_manager.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base class for ZenML secrets managers."""
+
 from abc import ABC, abstractmethod
 from typing import ClassVar, List
 
 from zenml.enums import StackComponentType
 from zenml.secret.base_secret import BaseSecretSchema
 from zenml.stack import StackComponent
```

### Comparing `zenml-0.8.1rc0/src/zenml/secrets_managers/local/__init__.py` & `zenml-0.9.0/src/zenml/integrations/slack/alerters/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
-#
+"""Alerter components defined by the Slack integration."""
+
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
-#       https://www.apache.org/licenses/LICENSE-2.0
+#       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+from zenml.integrations.slack.alerters.slack_alerter import SlackAlerter  # noqa
```

### Comparing `zenml-0.8.1rc0/src/zenml/secrets_managers/local/local_secrets_manager.py` & `zenml-0.9.0/src/zenml/secrets_managers/local/local_secrets_manager.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,51 +7,59 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML local secrets manager."""
+
 import os
 import uuid
 from pathlib import Path
 from typing import Any, ClassVar, Dict, List
 
 from pydantic import root_validator
 
 from zenml.cli.utils import error
 from zenml.constants import LOCAL_SECRETS_FILENAME, LOCAL_STORES_DIRECTORY_NAME
 from zenml.exceptions import SecretExistsError
 from zenml.io.fileio import remove
-from zenml.io.utils import (
-    create_file_if_not_exists,
-    get_global_config_directory,
-)
 from zenml.logger import get_logger
 from zenml.secret import SecretSchemaClassRegistry
 from zenml.secret.base_secret import BaseSecretSchema
 from zenml.secrets_managers.base_secrets_manager import BaseSecretsManager
+from zenml.secrets_managers.utils import decode_secret_dict, encode_secret
 from zenml.utils import yaml_utils
-from zenml.utils.secrets_manager_utils import decode_secret_dict, encode_secret
+from zenml.utils.io_utils import (
+    create_file_if_not_exists,
+    get_global_config_directory,
+)
 
 logger = get_logger(__name__)
 
 
 class LocalSecretsManager(BaseSecretsManager):
     """Class for ZenML local file-based secret manager."""
 
     secrets_file: str = ""
 
     # Class configuration
     FLAVOR: ClassVar[str] = "local"
 
     @root_validator(skip_on_failure=True)
     def set_secrets_file(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        """Sets the secrets_file attribute value according to the component
-        UUID."""
+        """Sets the secrets_file attribute value according to the component UUID.
+
+        Args:
+            values: The values to validate.
+
+        Returns:
+            The validated values.
+        """
         if values.get("secrets_file"):
             return values
 
         # not likely to happen, due to Pydantic validation, but mypy complains
         assert "uuid" in values
 
         values["secrets_file"] = cls.get_secret_store_path(values["uuid"])
@@ -61,58 +69,70 @@
     def get_secret_store_path(uuid: uuid.UUID) -> str:
         """Get the path to the secret store.
 
         Args:
             uuid: The UUID of the secret store.
 
         Returns:
-            The path to the secret store."""
+            The path to the secret store.
+        """
         return os.path.join(
             get_global_config_directory(),
             LOCAL_STORES_DIRECTORY_NAME,
             str(uuid),
             LOCAL_SECRETS_FILENAME,
         )
 
     @property
     def local_path(self) -> str:
-        """Path to the local directory where the secrets are stored."""
+        """Path to the local directory where the secrets are stored.
+
+        Returns:
+            The path to the local directory where the secrets are stored.
+        """
         return str(Path(self.secrets_file).parent)
 
     def _create_secrets_file__if_not_exists(self) -> None:
-        """Makes sure the secrets yaml file exists"""
+        """Makes sure the secrets yaml file exists."""
         create_file_if_not_exists(self.secrets_file)
 
     def _verify_secret_key_exists(self, secret_name: str) -> bool:
         """Checks if a secret key exists.
 
         Args:
             secret_name: The name of the secret key.
 
         Returns:
-            True if the secret key exists, False otherwise."""
+            True if the secret key exists, False otherwise.
+        """
         self._create_secrets_file__if_not_exists()
         secrets_store_items = yaml_utils.read_yaml(self.secrets_file)
         try:
             return secret_name in secrets_store_items
         except TypeError:
             return False
 
     def _get_all_secrets(self) -> Dict[str, Dict[str, str]]:
+        """Gets all secrets.
+
+        Returns:
+            A dictionary containing all secrets.
+        """
         self._create_secrets_file__if_not_exists()
         return yaml_utils.read_yaml(self.secrets_file) or {}
 
     def register_secret(self, secret: BaseSecretSchema) -> None:
         """Registers a new secret.
 
         Args:
             secret: The secret to register.
 
         Raises:
-            KeyError: If the secret already exists."""
+            SecretExistsError: If the secret already exists.
+        """
         self._create_secrets_file__if_not_exists()
 
         if self._verify_secret_key_exists(secret_name=secret.name):
             raise SecretExistsError(f"Secret `{secret.name}` already exists.")
         encoded_secret = encode_secret(secret)
 
         secrets_store_items = self._get_all_secrets()
@@ -125,15 +145,16 @@
         Args:
             secret_name: The name of the secret.
 
         Returns:
             The secret.
 
         Raises:
-            KeyError: If the secret does not exist."""
+            KeyError: If the secret does not exist.
+        """
         self._create_secrets_file__if_not_exists()
 
         secret_store_items = self._get_all_secrets()
         if not self._verify_secret_key_exists(secret_name=secret_name):
             raise KeyError(f"Secret `{secret_name}` does not exists.")
         secret_dict = secret_store_items[secret_name]
 
@@ -145,28 +166,30 @@
         )
         return secret_schema(**decoded_secret_dict)
 
     def get_all_secret_keys(self) -> List[str]:
         """Get all secret keys.
 
         Returns:
-            A list of all secret keys."""
+            A list of all secret keys.
+        """
         self._create_secrets_file__if_not_exists()
 
         secrets_store_items = self._get_all_secrets()
         return list(secrets_store_items.keys())
 
     def update_secret(self, secret: BaseSecretSchema) -> None:
         """Update an existing secret.
 
         Args:
             secret: The secret to update.
 
         Raises:
-            KeyError: If the secret does not exist."""
+            KeyError: If the secret does not exist.
+        """
         self._create_secrets_file__if_not_exists()
 
         if not self._verify_secret_key_exists(secret_name=secret.name):
             raise KeyError(f"Secret `{secret.name}` did not exist.")
         encoded_secret = encode_secret(secret)
 
         secrets_store_items = self._get_all_secrets()
@@ -176,15 +199,16 @@
     def delete_secret(self, secret_name: str) -> None:
         """Delete an existing secret.
 
         Args:
             secret_name: The name of the secret to delete.
 
         Raises:
-            KeyError: If the secret does not exist."""
+            KeyError: If the secret does not exist.
+        """
         self._create_secrets_file__if_not_exists()
 
         if not self._verify_secret_key_exists(secret_name=secret_name):
             raise KeyError(f"Secret `{secret_name}` does not exists.")
         secrets_store_items = self._get_all_secrets()
 
         try:
@@ -196,15 +220,16 @@
     def delete_all_secrets(self, force: bool = False) -> None:
         """Delete all existing secrets.
 
         Args:
             force: If True, delete all secrets.
 
         Raises:
-            ValueError: If force is False."""
+            ValueError: If force is False.
+        """
         self._create_secrets_file__if_not_exists()
 
         if not force:
             raise ValueError(
                 "This operation will delete all secrets. "
                 "To confirm, please pass `--yes`."
             )
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/__init__.py` & `zenml-0.9.0/src/zenml/services/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of the ZenML services module.
+
 A service is a process or set of processes that outlive a pipeline run.
 """
 
 from zenml.services.local.local_service import (
     LocalDaemonService,
     LocalDaemonServiceConfig,
     LocalDaemonServiceStatus,
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/local/local_daemon_entrypoint.py` & `zenml-0.9.0/src/zenml/services/local/local_daemon_entrypoint.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Implementation of a local daemon entrypoint.
+
 This executable file is utilized as an entrypoint for all ZenML services
 that are implemented as locally running daemon processes.
 """
 
 import os
 
 import click
@@ -28,23 +29,35 @@
 @click.option("--log-file", required=False, type=click.Path())
 @click.option("--pid-file", required=False, type=click.Path())
 def run(
     config_file: str,
     log_file: str,
     pid_file: str,
 ) -> None:
+    """Runs a ZenML service as a daemon process.
+
+    Args:
+        config_file: path to the configuration file for the service.
+        log_file: path to the log file for the service.
+        pid_file: path to the PID file for the service.
+    """
+
     @daemonize(
         log_file=log_file, pid_file=pid_file, working_directory=os.getcwd()
     )
     def launch_service(service_config_file: str) -> None:
-        """Instantiate and launch a ZenML local service from its
-        configuration file.
-        """
+        """Instantiate and launch a ZenML local service from its configuration file.
+
+        Args:
+            service_config_file: the path to the service configuration file.
 
-        # doing zenml imports here to avoid polluting the stdout/sterr
+        Raises:
+            TypeError: if the service configuration file is the wrong type.
+        """
+        # doing zenml imports here to avoid polluting the stdout/stderr
         # with messages before daemonization is complete
         from zenml.integrations.registry import integration_registry
         from zenml.logger import get_logger
         from zenml.services import LocalDaemonService, ServiceRegistry
 
         logger = get_logger(__name__)
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/local/local_service.py` & `zenml-0.9.0/src/zenml/services/local/local_service.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,34 +7,35 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a local ZenML service."""
 
 import os
 import pathlib
 import subprocess
 import sys
 import tempfile
 import time
 from abc import abstractmethod
 from typing import Dict, Generator, List, Optional, Tuple
 
 import psutil
 from pydantic import Field
 
-from zenml.io.utils import create_dir_recursive_if_not_exists
 from zenml.logger import get_logger
 from zenml.services.local.local_service_endpoint import (
     LocalDaemonServiceEndpoint,
 )
 from zenml.services.service import BaseService, ServiceConfig
 from zenml.services.service_status import ServiceState, ServiceStatus
+from zenml.utils.io_utils import create_dir_recursive_if_not_exists
 
 logger = get_logger(__name__)
 
 
 SERVICE_DAEMON_CONFIG_FILE_NAME = "service.json"
 SERVICE_DAEMON_LOG_FILE_NAME = "service.log"
 SERVICE_DAEMON_PID_FILE_NAME = "service.pid"
@@ -75,54 +76,58 @@
     # TODO [ENG-704]: remove field duplication between XServiceStatus and
     #   XServiceConfig (e.g. keep a private reference to the config in the
     #   status)
     silent_daemon: bool = False
 
     @property
     def config_file(self) -> Optional[str]:
-        """Get the path to the configuration file used to start the service
-        daemon.
+        """Get the path to the configuration file used to start the service daemon.
 
         Returns:
             The path to the configuration file, or None, if the
             service has never been started before.
         """
         if not self.runtime_path:
             return None
         return os.path.join(self.runtime_path, SERVICE_DAEMON_CONFIG_FILE_NAME)
 
     @property
     def log_file(self) -> Optional[str]:
-        """Get the path to the log file where the service output is/has been
-        logged.
+        """Get the path to the log file where the service output is/has been logged.
 
         Returns:
             The path to the log file, or None, if the service has never been
             started before, or if the service daemon output is suppressed.
         """
         if not self.runtime_path or self.silent_daemon:
             return None
         return os.path.join(self.runtime_path, SERVICE_DAEMON_LOG_FILE_NAME)
 
     @property
     def pid_file(self) -> Optional[str]:
-        """Get the path to the daemon PID file where the last known PID of the
-        daemon process is stored.
+        """Get the path to a daemon PID file.
+
+        This is where the last known PID of the daemon process is stored.
 
         Returns:
             The path to the PID file, or None, if the service has never been
             started before.
         """
         if not self.runtime_path or self.silent_daemon:
             return None
         return os.path.join(self.runtime_path, SERVICE_DAEMON_PID_FILE_NAME)
 
     @property
     def pid(self) -> Optional[int]:
-        """Return the PID of the currently running daemon"""
+        """Return the PID of the currently running daemon.
+
+        Returns:
+            The PID of the daemon, or None, if the service has never been
+            started before.
+        """
         pid_file = self.pid_file
         if not pid_file:
             return None
         if sys.platform == "win32":
             logger.warning(
                 "Daemon functionality is currently not supported on Windows."
             )
@@ -209,16 +214,20 @@
     status: LocalDaemonServiceStatus = Field(
         default_factory=LocalDaemonServiceStatus
     )
     # TODO [ENG-705]: allow multiple endpoints per service
     endpoint: Optional[LocalDaemonServiceEndpoint] = None
 
     def get_service_status_message(self) -> str:
-        """Get a message providing information about the current operational
-        state of the service."""
+        """Get a message about the current operational state of the service.
+
+        Returns:
+            A message providing information about the current operational
+            state of the service.
+        """
         msg = super().get_service_status_message()
         pid = self.status.pid
         if pid:
             msg += f"  Daemon PID: `{self.status.pid}`\n"
         if self.status.log_file:
             msg += (
                 f"For more information on the service status, please see the "
@@ -230,15 +239,14 @@
         """Check the the current operational state of the daemon process.
 
         Returns:
             The operational state of the daemon process and a message
             providing additional information about that state (e.g. a
             description of the error, if one is encountered).
         """
-
         if not self.status.pid:
             return ServiceState.INACTIVE, "service daemon is not running"
 
         # the daemon is running
         return ServiceState.ACTIVE, ""
 
     def _get_daemon_cmd(self) -> Tuple[List[str], Dict[str, str]]:
@@ -311,15 +319,14 @@
 
         command_env = os.environ.copy()
 
         return command, command_env
 
     def _start_daemon(self) -> None:
         """Start the service daemon process associated with this service."""
-
         pid = self.status.pid
         if pid:
             # service daemon is already running
             logger.debug(
                 "Daemon process for service '%s' is already running with PID %d",
                 self,
                 pid,
@@ -354,15 +361,14 @@
 
     def _stop_daemon(self, force: bool = False) -> None:
         """Stop the service daemon process associated with this service.
 
         Args:
             force: if True, the service daemon will be forcefully stopped
         """
-
         pid = self.status.pid
         if not pid:
             # service daemon is not running
             logger.debug(
                 "Daemon process for service '%s' no longer running",
                 self,
             )
@@ -378,30 +384,36 @@
             return
         if force:
             p.kill()
         else:
             p.terminate()
 
     def provision(self) -> None:
+        """Provision the service."""
         self._start_daemon()
 
     def deprovision(self, force: bool = False) -> None:
+        """Deprovision the service.
+
+        Args:
+            force: if True, the service daemon will be forcefully stopped
+        """
         self._stop_daemon(force)
 
     def get_logs(
         self, follow: bool = False, tail: Optional[int] = None
     ) -> Generator[str, bool, None]:
         """Retrieve the service logs.
 
         Args:
             follow: if True, the logs will be streamed as they are written
             tail: only retrieve the last NUM lines of log output.
 
-        Returns:
-            A generator that can be acccessed to get the service logs.
+        Yields:
+            A generator that can be accessed to get the service logs.
         """
         if not self.status.log_file or not os.path.exists(self.status.log_file):
             return
 
         with open(self.status.log_file, "r") as f:
             if tail:
                 # TODO[ENG-864]: implement a more efficient tailing mechanism that
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/local/local_service_endpoint.py` & `zenml-0.9.0/src/zenml/services/local/local_service_endpoint.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-
+"""Implementation of a local service endpoint."""
 
 from typing import Optional, Union
 
 from pydantic import Field
 
 from zenml.constants import DEFAULT_LOCAL_SERVICE_IP_ADDRESS
 from zenml.logger import get_logger
@@ -98,15 +98,14 @@
             An available TCP port number
 
         Raises:
             IOError: if the preferred TCP port is busy and `allocate_port` is
                 disabled in the endpoint configuration, or if no free TCP port
                 could be otherwise allocated.
         """
-
         # If a port value is explicitly configured, attempt to use it first
         if self.config.port:
             if port_available(self.config.port):
                 return self.config.port
             if not self.config.allocate_port:
                 raise IOError(f"TCP port {self.config.port} is not available.")
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service.py` & `zenml-0.9.0/src/zenml/services/service.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML Service class."""
 
 import time
 from abc import abstractmethod
 from typing import Any, ClassVar, Dict, Generator, Optional, Tuple, Type, cast
 from uuid import UUID, uuid4
 
 from pydantic import Field
@@ -49,32 +50,42 @@
     description: str = ""
     pipeline_name: str = ""
     pipeline_run_id: str = ""
     pipeline_step_name: str = ""
 
 
 class BaseServiceMeta(BaseTypedModelMeta):
-    """Metaclass responsible for registering different BaseService
-    subclasses.
+    """Metaclass responsible for registering different BaseService subclasses.
 
     This metaclass has two main responsibilities:
     1. register all BaseService types in the service registry. This is relevant
     when services are deserialized and instantiated from their JSON or dict
     representation, because their type needs to be known beforehand.
     2. ensuring BaseService instance uniqueness by enforcing that no two
     service instances have the same UUID value. Implementing this at the
     constructor level guarantees that deserializing a service instance from
     a JSON representation multiple times always returns the same service object.
     """
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "BaseServiceMeta":
-        """Creates a BaseService class and registers it in
-        the `ServiceRegistry`."""
+        """Creates a BaseService class and registers it in the `ServiceRegistry`.
+
+        Args:
+            name: name of the class.
+            bases: tuple of base classes.
+            dct: dictionary of class attributes.
+
+        Returns:
+            the created BaseServiceMeta class.
+
+        Raises:
+            TypeError: if the 'service_type' reserved attribute name is used.
+        """
         service_type = dct.get("SERVICE_TYPE", None)
 
         # register only classes of concrete service implementations
         if service_type:
             # add the service type class attribute to the class as a regular
             # immutable attribute to include it in the JSON representation
             if "service_type" in dct:
@@ -92,15 +103,27 @@
         # register only classes of concrete service implementations
         if service_type:
             # register the service type in the service registry
             ServiceRegistry().register_service_type(cls)
         return cls
 
     def __call__(cls, *args: Any, **kwargs: Any) -> "BaseServiceMeta":
-        """Validate the creation of a service."""
+        """Validate the creation of a service.
+
+        Args:
+            *args: positional arguments.
+            **kwargs: keyword arguments.
+
+        Returns:
+            the created BaseServiceMeta class.
+
+        Raises:
+            AttributeError: if the service UUID is untyped.
+            ValueError: if the service UUID is not a UUID type.
+        """
         if not getattr(cls, "SERVICE_TYPE", None):
             raise AttributeError(
                 f"Untyped service instances are not allowed. Please set the "
                 f"SERVICE_TYPE class attribute for {cls}."
             )
         uuid = kwargs.get("uuid", None)
         if uuid:
@@ -124,15 +147,15 @@
 
         svc = cast("BaseService", super().__call__(*args, **kwargs))
         ServiceRegistry().register_service(svc)
         return cast("BaseServiceMeta", svc)
 
 
 class BaseService(BaseTypedModel, metaclass=BaseServiceMeta):
-    """Base service class
+    """Base service class.
 
     This class implements generic functionality concerning the life-cycle
     management and tracking of an external service (e.g. process, container,
     Kubernetes deployment etc.).
 
     Attributes:
         SERVICE_TYPE: a service type descriptor with information describing
@@ -153,14 +176,19 @@
     # TODO [ENG-703]: allow multiple endpoints per service
     endpoint: Optional[BaseServiceEndpoint]
 
     def __init__(
         self,
         **attrs: Any,
     ) -> None:
+        """Initialize the service instance.
+
+        Args:
+            **attrs: keyword arguments.
+        """
         super().__init__(**attrs)
         self.config.name = self.config.name or self.__class__.__name__
 
     @abstractmethod
     def check_status(self) -> Tuple[ServiceState, str]:
         """Check the the current operational state of the external service.
 
@@ -184,19 +212,21 @@
         concrete service tracking functionality.
 
         Args:
             follow: if True, the logs will be streamed as they are written
             tail: only retrieve the last NUM lines of log output.
 
         Returns:
-            A generator that can be acccessed to get the service logs.
+            A generator that can be accessed to get the service logs.
         """
 
     def update_status(self) -> None:
-        """Check the current operational state of the external service
+        """Update the service of the service.
+
+        Check the current operational state of the external service
         and update the local operational status information to reflect it.
 
         This method should be overridden by subclasses that implement
         concrete service status tracking functionality.
         """
         logger.debug(
             "Running status check for service '%s' ...",
@@ -215,30 +245,36 @@
         if self.status.state == ServiceState.INACTIVE:
             return
 
         if self.endpoint:
             self.endpoint.update_status()
 
     def get_service_status_message(self) -> str:
-        """Get a message providing information about the current operational
-        state of the service."""
+        """Get a service status message.
+
+        Returns:
+            A message providing information about the current operational
+            state of the service.
+        """
         return (
             f"  Administrative state: `{self.admin_state.value}`\n"
             f"  Operational state: `{self.status.state.value}`\n"
             f"  Last status message: '{self.status.last_error}'\n"
         )
 
     def poll_service_status(self, timeout: int = 0) -> bool:
-        """Poll the external service status until the service operational
-        state matches the administrative state, the service enters a failed
-        state, or the timeout is reached.
+        """Polls the external service status.
+
+        It does this until the service operational state matches the
+        administrative state, the service enters a failed state, or the timeout
+        is reached.
 
         Args:
             timeout: maximum time to wait for the service operational state
-            to match the administrative state, in seconds
+                to match the administrative state, in seconds
 
         Returns:
             True if the service operational state matches the administrative
             state, False otherwise.
         """
         time_remaining = timeout
         while True:
@@ -301,21 +337,34 @@
         Returns:
             True if the service is in a failure state, otherwise False.
         """
         self.update_status()
         return self.status.state == ServiceState.ERROR
 
     def provision(self) -> None:
-        """Provisions resources to run the service."""
+        """Provisions resources to run the service.
+
+        Raises:
+            NotImplementedError: if the service does not implement provisioning functionality
+        """
         raise NotImplementedError(
             f"Provisioning resources not implemented for {self}."
         )
 
     def deprovision(self, force: bool = False) -> None:
-        """Deprovisions all resources used by the service."""
+        """Deprovisions all resources used by the service.
+
+        Args:
+            force: if True, the service will be deprovisioned even if it is
+                in a failed state.
+
+        Raises:
+            NotImplementedError: if the service does not implement
+                deprovisioning functionality.
+        """
         raise NotImplementedError(
             f"Deprovisioning resources not implemented for {self}."
         )
 
     def update(self, config: ServiceConfig) -> None:
         """Update the service configuration.
 
@@ -348,14 +397,16 @@
     def stop(self, timeout: int = 0, force: bool = False) -> None:
         """Stop the service and optionally wait for it to shutdown.
 
         Args:
             timeout: amount of time to wait for the service to shutdown.
                 If set to 0, the method will return immediately after checking
                 the service status.
+            force: if True, the service will be stopped even if it is not
+                currently running.
 
         Raises:
             RuntimeError: if the service cannot be stopped
         """
         with console.status(f"Stopping service '{self}'.\n"):
             self.admin_state = ServiceState.INACTIVE
             self.deprovision(force)
@@ -365,19 +416,27 @@
                     raise RuntimeError(
                         f"Failed to stop service {self}. Last state: "
                         f"'{self.status.state.value}'. Last error: "
                         f"'{self.status.last_error}'"
                     )
 
     def __repr__(self) -> str:
-        """String representation of the service."""
+        """String representation of the service.
+
+        Returns:
+            A string representation of the service.
+        """
         return f"{self.__class__.__qualname__}[{self.uuid}] (type: {self.SERVICE_TYPE.type}, flavor: {self.SERVICE_TYPE.flavor})"
 
     def __str__(self) -> str:
-        """String representation of the service."""
+        """String representation of the service.
+
+        Returns:
+            A string representation of the service.
+        """
         return self.__repr__()
 
     class Config:
         """Pydantic configuration class."""
 
         # validate attribute assignments
         validate_assignment = True
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service_endpoint.py` & `zenml-0.9.0/src/zenml/services/service_endpoint.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a ZenML service endpoint."""
 
 from typing import Any, Optional, Tuple
 
 from zenml.logger import get_logger
 from zenml.services.service_monitor import BaseServiceEndpointHealthMonitor
 from zenml.services.service_status import ServiceState, ServiceStatus
 from zenml.utils.enum_utils import StrEnum
@@ -44,20 +45,20 @@
     """
 
     name: str = ""
     description: str = ""
 
 
 class ServiceEndpointStatus(ServiceStatus):
-    """Status information describing the operational state of a service
-    endpoint (e.g. a HTTP/HTTPS API or generic TCP endpoint exposed by a
-    service).
+    """Status information describing the operational state of a service endpoint.
 
-    Concrete service classes should extend this class and add additional
-    attributes that make up the operational state of the service endpoint.
+    For example, this could be a HTTP/HTTPS API or generic TCP endpoint exposed
+    by a service. Concrete service classes should extend this class and add
+    additional attributes that make up the operational state of the service
+    endpoint.
 
     Attributes:
         protocol: the TCP protocol used by the service endpoint
         hostname: the hostname where the service endpoint is accessible
         port: the current TCP port where the service endpoint is accessible
     """
 
@@ -78,15 +79,15 @@
             # port and protocol are known
             return None
 
         return f"{self.protocol.value}://{self.hostname}:{self.port}/"
 
 
 class BaseServiceEndpoint(BaseTypedModel):
-    """Base service class
+    """Base service class.
 
     This class implements generic functionality concerning the life-cycle
     management and tracking of an external service endpoint (e.g. a HTTP/HTTPS
     API or generic TCP endpoint exposed by a service).
 
     Attributes:
         admin_state: the administrative state of the service endpoint
@@ -102,37 +103,42 @@
     monitor: Optional[BaseServiceEndpointHealthMonitor] = None
 
     def __init__(
         self,
         *args: Any,
         **kwargs: Any,
     ) -> None:
+        """Initialize the service endpoint.
+
+        Args:
+            *args: positional arguments.
+            **kwargs: keyword arguments.
+        """
         super().__init__(*args, **kwargs)
         self.config.name = self.config.name or self.__class__.__name__
 
     def check_status(self) -> Tuple[ServiceState, str]:
-        """Check the the current operational state of the external
-        service endpoint.
+        """Check the the current operational state of the external service endpoint.
 
         Returns:
             The operational state of the external service endpoint and a
             message providing additional information about that state
             (e.g. a description of the error, if one is encountered while
             checking the service status).
         """
         if not self.monitor:
             # no health monitor configured; assume service operational state
             # always matches the admin state
             return self.admin_state, ""
         return self.monitor.check_endpoint_status(self)
 
     def update_status(self) -> None:
-        """Check the the current operational state of the external service
-        endpoint and update the local operational status information
-        accordingly.
+        """Check the the current operational state of the external service endpoint.
+
+        It updates the local operational status information accordingly.
         """
         logger.debug(
             "Running health check for service endpoint '%s' ...",
             self.config.name,
         )
         state, err = self.check_status()
         logger.debug(
@@ -140,31 +146,31 @@
             self.config.name,
             state.name,
             err,
         )
         self.status.update_state(state, err)
 
     def is_active(self) -> bool:
-        """Check if the service endpoint is active (i.e. is responsive and can
-        receive requests).
+        """Check if the service endpoint is active.
 
-        This method will use the configured health monitor to actively check the
-        endpoint status and will return the result.
+        This means that it is responsive and can receive requests). This method
+        will use the configured health monitor to actively check the endpoint
+        status and will return the result.
 
         Returns:
             True if the service endpoint is active, otherwise False.
         """
         self.update_status()
         return self.status.state == ServiceState.ACTIVE
 
     def is_inactive(self) -> bool:
-        """Check if the service endpoint is inactive (i.e. is not responsive and
-        cannot receive requests).
+        """Check if the service endpoint is inactive.
 
-        This method will use the configured health monitor to actively check the
+        This means that it is unresponsive and cannot receive requests. This
+        method will use the configured health monitor to actively check the
         endpoint status and will return the result.
 
         Returns:
             True if the service endpoint is inactive, otherwise False.
         """
         self.update_status()
         return self.status.state == ServiceState.INACTIVE
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service_monitor.py` & `zenml-0.9.0/src/zenml/services/service_monitor.py`

 * *Files 13% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the service health monitor."""
 
 from abc import abstractmethod
 from typing import TYPE_CHECKING, Optional, Tuple
 
 import requests
 from pydantic import Field
 
@@ -53,16 +54,18 @@
         default_factory=ServiceEndpointHealthMonitorConfig
     )
 
     @abstractmethod
     def check_endpoint_status(
         self, endpoint: "BaseServiceEndpoint"
     ) -> Tuple[ServiceState, str]:
-        """Check the the current operational state of the external
-        service endpoint.
+        """Check the the current operational state of the external service endpoint.
+
+        Args:
+            endpoint: service endpoint to check
 
         This method should be overridden by subclasses that implement
         concrete service endpoint tracking functionality.
 
         Returns:
             The operational state of the external service endpoint and an
             optional error message, if an error is encountered while checking
@@ -100,37 +103,52 @@
     config: HTTPEndpointHealthMonitorConfig = Field(
         default_factory=HTTPEndpointHealthMonitorConfig
     )
 
     def get_healthcheck_uri(
         self, endpoint: "BaseServiceEndpoint"
     ) -> Optional[str]:
+        """Get the healthcheck URI for the given service endpoint.
+
+        Args:
+            endpoint: service endpoint to get the healthcheck URI for
+
+        Returns:
+            The healthcheck URI for the given service endpoint or None, if
+            the service endpoint doesn't have a healthcheck URI.
+        """
         uri = endpoint.status.uri
         if not uri:
             return None
         return f"{uri}{self.config.healthcheck_uri_path}"
 
     def check_endpoint_status(
         self, endpoint: "BaseServiceEndpoint"
     ) -> Tuple[ServiceState, str]:
-        """Run a HTTP endpoint API healthcheck
+        """Run a HTTP endpoint API healthcheck.
+
+        Args:
+            endpoint: service endpoint to check.
 
         Returns:
             The operational state of the external HTTP endpoint and an
             optional message describing that state (e.g. an error message,
             if an error is encountered while checking the HTTP endpoint
             status).
         """
         from zenml.services.service_endpoint import ServiceEndpointProtocol
 
         if endpoint.status.protocol not in [
             ServiceEndpointProtocol.HTTP,
             ServiceEndpointProtocol.HTTPS,
         ]:
-            return ServiceState.ERROR, "endpoint protocol is not HTTP nor HTTPS"
+            return (
+                ServiceState.ERROR,
+                "endpoint protocol is not HTTP nor HTTPS.",
+            )
 
         check_uri = self.get_healthcheck_uri(endpoint)
         if not check_uri:
             return ServiceState.ERROR, "no HTTP healthcheck URI available"
 
         logger.debug("Running HTTP healthcheck for URI: %s", check_uri)
 
@@ -174,15 +192,18 @@
     """
 
     config: TCPEndpointHealthMonitorConfig
 
     def check_endpoint_status(
         self, endpoint: "BaseServiceEndpoint"
     ) -> Tuple[ServiceState, str]:
-        """Run a TCP endpoint healthcheck
+        """Run a TCP endpoint healthcheck.
+
+        Args:
+            endpoint: service endpoint to check.
 
         Returns:
             The operational state of the external TCP endpoint and an
             optional message describing that state (e.g. an error message,
             if an error is encountered while checking the TCP endpoint
             status).
         """
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service_registry.py` & `zenml-0.9.0/src/zenml/services/service_registry.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML service registry."""
 
 import json
 from typing import TYPE_CHECKING, Any, Dict, Optional, Type, cast
 from uuid import UUID
 
 from zenml.logger import get_logger
 from zenml.services.service_type import ServiceType
@@ -30,22 +31,24 @@
     """Registry of service types and service instances.
 
     The service registry provides a central place to register service types
     as well as service instances.
     """
 
     def __init__(self) -> None:
+        """Initialize the service registry."""
         self.service_types: Dict[ServiceType, Type["BaseService"]] = {}
         self.services: Dict[UUID, "BaseService"] = {}
 
     def register_service_type(self, cls: Type["BaseService"]) -> None:
         """Registers a new service type.
 
         Args:
             cls: a BaseService subclass.
+
         Raises:
             TypeError: if the service type is already registered.
         """
         service_type = cls.SERVICE_TYPE
         if service_type not in self.service_types:
             self.service_types[service_type] = cls
             logger.debug(
@@ -72,29 +75,43 @@
             None, if no service class was registered for the service type.
         """
         return self.service_types.get(service_type)
 
     def get_service_types(
         self,
     ) -> Dict[ServiceType, Type["BaseService"]]:
-        """Get all registered service types."""
+        """Get all registered service types.
+
+        Returns:
+            Dictionary of service types indexed by their service type.
+        """
         return self.service_types.copy()
 
     def service_type_is_registered(self, service_type: ServiceType) -> bool:
-        """Check if a service type is registered."""
+        """Check if a service type is registered.
+
+        Args:
+            service_type: service type.
+
+        Returns:
+            True, if a service type is registered for the service type, False
+            otherwise.
+        """
         return service_type in self.service_types
 
     def register_service(self, service: "BaseService") -> None:
-        """Registers a new service instance
+        """Registers a new service instance.
 
         Args:
             service: a BaseService instance.
+
         Raises:
             TypeError: if the service instance has a service type that is not
                 registered.
+            Exception: if a preexisting service is found for that UUID.
         """
         service_type = service.SERVICE_TYPE
         if service_type not in self.service_types:
             raise TypeError(f"Service type `{service_type}` is not registered.")
 
         if service.uuid not in self.services:
             self.services[service.uuid] = service
@@ -107,15 +124,15 @@
                 f"{service}."
             )
 
     def get_service(self, uuid: UUID) -> Optional["BaseService"]:
         """Get the service instance registered for a UUID.
 
         Args:
-            UUID: service instance identifier.
+            uuid: service instance identifier.
 
         Returns:
             `BaseService` instance that was registered for the UUID or
             None, if no matching service instance was found.
         """
         return self.services.get(uuid)
 
@@ -125,15 +142,23 @@
         Returns:
             Dictionary of `BaseService` instances indexed by their UUID with
             all services that are currently registered.
         """
         return self.services.copy()
 
     def service_is_registered(self, uuid: UUID) -> bool:
-        """Check if a service instance is registered."""
+        """Check if a service instance is registered.
+
+        Args:
+            uuid: service instance identifier.
+
+        Returns:
+            True, if a service instance is registered for the UUID, False
+            otherwise.
+        """
         return uuid in self.services
 
     def load_service_from_dict(
         self, service_dict: Dict[str, Any]
     ) -> "BaseService":
         """Load a service instance from its dict representation.
 
@@ -146,14 +171,18 @@
 
         Args:
             service_dict: dict representation of the service configuration and
                 last known status
 
         Returns:
             A new or existing ZenML service instance.
+
+        Raises:
+            TypeError: if the service type is not registered.
+            ValueError: if the service type is not valid.
         """
         service_type = service_dict.get("service_type")
         if not service_type:
             raise ValueError(
                 "Service type not present in the service dictionary"
             )
         service_type = ServiceType.parse_obj(service_type)
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service_status.py` & `zenml-0.9.0/src/zenml/services/service_status.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ServiceStatus class."""
 
 from typing import Optional
 
 from zenml.logger import get_logger
 from zenml.utils.enum_utils import StrEnum
 from zenml.utils.typed_model import BaseTypedModel
 
@@ -28,17 +29,19 @@
     PENDING_STARTUP = "pending_startup"
     INACTIVE = "inactive"
     PENDING_SHUTDOWN = "pending_shutdown"
     ERROR = "error"
 
 
 class ServiceStatus(BaseTypedModel):
-    """Information describing the operational status of an external process
-    or service tracked by ZenML (e.g. process, container, Kubernetes
-    deployment etc.).
+    """Information about the status of a service or process.
+
+    This information describes the operational status of an external process or
+    service tracked by ZenML. This could be a process, container, Kubernetes
+    deployment etc.
 
     Concrete service classes should extend this class and add additional
     attributes that make up the operational state of the service.
 
     Attributes:
         state: the current operational state
         last_state: the operational state prior to the last status update
@@ -50,16 +53,15 @@
     last_error: str = ""
 
     def update_state(
         self,
         new_state: Optional[ServiceState] = None,
         error: str = "",
     ) -> None:
-        """Update the current operational state to reflect a new state
-        value and/or error.
+        """Update the current operational state to reflect a new state value and/or error.
 
         Args:
             new_state: new operational state discovered by the last service
                 status update
             error: error message describing an operational failure encountered
                 during the last service status update
         """
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/service_type.py` & `zenml-0.9.0/src/zenml/services/service_type.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of a ZenML ServiceType class."""
 
 from pydantic import BaseModel
 
 
 class ServiceType(BaseModel):
     """Service type descriptor.
```

### Comparing `zenml-0.8.1rc0/src/zenml/services/utils.py` & `zenml-0.9.0/src/zenml/services/utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,30 +7,30 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utils for the ZenML service module."""
 
 from typing import Optional
 
 from zenml.repository import Repository
 from zenml.services.service import BaseService
 from zenml.steps.step_context import StepContext
 
 
 def load_last_service_from_step(
     pipeline_name: str,
     step_name: str,
     step_context: Optional[StepContext] = None,
     running: bool = False,
 ) -> Optional[BaseService]:
-    """Get the last service created by the pipeline and step with the given
-    names.
+    """Get the last service created by the pipeline and step with the given names.
 
     This function searches backwards through the execution history for a
     named pipeline step and returns the first service instance that it finds
     logged as a step output.
 
     Args:
         pipeline_name: the name of the pipeline
@@ -41,14 +41,15 @@
 
     Returns:
         A BaseService instance that represents the service or None if no service
         was created during the last execution of the pipeline step.
 
     Raises:
         KeyError: if the pipeline or step name is not found in the execution.
+        RuntimeError: if the artifact is not a service.
     """
     if step_context is None:
         repo = Repository()
         pipeline = repo.get_pipeline(pipeline_name)
     else:
         pipeline = step_context.metadata_store.get_pipeline(
             pipeline_name=pipeline_name
```

### Comparing `zenml-0.8.1rc0/src/zenml/stack/__init__.py` & `zenml-0.9.0/src/zenml/stack/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,16 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-The stack is essentially all the configuration for the infrastructure of your 
+"""Initialization of the ZenML Stack.
+
+The stack is essentially all the configuration for the infrastructure of your
 MLOps platform.
 
 A stack is made up of multiple components. Some examples are:
 
 - An Artifact Store
 - A Metadata Store
 - An Orchestrator
```

### Comparing `zenml-0.8.1rc0/src/zenml/stack/flavor_registry.py` & `zenml-0.9.0/src/zenml/stack/flavor_registry.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML flavor registry."""
+
 from collections import defaultdict
 from typing import DefaultDict, Dict
 
 from zenml.enums import StackComponentType
 from zenml.logger import get_logger
 from zenml.zen_stores.models import FlavorWrapper
 
@@ -87,15 +89,22 @@
                 for flavor in integrated_flavors:
                     self._register_flavor(flavor)
 
     def _register_flavor(
         self,
         flavor: FlavorWrapper,
     ) -> None:
-        """Registers a stack component flavor."""
+        """Registers a stack component flavor.
+
+        Args:
+            flavor: The flavor to register.
+
+        Raises:
+            KeyError: If the flavor is already registered.
+        """
         flavors = self._flavors[flavor.type]
 
         if flavor.name in flavors:
             raise KeyError(
                 f"There is already a {flavor.type} with the flavor "
                 f"`{flavor.name}`. Please select another name for the flavor."
             )
@@ -104,13 +113,20 @@
         logger.debug(
             f"Registered flavor for '{flavor.name}' and type '{flavor.type}'.",
         )
 
     def get_flavors_by_type(
         self, component_type: StackComponentType
     ) -> Dict[str, FlavorWrapper]:
-        """Return the list of flavors with given type."""
+        """Return the list of flavors with given type.
+
+        Args:
+            component_type: The type of the stack component.
+
+        Returns:
+            The list of flavors with the given type.
+        """
         return self._flavors[component_type]
 
 
 # Create the instance of the registry
 flavor_registry = FlavorRegistry()
```

### Comparing `zenml-0.8.1rc0/src/zenml/stack/stack.py` & `zenml-0.9.0/src/zenml/stack/stack.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML Stack class."""
+
 import os
 import time
 import uuid
 from datetime import datetime
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
@@ -25,23 +27,23 @@
     Set,
     Type,
 )
 
 from zenml.config.global_config import GlobalConfiguration
 from zenml.enums import StackComponentType
 from zenml.exceptions import ProvisioningError, StackValidationError
-from zenml.io import utils
 from zenml.logger import get_logger
 from zenml.runtime_configuration import (
     RUN_NAME_OPTION_KEY,
     RuntimeConfiguration,
 )
-from zenml.utils import string_utils
+from zenml.utils import io_utils, string_utils
 
 if TYPE_CHECKING:
+    from zenml.alerter import BaseAlerter
     from zenml.artifact_stores import BaseArtifactStore
     from zenml.container_registries import BaseContainerRegistry
     from zenml.experiment_trackers.base_experiment_tracker import (
         BaseExperimentTracker,
     )
     from zenml.feature_stores import BaseFeatureStore
     from zenml.metadata_stores import BaseMetadataStore
@@ -75,62 +77,90 @@
         artifact_store: "BaseArtifactStore",
         container_registry: Optional["BaseContainerRegistry"] = None,
         secrets_manager: Optional["BaseSecretsManager"] = None,
         step_operator: Optional["BaseStepOperator"] = None,
         feature_store: Optional["BaseFeatureStore"] = None,
         model_deployer: Optional["BaseModelDeployer"] = None,
         experiment_tracker: Optional["BaseExperimentTracker"] = None,
+        alerter: Optional["BaseAlerter"] = None,
     ):
         """Initializes and validates a stack instance.
 
+        # noqa: DAR402
+
+        Args:
+            name: Name of the stack.
+            orchestrator: Orchestrator component of the stack.
+            metadata_store: Metadata store component of the stack.
+            artifact_store: Artifact store component of the stack.
+            container_registry: Container registry component of the stack.
+            secrets_manager: Secrets manager component of the stack.
+            step_operator: Step operator component of the stack.
+            feature_store: Feature store component of the stack.
+            model_deployer: Model deployer component of the stack.
+            experiment_tracker: Experiment tracker component of the stack.
+            alerter: Alerter component of the stack.
+
         Raises:
-             StackValidationError: If the stack configuration is not valid.
+            StackValidationError: If the stack configuration is not valid.
         """
         self._name = name
         self._orchestrator = orchestrator
         self._metadata_store = metadata_store
         self._artifact_store = artifact_store
         self._container_registry = container_registry
         self._step_operator = step_operator
         self._secrets_manager = secrets_manager
         self._feature_store = feature_store
         self._model_deployer = model_deployer
         self._experiment_tracker = experiment_tracker
+        self._alerter = alerter
 
     @classmethod
     def from_components(
         cls, name: str, components: Dict[StackComponentType, "StackComponent"]
     ) -> "Stack":
         """Creates a stack instance from a dict of stack components.
 
+        # noqa: DAR402
+
         Args:
             name: The name of the stack.
             components: The components of the stack.
 
         Returns:
             A stack instance consisting of the given components.
 
         Raises:
             TypeError: If a required component is missing or a component
                 doesn't inherit from the expected base class.
         """
+        from zenml.alerter import BaseAlerter
         from zenml.artifact_stores import BaseArtifactStore
         from zenml.container_registries import BaseContainerRegistry
         from zenml.experiment_trackers import BaseExperimentTracker
         from zenml.feature_stores import BaseFeatureStore
         from zenml.metadata_stores import BaseMetadataStore
         from zenml.model_deployers import BaseModelDeployer
         from zenml.orchestrators import BaseOrchestrator
         from zenml.secrets_managers import BaseSecretsManager
         from zenml.step_operators import BaseStepOperator
 
         def _raise_type_error(
             component: Optional["StackComponent"], expected_class: Type[Any]
         ) -> NoReturn:
-            """Raises a TypeError that the component has an unexpected type."""
+            """Raises a TypeError that the component has an unexpected type.
+
+            Args:
+                component: The component that has an unexpected type.
+                expected_class: The expected type of the component.
+
+            Raises:
+                TypeError: If the component has an unexpected type.
+            """
             raise TypeError(
                 f"Unable to create stack: Wrong stack component type "
                 f"`{component.__class__.__name__}` (expected: subclass "
                 f"of `{expected_class.__name__}`)"
             )
 
         orchestrator = components.get(StackComponentType.ORCHESTRATOR)
@@ -181,43 +211,52 @@
             StackComponentType.EXPERIMENT_TRACKER
         )
         if experiment_tracker is not None and not isinstance(
             experiment_tracker, BaseExperimentTracker
         ):
             _raise_type_error(experiment_tracker, BaseExperimentTracker)
 
+        alerter = components.get(StackComponentType.ALERTER)
+        if alerter is not None and not isinstance(alerter, BaseAlerter):
+            _raise_type_error(alerter, BaseAlerter)
+
         return Stack(
             name=name,
             orchestrator=orchestrator,
             metadata_store=metadata_store,
             artifact_store=artifact_store,
             container_registry=container_registry,
             secrets_manager=secrets_manager,
             step_operator=step_operator,
             feature_store=feature_store,
             model_deployer=model_deployer,
             experiment_tracker=experiment_tracker,
+            alerter=alerter,
         )
 
     @classmethod
     def default_local_stack(cls) -> "Stack":
-        """Creates a stack instance which is configured to run locally."""
+        """Creates a stack instance which is configured to run locally.
+
+        Returns:
+            A stack instance configured to run locally.
+        """
         from zenml.artifact_stores import LocalArtifactStore
         from zenml.metadata_stores import SQLiteMetadataStore
         from zenml.orchestrators import LocalOrchestrator
 
         orchestrator = LocalOrchestrator(name="default")
 
         artifact_store_uuid = uuid.uuid4()
         artifact_store_path = os.path.join(
             GlobalConfiguration().config_directory,
             "local_stores",
             str(artifact_store_uuid),
         )
-        utils.create_dir_recursive_if_not_exists(artifact_store_path)
+        io_utils.create_dir_recursive_if_not_exists(artifact_store_path)
         artifact_store = LocalArtifactStore(
             name="default",
             uuid=artifact_store_uuid,
             path=artifact_store_path,
         )
 
         metadata_store_path = os.path.join(artifact_store_path, "metadata.db")
@@ -230,88 +269,146 @@
             orchestrator=orchestrator,
             metadata_store=metadata_store,
             artifact_store=artifact_store,
         )
 
     @property
     def components(self) -> Dict[StackComponentType, "StackComponent"]:
-        """All components of the stack."""
+        """All components of the stack.
+
+        Returns:
+            A dictionary of all components of the stack.
+        """
         return {
             component.TYPE: component
             for component in [
                 self.orchestrator,
                 self.metadata_store,
                 self.artifact_store,
                 self.container_registry,
                 self.secrets_manager,
                 self.step_operator,
                 self.feature_store,
                 self.model_deployer,
                 self.experiment_tracker,
+                self.alerter,
             ]
             if component is not None
         }
 
     @property
     def name(self) -> str:
-        """The name of the stack."""
+        """The name of the stack.
+
+        Returns:
+            str: The name of the stack.
+        """
         return self._name
 
     @property
     def orchestrator(self) -> "BaseOrchestrator":
-        """The orchestrator of the stack."""
+        """The orchestrator of the stack.
+
+        Returns:
+            The orchestrator of the stack.
+        """
         return self._orchestrator
 
     @property
     def metadata_store(self) -> "BaseMetadataStore":
-        """The metadata store of the stack."""
+        """The metadata store of the stack.
+
+        Returns:
+            The metadata store of the stack.
+        """
         return self._metadata_store
 
     @property
     def artifact_store(self) -> "BaseArtifactStore":
-        """The artifact store of the stack."""
+        """The artifact store of the stack.
+
+        Returns:
+            The artifact store of the stack.
+        """
         return self._artifact_store
 
     @property
     def container_registry(self) -> Optional["BaseContainerRegistry"]:
-        """The container registry of the stack."""
+        """The container registry of the stack.
+
+        Returns:
+            The container registry of the stack or None if the stack does not
+            have a container registry.
+        """
         return self._container_registry
 
     @property
     def secrets_manager(self) -> Optional["BaseSecretsManager"]:
-        """The secrets manager of the stack."""
+        """The secrets manager of the stack.
+
+        Returns:
+            The secrets manager of the stack.
+        """
         return self._secrets_manager
 
     @property
     def step_operator(self) -> Optional["BaseStepOperator"]:
-        """The step operator of the stack."""
+        """The step operator of the stack.
+
+        Returns:
+            The step operator of the stack.
+        """
         return self._step_operator
 
     @property
     def feature_store(self) -> Optional["BaseFeatureStore"]:
-        """The feature store of the stack."""
+        """The feature store of the stack.
+
+        Returns:
+            The feature store of the stack.
+        """
         return self._feature_store
 
     @property
     def model_deployer(self) -> Optional["BaseModelDeployer"]:
-        """The model deployer of the stack."""
+        """The model deployer of the stack.
+
+        Returns:
+            The model deployer of the stack.
+        """
         return self._model_deployer
 
     @property
     def experiment_tracker(self) -> Optional["BaseExperimentTracker"]:
-        """The experiment tracker of the stack."""
+        """The experiment tracker of the stack.
+
+        Returns:
+            The experiment tracker of the stack.
+        """
         return self._experiment_tracker
 
     @property
+    def alerter(self) -> Optional["BaseAlerter"]:
+        """The alerter of the stack.
+
+        Returns:
+            The alerter of the stack.
+        """
+        return self._alerter
+
+    @property
     def runtime_options(self) -> Dict[str, Any]:
         """Runtime options that are available to configure this stack.
 
         This method combines the available runtime options for all components
         of this stack. See `StackComponent.runtime_options()` for
         more information.
+
+        Returns:
+            A dictionary of runtime options.
         """
         runtime_options: Dict[str, Any] = {}
         for component in self.components.values():
             duplicate_runtime_options = (
                 runtime_options.keys() & component.runtime_options.keys()
             )
             if duplicate_runtime_options:
@@ -321,15 +418,19 @@
                 )
 
             runtime_options.update(component.runtime_options)
 
         return runtime_options
 
     def dict(self) -> Dict[str, str]:
-        """Converts the stack into a dictionary."""
+        """Converts the stack into a dictionary.
+
+        Returns:
+            A dictionary containing the stack components.
+        """
         component_dict = {
             component_type.value: component.json(sort_keys=True)
             for component_type, component in self.components.items()
         }
         component_dict.update({"name": self.name})
         return component_dict
 
@@ -341,14 +442,17 @@
 
         This method combines the requirements of all stack components (except
         the ones specified in `exclude_components`).
 
         Args:
             exclude_components: Set of component types for which the
                 requirements should not be included in the output.
+
+        Returns:
+            Set of PyPI requirements.
         """
         exclude_components = exclude_components or set()
         requirements = [
             component.requirements
             for component in self.components.values()
             if component.TYPE not in exclude_components
         ]
@@ -356,32 +460,33 @@
 
     def validate(self) -> None:
         """Checks whether the stack configuration is valid.
 
         To check if a stack configuration is valid, the following criteria must
         be met:
         - all components must support the execution mode (either local or
-         remote execution) specified by the orchestrator of the stack
+            remote execution) specified by the orchestrator of the stack
         - the `StackValidator` of each stack component has to validate the
-         stack to make sure all the components are compatible with each other
-
-        Raises:
-             StackValidationError: If the stack configuration is not valid.
+            stack to make sure all the components are compatible with each other
         """
-
         for component in self.components.values():
             if component.validator:
                 component.validator.validate(stack=self)
 
     def _register_pipeline_run(
         self,
         pipeline: "BasePipeline",
         runtime_configuration: "RuntimeConfiguration",
     ) -> None:
-        """Registers a pipeline run in the ZenStore."""
+        """Registers a pipeline run in the ZenStore.
+
+        Args:
+            pipeline: The pipeline that is being run.
+            runtime_configuration: The runtime configuration of the pipeline.
+        """
         from zenml.repository import Repository
         from zenml.zen_stores.models import StackWrapper
         from zenml.zen_stores.models.pipeline_models import (
             PipelineRunWrapper,
             PipelineWrapper,
         )
 
@@ -408,14 +513,17 @@
         Args:
             pipeline: The pipeline to deploy.
             runtime_configuration: Contains all the runtime configuration
                 options specified for the pipeline run.
 
         Returns:
             The return value of the call to `orchestrator.run_pipeline(...)`.
+
+        Raises:
+            StackValidationError: If the stack configuration is not valid.
         """
         self.validate()
 
         for component in self.components.values():
             if not component.is_running:
                 raise StackValidationError(
                     f"The '{component.name}' {component.TYPE} stack component "
@@ -491,46 +599,44 @@
     def cleanup_step_run(self) -> None:
         """Cleans up resources after the step run is finished."""
         for component in self.components.values():
             component.cleanup_step_run()
 
     @property
     def is_provisioned(self) -> bool:
-        """If the stack provisioned resources to run locally."""
+        """If the stack provisioned resources to run locally.
+
+        Returns:
+            True if the stack provisioned resources to run locally.
+        """
         return all(
             component.is_provisioned for component in self.components.values()
         )
 
     @property
     def is_running(self) -> bool:
-        """If the stack is running locally."""
+        """If the stack is running locally.
+
+        Returns:
+            True if the stack is running locally, False otherwise.
+        """
         return all(
             component.is_running for component in self.components.values()
         )
 
     def provision(self) -> None:
-        """Provisions resources to run the stack locally.
-
-        Raises:
-            NotImplementedError: If any unprovisioned component does not
-                implement provisioning.
-        """
+        """Provisions resources to run the stack locally."""
         logger.info("Provisioning resources for stack '%s'.", self.name)
         for component in self.components.values():
             if not component.is_provisioned:
                 component.provision()
                 logger.info("Provisioned resources for %s.", component)
 
     def deprovision(self) -> None:
-        """Deprovisions all local resources of the stack.
-
-        Raises:
-            NotImplementedError: If any provisioned component does not
-                implement deprovisioning.
-        """
+        """Deprovisions all local resources of the stack."""
         logger.info("Deprovisioning resources for stack '%s'.", self.name)
         for component in self.components.values():
             if component.is_provisioned:
                 try:
                     component.deprovision()
                     logger.info("Deprovisioned resources for %s.", component)
                 except NotImplementedError as e:
```

### Comparing `zenml-0.8.1rc0/src/zenml/stack/stack_component.py` & `zenml-0.9.0/src/zenml/stack/stack_component.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML Stack Component class."""
+
 import textwrap
 from abc import ABC
 from typing import TYPE_CHECKING, Any, ClassVar, Dict, Optional, Set
 from uuid import UUID, uuid4
 
 from pydantic import BaseModel, Field, root_validator
 
@@ -40,67 +42,81 @@
 
     # Class Configuration
     TYPE: ClassVar[StackComponentType]
     FLAVOR: ClassVar[str]
 
     @property
     def log_file(self) -> Optional[str]:
-        """Optional path to a log file for the stack component."""
+        """Optional path to a log file for the stack component.
+
+        Returns:
+            Optional path to a log file for the stack component.
+        """
         # TODO [ENG-136]: Add support for multiple log files for a stack
         #  component. E.g. let each component return a generator that yields
         #  logs instead of specifying a single file path.
         return None
 
     @property
     def runtime_options(self) -> Dict[str, Any]:
         """Runtime options that are available to configure this component.
 
         The items of the dictionary should map option names (which can be used
         to configure the option in the `RuntimeConfiguration`) to default
         values for the option (or `None` if there is no default value).
+
+        Returns:
+            A dictionary of runtime options.
         """
         return {}
 
     @property
     def requirements(self) -> Set[str]:
-        """Set of PyPI requirements for the component."""
+        """Set of PyPI requirements for the component.
+
+        Returns:
+            A set of PyPI requirements for the component.
+        """
         from zenml.integrations.utils import get_requirements_for_module
 
         return set(get_requirements_for_module(self.__module__))
 
     @property
     def local_path(self) -> Optional[str]:
-        """Path to a local directory used by the component to store persistent
-        information.
+        """Path to a local directory used by the component to store persistent information.
 
         This property should only be implemented by components that need to
         store persistent information in a directory on the local machine and
         also need that information to be available during pipeline runs.
 
         IMPORTANT: the path returned by this property must always be a path
         that is relative to the ZenML global config directory. The local
         Kubeflow orchestrator relies on this convention to correctly mount the
         local folders in the Kubeflow containers. This is an example of a valid
         path:
 
         ```python
-        from zenml.io.utils import get_global_config_directory
+        from zenml.utils.io_utils import get_global_config_directory
         from zenml.constants import LOCAL_STORES_DIRECTORY_NAME
 
         ...
 
         @property
         def local_path(self) -> Optional[str]:
 
             return os.path.join(
                 get_global_config_directory(),
                 LOCAL_STORES_DIRECTORY_NAME,
                 str(uuid),
             )
         ```
+
+        Returns:
+            A path to a local directory used by the component to store
+            persistent information.
         """
         return None
 
     def prepare_pipeline_deployment(
         self,
         pipeline: "BasePipeline",
         stack: "Stack",
@@ -129,84 +145,142 @@
         """Prepares running a step."""
 
     def cleanup_step_run(self) -> None:
         """Cleans up resources after the step run is finished."""
 
     @property
     def post_registration_message(self) -> Optional[str]:
-        """Optional message that will be printed after the stack component is
-        registered."""
+        """Optional message that will be printed after the stack component is registered.
+
+        Returns:
+            An optional message.
+        """
         return None
 
     @property
     def validator(self) -> Optional["StackValidator"]:
         """The optional validator of the stack component.
 
         This validator will be called each time a stack with the stack
         component is initialized. Subclasses should override this property
         and return a `StackValidator` that makes sure they're not included in
         any stack that they're not compatible with.
+
+        Returns:
+            An optional `StackValidator` instance.
         """
         return None
 
     @property
     def is_provisioned(self) -> bool:
-        """If the component provisioned resources to run."""
+        """If the component provisioned resources to run.
+
+        Returns:
+            True if the component provisioned resources to run.
+        """
         return True
 
     @property
     def is_running(self) -> bool:
-        """If the component is running."""
+        """If the component is running.
+
+        Returns:
+            True if the component is running.
+        """
         return True
 
     @property
     def is_suspended(self) -> bool:
-        """If the component is suspended."""
+        """If the component is suspended.
+
+        Returns:
+            True if the component is suspended.
+        """
         return not self.is_running
 
     def provision(self) -> None:
-        """Provisions resources to run the component."""
+        """Provisions resources to run the component.
+
+        Raises:
+            NotImplementedError: If the component does not implement this
+                method.
+        """
         raise NotImplementedError(
             f"Provisioning resources not implemented for {self}."
         )
 
     def deprovision(self) -> None:
-        """Deprovisions all resources of the component."""
+        """Deprovisions all resources of the component.
+
+        Raises:
+            NotImplementedError: If the component does not implement this
+                method.
+        """
         raise NotImplementedError(
             f"Deprovisioning resource not implemented for {self}."
         )
 
     def resume(self) -> None:
-        """Resumes the provisioned resources of the component."""
+        """Resumes the provisioned resources of the component.
+
+        Raises:
+            NotImplementedError: If the component does not implement this
+                method.
+        """
         raise NotImplementedError(
             f"Resuming provisioned resources not implemented for {self}."
         )
 
     def suspend(self) -> None:
-        """Suspends the provisioned resources of the component."""
+        """Suspends the provisioned resources of the component.
+
+        Raises:
+            NotImplementedError: If the component does not implement this
+                method.
+        """
         raise NotImplementedError(
             f"Suspending provisioned resources not implemented for {self}."
         )
 
     def __repr__(self) -> str:
-        """String representation of the stack component."""
+        """String representation of the stack component.
+
+        Returns:
+            A string representation of the stack component.
+        """
         attribute_representation = ", ".join(
             f"{key}={value}" for key, value in self.dict().items()
         )
         return (
             f"{self.__class__.__qualname__}(type={self.TYPE}, "
             f"flavor={self.FLAVOR}, {attribute_representation})"
         )
 
     def __str__(self) -> str:
-        """String representation of the stack component."""
+        """String representation of the stack component.
+
+        Returns:
+            A string representation of the stack component.
+        """
         return self.__repr__()
 
     @root_validator(skip_on_failure=True)
     def _ensure_stack_component_complete(cls, values: Dict[str, Any]) -> Any:
+        """Ensures that the stack component is complete.
+
+        Args:
+            values: The values of the stack component.
+
+        Returns:
+            The values of the stack component.
+
+        Raises:
+            StackComponentInterfaceError: If the stack component is not
+                implemented correctly.
+        """
         try:
             stack_component_type = getattr(cls, "TYPE")
             assert stack_component_type in StackComponentType
         except (AttributeError, AssertionError):
             raise StackComponentInterfaceError(
                 textwrap.dedent(
                     """
```

### Comparing `zenml-0.8.1rc0/src/zenml/stack/stack_validator.py` & `zenml-0.9.0/src/zenml/stack/stack_validator.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the ZenML Stack Validator."""
+
 from typing import TYPE_CHECKING, AbstractSet, Callable, Optional, Tuple
 
 from zenml.enums import StackComponentType
 from zenml.exceptions import StackValidationError
 from zenml.logger import get_logger
 
 if TYPE_CHECKING:
@@ -53,14 +55,17 @@
 
     def validate(self, stack: "Stack") -> None:
         """Validates the given stack.
 
         Checks if the stack contains all the required components and passes
         the custom validation function of the validator.
 
+        Args:
+            stack: The stack to validate.
+
         Raises:
             StackValidationError: If the stack does not meet all the
                 validation criteria.
         """
         missing_components = self._required_components - set(stack.components)
         if missing_components:
             raise StackValidationError(
```

### Comparing `zenml-0.8.1rc0/src/zenml/step_operators/__init__.py` & `zenml-0.9.0/src/zenml/step_operators/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,16 +7,17 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-While an orchestrator defines how and where your entire pipeline runs, a step 
-operator defines how and where an individual step runs. This can be useful in a 
-variety of scenarios. An example could be if one step within a pipeline should 
+"""Step operators allow you to run steps on custom infrastructure.
+
+While an orchestrator defines how and where your entire pipeline runs, a step
+operator defines how and where an individual step runs. This can be useful in a
+variety of scenarios. An example could be if one step within a pipeline should
 run on a separate environment equipped with a GPU (like a trainer step).
 """
 from zenml.step_operators.base_step_operator import BaseStepOperator
 
 __all__ = ["BaseStepOperator"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/step_operators/base_step_operator.py` & `zenml-0.9.0/src/zenml/step_operators/base_step_operator.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base class for ZenML step operators."""
 
 from abc import ABC, abstractmethod
 from typing import ClassVar, List
 
 from zenml.enums import StackComponentType
 from zenml.stack import StackComponent
```

### Comparing `zenml-0.8.1rc0/src/zenml/step_operators/entrypoint.py` & `zenml-0.9.0/src/zenml/step_operators/entrypoint.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Entrypoint for the step operator."""
 
 import importlib
 import logging
 import sys
 from typing import Dict, Type, cast
 
 import click
@@ -42,14 +43,17 @@
 ) -> Type[_FunctionExecutor]:
     """Creates an executor class for a given step.
 
     Args:
         step_source_path: Import path of the step to run.
         input_artifact_type_mapping: A dictionary mapping input names to
             a string representation of their artifact classes.
+
+    Returns:
+        A class of an executor instance.
     """
     step_class = cast(
         Type[BaseStep], source_utils.load_source_path_class(step_source_path)
     )
     step_instance = step_class()
 
     materializers = step_instance.get_materializers(ensure_complete=True)
@@ -81,15 +85,22 @@
 
     return cast(
         Type[_FunctionExecutor], component_class.EXECUTOR_SPEC.executor_class
     )
 
 
 def load_execution_info(execution_info_path: str) -> ExecutionInfo:
-    """Loads the execution info from the given path."""
+    """Loads the execution info from the given path.
+
+    Args:
+        execution_info_path: Path to the execution info file.
+
+    Returns:
+        Execution info.
+    """
     with fileio.open(execution_info_path, "rb") as f:
         execution_info_proto = ExecutionInvocation.FromString(f.read())
 
     return ExecutionInfo.from_proto(execution_info_proto)
 
 
 def configure_executor(
@@ -124,15 +135,22 @@
 @click.option("--input_artifact_types_path", required=True, type=str)
 def main(
     main_module: str,
     step_source_path: str,
     execution_info_path: str,
     input_artifact_types_path: str,
 ) -> None:
-    """Runs a single ZenML step."""
+    """Runs a single ZenML step.
+
+    Args:
+        main_module: The module containing the main function.
+        step_source_path: Import path of the step to run.
+        execution_info_path: Path to the execution info file.
+        input_artifact_types_path: Path to the input artifact types file.
+    """
     # prevent running entire pipeline in user code if they would run at import
     # time (e.g. not wrapped in a function or __name__== "__main__" check)
     constants.SHOULD_PREVENT_PIPELINE_EXECUTION = True
 
     logging.basicConfig(stream=sys.stdout, level=logging.INFO)
     logging.getLogger().setLevel(logging.INFO)
```

### Comparing `zenml-0.8.1rc0/src/zenml/step_operators/step_executor_operator.py` & `zenml-0.9.0/src/zenml/step_operators/step_executor_operator.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Custom definition of a Step Executor Operator which can be passed into the Step Operator."""
+
 import json
 import os
 import sys
 from typing import TYPE_CHECKING, Any, List, Tuple, cast
 
 from tfx.orchestration.portable import data_types
 from tfx.orchestration.portable.base_executor_operator import (
@@ -43,28 +45,36 @@
 
 logger = get_logger(__name__)
 
 
 def _write_execution_info(
     execution_info: data_types.ExecutionInfo, path: str
 ) -> None:
-    """Writes execution information to a given path."""
+    """Writes execution information to a given path.
+
+    Args:
+        execution_info: Execution information to write.
+        path: Path to write the execution information to.
+    """
     execution_info_bytes = execution_info.to_proto().SerializeToString()
 
     with fileio.open(path, "wb") as f:
         f.write(execution_info_bytes)
 
     logger.debug("Finished writing execution info to '%s'", path)
 
 
 def _read_executor_output(
     output_path: str,
 ) -> execution_result_pb2.ExecutorOutput:
     """Reads executor output from the given path.
 
+    Args:
+        output_path: Path to read the executor output from.
+
     Returns:
         Executor output object.
 
     Raises:
         RuntimeError: If no output is written to the given path.
     """
     if fileio.exists(output_path):
@@ -157,14 +167,17 @@
 
         Args:
             stack: Stack on which the step is being executed.
             execution_info: Execution info needed to run the step.
 
         Returns:
             The step operator to run a step.
+
+        Raises:
+            RuntimeError: If no active step operator is found.
         """
         step_operator = stack.step_operator
 
         # the two following errors should never happen as the stack gets
         # validated before running the pipeline
         if not step_operator:
             raise RuntimeError(
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/__init__.py` & `zenml-0.9.0/src/zenml/steps/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,27 +7,29 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initializer for ZenML steps.
+
 A step is a single piece or stage of a ZenML pipeline. Think of each step as
-being one of the nodes of a Directed Acyclic Graph (or DAG). Steps are responsible for one aspect of processing
-or interacting with the data / artifacts in the pipeline.
+being one of the nodes of a Directed Acyclic Graph (or DAG). Steps are
+responsible for one aspect of processing or interacting with the data /
+artifacts in the pipeline.
 
-ZenML currently
-implements a basic step interface, but there will be other more customized
-interfaces (layered in a hierarchy) for specialized
-implementations. Conceptually, a Step is a discrete and independent part of a
-pipeline that is responsible for one particular aspect of data manipulation
-inside a ZenML pipeline.
+ZenML currently implements a basic step interface, but there will be other more
+customized interfaces (layered in a hierarchy) for specialized implementations.
+Conceptually, a Step is a discrete and independent part of a pipeline that is
+responsible for one particular aspect of data manipulation inside a ZenML
+pipeline.
 
-Steps can be subclassed from the `BaseStep` class, or used via our `@step` decorator.
+Steps can be subclassed from the `BaseStep` class, or used via our `@step`
+decorator.
 """
 
 from zenml.steps.base_step import BaseStep
 from zenml.steps.base_step_config import BaseStepConfig
 from zenml.steps.step_context import StepContext
 from zenml.steps.step_decorator import step
 from zenml.steps.step_environment import STEP_ENVIRONMENT_NAME, StepEnvironment
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/base_step.py` & `zenml-0.9.0/src/zenml/steps/base_step.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base Step for ZenML."""
 
 import collections
 import inspect
 import json
 import random
 from abc import abstractmethod
 from typing import (
@@ -75,15 +76,27 @@
     * Has a matching materializer.
     * Is a subclass of the Config class
     """
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "BaseStepMeta":
-        """Set up a new class with a qualified spec."""
+        """Set up a new class with a qualified spec.
+
+        Args:
+            name: The name of the class.
+            bases: The base classes of the class.
+            dct: The attributes of the class.
+
+        Returns:
+            The new class.
+
+        Raises:
+            StepInterfaceError: When unable to create the step.
+        """
         dct.setdefault("PARAM_SPEC", {})
         dct.setdefault("INPUT_SPEC", {})
         dct.setdefault("OUTPUT_SPEC", {})
         cls = cast(Type["BaseStep"], super().__new__(mcs, name, bases, dct))
 
         cls.INPUT_SIGNATURE = {}
         cls.OUTPUT_SIGNATURE = {}
@@ -232,23 +245,29 @@
     PARAM_SPEC: Dict[str, Any] = {}
     INPUT_SPEC: Dict[str, Type[BaseArtifact]] = {}
     OUTPUT_SPEC: Dict[str, Type[BaseArtifact]] = {}
 
     INSTANCE_CONFIGURATION: Dict[str, Any] = {}
 
     def __init__(self, *args: Any, **kwargs: Any) -> None:
+        """Initializes a step.
+
+        Args:
+            *args: Positional arguments passed to the step.
+            **kwargs: Keyword arguments passed to the step.
+        """
         self.name = self.__class__.__name__
         self.pipeline_parameter_name: Optional[str] = None
 
         kwargs.update(getattr(self, INSTANCE_CONFIGURATION))
 
+        # This value is only used in `BaseStep.__created_by_functional_api()`
+        kwargs.pop(PARAM_CREATED_BY_FUNCTIONAL_API, None)
+
         self.requires_context = bool(self.CONTEXT_PARAMETER_NAME)
-        self._created_by_functional_api = kwargs.pop(
-            PARAM_CREATED_BY_FUNCTIONAL_API, False
-        )
         self.custom_step_operator = kwargs.pop(PARAM_CUSTOM_STEP_OPERATOR, None)
 
         enable_cache = kwargs.pop(PARAM_ENABLE_CACHE, None)
         if enable_cache is None:
             if self.requires_context:
                 # Using the StepContext inside a step provides access to
                 # external resources which might influence the step execution.
@@ -275,15 +294,35 @@
         self._has_been_called = False
 
         self._verify_init_arguments(*args, **kwargs)
         self._verify_output_spec()
 
     @abstractmethod
     def entrypoint(self, *args: Any, **kwargs: Any) -> Any:
-        """Abstract method for core step logic."""
+        """Abstract method for core step logic.
+
+        Args:
+            *args: Positional arguments passed to the step.
+            **kwargs: Keyword arguments passed to the step.
+
+        Returns:
+            The output of the step.
+        """
+
+    @classmethod
+    def _created_by_functional_api(cls) -> bool:
+        """Returns if the step class was created by the functional API.
+
+        Returns:
+            `True` if the class was created by the functional API,
+            `False` otherwise.
+        """
+        return cls.INSTANCE_CONFIGURATION.get(
+            PARAM_CREATED_BY_FUNCTIONAL_API, False
+        )
 
     def get_materializers(
         self, ensure_complete: bool = False
     ) -> Dict[str, Type[BaseMaterializer]]:
         """Returns available materializers for the outputs of this step.
 
         Args:
@@ -328,30 +367,34 @@
                         url="https://docs.zenml.io/guides/index/custom-materializer",
                     )
 
         return materializers
 
     @property
     def _internal_execution_parameters(self) -> Dict[str, Any]:
-        """ZenML internal execution parameters for this step."""
+        """Internal ZenML execution parameters for this step.
+
+        Returns:
+            A dictionary containing the ZenML internal execution parameters
+        """
         parameters = {
             PARAM_PIPELINE_PARAMETER_NAME: self.pipeline_parameter_name,
             PARAM_CUSTOM_STEP_OPERATOR: self.custom_step_operator,
         }
 
         if self.enable_cache:
             # Caching is enabled so we compute a hash of the step function code
             # and materializers to catch changes in the step behavior
 
             # If the step was defined using the functional api, only track
             # changes to the entrypoint function. Otherwise track changes to
             # the entire step class.
             source_object = (
                 self.entrypoint
-                if self._created_by_functional_api
+                if self._created_by_functional_api()
                 else self.__class__
             )
             parameters["step_source"] = get_hashed_source(source_object)
 
             for name, materializer in self.get_materializers().items():
                 key = f"{name}_materializer_source"
                 parameters[key] = get_hashed_source(materializer)
@@ -469,16 +512,14 @@
             - checks if config parameters were set via a config object or file
             - tries to set missing config parameters from default values of the
               config class
 
         Raises:
             MissingStepParameterError: If no value could be found for one or
                 more config parameters.
-            StepInterfaceError: If a config parameter value couldn't be
-                serialized to json.
         """
         if self.CONFIG_CLASS:
             # we need to store a value for all config keys inside the
             # metadata store to make sure caching works as expected
             missing_keys = []
             for name, field in self.CONFIG_CLASS.__fields__.items():
                 if name in self.PARAM_SPEC:
@@ -579,15 +620,28 @@
 
         return combined_artifacts
 
     # TODO [ENG-157]: replaces Channels with ZenML class (BaseArtifact?)
     def __call__(
         self, *artifacts: Channel, **kw_artifacts: Channel
     ) -> Union[Channel, List[Channel]]:
-        """Generates a component when called."""
+        """Generates a component when called.
+
+        Args:
+            *artifacts: Positional input artifacts passed to
+                the __call__ method.
+            **kw_artifacts: Keyword input artifacts passed to
+                the __call__ method.
+
+        Returns:
+            A single output artifact or a list of output artifacts.
+
+        Raises:
+            StepInterfaceError: If the step has already been called.
+        """
         if self._has_been_called:
             raise StepInterfaceError(
                 f"Step {self.name} has already been called. A ZenML step "
                 f"instance can only be called once per pipeline run."
             )
         self._has_been_called = True
 
@@ -649,25 +703,37 @@
         if len(returns) == 1:
             return returns[0]
         else:
             return returns
 
     @property
     def component(self) -> _ZenMLSimpleComponent:
-        """Returns a TFX component."""
+        """Returns a TFX component.
+
+        Returns:
+            A TFX component.
+
+        Raises:
+            StepInterfaceError: If you are trying to access the step component
+                before creating it.
+        """
         if not self._component:
             raise StepInterfaceError(
                 "Trying to access the step component "
                 "before creating it via calling the step."
             )
         return self._component
 
     @property
     def executor_operator(self) -> Type[BaseExecutorOperator]:
-        """Executor operator class that should be used to run this step."""
+        """Executor operator class that should be used to run this step.
+
+        Returns:
+            A TFX executor operator class.
+        """
         if self.custom_step_operator:
             return StepExecutorOperator
         else:
             return PythonExecutorOperator
 
     def with_return_materializers(
         self: T,
@@ -689,16 +755,22 @@
 
         Raises:
             StepInterfaceError: If a materializer is not a `BaseMaterializer`
                 subclass or a materializer for a non-existent output is given.
         """
 
         def _is_materializer_class(value: Any) -> bool:
-            """Checks whether the given object is a `BaseMaterializer`
-            subclass."""
+            """Checks whether the given object is a `BaseMaterializer` subclass.
+
+            Args:
+                value: The object to check.
+
+            Returns:
+                True if the object is a `BaseMaterializer` subclass, False otherwise.
+            """
             is_class = isinstance(value, type)
             return is_class and issubclass(value, BaseMaterializer)
 
         if isinstance(materializers, dict):
             allowed_output_names = set(self.OUTPUT_SIGNATURE)
 
             for output_name, materializer in materializers.items():
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/builtin_steps/__init__.py` & `zenml-0.9.0/src/zenml/integrations/aws/secrets_managers/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from zenml.steps.builtin_steps.pandas_analyzer import (
-    PandasAnalyzer,
-    PandasAnalyzerConfig,
-)
-from zenml.steps.builtin_steps.pandas_datasource import (
-    PandasDatasource,
-    PandasDatasourceConfig,
+"""AWS Secrets Manager."""
+
+from zenml.integrations.aws.secrets_managers.aws_secrets_manager import (
+    AWSSecretsManager,
 )
+
+__all__ = ["AWSSecretsManager"]
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/builtin_steps/pandas_analyzer.py` & `zenml-0.9.0/src/zenml/steps/builtin_steps/pandas_analyzer.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,52 +7,55 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Pandas analyzer step."""
+
 from typing import Any, List, Optional, Type, Union
 
 import pandas as pd
 
 from zenml.artifacts import SchemaArtifact, StatisticsArtifact
 from zenml.steps import Output
 from zenml.steps.step_interfaces.base_analyzer_step import (
     BaseAnalyzerConfig,
     BaseAnalyzerStep,
 )
 
 
 class PandasAnalyzerConfig(BaseAnalyzerConfig):
-    """Config class for the PandasAnalyzer Config"""
+    """Config class for the PandasAnalyzer Config."""
 
     percentiles: List[float] = [0.25, 0.5, 0.75]
     include: Optional[Union[str, List[Type[Any]]]] = None
     exclude: Optional[Union[str, List[Type[Any]]]] = None
 
 
 class PandasAnalyzer(BaseAnalyzerStep):
-    """Simple step implementation which analyzes a given pd.DataFrame"""
+    """Simple step implementation which analyzes a given pd.DataFrame."""
 
     # Manually defining the type of the output artifacts
     OUTPUT_SPEC = {"statistics": StatisticsArtifact, "schema": SchemaArtifact}
 
     def entrypoint(  # type: ignore[override]
         self,
         dataset: pd.DataFrame,
         config: PandasAnalyzerConfig,
     ) -> Output(  # type:ignore[valid-type]
         statistics=pd.DataFrame, schema=pd.DataFrame
     ):
-        """Main entrypoint function for the pandas analyzer
+        """Main entrypoint function for the pandas analyzer.
 
         Args:
             dataset: pd.DataFrame, the given dataset
             config: the configuration of the step
+
         Returns:
             the statistics and the schema of the given dataframe
         """
         statistics = dataset.describe(
             percentiles=config.percentiles,
             include=config.include,
             exclude=config.exclude,
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/builtin_steps/pandas_datasource.py` & `zenml-0.9.0/src/zenml/steps/builtin_steps/pandas_datasource.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,44 +7,48 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Pandas datasource step."""
+
 from typing import List, Optional, Union
 
 import pandas as pd
 
 from zenml.steps.step_interfaces.base_datasource_step import (
     BaseDatasourceConfig,
     BaseDatasourceStep,
 )
 
 
 class PandasDatasourceConfig(BaseDatasourceConfig):
-    """Config class for the pandas csv datasource"""
+    """Config class for the pandas csv datasource."""
 
     path: str
     sep: str = ","
     header: Union[int, List[int], str] = "infer"
     names: Optional[List[str]] = None
     index_col: Optional[Union[int, str, List[Union[int, str]], bool]] = None
 
 
 class PandasDatasource(BaseDatasourceStep):
-    """Simple step implementation to ingest from a csv file using pandas"""
+    """Simple step implementation to ingest from a csv file using pandas."""
 
     def entrypoint(  # type: ignore[override]
         self,
         config: PandasDatasourceConfig,
     ) -> pd.DataFrame:
-        """Main entrypoint method for the PandasDatasource
+        """Main entrypoint method for the PandasDatasource.
+
         Args:
             config: the configuration of the step
+
         Returns:
             the resulting dataframe
         """
         return pd.read_csv(
             filepath_or_buffer=config.path,
             sep=config.sep,
             header=config.header,
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_context.py` & `zenml-0.9.0/src/zenml/steps/step_context.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,22 @@
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#
+#  Licensed under the Apache License, Version 2.0 (the "License");
+#  you may not use this file except in compliance with the License.
+#  You may obtain a copy of the License at:
+#
+#       http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+#  or implied. See the License for the specific language governing
+#  permissions and limitations under the License.
+"""Step context class."""
+
 from typing import TYPE_CHECKING, Dict, NamedTuple, Optional, Type, cast
 
 from zenml.exceptions import StepContextError
 from zenml.repository import Repository
 
 if TYPE_CHECKING:
     from zenml.artifacts.base_artifact import BaseArtifact
@@ -121,24 +136,32 @@
                 )
             return self._outputs[output_name]
         else:
             return next(iter(self._outputs.values()))
 
     @property
     def metadata_store(self) -> "BaseMetadataStore":
-        """
+        """Returns the metadata store.
+
         Returns an instance of the metadata store that is used to store
         metadata about the step (and the corresponding pipeline) which is
         being executed.
+
+        Returns:
+            The metadata store.
         """
         return self._metadata_store
 
     @property
     def stack(self) -> Optional["Stack"]:
-        """Returns the current active stack."""
+        """Returns the current active stack.
+
+        Returns:
+            The current active stack or None.
+        """
         return self._stack
 
     def get_output_materializer(
         self,
         output_name: Optional[str] = None,
         custom_materializer_class: Optional[Type["BaseMaterializer"]] = None,
     ) -> "BaseMaterializer":
@@ -153,19 +176,14 @@
             custom_materializer_class: If given, this `BaseMaterializer`
                 subclass will be initialized with the output artifact instead
                 of the materializer that was registered for this step output.
 
         Returns:
             A materializer initialized with the output artifact for
             the given output.
-
-        Raises:
-            StepContextError: If the step has no outputs, no output for
-                              the given `output_name` or if no `output_name`
-                              was given but the step has multiple outputs.
         """
         materializer_class, artifact = self._get_output(output_name)
         # use custom materializer class if provided or fallback to default
         # materializer for output
         materializer_class = custom_materializer_class or materializer_class
         return materializer_class(artifact)
 
@@ -176,14 +194,9 @@
             output_name: Optional name of the output for which to get the URI.
                 If no name is given and the step only has a single output,
                 the URI of this output will be returned. If the step has
                 multiple outputs, an exception will be raised.
 
         Returns:
             Artifact URI for the given output.
-
-        Raises:
-            StepContextError: If the step has no outputs, no output for
-                              the given `output_name` or if no `output_name`
-                              was given but the step has multiple outputs.
         """
         return cast(str, self._get_output(output_name).artifact.uri)
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_decorator.py` & `zenml-0.9.0/src/zenml/steps/step_decorator.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Step decorator function."""
+
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Dict,
     Optional,
     Type,
@@ -37,39 +39,37 @@
     from zenml.artifacts.base_artifact import BaseArtifact
 
 F = TypeVar("F", bound=Callable[..., Any])
 
 
 @overload
 def step(_func: F) -> Type[BaseStep]:
-    """Type annotations for step decorator in case of no arguments."""
     ...
 
 
 @overload
 def step(
     *,
     name: Optional[str] = None,
     enable_cache: bool = True,
     output_types: Optional[Dict[str, Type["BaseArtifact"]]] = None,
     custom_step_operator: Optional[str] = None,
 ) -> Callable[[F], Type[BaseStep]]:
-    """Type annotations for step decorator in case of arguments."""
     ...
 
 
 def step(
     _func: Optional[F] = None,
     *,
     name: Optional[str] = None,
     enable_cache: Optional[bool] = None,
     output_types: Optional[Dict[str, Type["BaseArtifact"]]] = None,
     custom_step_operator: Optional[str] = None,
 ) -> Union[Type[BaseStep], Callable[[F], Type[BaseStep]]]:
-    """Outer decorator function for the creation of a ZenML step
+    """Outer decorator function for the creation of a ZenML step.
 
     In order to be able to work with parameters such as `name`, it features a
     nested decorator structure.
 
     Args:
         _func: The decorated function.
         name: The name of the step. If left empty, the name of the decorated
@@ -85,19 +85,19 @@
 
     Returns:
         the inner decorator which creates the step class based on the
         ZenML BaseStep
     """
 
     def inner_decorator(func: F) -> Type[BaseStep]:
-        """Inner decorator function for the creation of a ZenML Step
+        """Inner decorator function for the creation of a ZenML Step.
 
         Args:
-          func: types.FunctionType, this function will be used as the
-            "process" method of the generated Step
+            func: types.FunctionType, this function will be used as the
+                "process" method of the generated Step.
 
         Returns:
             The class of a newly generated ZenML Step.
         """
         step_name = name or func.__name__
         output_spec = output_types or {}
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_environment.py` & `zenml-0.9.0/src/zenml/steps/step_environment.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,68 +7,79 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Step environment class."""
 
 from zenml.environment import BaseEnvironmentComponent
 
 STEP_ENVIRONMENT_NAME = "step_environment"
 
 
 class StepEnvironment(BaseEnvironmentComponent):
-    """Provides additional information about a step runtime inside a step
-    function in the form of an Environment component.
+    """Added information about a step runtime inside a step function.
 
-    This class can be used from within a pipeline step implementation to
-    access additional information about the runtime parameters of a pipeline
-    step, such as the pipeline name, pipeline run ID and other pipeline runtime
-    information. To use it, access it inside your step function like this:
+    This takes the form of an Environment component. This class can be used from
+    within a pipeline step implementation to access additional information about
+    the runtime parameters of a pipeline step, such as the pipeline name,
+    pipeline run ID and other pipeline runtime information. To use it, access it
+    inside your step function like this:
 
     ```python
     from zenml.environment import Environment
 
     @step
     def my_step(...)
         env = Environment().step_environment
         do_something_with(env.pipeline_name, env.pipeline_run_id, env.step_name)
     ```
-
     """
 
     NAME = STEP_ENVIRONMENT_NAME
 
     def __init__(
         self,
         pipeline_name: str,
         pipeline_run_id: str,
         step_name: str,
     ):
-        """Initialize the environment of the currently running
-        step.
+        """Initialize the environment of the currently running step.
 
         Args:
             pipeline_name: the name of the currently running pipeline
             pipeline_run_id: the ID of the currently running pipeline
             step_name: the name of the currently running step
         """
         super().__init__()
         self._pipeline_name = pipeline_name
         self._pipeline_run_id = pipeline_run_id
         self._step_name = step_name
 
     @property
     def pipeline_name(self) -> str:
-        """The name of the currently running pipeline."""
+        """The name of the currently running pipeline.
+
+        Returns:
+            The name of the currently running pipeline.
+        """
         return self._pipeline_name
 
     @property
     def pipeline_run_id(self) -> str:
-        """The ID of the current pipeline run."""
+        """The ID of the current pipeline run.
+
+        Returns:
+            The ID of the current pipeline run.
+        """
         return self._pipeline_run_id
 
     @property
     def step_name(self) -> str:
-        """The name of the currently running step."""
+        """The name of the currently running step.
+
+        Returns:
+            The name of the currently running step.
+        """
         return self._step_name
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/__init__.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,20 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for step interfaces."""
+
+from zenml.steps.step_interfaces.base_alerter_step import (
+    BaseAlerterStep,
+    BaseAlerterStepConfig,
+)
 from zenml.steps.step_interfaces.base_analyzer_step import (
     BaseAnalyzerConfig,
     BaseAnalyzerStep,
 )
 from zenml.steps.step_interfaces.base_datasource_step import (
     BaseDatasourceConfig,
     BaseDatasourceStep,
@@ -51,8 +57,10 @@
     "BaseEvaluatorStep",
     "BasePreprocessorConfig",
     "BasePreprocessorStep",
     "BaseSplitStep",
     "BaseSplitStepConfig",
     "BaseTrainerStep",
     "BaseTrainerConfig",
+    "BaseAlerterStep",
+    "BaseAlerterStepConfig",
 ]
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_analyzer_step.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_analyzer_step.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,31 +7,41 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base analyzer step."""
 
 from abc import abstractmethod
 
 from zenml.artifacts import DataArtifact, SchemaArtifact, StatisticsArtifact
 from zenml.steps import BaseStep, BaseStepConfig, Output, StepContext
 
 
 class BaseAnalyzerConfig(BaseStepConfig):
-    """Base class for analyzer step configurations"""
+    """Base class for analyzer step configurations."""
 
 
 class BaseAnalyzerStep(BaseStep):
-    """Base step implementation for any analyzer step implementation on ZenML"""
+    """Base step implementation for any analyzer step implementation."""
 
     @abstractmethod
     def entrypoint(  # type: ignore[override]
         self,
         dataset: DataArtifact,
         config: BaseAnalyzerConfig,
         context: StepContext,
     ) -> Output(  # type:ignore[valid-type]
         statistics=StatisticsArtifact, schema=SchemaArtifact
     ):
-        """Base entrypoint for any analyzer implementation"""
+        """Base entrypoint for any analyzer implementation.
+
+        Args:
+            dataset: The dataset to analyze.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            The statistics and the schema of the given dataset.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_datasource_step.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_evaluator_step.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,28 +7,41 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base Evaluator step."""
 
 from abc import abstractmethod
 
-from zenml.artifacts import DataArtifact
+from zenml.artifacts import DataArtifact, ModelArtifact
 from zenml.steps import BaseStep, BaseStepConfig, StepContext
 
 
-class BaseDatasourceConfig(BaseStepConfig):
-    """Base class for datasource configs to inherit from"""
+class BaseEvaluatorConfig(BaseStepConfig):
+    """Base class for evaluator step configurations."""
 
 
-class BaseDatasourceStep(BaseStep):
-    """Base step implementation for any datasource step implementation on ZenML"""
+class BaseEvaluatorStep(BaseStep):
+    """Base step implementation for any evaluator step implementation."""
 
     @abstractmethod
     def entrypoint(  # type: ignore[override]
         self,
-        config: BaseDatasourceConfig,
+        dataset: DataArtifact,
+        model: ModelArtifact,
+        config: BaseEvaluatorConfig,
         context: StepContext,
     ) -> DataArtifact:
-        """Base entrypoint for any datasource implementation"""
+        """Base entrypoint for any evaluator implementation.
+
+        Args:
+            dataset: The dataset.
+            model: The model.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            The result of the evaluator.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_drift_detection_step.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_drift_detection_step.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,32 +7,42 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base drift detection step."""
 
 from abc import abstractmethod
 from typing import Any
 
 from zenml.artifacts import DataArtifact
 from zenml.steps import BaseStep, BaseStepConfig, StepContext
 
 
 class BaseDriftDetectionConfig(BaseStepConfig):
-    """Base class for drift detection step configurations"""
+    """Base class for drift detection step configurations."""
 
 
 class BaseDriftDetectionStep(BaseStep):
-    """Base step implementation for any drift detection step implementation
-    on ZenML"""
+    """Base step implementation for any drift detection step implementation."""
 
     @abstractmethod
     def entrypoint(  # type: ignore[override]
         self,
         reference_dataset: DataArtifact,
         comparison_dataset: DataArtifact,
         config: BaseDriftDetectionConfig,
         context: StepContext,
     ) -> Any:
-        """Base entrypoint for any drift detection implementation"""
+        """Base entrypoint for any drift detection implementation.
+
+        Args:
+            reference_dataset: The reference dataset.
+            comparison_dataset: The comparison dataset.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            The result of the drift detection.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_evaluator_step.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_trainer_step.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,30 +7,41 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base trainer step."""
 
 from abc import abstractmethod
 
 from zenml.artifacts import DataArtifact, ModelArtifact
 from zenml.steps import BaseStep, BaseStepConfig, StepContext
 
 
-class BaseEvaluatorConfig(BaseStepConfig):
-    """Base class for evaluator step configurations"""
+class BaseTrainerConfig(BaseStepConfig):
+    """Base class for Trainer step configurations."""
 
 
-class BaseEvaluatorStep(BaseStep):
-    """Base step implementation for any evaluator step implementation on ZenML"""
+class BaseTrainerStep(BaseStep):
+    """Base step implementation for any Trainer step implementation."""
 
     @abstractmethod
     def entrypoint(  # type: ignore[override]
         self,
-        dataset: DataArtifact,
-        model: ModelArtifact,
-        config: BaseEvaluatorConfig,
+        train_dataset: DataArtifact,
+        validation_dataset: DataArtifact,
+        config: BaseTrainerConfig,
         context: StepContext,
-    ) -> DataArtifact:
-        """Base entrypoint for any evaluator implementation"""
+    ) -> ModelArtifact:
+        """Base entrypoint for any Trainer implementation.
+
+        Args:
+            train_dataset: The training dataset.
+            validation_dataset: The validation dataset.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            The trained model.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_preprocessor_step.py` & `zenml-0.9.0/src/zenml/steps/step_interfaces/base_split_step.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,38 +7,41 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base split step."""
 
 from abc import abstractmethod
 
-from zenml.artifacts import DataArtifact, SchemaArtifact, StatisticsArtifact
+from zenml.artifacts import DataArtifact
 from zenml.steps import BaseStep, BaseStepConfig, Output, StepContext
 
 
-class BasePreprocessorConfig(BaseStepConfig):
-    """Base class for Preprocessor step configurations"""
+class BaseSplitStepConfig(BaseStepConfig):
+    """Base class for split configs to inherit from."""
 
 
-class BasePreprocessorStep(BaseStep):
-    """Base step implementation for any Preprocessor step implementation on
-    ZenML"""
+class BaseSplitStep(BaseStep):
+    """Base step implementation for any split step implementation."""
 
     @abstractmethod
     def entrypoint(  # type: ignore[override]
         self,
-        train_dataset: DataArtifact,
-        test_dataset: DataArtifact,
-        validation_dataset: DataArtifact,
-        statistics: StatisticsArtifact,
-        schema: SchemaArtifact,
-        config: BasePreprocessorConfig,
+        dataset: DataArtifact,
+        config: BaseSplitStepConfig,
         context: StepContext,
     ) -> Output(  # type:ignore[valid-type]
-        train_transformed=DataArtifact,
-        test_transformed=DataArtifact,
-        validation_transformed=DataArtifact,
+        train=DataArtifact, test=DataArtifact, validation=DataArtifact
     ):
-        """Base entrypoint for any Preprocessor implementation"""
+        """Entrypoint for a function for the split steps to run.
+
+        Args:
+            dataset: The dataset to split.
+            config: The configuration for the step.
+            context: The context for the step.
+
+        Returns:
+            The split datasets.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_split_step.py` & `zenml-0.9.0/src/zenml/visualizers/base_visualizer.py`

 * *Files 25% similar despite different names*

```diff
@@ -7,30 +7,29 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-from abc import abstractmethod
+"""Implementation of the base class for all ZenML visualizers."""
 
-from zenml.artifacts import DataArtifact
-from zenml.steps import BaseStep, BaseStepConfig, Output, StepContext
+from abc import abstractmethod
+from typing import Any
 
+from zenml.logger import get_logger
 
-class BaseSplitStepConfig(BaseStepConfig):
-    """Base class for split configs to inherit from"""
+logger = get_logger(__name__)
 
 
-class BaseSplitStep(BaseStep):
-    """Base step implementation for any split step implementation on ZenML"""
+class BaseVisualizer:
+    """Base class for all ZenML Visualizers."""
 
     @abstractmethod
-    def entrypoint(  # type: ignore[override]
-        self,
-        dataset: DataArtifact,
-        config: BaseSplitStepConfig,
-        context: StepContext,
-    ) -> Output(  # type:ignore[valid-type]
-        train=DataArtifact, test=DataArtifact, validation=DataArtifact
-    ):
-        """Entrypoint for a function for the split steps to run"""
+    def visualize(self, object: Any, *args: Any, **kwargs: Any) -> None:
+        """Method to visualize objects.
+
+        Args:
+            object: The object to visualize.
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_interfaces/base_trainer_step.py` & `zenml-0.9.0/src/zenml/secret/schemas/basic_auth_secret_schema.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,37 +1,35 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Basic Authentication Secret Schema definition."""
 
-from abc import abstractmethod
+from typing import ClassVar
 
-from zenml.artifacts import DataArtifact, ModelArtifact
-from zenml.steps import BaseStep, BaseStepConfig, StepContext
+from zenml.secret.base_secret import BaseSecretSchema
 
+BASIC_AUTH_SCHEMA_TYPE = "basic_auth"
 
-class BaseTrainerConfig(BaseStepConfig):
-    """Base class for Trainer step configurations"""
 
+class BasicAuthSecretSchema(BaseSecretSchema):
+    """Secret schema for basic authentication.
 
-class BaseTrainerStep(BaseStep):
-    """Base step implementation for any Trainer step implementation on
-    ZenML"""
+    Attributes:
+        username: The username that should be used for authentication.
+        password: The password that should be used for authentication.
+    """
 
-    @abstractmethod
-    def entrypoint(  # type: ignore[override]
-        self,
-        train_dataset: DataArtifact,
-        validation_dataset: DataArtifact,
-        config: BaseTrainerConfig,
-        context: StepContext,
-    ) -> ModelArtifact:
-        """Base entrypoint for any Trainer implementation"""
+    username: str
+    password: str
+
+    # Class configuration
+    TYPE: ClassVar[str] = BASIC_AUTH_SCHEMA_TYPE
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/step_output.py` & `zenml-0.9.0/src/zenml/steps/step_output.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,22 +7,32 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Step output class."""
 
 from typing import Any, Iterator, NamedTuple, Tuple, Type
 
 
 class Output(object):
     """A named tuple with a default name that cannot be overridden."""
 
     def __init__(self, **kwargs: Type[Any]):
+        """Initializes the output.
+
+        Args:
+            **kwargs: The output values.
+        """
         # TODO [ENG-161]: do we even need the named tuple here or is
         #  a list of tuples (name, Type) sufficient?
         self.outputs = NamedTuple("ZenOutput", **kwargs)  # type: ignore[misc]
 
     def items(self) -> Iterator[Tuple[str, Type[Any]]]:
-        """Yields a tuple of type (output_name, output_type)."""
+        """Yields a tuple of type (output_name, output_type).
+
+        Yields:
+            A tuple of type (output_name, output_type).
+        """
         yield from self.outputs.__annotations__.items()
```

### Comparing `zenml-0.8.1rc0/src/zenml/steps/utils.py` & `zenml-0.9.0/src/zenml/steps/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,16 @@
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
 
-"""
+"""Utility functions for Steps.
+
 The collection of utility functions/classes are inspired by their original
 implementation of the Tensorflow Extended team, which can be found here:
 
 https://github.com/tensorflow/tfx/blob/master/tfx/dsl/component/experimental
 /decorators.py
 
 This version is heavily adjusted to work with the Pipeline-Step paradigm which
@@ -98,14 +99,20 @@
 def resolve_type_annotation(obj: Any) -> Any:
     """Returns the non-generic class for generic aliases of the typing module.
 
     If the input is no generic typing alias, the input itself is returned.
 
     Example: if the input object is `typing.Dict`, this method will return the
     concrete class `dict`.
+
+    Args:
+        obj: The object to resolve.
+
+    Returns:
+        The non-generic class for generic aliases of the typing module.
     """
     from typing import _GenericAlias  # type: ignore[attr-defined]
 
     if sys.version_info >= (3, 8):
         return typing.get_origin(obj) or obj
     else:
         # python 3.7
@@ -211,14 +218,15 @@
             "__module__": step_module,
         },
     )
 
 
 class _PropertyDictWrapper(json_utils.Jsonable):
     """Helper class to wrap inputs/outputs from TFX nodes.
+
     Currently, this class is read-only (setting properties is not implemented).
     Internal class: no backwards compatibility guarantees.
     Code Credit: https://github.com/tensorflow/tfx/blob
     /51946061ae3be656f1718a3d62cd47228b89b8f4/tfx/types/node_common.py
     """
 
     def __init__(
@@ -232,64 +240,109 @@
             data: The data to be wrapped.
             compat_aliases: Compatibility aliases to support deprecated keys.
         """
         self._data = data
         self._compat_aliases = compat_aliases or {}
 
     def __iter__(self) -> Iterator[str]:
-        """Returns a generator that yields keys of the wrapped dictionary."""
+        """Returns a generator that yields keys of the wrapped dictionary.
+
+        Yields:
+            Keys of the wrapped dictionary.
+        """
         yield from self._data
 
     def __getitem__(self, key: str) -> Channel:
-        """Returns the dictionary value for the specified key."""
+        """Returns the dictionary value for the specified key.
+
+        Args:
+            key: The key to look up.
+
+        Returns:
+            The dictionary value for the specified key.
+        """
         if key in self._compat_aliases:
             key = self._compat_aliases[key]
         return self._data[key]
 
     def __getattr__(self, key: str) -> Channel:
-        """Returns the dictionary value for the specified key."""
+        """Returns the dictionary value for the specified key.
+
+        Args:
+            key: The key to look up.
+
+        Returns:
+            The dictionary value for the specified key.
+
+        Raises:
+            AttributeError: If the key is not found.
+        """
         if key in self._compat_aliases:
             key = self._compat_aliases[key]
         try:
             return self._data[key]
         except KeyError:
             raise AttributeError
 
     def __repr__(self) -> str:
-        """Returns the representation of the wrapped dictionary."""
+        """Returns the representation of the wrapped dictionary.
+
+        Returns:
+            The representation of the wrapped dictionary.
+        """
         return repr(self._data)
 
     def get_all(self) -> Dict[str, Channel]:
-        """Returns the wrapped dictionary."""
+        """Returns the wrapped dictionary.
+
+        Returns:
+            The wrapped dictionary.
+        """
         return self._data
 
     def keys(self) -> KeysView[str]:
-        """Returns the keys of the wrapped dictionary."""
+        """Returns the keys of the wrapped dictionary.
+
+        Returns:
+            The keys of the wrapped dictionary.
+        """
         return self._data.keys()
 
     def values(self) -> ValuesView[Channel]:
-        """Returns the values of the wrapped dictionary."""
+        """Returns the values of the wrapped dictionary.
+
+        Returns:
+            The values of the wrapped dictionary.
+        """
         return self._data.values()
 
     def items(self) -> ItemsView[str, Channel]:
-        """Returns the items of the wrapped dictionary."""
+        """Returns the items of the wrapped dictionary.
+
+        Returns:
+            The items of the wrapped dictionary.
+        """
         return self._data.items()
 
 
 class _ZenMLSimpleComponent(_SimpleComponent):
     """Simple ZenML TFX component with outputs overridden."""
 
     @property
     def outputs(self) -> _PropertyDictWrapper:  # type: ignore[override]
-        """Returns the wrapped spec outputs."""
+        """Returns the wrapped spec outputs.
+
+        Returns:
+            The wrapped spec outputs.
+        """
         return _PropertyDictWrapper(self.spec.outputs)
 
 
 class _FunctionExecutor(BaseExecutor):
-    """Base TFX Executor class which is compatible with ZenML steps"""
+    """Base TFX Executor class which is compatible with ZenML steps."""
 
     _FUNCTION = staticmethod(lambda: None)
     materializers: ClassVar[
         Optional[Dict[str, Type["BaseMaterializer"]]]
     ] = None
 
     def resolve_materializer_with_registry(
@@ -300,26 +353,30 @@
         Args:
             param_name: Name of param.
             artifact: A TFX artifact type.
 
         Returns:
             The right materializer based on the defaults or optionally the one
             set by the user.
+
+        Raises:
+            ValueError: If the materializer is not found.
         """
         if not self.materializers:
-            raise ValueError("Materializers are missing is not set!")
+            raise ValueError("Materializers are not set!")
 
         materializer_class = self.materializers[param_name]
         return materializer_class
 
     def resolve_input_artifact(
         self, artifact: BaseArtifact, data_type: Type[Any]
     ) -> Any:
-        """Resolves an input artifact, i.e., reading it from the Artifact Store
-        to a pythonic object.
+        """Resolves an input artifact.
+
+        This method reads it from the Artifact Store to a Pythonic object.
 
         Args:
             artifact: A TFX artifact type.
             data_type: The type of data to be materialized.
 
         Returns:
             Return the output of `handle_input()` of selected materializer.
@@ -340,16 +397,18 @@
         )(artifact)
         # The materializer now returns a resolved input
         return materializer.handle_input(data_type=data_type)
 
     def resolve_output_artifact(
         self, param_name: str, artifact: BaseArtifact, data: Any
     ) -> None:
-        """Resolves an output artifact, i.e., writing it to the Artifact Store.
-        Calls `handle_return(return_values)` of the selected materializer.
+        """Resolves an output artifact.
+
+        This writes it to the Artifact Store. Calls
+        `handle_return(return_values)` of the selected materializer.
 
         Args:
             param_name: Name of output param.
             artifact: A TFX artifact type.
             data: The object to be passed to `handle_return()`.
         """
         # Skip materialization for BaseArtifact and subclasses.
@@ -367,18 +426,18 @@
         self, output_value: Any, specified_type: Type[Any]
     ) -> None:
         """Raise error if types don't match.
 
         Args:
             output_value: Value of output.
             specified_type: What the type of output should be as defined in the
-            signature.
+                signature.
 
         Raises:
-            ValueError if types do not match.
+            ValueError: if types do not match.
         """
         # TODO [ENG-160]: Include this check when we figure out the logic of
         #  slightly different subclasses.
         if not do_types_match(type(output_value), specified_type):
             raise ValueError(
                 f"Output `{output_value}` of type {type(output_value)} does "
                 f"not match specified return type {specified_type} in step "
@@ -387,20 +446,25 @@
 
     def Do(
         self,
         input_dict: Dict[str, List[BaseArtifact]],
         output_dict: Dict[str, List[BaseArtifact]],
         exec_properties: Dict[str, Any],
     ) -> None:
-        """Main block for the execution of the step
+        """Main block for the execution of the step.
 
         Args:
             input_dict: dictionary containing the input artifacts
             output_dict: dictionary containing the output artifacts
             exec_properties: dictionary containing the execution parameters
+
+        Raises:
+            MissingStepParameterError: if a required parameter is missing.
+            RuntimeError: if the step fails.
+            StepInterfaceError: if the step interface is not implemented.
         """
         step_name = getattr(self, PARAM_STEP_NAME)
 
         # remove all ZenML internal execution properties
         exec_properties = {
             k: json.loads(v)
             for k, v in exec_properties.items()
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/analytics_utils.py` & `zenml-0.9.0/src/zenml/utils/analytics_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,28 +7,30 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""Analytics code for ZenML"""
+"""Analytics code for ZenML."""
 
 from enum import Enum
 from typing import Any, Callable, Dict, Optional, Union
 
 from zenml import __version__
 from zenml.constants import IS_DEBUG_ENV, SEGMENT_KEY_DEV, SEGMENT_KEY_PROD
 from zenml.environment import Environment, get_environment
 from zenml.logger import get_logger
 
 logger = get_logger(__name__)
 
 
 class AnalyticsEvent(str, Enum):
+    """Enum of events to track in segment."""
+
     # Pipelines
     RUN_PIPELINE = "Pipeline run"
     GET_PIPELINES = "Pipelines fetched"
     GET_PIPELINE = "Pipeline fetched"
 
     # Repo
     INITIALIZE_REPO = "ZenML initialized"
@@ -41,14 +43,15 @@
     UPDATED_STACK_COMPONENT = "Stack component updated"
 
     # Stack
     REGISTERED_STACK = "Stack registered"
     REGISTERED_DEFAULT_STACK = "Default stack registered"
     SET_STACK = "Stack set"
     UPDATED_STACK = "Stack updated"
+    COPIED_STACK = "Stack copied"
     IMPORT_STACK = "Stack imported"
     EXPORT_STACK = "Stack exported"
 
     # Analytics opt in and out
     OPT_IN_ANALYTICS = "Analytics opt-in"
     OPT_OUT_ANALYTICS = "Analytics opt-out"
 
@@ -93,18 +96,21 @@
     if IS_DEBUG_ENV:
         return SEGMENT_KEY_DEV
     else:
         return SEGMENT_KEY_PROD
 
 
 def identify_user(user_metadata: Optional[Dict[str, Any]] = None) -> bool:
-    """Attach metadata to user directly
+    """Attach metadata to user directly.
 
     Args:
-        metadata: Dict of metadata to attach to the user.
+        user_metadata: Dict of metadata to attach to the user.
+
+    Returns:
+        True if event is sent successfully, False is not.
     """
     # TODO [ENG-857]: The identify_user function shares a lot of setup with
     #  track_event() - this duplicated code could be given its own function
     try:
         from zenml.config.global_config import GlobalConfiguration
 
         gc = GlobalConfiguration()
@@ -142,16 +148,15 @@
         return False
 
 
 def track_event(
     event: Union[str, AnalyticsEvent],
     metadata: Optional[Dict[str, Any]] = None,
 ) -> bool:
-    """
-    Track segment event if user opted-in.
+    """Track segment event if user opted-in.
 
     Args:
         event: Name of event to track in segment.
         metadata: Dict of metadata to track.
 
     Returns:
         True if event is sent successfully, False is not.
@@ -212,24 +217,47 @@
         return False
 
 
 def parametrized(
     dec: Callable[..., Callable[..., Any]]
 ) -> Callable[..., Callable[[Callable[..., Any]], Callable[..., Any]]]:
     """This is a meta-decorator, that is, a decorator for decorators.
+
     As a decorator is a function, it actually works as a regular decorator
-    with arguments:"""
+    with arguments.
+
+    Args:
+        dec: Decorator to be applied to the function.
+
+    Returns:
+        Decorator that applies the given decorator to the function.
+    """
 
     def layer(
         *args: Any, **kwargs: Any
     ) -> Callable[[Callable[..., Any]], Callable[..., Any]]:
-        """Internal layer"""
+        """Internal layer.
+
+        Args:
+            *args: Arguments to be passed to the decorator.
+            **kwargs: Keyword arguments to be passed to the decorator.
+
+        Returns:
+            Decorator that applies the given decorator to the function.
+        """
 
         def repl(f: Callable[..., Any]) -> Callable[..., Any]:
-            """Internal repl"""
+            """Internal REPL.
+
+            Args:
+                f: Function to be decorated.
+
+            Returns:
+                Decorated function.
+            """
             return dec(f, *args, **kwargs)
 
         return repl
 
     return layer
 
 
@@ -239,21 +267,32 @@
     event: Optional[Union[str, AnalyticsEvent]] = None,
 ) -> Callable[..., Any]:
     """Decorator to track event.
 
     Args:
         func: Function that is decorated.
         event: Event string to stamp with.
+
+    Returns:
+        Decorated function.
     """
     # Need to redefine the name for the event here in order for mypy
     # to recognize it's not an optional string anymore
     # TODO [ENG-168]: open bug ticket and link here
     event_name = event or func.__name__  # default to name of function
     metadata: Dict[str, Any] = {}
 
     def inner_func(*args: Any, **kwargs: Any) -> Any:
-        """Inner decorator function."""
+        """Inner decorator function.
+
+        Args:
+            *args: Arguments to be passed to the function.
+            **kwargs: Keyword arguments to be passed to the function.
+
+        Returns:
+            Result of the function.
+        """
         track_event(event_name, metadata=metadata)
         result = func(*args, **kwargs)
         return result
 
     return inner_func
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/daemon.py` & `zenml-0.9.0/src/zenml/utils/daemon.py`

 * *Files 6% similar despite different names*

```diff
@@ -63,31 +63,37 @@
     sleeping_daemon(period=30)
 
     print("I'm the daemon's parent!.")
     time.sleep(10) # just to prove that the daemon is running in parallel
     ```
 
     Args:
-        _func: decorated function
         pid_file: an optional file where the PID of the daemon process will
             be stored.
         log_file: file where stdout and stderr are redirected for the daemon
             process. If not supplied, the daemon will be silenced (i.e. have
             its stdout/stderr redirected to /dev/null).
         working_directory: working directory for the daemon process,
             defaults to the root directory.
+
     Returns:
         Decorated function that, when called, will detach from the current
         process and continue executing in the background, as a daemon
         process.
     """
 
     def inner_decorator(_func: F) -> F:
         def daemon(*args: Any, **kwargs: Any) -> None:
-            """Standard daemonization of a process."""
+            """Standard daemonization of a process.
+
+            Args:
+                *args: Arguments to be passed to the decorated function.
+                **kwargs: Keyword arguments to be passed to the decorated
+                    function.
+            """
             # flake8: noqa: C901
             if sys.platform == "win32":
                 logger.error(
                     "Daemon functionality is currently not supported on Windows."
                 )
             else:
                 run_as_daemon(
@@ -110,17 +116,15 @@
         "Daemon functionality is currently not supported on Windows."
     )
 else:
 
     CHILD_PROCESS_WAIT_TIMEOUT = 5
 
     def terminate_children() -> None:
-        """Terminate all processes that are children of the currently running
-        process.
-        """
+        """Terminate all processes that are children of the currently running process."""
         pid = os.getpid()
         try:
             parent = psutil.Process(pid)
         except psutil.Error:
             # could not find parent process id
             return
         children = parent.children(recursive=False)
@@ -152,14 +156,15 @@
                 process.
             log_file: Optional file to which the daemons stdout/stderr will be
                 redirected to.
             working_directory: Working directory for the daemon process,
                 defaults to the root directory.
             args: Positional arguments to pass to the daemon function.
             kwargs: Keyword arguments to pass to the daemon function.
+
         Raises:
             FileExistsError: If the PID file already exists.
         """
         # convert to absolute path as we will change working directory later
         if pid_file:
             pid_file = os.path.abspath(pid_file)
         if log_file:
@@ -234,15 +239,20 @@
         def cleanup() -> None:
             """Daemon cleanup."""
             terminate_children()
             if pid_file and os.path.exists(pid_file):
                 os.remove(pid_file)
 
         def sighndl(signum: int, frame: Optional[types.FrameType]) -> None:
-            """Daemon signal handler."""
+            """Daemon signal handler.
+
+            Args:
+                signum: Signal number.
+                frame: Frame object.
+            """
             cleanup()
 
         signal.signal(signal.SIGTERM, sighndl)
         signal.signal(signal.SIGINT, sighndl)
         atexit.register(cleanup)
 
         # finally run the actual daemon code
@@ -266,20 +276,22 @@
         if psutil.pid_exists(pid):
             process = psutil.Process(pid)
             process.terminate()
         else:
             logger.warning("PID from '%s' does not exist.", pid_file)
 
     def get_daemon_pid_if_running(pid_file: str) -> Optional[int]:
-        """Read and return the PID value from a PID file if the daemon process
-        tracked by the PID file is running.
+        """Read and return the PID value from a PID file.
+
+        It does this if the daemon process tracked by the PID file is running.
 
         Args:
             pid_file: Path to file containing the PID of the daemon
                 process to check.
+
         Returns:
             The PID of the daemon process if it is running, otherwise None.
         """
         try:
             with open(pid_file, "r") as f:
                 pid = int(f.read().strip())
         except (IOError, FileNotFoundError):
@@ -292,9 +304,12 @@
 
     def check_if_daemon_is_running(pid_file: str) -> bool:
         """Checks whether a daemon process indicated by the PID file is running.
 
         Args:
             pid_file: Path to file containing the PID of the daemon
                 process to check.
+
+        Returns:
+            True if the daemon process is running, otherwise False.
         """
         return get_daemon_pid_if_running(pid_file) is not None
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/docker_utils.py` & `zenml-0.9.0/src/zenml/utils/docker_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,38 +7,47 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions relating to Docker."""
+
 import json
 import os
 from typing import AbstractSet, Any, Dict, Iterable, List, Optional, cast
 
 import pkg_resources
 from docker.client import DockerClient
 from docker.utils import build as docker_build_utils
 
 import zenml
 from zenml.config.global_config import GlobalConfiguration
 from zenml.constants import ENV_ZENML_CONFIG_PATH
 from zenml.io import fileio
-from zenml.io.utils import read_file_contents_as_string
 from zenml.logger import get_logger
 from zenml.utils import string_utils
+from zenml.utils.io_utils import read_file_contents_as_string
 
 DEFAULT_BASE_IMAGE = f"zenmldocker/zenml:{zenml.__version__}"
 CONTAINER_ZENML_CONFIG_DIR = ".zenconfig"
 
 logger = get_logger(__name__)
 
 
 def _parse_dockerignore(dockerignore_path: str) -> List[str]:
-    """Parses a dockerignore file and returns a list of patterns to ignore."""
+    """Parses a dockerignore file and returns a list of patterns to ignore.
+
+    Args:
+        dockerignore_path: Path to the dockerignore file.
+
+    Returns:
+        List of patterns to ignore.
+    """
     try:
         file_content = read_file_contents_as_string(dockerignore_path)
     except FileNotFoundError:
         logger.warning(
             "Unable to find dockerignore file at path '%s'.", dockerignore_path
         )
         return []
@@ -166,16 +175,22 @@
             default_dockerignore_path,
         )
 
     return context
 
 
 def get_current_environment_requirements() -> Dict[str, str]:
-    """Returns a dict of package requirements for the environment that
-    the current python process is running in."""
+    """Returns a dict of package requirements.
+
+    This applies to the environment that in which the current python process is
+    running.
+
+    Returns:
+        A dict of package requirements.
+    """
     return {
         distribution.key: distribution.version
         for distribution in pkg_resources.working_set
     }
 
 
 def build_docker_image(
@@ -317,15 +332,22 @@
             image_name,
             repo_digests,
         )
         return None
 
 
 def is_local_image(image_name: str) -> bool:
-    """Returns whether an image was pulled from a registry or not."""
+    """Returns whether an image was pulled from a registry or not.
+
+    Args:
+        image_name: Name of the image to check.
+
+    Returns:
+        `True` if the image was pulled from a registry, `False` otherwise.
+    """
     docker_client = DockerClient.from_env()
     images = docker_client.images.list(name=image_name)
     if images:
         # An image with this name is available locally -> now check whether it
         # was pulled from a repo or built locally (in which case the repo
         # digest is empty)
         return get_image_digest(image_name) is None
@@ -333,19 +355,20 @@
         # no image with this name found locally
         return False
 
 
 def _process_stream(stream: Iterable[bytes]) -> None:
     """Processes the output stream of a docker command call.
 
+    Args:
+        stream: The output stream of a docker command call.
+
     Raises:
-        JSONDecodeError: If a line in the stream is not json decodable.
         RuntimeError: If there was an error while running the docker command.
     """
-
     for element in stream:
         lines = element.decode("utf-8").strip().split("\n")
 
         for line in lines:
             try:
                 line_json = json.loads(line)
                 if "error" in line_json:
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/enum_utils.py` & `zenml-0.9.0/src/zenml/utils/enum_utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,28 +7,41 @@
 #       http://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Util functions for enums."""
 
 from enum import Enum
 from typing import List
 
 
 class StrEnum(str, Enum):
-    """Base enum type for string enum values"""
+    """Base enum type for string enum values."""
 
     def __str__(self) -> str:
-        """Returns the enum string value."""
+        """Returns the enum string value.
+
+        Returns:
+            The enum string value.
+        """
         return self.value  # type: ignore
 
     @classmethod
     def names(cls) -> List[str]:
-        """Get all enum names as a list of strings"""
+        """Get all enum names as a list of strings.
+
+        Returns:
+            A list of all enum names.
+        """
         return [c.name for c in cls]
 
     @classmethod
     def values(cls) -> List[str]:
-        """Get all enum values as a list of strings"""
+        """Get all enum values as a list of strings.
+
+        Returns:
+            A list of all enum values.
+        """
         return [c.value for c in cls]
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/filesync_model.py` & `zenml-0.9.0/src/zenml/utils/filesync_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Filesync utils for ZenML."""
+
 import json
 import os
 from typing import Any, Optional
 
 from pydantic import BaseModel
 
 from zenml.io import fileio
@@ -35,16 +37,15 @@
     information stored in the associated configuration file.
     """
 
     _config_file: str
     _config_file_timestamp: Optional[float]
 
     def __init__(self, config_file: str, **kwargs: Any) -> None:
-        """Create a FileSyncModel instance synchronized with a configuration
-        file on disk.
+        """Create a FileSyncModel instance synchronized with a configuration file on disk.
 
         Args:
             config_file: configuration file path. If the file exists, the model
                 will be initialized with the values from the file.
             **kwargs: additional keyword arguments to pass to the Pydantic model
                 constructor. If supplied, these values will override those
                 loaded from the configuration file.
@@ -60,25 +61,34 @@
         super(FileSyncModel, self).__init__(**config_dict)
 
         # write the configuration file to disk, to reflect new attributes
         # and schema changes
         self.write_config()
 
     def __setattr__(self, key: str, value: Any) -> None:
-        """Sets an attribute on the model and persists the new value in the
-        configuration file.
+        """Sets an attribute on the model and persists it in the configuration file.
 
+        Args:
+            key: attribute name.
+            value: attribute value.
         """
         super(FileSyncModel, self).__setattr__(key, value)
         if key.startswith("_"):
             return
         self.write_config()
 
     def __getattribute__(self, key: str) -> Any:
-        """Gets an attribute value for a specific key."""
+        """Gets an attribute value for a specific key.
+
+        Args:
+            key: attribute name.
+
+        Returns:
+            attribute value.
+        """
         if not key.startswith("_") and key in self.__dict__:
             self.load_config()
         return super(FileSyncModel, self).__getattribute__(key)
 
     def write_config(self) -> None:
         """Writes the model to the configuration file."""
         config_dict = json.loads(self.json())
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/networking_utils.py` & `zenml-0.9.0/src/zenml/utils/networking_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions for networking."""
+
 import socket
 from typing import Optional, cast
 
 from zenml.logger import get_logger
 
 logger = get_logger(__name__)
 
@@ -38,15 +40,19 @@
         logger.debug("Port %d unavailable: %s", port, e)
         return False
 
     return True
 
 
 def find_available_port() -> int:
-    """Finds a local random unoccupied TCP port."""
+    """Finds a local random unoccupied TCP port.
+
+    Returns:
+        A random unoccupied TCP port.
+    """
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
         s.bind(("127.0.0.1", 0))
         _, port = s.getsockname()
 
     return cast(int, port)
 
 
@@ -54,14 +60,15 @@
     start: int = SCAN_PORT_RANGE[0], stop: int = SCAN_PORT_RANGE[1]
 ) -> Optional[int]:
     """Scan the local network for an available port in the given range.
 
     Args:
         start: the beginning of the port range value to scan
         stop: the (inclusive) end of the port range value to scan
+
     Returns:
         The first available port in the given range, or None if no available
         port is found.
     """
     for port in range(start, stop + 1):
         if port_available(port):
             return port
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/secrets_manager_utils.py` & `zenml-0.9.0/src/zenml/secrets_managers/utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions for the ZenML secrets manager module."""
+
 import base64
 from typing import Dict, Tuple
 
 from zenml.constants import ZENML_SCHEMA_NAME
 from zenml.secret.base_secret import BaseSecretSchema
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/singleton.py` & `zenml-0.9.0/src/zenml/utils/singleton.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility class to turn classes into singleton classes."""
 
 from typing import Any, Optional, cast
 
 
 class SingletonMetaClass(type):
     """Singleton metaclass.
 
@@ -33,20 +34,33 @@
     the_lost_ring = OneRing('Frodo')
     print(the_lost_ring.owner)  # Sauron
     OneRing._clear() # ring destroyed
     ```
     """
 
     def __init__(cls, *args: Any, **kwargs: Any) -> None:
-        """Initialize a singleton class."""
+        """Initialize a singleton class.
+
+        Args:
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
+        """
         super().__init__(*args, **kwargs)
         cls.__singleton_instance: Optional["SingletonMetaClass"] = None
 
     def __call__(cls, *args: Any, **kwargs: Any) -> "SingletonMetaClass":
-        """Create or return the singleton instance."""
+        """Create or return the singleton instance.
+
+        Args:
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
+
+        Returns:
+            The singleton instance.
+        """
         if not cls.__singleton_instance:
             cls.__singleton_instance = cast(
                 "SingletonMetaClass", super().__call__(*args, **kwargs)
             )
 
         return cls.__singleton_instance
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/source_utils.py` & `zenml-0.9.0/src/zenml/utils/source_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Utility functions for source code.
+
 These utils are predicated on the following definitions:
 
 * class_source: This is a python-import type path to a class, e.g.
     some.mod.class
 * module_source: This is a python-import type path to a module, e.g. some.mod
 * file_path, relative_path, absolute_path: These are file system paths.
 * source: This is a class_source or module_source. If it is a class_source, it
@@ -53,88 +54,126 @@
 
 
 def is_standard_pin(pin: str) -> bool:
     """Returns `True` if pin is valid ZenML pin, else False.
 
     Args:
         pin: potential ZenML pin like 'zenml_0.1.1'
+
+    Returns:
+        `True` if pin is valid ZenML pin, else False.
     """
     if pin.startswith(f"{APP_NAME}_"):
         return True
     return False
 
 
 def is_inside_repository(file_path: str) -> bool:
-    """Returns whether a file is inside a zenml repository."""
+    """Returns whether a file is inside a zenml repository.
+
+    Args:
+        file_path: A file path.
+
+    Returns:
+        `True` if the file is inside a zenml repository, else `False`.
+    """
     from zenml.repository import Repository
 
     repo_path = Repository.find_repository()
     if not repo_path:
         return False
 
     repo_path = repo_path.resolve()
     absolute_file_path = pathlib.Path(file_path).resolve()
     return repo_path in absolute_file_path.parents
 
 
 def is_third_party_module(file_path: str) -> bool:
-    """Returns whether a file belongs to a third party package."""
+    """Returns whether a file belongs to a third party package.
+
+    Args:
+        file_path: A file path.
+
+    Returns:
+        `True` if the file belongs to a third party package, else `False`.
+    """
     absolute_file_path = pathlib.Path(file_path).resolve()
 
     for path in site.getsitepackages() + [site.getusersitepackages()]:
         if pathlib.Path(path).resolve() in absolute_file_path.parents:
             return True
 
     return False
 
 
 def create_zenml_pin() -> str:
-    """Creates a ZenML pin for source pinning from release version."""
+    """Creates a ZenML pin for source pinning from release version.
+
+    Returns:
+        ZenML pin.
+    """
     return f"{APP_NAME}_{__version__}"
 
 
 def resolve_standard_source(source: str) -> str:
     """Creates a ZenML pin for source pinning from release version.
 
     Args:
         source: class_source e.g. this.module.Class.
+
+    Returns:
+        ZenML pin.
+
+    Raises:
+        AssertionError: If source is already pinned.
     """
     if "@" in source:
         raise AssertionError(f"source {source} is already pinned.")
     pin = create_zenml_pin()
     return f"{source}@{pin}"
 
 
 def is_standard_source(source: str) -> bool:
     """Returns `True` if source is a standard ZenML source.
 
     Args:
         source: class_source e.g. this.module.Class[@pin].
+
+    Returns:
+        `True` if source is a standard ZenML source, else `False`.
     """
     if source.split(".")[0] == "zenml":
         return True
     return False
 
 
 def get_class_source_from_source(source: str) -> str:
     """Gets class source from source, i.e. module.path@version, returns version.
 
     Args:
         source: source pointing to potentially pinned sha.
+
+    Returns:
+        class_source e.g. this.module.Class.
     """
     # source need not even be pinned
     return source.split("@")[0]
 
 
 def get_module_source_from_source(source: str) -> str:
-    """Gets module source from source. E.g. `some.module.file.class@version`,
-    returns `some.module`.
+    """Gets module source from source.
+
+    For example `some.module.file.class@version` would
+    return `some.module`.
 
     Args:
         source: source pointing to potentially pinned sha.
+
+    Returns:
+        module_source e.g. some.module.
     """
     class_source = get_class_source_from_source(source)
     return ".".join(class_source.split(".")[:-2])
 
 
 def get_module_source_from_module(module: ModuleType) -> str:
     """Gets the source of the supplied module.
@@ -189,15 +228,15 @@
         )
 
     # Remove root_path from module_path to get relative path left over
     module_path = module_path.replace(root_path, "")[1:]
 
     # Kick out the .py and replace `/` with `.` to get the module source
     module_path = module_path.replace(".py", "")
-    module_source = module_path.replace("/", ".")
+    module_source = module_path.replace(os.path.sep, ".")
 
     logger.debug(
         f"Resolved module source for module {module} to: {module_source}"
     )
 
     return module_source
 
@@ -205,45 +244,53 @@
 def get_relative_path_from_module_source(module_source: str) -> str:
     """Get a directory path from module, relative to root of the package tree.
 
     E.g. zenml.core.step will return zenml/core/step.
 
     Args:
         module_source: A module e.g. zenml.core.step
+
+    Returns:
+        A relative path e.g. zenml/core/step.
     """
-    return module_source.replace(".", "/")
+    return module_source.replace(".", os.path.sep)
 
 
 def get_absolute_path_from_module_source(module: str) -> str:
     """Get a directory path from module source.
 
     E.g. `zenml.core.step` will return `full/path/to/zenml/core/step`.
 
     Args:
         module: A module e.g. `zenml.core.step`.
+
+    Returns:
+        An absolute path e.g. `full/path/to/zenml/core/step`.
     """
     mod = importlib.import_module(module)
     return mod.__path__[0]
 
 
 def get_source_root_path() -> str:
-    """Get the repository root path or the source root path of the current
-    process.
+    """Gets repository root path or the source root path of the current process.
 
     E.g.:
 
       * if the process was started by running a `run.py` file under
       `full/path/to/my/run.py`, and the repository root is configured at
       `full/path`, the source root path is `full/path`.
 
       * same case as above, but when there is no repository root configured,
       the source root path is `full/path/to/my`.
 
     Returns:
         The source root path of the current process.
+
+    Raises:
+        RuntimeError: if the main module was not started or determined.
     """
     from zenml.repository import Repository
 
     repo_root = Repository.find_repository()
     if repo_root:
         logger.debug("Using repository root as source root: %s", repo_root)
         return str(repo_root.resolve())
@@ -265,37 +312,48 @@
     logger.debug("Using main module location as source root: %s", path)
     return str(path)
 
 
 def get_module_source_from_class(
     class_: Union[Type[Any], str]
 ) -> Optional[str]:
-    """Takes class input and returns module_source. If class is already string
-    then returns the same.
+    """Takes class input and returns module_source.
+
+    If class is already string then returns the same.
 
     Args:
         class_: object of type class.
+
+    Returns:
+        module_source of class.
+
+    Raises:
+        AssertionError: if step_type is neither a class nor a string.
     """
     if isinstance(class_, str):
         module_source = class_
     else:
         # Infer it from the class provided
         if not inspect.isclass(class_):
             raise AssertionError("step_type is neither string nor class.")
         module_source = class_.__module__ + "." + class_.__name__
     return module_source
 
 
 def get_source(value: Any) -> str:
-    """Returns the source code of an object. If executing within a IPython
-    kernel environment, then this monkey-patches `inspect` module temporarily
-    with a workaround to get source from the cell.
+    """Returns the source code of an object.
 
-    Raises:
-        TypeError: If source not found.
+    If executing within a IPython kernel environment, then this monkey-patches
+    `inspect` module temporarily with a workaround to get source from the cell.
+
+    Args:
+        value: object to get source from.
+
+    Returns:
+        Source code of object.
     """
     if Environment.in_notebook():
         # Monkey patch inspect.getfile temporarily to make getsource work.
         # Source: https://stackoverflow.com/questions/51566497/
         def _new_getfile(
             object: Any,
             _old_getfile: Callable[
@@ -344,15 +402,25 @@
     else:
         # Use standard inspect if running outside a notebook
         src = inspect.getsource(value)
     return src
 
 
 def get_hashed_source(value: Any) -> str:
-    """Returns a hash of the objects source code."""
+    """Returns a hash of the objects source code.
+
+    Args:
+        value: object to get source from.
+
+    Returns:
+        Hash of source code.
+
+    Raises:
+        TypeError: If unable to compute the hash.
+    """
     try:
         source_code = get_source(value)
     except TypeError:
         raise TypeError(
             f"Unable to compute the hash of source code of object: {value}."
         )
     return hashlib.sha256(source_code.encode("utf-8")).hexdigest()
@@ -364,15 +432,16 @@
     For classes that are not built-in nor imported from a Python package, the
     `get_source_root_path` function is used to determine the root path
     relative to which the class source is resolved.
 
     Args:
         class_: A Python Class reference.
 
-    Returns: source_path e.g. this.module.Class.
+    Returns:
+        source_path e.g. this.module.Class.
     """
     initial_source = class_.__module__ + "." + class_.__name__
     if is_standard_source(initial_source):
         return resolve_standard_source(initial_source)
 
     try:
         file_path = inspect.getfile(class_)
@@ -396,30 +465,37 @@
 
     logger.debug(f"Resolved class {class_} to {module_source}")
 
     return module_source + "." + class_.__name__
 
 
 def import_class_by_path(class_path: str) -> Type[Any]:
-    """Imports a class based on a given path
+    """Imports a class based on a given path.
 
     Args:
         class_path: str, class_source e.g. this.module.Class
 
-    Returns: the given class
+    Returns:
+        the given class
     """
-    classname = class_path.split(".")[-1]
-    modulename = ".".join(class_path.split(".")[0:-1])
+    modulename, classname = class_path.rsplit(".", 1)
     mod = importlib.import_module(modulename)
     return getattr(mod, classname)  # type: ignore[no-any-return]
 
 
 @contextmanager
 def prepend_python_path(path: str) -> Iterator[None]:
-    """Simple context manager to help import module within the repo"""
+    """Simple context manager to help import module within the repo.
+
+    Args:
+        path: str, path to prepend to sys.path
+
+    Yields:
+        None
+    """
     try:
         # Entering the with statement
         sys.path.insert(0, path)
         yield
     finally:
         # Exiting the with statement
         sys.path.remove(path)
@@ -429,14 +505,17 @@
     source: str, import_path: Optional[str] = None
 ) -> Type[Any]:
     """Loads a Python class from the source.
 
     Args:
         source: class_source e.g. this.module.Class[@sha]
         import_path: optional path to add to python path
+
+    Returns:
+        the given class
     """
     from zenml.repository import Repository
 
     repo_root = Repository.find_repository()
     if not import_path and repo_root:
         import_path = str(repo_root)
 
@@ -467,44 +546,46 @@
 
     # In case the module is already fully or partially imported and the module
     #  path is something like materializer.materializer the full path needs to
     #  be checked for in the sys.modules to avoid getting an empty namespace
     #  module
     full_module_path = os.path.splitext(
         os.path.relpath(file_path, os.getcwd())
-    )[0].replace("/", ".")
+    )[0].replace(os.path.sep, ".")
 
     if full_module_path not in sys.modules:
         with prepend_python_path(os.path.dirname(file_path)):
             module = importlib.import_module(module_name)
         return module
     else:
         return sys.modules[full_module_path]
 
 
 def validate_flavor_source(
     source: str, component_type: StackComponentType
 ) -> Type[StackComponent]:
-    """Utility function to import a StackComponent class from a given source
-    and validate its type.
+    """Utility function to import a StackComponent class from a given source and validate its type.
 
     Args:
         source: source path of the implementation
         component_type: the type of the stack component
 
+    Returns:
+        the imported class
+
     Raises:
         ValueError: If ZenML cannot find the given module path
         TypeError: If the given module path does not point to a subclass of a
             StackComponent which has the right component type.
     """
     try:
         stack_component_class = load_source_path_class(source)
-    except (ValueError, AttributeError, ImportError):
+    except (ValueError, AttributeError, ImportError) as e:
         raise ValueError(
-            f"ZenML can not import the source '{source}' of the given module."
+            f"ZenML can not import the flavor class '{source}': {e}"
         )
 
     if not issubclass(stack_component_class, StackComponent):
         raise TypeError(
             f"The source '{source}' does not point to a subclass of the ZenML"
             f"StackComponent."
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/typed_model.py` & `zenml-0.9.0/src/zenml/utils/typed_model.py`

 * *Files 13% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility classes for adding type information to Pydantic models."""
+
 import json
 from typing import Any, Dict, Tuple, Type, cast
 
 from pydantic import BaseModel, Field
 from pydantic.main import ModelMetaclass
 from typing_extensions import Literal
 
@@ -23,16 +25,31 @@
 
 class BaseTypedModelMeta(ModelMetaclass):
     """Metaclass responsible for adding type information to Pydantic models."""
 
     def __new__(
         mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]
     ) -> "BaseTypedModelMeta":
-        """Creates a pydantic BaseModel class that includes a hidden attribute that
-        reflects the full class identifier."""
+        """Creates a Pydantic BaseModel class.
+
+        This includes a hidden attribute that reflects the full class
+        identifier.
+
+        Args:
+            name: The name of the class.
+            bases: The base classes of the class.
+            dct: The class dictionary.
+
+        Returns:
+            A Pydantic BaseModel class that includes a hidden attribute that
+            reflects the full class identifier.
+
+        Raises:
+            TypeError: If the class is not a Pydantic BaseModel class.
+        """
         if "type" in dct:
             raise TypeError(
                 "`type` is a reserved attribute name for BaseTypedModel "
                 "subclasses"
             )
         type_name = f"{dct['__module__']}.{dct['__qualname__']}"
         type_ann = Literal[type_name]  # type: ignore [misc,valid-type]
@@ -83,22 +100,24 @@
     """
 
     @classmethod
     def from_dict(
         cls,
         model_dict: Dict[str, Any],
     ) -> "BaseTypedModel":
-        """Instantiate a Pydantic model from a serialized JSON-able dict
-        representation.
+        """Instantiate a Pydantic model from a serialized JSON-able dict representation.
 
         Args:
             model_dict: the model attributes serialized as JSON-able dict.
 
         Returns:
             A BaseTypedModel created from the serialized representation.
+
+        Raises:
+            RuntimeError: if the model_dict contains an invalid type.
         """
         model_type = model_dict.get("type")
         if not model_type:
             raise RuntimeError(
                 "`type` information is missing from the serialized model dict."
             )
         cls = load_source_path_class(model_type)
```

### Comparing `zenml-0.8.1rc0/src/zenml/utils/yaml_utils.py` & `zenml-0.9.0/src/zenml/utils/yaml_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,77 +7,93 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Utility functions to help with YAML files and data."""
 
 import json
 from pathlib import Path
 from typing import Any, Dict
 from uuid import UUID
 
 import yaml
 
-from zenml.io import fileio, utils
+from zenml.io import fileio
+from zenml.utils import io_utils
 
 
-def write_yaml(file_path: str, contents: Dict[Any, Any]) -> None:
+def write_yaml(
+    file_path: str, contents: Dict[Any, Any], sort_keys: bool = True
+) -> None:
     """Write contents as YAML format to file_path.
 
     Args:
         file_path: Path to YAML file.
         contents: Contents of YAML file as dict.
+        sort_keys: If `True`, keys are sorted alphabetically. If `False`,
+            the order in which the keys were inserted into the dict will
+            be preserved.
 
     Raises:
         FileNotFoundError: if directory does not exist.
     """
-    if not utils.is_remote(file_path):
+    if not io_utils.is_remote(file_path):
         dir_ = str(Path(file_path).parent)
         if not fileio.isdir(dir_):
             raise FileNotFoundError(f"Directory {dir_} does not exist.")
-    utils.write_file_contents_as_string(file_path, yaml.dump(contents))
+    io_utils.write_file_contents_as_string(
+        file_path, yaml.dump(contents, sort_keys=sort_keys)
+    )
 
 
 def append_yaml(file_path: str, contents: Dict[Any, Any]) -> None:
-    """Append contents to a YAML file at file_path."""
+    """Append contents to a YAML file at file_path.
+
+    Args:
+        file_path: Path to YAML file.
+        contents: Contents of YAML file as dict.
+
+    Raises:
+        FileNotFoundError: if directory does not exist.
+    """
     file_contents = read_yaml(file_path) or {}
     file_contents.update(contents)
-    if not utils.is_remote(file_path):
+    if not io_utils.is_remote(file_path):
         dir_ = str(Path(file_path).parent)
         if not fileio.isdir(dir_):
             raise FileNotFoundError(f"Directory {dir_} does not exist.")
-    utils.write_file_contents_as_string(file_path, yaml.dump(file_contents))
+    io_utils.write_file_contents_as_string(file_path, yaml.dump(file_contents))
 
 
 def read_yaml(file_path: str) -> Any:
     """Read YAML on file path and returns contents as dict.
 
     Args:
         file_path: Path to YAML file.
 
     Returns:
         Contents of the file in a dict.
 
     Raises:
         FileNotFoundError: if file does not exist.
     """
-
     if fileio.exists(file_path):
-        contents = utils.read_file_contents_as_string(file_path)
+        contents = io_utils.read_file_contents_as_string(file_path)
         # TODO: [LOW] consider adding a default empty dict to be returned
         #   instead of None
         return yaml.safe_load(contents)
     else:
         raise FileNotFoundError(f"{file_path} does not exist.")
 
 
 def is_yaml(file_path: str) -> bool:
-    """Returns True if file_path is YAML, else False
+    """Returns True if file_path is YAML, else False.
 
     Args:
         file_path: Path to YAML file.
 
     Returns:
         True if is yaml, else False.
     """
@@ -89,40 +105,53 @@
 def write_json(file_path: str, contents: Dict[str, Any]) -> None:
     """Write contents as JSON format to file_path.
 
     Args:
         file_path: Path to JSON file.
         contents: Contents of JSON file as dict.
 
-    Returns:
-        Contents of the file in a dict.
-
     Raises:
         FileNotFoundError: if directory does not exist.
     """
-    if not utils.is_remote(file_path):
+    if not io_utils.is_remote(file_path):
         dir_ = str(Path(file_path).parent)
         if not fileio.isdir(dir_):
             # Check if it is a local path, if it doesn't exist, raise Exception.
             raise FileNotFoundError(f"Directory {dir_} does not exist.")
-    utils.write_file_contents_as_string(file_path, json.dumps(contents))
+    io_utils.write_file_contents_as_string(file_path, json.dumps(contents))
 
 
 def read_json(file_path: str) -> Any:
     """Read JSON on file path and returns contents as dict.
 
     Args:
         file_path: Path to JSON file.
+
+    Returns:
+        Contents of the file in a dict.
+
+    Raises:
+        FileNotFoundError: if file does not exist.
     """
     if fileio.exists(file_path):
-        contents = utils.read_file_contents_as_string(file_path)
+        contents = io_utils.read_file_contents_as_string(file_path)
         return json.loads(contents)
     else:
         raise FileNotFoundError(f"{file_path} does not exist.")
 
 
 class UUIDEncoder(json.JSONEncoder):
+    """JSON encoder for UUID objects."""
+
     def default(self, obj: Any) -> Any:
+        """Default UUID encoder for JSON.
+
+        Args:
+            obj: Object to encode.
+
+        Returns:
+            Encoded object.
+        """
         if isinstance(obj, UUID):
             # if the obj is uuid, we simply return the value of uuid
             return obj.hex
         return json.JSONEncoder.default(self, obj)
```

### Comparing `zenml-0.8.1rc0/src/zenml/visualizers/__init__.py` & `zenml-0.9.0/src/zenml/visualizers/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,15 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
+"""Initialization of the visualizers module.
+
 The `visualizers` module offers a way of constructing and displaying
 visualizations of steps and pipeline results. The `BaseVisualizer` class is at
 the root of all the other visualizers, including options to view the results of
 pipeline runs, steps and pipelines themselves.
 """
 from zenml.visualizers.base_pipeline_run_visualizer import (
     BasePipelineRunVisualizer,
```

### Comparing `zenml-0.8.1rc0/src/zenml/visualizers/base_pipeline_run_visualizer.py` & `zenml-0.9.0/src/zenml/visualizers/base_pipeline_visualizer.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,26 +7,31 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the BasePipelineVisualizer."""
 
 from abc import abstractmethod
 from typing import Any
 
 from zenml.logger import get_logger
-from zenml.post_execution import PipelineRunView
+from zenml.post_execution import PipelineView
 from zenml.visualizers.base_visualizer import BaseVisualizer
 
 logger = get_logger(__name__)
 
 
-class BasePipelineRunVisualizer(BaseVisualizer):
-    """The base implementation of a ZenML Pipeline Run Visualizer."""
+class BasePipelineVisualizer(BaseVisualizer):
+    """The base implementation of a ZenML Pipeline Visualizer."""
 
     @abstractmethod
-    def visualize(
-        self, object: PipelineRunView, *args: Any, **kwargs: Any
-    ) -> None:
-        """Method to visualize pipeline runs."""
+    def visualize(self, object: PipelineView, *args: Any, **kwargs: Any) -> Any:
+        """Method to visualize pipelines.
+
+        Args:
+            object: The pipeline to visualize.
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/visualizers/base_pipeline_visualizer.py` & `zenml-0.9.0/src/zenml/visualizers/base_step_visualizer.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,24 +7,31 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Implementation of the BaseStepVisualizer."""
 
 from abc import abstractmethod
 from typing import Any
 
 from zenml.logger import get_logger
-from zenml.post_execution import PipelineView
+from zenml.post_execution import StepView
 from zenml.visualizers.base_visualizer import BaseVisualizer
 
 logger = get_logger(__name__)
 
 
-class BasePipelineVisualizer(BaseVisualizer):
-    """The base implementation of a ZenML Pipeline Visualizer."""
+class BaseStepVisualizer(BaseVisualizer):
+    """The base implementation of a ZenML Step Visualizer."""
 
     @abstractmethod
-    def visualize(self, object: PipelineView, *args: Any, **kwargs: Any) -> Any:
-        """Method to visualize pipelines."""
+    def visualize(self, object: StepView, *args: Any, **kwargs: Any) -> Any:
+        """Method to visualize steps.
+
+        Args:
+            object: The step to visualize.
+            *args: Additional arguments.
+            **kwargs: Additional keyword arguments.
+        """
```

### Comparing `zenml-0.8.1rc0/src/zenml/visualizers/base_visualizer.py` & `zenml-0.9.0/src/zenml/zen_server/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,28 +1,36 @@
-#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
 #
 #  Licensed under the Apache License, Version 2.0 (the "License");
 #  you may not use this file except in compliance with the License.
 #  You may obtain a copy of the License at:
 #
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for ZenServer.
 
-from abc import abstractmethod
-from typing import Any
-
-from zenml.logger import get_logger
-
-logger = get_logger(__name__)
-
-
-class BaseVisualizer:
-    """Base class for all ZenML Visualizers."""
-
-    @abstractmethod
-    def visualize(self, object: Any, *args: Any, **kwargs: Any) -> None:
-        """Method to visualize objects."""
+The ZenServer is a simple webserver to let you collaborate on stacks via
+the network. It can be spun up in a background daemon from the command line
+using `zenml server up` and managed from the same command line group.
+
+Using the ZenServer's stacks in your project just requires setting up a
+profile with `rest` store-type pointed to the url of the server.
+"""
+
+from zenml.zen_server.zen_server import (
+    ZenServer,
+    ZenServerConfig,
+    ZenServerEndpoint,
+    ZenServerEndpointConfig,
+)
+
+__all__ = [
+    "ZenServer",
+    "ZenServerConfig",
+    "ZenServerEndpoint",
+    "ZenServerEndpointConfig",
+]
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_server/zen_server.py` & `zenml-0.9.0/src/zenml/zen_server/zen_server.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,7 +1,22 @@
+#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
+#
+#  Licensed under the Apache License, Version 2.0 (the "License");
+#  you may not use this file except in compliance with the License.
+#  You may obtain a copy of the License at:
+#
+#       https://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+#  or implied. See the License for the specific language governing
+#  permissions and limitations under the License.
+"""Zen Server implementation."""
+
 import os
 from typing import Any, Dict, Optional, Union
 
 import uvicorn  # type: ignore[import]
 from pydantic import Field
 
 from zenml.config.global_config import GlobalConfiguration
@@ -49,14 +64,19 @@
     """
 
     config: ZenServerEndpointConfig
     monitor: HTTPEndpointHealthMonitor
 
     @property
     def endpoint_uri(self) -> Optional[str]:
+        """Return the endpoint URI.
+
+        Returns:
+            The endpoint URI or None if the endpoint is not available.
+        """
         uri = self.status.uri
         if not uri:
             return None
         return f"{uri}{self.config.zen_server_uri_path}"
 
 
 class ZenServerConfig(LocalDaemonServiceConfig):
@@ -95,14 +115,20 @@
     endpoint: ZenServerEndpoint
 
     def __init__(
         self,
         config: Union[ZenServerConfig, Dict[str, Any]],
         **attrs: Any,
     ) -> None:
+        """Initialize the ZenServer.
+
+        Args:
+            config: service configuration.
+            attrs: additional attributes.
+        """
         # ensure that the endpoint is created before the service is initialized
         if isinstance(config, ZenServerConfig) and "endpoint" not in attrs:
 
             endpoint_uri_path = ZEN_SERVER_URL_PATH
             healthcheck_uri_path = ZEN_SERVER_HEALTHCHECK_URL_PATH
             use_head_request = True
 
@@ -120,14 +146,19 @@
                     )
                 ),
             )
             attrs["endpoint"] = endpoint
         super().__init__(config=config, **attrs)
 
     def run(self) -> None:
+        """Run the ZenServer.
+
+        Raises:
+            ValueError: if unable to find the profile.
+        """
         profile = GlobalConfiguration().get_profile(self.config.profile_name)
         if profile is None:
             raise ValueError(
                 f"Could not find profile with name {self.config.profile_name}."
             )
 
         if profile.store_type == StoreType.REST:
@@ -161,12 +192,12 @@
 
     @property
     def zen_server_uri(self) -> Optional[str]:
         """Get the URI where the service responsible for the ZenServer is running.
 
         Returns:
             The URI where the service can be contacted for requests,
-             or None, if the service isn't running.
+                or None, if the service isn't running.
         """
         if not self.is_running:
             return None
         return self.endpoint.endpoint_uri
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_server/zen_server_api.py` & `zenml-0.9.0/src/zenml/zen_server/zen_server_api.py`

 * *Files 26% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Zen Server API."""
+
 import os
 from typing import Any, Dict, List, Optional
 
 from fastapi import APIRouter, Depends, FastAPI, HTTPException, status
 from fastapi.security import HTTPBasic, HTTPBasicCredentials
 from pydantic import BaseModel
 
@@ -84,14 +86,16 @@
     skip_default_registrations=True,
     track_analytics=False,
     skip_migration=True,
 )
 
 
 class ErrorModel(BaseModel):
+    """Base class for error responses."""
+
     detail: Any
 
 
 error_response = dict(model=ErrorModel)
 
 security = HTTPBasic()
 
@@ -100,14 +104,17 @@
     """Authorizes any request to the ZenServer.
 
     Right now this method only checks if the username provided as part of http
     basic auth credentials is registered in the ZenStore.
 
     Args:
         credentials: HTTP basic auth credentials passed to the request.
+
+    Raises:
+        HTTPException: If the username is not registered in the ZenStore.
     """
     try:
         zen_store.get_user(credentials.username)
     except KeyError:
         raise HTTPException(
             status_code=status.HTTP_401_UNAUTHORIZED,
             detail="Incorrect username.",
@@ -120,125 +127,216 @@
 )
 
 # to run this file locally, execute:
 # uvicorn zenml.zen_server.zen_server_api:app --reload
 
 
 def error_detail(error: Exception) -> List[str]:
-    """Convert an Exception to API representation."""
+    """Convert an Exception to API representation.
+
+    Args:
+        error: Exception to convert.
+
+    Returns:
+        List of strings representing the error.
+    """
     return [type(error).__name__] + [str(a) for a in error.args]
 
 
 def not_found(error: Exception) -> HTTPException:
-    """Convert an Exception to a HTTP 404 response."""
+    """Convert an Exception to a HTTP 404 response.
+
+    Args:
+        error: Exception to convert.
+
+    Returns:
+        HTTPException with status code 404.
+    """
     return HTTPException(status_code=404, detail=error_detail(error))
 
 
 def conflict(error: Exception) -> HTTPException:
-    """Convert an Exception to a HTTP 409 response."""
+    """Convert an Exception to a HTTP 409 response.
+
+    Args:
+        error: Exception to convert.
+
+    Returns:
+        HTTPException with status code 409.
+    """
     return HTTPException(status_code=409, detail=error_detail(error))
 
 
 @authed.get("/", response_model=ProfileConfiguration)
 async def service_info() -> ProfileConfiguration:
-    """Returns the profile configuration for this service."""
+    """Returns the profile configuration for this service.
+
+    Returns:
+        Profile configuration for this service.
+    """
     return profile
 
 
 @app.head("/health")
 @app.get("/health")
 async def health() -> str:
+    """Get health status of the server.
+
+    Returns:
+        String representing the health status of the server.
+    """
     return "OK"
 
 
 @authed.get(STACKS_EMPTY, response_model=bool)
 async def stacks_empty() -> bool:
-    """Returns whether stacks are registered or not."""
+    """Returns whether stacks are registered or not.
+
+    Returns:
+        True if there are no stacks registered, False otherwise.
+    """
     return zen_store.stacks_empty
 
 
 @authed.get(
     STACK_CONFIGURATIONS + "/{name}",
     response_model=Dict[StackComponentType, str],
     responses={404: error_response},
 )
 async def get_stack_configuration(name: str) -> Dict[StackComponentType, str]:
-    """Returns the configuration for the requested stack."""
+    """Returns the configuration for the requested stack.
+
+    Args:
+        name: Name of the stack.
+
+    Returns:
+        Configuration for the requested stack.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_stack_configuration(name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     STACK_CONFIGURATIONS,
     response_model=Dict[str, Dict[StackComponentType, str]],
 )
 async def stack_configurations() -> Dict[str, Dict[StackComponentType, str]]:
-    """Returns configurations for all stacks."""
+    """Returns configurations for all stacks.
+
+    Returns:
+        Configurations for all stacks.
+    """
     return zen_store.stack_configurations
 
 
 @authed.post(STACK_COMPONENTS, responses={409: error_response})
 async def register_stack_component(
     component: ComponentWrapper,
 ) -> None:
-    """Registers a stack component."""
+    """Registers a stack component.
+
+    Args:
+        component: Stack component to register.
+
+    Raises:
+        conflict: when the component already exists.
+    """
     try:
         zen_store.register_stack_component(component)
     except StackComponentExistsError as error:
         raise conflict(error) from error
 
 
 @authed.delete(STACKS + "/{name}", responses={404: error_response})
 async def deregister_stack(name: str) -> None:
-    """Deregisters a stack."""
+    """Deregisters a stack.
+
+    Args:
+        name: Name of the stack to deregister.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.deregister_stack(name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(STACKS, response_model=List[StackWrapper])
 async def stacks() -> List[StackWrapper]:
-    """Returns all stacks."""
+    """Returns all stacks.
+
+    Returns:
+        All stacks.
+    """
     return zen_store.stacks
 
 
 @authed.get(
     STACKS + "/{name}",
     response_model=StackWrapper,
     responses={404: error_response},
 )
 async def get_stack(name: str) -> StackWrapper:
-    """Returns the requested stack."""
+    """Returns the requested stack.
+
+    Args:
+        name: Name of the stack.
+
+    Returns:
+        The requested stack.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_stack(name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(
     STACKS,
     responses={409: error_response},
 )
 async def register_stack(stack: StackWrapper) -> None:
-    """Registers a stack."""
+    """Registers a stack.
+
+    Args:
+        stack: Stack to register.
+
+    Raises:
+        conflict: when a stack with the same name is already registered
+    """
     try:
         zen_store.register_stack(stack)
     except (StackExistsError, StackComponentExistsError) as error:
         raise conflict(error) from error
 
 
 @authed.put(
     STACKS + "/{name}",
     responses={404: error_response},
 )
 async def update_stack(stack: StackWrapper, name: str) -> None:
-    """Updates a stack."""
+    """Updates a stack.
+
+    Args:
+        stack: Stack to update.
+        name: Name of the stack.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.update_stack(name, stack)
     except DoesNotExistException as error:
         raise not_found(error) from error
 
 
 @authed.put(
@@ -247,194 +345,344 @@
     responses={404: error_response},
 )
 async def update_stack_component(
     name: str,
     component_type: StackComponentType,
     component: ComponentWrapper,
 ) -> Dict[str, str]:
-    """Updates a stack component."""
+    """Updates a stack component.
+
+    Args:
+        name: Name of the stack component.
+        component_type: Type of the stack component.
+        component: Stack component to update.
+
+    Returns:
+        Updated stack component.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.update_stack_component(name, component_type, component)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     STACK_COMPONENTS + "/{component_type}/{name}",
     response_model=ComponentWrapper,
     responses={404: error_response},
 )
 async def get_stack_component(
     component_type: StackComponentType, name: str
 ) -> ComponentWrapper:
-    """Returns the requested stack component."""
+    """Returns the requested stack component.
+
+    Args:
+        component_type: Type of the stack component.
+        name: Name of the stack component.
+
+    Returns:
+        The requested stack component.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_stack_component(component_type, name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     STACK_COMPONENTS + "/{component_type}",
     response_model=List[ComponentWrapper],
 )
 async def get_stack_components(
     component_type: StackComponentType,
 ) -> List[ComponentWrapper]:
-    """Returns all stack components for the requested type."""
+    """Returns all stack components for the requested type.
+
+    Args:
+        component_type: Type of the stack components.
+
+    Returns:
+        All stack components for the requested type.
+    """
     return zen_store.get_stack_components(component_type)
 
 
 @authed.delete(
     STACK_COMPONENTS + "/{component_type}/{name}",
     responses={404: error_response, 409: error_response},
 )
 async def deregister_stack_component(
     component_type: StackComponentType, name: str
 ) -> None:
-    """Deregisters a stack component."""
+    """Deregisters a stack component.
+
+    Args:
+        component_type: Type of the stack component.
+        name: Name of the stack component.
+
+    Returns:
+        None
+
+    Raises:
+        not_found: when none are found
+        conflict: when the stack component is still in use
+    """
     try:
         return zen_store.deregister_stack_component(component_type, name=name)
     except KeyError as error:
         raise not_found(error) from error
     except ValueError as error:
         raise conflict(error) from error
 
 
 @authed.get(USERS, response_model=List[User])
 async def users() -> List[User]:
-    """Returns all users."""
+    """Returns all users.
+
+    Returns:
+        All users.
+    """
     return zen_store.users
 
 
 @authed.get(USERS + "/{name}", responses={404: error_response})
 async def get_user(name: str) -> User:
-    """Gets a specific user."""
+    """Gets a specific user.
+
+    Args:
+        name: Name of the user.
+
+    Returns:
+        The requested user.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_user(user_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(
     USERS,
     response_model=User,
     responses={409: error_response},
 )
 async def create_user(user: User) -> User:
-    """Creates a user."""
+    """Creates a user.
+
+    # noqa: DAR401
+
+    Args:
+        user: User to create.
+
+    Returns:
+        The created user.
+    """
     try:
         return zen_store.create_user(user.name)
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.delete(USERS + "/{name}", responses={404: error_response})
 async def delete_user(name: str) -> None:
-    """Deletes a user."""
+    """Deletes a user.
+
+    Args:
+        name: Name of the user.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.delete_user(user_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     USERS + "/{name}/teams",
     response_model=List[Team],
     responses={404: error_response},
 )
 async def teams_for_user(name: str) -> List[Team]:
-    """Returns all teams for a user."""
+    """Returns all teams for a user.
+
+    Args:
+        name: Name of the user.
+
+    Returns:
+        All teams for the user.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_teams_for_user(user_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     USERS + "/{name}/role_assignments",
     response_model=List[RoleAssignment],
     responses={404: error_response},
 )
 async def role_assignments_for_user(
     name: str, project_name: Optional[str] = None
 ) -> List[RoleAssignment]:
-    """Returns all role assignments for a user."""
+    """Returns all role assignments for a user.
+
+    Args:
+        name: Name of the user.
+        project_name: Name of the project.
+
+    Returns:
+        All role assignments for the user.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_role_assignments_for_user(
             user_name=name, project_name=project_name, include_team_roles=False
         )
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(TEAMS, response_model=List[Team])
 async def teams() -> List[Team]:
-    """Returns all teams."""
+    """Returns all teams.
+
+    Returns:
+        All teams.
+    """
     return zen_store.teams
 
 
 @authed.get(TEAMS + "/{name}", responses={404: error_response})
 async def get_team(name: str) -> Team:
-    """Gets a specific team."""
+    """Gets a specific team.
+
+    Args:
+        name: Name of the team.
+
+    Returns:
+        The requested team.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_team(team_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(
     TEAMS,
     response_model=Team,
     responses={409: error_response},
 )
 async def create_team(team: Team) -> Team:
-    """Creates a team."""
+    """Creates a team.
+
+    Args:
+        team: Team to create.
+
+    Returns:
+        The created team.
+
+    Raises:
+        conflict: when the team already exists
+    """
     try:
         return zen_store.create_team(team.name)
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.delete(TEAMS + "/{name}", responses={404: error_response})
 async def delete_team(name: str) -> None:
-    """Deletes a team."""
+    """Deletes a team.
+
+    Args:
+        name: Name of the team.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.delete_team(team_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     TEAMS + "/{name}/users",
     response_model=List[User],
     responses={404: error_response},
 )
 async def users_for_team(name: str) -> List[User]:
-    """Returns all users for a team."""
+    """Returns all users for a team.
+
+    Args:
+        name: Name of the team.
+
+    Returns:
+        All users for the team.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_users_for_team(team_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(TEAMS + "/{name}/users", responses={404: error_response})
 async def add_user_to_team(name: str, user: User) -> None:
-    """Adds a user to a team."""
+    """Adds a user to a team.
+
+    Args:
+        name: Name of the team.
+        user: User to add to the team.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.add_user_to_team(team_name=name, user_name=user.name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.delete(
     TEAMS + "/{team_name}/users/{user_name}", responses={404: error_response}
 )
 async def remove_user_from_team(team_name: str, user_name: str) -> None:
-    """Removes a user from a team."""
+    """Removes a user from a team.
+
+    Args:
+        team_name: Name of the team.
+        user_name: Name of the user.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.remove_user_from_team(
             team_name=team_name, user_name=user_name
         )
     except KeyError as error:
         raise not_found(error) from error
 
@@ -443,115 +691,196 @@
     TEAMS + "/{name}/role_assignments",
     response_model=List[RoleAssignment],
     responses={404: error_response},
 )
 async def role_assignments_for_team(
     name: str, project_name: Optional[str] = None
 ) -> List[RoleAssignment]:
-    """Gets all role assignments for a team."""
+    """Gets all role assignments for a team.
+
+    Args:
+        name: Name of the team.
+        project_name: Name of the project.
+
+    Returns:
+        All role assignments for the team.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_role_assignments_for_team(
             team_name=name, project_name=project_name
         )
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(PROJECTS, response_model=List[Project])
 async def projects() -> List[Project]:
-    """Returns all projects."""
+    """Returns all projects.
+
+    Returns:
+        All projects.
+    """
     return zen_store.projects
 
 
 @authed.get(
     PROJECTS + "/{project_name}",
     response_model=Project,
     responses={404: error_response},
 )
 async def get_project(project_name: str) -> Project:
-    """Get a project for given name."""
+    """Get a project for given name.
+
+    # noqa: DAR401
+
+    Args:
+        project_name: Name of the project.
+
+    Returns:
+        The requested project.
+    """
     try:
         return zen_store.get_project(project_name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(
     PROJECTS,
     response_model=Project,
     responses={409: error_response},
 )
 async def create_project(project: Project) -> Project:
-    """Creates a project."""
+    """Creates a project.
+
+    # noqa: DAR401
+
+    Args:
+        project: Project to create.
+
+    Returns:
+        The created project.
+    """
     try:
         return zen_store.create_project(
             project_name=project.name, description=project.description
         )
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.delete(PROJECTS + "/{name}", responses={404: error_response})
 async def delete_project(name: str) -> None:
-    """Deletes a project."""
+    """Deletes a project.
+
+    Args:
+        name: Name of the project.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.delete_project(project_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(ROLES, response_model=List[Role])
 async def roles() -> List[Role]:
-    """Returns all roles."""
+    """Returns all roles.
+
+    Returns:
+        All roles.
+    """
     return zen_store.roles
 
 
 @authed.get(ROLES + "/{name}", responses={404: error_response})
 async def get_role(name: str) -> Role:
-    """Gets a specific role."""
+    """Gets a specific role.
+
+    Args:
+        name: Name of the role.
+
+    Returns:
+        The requested role.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_role(role_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.post(
     ROLES,
     response_model=Role,
     responses={409: error_response},
 )
 async def create_role(role: Role) -> Role:
-    """Creates a role."""
+    """Creates a role.
+
+    # noqa: DAR401
+
+    Args:
+        role: Role to create.
+
+    Returns:
+        The created role.
+    """
     try:
         return zen_store.create_role(role.name)
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.delete(ROLES + "/{name}", responses={404: error_response})
 async def delete_role(name: str) -> None:
-    """Deletes a role."""
+    """Deletes a role.
+
+    Args:
+        name: Name of the role.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         zen_store.delete_role(role_name=name)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(ROLE_ASSIGNMENTS, response_model=List[RoleAssignment])
 async def role_assignments() -> List[RoleAssignment]:
-    """Returns all role assignments."""
+    """Returns all role assignments.
+
+    Returns:
+        All role assignments.
+    """
     return zen_store.role_assignments
 
 
 @authed.post(
     ROLE_ASSIGNMENTS,
     responses={404: error_response},
 )
 async def assign_role(data: Dict[str, Any]) -> None:
-    """Assigns a role."""
+    """Assigns a role.
+
+    Args:
+        data: Data containing the role assignment.
+
+    Raises:
+        not_found: when none are found
+    """
     role_name = data["role_name"]
     entity_name = data["entity_name"]
     project_name = data.get("project_name")
     is_user = data.get("is_user", True)
 
     try:
         zen_store.assign_role(
@@ -562,15 +891,22 @@
         )
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.delete(ROLE_ASSIGNMENTS, responses={404: error_response})
 async def revoke_role(data: Dict[str, Any]) -> None:
-    """Revokes a role."""
+    """Revokes a role.
+
+    Args:
+        data: Data containing the role assignment.
+
+    Raises:
+        not_found: when none are found
+    """
     role_name = data["role_name"]
     entity_name = data["entity_name"]
     project_name = data.get("project_name")
     is_user = data.get("is_user", True)
 
     try:
         zen_store.revoke_role(
@@ -585,29 +921,49 @@
 
 @authed.get(
     PIPELINE_RUNS + "/{pipeline_name}", response_model=List[PipelineRunWrapper]
 )
 async def pipeline_runs(
     pipeline_name: str, project_name: Optional[str] = None
 ) -> List[PipelineRunWrapper]:
-    """Returns all runs for a pipeline."""
+    """Returns all runs for a pipeline.
+
+    Args:
+        pipeline_name: Name of the pipeline.
+        project_name: Name of the project.
+
+    Returns:
+        All runs for a pipeline.
+    """
     return zen_store.get_pipeline_runs(
         pipeline_name=pipeline_name, project_name=project_name
     )
 
 
 @authed.get(
     PIPELINE_RUNS + "/{pipeline_name}/{run_name}",
     response_model=PipelineRunWrapper,
     responses={404: error_response},
 )
 async def pipeline_run(
     pipeline_name: str, run_name: str, project_name: Optional[str] = None
 ) -> PipelineRunWrapper:
-    """Returns a single pipeline run."""
+    """Returns a single pipeline run.
+
+    Args:
+        pipeline_name: Name of the pipeline.
+        run_name: Name of the run.
+        project_name: Name of the project.
+
+    Returns:
+        The requested pipeline run.
+
+    Raises:
+        not_found: when none are found.
+    """
     try:
         return zen_store.get_pipeline_run(
             pipeline_name=pipeline_name,
             run_name=run_name,
             project_name=project_name,
         )
     except KeyError as error:
@@ -615,59 +971,105 @@
 
 
 @authed.post(
     PIPELINE_RUNS,
     responses={409: error_response},
 )
 async def register_pipeline_run(pipeline_run: PipelineRunWrapper) -> None:
-    """Registers a pipeline run."""
+    """Registers a pipeline run.
+
+    # noqa: DAR401
+
+    Args:
+        pipeline_run: Pipeline run to register.
+
+    Returns:
+        None
+    """
     try:
         return zen_store.register_pipeline_run(pipeline_run)
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.get(FLAVORS, response_model=List[FlavorWrapper])
 async def flavors() -> List[FlavorWrapper]:
+    """Get all flavors.
+
+    Returns:
+        All flavors.
+    """
     return zen_store.flavors
 
 
 @authed.post(
     FLAVORS,
     response_model=FlavorWrapper,
     responses={409: error_response},
 )
 async def create_flavor(flavor: FlavorWrapper) -> FlavorWrapper:
-    """Creates a flavor."""
+    """Creates a flavor.
+
+    # noqa: DAR401
+
+    Args:
+        flavor: Flavor to create.
+
+    Returns:
+        The created flavor.
+    """
     try:
         return zen_store.create_flavor(
             name=flavor.name,
             source=flavor.source,
             stack_component_type=flavor.type,
         )
     except EntityExistsError as error:
         raise conflict(error) from error
 
 
 @authed.get(FLAVORS + "/{component_type}", responses={404: error_response})
 async def get_flavor_by_type(
     component_type: StackComponentType,
 ) -> List[FlavorWrapper]:
+    """Returns all flavors of a given type.
+
+    Args:
+        component_type: Type of the component.
+
+    Returns:
+        The requested flavors.
+
+    Raises:
+        not_found: when none are found.
+    """
     try:
         return zen_store.get_flavors_by_type(component_type=component_type)
     except KeyError as error:
         raise not_found(error) from error
 
 
 @authed.get(
     FLAVORS + "/{component_type}/{name}", responses={404: error_response}
 )
 async def get_flavor_by_type_and_name(
     component_type: StackComponentType, name: str
 ) -> FlavorWrapper:
+    """Returns a flavor of a given type and name.
+
+    Args:
+        component_type: Type of the component
+        name: Name of the flavor.
+
+    Returns:
+        The requested flavor.
+
+    Raises:
+        not_found: when none are found
+    """
     try:
         return zen_store.get_flavor_by_name_and_type(
             component_type=component_type, flavor_name=name
         )
     except KeyError as error:
         raise not_found(error) from error
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/__init__.py` & `zenml-0.9.0/src/zenml/zen_stores/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,17 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
-"""
-ZenStores define ways to store ZenML relevant data locally or remotely.
-"""
+"""ZenStores define ways to store ZenML relevant data locally or remotely."""
+
 from zenml.zen_stores.base_zen_store import BaseZenStore
 from zenml.zen_stores.local_zen_store import LocalZenStore
 from zenml.zen_stores.rest_zen_store import RestZenStore
 from zenml.zen_stores.sql_zen_store import SqlZenStore
 
 __all__ = [
     "BaseZenStore",
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/base_zen_store.py` & `zenml-0.9.0/src/zenml/zen_stores/base_zen_store.py`

 * *Files 9% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Base Zen Store implementation."""
+
 import base64
 from abc import ABC, abstractmethod
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import yaml
 
@@ -112,35 +114,53 @@
         Returns:
             Url pointing to the path for the store type.
         """
 
     @staticmethod
     @abstractmethod
     def is_valid_url(url: str) -> bool:
-        """Check if the given url is valid."""
+        """Check if the given url is valid.
+
+        Args:
+            url: The url to check.
+
+        Returns:
+            True if the url is valid, False otherwise.
+        """
 
     # Public Interface:
 
     @property
     @abstractmethod
     def type(self) -> StoreType:
-        """The type of zen store."""
+        """The type of zen store.
+
+        Returns:
+            The type of zen store.
+        """
 
     @property
     @abstractmethod
     def url(self) -> str:
-        """Get the repository URL."""
+        """Get the repository URL.
+
+        Returns:
+            The repository URL.
+        """
 
     @property
     @abstractmethod
     def stacks_empty(self) -> bool:
         """Check if the store is empty (no stacks are configured).
 
         The implementation of this method should check if the store is empty
         without having to load all the stacks from the persistent storage.
+
+        Returns:
+            True if the store is empty, False otherwise.
         """
 
     @abstractmethod
     def get_stack_configuration(
         self, name: str
     ) -> Dict[StackComponentType, str]:
         """Fetches a stack configuration by name.
@@ -331,15 +351,15 @@
     def _create_team(self, team_name: str) -> Team:
         """Creates a new team.
 
         Args:
             team_name: Unique team name.
 
         Returns:
-             The newly created team.
+            The newly created team.
 
         Raises:
             EntityExistsError: If a team with the given name already exists.
         """
 
     @abstractmethod
     def _get_team(self, team_name: str) -> Team:
@@ -420,15 +440,15 @@
         """Creates a new project.
 
         Args:
             project_name: Unique project name.
             description: Optional project description.
 
         Returns:
-             The newly created project.
+            The newly created project.
 
         Raises:
             EntityExistsError: If a project with the given name already exists.
         """
 
     @abstractmethod
     def _delete_project(self, project_name: str) -> None:
@@ -477,15 +497,15 @@
     def _create_role(self, role_name: str) -> Role:
         """Creates a new role.
 
         Args:
             role_name: Unique role name.
 
         Returns:
-             The newly created role.
+            The newly created role.
 
         Raises:
             EntityExistsError: If a role with the given name already exists.
         """
 
     @abstractmethod
     def _delete_role(self, role_name: str) -> None:
@@ -682,15 +702,15 @@
 
         Args:
             source: the source path to the implemented flavor.
             name: the name of the flavor.
             stack_component_type: the corresponding StackComponentType.
 
         Returns:
-             The newly created flavor.
+            The newly created flavor.
 
         Raises:
             EntityExistsError: If a flavor with the given name and type
                 already exists.
         """
 
     @abstractmethod
@@ -726,48 +746,46 @@
                 or there are more than one instances
         """
 
     # Common code (user facing):
 
     @property
     def stacks(self) -> List[StackWrapper]:
-        """All stacks registered in this zen store."""
+        """All stacks registered in this zen store.
+
+        Returns:
+            A list of all stacks registered in this zen store.
+        """
         return [
             self._stack_from_dict(name, conf)
             for name, conf in self.stack_configurations.items()
         ]
 
     def get_stack(self, name: str) -> StackWrapper:
         """Fetch a stack by name.
 
         Args:
             name: The name of the stack to retrieve.
 
         Returns:
             StackWrapper instance if the stack exists.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         return self._stack_from_dict(name, self.get_stack_configuration(name))
 
     def _register_stack(self, stack: StackWrapper) -> None:
         """Register a stack and its components.
 
         If any of the stack's components aren't registered in the zen store
         yet, this method will try to register them as well.
 
         Args:
             stack: The stack to register.
 
         Raises:
             StackExistsError: If a stack with the same name already exists.
-            StackComponentExistsError: If a component of the stack wasn't
-                registered and a different component with the same name
-                already exists.
         """
         try:
             self.get_stack(stack.name)
         except KeyError:
             pass
         else:
             raise StackExistsError(
@@ -779,14 +797,17 @@
             component: ComponentWrapper,
         ) -> Tuple[StackComponentType, str]:
             """Try to register a stack component, if it doesn't exist.
 
             Args:
                 component: StackComponentWrapper to register.
 
+            Returns:
+                The type and name of the component.
+
             Raises:
                 StackComponentExistsError: If a component with same name exists.
             """
             try:
                 existing_component = self.get_stack_component(
                     component_type=component.type, name=component.name
                 )
@@ -813,15 +834,16 @@
         yet, this method will try to register them as well.
 
         Args:
             name: The original name of the stack.
             stack: The new stack to use in the update.
 
         Raises:
-            DoesNotExistException: If no stack exists with the given name.
+            KeyError: If no stack exists with the given name.
+            StackExistsError: If a stack with the same name already exists.
         """
         try:
             self.get_stack(name)
         except KeyError:
             raise KeyError(
                 f"Unable to update stack with name '{stack.name}': No existing "
                 f"stack found with this name."
@@ -836,14 +858,22 @@
                 )
         except KeyError:
             pass
 
         def __check_component(
             component: ComponentWrapper,
         ) -> Tuple[StackComponentType, str]:
+            """Try to register a stack component, if it doesn't exist.
+
+            Args:
+                component: StackComponentWrapper to register.
+
+            Returns:
+                The type and name of the component.
+            """
             try:
                 _ = self.get_stack_component(
                     component_type=component.type, name=component.name
                 )
             except KeyError:
                 self._register_stack_component(component)
             return component.type, component.name
@@ -858,16 +888,20 @@
             self.deregister_stack(name)
 
     def get_stack_component(
         self, component_type: StackComponentType, name: str
     ) -> ComponentWrapper:
         """Get a registered stack component.
 
-        Raises:
-            KeyError: If no component with the requested type and name exists.
+        Args:
+            component_type: The type of the component.
+            name: The name of the component.
+
+        Returns:
+            The component.
         """
         flavor, config = self._get_component_flavor_and_config(
             component_type, name=name
         )
         uuid = yaml.safe_load(base64.b64decode(config).decode())["uuid"]
         return ComponentWrapper(
             type=component_type,
@@ -942,22 +976,39 @@
     # Common code (internal implementations, private):
 
     def _track_event(
         self,
         event: Union[str, AnalyticsEvent],
         metadata: Optional[Dict[str, Any]] = None,
     ) -> bool:
+        """Track an analytics event.
+
+        Args:
+            event: The event to track.
+            metadata: Additional metadata to track with the event.
+
+        Returns:
+            True if the event was successfully tracked, False otherwise.
+        """
         if self._track_analytics:
             return track_event(event, metadata)
         return False
 
     def _stack_from_dict(
         self, name: str, stack_configuration: Dict[StackComponentType, str]
     ) -> StackWrapper:
-        """Build a StackWrapper from stored configurations"""
+        """Build a StackWrapper from stored configurations.
+
+        Args:
+            name: The name of the stack.
+            stack_configuration: The configuration of the stack.
+
+        Returns:
+            A StackWrapper instance.
+        """
         stack_components = [
             self.get_stack_component(
                 component_type=component_type, name=component_name
             )
             for component_type, component_name in stack_configuration.items()
         ]
         return StackWrapper(name=name, components=stack_components)
@@ -971,17 +1022,16 @@
         component: ComponentWrapper,
     ) -> None:
         """Register a stack component.
 
         Args:
             component: The component to register.
 
-        Raises:
-            StackComponentExistsError: If a stack component with the same type
-                and name already exists.
+        Returns:
+            None
         """
         analytics_metadata = {
             "type": component.type.value,
             "flavor": component.flavor,
         }
         self._track_event(
             AnalyticsEvent.REGISTERED_STACK_COMPONENT,
@@ -998,16 +1048,16 @@
         """Update a stack component.
 
         Args:
             name: The original name of the stack component.
             component_type: The type of the stack component to update.
             component: The new component to update with.
 
-        Raises:
-            KeyError: If no stack component exists with the given name.
+        Returns:
+            The updated stack configuration.
         """
         analytics_metadata = {
             "type": component.type.value,
             "flavor": component.flavor,
         }
         self._track_event(
             AnalyticsEvent.UPDATED_STACK_COMPONENT,
@@ -1017,187 +1067,163 @@
 
     def deregister_stack(self, name: str) -> None:
         """Delete a stack from storage.
 
         Args:
             name: The name of the stack to be deleted.
 
-        Raises:
-            KeyError: If no stack exists for the given name.
+        Returns:
+            None.
         """
         # No tracking events, here for consistency
         return self._deregister_stack(name)
 
     def create_user(self, user_name: str) -> User:
         """Creates a new user.
 
         Args:
             user_name: Unique username.
 
         Returns:
-             The newly created user.
-
-        Raises:
-            EntityExistsError: If a user with the given name already exists.
+            The newly created user.
         """
         self._track_event(AnalyticsEvent.CREATED_USER)
         return self._create_user(user_name)
 
     def delete_user(self, user_name: str) -> None:
         """Deletes a user.
 
         Args:
             user_name: Name of the user to delete.
 
-        Raises:
-            KeyError: If no user with the given name exists.
+        Returns:
+            None.
         """
         self._track_event(AnalyticsEvent.DELETED_USER)
         return self._delete_user(user_name)
 
     def get_user(self, user_name: str) -> User:
         """Gets a specific user.
 
         Args:
             user_name: Name of the user to get.
 
         Returns:
             The requested user.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         # No tracking events, here for consistency
         return self._get_user(user_name)
 
     def create_team(self, team_name: str) -> Team:
         """Creates a new team.
 
         Args:
             team_name: Unique team name.
 
         Returns:
-             The newly created team.
-
-        Raises:
-            EntityExistsError: If a team with the given name already exists.
+            The newly created team.
         """
         self._track_event(AnalyticsEvent.CREATED_TEAM)
         return self._create_team(team_name)
 
     def get_team(self, team_name: str) -> Team:
         """Gets a specific team.
 
         Args:
             team_name: Name of the team to get.
 
         Returns:
             The requested team.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         # No tracking events, here for consistency
         return self._get_team(team_name)
 
     def delete_team(self, team_name: str) -> None:
         """Deletes a team.
 
         Args:
             team_name: Name of the team to delete.
 
-        Raises:
-            KeyError: If no team with the given name exists.
+        Returns:
+            None
         """
         self._track_event(AnalyticsEvent.DELETED_TEAM)
         return self._delete_team(team_name)
 
     def get_project(self, project_name: str) -> Project:
         """Gets a specific project.
 
         Args:
             project_name: Name of the project to get.
 
         Returns:
             The requested project.
-
-        Raises:
-            KeyError: If no project with the given name exists.
         """
         # No tracking events, here for consistency
         return self._get_project(project_name)
 
     def create_project(
         self, project_name: str, description: Optional[str] = None
     ) -> Project:
         """Creates a new project.
 
         Args:
             project_name: Unique project name.
             description: Optional project description.
 
         Returns:
-             The newly created project.
-
-        Raises:
-            EntityExistsError: If a project with the given name already exists.
+            The newly created project.
         """
         self._track_event(AnalyticsEvent.CREATED_PROJECT)
         return self._create_project(project_name, description)
 
     def delete_project(self, project_name: str) -> None:
         """Deletes a project.
 
         Args:
             project_name: Name of the project to delete.
 
-        Raises:
-            KeyError: If no project with the given name exists.
+        Returns:
+            None.
         """
         self._track_event(AnalyticsEvent.DELETED_PROJECT)
         return self._delete_project(project_name)
 
     def get_role(self, role_name: str) -> Role:
         """Gets a specific role.
 
         Args:
             role_name: Name of the role to get.
 
         Returns:
             The requested role.
-
-        Raises:
-            KeyError: If no role with the given name exists.
         """
         # No tracking events, here for consistency
         return self._get_role(role_name)
 
     def create_role(self, role_name: str) -> Role:
         """Creates a new role.
 
         Args:
             role_name: Unique role name.
 
         Returns:
-             The newly created role.
-
-        Raises:
-            EntityExistsError: If a role with the given name already exists.
+            The newly created role.
         """
         self._track_event(AnalyticsEvent.CREATED_ROLE)
         return self._create_role(role_name)
 
     def delete_role(self, role_name: str) -> None:
         """Deletes a role.
 
         Args:
-            role_name: Name of the role to delete.
+            role_name: Name of the role to delete
 
-        Raises:
-            KeyError: If no role with the given name exists.
+        Returns:
+            None.
         """
         self._track_event(AnalyticsEvent.DELETED_ROLE)
         return self._delete_role(role_name)
 
     def create_flavor(
         self,
         source: str,
@@ -1208,21 +1234,16 @@
 
         Args:
             source: the source path to the implemented flavor.
             name: the name of the flavor.
             stack_component_type: the corresponding StackComponentType.
 
         Returns:
-             The newly created flavor.
-
-        Raises:
-            EntityExistsError: If a flavor with the given name and type
-                already exists.
+            The newly created flavor.
         """
-
         analytics_metadata = {
             "type": stack_component_type.value,
         }
         track_event(
             AnalyticsEvent.CREATED_FLAVOR,
             metadata=analytics_metadata,
         )
@@ -1233,19 +1254,16 @@
 
         If any of the stack's components aren't registered in the zen store
         yet, this method will try to register them as well.
 
         Args:
             stack: The stack to register.
 
-        Raises:
-            StackExistsError: If a stack with the same name already exists.
-            StackComponentExistsError: If a component of the stack wasn't
-                registered and a different component with the same name
-                already exists.
+        Returns:
+            None
         """
         metadata = {c.type.value: c.flavor for c in stack.components}
         metadata["store_type"] = self.type.value
         track_event(AnalyticsEvent.REGISTERED_STACK, metadata=metadata)
         return self._register_stack(stack)
 
     def update_stack(self, name: str, stack: StackWrapper) -> None:
@@ -1254,14 +1272,14 @@
         If any of the stack's components aren't registered in the stack store
         yet, this method will try to register them as well.
 
         Args:
             name: The original name of the stack.
             stack: The new stack to use in the update.
 
-        Raises:
-            DoesNotExistException: If no stack exists with the given name.
+        Returns:
+            None.
         """
         metadata = {c.type.value: c.flavor for c in stack.components}
         metadata["store_type"] = self.type.value
         track_event(AnalyticsEvent.UPDATED_STACK, metadata=metadata)
         return self._update_stack(name, stack)
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/local_zen_store.py` & `zenml-0.9.0/src/zenml/zen_stores/local_zen_store.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Local Zen Store implementation."""
+
 import base64
 import itertools
 import os
 import re
 from pathlib import Path
 from typing import (
     Any,
@@ -27,16 +29,17 @@
     Union,
     overload,
 )
 from uuid import UUID
 
 from zenml.enums import StackComponentType, StoreType
 from zenml.exceptions import EntityExistsError, StackComponentExistsError
-from zenml.io import fileio, utils
+from zenml.io import fileio
 from zenml.logger import get_logger
+from zenml.utils import io_utils
 from zenml.zen_stores import BaseZenStore
 from zenml.zen_stores.models import (
     ComponentWrapper,
     FlavorWrapper,
     Project,
     Role,
     RoleAssignment,
@@ -55,23 +58,21 @@
 )
 
 
 @overload
 def _get_unique_entity(
     entity_name: str, collection: Sequence[E], ensure_exists: bool = True
 ) -> E:
-    """Type annotations in case of `ensure_exists=True`."""
     ...
 
 
 @overload
 def _get_unique_entity(
     entity_name: str, collection: Sequence[E], ensure_exists: bool = False
 ) -> Optional[E]:
-    """Type annotations in case of `ensure_exists=False`."""
     ...
 
 
 def _get_unique_entity(
     entity_name: str, collection: Sequence[E], ensure_exists: bool = True
 ) -> Optional[E]:
     """Gets an entity with a specific name from a collection.
@@ -102,14 +103,16 @@
             raise KeyError(f"No entity found with name '{entity_name}'.")
         return matches[0]
     else:
         return matches[0] if matches else None
 
 
 class LocalZenStore(BaseZenStore):
+    """Local Zen Store implementation."""
+
     def initialize(
         self,
         url: str,
         *args: Any,
         store_data: Optional[ZenStoreModel] = None,
         **kwargs: Any,
     ) -> "LocalZenStore":
@@ -121,21 +124,24 @@
             store_data: optional store data object to pre-populate the
                 zen store with.
             args: additional positional arguments (ignored).
             kwargs: additional keyword arguments (ignored).
 
         Returns:
             The initialized ZenStore instance.
+
+        Raises:
+            ValueError: If the given URL is invalid.
         """
         if not self.is_valid_url(url):
             raise ValueError(f"Invalid URL for local store: {url}")
 
         self._root = self.get_path_from_url(url)
         self._url = f"file://{self._root}"
-        utils.create_dir_recursive_if_not_exists(str(self._root))
+        io_utils.create_dir_recursive_if_not_exists(str(self._root))
 
         if store_data is not None:
             self.__store = store_data
         else:
             self.__store = ZenStoreModel(str(self.root / "stacks.yaml"))
 
         self.__pipeline_store = ZenStorePipelineModel(
@@ -145,53 +151,82 @@
         super().initialize(url, *args, **kwargs)
         return self
 
     # Public interface implementations:
 
     @property
     def type(self) -> StoreType:
-        """The type of zen store."""
+        """The type of zen store.
+
+        Returns:
+            The type of zen store.
+        """
         return StoreType.LOCAL
 
     @property
     def url(self) -> str:
-        """URL of the repository."""
+        """URL of the repository.
+
+        Returns:
+            The URL of the repository.
+        """
         return self._url
 
     # Static methods:
 
     @staticmethod
     def get_path_from_url(url: str) -> Optional[Path]:
         """Get the path from a URL.
 
         Args:
             url: The URL to get the path from.
 
         Returns:
             The path from the URL.
+
+        Raises:
+            ValueError: If the URL is invalid.
         """
         if not LocalZenStore.is_valid_url(url):
             raise ValueError(f"Invalid URL for local store: {url}")
         url = url.replace("file://", "")
         return Path(url)
 
     @staticmethod
     def get_local_url(path: str) -> str:
-        """Get a local URL for a given local path."""
+        """Get a local URL for a given local path.
+
+        Args:
+            path: The path to get the local URL for.
+
+        Returns:
+            The local URL for the path.
+        """
         return f"file://{path}"
 
     @staticmethod
     def is_valid_url(url: str) -> bool:
-        """Check if the given url is a valid local path."""
+        """Check if the given url is a valid local path.
+
+        Args:
+            url: The url to check.
+
+        Returns:
+            `True` if the url is a valid local url or path.
+        """
         scheme = re.search("^([a-z0-9]+://)", url)
         return not scheme or scheme.group() == "file://"
 
     @property
     def stacks_empty(self) -> bool:
-        """Check if the zen store is empty."""
+        """Check if the zen store is empty.
+
+        Returns:
+            `True` if the zen store is empty.
+        """
         return len(self.__store.stacks) == 0
 
     def get_stack_configuration(
         self, name: str
     ) -> Dict[StackComponentType, str]:
         """Fetches a stack configuration by name.
 
@@ -243,18 +278,18 @@
                 f"with this name."
             )
 
         # write the component configuration file
         component_config_path = self._get_stack_component_config_path(
             component_type=component.type, name=component.name
         )
-        utils.create_dir_recursive_if_not_exists(
+        io_utils.create_dir_recursive_if_not_exists(
             os.path.dirname(component_config_path)
         )
-        utils.write_file_contents_as_string(
+        io_utils.write_file_contents_as_string(
             component_config_path,
             base64.b64decode(component.config).decode(),
         )
 
         # add the component to the zen store dict and write it to disk
         components[component.name] = component.flavor
         self.__store.write_config()
@@ -273,16 +308,21 @@
         """Update a stack component.
 
         Args:
             name: The original name of the stack component.
             component_type: The type of the stack component to update.
             component: The new component to update with.
 
+        Returns:
+            The updated stack component.
+
         Raises:
             KeyError: If no stack component exists with the given name.
+            StackComponentExistsError: If a stack component with the same type
+                and name already exists.
         """
         components = self.__store.stack_components[component_type]
         if name not in components:
             raise KeyError(
                 f"Unable to update stack component (type: {component_type}) "
                 f"with name '{name}': No existing stack component "
                 f"found with this name."
@@ -292,18 +332,18 @@
                 f"Unable to update stack component (type: {component_type}) "
                 f"with name '{component.name}': a stack component already "
                 f"is registered with this name."
             )
         component_config_path = self._get_stack_component_config_path(
             component_type=component.type, name=component.name
         )
-        utils.create_dir_recursive_if_not_exists(
+        io_utils.create_dir_recursive_if_not_exists(
             os.path.dirname(component_config_path)
         )
-        utils.write_file_contents_as_string(
+        io_utils.write_file_contents_as_string(
             component_config_path,
             base64.b64decode(component.config).decode(),
         )
         if name != component.name:
             self._delete_stack_component(component_type, name)
 
         # add the component to the stack store dict and write it to disk
@@ -323,17 +363,14 @@
         return {component.type.value: component.flavor}
 
     def _deregister_stack(self, name: str) -> None:
         """Remove a stack from storage.
 
         Args:
             name: The name of the stack to be deleted.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         del self.__store.stacks[name]
         self.__store.write_config()
 
     # Private interface implementations:
 
     def _save_stack(
@@ -376,35 +413,41 @@
             )
 
         component_config_path = self._get_stack_component_config_path(
             component_type=component_type, name=name
         )
         flavor = components[name]
         config = base64.b64encode(
-            utils.read_file_contents_as_string(component_config_path).encode()
+            io_utils.read_file_contents_as_string(
+                component_config_path
+            ).encode()
         )
         return flavor, config
 
     def _get_stack_component_names(
         self, component_type: StackComponentType
     ) -> List[str]:
-        """Get names of all registered stack components of a given type."""
+        """Get names of all registered stack components of a given type.
+
+        Args:
+            component_type: The type of the stack components to fetch.
+
+        Returns:
+            List of names of all registered stack components of the given type.
+        """
         return list(self.__store.stack_components[component_type])
 
     def _delete_stack_component(
         self, component_type: StackComponentType, name: str
     ) -> None:
         """Remove a StackComponent from storage.
 
         Args:
             component_type: The type of component to delete.
             name: Then name of the component to delete.
-
-        Raises:
-            KeyError: If no component exists for given type and name.
         """
         component_config_path = self._get_stack_component_config_path(
             component_type=component_type, name=name
         )
 
         if fileio.exists(component_config_path):
             fileio.remove(component_config_path)
@@ -428,17 +471,14 @@
         """Get a specific user by name.
 
         Args:
             user_name: Name of the user to get.
 
         Returns:
             The requested user, if it was found.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         return _get_unique_entity(user_name, collection=self.__store.users)
 
     def _create_user(self, user_name: str) -> User:
         """Creates a new user.
 
         Args:
@@ -463,17 +503,14 @@
         return user
 
     def _delete_user(self, user_name: str) -> None:
         """Deletes a user.
 
         Args:
             user_name: Name of the user to delete.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         user = _get_unique_entity(user_name, collection=self.__store.users)
         self.__store.users.remove(user)
         for user_names in self.__store.team_assignments.values():
             user_names.discard(user.name)
 
         self.__store.role_assignments = [
@@ -497,28 +534,25 @@
         """Gets a specific team.
 
         Args:
             team_name: Name of the team to get.
 
         Returns:
             The requested team.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         return _get_unique_entity(team_name, collection=self.__store.teams)
 
     def _create_team(self, team_name: str) -> Team:
         """Creates a new team.
 
         Args:
             team_name: Unique team name.
 
         Returns:
-             The newly created team.
+            The newly created team.
 
         Raises:
             EntityExistsError: If a team with the given name already exists.
         """
         if _get_unique_entity(
             team_name, collection=self.__store.teams, ensure_exists=False
         ):
@@ -532,17 +566,14 @@
         return team
 
     def _delete_team(self, team_name: str) -> None:
         """Deletes a team.
 
         Args:
             team_name: Name of the team to delete.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         team = _get_unique_entity(team_name, collection=self.__store.teams)
         self.__store.teams.remove(team)
         self.__store.team_assignments.pop(team.name, None)
         self.__store.role_assignments = [
             assignment
             for assignment in self.__store.role_assignments
@@ -553,32 +584,26 @@
 
     def add_user_to_team(self, team_name: str, user_name: str) -> None:
         """Adds a user to a team.
 
         Args:
             team_name: Name of the team.
             user_name: Name of the user.
-
-        Raises:
-            KeyError: If no user and team with the given names exists.
         """
         team = _get_unique_entity(team_name, self.__store.teams)
         user = _get_unique_entity(user_name, self.__store.users)
         self.__store.team_assignments[team.name].add(user.name)
         self.__store.write_config()
 
     def remove_user_from_team(self, team_name: str, user_name: str) -> None:
         """Removes a user from a team.
 
         Args:
             team_name: Name of the team.
             user_name: Name of the user.
-
-        Raises:
-            KeyError: If no user and team with the given names exists.
         """
         team = _get_unique_entity(team_name, self.__store.teams)
         user = _get_unique_entity(user_name, self.__store.users)
         self.__store.team_assignments[team.name].remove(user.name)
         self.__store.write_config()
 
     @property
@@ -594,17 +619,14 @@
         """Get an existing project by name.
 
         Args:
             project_name: Name of the project to get.
 
         Returns:
             The requested project if one was found.
-
-        Raises:
-            KeyError: If there is no such project.
         """
         return _get_unique_entity(
             project_name, collection=self.__store.projects
         )
 
     def _create_project(
         self, project_name: str, description: Optional[str] = None
@@ -612,15 +634,15 @@
         """Creates a new project.
 
         Args:
             project_name: Unique project name.
             description: Optional project description.
 
         Returns:
-             The newly created project.
+            The newly created project.
 
         Raises:
             EntityExistsError: If a project with the given name already exists.
         """
         if _get_unique_entity(
             project_name, collection=self.__store.projects, ensure_exists=False
         ):
@@ -634,17 +656,14 @@
         return project
 
     def _delete_project(self, project_name: str) -> None:
         """Deletes a project.
 
         Args:
             project_name: Name of the project to delete.
-
-        Raises:
-            KeyError: If no project with the given name exists.
         """
         project = _get_unique_entity(
             project_name, collection=self.__store.projects
         )
         self.__store.projects.remove(project)
         self.__store.role_assignments = [
             assignment
@@ -677,28 +696,25 @@
         """Gets a specific role.
 
         Args:
             role_name: Name of the role to get.
 
         Returns:
             The requested role.
-
-        Raises:
-            KeyError: If no role with the given name exists.
         """
         return _get_unique_entity(role_name, collection=self.__store.roles)
 
     def _create_role(self, role_name: str) -> Role:
         """Creates a new role.
 
         Args:
             role_name: Unique role name.
 
         Returns:
-             The newly created role.
+            The newly created role.
 
         Raises:
             EntityExistsError: If a role with the given name already exists.
         """
         if _get_unique_entity(
             role_name, collection=self.__store.roles, ensure_exists=False
         ):
@@ -712,17 +728,14 @@
         return role
 
     def _delete_role(self, role_name: str) -> None:
         """Deletes a role.
 
         Args:
             role_name: Name of the role to delete.
-
-        Raises:
-            KeyError: If no role with the given name exists.
         """
         role = _get_unique_entity(role_name, collection=self.__store.roles)
         self.__store.roles.remove(role)
         self.__store.role_assignments = [
             assignment
             for assignment in self.__store.role_assignments
             if assignment.role_id != role.id
@@ -742,17 +755,14 @@
 
         Args:
             role_name: Name of the role to assign.
             entity_name: User or team name.
             project_name: Optional project name.
             is_user: Boolean indicating whether the given `entity_name` refers
                 to a user.
-
-        Raises:
-            KeyError: If no role, entity or project with the given names exists.
         """
         role = _get_unique_entity(role_name, collection=self.__store.roles)
         project_id: Optional[UUID] = None
         if project_name:
             project_id = _get_unique_entity(
                 project_name, collection=self.__store.projects
             ).id
@@ -782,17 +792,14 @@
 
         Args:
             role_name: Name of the role to revoke.
             entity_name: User or team name.
             project_name: Optional project name.
             is_user: Boolean indicating whether the given `entity_name` refers
                 to a user.
-
-        Raises:
-            KeyError: If no role, entity or project with the given names exists.
         """
         role = _get_unique_entity(role_name, collection=self.__store.roles)
 
         user_id: Optional[UUID] = None
         team_id: Optional[UUID] = None
         project_id: Optional[UUID] = None
 
@@ -822,33 +829,27 @@
         """Fetches all users of a team.
 
         Args:
             team_name: Name of the team.
 
         Returns:
             List of users that are part of the team.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         team = _get_unique_entity(team_name, collection=self.__store.teams)
         user_names = self.__store.team_assignments[team.name]
         return [user for user in self.users if user.name in user_names]
 
     def get_teams_for_user(self, user_name: str) -> List[Team]:
         """Fetches all teams for a user.
 
         Args:
             user_name: Name of the user.
 
         Returns:
             List of teams that the user is part of.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         user = _get_unique_entity(user_name, collection=self.__store.users)
         team_names = [
             team_name
             for team_name, user_names in self.__store.team_assignments.items()
             if user.name in user_names
         ]
@@ -867,17 +868,14 @@
             project_name: Optional filter to only return roles assigned for
                 this project.
             include_team_roles: If `True`, includes roles for all teams that
                 the user is part of.
 
         Returns:
             List of role assignments for this user.
-
-        Raises:
-            KeyError: If no user or project with the given names exists.
         """
         user = _get_unique_entity(user_name, collection=self.__store.users)
         project_id = (
             _get_unique_entity(
                 project_name, collection=self.__store.projects
             ).id
             if project_name
@@ -904,17 +902,14 @@
         Args:
             team_name: Name of the user.
             project_name: Optional filter to only return roles assigned for
                 this project.
 
         Returns:
             List of role assignments for this team.
-
-        Raises:
-            KeyError: If no team or project with the given names exists.
         """
         team = _get_unique_entity(team_name, collection=self.__store.teams)
         project_id = (
             _get_unique_entity(
                 project_name, collection=self.__store.projects
             ).id
             if project_name
@@ -936,14 +931,17 @@
 
         Args:
             pipeline_name: Name of the pipeline for which to get the run.
             run_name: Name of the pipeline run to get.
             project_name: Optional name of the project from which to get the
                 pipeline run.
 
+        Returns:
+            Pipeline run.
+
         Raises:
             KeyError: If no pipeline run (or project) with the given name
                 exists.
         """
         runs = self.__pipeline_store.pipeline_runs[pipeline_name]
 
         for run in runs:
@@ -967,14 +965,17 @@
     ) -> List[PipelineRunWrapper]:
         """Gets pipeline runs.
 
         Args:
             pipeline_name: Name of the pipeline for which to get runs.
             project_name: Optional name of the project from which to get the
                 pipeline runs.
+
+        Returns:
+            List of pipeline runs.
         """
         runs = self.__pipeline_store.pipeline_runs[pipeline_name]
         if project_name:
             runs = [run for run in runs if run.project_name == project_name]
 
         return runs
 
@@ -1032,21 +1033,20 @@
 
         Args:
             source: the source path to the implemented flavor.
             name: the name of the flavor.
             stack_component_type: the corresponding StackComponentType.
 
         Returns:
-             The newly created flavor.
+            The newly created flavor.
 
         Raises:
             EntityExistsError: If a flavor with the given name and type
                 already exists.
         """
-
         if _get_unique_entity(
             name,
             collection=self.get_flavors_by_type(stack_component_type),
             ensure_exists=False,
         ):
             raise EntityExistsError(
                 f"The flavor '{name}' for the stack component type "
@@ -1090,42 +1090,53 @@
 
         Args:
             flavor_name: The name of the flavor.
             component_type: Optional, the type of the component.
 
         Returns:
             Flavor instance if it exists
-
-        Raises:
-            KeyError: If no flavor exists with the given name and type
-                or there are more than one instances
         """
         matches = self.get_flavors_by_type(component_type)
         return _get_unique_entity(
             entity_name=flavor_name,
             collection=matches,
             ensure_exists=True,
         )
 
     # Implementation-specific internal methods:
 
     @property
     def root(self) -> Path:
-        """The root directory of the zen store."""
+        """The root directory of the zen store.
+
+        Returns:
+            The root directory of the zen store.
+
+        Raises:
+            RuntimeError: If the local ZenStore has not been initialized.
+        """
         if not self._root:
             raise RuntimeError(
                 "Local zen store has not been initialized. Call `initialize` "
                 "before using the store."
             )
         return self._root
 
     def _get_stack_component_config_path(
         self, component_type: StackComponentType, name: str
     ) -> str:
-        """Path to the configuration file of a stack component."""
+        """Path to the configuration file of a stack component.
+
+        Args:
+            component_type: The type of the stack component.
+            name: The name of the stack component.
+
+        Returns:
+            The path to the configuration file of the stack component.
+        """
         path = self.root / component_type.plural / f"{name}.yaml"
         return str(path)
 
     def _get_role_assignments(
         self,
         role_id: Optional[UUID] = None,
         project_id: Optional[UUID] = None,
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/__init__.py` & `zenml-0.9.0/src/zenml/zen_stores/models/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Initialization for ZenML models submodule."""
+
 from zenml.zen_stores.models.component_wrapper import ComponentWrapper
 from zenml.zen_stores.models.flavor_wrapper import FlavorWrapper
 from zenml.zen_stores.models.stack_wrapper import StackWrapper
 from zenml.zen_stores.models.user_management_models import (
     Project,
     Role,
     RoleAssignment,
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/component_wrapper.py` & `zenml-0.9.0/src/zenml/zen_stores/models/component_wrapper.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Component wrapper implementation."""
 
 import base64
 import json
 from typing import TYPE_CHECKING
 from uuid import UUID
 
 import yaml
@@ -26,43 +27,48 @@
 if TYPE_CHECKING:
     from zenml.stack import StackComponent
 
 logger = get_logger(__name__)
 
 
 class ComponentWrapper(BaseModel):
-    """Serializable Configuration of a StackComponent"""
+    """Serializable Configuration of a StackComponent."""
 
     type: StackComponentType
     flavor: str
     name: str
     uuid: UUID
     config: bytes  # b64 encoded yaml config
 
     @classmethod
     def from_component(cls, component: "StackComponent") -> "ComponentWrapper":
-        """Creates a ComponentWrapper from an actual instance of a Stack
-        Component.
+        """Creates a ComponentWrapper from an instance of a Stack Component.
 
         Args:
             component: the instance of a StackComponent
+
+        Returns:
+            a ComponentWrapper
         """
         return cls(
             type=component.TYPE,
             flavor=component.FLAVOR,
             name=component.name,
             uuid=component.uuid,
             config=base64.b64encode(
                 yaml.dump(json.loads(component.json())).encode()
             ),
         )
 
     def to_component(self) -> "StackComponent":
-        """Converts the ComponentWrapper into an actual instance of a Stack
-        Component."""
+        """Converts the ComponentWrapper into an actual instance of a Stack Component.
+
+        Returns:
+            a StackComponent
+        """
         from zenml.repository import Repository
 
         flavor = Repository(skip_repository_check=True).get_flavor(  # type: ignore[call-arg]
             name=self.flavor, component_type=self.type
         )
 
         config = yaml.safe_load(base64.b64decode(self.config).decode())
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/flavor_wrapper.py` & `zenml-0.9.0/src/zenml/zen_stores/models/flavor_wrapper.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,39 +7,46 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Flavor wrapper implementation."""
+
 from typing import Optional, Type
 
 from pydantic import BaseModel
 
 from zenml.enums import StackComponentType
 from zenml.stack.stack_component import StackComponent
 from zenml.utils.source_utils import (
     load_source_path_class,
     validate_flavor_source,
 )
 
 
 class FlavorWrapper(BaseModel):
-    """Network serializable wrapper representing the custom implementation of
-    a stack component flavor."""
+    """Network serializable wrapper.
+
+    This represents the custom implementation of a stack component flavor.
+    """
 
     name: str
     type: StackComponentType
     source: str
     integration: Optional[str]
 
     @property
     def reachable(self) -> bool:
-        """Property to which indicates whether ZenML can import the module
-        within the source."""
+        """Indicates whether ZenML can import the module within the source.
+
+        Returns:
+            True if the source is reachable, False otherwise.
+        """
         from zenml.integrations.registry import integration_registry
 
         if self.integration:
             if self.integration == "built-in":
                 return True
             else:
                 return integration_registry.is_installed(self.integration)
@@ -57,23 +64,33 @@
 
     @classmethod
     def from_flavor(cls, flavor: Type[StackComponent]) -> "FlavorWrapper":
         """Creates a FlavorWrapper from a flavor class.
 
         Args:
             flavor: the class which defines the flavor
+
+        Returns:
+            a FlavorWrapper
         """
         return FlavorWrapper(
             name=flavor.FLAVOR,
             type=flavor.TYPE,
             source=flavor.__module__ + "." + flavor.__name__,
         )
 
     def to_flavor(self) -> Type[StackComponent]:
-        """Imports and returns the class of the flavor."""
+        """Imports and returns the class of the flavor.
+
+        Returns:
+            the class of the flavor
+
+        Raises:
+            ImportError: if the flavor is not able to be imported.
+        """
         try:
             return load_source_path_class(source=self.source)  # noqa
         except (ModuleNotFoundError, ImportError, NotImplementedError):
             if self.integration:
                 raise ImportError(
                     f"The {self.type} flavor '{self.name}' is "
                     f"a part of ZenML's '{self.integration}' "
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/pipeline_models.py` & `zenml-0.9.0/src/zenml/zen_stores/models/pipeline_models.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Pipeline models implementation."""
+
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, cast
 from uuid import UUID
 
 from pydantic import BaseModel, Field
 
 import zenml
 from zenml.logger import get_logger
@@ -32,14 +34,18 @@
 
     If the current working directory is not inside a git repo, this will return
     `None`.
 
     Args:
         clean: If `True` and there any untracked files or files in the index or
             working tree, this function will return `None`.
+
+    Returns:
+        The current git HEAD SHA or `None` if the current working directory is
+        not inside a git repo.
     """
     try:
         from git.exc import InvalidGitRepositoryError
         from git.repo.base import Repo
     except ImportError:
         return None
 
@@ -62,15 +68,22 @@
     """
 
     name: str
     docstring: Optional[str]
 
     @classmethod
     def from_step(cls, step: "BaseStep") -> "StepWrapper":
-        """Creates a StepWrapper from a step instance."""
+        """Creates a StepWrapper from a step instance.
+
+        Args:
+            step: The step instance.
+
+        Returns:
+            A StepWrapper instance.
+        """
         return cls(
             name=step.name,
             docstring=step.__doc__,
         )
 
 
 class PipelineWrapper(BaseModel):
@@ -84,15 +97,22 @@
 
     name: str
     docstring: Optional[str]
     steps: List[StepWrapper]
 
     @classmethod
     def from_pipeline(cls, pipeline: "BasePipeline") -> "PipelineWrapper":
-        """Creates a PipelineWrapper from a pipeline instance."""
+        """Creates a PipelineWrapper from a pipeline instance.
+
+        Args:
+            pipeline: The pipeline instance.
+
+        Returns:
+            A PipelineWrapper instance.
+        """
         steps = [
             StepWrapper.from_step(step) for step in pipeline.steps.values()
         ]
 
         return cls(
             name=pipeline.name,
             docstring=pipeline.__doc__,
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/stack_wrapper.py` & `zenml-0.9.0/src/zenml/zen_stores/models/stack_wrapper.py`

 * *Files 8% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Stack wrapper implementation."""
+
 from typing import List, Optional
 
 from pydantic import BaseModel
 
 from zenml.enums import StackComponentType
 from zenml.stack import Stack
 from zenml.zen_stores.models import ComponentWrapper
@@ -28,37 +30,51 @@
 
     @classmethod
     def from_stack(cls, stack: Stack) -> "StackWrapper":
         """Creates a StackWrapper from an actual Stack instance.
 
         Args:
             stack: the instance of a Stack
+
+        Returns:
+            a StackWrapper
         """
         return cls(
             name=stack.name,
             components=[
                 ComponentWrapper.from_component(component)
                 for t, component in stack.components.items()
             ],
         )
 
     def to_stack(self) -> Stack:
-        """Creates the corresponding Stack instance from the wrapper."""
+        """Creates the corresponding Stack instance from the wrapper.
+
+        Returns:
+            the corresponding Stack instance
+        """
         stack_components = {}
         for component_wrapper in self.components:
             component_type = component_wrapper.type
             component = component_wrapper.to_component()
             stack_components[component_type] = component
 
         return Stack.from_components(
             name=self.name, components=stack_components
         )
 
     def get_component_wrapper(
         self, component_type: StackComponentType
     ) -> Optional[ComponentWrapper]:
-        """Returns the component of the given type."""
+        """Returns the component of the given type.
+
+        Args:
+            component_type: the type of the component to return
+
+        Returns:
+            the component of the given type or None if not found
+        """
         for component_wrapper in self.components:
             if component_wrapper.type == component_type:
                 return component_wrapper
 
         return None
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/user_management_models.py` & `zenml-0.9.0/src/zenml/zen_stores/models/user_management_models.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""User management models implementation."""
+
 from datetime import datetime
 from enum import Enum
 from typing import Any, Dict, Optional, Set
 from uuid import UUID, uuid4
 
 from pydantic import BaseModel, Field, root_validator
 
@@ -53,14 +55,16 @@
         types: Types of permissions.
     """
 
     operation: Operation
     types: Set[PermissionType]
 
     class Config:
+        """Pydantic configuration."""
+
         # similar to non-mutable but also makes the object hashable
         frozen = True
 
 
 class Role(BaseModel):
     """Pydantic object representing a role.
 
@@ -140,16 +144,25 @@
     role_id: UUID
     project_id: Optional[UUID] = None
     team_id: Optional[UUID] = None
     user_id: Optional[UUID] = None
 
     @root_validator
     def ensure_single_entity(cls, values: Dict[str, Any]) -> Dict[str, Any]:
-        """Validates that either `user_id` or `team_id` is set."""
+        """Validates that either `user_id` or `team_id` is set.
+
+        Args:
+            values: The values to validate.
+
+        Returns:
+            The validated values.
 
+        Raises:
+            ValueError: If neither `user_id` nor `team_id` is set.
+        """
         user_id = values.get("user_id", None)
         team_id = values.get("team_id", None)
         if user_id and team_id:
             raise ValueError("Only `user_id` or `team_id` is allowed.")
 
         if not (user_id or team_id):
             raise ValueError(
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/models/zen_store_model.py` & `zenml-0.9.0/src/zenml/zen_stores/models/zen_store_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""Zen Store model."""
 
 from collections import defaultdict
 from typing import DefaultDict, Dict, List, Set
 
 from pydantic import Field, validator
 
 from zenml.enums import StackComponentType
@@ -41,16 +42,24 @@
         default=defaultdict(list)
     )
 
     @validator("pipeline_runs")
     def _construct_pipeline_runs_defaultdict(
         cls, pipeline_runs: Dict[str, List[PipelineRunWrapper]]
     ) -> DefaultDict[str, List[PipelineRunWrapper]]:
-        """Ensures that `pipeline_runs` is a defaultdict so runs
-        of a new pipeline can be added without issues."""
+        """Ensures that `pipeline_runs` is a defaultdict.
+
+        This is so runs of a new pipeline can be added without issues.
+
+        Args:
+            pipeline_runs: the dictionary of pipeline runs.
+
+        Returns:
+            The defaultdict of pipeline runs
+        """
         return defaultdict(list, pipeline_runs)
 
     class Config:
         """Pydantic configuration class."""
 
         # Validate attributes when assigning them. We need to set this in order
         # to have a mix of mutable and immutable attributes
@@ -95,24 +104,41 @@
         default=defaultdict(set)
     )
 
     @validator("stack_components")
     def _construct_stack_components_defaultdict(
         cls, stack_components: Dict[StackComponentType, Dict[str, str]]
     ) -> DefaultDict[StackComponentType, Dict[str, str]]:
-        """Ensures that `stack_components` is a defaultdict so stack
-        components of a new component type can be added without issues."""
+        """Ensures that `stack_components` is a defaultdict.
+
+        This is so stack components of a new component type can be added without
+        issues.
+
+        Args:
+            stack_components: the dictionary of stack components
+
+        Returns:
+            Stack components dictionary.
+        """
         return defaultdict(dict, stack_components)
 
     @validator("team_assignments")
     def _construct_team_assignments_defaultdict(
         cls, team_assignments: Dict[str, Set[str]]
     ) -> DefaultDict[str, Set[str]]:
-        """Ensures that `team_assignments` is a defaultdict so users
-        of a new teams can be added without issues."""
+        """Ensures that `team_assignments` is a defaultdict.
+
+        This is so users of a new teams can be added without issues.
+
+        Args:
+            team_assignments: the dictionary of team assignments.
+
+        Returns:
+            Team assignments dictionary.
+        """
         return defaultdict(set, team_assignments)
 
     class Config:
         """Pydantic configuration class."""
 
         # Validate attributes when assigning them. We need to set this in order
         # to have a mix of mutable and immutable attributes
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/rest_zen_store.py` & `zenml-0.9.0/src/zenml/zen_stores/rest_zen_store.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""REST Zen Store implementation."""
+
 import re
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Tuple, Union, cast
 
 import requests
 from pydantic import BaseModel
 
@@ -55,15 +57,15 @@
 logger = get_logger(__name__)
 
 # type alias for possible json payloads (the Anys are recursive Json instances)
 Json = Union[Dict[str, Any], List[Any], str, int, float, bool, None]
 
 
 class RestZenStore(BaseZenStore):
-    """ZenStore implementation for accessing data from a REST api."""
+    """ZenStore implementation for accessing data from a REST API."""
 
     def initialize(
         self,
         url: str,
         *args: Any,
         **kwargs: Any,
     ) -> "RestZenStore":
@@ -72,14 +74,17 @@
         Args:
             url: Endpoint URL of the service for zen storage.
             args: additional positional arguments (ignored).
             kwargs: additional keyword arguments (ignored).
 
         Returns:
             The initialized zen store instance.
+
+        Raises:
+            ValueError: if the url is not a valid URL.
         """
         if not self.is_valid_url(url.strip("/")):
             raise ValueError("Invalid URL for REST store: {url}")
         self._url = url.strip("/")
         super().initialize(url, *args, **kwargs)
         return self
 
@@ -94,61 +99,79 @@
     def get_path_from_url(url: str) -> Optional[Path]:
         """Get the path from a URL, if it points or is backed by a local file.
 
         Args:
             url: The URL to get the path from.
 
         Returns:
-            None, because there are no local paths from REST urls.
+            None, because there are no local paths from REST URLs.
         """
         return None
 
     @staticmethod
     def get_local_url(path: str) -> str:
         """Get a local URL for a given local path.
 
         Args:
-             path: the path string to build a URL out of.
-
-        Returns:
-            Url pointing to the path for the store type.
+            path: the path string to build a URL out of.
 
         Raises:
             NotImplementedError: always
         """
         raise NotImplementedError("Cannot build a REST url from a path.")
 
     @staticmethod
     def is_valid_url(url: str) -> bool:
-        """Check if the given url is a valid local path."""
+        """Check if the given url is a valid local path.
+
+        Args:
+            url: The url to check.
+
+        Returns:
+            True, if the url is a valid local path, False otherwise.
+        """
         scheme = re.search("^([a-z0-9]+://)", url)
         return (
             scheme is not None
             and scheme.group() in ("https://", "http://")
             and url[-1] != "/"
         )
 
     # Public Interface:
 
     @property
     def type(self) -> StoreType:
-        """The type of stack store."""
+        """The type of stack store.
+
+        Returns:
+            The type of the stack store.
+        """
         return StoreType.REST
 
     @property
     def url(self) -> str:
-        """Get the stack store URL."""
+        """Get the stack store URL.
+
+        Returns:
+            The URL of the stack store.
+        """
         return self._url
 
     @property
     def stacks_empty(self) -> bool:
         """Check if the store is empty (no stacks are configured).
 
         The implementation of this method should check if the store is empty
         without having to load all the stacks from the persistent storage.
+
+        Returns:
+            True, if the store is empty, False otherwise.
+
+        Raises:
+            ValueError: if the response is not a boolean.
         """
         empty = self.get(STACKS_EMPTY)
         if not isinstance(empty, bool):
             raise ValueError(
                 f"Bad API Response. Expected boolean, got:\n{empty}"
             )
         return empty
@@ -159,28 +182,28 @@
         """Fetches a stack configuration by name.
 
         Args:
             name: The name of the stack to fetch.
 
         Returns:
             Dict[StackComponentType, str] for the requested stack name.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         return self._parse_stack_configuration(
             self.get(f"{STACK_CONFIGURATIONS}/{name}")
         )
 
     @property
     def stack_configurations(self) -> Dict[str, Dict[StackComponentType, str]]:
         """Configurations for all stacks registered in this stack store.
 
         Returns:
             Dictionary mapping stack names to Dict[StackComponentType, str]'s
+
+        Raises:
+            ValueError: If the API response is not a dict.
         """
         body = self.get(STACK_CONFIGURATIONS)
         if not isinstance(body, dict):
             raise ValueError(
                 f"Bad API Response. Expected dict, got {type(body)}"
             )
         return {
@@ -192,18 +215,14 @@
         self,
         component: ComponentWrapper,
     ) -> None:
         """Register a stack component.
 
         Args:
             component: The component to register.
-
-        Raises:
-            KeyError: If a stack component with the same type
-                and name already exists.
         """
         self.post(STACK_COMPONENTS, body=component)
 
     def _update_stack_component(
         self,
         name: str,
         component_type: StackComponentType,
@@ -212,16 +231,19 @@
         """Update a stack component.
 
         Args:
             name: The original name of the stack component.
             component_type: The type of the stack component to update.
             component: The new component to update with.
 
+        Returns:
+            The updated component.
+
         Raises:
-            KeyError: If no stack component exists with the given name.
+            ValueError: in cases of a bad API response.
         """
         body = self.put(
             f"{STACK_COMPONENTS}/{component_type}/{name}", body=component
         )
         if isinstance(body, dict):
             return cast(Dict[str, str], body)
         else:
@@ -230,38 +252,45 @@
             )
 
     def _deregister_stack(self, name: str) -> None:
         """Delete a stack from storage.
 
         Args:
             name: The name of the stack to be deleted.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         self.delete(f"{STACKS}/{name}")
 
     def _save_stack(
         self,
         name: str,
         stack_configuration: Dict[StackComponentType, str],
     ) -> None:
         """Add a stack to storage.
 
         Args:
             name: The name to save the stack as.
             stack_configuration: Dict[StackComponentType, str] to persist.
+
+        Raises:
+            NotImplementedError: always.
         """
         raise NotImplementedError
 
     # Custom implementations:
 
     @property
     def stacks(self) -> List[StackWrapper]:
-        """All stacks registered in this repository."""
+        """All stacks registered in this repository.
+
+        Returns:
+            List[StackWrapper] of all stacks registered in this repository.
+
+        Raises:
+            ValueError: If the API response is not a list of stacks.
+        """
         body = self.get(STACKS)
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
         return [StackWrapper.parse_obj(s) for s in body]
 
@@ -269,34 +298,25 @@
         """Fetch a stack by name.
 
         Args:
             name: The name of the stack to retrieve.
 
         Returns:
             StackWrapper instance if the stack exists.
-
-        Raises:
-            KeyError: If no stack exists for the given name.
         """
         return StackWrapper.parse_obj(self.get(f"{STACKS}/{name}"))
 
     def _register_stack(self, stack: StackWrapper) -> None:
         """Register a stack and its components.
 
         If any of the stacks' components aren't registered in the stack store
         yet, this method will try to register them as well.
 
         Args:
             stack: The stack to register.
-
-        Raises:
-            StackExistsError: If a stack with the same name already exists.
-            StackComponentExistsError: If a component of the stack wasn't
-                registered and a different component with the same name
-                already exists.
         """
         self.post(STACKS, stack)
 
     def _update_stack(self, name: str, stack: StackWrapper) -> None:
         """Update a stack and its components.
 
         If any of the stack's components aren't registered in the stack store
@@ -311,16 +331,20 @@
             self.deregister_stack(name)
 
     def get_stack_component(
         self, component_type: StackComponentType, name: str
     ) -> ComponentWrapper:
         """Get a registered stack component.
 
-        Raises:
-            KeyError: If no component with the requested type and name exists.
+        Args:
+            component_type: The type of the component to retrieve.
+            name: The name of the component to retrieve.
+
+        Returns:
+            ComponentWrapper instance if the component exists.
         """
         return ComponentWrapper.parse_obj(
             self.get(f"{STACK_COMPONENTS}/{component_type}/{name}")
         )
 
     def get_stack_components(
         self, component_type: StackComponentType
@@ -328,14 +352,17 @@
         """Fetches all registered stack components of the given type.
 
         Args:
             component_type: StackComponentType to list members of
 
         Returns:
             A list of StackComponentConfiguration instances.
+
+        Raises:
+            ValueError: If the API response is not a list of components.
         """
         body = self.get(f"{STACK_COMPONENTS}/{component_type}")
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
         return [ComponentWrapper.parse_obj(c) for c in body]
@@ -344,18 +371,14 @@
         self, component_type: StackComponentType, name: str
     ) -> None:
         """Deregisters a stack component.
 
         Args:
             component_type: The type of the component to deregister.
             name: The name of the component to deregister.
-
-        Raises:
-            ValueError: if trying to deregister a component that's part
-                of a stack.
         """
         self.delete(f"{STACK_COMPONENTS}/{component_type}/{name}")
 
     # User, project and role management
 
     @property
     def users(self) -> List[User]:
@@ -378,43 +401,34 @@
         """Get a specific user by name.
 
         Args:
             user_name: Name of the user to get.
 
         Returns:
             The requested user, if it was found.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         return User.parse_obj(self.get(f"{USERS}/{user_name}"))
 
     def _create_user(self, user_name: str) -> User:
         """Creates a new user.
 
         Args:
             user_name: Unique username.
 
         Returns:
-             The newly created user.
-
-        Raises:
-            EntityExistsError: If a user with the given name already exists.
+            The newly created user.
         """
         user = User(name=user_name)
         return User.parse_obj(self.post(USERS, body=user))
 
     def _delete_user(self, user_name: str) -> None:
         """Deletes a user.
 
         Args:
             user_name: Name of the user to delete.
-
-        Raises:
-            KeyError: If no user with the given name exists.
         """
         self.delete(f"{USERS}/{user_name}")
 
     @property
     def teams(self) -> List[Team]:
         """All registered teams.
 
@@ -435,68 +449,53 @@
         """Gets a specific team.
 
         Args:
             team_name: Name of the team to get.
 
         Returns:
             The requested team.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         return Team.parse_obj(self.get(f"{TEAMS}/{team_name}"))
 
     def _create_team(self, team_name: str) -> Team:
         """Creates a new team.
 
         Args:
             team_name: Unique team name.
 
         Returns:
-             The newly created team.
-
-        Raises:
-            EntityExistsError: If a team with the given name already exists.
+            The newly created team.
         """
         team = Team(name=team_name)
         return Team.parse_obj(self.post(TEAMS, body=team))
 
     def _delete_team(self, team_name: str) -> None:
         """Deletes a team.
 
         Args:
             team_name: Name of the team to delete.
-
-        Raises:
-            KeyError: If no team with the given name exists.
         """
         self.delete(f"{TEAMS}/{team_name}")
 
     def add_user_to_team(self, team_name: str, user_name: str) -> None:
         """Adds a user to a team.
 
         Args:
             team_name: Name of the team.
             user_name: Name of the user.
-
-        Raises:
-            KeyError: If no user and team with the given names exists.
         """
         user = User(name=user_name)
         self.post(f"{TEAMS}/{team_name}/users", user)
 
     def remove_user_from_team(self, team_name: str, user_name: str) -> None:
         """Removes a user from a team.
 
         Args:
             team_name: Name of the team.
             user_name: Name of the user.
-
-        Raises:
-            KeyError: If no user and team with the given names exists.
         """
         self.delete(f"{TEAMS}/{team_name}/users/{user_name}")
 
     @property
     def projects(self) -> List[Project]:
         """All registered projects.
 
@@ -517,46 +516,37 @@
         """Get an existing project by name.
 
         Args:
             project_name: Name of the project to get.
 
         Returns:
             The requested project if one was found.
-
-        Raises:
-            KeyError: If there is no such project.
         """
         return Project.parse_obj(self.get(f"{PROJECTS}/{project_name}"))
 
     def _create_project(
         self, project_name: str, description: Optional[str] = None
     ) -> Project:
         """Creates a new project.
 
         Args:
             project_name: Unique project name.
             description: Optional project description.
 
         Returns:
-             The newly created project.
-
-        Raises:
-            EntityExistsError: If a project with the given name already exists.
+            The newly created project.
         """
         project = Project(name=project_name, description=description)
         return Project.parse_obj(self.post(PROJECTS, body=project))
 
     def _delete_project(self, project_name: str) -> None:
         """Deletes a project.
 
         Args:
             project_name: Name of the project to delete.
-
-        Raises:
-            KeyError: If no project with the given name exists.
         """
         self.delete(f"{PROJECTS}/{project_name}")
 
     @property
     def roles(self) -> List[Role]:
         """All registered roles.
 
@@ -597,43 +587,34 @@
         """Gets a specific role.
 
         Args:
             role_name: Name of the role to get.
 
         Returns:
             The requested role.
-
-        Raises:
-            KeyError: If no role with the given name exists.
         """
         return Role.parse_obj(self.get(f"{ROLES}/{role_name}"))
 
     def _create_role(self, role_name: str) -> Role:
         """Creates a new role.
 
         Args:
             role_name: Unique role name.
 
         Returns:
-             The newly created role.
-
-        Raises:
-            EntityExistsError: If a role with the given name already exists.
+            The newly created role.
         """
         role = Role(name=role_name)
         return Role.parse_obj(self.post(ROLES, body=role))
 
     def _delete_role(self, role_name: str) -> None:
         """Deletes a role.
 
         Args:
             role_name: Name of the role to delete.
-
-        Raises:
-            KeyError: If no role with the given name exists.
         """
         self.delete(f"{ROLES}/{role_name}")
 
     def assign_role(
         self,
         role_name: str,
         entity_name: str,
@@ -644,17 +625,14 @@
 
         Args:
             role_name: Name of the role to assign.
             entity_name: User or team name.
             project_name: Optional project name.
             is_user: Boolean indicating whether the given `entity_name` refers
                 to a user.
-
-        Raises:
-            KeyError: If no role, entity or project with the given names exists.
         """
         data = {
             "role_name": role_name,
             "entity_name": entity_name,
             "project_name": project_name,
             "is_user": is_user,
         }
@@ -677,17 +655,14 @@
 
         Args:
             role_name: Name of the role to revoke.
             entity_name: User or team name.
             project_name: Optional project name.
             is_user: Boolean indicating whether the given `entity_name` refers
                 to a user.
-
-        Raises:
-            KeyError: If no role, entity or project with the given names exists.
         """
         data = {
             "role_name": role_name,
             "entity_name": entity_name,
             "project_name": project_name,
             "is_user": is_user,
         }
@@ -705,15 +680,14 @@
         Args:
             team_name: Name of the team.
 
         Returns:
             List of users that are part of the team.
 
         Raises:
-            KeyError: If no team with the given name exists.
             ValueError: In case of a bad API response.
         """
         body = self.get(f"{TEAMS}/{team_name}/users")
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
@@ -725,15 +699,14 @@
         Args:
             user_name: Name of the user.
 
         Returns:
             List of teams that the user is part of.
 
         Raises:
-            KeyError: If no user with the given name exists.
             ValueError: In case of a bad API response.
         """
         body = self.get(f"{USERS}/{user_name}/teams")
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
@@ -754,15 +727,14 @@
             include_team_roles: If `True`, includes roles for all teams that
                 the user is part of.
 
         Returns:
             List of role assignments for this user.
 
         Raises:
-            KeyError: If no user or project with the given names exists.
             ValueError: In case of a bad API response.
         """
         path = f"{USERS}/{user_name}/role_assignments"
         if project_name:
             path += f"?project_name={project_name}"
 
         body = self.get(path)
@@ -793,15 +765,14 @@
             project_name: Optional filter to only return roles assigned for
                 this project.
 
         Returns:
             List of role assignments for this team.
 
         Raises:
-            KeyError: If no user or project with the given names exists.
             ValueError: In case of a bad API response.
         """
         path = f"{TEAMS}/{team_name}/role_assignments"
         if project_name:
             path += f"?project_name={project_name}"
 
         body = self.get(path)
@@ -826,17 +797,16 @@
 
         Args:
             pipeline_name: Name of the pipeline for which to get the run.
             run_name: Name of the pipeline run to get.
             project_name: Optional name of the project from which to get the
                 pipeline run.
 
-        Raises:
-            KeyError: If no pipeline run (or project) with the given name
-                exists.
+        Returns:
+            A pipeline run object.
         """
         path = f"{PIPELINE_RUNS}/{pipeline_name}/{run_name}"
         if project_name:
             path += f"?project_name={project_name}"
 
         body = self.get(path)
         return PipelineRunWrapper.parse_obj(body)
@@ -846,14 +816,20 @@
     ) -> List[PipelineRunWrapper]:
         """Gets pipeline runs.
 
         Args:
             pipeline_name: Name of the pipeline for which to get runs.
             project_name: Optional name of the project from which to get the
                 pipeline runs.
+
+        Returns:
+            List of pipeline runs.
+
+        Raises:
+            ValueError: In case of a bad API response.
         """
         path = f"{PIPELINE_RUNS}/{pipeline_name}"
         if project_name:
             path += f"?project_name={project_name}"
 
         body = self.get(path)
         if not isinstance(body, list):
@@ -866,59 +842,89 @@
         self,
         pipeline_run: PipelineRunWrapper,
     ) -> None:
         """Registers a pipeline run.
 
         Args:
             pipeline_run: The pipeline run to register.
-
-        Raises:
-            EntityExistsError: If a pipeline run with the same name already
-                exists.
         """
         self.post(PIPELINE_RUNS, body=pipeline_run)
 
     # Private interface shall not be implemented for REST store, instead the
     # API only provides all public methods, including the ones that would
     # otherwise be inherited from the BaseZenStore in other implementations.
     # Don't call these! ABC complains that they aren't implemented, but they
     # aren't needed with the custom implementations of base methods.
 
     def _create_stack(
         self, name: str, stack_configuration: Dict[StackComponentType, str]
     ) -> None:
-        """Add a stack to storage"""
+        """Add a stack to storage.
+
+        Args:
+            name: Name of the stack.
+            stack_configuration: Configuration of the stack.
+
+        Raises:
+            NotImplementedError: If this method is called.
+        """
         raise NotImplementedError("Not to be accessed directly in client!")
 
     def _get_component_flavor_and_config(
         self, component_type: StackComponentType, name: str
     ) -> Tuple[str, bytes]:
-        """Fetch the flavor and configuration for a stack component."""
+        """Fetch the flavor and configuration for a stack component.
+
+        Args:
+            component_type: Type of the component.
+            name: Name of the component.
+
+        Raises:
+            NotImplementedError: If the component type is not supported.
+        """
         raise NotImplementedError("Not to be accessed directly in client!")
 
     def _get_stack_component_names(
         self, component_type: StackComponentType
     ) -> List[str]:
-        """Get names of all registered stack components of a given type."""
+        """Get names of all registered stack components of a given type.
+
+        Args:
+            component_type: Type of the components.
+
+        Raises:
+            NotImplementedError: always
+        """
         raise NotImplementedError("Not to be accessed directly in client!")
 
     def _delete_stack_component(
         self, component_type: StackComponentType, name: str
     ) -> None:
-        """Remove a StackComponent from storage."""
+        """Remove a StackComponent from storage.
+
+        Args:
+            component_type: Type of the component.
+            name: Name of the component.
+
+        Raises:
+            NotImplementedError: always.
+        """
         raise NotImplementedError("Not to be accessed directly in client!")
 
     # Handling stack component flavors
 
     @property
     def flavors(self) -> List[FlavorWrapper]:
         """All registered flavors.
 
         Returns:
             A list of all registered flavors.
+
+        Raises:
+            ValueError: If the API response is not a list.
         """
         body = self.get(FLAVORS)
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
         return [FlavorWrapper.parse_obj(flavor_dict) for flavor_dict in body]
@@ -933,19 +939,15 @@
 
         Args:
             source: the source path to the implemented flavor.
             name: the name of the flavor.
             stack_component_type: the corresponding StackComponentType.
 
         Returns:
-             The newly created flavor.
-
-        Raises:
-            EntityExistsError: If a flavor with the given name and type
-                already exists.
+            The newly created flavor.
         """
         flavor = FlavorWrapper(
             name=name,
             source=source,
             type=stack_component_type,
         )
         return FlavorWrapper.parse_obj(self.post(FLAVORS, body=flavor))
@@ -956,14 +958,17 @@
         """Fetch all flavor defined for a specific stack component type.
 
         Args:
             component_type: The type of the stack component.
 
         Returns:
             List of all the flavors for the given stack component type.
+
+        Raises:
+            ValueError: If a list of flavors is not returned.
         """
         body = self.get(f"{FLAVORS}/{component_type}")
         if not isinstance(body, list):
             raise ValueError(
                 f"Bad API Response. Expected list, got {type(body)}"
             )
         return [FlavorWrapper.parse_obj(flavor_dict) for flavor_dict in body]
@@ -977,40 +982,72 @@
 
         Args:
             flavor_name: The name of the flavor.
             component_type: Optional, the type of the component.
 
         Returns:
             Flavor instance if it exists
-
-        Raises:
-            KeyError: If no flavor exists with the given name and type
-                or there are more than one instances
         """
         return FlavorWrapper.parse_obj(
             self.get(f"{FLAVORS}/{component_type}/{flavor_name}")
         )
 
     # Implementation specific methods:
 
     def _parse_stack_configuration(
         self, to_parse: Json
     ) -> Dict[StackComponentType, str]:
-        """Parse an API response into `Dict[StackComponentType, str]`."""
+        """Parse an API response into `Dict[StackComponentType, str]`.
+
+        Args:
+            to_parse: The response to parse.
+
+        Returns:
+            A dictionary mapping the component type to the path to the
+            configuration.
+
+        Raises:
+            ValueError: If the response is not a dictionary.
+        """
         if not isinstance(to_parse, dict):
             raise ValueError(
                 f"Bad API Response. Expected dict, got {type(to_parse)}."
             )
         return {
             StackComponentType(typ): component_name
             for typ, component_name in to_parse.items()
         }
 
     def _handle_response(self, response: requests.Response) -> Json:
-        """Handle API response, translating http status codes to Exception."""
+        """Handle API response, translating http status codes to Exception.
+
+        Args:
+            response: The response to handle.
+
+        Returns:
+            The parsed response.
+
+        Raises:
+            DoesNotExistException: If the response indicates that the
+                requested entity does not exist.
+            EntityExistsError: If the response indicates that the requested
+                entity already exists.
+            HTTPError: If the response indicates that the requested entity
+                does not exist.
+            KeyError: If the response indicates that the requested entity
+                does not exist.
+            RuntimeError: If the response indicates that the requested entity
+                does not exist.
+            StackComponentExistsError: If the response indicates that the
+                requested entity already exists.
+            StackExistsError: If the response indicates that the requested
+                entity already exists.
+            ValueError: If the response indicates that the requested entity
+                does not exist.
+        """
         if response.status_code >= 200 and response.status_code < 300:
             try:
                 payload: Json = response.json()
                 return payload
             except requests.exceptions.JSONDecodeError:
                 raise ValueError(
                     "Bad response from API. Expected json, got\n"
@@ -1050,41 +1087,75 @@
             raise RuntimeError(
                 "Error retrieving from API. Got response "
                 f"{response.status_code} with body:\n{response.text}"
             )
 
     @staticmethod
     def _get_authentication() -> Tuple[str, str]:
-        """Gets HTTP basic auth credentials."""
+        """Gets HTTP basic auth credentials.
+
+        Returns:
+            A tuple of the username and password.
+        """
         from zenml.repository import Repository
 
         return Repository().active_user_name, ""
 
     def get(self, path: str) -> Json:
-        """Make a GET request to the given endpoint path."""
+        """Make a GET request to the given endpoint path.
+
+        Args:
+            path: The path to the endpoint.
+
+        Returns:
+            The response body.
+        """
         return self._handle_response(
             requests.get(self.url + path, auth=self._get_authentication())
         )
 
     def delete(self, path: str) -> Json:
-        """Make a DELETE request to the given endpoint path."""
+        """Make a DELETE request to the given endpoint path.
+
+        Args:
+            path: The path to the endpoint.
+
+        Returns:
+            The response body.
+        """
         return self._handle_response(
             requests.delete(self.url + path, auth=self._get_authentication())
         )
 
     def post(self, path: str, body: BaseModel) -> Json:
-        """Make a POST request to the given endpoint path."""
+        """Make a POST request to the given endpoint path.
+
+        Args:
+            path: The path to the endpoint.
+            body: The body to send.
+
+        Returns:
+            The response body.
+        """
         endpoint = self.url + path
         return self._handle_response(
             requests.post(
                 endpoint, data=body.json(), auth=self._get_authentication()
             )
         )
 
     def put(self, path: str, body: BaseModel) -> Json:
-        """Make a PUT request to the given endpoint path."""
+        """Make a PUT request to the given endpoint path.
+
+        Args:
+            path: The path to the endpoint.
+            body: The body to send.
+
+        Returns:
+            The response body.
+        """
         endpoint = self.url + path
         return self._handle_response(
             requests.put(
                 endpoint, data=body.json(), auth=self._get_authentication()
             )
         )
```

### Comparing `zenml-0.8.1rc0/src/zenml/zen_stores/sql_zen_store.py` & `zenml-0.9.0/src/zenml/zen_stores/sql_zen_store.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,30 +7,32 @@
 #       https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 #  or implied. See the License for the specific language governing
 #  permissions and limitations under the License.
+"""SQL Zen Store implementation."""
+
 import datetime as dt
 import json
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Tuple
 from uuid import UUID, uuid4
 
 from sqlalchemy.engine.url import make_url
 from sqlalchemy.exc import ArgumentError, NoResultFound
 from sqlmodel import Field, Session, SQLModel, create_engine, select
 from sqlmodel.sql.expression import Select, SelectOfScalar
 
 from zenml.enums import StackComponentType, StoreType
 from zenml.exceptions import EntityExistsError, StackComponentExistsError
-from zenml.io import utils
 from zenml.logger import get_logger
+from zenml.utils import io_utils
 from zenml.zen_stores import BaseZenStore
 from zenml.zen_stores.models import (
     ComponentWrapper,
     FlavorWrapper,
     Project,
     Role,
     RoleAssignment,
@@ -48,95 +50,124 @@
 SelectOfScalar.inherit_cache = True  # type: ignore
 Select.inherit_cache = True  # type: ignore
 
 logger = get_logger(__name__)
 
 
 def _sqlmodel_uuid() -> UUID:
-    """Generates a UUID whose hex string does not start with a '0'."""
+    """Generates a UUID whose hex string does not start with a '0'.
+
+    Returns:
+        A UUID whose hex string does not start with a '0'.
+    """
     # SQLModel crashes when a UUID hex string starts with '0'
     # (see: https://github.com/tiangolo/sqlmodel/issues/25)
     uuid = uuid4()
     while uuid.hex[0] == "0":
         uuid = uuid4()
     return uuid
 
 
 class ZenUser(SQLModel, table=True):
+    """SQL Model for users."""
+
     id: int = Field(primary_key=True)
     name: str
 
 
 class ZenStack(SQLModel, table=True):
+    """SQL Model for stacks."""
+
     name: str = Field(primary_key=True)
     created_by: int
     create_time: Optional[dt.datetime] = Field(default_factory=dt.datetime.now)
 
 
 class ZenStackComponent(SQLModel, table=True):
+    """SQL Model for stack components."""
+
     component_type: StackComponentType = Field(primary_key=True)
     name: str = Field(primary_key=True)
     component_flavor: str
     configuration: bytes  # e.g. base64 encoded json string
 
 
 class ZenFlavor(SQLModel, table=True):
+    """SQL Model for flavors."""
+
     type: StackComponentType = Field(primary_key=True)
     name: str = Field(primary_key=True)
     source: str
     integration: Optional[str]
 
 
 class ZenStackDefinition(SQLModel, table=True):
-    """Join table between Stacks and StackComponents"""
+    """SQL Model for stack definitions.
+
+    Join table between Stacks and StackComponents.
+    """
 
     stack_name: str = Field(primary_key=True, foreign_key="zenstack.name")
     component_type: StackComponentType = Field(
         primary_key=True, foreign_key="zenstackcomponent.component_type"
     )
     component_name: str = Field(
         primary_key=True, foreign_key="zenstackcomponent.name"
     )
 
 
 class UserTable(User, SQLModel, table=True):
+    """SQL Model for users."""
+
     id: UUID = Field(primary_key=True, default_factory=_sqlmodel_uuid)
 
 
 class TeamTable(Team, SQLModel, table=True):
+    """SQL Model for teams."""
+
     id: UUID = Field(primary_key=True, default_factory=_sqlmodel_uuid)
 
 
 class ProjectTable(Project, SQLModel, table=True):
+    """SQL Model for projects."""
+
     id: UUID = Field(primary_key=True, default_factory=_sqlmodel_uuid)
     creation_date: datetime = Field(default_factory=datetime.now)
 
 
 class RoleTable(SQLModel, table=True):
+    """SQL Model for roles."""
+
     id: UUID = Field(primary_key=True, default_factory=_sqlmodel_uuid)
     creation_date: datetime = Field(default_factory=datetime.now)
     name: str
 
 
 class TeamAssignmentTable(SQLModel, table=True):
+    """SQL Model for team assignments."""
+
     user_id: UUID = Field(primary_key=True, foreign_key="usertable.id")
     team_id: UUID = Field(primary_key=True, foreign_key="teamtable.id")
 
 
 class RoleAssignmentTable(RoleAssignment, SQLModel, table=True):
+    """SQL Model for role assignments."""
+
     id: UUID = Field(primary_key=True, default_factory=_sqlmodel_uuid)
     role_id: UUID = Field(foreign_key="roletable.id")
     user_id: Optional[UUID] = Field(default=None, foreign_key="usertable.id")
     team_id: Optional[UUID] = Field(default=None, foreign_key="teamtable.id")
     project_id: Optional[UUID] = Field(
         default=None, foreign_key="projecttable.id"
     )
 
 
 class PipelineRunTable(SQLModel, table=True):
+    """SQL Model for pipeline runs."""
+
     name: str = Field(primary_key=True)
     zenml_version: str
     git_sha: Optional[str]
 
     pipeline_name: str
     pipeline: str
     stack: str
@@ -147,65 +178,83 @@
         default=None, foreign_key="projecttable.name"
     )
 
     @classmethod
     def from_pipeline_run_wrapper(
         cls, wrapper: PipelineRunWrapper
     ) -> "PipelineRunTable":
+        """Creates a PipelineRunTable from a PipelineRunWrapper.
+
+        Args:
+            wrapper: The PipelineRunWrapper to create the PipelineRunTable from.
+
+        Returns:
+            A PipelineRunTable.
+        """
         return PipelineRunTable(
             name=wrapper.name,
             zenml_version=wrapper.zenml_version,
             git_sha=wrapper.git_sha,
             pipeline_name=wrapper.pipeline.name,
             pipeline=wrapper.pipeline.json(),
             stack=wrapper.stack.json(),
             runtime_configuration=json.dumps(wrapper.runtime_configuration),
             user_id=wrapper.user_id,
             project_name=wrapper.project_name,
         )
 
     def to_pipeline_run_wrapper(self) -> PipelineRunWrapper:
+        """Creates a PipelineRunWrapper from a PipelineRunTable.
+
+        Returns:
+            A PipelineRunWrapper.
+        """
         return PipelineRunWrapper(
             name=self.name,
             zenml_version=self.zenml_version,
             git_sha=self.git_sha,
             pipeline=PipelineWrapper.parse_raw(self.pipeline),
             stack=StackWrapper.parse_raw(self.stack),
             runtime_configuration=json.loads(self.runtime_configuration),
             user_id=self.user_id,
             project_name=self.project_name,
         )
 
 
 class SqlZenStore(BaseZenStore):
-    """Repository Implementation that uses SQL database backend"""
+    """Repository Implementation that uses SQL database backend."""
 
     def initialize(
         self,
         url: str,
         *args: Any,
         **kwargs: Any,
     ) -> "SqlZenStore":
         """Initialize a new SqlZenStore.
 
         Args:
             url: odbc path to a database.
-            args, kwargs: additional parameters for SQLModel.
+            *args: Additional positional arguments.
+            **kwargs: Additional keyword arguments.
+
         Returns:
             The initialized zen store instance.
+
+        Raises:
+            ValueError: If the database is not found.
         """
         if not self.is_valid_url(url):
             raise ValueError(f"Invalid URL for SQL store: {url}")
 
         logger.debug("Initializing SqlZenStore at %s", url)
         self._url = url
 
         local_path = self.get_path_from_url(url)
         if local_path:
-            utils.create_dir_recursive_if_not_exists(str(local_path.parent))
+            io_utils.create_dir_recursive_if_not_exists(str(local_path.parent))
 
         # we need to remove `skip_default_registrations` from the kwargs,
         # because SQLModel will raise an error if it is present
         sql_kwargs = kwargs.copy()
         sql_kwargs.pop("skip_default_registrations", False)
         sql_kwargs.pop("track_analytics", False)
         sql_kwargs.pop("skip_migration", False)
@@ -219,20 +268,31 @@
         super().initialize(url, *args, **kwargs)
         return self
 
     # Public interface implementations:
 
     @property
     def type(self) -> StoreType:
-        """The type of zen store."""
+        """The type of zen store.
+
+        Returns:
+            The type of zen store.
+        """
         return StoreType.SQL
 
     @property
     def url(self) -> str:
-        """URL of the repository."""
+        """URL of the repository.
+
+        Returns:
+            The URL of the repository.
+
+        Raises:
+            RuntimeError: If the SQL zen store is not initialized.
+        """
         if not self._url:
             raise RuntimeError(
                 "SQL zen store has not been initialized. Call `initialize` "
                 "before using the store."
             )
         return self._url
 
@@ -249,41 +309,62 @@
 
         Args:
             url: The URL to get the path from.
 
         Returns:
             The path extracted from the URL, or None, if the URL does not
             point to a local sqlite file.
+
+        Raises:
+            ValueError: If the URL is not a valid SQLite URL.
         """
         if not SqlZenStore.is_valid_url(url):
             raise ValueError(f"Invalid URL for SQL store: {url}")
         if not url.startswith("sqlite:///"):
             return None
         url = url.replace("sqlite:///", "")
         return Path(url)
 
     @staticmethod
     def get_local_url(path: str) -> str:
-        """Get a local SQL url for a given local path."""
+        """Get a local SQL url for a given local path.
+
+        Args:
+            path: The path to the local sqlite file.
+
+        Returns:
+            The local SQL url for the given path.
+        """
         return f"sqlite:///{path}/zenml.db"
 
     @staticmethod
     def is_valid_url(url: str) -> bool:
-        """Check if the given url is a valid SQL url."""
+        """Check if the given url is a valid SQL url.
+
+        Args:
+            url: The url to check.
+
+        Returns:
+            True if the url is a valid SQL url, False otherwise.
+        """
         try:
             make_url(url)
         except ArgumentError:
             logger.debug("Invalid SQL URL: %s", url)
             return False
 
         return True
 
     @property
     def stacks_empty(self) -> bool:
-        """Check if the zen store is empty."""
+        """Check if the zen store is empty.
+
+        Returns:
+            True if the zen store is empty, False otherwise.
+        """
         with Session(self.engine) as session:
             return session.exec(select(ZenStack)).first() is None
 
     def get_stack_configuration(
         self, name: str
     ) -> Dict[StackComponentType, str]:
         """Fetches a stack configuration by name.
@@ -379,16 +460,21 @@
         """Update a stack component.
 
         Args:
             name: The original name of the stack component.
             component_type: The type of the stack component to update.
             component: The new component to update with.
 
+        Returns:
+            The updated stack component.
+
         Raises:
             KeyError: If no stack component exists with the given name.
+            StackComponentExistsError: If a stack component with the same type
+                and name already exists.
         """
         with Session(self.engine) as session:
             updated_component = session.exec(
                 select(ZenStackComponent)
                 .where(ZenStackComponent.component_type == component_type)
                 .where(ZenStackComponent.name == name)
             ).first()
@@ -627,15 +713,15 @@
     def _create_user(self, user_name: str) -> User:
         """Creates a new user.
 
         Args:
             user_name: Unique username.
 
         Returns:
-             The newly created user.
+            The newly created user.
 
         Raises:
             EntityExistsError: If a user with the given name already exists.
         """
         with Session(self.engine) as session:
             existing_user = session.exec(
                 select(UserTable).where(UserTable.name == user_name)
@@ -718,15 +804,15 @@
     def _create_team(self, team_name: str) -> Team:
         """Creates a new team.
 
         Args:
             team_name: Unique team name.
 
         Returns:
-             The newly created team.
+            The newly created team.
 
         Raises:
             EntityExistsError: If a team with the given name already exists.
         """
         with Session(self.engine) as session:
             existing_team = session.exec(
                 select(TeamTable).where(TeamTable.name == team_name)
@@ -864,15 +950,15 @@
         """Creates a new project.
 
         Args:
             project_name: Unique project name.
             description: Optional project description.
 
         Returns:
-             The newly created project.
+            The newly created project.
 
         Raises:
             EntityExistsError: If a project with the given name already exists.
         """
         with Session(self.engine) as session:
             existing_project = session.exec(
                 select(ProjectTable).where(ProjectTable.name == project_name)
@@ -967,15 +1053,15 @@
     def _create_role(self, role_name: str) -> Role:
         """Creates a new role.
 
         Args:
             role_name: Unique role name.
 
         Returns:
-             The newly created role.
+            The newly created role.
 
         Raises:
             EntityExistsError: If a role with the given name already exists.
         """
         with Session(self.engine) as session:
             existing_role = session.exec(
                 select(RoleTable).where(RoleTable.name == role_name)
@@ -1286,14 +1372,17 @@
 
         Args:
             pipeline_name: Name of the pipeline for which to get the run.
             run_name: Name of the pipeline run to get.
             project_name: Optional name of the project from which to get the
                 pipeline run.
 
+        Returns:
+            Pipeline run.
+
         Raises:
             KeyError: If no pipeline run (or project) with the given name
                 exists.
         """
         with Session(self.engine) as session:
             try:
                 statement = (
@@ -1317,14 +1406,20 @@
     ) -> List[PipelineRunWrapper]:
         """Gets pipeline runs.
 
         Args:
             pipeline_name: Name of the pipeline for which to get runs.
             project_name: Optional name of the project from which to get the
                 pipeline runs.
+
+        Returns:
+            List of pipeline runs.
+
+        Raises:
+            KeyError: If no pipeline with the given name exists.
         """
         with Session(self.engine) as session:
             try:
                 statement = select(PipelineRunTable).where(
                     PipelineRunTable.pipeline_name == pipeline_name
                 )
 
@@ -1392,18 +1487,17 @@
     ) -> FlavorWrapper:
         """Creates a new flavor.
 
         Args:
             source: the source path to the implemented flavor.
             name: the name of the flavor.
             stack_component_type: the corresponding StackComponentType.
-            integration: the name of the integration.
 
         Returns:
-             The newly created flavor.
+            The newly created flavor.
 
         Raises:
             EntityExistsError: If a flavor with the given name and type
                 already exists.
         """
         with Session(self.engine) as session:
             existing_flavor = session.exec(
@@ -1487,17 +1581,25 @@
             except NoResultFound as error:
                 raise KeyError from error
 
     # Implementation-specific internal methods:
 
     @property
     def stack_names(self) -> List[str]:
-        """Names of all stacks registered in this ZenStore."""
+        """Names of all stacks registered in this ZenStore.
+
+        Returns:
+            List of all stack names.
+        """
         with Session(self.engine) as session:
             return [s.name for s in session.exec(select(ZenStack))]
 
     def _delete_query_results(self, query: Any) -> None:
-        """Deletes all rows returned by the input query."""
+        """Deletes all rows returned by the input query.
+
+        Args:
+            query: The query to execute.
+        """
         with Session(self.engine) as session:
             for result in session.exec(query).all():
                 session.delete(result)
             session.commit()
```

### Comparing `zenml-0.8.1rc0/setup.py` & `zenml-0.9.0/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,46 +2,51 @@
 from setuptools import setup
 
 package_dir = \
 {'': 'src'}
 
 packages = \
 ['zenml',
+ 'zenml.alerter',
  'zenml.artifact_stores',
  'zenml.artifacts',
  'zenml.cli',
  'zenml.config',
  'zenml.container_registries',
  'zenml.entrypoints',
  'zenml.experiment_trackers',
  'zenml.feature_stores',
  'zenml.integrations',
  'zenml.integrations.airflow',
  'zenml.integrations.airflow.orchestrators',
  'zenml.integrations.aws',
  'zenml.integrations.aws.container_registries',
- 'zenml.integrations.aws.secret_schemas',
  'zenml.integrations.aws.secrets_managers',
+ 'zenml.integrations.aws.step_operators',
  'zenml.integrations.azure',
  'zenml.integrations.azure.artifact_stores',
- 'zenml.integrations.azureml',
- 'zenml.integrations.azureml.step_operators',
+ 'zenml.integrations.azure.secrets_managers',
+ 'zenml.integrations.azure.step_operators',
  'zenml.integrations.dash',
  'zenml.integrations.dash.visualizers',
  'zenml.integrations.evidently',
  'zenml.integrations.evidently.steps',
  'zenml.integrations.evidently.visualizers',
  'zenml.integrations.facets',
  'zenml.integrations.facets.visualizers',
  'zenml.integrations.feast',
  'zenml.integrations.feast.feature_stores',
  'zenml.integrations.gcp',
  'zenml.integrations.gcp.artifact_stores',
- 'zenml.integrations.gcp_secrets_manager',
- 'zenml.integrations.gcp_secrets_manager.secrets_manager',
+ 'zenml.integrations.gcp.orchestrators',
+ 'zenml.integrations.gcp.secrets_manager',
+ 'zenml.integrations.gcp.step_operators',
+ 'zenml.integrations.github',
+ 'zenml.integrations.github.orchestrators',
+ 'zenml.integrations.github.secrets_managers',
  'zenml.integrations.graphviz',
  'zenml.integrations.graphviz.visualizers',
  'zenml.integrations.huggingface',
  'zenml.integrations.huggingface.materializers',
  'zenml.integrations.kubeflow',
  'zenml.integrations.kubeflow.metadata_stores',
  'zenml.integrations.kubeflow.orchestrators',
@@ -58,35 +63,32 @@
  'zenml.integrations.plotly.visualizers',
  'zenml.integrations.pytorch',
  'zenml.integrations.pytorch.materializers',
  'zenml.integrations.pytorch_lightning',
  'zenml.integrations.pytorch_lightning.materializers',
  'zenml.integrations.s3',
  'zenml.integrations.s3.artifact_stores',
- 'zenml.integrations.sagemaker',
- 'zenml.integrations.sagemaker.step_operators',
  'zenml.integrations.scipy',
  'zenml.integrations.scipy.materializers',
  'zenml.integrations.seldon',
  'zenml.integrations.seldon.model_deployers',
  'zenml.integrations.seldon.secret_schemas',
  'zenml.integrations.seldon.services',
  'zenml.integrations.seldon.steps',
  'zenml.integrations.sklearn',
  'zenml.integrations.sklearn.helpers',
  'zenml.integrations.sklearn.materializers',
  'zenml.integrations.sklearn.steps',
+ 'zenml.integrations.slack',
+ 'zenml.integrations.slack.alerters',
  'zenml.integrations.tensorflow',
  'zenml.integrations.tensorflow.materializers',
  'zenml.integrations.tensorflow.services',
  'zenml.integrations.tensorflow.steps',
  'zenml.integrations.tensorflow.visualizers',
- 'zenml.integrations.vertex',
- 'zenml.integrations.vertex.orchestrator',
- 'zenml.integrations.vertex.step_operators',
  'zenml.integrations.wandb',
  'zenml.integrations.wandb.experiment_trackers',
  'zenml.integrations.whylogs',
  'zenml.integrations.whylogs.materializers',
  'zenml.integrations.whylogs.steps',
  'zenml.integrations.whylogs.visualizers',
  'zenml.integrations.xgboost',
@@ -97,14 +99,15 @@
  'zenml.model_deployers',
  'zenml.orchestrators',
  'zenml.orchestrators.local',
  'zenml.pipelines',
  'zenml.pipelines.builtin_pipelines',
  'zenml.post_execution',
  'zenml.secret',
+ 'zenml.secret.schemas',
  'zenml.secrets_managers',
  'zenml.secrets_managers.local',
  'zenml.services',
  'zenml.services.local',
  'zenml.stack',
  'zenml.step_operators',
  'zenml.steps',
@@ -121,46 +124,47 @@
 
 install_requires = \
 ['analytics-python>=1.4.0,<2.0.0',
  'apache-beam>=2.30.0,<3.0.0',
  'click-params>=0.3.0,<0.4.0',
  'click>=8.0.1,<9.0.0',
  'distro>=1.6.0,<2.0.0',
- 'fastapi>=0.75.0,<0.76.0',
  'gitpython>=3.1.18,<4.0.0',
  'httplib2>=0.19.1,<0.20',
  'markupsafe==1.1.1',
- 'ml-pipelines-sdk==1.8.0rc1',
+ 'ml-pipelines-sdk==1.8.0',
  'nbconvert==6.4.4',
  'pandas>=1.1.5,<2.0.0',
  'pydantic>=1.9.0,<2.0.0',
  'pyparsing>=2.4.0,<3',
  'python-dateutil>=2.8.1,<3.0.0',
  'pyyaml>=5.4.1,<6.0.0',
  'rich[jupyter]>=12.0.0,<13.0.0',
- 'semver>=2.13.0,<3.0.0',
- 'sqlmodel>=0.0.6,<0.1.0',
- 'uvicorn[standard]>=0.17.5,<0.18.0']
+ 'sqlmodel>=0.0.6,<0.1.0']
+
+extras_require = \
+{'server': ['fastapi>=0.75.0,<0.76.0', 'uvicorn[standard]>=0.17.5,<0.18.0']}
 
 entry_points = \
 {'console_scripts': ['zenml = zenml.cli.cli:cli']}
 
 setup_kwargs = {
     'name': 'zenml',
-    'version': '0.8.1rc0',
+    'version': '0.9.0',
     'description': 'ZenML: Write production-ready ML code.',
-    'long_description': '<div align="center">\n    <img src="https://zenml.io/assets/social/github.svg">\n</div>\n\n# ⏲️ Join the ZenML team on the MLOps Day\n\nWe are hosting a MLOps day where we\'ll be building a vendor-agnostic MLOps pipeline from scratch.\n\nSign up [here](https://www.eventbrite.com/e/zenml-mlops-day-join-us-in-building-a-vendor-agnostic-mlops-pipeline-tickets-336331515617) to join the entire ZenML team in showcasing the latest release, answering the community\'s questions, and live-coding vendor agnostic MLOps features with the ZenML framework!\n\n# 👀 What is ZenML?\n\n**ZenML** is an extensible, open-source MLOps framework to create\nproduction-ready machine learning pipelines. Built for data scientists, it has a\nsimple, flexible syntax, is cloud- and tool-agnostic, and has\ninterfaces/abstractions that are catered towards ML workflows.\n\nAt its core, **ZenML pipelines execute ML-specific workflows** from sourcing\ndata to splitting, preprocessing, training, all the way to the evaluation of\nresults and even serving. There are many built-in batteries to support common ML\ndevelopment tasks. ZenML is not here to replace the great tools that solve these\nindividual problems. Rather, it offers an **extensible framework** and a\nstandard abstraction to write and build your workflows.\n\n🎉 **Version 0.8.0 out now!** [Check out the release notes\nhere](https://github.com/zenml-io/zenml/releases).\n\n[![PyPI - Python\nVersion](https://img.shields.io/pypi/pyversions/zenml)](https://pypi.org/project/zenml/)\n[![PyPI Status](https://pepy.tech/badge/zenml)](https://pepy.tech/project/zenml)\n![GitHub](https://img.shields.io/github/license/zenml-io/zenml)\n[![Codecov](https://codecov.io/gh/zenml-io/zenml/branch/main/graph/badge.svg)](https://codecov.io/gh/zenml-io/zenml)\n[![Interrogate](docs/interrogate.svg)](https://interrogate.readthedocs.io/en/latest/)\n[![Main Workflow\nTests](https://github.com/zenml-io/zenml/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/zenml-io/zenml/actions/workflows/ci.yml)\n\n<div align="center">\nJoin our <a href="https://zenml.io/slack-invite" target="_blank">\n    <img width="25" src="https://cdn3.iconfinder.com/data/icons/logos-and-brands-adobe/512/306_Slack-512.png" alt="Slack"/>\n<b>Slack Community</b> </a> and become part of the ZenML family\n</div>\n<div align="center"> Give us a \n    <img width="25" src="https://cdn.iconscout.com/icon/free/png-256/github-153-675523.png" alt="Slack"/>\n<b>GitHub star</b> to show your love\n</div>\n<div align="center"> \n    <b>NEW: </b> <a href="https://zenml.io/discussion" target="_blank"><img width="25" src="https://cdn1.iconfinder.com/data/icons/social-17/48/like-512.png" alt="Vote"/><b> Vote</b></a> on the next ZenML features \n</div>\n\n<br>\n\n# 🤖 Why use ZenML?\n\nZenML pipelines are designed to be written early on the development lifecycle.\nData scientists can explore their pipelines as they develop towards production,\nswitching stacks from local to cloud deployments with ease. You can read more\nabout why we started building ZenML [on our\nblog](https://blog.zenml.io/why-zenml/). By using ZenML in the early stages of\nyour project, you get the following benefits:\n\n- **Extensible** so you can build out the framework to suit your specific needs\n- **Reproducibility** of training and inference workflows\n- A **simple and clear** way to represent the steps of your pipeline in code\n- **Batteries-included integrations**: bring all your favorite tools together\n- Easy switch between local and cloud stacks\n- Painless **deployment and configuration** of infrastructure\n\n# 📖 Learn More\n\n| ZenML Resources | Description |\n| ------------- | - |\n| 🧘\u200d♀️ **[ZenML 101]** | New to ZenML? Here\'s everything you need to know! |\n| ⚛️ **[Core Concepts]** | Some key terms and concepts we use. |\n| 🗃 **[Functional API Guide]** | Build production ML pipelines with simple functions. |\n| 🚀 **[New in v0.8.0]** | New features, bug fixes. |\n| 🗳 **[Vote for Features]** | Pick what we work on next! |\n| 📓 **[Docs]** | Full documentation for creating your own ZenML pipelines. |\n| 📒 **[API Reference]** | The detailed reference for ZenML\'s API. |\n| 🍰 **[ZenBytes]** | A guided and in-depth tutorial on MLOps and ZenML. |\n| 🗂️️ **[ZenFiles]** | End-to-end projects using ZenML. |\n| ⚽️ **[Examples]** | Learn best through examples where ZenML is used? We\'ve got you covered. |\n| 📬 **[Blog]** | Use cases of ZenML and technical deep dives on how we built it. |\n| 🔈 **[Podcast]** | Conversations with leaders in ML, released every 2 weeks. |\n| 📣 **[Newsletter]** | We build ZenML in public. Subscribe to learn how we work. |\n| 💬 **[Join Slack]** | Need help with your specific use case? Say hi on Slack! |\n| 🗺 **[Roadmap]** | See where ZenML is working to build new features. |\n| 🙋\u200d♀️ **[Contribute]** | How to contribute to the ZenML project and code base. |\n\n[ZenML 101]: https://docs.zenml.io/\n[Core Concepts]: https://docs.zenml.io/core-concepts\n[Functional API Guide]: https://docs.zenml.io/v/docs/guides/functional-api\n[New in v0.8.0]: https://github.com/zenml-io/zenml/releases\n[Vote for Features]: https://zenml.io/discussion\n[Docs]: https://docs.zenml.io/\n[API Reference]: https://apidocs.zenml.io/\n[ZenBytes]: https://github.com/zenml-io/zenbytes\n[ZenFiles]: https://github.com/zenml-io/zenfiles\n[Examples]: https://github.com/zenml-io/zenml/tree/main/examples\n[Blog]: https://blog.zenml.io/\n[Podcast]: https://podcast.zenml.io/\n[Newsletter]: https://zenml.io/newsletter/\n[Join Slack]: https://zenml.io/slack-invite/\n[Roadmap]: https://zenml.io/roadmap\n[Contribute]: https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md\n\n# 🎮 Features\n\n### 1. 💪 Write local, run anywhere\n\nYou only need to write your core machine learning workflow code once, but you\ncan run it anywhere. We decouple your code from the environment and\ninfrastructure on which this code runs.\n\nSwitching from local experiments to cloud-based pipelines doesn\'t need to be\ncomplicated. ZenML supports running pipelines wherever you want, for example by\nusing Kubeflow, one of our built-in integrations, or any orchestrator of your\nchoice. Switching from your local stack to a cloud stack is easy to do with our\nCLI tool.\n\n![You can run your pipelines locally or in the\ncloud](docs/book/assets/core_concepts/concepts-3.png)\n\n### 2. 🌈 All your MLOps stacks in one place\n\nOnce code is organized into a ZenML pipeline, you can supercharge your ML\ndevelopment with [powerful\nintegrations](https://docs.zenml.io/features/integrations) on multiple [MLOps\nstacks](https://docs.zenml.io/core-concepts). There are lots of moving parts for\nall the MLOps tooling and infrastructure you require for ML in production and\nZenML aims to bring it all together under one roof.\n\nWe already support common use cases and integrations to standard ML tools via\nour stack components, from orchestrators like Airflow and Kubeflow to model\ndeployment via MLflow or Seldon Core, to custom infrastructure for training your\nmodels in the cloud and so on. If you want to learn more about our integrations,\ncheck out [our Examples](https://github.com/zenml-io/zenml/tree/main/examples)\nto see how they work.\n\n![ZenML is the glue](docs/book/assets/stack-list.png)\n\n### 3. 🛠 Extensibility\n\nZenML\'s Stack Components are built to support most machine learning use cases.\nWe offer a batteries-included initial installation that should serve many needs\nand workflows, but if you need a special kind of monitoring tool added, for\nexample, or a different orchestrator to run your pipelines, ZenML is built as a\nframework making it easy to extend and build out whatever you need.\n\n![ZenML is fully extensible](docs/book/assets/extensibility.gif)\n\n### 4. 🔍 Automated metadata tracking\n\nZenML tracks metadata for all the pipelines you run. This ensures that:\n\n- Code is versioned\n- Data is versioned\n- Models are versioned\n- Configurations are versioned\n\nThis also enables caching of the data that powers your pipelines which helps you\niterate quickly through ML experiments. (Read [our\nblogpost](https://blog.zenml.io/caching-ml-pipelines/) to learn more!)\n\n![Visualize your pipeline steps](docs/book/assets/dag-visualizer.png)\n\n### 5. ➿ Continuous Training and Continuous Deployment (CT/CD)\n\nContinuous Training (CT) refers to the paradigm where a team deploys training pipelines \nthat run automatically to train models on new (fresh) data. Continuous Deployment (CD) \nrefers to the paradigm where newly trained models are automatically deployed to a prediction \nservice/server\n\nZenML enabled CT/CD by enabling the model preparation and model training with model deployment. \nWith the built-in functionalities like Schedules, Model Deployers and Services you can \ncreate end-to-end ML workflows with Continuous Training and Deployment that deploys your \nmodel in a local environment with MLFlow integration or even in a production-grade environment \nlike Kubernetes with our Seldon Core integration. You can also listed served models with the CLI:\n\n![CI/CD/CT in ZenML](docs/book/assets/ct_cd_zenml.gif)\n\n```\nzenml served-models list\n```\n\nRead more about CT/CD in ZenML [here](https://blog.zenml.io/ci-ct-cd-with-zenml/).\n\n# 🤸 Getting Started\n\n## 💾 Install ZenML\n\n*Requirements*: ZenML supports Python 3.7 and 3.8.\n\nZenML is available for easy installation into your environment via PyPI:\n\n```bash\npip install zenml\n```\n\nAlternatively, if you’re feeling brave, feel free to install the bleeding edge:\n**NOTE:** Do so on your own risk, no guarantees given!\n\n```bash\npip install git+https://github.com/zenml-io/zenml.git@main --upgrade\n```\n\nZenML is also available as a Docker image hosted publicly on\n[DockerHub](https://hub.docker.com/r/zenmldocker/zenml). Use the following\ncommand to get started in a bash environment:\n\n```shell\ndocker run -it zenmldocker/zenml /bin/bash\n```\n\n## 🚅 Quickstart\n\nThe quickest way to get started is to create a simple pipeline.\n\n#### Step 1: Initialize a ZenML repo\n\n```bash\nzenml init\nzenml integration install sklearn -y # we use scikit-learn for this example\n```\n\n#### Step 2: Assemble, run, and evaluate your pipeline locally\n\n```python\nimport numpy as np\nfrom sklearn.base import ClassifierMixin\n\nfrom zenml.integrations.sklearn.helpers.digits import get_digits, get_digits_model\nfrom zenml.pipelines import pipeline\nfrom zenml.steps import step, Output\n\n@step\ndef importer() -> Output(\n    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n):\n    """Loads the digits array as normal numpy arrays."""\n    X_train, X_test, y_train, y_test = get_digits()\n    return X_train, X_test, y_train, y_test\n\n\n@step\ndef trainer(\n    X_train: np.ndarray,\n    y_train: np.ndarray,\n) -> ClassifierMixin:\n    """Train a simple sklearn classifier for the digits dataset."""\n    model = get_digits_model()\n    model.fit(X_train, y_train)\n    return model\n\n\n@step\ndef evaluator(\n    X_test: np.ndarray,\n    y_test: np.ndarray,\n    model: ClassifierMixin,\n) -> float:\n    """Calculate the accuracy on the test set"""\n    test_acc = model.score(X_test, y_test)\n    print(f"Test accuracy: {test_acc}")\n    return test_acc\n\n\n@pipeline\ndef mnist_pipeline(\n    importer,\n    trainer,\n    evaluator,\n):\n    """Links all the steps together in a pipeline"""\n    X_train, X_test, y_train, y_test = importer()\n    model = trainer(X_train=X_train, y_train=y_train)\n    evaluator(X_test=X_test, y_test=y_test, model=model)\n\n\npipeline = mnist_pipeline(\n    importer=importer(),\n    trainer=trainer(),\n    evaluator=evaluator(),\n)\npipeline.run()\n```\n\n# :racehorse: Get a guided tour with `zenml go`\n\nFor a slightly more in-depth introduction to ZenML, taught through Jupyter\nnotebooks, install `zenml` via pip as described above and type:\n\n```shell\nzenml go\n```\n\nThis will spin up a Jupyter notebook that showcases the above example plus more\non how to use and extend ZenML.\n\n# 👭 Collaborate with your team\n\nZenML is built to support teams working together. The underlying infrastructure\non which your ML workflows run can be shared, as can the data, assets and\nartifacts that you need to enable your work. ZenML Profiles offer an easy way to\nmanage and switch between your stacks. The ZenML Server handles all the\ninteraction and sharing and you can host it wherever you\'d like.\n\n```\nzenml server up\n```\n\nRead more about collaboration in ZenML [here](https://docs.zenml.io/collaborate/collaborate).\n\n# 🍰 ZenBytes\n\n[ZenBytes](https://github.com/zenml-io/zenbytes) is a series of short practical\nMLOps lessons through ZenML and its various integrations. It is intended for\npeople looking to learn about MLOps generally, and also for ML practitioners who\nwant to get started with ZenML.\n\nAfter you\'ve run and understood the simple example above, your next port of call\nis probably either the [fully-fleshed-out quickstart\nexample](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) and\nthen to look at [the ZenBytes repository](https://github.com/zenml-io/zenbytes)\nand notebooks.\n\n# 🗂️ ZenFiles\n\nZenFiles are production-grade ML use-cases powered by ZenML. They are fully\nfleshed out, end-to-end, projects that showcase ZenML\'s capabilities. They can\nalso serve as a template from which to start similar projects.\n\nThe ZenFiles project is fully maintained and can be viewed as a sister\nrepository of ZenML. Check it out [here](https://github.com/zenml-io/zenfiles).\n\n# 🗺 Roadmap\n\nZenML is being built in public. The [roadmap](https://zenml.io/roadmap) is a\nregularly updated source of truth for the ZenML community to understand where\nthe product is going in the short, medium, and long term.\n\nZenML is managed by a [core team](https://zenml.io/team) of developers that are\nresponsible for making key decisions and incorporating feedback from the\ncommunity. The team oversees feedback via various channels, and you can directly\ninfluence the roadmap as follows:\n\n- Vote on your most wanted feature on our [Discussion\n  board](https://zenml.io/discussion). You can also request for new features here.\n- Start a thread in our [Slack channel](https://zenml.io/slack-invite).\n\n# 🙋\u200d♀️ Contributing & Community\n\nWe would love to develop ZenML together with our community! Best way to get\nstarted is to select any issue from the [`good-first-issue`\nlabel](https://github.com/zenml-io/zenml/labels/good%20first%20issue). If you\nwould like to contribute, please review our [Contributing\nGuide](CONTRIBUTING.md) for all relevant details.\n\n<br>\n\n![Repobeats analytics\nimage](https://repobeats.axiom.co/api/embed/635c57b743efe649cadceba6a2e6a956663f96dd.svg\n"Repobeats analytics image")\n\n\n# 🆘 Where to get help\n\nFirst point of call should be [our Slack group](https://zenml.io/slack-invite/).\nAsk your questions about bugs or specific use cases and someone from the core\nteam will respond.\n\n# 📜 License\n\nZenML is distributed under the terms of the Apache License Version 2.0. A\ncomplete version of the license is available in the [LICENSE.md](LICENSE.md) in\nthis repository. Any contribution made to this project will be licensed under\nthe Apache License Version 2.0.\n',
+    'long_description': '<div align="center">\n    <img src="docs/book/assets/oss-header.svg">\n</div>\n\n# :family_man_woman_boy_boy: ZenML: Meet the Team\n\nHi ZenCommunity! Did you ever have a question that\'s too hard to express on our Slack? Is it just too much effort to say everything on a \nlong GitHub issue? Or are you just curious what ZenML has been up to in the past week? Well, register now for the ZenML Office \n(Half) Hour to get your answers and more!\n\nEvery week, part of the ZenML core team will pop in for 30 minutes to interact directly with the community. Sometimes we\'ll be presenting a \nfeature, other times just taking questions, and having fun. Join us if you are curious about ZenML, or just want to talk shop about MLOps.\n\nWe will host the gathering every Wednesday 8:30AM PT (5:30PM CET). Register now through [this link](https://www.eventbrite.com/e/zenml-meet-the-community-tickets-354426688767), \nor subscribe to the [public events calendar](https://calendar.google.com/calendar/u/0/r?cid=Y19iaDJ0Zm44ZzdodXBlbnBzaWplY3UwMmNjZ0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t) to get notified \nbefore every community gathering.\n\n# 👀 What is ZenML?\n\n**ZenML** is an extensible, open-source MLOps framework for creating \nportable, production-ready MLOps pipelines. Built to enable collaboration among data scientists, ML Engineers, and MLOps Developers,\nit has a simple, flexible syntax, is **cloud-** and \n**tool-agnostic**, and has interfaces/abstractions that are thoughtfully designed for \nML workflows. \n\nAt its core, **ZenML pipelines execute ML-specific workflows** from sourcing\ndata to splitting, preprocessing, training, all the way to serving and monitoring \nML models in production. There are many built-in features to support\ncommon ML development tasks. ZenML is not here to replace the great tools that\nsolve these individual problems. Rather, it offers an **extensible framework** and a\nstandard abstraction to write and build your workflows.\n\n🎉 **Version 0.9.0 out now!** [Check out the release notes\nhere](https://github.com/zenml-io/zenml/releases).\n\n[![PyPI - Python\nVersion](https://img.shields.io/pypi/pyversions/zenml)](https://pypi.org/project/zenml/)\n[![PyPI Status](https://pepy.tech/badge/zenml)](https://pepy.tech/project/zenml)\n![GitHub](https://img.shields.io/github/license/zenml-io/zenml)\n[![Codecov](https://codecov.io/gh/zenml-io/zenml/branch/main/graph/badge.svg)](https://codecov.io/gh/zenml-io/zenml)\n[![Interrogate](docs/book/assets/interrogate.svg)](https://interrogate.readthedocs.io/en/latest/)\n[![Main Workflow\nTests](https://github.com/zenml-io/zenml/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/zenml-io/zenml/actions/workflows/ci.yml)\n\n<div align="center">\nJoin our <a href="https://zenml.io/slack-invite" target="_blank">\n    <img width="25" src="https://cdn3.iconfinder.com/data/icons/logos-and-brands-adobe/512/306_Slack-512.png" alt="Slack"/>\n<b>Slack Community</b> </a> and become part of the ZenML family\n</div>\n<div align="center"> Give us a \n    <img width="25" src="https://cdn.iconscout.com/icon/free/png-256/github-153-675523.png" alt="Slack"/>\n<b>GitHub star</b> to show your love\n</div>\n<div align="center"> \n    <b>NEW: </b> <a href="https://zenml.io/discussion" target="_blank"><img width="25" src="https://cdn1.iconfinder.com/data/icons/social-17/48/like-512.png" alt="Vote"/><b> Vote</b></a> on the next ZenML features \n</div>\n\n<br>\n\n# 🤖 Why use ZenML?\n\nZenML pipelines are designed to be written early on the development lifecycle.\nData scientists can explore their pipelines as they develop towards production,\nswitching stacks from local to cloud deployments with ease. You can read more\nabout why we started building ZenML [on our\nblog](https://blog.zenml.io/why-zenml/). By using ZenML in the early stages of\nyour project, you get the following benefits:\n\n- **Extensible** so you can build out the framework to suit your specific needs\n- **Reproducibility** of training and inference workflows\n- A **simple and clear** way to represent the steps of your pipeline in code\n- **Batteries-included integrations**: bring all your favorite tools together\n- Easy switch between local and cloud stacks\n- Painless **deployment and configuration** of infrastructure\n\n# 📖 Learn More\n\n| ZenML Resources | Description |\n| ------------- | - |\n| 🧘\u200d♀️ **[ZenML 101]** | New to ZenML? Here\'s everything you need to know! |\n| ⚛️ **[Core Concepts]** | Some key terms and concepts we use. |\n| 🗃 **[Functional API Guide]** | Build production ML pipelines with simple functions. |\n| 🚀 **[New in v0.9.0]** | New features, bug fixes. |\n| 🗳 **[Vote for Features]** | Pick what we work on next! |\n| 📓 **[Docs]** | Full documentation for creating your own ZenML pipelines. |\n| 📒 **[API Reference]** | The detailed reference for ZenML\'s API. |\n| 🍰 **[ZenBytes]** | A guided and in-depth tutorial on MLOps and ZenML. |\n| 🗂️️ **[ZenFiles]** | End-to-end projects using ZenML. |\n| ⚽️ **[Examples]** | Learn best through examples where ZenML is used? We\'ve got you covered. |\n| 📬 **[Blog]** | Use cases of ZenML and technical deep dives on how we built it. |\n| 🔈 **[Podcast]** | Conversations with leaders in ML, released every 2 weeks. |\n| 📣 **[Newsletter]** | We build ZenML in public. Subscribe to learn how we work. |\n| 💬 **[Join Slack]** | Need help with your specific use case? Say hi on Slack! |\n| 🗺 **[Roadmap]** | See where ZenML is working to build new features. |\n| 🙋\u200d♀️ **[Contribute]** | How to contribute to the ZenML project and code base. |\n\n[ZenML 101]: https://docs.zenml.io/\n[Core Concepts]: https://docs.zenml.io/core-concepts\n[Functional API Guide]: https://docs.zenml.io/v/docs/guides/functional-api\n[New in v0.9.0]: https://github.com/zenml-io/zenml/releases\n[Vote for Features]: https://zenml.io/discussion\n[Docs]: https://docs.zenml.io/\n[API Reference]: https://apidocs.zenml.io/\n[ZenBytes]: https://github.com/zenml-io/zenbytes\n[ZenFiles]: https://github.com/zenml-io/zenfiles\n[Examples]: https://github.com/zenml-io/zenml/tree/main/examples\n[Blog]: https://blog.zenml.io/\n[Podcast]: https://podcast.zenml.io/\n[Newsletter]: https://zenml.io/newsletter/\n[Join Slack]: https://zenml.io/slack-invite/\n[Roadmap]: https://zenml.io/roadmap\n[Contribute]: https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md\n\n# 🎮 Features\n\n### 1. 💪 Write local, run anywhere\n\nYou only need to write your core machine learning workflow code once, but you\ncan run it anywhere. We decouple your code from the environment and\ninfrastructure on which this code runs.\n\nSwitching from local experiments to cloud-based pipelines doesn\'t need to be\ncomplicated. ZenML supports running pipelines wherever you want, for example by\nusing Kubeflow, one of our built-in integrations, or any orchestrator of your\nchoice. Switching from your local stack to a cloud stack is easy to do with our\nCLI tool.\n\n![You can run your pipelines locally or in the\ncloud](docs/book/assets/core_concepts/concepts-3.png)\n\n### 2. 🌈 All your MLOps stacks in one place\n\nOnce code is organized into a ZenML pipeline, you can supercharge your ML\ndevelopment with [powerful\nintegrations](https://docs.zenml.io/features/integrations) on multiple [MLOps\nstacks](https://docs.zenml.io/core-concepts). There are lots of moving parts for\nall the MLOps tooling and infrastructure you require for ML in production and\nZenML aims to bring it all together under one roof.\n\nWe already support common use cases and integrations to standard ML tools via\nour stack components, from orchestrators like Airflow and Kubeflow to model\ndeployment via MLflow or Seldon Core, to custom infrastructure for training your\nmodels in the cloud and so on. If you want to learn more about our integrations,\ncheck out [our Examples](https://github.com/zenml-io/zenml/tree/main/examples)\nto see how they work.\n\n![ZenML is the glue](docs/book/assets/stack-list.png)\n\n### 3. 🛠 Extensibility\n\nZenML\'s Stack Components are built to support most machine learning use cases.\nWe offer a batteries-included initial installation that should serve many needs\nand workflows, but if you need a special kind of monitoring tool added, for\nexample, or a different orchestrator to run your pipelines, ZenML is built as a\nframework making it easy to extend and build out whatever you need.\n\n![ZenML is fully extensible](docs/book/assets/extensibility.gif)\n\n### 4. 🔍 Automated metadata tracking\n\nZenML tracks metadata for all the pipelines you run. This ensures that:\n\n- Code is versioned\n- Data is versioned\n- Models are versioned\n- Configurations are versioned\n\nThis also enables caching of the data that powers your pipelines which helps you\niterate quickly through ML experiments. (Read [our\nblogpost](https://blog.zenml.io/caching-ml-pipelines/) to learn more!)\n\n![Visualize your pipeline steps](docs/book/assets/dag-visualizer.png)\n\n### 5. ➿ Continuous Training and Continuous Deployment (CT/CD)\n\nContinuous Training (CT) refers to the paradigm where a team deploys training pipelines \nthat run automatically to train models on new (fresh) data. Continuous Deployment (CD) \nrefers to the paradigm where newly trained models are automatically deployed to a prediction \nservice/server\n\nZenML enabled CT/CD by enabling the model preparation and model training with model deployment. \nWith the built-in functionalities like Schedules, Model Deployers and Services you can \ncreate end-to-end ML workflows with Continuous Training and Deployment that deploys your \nmodel in a local environment with MLFlow integration or even in a production-grade environment \nlike Kubernetes with our Seldon Core integration. You can also listed served models with the CLI:\n\n![CI/CD/CT in ZenML](docs/book/assets/ct_cd_zenml.gif)\n\n```\nzenml served-models list\n```\n\nRead more about CT/CD in ZenML [here](https://blog.zenml.io/ci-ct-cd-with-zenml/).\n\n# 🤸 Getting Started\n\n## 💾 Install ZenML\n\n*Requirements*: ZenML supports Python 3.7, 3.8, and 3.9.\n\nZenML is available for easy installation into your environment via PyPI:\n\n```bash\npip install zenml\n```\n\nAlternatively, if you’re feeling brave, feel free to install the bleeding edge:\n**NOTE:** Do so on your own risk, no guarantees given!\n\n```bash\npip install git+https://github.com/zenml-io/zenml.git@main --upgrade\n```\n\nZenML is also available as a Docker image hosted publicly on\n[DockerHub](https://hub.docker.com/r/zenmldocker/zenml). Use the following\ncommand to get started in a bash environment:\n\n```shell\ndocker run -it zenmldocker/zenml /bin/bash\n```\n\n### 🐛 Known installation issues for M1 Mac Users\n\nIf you have a M1 Mac machine and you are encountering an error while trying to install ZenML, \nplease try to setup `brew` and `pyenv` with Rosetta 2 and then install ZenML. The issue arises because some of the dependencies \naren’t fully compatible with the vanilla ARM64 Architecture. The following links may be helpful (Thank you @Reid Falconer) :\n\n- [Pyenv with Apple Silicon](http://sixty-north.com/blog/pyenv-apple-silicon.html)\n- [Install Python Under Rosetta 2](https://medium.com/thinknum/how-to-install-python-under-rosetta-2-f98c0865e012)\n\n## 🚅 Quickstart\n\nThe quickest way to get started is to create a simple pipeline.\n\n#### Step 1: Initialize a ZenML repo\n\n```bash\nzenml init\nzenml integration install sklearn -y # we use scikit-learn for this example\n```\n\n#### Step 2: Assemble, run, and evaluate your pipeline locally\n\n```python\nimport numpy as np\nfrom sklearn.base import ClassifierMixin\n\nfrom zenml.integrations.sklearn.helpers.digits import get_digits, get_digits_model\nfrom zenml.pipelines import pipeline\nfrom zenml.steps import step, Output\n\n@step\ndef importer() -> Output(\n    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n):\n    """Loads the digits array as normal numpy arrays."""\n    X_train, X_test, y_train, y_test = get_digits()\n    return X_train, X_test, y_train, y_test\n\n\n@step\ndef trainer(\n    X_train: np.ndarray,\n    y_train: np.ndarray,\n) -> ClassifierMixin:\n    """Train a simple sklearn classifier for the digits dataset."""\n    model = get_digits_model()\n    model.fit(X_train, y_train)\n    return model\n\n\n@step\ndef evaluator(\n    X_test: np.ndarray,\n    y_test: np.ndarray,\n    model: ClassifierMixin,\n) -> float:\n    """Calculate the accuracy on the test set"""\n    test_acc = model.score(X_test, y_test)\n    print(f"Test accuracy: {test_acc}")\n    return test_acc\n\n\n@pipeline\ndef mnist_pipeline(\n    importer,\n    trainer,\n    evaluator,\n):\n    """Links all the steps together in a pipeline"""\n    X_train, X_test, y_train, y_test = importer()\n    model = trainer(X_train=X_train, y_train=y_train)\n    evaluator(X_test=X_test, y_test=y_test, model=model)\n\n\npipeline = mnist_pipeline(\n    importer=importer(),\n    trainer=trainer(),\n    evaluator=evaluator(),\n)\npipeline.run()\n```\n\n# :racehorse: Get a guided tour with `zenml go`\n\nFor a slightly more in-depth introduction to ZenML, taught through Jupyter\nnotebooks, install `zenml` via pip as described above and type:\n\n```shell\nzenml go\n```\n\nThis will spin up a Jupyter notebook that showcases the above example plus more\non how to use and extend ZenML.\n\n# 👭 Collaborate with your team\n\nZenML is built to support teams working together. The underlying infrastructure\non which your ML workflows run can be shared, as can the data, assets and\nartifacts that you need to enable your work. ZenML Profiles offer an easy way to\nmanage and switch between your stacks. The ZenML Server handles all the\ninteraction and sharing and you can host it wherever you\'d like.\n\n```\n# Make sure to install ZenML with all necessary requirements for the ZenServer\npip install zenml[server]\nzenml server up\n```\n\nRead more about collaboration in ZenML [here](https://docs.zenml.io/collaborate/collaborate).\n\n# 🍰 ZenBytes\n\n[ZenBytes](https://github.com/zenml-io/zenbytes) is a series of short practical\nMLOps lessons through ZenML and its various integrations. It is intended for\npeople looking to learn about MLOps generally, and also for ML practitioners who\nwant to get started with ZenML.\n\nAfter you\'ve run and understood the simple example above, your next port of call\nis probably either the [fully-fleshed-out quickstart\nexample](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) and\nthen to look at [the ZenBytes repository](https://github.com/zenml-io/zenbytes)\nand notebooks.\n\n# 🗂️ ZenFiles\n\nZenFiles are production-grade ML use-cases powered by ZenML. They are fully\nfleshed out, end-to-end, projects that showcase ZenML\'s capabilities. They can\nalso serve as a template from which to start similar projects.\n\nThe ZenFiles project is fully maintained and can be viewed as a sister\nrepository of ZenML. Check it out [here](https://github.com/zenml-io/zenfiles).\n\n# 🗺 Roadmap\n\nZenML is being built in public. The [roadmap](https://zenml.io/roadmap) is a\nregularly updated source of truth for the ZenML community to understand where\nthe product is going in the short, medium, and long term.\n\nZenML is managed by a [core team](https://zenml.io/team) of developers that are\nresponsible for making key decisions and incorporating feedback from the\ncommunity. The team oversees feedback via various channels, and you can directly\ninfluence the roadmap as follows:\n\n- Vote on your most wanted feature on our [Discussion\n  board](https://zenml.io/discussion). You can also request for new features here.\n- Start a thread in our [Slack channel](https://zenml.io/slack-invite).\n\n# 🙋\u200d♀️ Contributing & Community\n\nWe would love to develop ZenML together with our community! Best way to get\nstarted is to select any issue from the [`good-first-issue`\nlabel](https://github.com/zenml-io/zenml/labels/good%20first%20issue). If you\nwould like to contribute, please review our [Contributing\nGuide](CONTRIBUTING.md) for all relevant details.\n\n<br>\n\n![Repobeats analytics\nimage](https://repobeats.axiom.co/api/embed/635c57b743efe649cadceba6a2e6a956663f96dd.svg\n"Repobeats analytics image")\n\n\n# 🆘 Where to get help\n\nFirst point of call should be [our Slack group](https://zenml.io/slack-invite/).\nAsk your questions about bugs or specific use cases and someone from the core\nteam will respond.\n\n# 📜 License\n\nZenML is distributed under the terms of the Apache License Version 2.0. A\ncomplete version of the license is available in the [LICENSE.md](LICENSE.md) in\nthis repository. Any contribution made to this project will be licensed under\nthe Apache License Version 2.0.\n',
     'author': 'ZenML GmbH',
     'author_email': 'info@zenml.io',
     'maintainer': None,
     'maintainer_email': None,
     'url': 'https://zenml.io',
     'package_dir': package_dir,
     'packages': packages,
     'package_data': package_data,
     'install_requires': install_requires,
+    'extras_require': extras_require,
     'entry_points': entry_points,
     'python_requires': '>=3.7.1,<3.10',
 }
 
 
 setup(**setup_kwargs)
```

### Comparing `zenml-0.8.1rc0/PKG-INFO` & `zenml-0.9.0/PKG-INFO`

 * *Files 8% similar despite different names*

```diff
@@ -1,1068 +1,1156 @@
 00000000: 4d65 7461 6461 7461 2d56 6572 7369 6f6e  Metadata-Version
 00000010: 3a20 322e 310a 4e61 6d65 3a20 7a65 6e6d  : 2.1.Name: zenm
-00000020: 6c0a 5665 7273 696f 6e3a 2030 2e38 2e31  l.Version: 0.8.1
-00000030: 7263 300a 5375 6d6d 6172 793a 205a 656e  rc0.Summary: Zen
-00000040: 4d4c 3a20 5772 6974 6520 7072 6f64 7563  ML: Write produc
-00000050: 7469 6f6e 2d72 6561 6479 204d 4c20 636f  tion-ready ML co
-00000060: 6465 2e0a 486f 6d65 2d70 6167 653a 2068  de..Home-page: h
-00000070: 7474 7073 3a2f 2f7a 656e 6d6c 2e69 6f0a  ttps://zenml.io.
-00000080: 4c69 6365 6e73 653a 2041 7061 6368 652d  License: Apache-
-00000090: 322e 300a 4b65 7977 6f72 6473 3a20 6d61  2.0.Keywords: ma
-000000a0: 6368 696e 6520 6c65 6172 6e69 6e67 2c70  chine learning,p
-000000b0: 726f 6475 6374 696f 6e2c 7069 7065 6c69  roduction,pipeli
-000000c0: 6e65 2c6d 6c6f 7073 2c64 6576 6f70 730a  ne,mlops,devops.
-000000d0: 4175 7468 6f72 3a20 5a65 6e4d 4c20 476d  Author: ZenML Gm
-000000e0: 6248 0a41 7574 686f 722d 656d 6169 6c3a  bH.Author-email:
-000000f0: 2069 6e66 6f40 7a65 6e6d 6c2e 696f 0a52   info@zenml.io.R
-00000100: 6571 7569 7265 732d 5079 7468 6f6e 3a20  equires-Python: 
-00000110: 3e3d 332e 372e 312c 3c33 2e31 300a 436c  >=3.7.1,<3.10.Cl
-00000120: 6173 7369 6669 6572 3a20 4465 7665 6c6f  assifier: Develo
-00000130: 706d 656e 7420 5374 6174 7573 203a 3a20  pment Status :: 
-00000140: 3420 2d20 4265 7461 0a43 6c61 7373 6966  4 - Beta.Classif
-00000150: 6965 723a 2049 6e74 656e 6465 6420 4175  ier: Intended Au
-00000160: 6469 656e 6365 203a 3a20 4465 7665 6c6f  dience :: Develo
-00000170: 7065 7273 0a43 6c61 7373 6966 6965 723a  pers.Classifier:
-00000180: 2049 6e74 656e 6465 6420 4175 6469 656e   Intended Audien
-00000190: 6365 203a 3a20 5363 6965 6e63 652f 5265  ce :: Science/Re
-000001a0: 7365 6172 6368 0a43 6c61 7373 6966 6965  search.Classifie
-000001b0: 723a 2049 6e74 656e 6465 6420 4175 6469  r: Intended Audi
-000001c0: 656e 6365 203a 3a20 5379 7374 656d 2041  ence :: System A
-000001d0: 646d 696e 6973 7472 6174 6f72 730a 436c  dministrators.Cl
-000001e0: 6173 7369 6669 6572 3a20 4c69 6365 6e73  assifier: Licens
-000001f0: 6520 3a3a 204f 5349 2041 7070 726f 7665  e :: OSI Approve
-00000200: 6420 3a3a 2041 7061 6368 6520 536f 6674  d :: Apache Soft
-00000210: 7761 7265 204c 6963 656e 7365 0a43 6c61  ware License.Cla
-00000220: 7373 6966 6965 723a 2050 726f 6772 616d  ssifier: Program
-00000230: 6d69 6e67 204c 616e 6775 6167 6520 3a3a  ming Language ::
-00000240: 2050 7974 686f 6e20 3a3a 2033 0a43 6c61   Python :: 3.Cla
-00000250: 7373 6966 6965 723a 2050 726f 6772 616d  ssifier: Program
-00000260: 6d69 6e67 204c 616e 6775 6167 6520 3a3a  ming Language ::
-00000270: 2050 7974 686f 6e20 3a3a 2033 203a 3a20   Python :: 3 :: 
-00000280: 4f6e 6c79 0a43 6c61 7373 6966 6965 723a  Only.Classifier:
-00000290: 2050 726f 6772 616d 6d69 6e67 204c 616e   Programming Lan
-000002a0: 6775 6167 6520 3a3a 2050 7974 686f 6e20  guage :: Python 
-000002b0: 3a3a 2033 2e37 0a43 6c61 7373 6966 6965  :: 3.7.Classifie
-000002c0: 723a 2050 726f 6772 616d 6d69 6e67 204c  r: Programming L
-000002d0: 616e 6775 6167 6520 3a3a 2050 7974 686f  anguage :: Pytho
-000002e0: 6e20 3a3a 2033 2e38 0a43 6c61 7373 6966  n :: 3.8.Classif
-000002f0: 6965 723a 2050 726f 6772 616d 6d69 6e67  ier: Programming
-00000300: 204c 616e 6775 6167 6520 3a3a 2050 7974   Language :: Pyt
-00000310: 686f 6e20 3a3a 2033 2e39 0a43 6c61 7373  hon :: 3.9.Class
-00000320: 6966 6965 723a 2054 6f70 6963 203a 3a20  ifier: Topic :: 
-00000330: 536f 6674 7761 7265 2044 6576 656c 6f70  Software Develop
-00000340: 6d65 6e74 203a 3a20 4c69 6272 6172 6965  ment :: Librarie
-00000350: 7320 3a3a 2050 7974 686f 6e20 4d6f 6475  s :: Python Modu
-00000360: 6c65 730a 436c 6173 7369 6669 6572 3a20  les.Classifier: 
-00000370: 546f 7069 6320 3a3a 2053 7973 7465 6d20  Topic :: System 
-00000380: 3a3a 2044 6973 7472 6962 7574 6564 2043  :: Distributed C
-00000390: 6f6d 7075 7469 6e67 0a43 6c61 7373 6966  omputing.Classif
-000003a0: 6965 723a 2054 7970 696e 6720 3a3a 2054  ier: Typing :: T
-000003b0: 7970 6564 0a52 6571 7569 7265 732d 4469  yped.Requires-Di
-000003c0: 7374 3a20 616e 616c 7974 6963 732d 7079  st: analytics-py
-000003d0: 7468 6f6e 2028 3e3d 312e 342e 302c 3c32  thon (>=1.4.0,<2
-000003e0: 2e30 2e30 290a 5265 7175 6972 6573 2d44  .0.0).Requires-D
-000003f0: 6973 743a 2061 7061 6368 652d 6265 616d  ist: apache-beam
-00000400: 2028 3e3d 322e 3330 2e30 2c3c 332e 302e   (>=2.30.0,<3.0.
-00000410: 3029 0a52 6571 7569 7265 732d 4469 7374  0).Requires-Dist
-00000420: 3a20 636c 6963 6b20 283e 3d38 2e30 2e31  : click (>=8.0.1
-00000430: 2c3c 392e 302e 3029 0a52 6571 7569 7265  ,<9.0.0).Require
-00000440: 732d 4469 7374 3a20 636c 6963 6b2d 7061  s-Dist: click-pa
-00000450: 7261 6d73 2028 3e3d 302e 332e 302c 3c30  rams (>=0.3.0,<0
-00000460: 2e34 2e30 290a 5265 7175 6972 6573 2d44  .4.0).Requires-D
-00000470: 6973 743a 2064 6973 7472 6f20 283e 3d31  ist: distro (>=1
-00000480: 2e36 2e30 2c3c 322e 302e 3029 0a52 6571  .6.0,<2.0.0).Req
-00000490: 7569 7265 732d 4469 7374 3a20 6661 7374  uires-Dist: fast
-000004a0: 6170 6920 283e 3d30 2e37 352e 302c 3c30  api (>=0.75.0,<0
-000004b0: 2e37 362e 3029 0a52 6571 7569 7265 732d  .76.0).Requires-
-000004c0: 4469 7374 3a20 6769 7470 7974 686f 6e20  Dist: gitpython 
-000004d0: 283e 3d33 2e31 2e31 382c 3c34 2e30 2e30  (>=3.1.18,<4.0.0
-000004e0: 290a 5265 7175 6972 6573 2d44 6973 743a  ).Requires-Dist:
-000004f0: 2068 7474 706c 6962 3220 283e 3d30 2e31   httplib2 (>=0.1
-00000500: 392e 312c 3c30 2e32 3029 0a52 6571 7569  9.1,<0.20).Requi
-00000510: 7265 732d 4469 7374 3a20 6d61 726b 7570  res-Dist: markup
-00000520: 7361 6665 2028 3d3d 312e 312e 3129 0a52  safe (==1.1.1).R
-00000530: 6571 7569 7265 732d 4469 7374 3a20 6d6c  equires-Dist: ml
-00000540: 2d70 6970 656c 696e 6573 2d73 646b 2028  -pipelines-sdk (
-00000550: 3d3d 312e 382e 3072 6331 290a 5265 7175  ==1.8.0rc1).Requ
-00000560: 6972 6573 2d44 6973 743a 206e 6263 6f6e  ires-Dist: nbcon
-00000570: 7665 7274 2028 3d3d 362e 342e 3429 0a52  vert (==6.4.4).R
-00000580: 6571 7569 7265 732d 4469 7374 3a20 7061  equires-Dist: pa
-00000590: 6e64 6173 2028 3e3d 312e 312e 352c 3c32  ndas (>=1.1.5,<2
-000005a0: 2e30 2e30 290a 5265 7175 6972 6573 2d44  .0.0).Requires-D
-000005b0: 6973 743a 2070 7964 616e 7469 6320 283e  ist: pydantic (>
-000005c0: 3d31 2e39 2e30 2c3c 322e 302e 3029 0a52  =1.9.0,<2.0.0).R
-000005d0: 6571 7569 7265 732d 4469 7374 3a20 7079  equires-Dist: py
-000005e0: 7061 7273 696e 6720 283e 3d32 2e34 2e30  parsing (>=2.4.0
-000005f0: 2c3c 3329 0a52 6571 7569 7265 732d 4469  ,<3).Requires-Di
-00000600: 7374 3a20 7079 7468 6f6e 2d64 6174 6575  st: python-dateu
-00000610: 7469 6c20 283e 3d32 2e38 2e31 2c3c 332e  til (>=2.8.1,<3.
-00000620: 302e 3029 0a52 6571 7569 7265 732d 4469  0.0).Requires-Di
-00000630: 7374 3a20 7079 7961 6d6c 2028 3e3d 352e  st: pyyaml (>=5.
-00000640: 342e 312c 3c36 2e30 2e30 290a 5265 7175  4.1,<6.0.0).Requ
-00000650: 6972 6573 2d44 6973 743a 2072 6963 685b  ires-Dist: rich[
-00000660: 6a75 7079 7465 725d 2028 3e3d 3132 2e30  jupyter] (>=12.0
-00000670: 2e30 2c3c 3133 2e30 2e30 290a 5265 7175  .0,<13.0.0).Requ
-00000680: 6972 6573 2d44 6973 743a 2073 656d 7665  ires-Dist: semve
-00000690: 7220 283e 3d32 2e31 332e 302c 3c33 2e30  r (>=2.13.0,<3.0
-000006a0: 2e30 290a 5265 7175 6972 6573 2d44 6973  .0).Requires-Dis
-000006b0: 743a 2073 716c 6d6f 6465 6c20 283e 3d30  t: sqlmodel (>=0
-000006c0: 2e30 2e36 2c3c 302e 312e 3029 0a52 6571  .0.6,<0.1.0).Req
-000006d0: 7569 7265 732d 4469 7374 3a20 7576 6963  uires-Dist: uvic
-000006e0: 6f72 6e5b 7374 616e 6461 7264 5d20 283e  orn[standard] (>
-000006f0: 3d30 2e31 372e 352c 3c30 2e31 382e 3029  =0.17.5,<0.18.0)
-00000700: 0a50 726f 6a65 6374 2d55 524c 3a20 446f  .Project-URL: Do
-00000710: 6375 6d65 6e74 6174 696f 6e2c 2068 7474  cumentation, htt
-00000720: 7073 3a2f 2f64 6f63 732e 7a65 6e6d 6c2e  ps://docs.zenml.
-00000730: 696f 0a50 726f 6a65 6374 2d55 524c 3a20  io.Project-URL: 
-00000740: 5265 706f 7369 746f 7279 2c20 6874 7470  Repository, http
-00000750: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f7a  s://github.com/z
-00000760: 656e 6d6c 2d69 6f2f 7a65 6e6d 6c0a 4465  enml-io/zenml.De
-00000770: 7363 7269 7074 696f 6e2d 436f 6e74 656e  scription-Conten
-00000780: 742d 5479 7065 3a20 7465 7874 2f6d 6172  t-Type: text/mar
-00000790: 6b64 6f77 6e0a 0a3c 6469 7620 616c 6967  kdown..<div alig
-000007a0: 6e3d 2263 656e 7465 7222 3e0a 2020 2020  n="center">.    
-000007b0: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
-000007c0: 2f2f 7a65 6e6d 6c2e 696f 2f61 7373 6574  //zenml.io/asset
-000007d0: 732f 736f 6369 616c 2f67 6974 6875 622e  s/social/github.
-000007e0: 7376 6722 3e0a 3c2f 6469 763e 0a0a 2320  svg">.</div>..# 
-000007f0: e28f b2ef b88f 204a 6f69 6e20 7468 6520  ...... Join the 
-00000800: 5a65 6e4d 4c20 7465 616d 206f 6e20 7468  ZenML team on th
-00000810: 6520 4d4c 4f70 7320 4461 790a 0a57 6520  e MLOps Day..We 
-00000820: 6172 6520 686f 7374 696e 6720 6120 4d4c  are hosting a ML
-00000830: 4f70 7320 6461 7920 7768 6572 6520 7765  Ops day where we
-00000840: 276c 6c20 6265 2062 7569 6c64 696e 6720  'll be building 
-00000850: 6120 7665 6e64 6f72 2d61 676e 6f73 7469  a vendor-agnosti
-00000860: 6320 4d4c 4f70 7320 7069 7065 6c69 6e65  c MLOps pipeline
-00000870: 2066 726f 6d20 7363 7261 7463 682e 0a0a   from scratch...
-00000880: 5369 676e 2075 7020 5b68 6572 655d 2868  Sign up [here](h
-00000890: 7474 7073 3a2f 2f77 7777 2e65 7665 6e74  ttps://www.event
-000008a0: 6272 6974 652e 636f 6d2f 652f 7a65 6e6d  brite.com/e/zenm
-000008b0: 6c2d 6d6c 6f70 732d 6461 792d 6a6f 696e  l-mlops-day-join
-000008c0: 2d75 732d 696e 2d62 7569 6c64 696e 672d  -us-in-building-
-000008d0: 612d 7665 6e64 6f72 2d61 676e 6f73 7469  a-vendor-agnosti
-000008e0: 632d 6d6c 6f70 732d 7069 7065 6c69 6e65  c-mlops-pipeline
-000008f0: 2d74 6963 6b65 7473 2d33 3336 3333 3135  -tickets-3363315
-00000900: 3135 3631 3729 2074 6f20 6a6f 696e 2074  15617) to join t
-00000910: 6865 2065 6e74 6972 6520 5a65 6e4d 4c20  he entire ZenML 
-00000920: 7465 616d 2069 6e20 7368 6f77 6361 7369  team in showcasi
-00000930: 6e67 2074 6865 206c 6174 6573 7420 7265  ng the latest re
-00000940: 6c65 6173 652c 2061 6e73 7765 7269 6e67  lease, answering
-00000950: 2074 6865 2063 6f6d 6d75 6e69 7479 2773   the community's
-00000960: 2071 7565 7374 696f 6e73 2c20 616e 6420   questions, and 
-00000970: 6c69 7665 2d63 6f64 696e 6720 7665 6e64  live-coding vend
-00000980: 6f72 2061 676e 6f73 7469 6320 4d4c 4f70  or agnostic MLOp
-00000990: 7320 6665 6174 7572 6573 2077 6974 6820  s features with 
-000009a0: 7468 6520 5a65 6e4d 4c20 6672 616d 6577  the ZenML framew
-000009b0: 6f72 6b21 0a0a 2320 f09f 9180 2057 6861  ork!..# .... Wha
-000009c0: 7420 6973 205a 656e 4d4c 3f0a 0a2a 2a5a  t is ZenML?..**Z
-000009d0: 656e 4d4c 2a2a 2069 7320 616e 2065 7874  enML** is an ext
-000009e0: 656e 7369 626c 652c 206f 7065 6e2d 736f  ensible, open-so
-000009f0: 7572 6365 204d 4c4f 7073 2066 7261 6d65  urce MLOps frame
-00000a00: 776f 726b 2074 6f20 6372 6561 7465 0a70  work to create.p
-00000a10: 726f 6475 6374 696f 6e2d 7265 6164 7920  roduction-ready 
-00000a20: 6d61 6368 696e 6520 6c65 6172 6e69 6e67  machine learning
-00000a30: 2070 6970 656c 696e 6573 2e20 4275 696c   pipelines. Buil
-00000a40: 7420 666f 7220 6461 7461 2073 6369 656e  t for data scien
-00000a50: 7469 7374 732c 2069 7420 6861 7320 610a  tists, it has a.
-00000a60: 7369 6d70 6c65 2c20 666c 6578 6962 6c65  simple, flexible
-00000a70: 2073 796e 7461 782c 2069 7320 636c 6f75   syntax, is clou
-00000a80: 642d 2061 6e64 2074 6f6f 6c2d 6167 6e6f  d- and tool-agno
-00000a90: 7374 6963 2c20 616e 6420 6861 730a 696e  stic, and has.in
-00000aa0: 7465 7266 6163 6573 2f61 6273 7472 6163  terfaces/abstrac
-00000ab0: 7469 6f6e 7320 7468 6174 2061 7265 2063  tions that are c
-00000ac0: 6174 6572 6564 2074 6f77 6172 6473 204d  atered towards M
-00000ad0: 4c20 776f 726b 666c 6f77 732e 0a0a 4174  L workflows...At
-00000ae0: 2069 7473 2063 6f72 652c 202a 2a5a 656e   its core, **Zen
-00000af0: 4d4c 2070 6970 656c 696e 6573 2065 7865  ML pipelines exe
-00000b00: 6375 7465 204d 4c2d 7370 6563 6966 6963  cute ML-specific
-00000b10: 2077 6f72 6b66 6c6f 7773 2a2a 2066 726f   workflows** fro
-00000b20: 6d20 736f 7572 6369 6e67 0a64 6174 6120  m sourcing.data 
-00000b30: 746f 2073 706c 6974 7469 6e67 2c20 7072  to splitting, pr
-00000b40: 6570 726f 6365 7373 696e 672c 2074 7261  eprocessing, tra
-00000b50: 696e 696e 672c 2061 6c6c 2074 6865 2077  ining, all the w
-00000b60: 6179 2074 6f20 7468 6520 6576 616c 7561  ay to the evalua
-00000b70: 7469 6f6e 206f 660a 7265 7375 6c74 7320  tion of.results 
-00000b80: 616e 6420 6576 656e 2073 6572 7669 6e67  and even serving
-00000b90: 2e20 5468 6572 6520 6172 6520 6d61 6e79  . There are many
-00000ba0: 2062 7569 6c74 2d69 6e20 6261 7474 6572   built-in batter
-00000bb0: 6965 7320 746f 2073 7570 706f 7274 2063  ies to support c
-00000bc0: 6f6d 6d6f 6e20 4d4c 0a64 6576 656c 6f70  ommon ML.develop
-00000bd0: 6d65 6e74 2074 6173 6b73 2e20 5a65 6e4d  ment tasks. ZenM
-00000be0: 4c20 6973 206e 6f74 2068 6572 6520 746f  L is not here to
-00000bf0: 2072 6570 6c61 6365 2074 6865 2067 7265   replace the gre
-00000c00: 6174 2074 6f6f 6c73 2074 6861 7420 736f  at tools that so
-00000c10: 6c76 6520 7468 6573 650a 696e 6469 7669  lve these.indivi
-00000c20: 6475 616c 2070 726f 626c 656d 732e 2052  dual problems. R
-00000c30: 6174 6865 722c 2069 7420 6f66 6665 7273  ather, it offers
-00000c40: 2061 6e20 2a2a 6578 7465 6e73 6962 6c65   an **extensible
-00000c50: 2066 7261 6d65 776f 726b 2a2a 2061 6e64   framework** and
-00000c60: 2061 0a73 7461 6e64 6172 6420 6162 7374   a.standard abst
-00000c70: 7261 6374 696f 6e20 746f 2077 7269 7465  raction to write
-00000c80: 2061 6e64 2062 7569 6c64 2079 6f75 7220   and build your 
-00000c90: 776f 726b 666c 6f77 732e 0a0a f09f 8e89  workflows.......
-00000ca0: 202a 2a56 6572 7369 6f6e 2030 2e38 2e30   **Version 0.8.0
-00000cb0: 206f 7574 206e 6f77 212a 2a20 5b43 6865   out now!** [Che
-00000cc0: 636b 206f 7574 2074 6865 2072 656c 6561  ck out the relea
-00000cd0: 7365 206e 6f74 6573 0a68 6572 655d 2868  se notes.here](h
-00000ce0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
-00000cf0: 6d2f 7a65 6e6d 6c2d 696f 2f7a 656e 6d6c  m/zenml-io/zenml
-00000d00: 2f72 656c 6561 7365 7329 2e0a 0a5b 215b  /releases)...[![
-00000d10: 5079 5049 202d 2050 7974 686f 6e0a 5665  PyPI - Python.Ve
-00000d20: 7273 696f 6e5d 2868 7474 7073 3a2f 2f69  rsion](https://i
-00000d30: 6d67 2e73 6869 656c 6473 2e69 6f2f 7079  mg.shields.io/py
-00000d40: 7069 2f70 7976 6572 7369 6f6e 732f 7a65  pi/pyversions/ze
-00000d50: 6e6d 6c29 5d28 6874 7470 733a 2f2f 7079  nml)](https://py
-00000d60: 7069 2e6f 7267 2f70 726f 6a65 6374 2f7a  pi.org/project/z
-00000d70: 656e 6d6c 2f29 0a5b 215b 5079 5049 2053  enml/).[![PyPI S
-00000d80: 7461 7475 735d 2868 7474 7073 3a2f 2f70  tatus](https://p
-00000d90: 6570 792e 7465 6368 2f62 6164 6765 2f7a  epy.tech/badge/z
-00000da0: 656e 6d6c 295d 2868 7474 7073 3a2f 2f70  enml)](https://p
-00000db0: 6570 792e 7465 6368 2f70 726f 6a65 6374  epy.tech/project
-00000dc0: 2f7a 656e 6d6c 290a 215b 4769 7448 7562  /zenml).![GitHub
-00000dd0: 5d28 6874 7470 733a 2f2f 696d 672e 7368  ](https://img.sh
-00000de0: 6965 6c64 732e 696f 2f67 6974 6875 622f  ields.io/github/
-00000df0: 6c69 6365 6e73 652f 7a65 6e6d 6c2d 696f  license/zenml-io
-00000e00: 2f7a 656e 6d6c 290a 5b21 5b43 6f64 6563  /zenml).[![Codec
-00000e10: 6f76 5d28 6874 7470 733a 2f2f 636f 6465  ov](https://code
-00000e20: 636f 762e 696f 2f67 682f 7a65 6e6d 6c2d  cov.io/gh/zenml-
-00000e30: 696f 2f7a 656e 6d6c 2f62 7261 6e63 682f  io/zenml/branch/
-00000e40: 6d61 696e 2f67 7261 7068 2f62 6164 6765  main/graph/badge
-00000e50: 2e73 7667 295d 2868 7474 7073 3a2f 2f63  .svg)](https://c
-00000e60: 6f64 6563 6f76 2e69 6f2f 6768 2f7a 656e  odecov.io/gh/zen
-00000e70: 6d6c 2d69 6f2f 7a65 6e6d 6c29 0a5b 215b  ml-io/zenml).[![
-00000e80: 496e 7465 7272 6f67 6174 655d 2864 6f63  Interrogate](doc
-00000e90: 732f 696e 7465 7272 6f67 6174 652e 7376  s/interrogate.sv
-00000ea0: 6729 5d28 6874 7470 733a 2f2f 696e 7465  g)](https://inte
-00000eb0: 7272 6f67 6174 652e 7265 6164 7468 6564  rrogate.readthed
-00000ec0: 6f63 732e 696f 2f65 6e2f 6c61 7465 7374  ocs.io/en/latest
-00000ed0: 2f29 0a5b 215b 4d61 696e 2057 6f72 6b66  /).[![Main Workf
-00000ee0: 6c6f 770a 5465 7374 735d 2868 7474 7073  low.Tests](https
-00000ef0: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
-00000f00: 6e6d 6c2d 696f 2f7a 656e 6d6c 2f61 6374  nml-io/zenml/act
-00000f10: 696f 6e73 2f77 6f72 6b66 6c6f 7773 2f63  ions/workflows/c
-00000f20: 692e 796d 6c2f 6261 6467 652e 7376 673f  i.yml/badge.svg?
-00000f30: 6272 616e 6368 3d6d 6169 6e29 5d28 6874  branch=main)](ht
-00000f40: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
-00000f50: 2f7a 656e 6d6c 2d69 6f2f 7a65 6e6d 6c2f  /zenml-io/zenml/
-00000f60: 6163 7469 6f6e 732f 776f 726b 666c 6f77  actions/workflow
-00000f70: 732f 6369 2e79 6d6c 290a 0a3c 6469 7620  s/ci.yml)..<div 
-00000f80: 616c 6967 6e3d 2263 656e 7465 7222 3e0a  align="center">.
-00000f90: 4a6f 696e 206f 7572 203c 6120 6872 6566  Join our <a href
-00000fa0: 3d22 6874 7470 733a 2f2f 7a65 6e6d 6c2e  ="https://zenml.
-00000fb0: 696f 2f73 6c61 636b 2d69 6e76 6974 6522  io/slack-invite"
-00000fc0: 2074 6172 6765 743d 225f 626c 616e 6b22   target="_blank"
-00000fd0: 3e0a 2020 2020 3c69 6d67 2077 6964 7468  >.    <img width
-00000fe0: 3d22 3235 2220 7372 633d 2268 7474 7073  ="25" src="https
-00000ff0: 3a2f 2f63 646e 332e 6963 6f6e 6669 6e64  ://cdn3.iconfind
-00001000: 6572 2e63 6f6d 2f64 6174 612f 6963 6f6e  er.com/data/icon
-00001010: 732f 6c6f 676f 732d 616e 642d 6272 616e  s/logos-and-bran
-00001020: 6473 2d61 646f 6265 2f35 3132 2f33 3036  ds-adobe/512/306
-00001030: 5f53 6c61 636b 2d35 3132 2e70 6e67 2220  _Slack-512.png" 
-00001040: 616c 743d 2253 6c61 636b 222f 3e0a 3c62  alt="Slack"/>.<b
-00001050: 3e53 6c61 636b 2043 6f6d 6d75 6e69 7479  >Slack Community
-00001060: 3c2f 623e 203c 2f61 3e20 616e 6420 6265  </b> </a> and be
-00001070: 636f 6d65 2070 6172 7420 6f66 2074 6865  come part of the
-00001080: 205a 656e 4d4c 2066 616d 696c 790a 3c2f   ZenML family.</
-00001090: 6469 763e 0a3c 6469 7620 616c 6967 6e3d  div>.<div align=
-000010a0: 2263 656e 7465 7222 3e20 4769 7665 2075  "center"> Give u
-000010b0: 7320 6120 0a20 2020 203c 696d 6720 7769  s a .    <img wi
-000010c0: 6474 683d 2232 3522 2073 7263 3d22 6874  dth="25" src="ht
-000010d0: 7470 733a 2f2f 6364 6e2e 6963 6f6e 7363  tps://cdn.iconsc
-000010e0: 6f75 742e 636f 6d2f 6963 6f6e 2f66 7265  out.com/icon/fre
-000010f0: 652f 706e 672d 3235 362f 6769 7468 7562  e/png-256/github
-00001100: 2d31 3533 2d36 3735 3532 332e 706e 6722  -153-675523.png"
-00001110: 2061 6c74 3d22 536c 6163 6b22 2f3e 0a3c   alt="Slack"/>.<
-00001120: 623e 4769 7448 7562 2073 7461 723c 2f62  b>GitHub star</b
-00001130: 3e20 746f 2073 686f 7720 796f 7572 206c  > to show your l
-00001140: 6f76 650a 3c2f 6469 763e 0a3c 6469 7620  ove.</div>.<div 
-00001150: 616c 6967 6e3d 2263 656e 7465 7222 3e20  align="center"> 
-00001160: 0a20 2020 203c 623e 4e45 573a 203c 2f62  .    <b>NEW: </b
-00001170: 3e20 3c61 2068 7265 663d 2268 7474 7073  > <a href="https
-00001180: 3a2f 2f7a 656e 6d6c 2e69 6f2f 6469 7363  ://zenml.io/disc
-00001190: 7573 7369 6f6e 2220 7461 7267 6574 3d22  ussion" target="
-000011a0: 5f62 6c61 6e6b 223e 3c69 6d67 2077 6964  _blank"><img wid
-000011b0: 7468 3d22 3235 2220 7372 633d 2268 7474  th="25" src="htt
-000011c0: 7073 3a2f 2f63 646e 312e 6963 6f6e 6669  ps://cdn1.iconfi
-000011d0: 6e64 6572 2e63 6f6d 2f64 6174 612f 6963  nder.com/data/ic
-000011e0: 6f6e 732f 736f 6369 616c 2d31 372f 3438  ons/social-17/48
-000011f0: 2f6c 696b 652d 3531 322e 706e 6722 2061  /like-512.png" a
-00001200: 6c74 3d22 566f 7465 222f 3e3c 623e 2056  lt="Vote"/><b> V
-00001210: 6f74 653c 2f62 3e3c 2f61 3e20 6f6e 2074  ote</b></a> on t
-00001220: 6865 206e 6578 7420 5a65 6e4d 4c20 6665  he next ZenML fe
-00001230: 6174 7572 6573 200a 3c2f 6469 763e 0a0a  atures .</div>..
-00001240: 3c62 723e 0a0a 2320 f09f a496 2057 6879  <br>..# .... Why
-00001250: 2075 7365 205a 656e 4d4c 3f0a 0a5a 656e   use ZenML?..Zen
-00001260: 4d4c 2070 6970 656c 696e 6573 2061 7265  ML pipelines are
-00001270: 2064 6573 6967 6e65 6420 746f 2062 6520   designed to be 
-00001280: 7772 6974 7465 6e20 6561 726c 7920 6f6e  written early on
-00001290: 2074 6865 2064 6576 656c 6f70 6d65 6e74   the development
-000012a0: 206c 6966 6563 7963 6c65 2e0a 4461 7461   lifecycle..Data
-000012b0: 2073 6369 656e 7469 7374 7320 6361 6e20   scientists can 
-000012c0: 6578 706c 6f72 6520 7468 6569 7220 7069  explore their pi
-000012d0: 7065 6c69 6e65 7320 6173 2074 6865 7920  pelines as they 
-000012e0: 6465 7665 6c6f 7020 746f 7761 7264 7320  develop towards 
-000012f0: 7072 6f64 7563 7469 6f6e 2c0a 7377 6974  production,.swit
-00001300: 6368 696e 6720 7374 6163 6b73 2066 726f  ching stacks fro
-00001310: 6d20 6c6f 6361 6c20 746f 2063 6c6f 7564  m local to cloud
-00001320: 2064 6570 6c6f 796d 656e 7473 2077 6974   deployments wit
-00001330: 6820 6561 7365 2e20 596f 7520 6361 6e20  h ease. You can 
-00001340: 7265 6164 206d 6f72 650a 6162 6f75 7420  read more.about 
-00001350: 7768 7920 7765 2073 7461 7274 6564 2062  why we started b
-00001360: 7569 6c64 696e 6720 5a65 6e4d 4c20 5b6f  uilding ZenML [o
-00001370: 6e20 6f75 720a 626c 6f67 5d28 6874 7470  n our.blog](http
-00001380: 733a 2f2f 626c 6f67 2e7a 656e 6d6c 2e69  s://blog.zenml.i
-00001390: 6f2f 7768 792d 7a65 6e6d 6c2f 292e 2042  o/why-zenml/). B
-000013a0: 7920 7573 696e 6720 5a65 6e4d 4c20 696e  y using ZenML in
-000013b0: 2074 6865 2065 6172 6c79 2073 7461 6765   the early stage
-000013c0: 7320 6f66 0a79 6f75 7220 7072 6f6a 6563  s of.your projec
-000013d0: 742c 2079 6f75 2067 6574 2074 6865 2066  t, you get the f
-000013e0: 6f6c 6c6f 7769 6e67 2062 656e 6566 6974  ollowing benefit
-000013f0: 733a 0a0a 2d20 2a2a 4578 7465 6e73 6962  s:..- **Extensib
-00001400: 6c65 2a2a 2073 6f20 796f 7520 6361 6e20  le** so you can 
-00001410: 6275 696c 6420 6f75 7420 7468 6520 6672  build out the fr
-00001420: 616d 6577 6f72 6b20 746f 2073 7569 7420  amework to suit 
-00001430: 796f 7572 2073 7065 6369 6669 6320 6e65  your specific ne
-00001440: 6564 730a 2d20 2a2a 5265 7072 6f64 7563  eds.- **Reproduc
-00001450: 6962 696c 6974 792a 2a20 6f66 2074 7261  ibility** of tra
-00001460: 696e 696e 6720 616e 6420 696e 6665 7265  ining and infere
-00001470: 6e63 6520 776f 726b 666c 6f77 730a 2d20  nce workflows.- 
-00001480: 4120 2a2a 7369 6d70 6c65 2061 6e64 2063  A **simple and c
-00001490: 6c65 6172 2a2a 2077 6179 2074 6f20 7265  lear** way to re
-000014a0: 7072 6573 656e 7420 7468 6520 7374 6570  present the step
-000014b0: 7320 6f66 2079 6f75 7220 7069 7065 6c69  s of your pipeli
-000014c0: 6e65 2069 6e20 636f 6465 0a2d 202a 2a42  ne in code.- **B
-000014d0: 6174 7465 7269 6573 2d69 6e63 6c75 6465  atteries-include
-000014e0: 6420 696e 7465 6772 6174 696f 6e73 2a2a  d integrations**
-000014f0: 3a20 6272 696e 6720 616c 6c20 796f 7572  : bring all your
-00001500: 2066 6176 6f72 6974 6520 746f 6f6c 7320   favorite tools 
-00001510: 746f 6765 7468 6572 0a2d 2045 6173 7920  together.- Easy 
-00001520: 7377 6974 6368 2062 6574 7765 656e 206c  switch between l
-00001530: 6f63 616c 2061 6e64 2063 6c6f 7564 2073  ocal and cloud s
-00001540: 7461 636b 730a 2d20 5061 696e 6c65 7373  tacks.- Painless
-00001550: 202a 2a64 6570 6c6f 796d 656e 7420 616e   **deployment an
-00001560: 6420 636f 6e66 6967 7572 6174 696f 6e2a  d configuration*
-00001570: 2a20 6f66 2069 6e66 7261 7374 7275 6374  * of infrastruct
-00001580: 7572 650a 0a23 20f0 9f93 9620 4c65 6172  ure..# .... Lear
-00001590: 6e20 4d6f 7265 0a0a 7c20 5a65 6e4d 4c20  n More..| ZenML 
-000015a0: 5265 736f 7572 6365 7320 7c20 4465 7363  Resources | Desc
-000015b0: 7269 7074 696f 6e20 7c0a 7c20 2d2d 2d2d  ription |.| ----
-000015c0: 2d2d 2d2d 2d2d 2d2d 2d20 7c20 2d20 7c0a  --------- | - |.
-000015d0: 7c20 f09f a798 e280 8de2 9980 efb8 8f20  | ............. 
-000015e0: 2a2a 5b5a 656e 4d4c 2031 3031 5d2a 2a20  **[ZenML 101]** 
-000015f0: 7c20 4e65 7720 746f 205a 656e 4d4c 3f20  | New to ZenML? 
-00001600: 4865 7265 2773 2065 7665 7279 7468 696e  Here's everythin
-00001610: 6720 796f 7520 6e65 6564 2074 6f20 6b6e  g you need to kn
-00001620: 6f77 2120 7c0a 7c20 e29a 9bef b88f 202a  ow! |.| ...... *
-00001630: 2a5b 436f 7265 2043 6f6e 6365 7074 735d  *[Core Concepts]
-00001640: 2a2a 207c 2053 6f6d 6520 6b65 7920 7465  ** | Some key te
-00001650: 726d 7320 616e 6420 636f 6e63 6570 7473  rms and concepts
-00001660: 2077 6520 7573 652e 207c 0a7c 20f0 9f97   we use. |.| ...
-00001670: 8320 2a2a 5b46 756e 6374 696f 6e61 6c20  . **[Functional 
-00001680: 4150 4920 4775 6964 655d 2a2a 207c 2042  API Guide]** | B
-00001690: 7569 6c64 2070 726f 6475 6374 696f 6e20  uild production 
-000016a0: 4d4c 2070 6970 656c 696e 6573 2077 6974  ML pipelines wit
-000016b0: 6820 7369 6d70 6c65 2066 756e 6374 696f  h simple functio
-000016c0: 6e73 2e20 7c0a 7c20 f09f 9a80 202a 2a5b  ns. |.| .... **[
-000016d0: 4e65 7720 696e 2076 302e 382e 305d 2a2a  New in v0.8.0]**
-000016e0: 207c 204e 6577 2066 6561 7475 7265 732c   | New features,
-000016f0: 2062 7567 2066 6978 6573 2e20 7c0a 7c20   bug fixes. |.| 
-00001700: f09f 97b3 202a 2a5b 566f 7465 2066 6f72  .... **[Vote for
-00001710: 2046 6561 7475 7265 735d 2a2a 207c 2050   Features]** | P
-00001720: 6963 6b20 7768 6174 2077 6520 776f 726b  ick what we work
-00001730: 206f 6e20 6e65 7874 2120 7c0a 7c20 f09f   on next! |.| ..
-00001740: 9393 202a 2a5b 446f 6373 5d2a 2a20 7c20  .. **[Docs]** | 
-00001750: 4675 6c6c 2064 6f63 756d 656e 7461 7469  Full documentati
-00001760: 6f6e 2066 6f72 2063 7265 6174 696e 6720  on for creating 
-00001770: 796f 7572 206f 776e 205a 656e 4d4c 2070  your own ZenML p
-00001780: 6970 656c 696e 6573 2e20 7c0a 7c20 f09f  ipelines. |.| ..
-00001790: 9392 202a 2a5b 4150 4920 5265 6665 7265  .. **[API Refere
-000017a0: 6e63 655d 2a2a 207c 2054 6865 2064 6574  nce]** | The det
-000017b0: 6169 6c65 6420 7265 6665 7265 6e63 6520  ailed reference 
-000017c0: 666f 7220 5a65 6e4d 4c27 7320 4150 492e  for ZenML's API.
-000017d0: 207c 0a7c 20f0 9f8d b020 2a2a 5b5a 656e   |.| .... **[Zen
-000017e0: 4279 7465 735d 2a2a 207c 2041 2067 7569  Bytes]** | A gui
-000017f0: 6465 6420 616e 6420 696e 2d64 6570 7468  ded and in-depth
-00001800: 2074 7574 6f72 6961 6c20 6f6e 204d 4c4f   tutorial on MLO
-00001810: 7073 2061 6e64 205a 656e 4d4c 2e20 7c0a  ps and ZenML. |.
-00001820: 7c20 f09f 9782 efb8 8fef b88f 202a 2a5b  | .......... **[
-00001830: 5a65 6e46 696c 6573 5d2a 2a20 7c20 456e  ZenFiles]** | En
-00001840: 642d 746f 2d65 6e64 2070 726f 6a65 6374  d-to-end project
-00001850: 7320 7573 696e 6720 5a65 6e4d 4c2e 207c  s using ZenML. |
-00001860: 0a7c 20e2 9abd efb8 8f20 2a2a 5b45 7861  .| ...... **[Exa
-00001870: 6d70 6c65 735d 2a2a 207c 204c 6561 726e  mples]** | Learn
-00001880: 2062 6573 7420 7468 726f 7567 6820 6578   best through ex
-00001890: 616d 706c 6573 2077 6865 7265 205a 656e  amples where Zen
-000018a0: 4d4c 2069 7320 7573 6564 3f20 5765 2776  ML is used? We'v
-000018b0: 6520 676f 7420 796f 7520 636f 7665 7265  e got you covere
-000018c0: 642e 207c 0a7c 20f0 9f93 ac20 2a2a 5b42  d. |.| .... **[B
-000018d0: 6c6f 675d 2a2a 207c 2055 7365 2063 6173  log]** | Use cas
-000018e0: 6573 206f 6620 5a65 6e4d 4c20 616e 6420  es of ZenML and 
-000018f0: 7465 6368 6e69 6361 6c20 6465 6570 2064  technical deep d
-00001900: 6976 6573 206f 6e20 686f 7720 7765 2062  ives on how we b
-00001910: 7569 6c74 2069 742e 207c 0a7c 20f0 9f94  uilt it. |.| ...
-00001920: 8820 2a2a 5b50 6f64 6361 7374 5d2a 2a20  . **[Podcast]** 
-00001930: 7c20 436f 6e76 6572 7361 7469 6f6e 7320  | Conversations 
-00001940: 7769 7468 206c 6561 6465 7273 2069 6e20  with leaders in 
-00001950: 4d4c 2c20 7265 6c65 6173 6564 2065 7665  ML, released eve
-00001960: 7279 2032 2077 6565 6b73 2e20 7c0a 7c20  ry 2 weeks. |.| 
-00001970: f09f 93a3 202a 2a5b 4e65 7773 6c65 7474  .... **[Newslett
-00001980: 6572 5d2a 2a20 7c20 5765 2062 7569 6c64  er]** | We build
-00001990: 205a 656e 4d4c 2069 6e20 7075 626c 6963   ZenML in public
-000019a0: 2e20 5375 6273 6372 6962 6520 746f 206c  . Subscribe to l
-000019b0: 6561 726e 2068 6f77 2077 6520 776f 726b  earn how we work
-000019c0: 2e20 7c0a 7c20 f09f 92ac 202a 2a5b 4a6f  . |.| .... **[Jo
-000019d0: 696e 2053 6c61 636b 5d2a 2a20 7c20 4e65  in Slack]** | Ne
-000019e0: 6564 2068 656c 7020 7769 7468 2079 6f75  ed help with you
-000019f0: 7220 7370 6563 6966 6963 2075 7365 2063  r specific use c
-00001a00: 6173 653f 2053 6179 2068 6920 6f6e 2053  ase? Say hi on S
-00001a10: 6c61 636b 2120 7c0a 7c20 f09f 97ba 202a  lack! |.| .... *
-00001a20: 2a5b 526f 6164 6d61 705d 2a2a 207c 2053  *[Roadmap]** | S
-00001a30: 6565 2077 6865 7265 205a 656e 4d4c 2069  ee where ZenML i
-00001a40: 7320 776f 726b 696e 6720 746f 2062 7569  s working to bui
-00001a50: 6c64 206e 6577 2066 6561 7475 7265 732e  ld new features.
-00001a60: 207c 0a7c 20f0 9f99 8be2 808d e299 80ef   |.| ...........
-00001a70: b88f 202a 2a5b 436f 6e74 7269 6275 7465  .. **[Contribute
-00001a80: 5d2a 2a20 7c20 486f 7720 746f 2063 6f6e  ]** | How to con
-00001a90: 7472 6962 7574 6520 746f 2074 6865 205a  tribute to the Z
-00001aa0: 656e 4d4c 2070 726f 6a65 6374 2061 6e64  enML project and
-00001ab0: 2063 6f64 6520 6261 7365 2e20 7c0a 0a5b   code base. |..[
-00001ac0: 5a65 6e4d 4c20 3130 315d 3a20 6874 7470  ZenML 101]: http
-00001ad0: 733a 2f2f 646f 6373 2e7a 656e 6d6c 2e69  s://docs.zenml.i
-00001ae0: 6f2f 0a5b 436f 7265 2043 6f6e 6365 7074  o/.[Core Concept
-00001af0: 735d 3a20 6874 7470 733a 2f2f 646f 6373  s]: https://docs
-00001b00: 2e7a 656e 6d6c 2e69 6f2f 636f 7265 2d63  .zenml.io/core-c
-00001b10: 6f6e 6365 7074 730a 5b46 756e 6374 696f  oncepts.[Functio
-00001b20: 6e61 6c20 4150 4920 4775 6964 655d 3a20  nal API Guide]: 
-00001b30: 6874 7470 733a 2f2f 646f 6373 2e7a 656e  https://docs.zen
-00001b40: 6d6c 2e69 6f2f 762f 646f 6373 2f67 7569  ml.io/v/docs/gui
-00001b50: 6465 732f 6675 6e63 7469 6f6e 616c 2d61  des/functional-a
-00001b60: 7069 0a5b 4e65 7720 696e 2076 302e 382e  pi.[New in v0.8.
-00001b70: 305d 3a20 6874 7470 733a 2f2f 6769 7468  0]: https://gith
-00001b80: 7562 2e63 6f6d 2f7a 656e 6d6c 2d69 6f2f  ub.com/zenml-io/
-00001b90: 7a65 6e6d 6c2f 7265 6c65 6173 6573 0a5b  zenml/releases.[
-00001ba0: 566f 7465 2066 6f72 2046 6561 7475 7265  Vote for Feature
-00001bb0: 735d 3a20 6874 7470 733a 2f2f 7a65 6e6d  s]: https://zenm
-00001bc0: 6c2e 696f 2f64 6973 6375 7373 696f 6e0a  l.io/discussion.
-00001bd0: 5b44 6f63 735d 3a20 6874 7470 733a 2f2f  [Docs]: https://
-00001be0: 646f 6373 2e7a 656e 6d6c 2e69 6f2f 0a5b  docs.zenml.io/.[
-00001bf0: 4150 4920 5265 6665 7265 6e63 655d 3a20  API Reference]: 
-00001c00: 6874 7470 733a 2f2f 6170 6964 6f63 732e  https://apidocs.
-00001c10: 7a65 6e6d 6c2e 696f 2f0a 5b5a 656e 4279  zenml.io/.[ZenBy
-00001c20: 7465 735d 3a20 6874 7470 733a 2f2f 6769  tes]: https://gi
-00001c30: 7468 7562 2e63 6f6d 2f7a 656e 6d6c 2d69  thub.com/zenml-i
-00001c40: 6f2f 7a65 6e62 7974 6573 0a5b 5a65 6e46  o/zenbytes.[ZenF
-00001c50: 696c 6573 5d3a 2068 7474 7073 3a2f 2f67  iles]: https://g
-00001c60: 6974 6875 622e 636f 6d2f 7a65 6e6d 6c2d  ithub.com/zenml-
-00001c70: 696f 2f7a 656e 6669 6c65 730a 5b45 7861  io/zenfiles.[Exa
-00001c80: 6d70 6c65 735d 3a20 6874 7470 733a 2f2f  mples]: https://
-00001c90: 6769 7468 7562 2e63 6f6d 2f7a 656e 6d6c  github.com/zenml
-00001ca0: 2d69 6f2f 7a65 6e6d 6c2f 7472 6565 2f6d  -io/zenml/tree/m
-00001cb0: 6169 6e2f 6578 616d 706c 6573 0a5b 426c  ain/examples.[Bl
-00001cc0: 6f67 5d3a 2068 7474 7073 3a2f 2f62 6c6f  og]: https://blo
-00001cd0: 672e 7a65 6e6d 6c2e 696f 2f0a 5b50 6f64  g.zenml.io/.[Pod
-00001ce0: 6361 7374 5d3a 2068 7474 7073 3a2f 2f70  cast]: https://p
-00001cf0: 6f64 6361 7374 2e7a 656e 6d6c 2e69 6f2f  odcast.zenml.io/
-00001d00: 0a5b 4e65 7773 6c65 7474 6572 5d3a 2068  .[Newsletter]: h
-00001d10: 7474 7073 3a2f 2f7a 656e 6d6c 2e69 6f2f  ttps://zenml.io/
-00001d20: 6e65 7773 6c65 7474 6572 2f0a 5b4a 6f69  newsletter/.[Joi
-00001d30: 6e20 536c 6163 6b5d 3a20 6874 7470 733a  n Slack]: https:
-00001d40: 2f2f 7a65 6e6d 6c2e 696f 2f73 6c61 636b  //zenml.io/slack
-00001d50: 2d69 6e76 6974 652f 0a5b 526f 6164 6d61  -invite/.[Roadma
-00001d60: 705d 3a20 6874 7470 733a 2f2f 7a65 6e6d  p]: https://zenm
-00001d70: 6c2e 696f 2f72 6f61 646d 6170 0a5b 436f  l.io/roadmap.[Co
-00001d80: 6e74 7269 6275 7465 5d3a 2068 7474 7073  ntribute]: https
-00001d90: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
-00001da0: 6e6d 6c2d 696f 2f7a 656e 6d6c 2f62 6c6f  nml-io/zenml/blo
-00001db0: 622f 6d61 696e 2f43 4f4e 5452 4942 5554  b/main/CONTRIBUT
-00001dc0: 494e 472e 6d64 0a0a 2320 f09f 8eae 2046  ING.md..# .... F
-00001dd0: 6561 7475 7265 730a 0a23 2323 2031 2e20  eatures..### 1. 
-00001de0: f09f 92aa 2057 7269 7465 206c 6f63 616c  .... Write local
-00001df0: 2c20 7275 6e20 616e 7977 6865 7265 0a0a  , run anywhere..
-00001e00: 596f 7520 6f6e 6c79 206e 6565 6420 746f  You only need to
-00001e10: 2077 7269 7465 2079 6f75 7220 636f 7265   write your core
-00001e20: 206d 6163 6869 6e65 206c 6561 726e 696e   machine learnin
-00001e30: 6720 776f 726b 666c 6f77 2063 6f64 6520  g workflow code 
-00001e40: 6f6e 6365 2c20 6275 7420 796f 750a 6361  once, but you.ca
-00001e50: 6e20 7275 6e20 6974 2061 6e79 7768 6572  n run it anywher
-00001e60: 652e 2057 6520 6465 636f 7570 6c65 2079  e. We decouple y
-00001e70: 6f75 7220 636f 6465 2066 726f 6d20 7468  our code from th
-00001e80: 6520 656e 7669 726f 6e6d 656e 7420 616e  e environment an
-00001e90: 640a 696e 6672 6173 7472 7563 7475 7265  d.infrastructure
-00001ea0: 206f 6e20 7768 6963 6820 7468 6973 2063   on which this c
-00001eb0: 6f64 6520 7275 6e73 2e0a 0a53 7769 7463  ode runs...Switc
-00001ec0: 6869 6e67 2066 726f 6d20 6c6f 6361 6c20  hing from local 
-00001ed0: 6578 7065 7269 6d65 6e74 7320 746f 2063  experiments to c
-00001ee0: 6c6f 7564 2d62 6173 6564 2070 6970 656c  loud-based pipel
-00001ef0: 696e 6573 2064 6f65 736e 2774 206e 6565  ines doesn't nee
-00001f00: 6420 746f 2062 650a 636f 6d70 6c69 6361  d to be.complica
-00001f10: 7465 642e 205a 656e 4d4c 2073 7570 706f  ted. ZenML suppo
-00001f20: 7274 7320 7275 6e6e 696e 6720 7069 7065  rts running pipe
-00001f30: 6c69 6e65 7320 7768 6572 6576 6572 2079  lines wherever y
-00001f40: 6f75 2077 616e 742c 2066 6f72 2065 7861  ou want, for exa
-00001f50: 6d70 6c65 2062 790a 7573 696e 6720 4b75  mple by.using Ku
-00001f60: 6265 666c 6f77 2c20 6f6e 6520 6f66 206f  beflow, one of o
-00001f70: 7572 2062 7569 6c74 2d69 6e20 696e 7465  ur built-in inte
-00001f80: 6772 6174 696f 6e73 2c20 6f72 2061 6e79  grations, or any
-00001f90: 206f 7263 6865 7374 7261 746f 7220 6f66   orchestrator of
-00001fa0: 2079 6f75 720a 6368 6f69 6365 2e20 5377   your.choice. Sw
-00001fb0: 6974 6368 696e 6720 6672 6f6d 2079 6f75  itching from you
-00001fc0: 7220 6c6f 6361 6c20 7374 6163 6b20 746f  r local stack to
-00001fd0: 2061 2063 6c6f 7564 2073 7461 636b 2069   a cloud stack i
-00001fe0: 7320 6561 7379 2074 6f20 646f 2077 6974  s easy to do wit
-00001ff0: 6820 6f75 720a 434c 4920 746f 6f6c 2e0a  h our.CLI tool..
-00002000: 0a21 5b59 6f75 2063 616e 2072 756e 2079  .![You can run y
-00002010: 6f75 7220 7069 7065 6c69 6e65 7320 6c6f  our pipelines lo
-00002020: 6361 6c6c 7920 6f72 2069 6e20 7468 650a  cally or in the.
-00002030: 636c 6f75 645d 2864 6f63 732f 626f 6f6b  cloud](docs/book
-00002040: 2f61 7373 6574 732f 636f 7265 5f63 6f6e  /assets/core_con
-00002050: 6365 7074 732f 636f 6e63 6570 7473 2d33  cepts/concepts-3
-00002060: 2e70 6e67 290a 0a23 2323 2032 2e20 f09f  .png)..### 2. ..
-00002070: 8c88 2041 6c6c 2079 6f75 7220 4d4c 4f70  .. All your MLOp
-00002080: 7320 7374 6163 6b73 2069 6e20 6f6e 6520  s stacks in one 
-00002090: 706c 6163 650a 0a4f 6e63 6520 636f 6465  place..Once code
-000020a0: 2069 7320 6f72 6761 6e69 7a65 6420 696e   is organized in
-000020b0: 746f 2061 205a 656e 4d4c 2070 6970 656c  to a ZenML pipel
-000020c0: 696e 652c 2079 6f75 2063 616e 2073 7570  ine, you can sup
-000020d0: 6572 6368 6172 6765 2079 6f75 7220 4d4c  ercharge your ML
-000020e0: 0a64 6576 656c 6f70 6d65 6e74 2077 6974  .development wit
-000020f0: 6820 5b70 6f77 6572 6675 6c0a 696e 7465  h [powerful.inte
-00002100: 6772 6174 696f 6e73 5d28 6874 7470 733a  grations](https:
-00002110: 2f2f 646f 6373 2e7a 656e 6d6c 2e69 6f2f  //docs.zenml.io/
-00002120: 6665 6174 7572 6573 2f69 6e74 6567 7261  features/integra
-00002130: 7469 6f6e 7329 206f 6e20 6d75 6c74 6970  tions) on multip
-00002140: 6c65 205b 4d4c 4f70 730a 7374 6163 6b73  le [MLOps.stacks
-00002150: 5d28 6874 7470 733a 2f2f 646f 6373 2e7a  ](https://docs.z
-00002160: 656e 6d6c 2e69 6f2f 636f 7265 2d63 6f6e  enml.io/core-con
-00002170: 6365 7074 7329 2e20 5468 6572 6520 6172  cepts). There ar
-00002180: 6520 6c6f 7473 206f 6620 6d6f 7669 6e67  e lots of moving
-00002190: 2070 6172 7473 2066 6f72 0a61 6c6c 2074   parts for.all t
-000021a0: 6865 204d 4c4f 7073 2074 6f6f 6c69 6e67  he MLOps tooling
-000021b0: 2061 6e64 2069 6e66 7261 7374 7275 6374   and infrastruct
-000021c0: 7572 6520 796f 7520 7265 7175 6972 6520  ure you require 
-000021d0: 666f 7220 4d4c 2069 6e20 7072 6f64 7563  for ML in produc
-000021e0: 7469 6f6e 2061 6e64 0a5a 656e 4d4c 2061  tion and.ZenML a
-000021f0: 696d 7320 746f 2062 7269 6e67 2069 7420  ims to bring it 
-00002200: 616c 6c20 746f 6765 7468 6572 2075 6e64  all together und
-00002210: 6572 206f 6e65 2072 6f6f 662e 0a0a 5765  er one roof...We
-00002220: 2061 6c72 6561 6479 2073 7570 706f 7274   already support
-00002230: 2063 6f6d 6d6f 6e20 7573 6520 6361 7365   common use case
-00002240: 7320 616e 6420 696e 7465 6772 6174 696f  s and integratio
-00002250: 6e73 2074 6f20 7374 616e 6461 7264 204d  ns to standard M
-00002260: 4c20 746f 6f6c 7320 7669 610a 6f75 7220  L tools via.our 
-00002270: 7374 6163 6b20 636f 6d70 6f6e 656e 7473  stack components
-00002280: 2c20 6672 6f6d 206f 7263 6865 7374 7261  , from orchestra
-00002290: 746f 7273 206c 696b 6520 4169 7266 6c6f  tors like Airflo
-000022a0: 7720 616e 6420 4b75 6265 666c 6f77 2074  w and Kubeflow t
-000022b0: 6f20 6d6f 6465 6c0a 6465 706c 6f79 6d65  o model.deployme
-000022c0: 6e74 2076 6961 204d 4c66 6c6f 7720 6f72  nt via MLflow or
-000022d0: 2053 656c 646f 6e20 436f 7265 2c20 746f   Seldon Core, to
-000022e0: 2063 7573 746f 6d20 696e 6672 6173 7472   custom infrastr
-000022f0: 7563 7475 7265 2066 6f72 2074 7261 696e  ucture for train
-00002300: 696e 6720 796f 7572 0a6d 6f64 656c 7320  ing your.models 
-00002310: 696e 2074 6865 2063 6c6f 7564 2061 6e64  in the cloud and
-00002320: 2073 6f20 6f6e 2e20 4966 2079 6f75 2077   so on. If you w
-00002330: 616e 7420 746f 206c 6561 726e 206d 6f72  ant to learn mor
-00002340: 6520 6162 6f75 7420 6f75 7220 696e 7465  e about our inte
-00002350: 6772 6174 696f 6e73 2c0a 6368 6563 6b20  grations,.check 
-00002360: 6f75 7420 5b6f 7572 2045 7861 6d70 6c65  out [our Example
-00002370: 735d 2868 7474 7073 3a2f 2f67 6974 6875  s](https://githu
-00002380: 622e 636f 6d2f 7a65 6e6d 6c2d 696f 2f7a  b.com/zenml-io/z
-00002390: 656e 6d6c 2f74 7265 652f 6d61 696e 2f65  enml/tree/main/e
-000023a0: 7861 6d70 6c65 7329 0a74 6f20 7365 6520  xamples).to see 
-000023b0: 686f 7720 7468 6579 2077 6f72 6b2e 0a0a  how they work...
-000023c0: 215b 5a65 6e4d 4c20 6973 2074 6865 2067  ![ZenML is the g
-000023d0: 6c75 655d 2864 6f63 732f 626f 6f6b 2f61  lue](docs/book/a
-000023e0: 7373 6574 732f 7374 6163 6b2d 6c69 7374  ssets/stack-list
-000023f0: 2e70 6e67 290a 0a23 2323 2033 2e20 f09f  .png)..### 3. ..
-00002400: 9ba0 2045 7874 656e 7369 6269 6c69 7479  .. Extensibility
-00002410: 0a0a 5a65 6e4d 4c27 7320 5374 6163 6b20  ..ZenML's Stack 
-00002420: 436f 6d70 6f6e 656e 7473 2061 7265 2062  Components are b
-00002430: 7569 6c74 2074 6f20 7375 7070 6f72 7420  uilt to support 
-00002440: 6d6f 7374 206d 6163 6869 6e65 206c 6561  most machine lea
-00002450: 726e 696e 6720 7573 6520 6361 7365 732e  rning use cases.
-00002460: 0a57 6520 6f66 6665 7220 6120 6261 7474  .We offer a batt
-00002470: 6572 6965 732d 696e 636c 7564 6564 2069  eries-included i
-00002480: 6e69 7469 616c 2069 6e73 7461 6c6c 6174  nitial installat
-00002490: 696f 6e20 7468 6174 2073 686f 756c 6420  ion that should 
-000024a0: 7365 7276 6520 6d61 6e79 206e 6565 6473  serve many needs
-000024b0: 0a61 6e64 2077 6f72 6b66 6c6f 7773 2c20  .and workflows, 
-000024c0: 6275 7420 6966 2079 6f75 206e 6565 6420  but if you need 
-000024d0: 6120 7370 6563 6961 6c20 6b69 6e64 206f  a special kind o
-000024e0: 6620 6d6f 6e69 746f 7269 6e67 2074 6f6f  f monitoring too
-000024f0: 6c20 6164 6465 642c 2066 6f72 0a65 7861  l added, for.exa
-00002500: 6d70 6c65 2c20 6f72 2061 2064 6966 6665  mple, or a diffe
-00002510: 7265 6e74 206f 7263 6865 7374 7261 746f  rent orchestrato
-00002520: 7220 746f 2072 756e 2079 6f75 7220 7069  r to run your pi
-00002530: 7065 6c69 6e65 732c 205a 656e 4d4c 2069  pelines, ZenML i
-00002540: 7320 6275 696c 7420 6173 2061 0a66 7261  s built as a.fra
-00002550: 6d65 776f 726b 206d 616b 696e 6720 6974  mework making it
-00002560: 2065 6173 7920 746f 2065 7874 656e 6420   easy to extend 
-00002570: 616e 6420 6275 696c 6420 6f75 7420 7768  and build out wh
-00002580: 6174 6576 6572 2079 6f75 206e 6565 642e  atever you need.
-00002590: 0a0a 215b 5a65 6e4d 4c20 6973 2066 756c  ..![ZenML is ful
-000025a0: 6c79 2065 7874 656e 7369 626c 655d 2864  ly extensible](d
-000025b0: 6f63 732f 626f 6f6b 2f61 7373 6574 732f  ocs/book/assets/
-000025c0: 6578 7465 6e73 6962 696c 6974 792e 6769  extensibility.gi
-000025d0: 6629 0a0a 2323 2320 342e 20f0 9f94 8d20  f)..### 4. .... 
-000025e0: 4175 746f 6d61 7465 6420 6d65 7461 6461  Automated metada
-000025f0: 7461 2074 7261 636b 696e 670a 0a5a 656e  ta tracking..Zen
-00002600: 4d4c 2074 7261 636b 7320 6d65 7461 6461  ML tracks metada
-00002610: 7461 2066 6f72 2061 6c6c 2074 6865 2070  ta for all the p
-00002620: 6970 656c 696e 6573 2079 6f75 2072 756e  ipelines you run
-00002630: 2e20 5468 6973 2065 6e73 7572 6573 2074  . This ensures t
-00002640: 6861 743a 0a0a 2d20 436f 6465 2069 7320  hat:..- Code is 
-00002650: 7665 7273 696f 6e65 640a 2d20 4461 7461  versioned.- Data
-00002660: 2069 7320 7665 7273 696f 6e65 640a 2d20   is versioned.- 
-00002670: 4d6f 6465 6c73 2061 7265 2076 6572 7369  Models are versi
-00002680: 6f6e 6564 0a2d 2043 6f6e 6669 6775 7261  oned.- Configura
-00002690: 7469 6f6e 7320 6172 6520 7665 7273 696f  tions are versio
-000026a0: 6e65 640a 0a54 6869 7320 616c 736f 2065  ned..This also e
-000026b0: 6e61 626c 6573 2063 6163 6869 6e67 206f  nables caching o
-000026c0: 6620 7468 6520 6461 7461 2074 6861 7420  f the data that 
-000026d0: 706f 7765 7273 2079 6f75 7220 7069 7065  powers your pipe
-000026e0: 6c69 6e65 7320 7768 6963 6820 6865 6c70  lines which help
-000026f0: 7320 796f 750a 6974 6572 6174 6520 7175  s you.iterate qu
-00002700: 6963 6b6c 7920 7468 726f 7567 6820 4d4c  ickly through ML
-00002710: 2065 7870 6572 696d 656e 7473 2e20 2852   experiments. (R
-00002720: 6561 6420 5b6f 7572 0a62 6c6f 6770 6f73  ead [our.blogpos
-00002730: 745d 2868 7474 7073 3a2f 2f62 6c6f 672e  t](https://blog.
-00002740: 7a65 6e6d 6c2e 696f 2f63 6163 6869 6e67  zenml.io/caching
-00002750: 2d6d 6c2d 7069 7065 6c69 6e65 732f 2920  -ml-pipelines/) 
-00002760: 746f 206c 6561 726e 206d 6f72 6521 290a  to learn more!).
-00002770: 0a21 5b56 6973 7561 6c69 7a65 2079 6f75  .![Visualize you
-00002780: 7220 7069 7065 6c69 6e65 2073 7465 7073  r pipeline steps
-00002790: 5d28 646f 6373 2f62 6f6f 6b2f 6173 7365  ](docs/book/asse
-000027a0: 7473 2f64 6167 2d76 6973 7561 6c69 7a65  ts/dag-visualize
-000027b0: 722e 706e 6729 0a0a 2323 2320 352e 20e2  r.png)..### 5. .
-000027c0: 9ebf 2043 6f6e 7469 6e75 6f75 7320 5472  .. Continuous Tr
-000027d0: 6169 6e69 6e67 2061 6e64 2043 6f6e 7469  aining and Conti
-000027e0: 6e75 6f75 7320 4465 706c 6f79 6d65 6e74  nuous Deployment
-000027f0: 2028 4354 2f43 4429 0a0a 436f 6e74 696e   (CT/CD)..Contin
-00002800: 756f 7573 2054 7261 696e 696e 6720 2843  uous Training (C
-00002810: 5429 2072 6566 6572 7320 746f 2074 6865  T) refers to the
-00002820: 2070 6172 6164 6967 6d20 7768 6572 6520   paradigm where 
-00002830: 6120 7465 616d 2064 6570 6c6f 7973 2074  a team deploys t
-00002840: 7261 696e 696e 6720 7069 7065 6c69 6e65  raining pipeline
-00002850: 7320 0a74 6861 7420 7275 6e20 6175 746f  s .that run auto
-00002860: 6d61 7469 6361 6c6c 7920 746f 2074 7261  matically to tra
-00002870: 696e 206d 6f64 656c 7320 6f6e 206e 6577  in models on new
-00002880: 2028 6672 6573 6829 2064 6174 612e 2043   (fresh) data. C
-00002890: 6f6e 7469 6e75 6f75 7320 4465 706c 6f79  ontinuous Deploy
-000028a0: 6d65 6e74 2028 4344 2920 0a72 6566 6572  ment (CD) .refer
-000028b0: 7320 746f 2074 6865 2070 6172 6164 6967  s to the paradig
-000028c0: 6d20 7768 6572 6520 6e65 776c 7920 7472  m where newly tr
-000028d0: 6169 6e65 6420 6d6f 6465 6c73 2061 7265  ained models are
-000028e0: 2061 7574 6f6d 6174 6963 616c 6c79 2064   automatically d
-000028f0: 6570 6c6f 7965 6420 746f 2061 2070 7265  eployed to a pre
-00002900: 6469 6374 696f 6e20 0a73 6572 7669 6365  diction .service
-00002910: 2f73 6572 7665 720a 0a5a 656e 4d4c 2065  /server..ZenML e
-00002920: 6e61 626c 6564 2043 542f 4344 2062 7920  nabled CT/CD by 
-00002930: 656e 6162 6c69 6e67 2074 6865 206d 6f64  enabling the mod
-00002940: 656c 2070 7265 7061 7261 7469 6f6e 2061  el preparation a
-00002950: 6e64 206d 6f64 656c 2074 7261 696e 696e  nd model trainin
-00002960: 6720 7769 7468 206d 6f64 656c 2064 6570  g with model dep
-00002970: 6c6f 796d 656e 742e 200a 5769 7468 2074  loyment. .With t
-00002980: 6865 2062 7569 6c74 2d69 6e20 6675 6e63  he built-in func
-00002990: 7469 6f6e 616c 6974 6965 7320 6c69 6b65  tionalities like
-000029a0: 2053 6368 6564 756c 6573 2c20 4d6f 6465   Schedules, Mode
-000029b0: 6c20 4465 706c 6f79 6572 7320 616e 6420  l Deployers and 
-000029c0: 5365 7276 6963 6573 2079 6f75 2063 616e  Services you can
-000029d0: 200a 6372 6561 7465 2065 6e64 2d74 6f2d   .create end-to-
-000029e0: 656e 6420 4d4c 2077 6f72 6b66 6c6f 7773  end ML workflows
-000029f0: 2077 6974 6820 436f 6e74 696e 756f 7573   with Continuous
-00002a00: 2054 7261 696e 696e 6720 616e 6420 4465   Training and De
-00002a10: 706c 6f79 6d65 6e74 2074 6861 7420 6465  ployment that de
-00002a20: 706c 6f79 7320 796f 7572 200a 6d6f 6465  ploys your .mode
-00002a30: 6c20 696e 2061 206c 6f63 616c 2065 6e76  l in a local env
-00002a40: 6972 6f6e 6d65 6e74 2077 6974 6820 4d4c  ironment with ML
-00002a50: 466c 6f77 2069 6e74 6567 7261 7469 6f6e  Flow integration
-00002a60: 206f 7220 6576 656e 2069 6e20 6120 7072   or even in a pr
-00002a70: 6f64 7563 7469 6f6e 2d67 7261 6465 2065  oduction-grade e
-00002a80: 6e76 6972 6f6e 6d65 6e74 200a 6c69 6b65  nvironment .like
-00002a90: 204b 7562 6572 6e65 7465 7320 7769 7468   Kubernetes with
-00002aa0: 206f 7572 2053 656c 646f 6e20 436f 7265   our Seldon Core
-00002ab0: 2069 6e74 6567 7261 7469 6f6e 2e20 596f   integration. Yo
-00002ac0: 7520 6361 6e20 616c 736f 206c 6973 7465  u can also liste
-00002ad0: 6420 7365 7276 6564 206d 6f64 656c 7320  d served models 
-00002ae0: 7769 7468 2074 6865 2043 4c49 3a0a 0a21  with the CLI:..!
-00002af0: 5b43 492f 4344 2f43 5420 696e 205a 656e  [CI/CD/CT in Zen
-00002b00: 4d4c 5d28 646f 6373 2f62 6f6f 6b2f 6173  ML](docs/book/as
-00002b10: 7365 7473 2f63 745f 6364 5f7a 656e 6d6c  sets/ct_cd_zenml
-00002b20: 2e67 6966 290a 0a60 6060 0a7a 656e 6d6c  .gif)..```.zenml
-00002b30: 2073 6572 7665 642d 6d6f 6465 6c73 206c   served-models l
-00002b40: 6973 740a 6060 600a 0a52 6561 6420 6d6f  ist.```..Read mo
-00002b50: 7265 2061 626f 7574 2043 542f 4344 2069  re about CT/CD i
-00002b60: 6e20 5a65 6e4d 4c20 5b68 6572 655d 2868  n ZenML [here](h
-00002b70: 7474 7073 3a2f 2f62 6c6f 672e 7a65 6e6d  ttps://blog.zenm
-00002b80: 6c2e 696f 2f63 692d 6374 2d63 642d 7769  l.io/ci-ct-cd-wi
-00002b90: 7468 2d7a 656e 6d6c 2f29 2e0a 0a23 20f0  th-zenml/)...# .
-00002ba0: 9fa4 b820 4765 7474 696e 6720 5374 6172  ... Getting Star
-00002bb0: 7465 640a 0a23 2320 f09f 92be 2049 6e73  ted..## .... Ins
-00002bc0: 7461 6c6c 205a 656e 4d4c 0a0a 2a52 6571  tall ZenML..*Req
-00002bd0: 7569 7265 6d65 6e74 732a 3a20 5a65 6e4d  uirements*: ZenM
-00002be0: 4c20 7375 7070 6f72 7473 2050 7974 686f  L supports Pytho
-00002bf0: 6e20 332e 3720 616e 6420 332e 382e 0a0a  n 3.7 and 3.8...
-00002c00: 5a65 6e4d 4c20 6973 2061 7661 696c 6162  ZenML is availab
-00002c10: 6c65 2066 6f72 2065 6173 7920 696e 7374  le for easy inst
-00002c20: 616c 6c61 7469 6f6e 2069 6e74 6f20 796f  allation into yo
-00002c30: 7572 2065 6e76 6972 6f6e 6d65 6e74 2076  ur environment v
-00002c40: 6961 2050 7950 493a 0a0a 6060 6062 6173  ia PyPI:..```bas
-00002c50: 680a 7069 7020 696e 7374 616c 6c20 7a65  h.pip install ze
-00002c60: 6e6d 6c0a 6060 600a 0a41 6c74 6572 6e61  nml.```..Alterna
-00002c70: 7469 7665 6c79 2c20 6966 2079 6f75 e280  tively, if you..
-00002c80: 9972 6520 6665 656c 696e 6720 6272 6176  .re feeling brav
-00002c90: 652c 2066 6565 6c20 6672 6565 2074 6f20  e, feel free to 
-00002ca0: 696e 7374 616c 6c20 7468 6520 626c 6565  install the blee
-00002cb0: 6469 6e67 2065 6467 653a 0a2a 2a4e 4f54  ding edge:.**NOT
-00002cc0: 453a 2a2a 2044 6f20 736f 206f 6e20 796f  E:** Do so on yo
-00002cd0: 7572 206f 776e 2072 6973 6b2c 206e 6f20  ur own risk, no 
-00002ce0: 6775 6172 616e 7465 6573 2067 6976 656e  guarantees given
-00002cf0: 210a 0a60 6060 6261 7368 0a70 6970 2069  !..```bash.pip i
-00002d00: 6e73 7461 6c6c 2067 6974 2b68 7474 7073  nstall git+https
-00002d10: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
-00002d20: 6e6d 6c2d 696f 2f7a 656e 6d6c 2e67 6974  nml-io/zenml.git
-00002d30: 406d 6169 6e20 2d2d 7570 6772 6164 650a  @main --upgrade.
-00002d40: 6060 600a 0a5a 656e 4d4c 2069 7320 616c  ```..ZenML is al
-00002d50: 736f 2061 7661 696c 6162 6c65 2061 7320  so available as 
-00002d60: 6120 446f 636b 6572 2069 6d61 6765 2068  a Docker image h
-00002d70: 6f73 7465 6420 7075 626c 6963 6c79 206f  osted publicly o
-00002d80: 6e0a 5b44 6f63 6b65 7248 7562 5d28 6874  n.[DockerHub](ht
-00002d90: 7470 733a 2f2f 6875 622e 646f 636b 6572  tps://hub.docker
-00002da0: 2e63 6f6d 2f72 2f7a 656e 6d6c 646f 636b  .com/r/zenmldock
-00002db0: 6572 2f7a 656e 6d6c 292e 2055 7365 2074  er/zenml). Use t
-00002dc0: 6865 2066 6f6c 6c6f 7769 6e67 0a63 6f6d  he following.com
-00002dd0: 6d61 6e64 2074 6f20 6765 7420 7374 6172  mand to get star
-00002de0: 7465 6420 696e 2061 2062 6173 6820 656e  ted in a bash en
-00002df0: 7669 726f 6e6d 656e 743a 0a0a 6060 6073  vironment:..```s
-00002e00: 6865 6c6c 0a64 6f63 6b65 7220 7275 6e20  hell.docker run 
-00002e10: 2d69 7420 7a65 6e6d 6c64 6f63 6b65 722f  -it zenmldocker/
-00002e20: 7a65 6e6d 6c20 2f62 696e 2f62 6173 680a  zenml /bin/bash.
-00002e30: 6060 600a 0a23 2320 f09f 9a85 2051 7569  ```..## .... Qui
-00002e40: 636b 7374 6172 740a 0a54 6865 2071 7569  ckstart..The qui
-00002e50: 636b 6573 7420 7761 7920 746f 2067 6574  ckest way to get
-00002e60: 2073 7461 7274 6564 2069 7320 746f 2063   started is to c
-00002e70: 7265 6174 6520 6120 7369 6d70 6c65 2070  reate a simple p
-00002e80: 6970 656c 696e 652e 0a0a 2323 2323 2053  ipeline...#### S
-00002e90: 7465 7020 313a 2049 6e69 7469 616c 697a  tep 1: Initializ
-00002ea0: 6520 6120 5a65 6e4d 4c20 7265 706f 0a0a  e a ZenML repo..
-00002eb0: 6060 6062 6173 680a 7a65 6e6d 6c20 696e  ```bash.zenml in
-00002ec0: 6974 0a7a 656e 6d6c 2069 6e74 6567 7261  it.zenml integra
-00002ed0: 7469 6f6e 2069 6e73 7461 6c6c 2073 6b6c  tion install skl
-00002ee0: 6561 726e 202d 7920 2320 7765 2075 7365  earn -y # we use
-00002ef0: 2073 6369 6b69 742d 6c65 6172 6e20 666f   scikit-learn fo
-00002f00: 7220 7468 6973 2065 7861 6d70 6c65 0a60  r this example.`
-00002f10: 6060 0a0a 2323 2323 2053 7465 7020 323a  ``..#### Step 2:
-00002f20: 2041 7373 656d 626c 652c 2072 756e 2c20   Assemble, run, 
-00002f30: 616e 6420 6576 616c 7561 7465 2079 6f75  and evaluate you
-00002f40: 7220 7069 7065 6c69 6e65 206c 6f63 616c  r pipeline local
-00002f50: 6c79 0a0a 6060 6070 7974 686f 6e0a 696d  ly..```python.im
-00002f60: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
-00002f70: 0a66 726f 6d20 736b 6c65 6172 6e2e 6261  .from sklearn.ba
-00002f80: 7365 2069 6d70 6f72 7420 436c 6173 7369  se import Classi
-00002f90: 6669 6572 4d69 7869 6e0a 0a66 726f 6d20  fierMixin..from 
-00002fa0: 7a65 6e6d 6c2e 696e 7465 6772 6174 696f  zenml.integratio
-00002fb0: 6e73 2e73 6b6c 6561 726e 2e68 656c 7065  ns.sklearn.helpe
-00002fc0: 7273 2e64 6967 6974 7320 696d 706f 7274  rs.digits import
-00002fd0: 2067 6574 5f64 6967 6974 732c 2067 6574   get_digits, get
-00002fe0: 5f64 6967 6974 735f 6d6f 6465 6c0a 6672  _digits_model.fr
-00002ff0: 6f6d 207a 656e 6d6c 2e70 6970 656c 696e  om zenml.pipelin
-00003000: 6573 2069 6d70 6f72 7420 7069 7065 6c69  es import pipeli
-00003010: 6e65 0a66 726f 6d20 7a65 6e6d 6c2e 7374  ne.from zenml.st
-00003020: 6570 7320 696d 706f 7274 2073 7465 702c  eps import step,
-00003030: 204f 7574 7075 740a 0a40 7374 6570 0a64   Output..@step.d
-00003040: 6566 2069 6d70 6f72 7465 7228 2920 2d3e  ef importer() ->
-00003050: 204f 7574 7075 7428 0a20 2020 2058 5f74   Output(.    X_t
-00003060: 7261 696e 3d6e 702e 6e64 6172 7261 792c  rain=np.ndarray,
-00003070: 2058 5f74 6573 743d 6e70 2e6e 6461 7272   X_test=np.ndarr
-00003080: 6179 2c20 795f 7472 6169 6e3d 6e70 2e6e  ay, y_train=np.n
-00003090: 6461 7272 6179 2c20 795f 7465 7374 3d6e  darray, y_test=n
-000030a0: 702e 6e64 6172 7261 790a 293a 0a20 2020  p.ndarray.):.   
-000030b0: 2022 2222 4c6f 6164 7320 7468 6520 6469   """Loads the di
-000030c0: 6769 7473 2061 7272 6179 2061 7320 6e6f  gits array as no
-000030d0: 726d 616c 206e 756d 7079 2061 7272 6179  rmal numpy array
-000030e0: 732e 2222 220a 2020 2020 585f 7472 6169  s.""".    X_trai
-000030f0: 6e2c 2058 5f74 6573 742c 2079 5f74 7261  n, X_test, y_tra
-00003100: 696e 2c20 795f 7465 7374 203d 2067 6574  in, y_test = get
-00003110: 5f64 6967 6974 7328 290a 2020 2020 7265  _digits().    re
-00003120: 7475 726e 2058 5f74 7261 696e 2c20 585f  turn X_train, X_
-00003130: 7465 7374 2c20 795f 7472 6169 6e2c 2079  test, y_train, y
-00003140: 5f74 6573 740a 0a0a 4073 7465 700a 6465  _test...@step.de
-00003150: 6620 7472 6169 6e65 7228 0a20 2020 2058  f trainer(.    X
-00003160: 5f74 7261 696e 3a20 6e70 2e6e 6461 7272  _train: np.ndarr
-00003170: 6179 2c0a 2020 2020 795f 7472 6169 6e3a  ay,.    y_train:
-00003180: 206e 702e 6e64 6172 7261 792c 0a29 202d   np.ndarray,.) -
-00003190: 3e20 436c 6173 7369 6669 6572 4d69 7869  > ClassifierMixi
-000031a0: 6e3a 0a20 2020 2022 2222 5472 6169 6e20  n:.    """Train 
-000031b0: 6120 7369 6d70 6c65 2073 6b6c 6561 726e  a simple sklearn
-000031c0: 2063 6c61 7373 6966 6965 7220 666f 7220   classifier for 
-000031d0: 7468 6520 6469 6769 7473 2064 6174 6173  the digits datas
-000031e0: 6574 2e22 2222 0a20 2020 206d 6f64 656c  et.""".    model
-000031f0: 203d 2067 6574 5f64 6967 6974 735f 6d6f   = get_digits_mo
-00003200: 6465 6c28 290a 2020 2020 6d6f 6465 6c2e  del().    model.
-00003210: 6669 7428 585f 7472 6169 6e2c 2079 5f74  fit(X_train, y_t
-00003220: 7261 696e 290a 2020 2020 7265 7475 726e  rain).    return
-00003230: 206d 6f64 656c 0a0a 0a40 7374 6570 0a64   model...@step.d
-00003240: 6566 2065 7661 6c75 6174 6f72 280a 2020  ef evaluator(.  
-00003250: 2020 585f 7465 7374 3a20 6e70 2e6e 6461    X_test: np.nda
-00003260: 7272 6179 2c0a 2020 2020 795f 7465 7374  rray,.    y_test
-00003270: 3a20 6e70 2e6e 6461 7272 6179 2c0a 2020  : np.ndarray,.  
-00003280: 2020 6d6f 6465 6c3a 2043 6c61 7373 6966    model: Classif
-00003290: 6965 724d 6978 696e 2c0a 2920 2d3e 2066  ierMixin,.) -> f
-000032a0: 6c6f 6174 3a0a 2020 2020 2222 2243 616c  loat:.    """Cal
-000032b0: 6375 6c61 7465 2074 6865 2061 6363 7572  culate the accur
-000032c0: 6163 7920 6f6e 2074 6865 2074 6573 7420  acy on the test 
-000032d0: 7365 7422 2222 0a20 2020 2074 6573 745f  set""".    test_
-000032e0: 6163 6320 3d20 6d6f 6465 6c2e 7363 6f72  acc = model.scor
-000032f0: 6528 585f 7465 7374 2c20 795f 7465 7374  e(X_test, y_test
-00003300: 290a 2020 2020 7072 696e 7428 6622 5465  ).    print(f"Te
-00003310: 7374 2061 6363 7572 6163 793a 207b 7465  st accuracy: {te
-00003320: 7374 5f61 6363 7d22 290a 2020 2020 7265  st_acc}").    re
-00003330: 7475 726e 2074 6573 745f 6163 630a 0a0a  turn test_acc...
-00003340: 4070 6970 656c 696e 650a 6465 6620 6d6e  @pipeline.def mn
-00003350: 6973 745f 7069 7065 6c69 6e65 280a 2020  ist_pipeline(.  
-00003360: 2020 696d 706f 7274 6572 2c0a 2020 2020    importer,.    
-00003370: 7472 6169 6e65 722c 0a20 2020 2065 7661  trainer,.    eva
-00003380: 6c75 6174 6f72 2c0a 293a 0a20 2020 2022  luator,.):.    "
-00003390: 2222 4c69 6e6b 7320 616c 6c20 7468 6520  ""Links all the 
-000033a0: 7374 6570 7320 746f 6765 7468 6572 2069  steps together i
-000033b0: 6e20 6120 7069 7065 6c69 6e65 2222 220a  n a pipeline""".
-000033c0: 2020 2020 585f 7472 6169 6e2c 2058 5f74      X_train, X_t
-000033d0: 6573 742c 2079 5f74 7261 696e 2c20 795f  est, y_train, y_
-000033e0: 7465 7374 203d 2069 6d70 6f72 7465 7228  test = importer(
-000033f0: 290a 2020 2020 6d6f 6465 6c20 3d20 7472  ).    model = tr
-00003400: 6169 6e65 7228 585f 7472 6169 6e3d 585f  ainer(X_train=X_
-00003410: 7472 6169 6e2c 2079 5f74 7261 696e 3d79  train, y_train=y
-00003420: 5f74 7261 696e 290a 2020 2020 6576 616c  _train).    eval
-00003430: 7561 746f 7228 585f 7465 7374 3d58 5f74  uator(X_test=X_t
-00003440: 6573 742c 2079 5f74 6573 743d 795f 7465  est, y_test=y_te
-00003450: 7374 2c20 6d6f 6465 6c3d 6d6f 6465 6c29  st, model=model)
-00003460: 0a0a 0a70 6970 656c 696e 6520 3d20 6d6e  ...pipeline = mn
-00003470: 6973 745f 7069 7065 6c69 6e65 280a 2020  ist_pipeline(.  
-00003480: 2020 696d 706f 7274 6572 3d69 6d70 6f72    importer=impor
-00003490: 7465 7228 292c 0a20 2020 2074 7261 696e  ter(),.    train
-000034a0: 6572 3d74 7261 696e 6572 2829 2c0a 2020  er=trainer(),.  
-000034b0: 2020 6576 616c 7561 746f 723d 6576 616c    evaluator=eval
-000034c0: 7561 746f 7228 292c 0a29 0a70 6970 656c  uator(),.).pipel
-000034d0: 696e 652e 7275 6e28 290a 6060 600a 0a23  ine.run().```..#
-000034e0: 203a 7261 6365 686f 7273 653a 2047 6574   :racehorse: Get
-000034f0: 2061 2067 7569 6465 6420 746f 7572 2077   a guided tour w
-00003500: 6974 6820 607a 656e 6d6c 2067 6f60 0a0a  ith `zenml go`..
-00003510: 466f 7220 6120 736c 6967 6874 6c79 206d  For a slightly m
-00003520: 6f72 6520 696e 2d64 6570 7468 2069 6e74  ore in-depth int
-00003530: 726f 6475 6374 696f 6e20 746f 205a 656e  roduction to Zen
-00003540: 4d4c 2c20 7461 7567 6874 2074 6872 6f75  ML, taught throu
-00003550: 6768 204a 7570 7974 6572 0a6e 6f74 6562  gh Jupyter.noteb
-00003560: 6f6f 6b73 2c20 696e 7374 616c 6c20 607a  ooks, install `z
-00003570: 656e 6d6c 6020 7669 6120 7069 7020 6173  enml` via pip as
-00003580: 2064 6573 6372 6962 6564 2061 626f 7665   described above
-00003590: 2061 6e64 2074 7970 653a 0a0a 6060 6073   and type:..```s
-000035a0: 6865 6c6c 0a7a 656e 6d6c 2067 6f0a 6060  hell.zenml go.``
-000035b0: 600a 0a54 6869 7320 7769 6c6c 2073 7069  `..This will spi
-000035c0: 6e20 7570 2061 204a 7570 7974 6572 206e  n up a Jupyter n
-000035d0: 6f74 6562 6f6f 6b20 7468 6174 2073 686f  otebook that sho
-000035e0: 7763 6173 6573 2074 6865 2061 626f 7665  wcases the above
-000035f0: 2065 7861 6d70 6c65 2070 6c75 7320 6d6f   example plus mo
-00003600: 7265 0a6f 6e20 686f 7720 746f 2075 7365  re.on how to use
-00003610: 2061 6e64 2065 7874 656e 6420 5a65 6e4d   and extend ZenM
-00003620: 4c2e 0a0a 2320 f09f 91ad 2043 6f6c 6c61  L...# .... Colla
-00003630: 626f 7261 7465 2077 6974 6820 796f 7572  borate with your
-00003640: 2074 6561 6d0a 0a5a 656e 4d4c 2069 7320   team..ZenML is 
-00003650: 6275 696c 7420 746f 2073 7570 706f 7274  built to support
-00003660: 2074 6561 6d73 2077 6f72 6b69 6e67 2074   teams working t
-00003670: 6f67 6574 6865 722e 2054 6865 2075 6e64  ogether. The und
-00003680: 6572 6c79 696e 6720 696e 6672 6173 7472  erlying infrastr
-00003690: 7563 7475 7265 0a6f 6e20 7768 6963 6820  ucture.on which 
-000036a0: 796f 7572 204d 4c20 776f 726b 666c 6f77  your ML workflow
-000036b0: 7320 7275 6e20 6361 6e20 6265 2073 6861  s run can be sha
-000036c0: 7265 642c 2061 7320 6361 6e20 7468 6520  red, as can the 
-000036d0: 6461 7461 2c20 6173 7365 7473 2061 6e64  data, assets and
-000036e0: 0a61 7274 6966 6163 7473 2074 6861 7420  .artifacts that 
-000036f0: 796f 7520 6e65 6564 2074 6f20 656e 6162  you need to enab
-00003700: 6c65 2079 6f75 7220 776f 726b 2e20 5a65  le your work. Ze
-00003710: 6e4d 4c20 5072 6f66 696c 6573 206f 6666  nML Profiles off
-00003720: 6572 2061 6e20 6561 7379 2077 6179 2074  er an easy way t
-00003730: 6f0a 6d61 6e61 6765 2061 6e64 2073 7769  o.manage and swi
-00003740: 7463 6820 6265 7477 6565 6e20 796f 7572  tch between your
-00003750: 2073 7461 636b 732e 2054 6865 205a 656e   stacks. The Zen
-00003760: 4d4c 2053 6572 7665 7220 6861 6e64 6c65  ML Server handle
-00003770: 7320 616c 6c20 7468 650a 696e 7465 7261  s all the.intera
-00003780: 6374 696f 6e20 616e 6420 7368 6172 696e  ction and sharin
-00003790: 6720 616e 6420 796f 7520 6361 6e20 686f  g and you can ho
-000037a0: 7374 2069 7420 7768 6572 6576 6572 2079  st it wherever y
-000037b0: 6f75 2764 206c 696b 652e 0a0a 6060 600a  ou'd like...```.
-000037c0: 7a65 6e6d 6c20 7365 7276 6572 2075 700a  zenml server up.
-000037d0: 6060 600a 0a52 6561 6420 6d6f 7265 2061  ```..Read more a
-000037e0: 626f 7574 2063 6f6c 6c61 626f 7261 7469  bout collaborati
-000037f0: 6f6e 2069 6e20 5a65 6e4d 4c20 5b68 6572  on in ZenML [her
-00003800: 655d 2868 7474 7073 3a2f 2f64 6f63 732e  e](https://docs.
-00003810: 7a65 6e6d 6c2e 696f 2f63 6f6c 6c61 626f  zenml.io/collabo
-00003820: 7261 7465 2f63 6f6c 6c61 626f 7261 7465  rate/collaborate
-00003830: 292e 0a0a 2320 f09f 8db0 205a 656e 4279  )...# .... ZenBy
-00003840: 7465 730a 0a5b 5a65 6e42 7974 6573 5d28  tes..[ZenBytes](
-00003850: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-00003860: 6f6d 2f7a 656e 6d6c 2d69 6f2f 7a65 6e62  om/zenml-io/zenb
-00003870: 7974 6573 2920 6973 2061 2073 6572 6965  ytes) is a serie
-00003880: 7320 6f66 2073 686f 7274 2070 7261 6374  s of short pract
-00003890: 6963 616c 0a4d 4c4f 7073 206c 6573 736f  ical.MLOps lesso
-000038a0: 6e73 2074 6872 6f75 6768 205a 656e 4d4c  ns through ZenML
-000038b0: 2061 6e64 2069 7473 2076 6172 696f 7573   and its various
-000038c0: 2069 6e74 6567 7261 7469 6f6e 732e 2049   integrations. I
-000038d0: 7420 6973 2069 6e74 656e 6465 6420 666f  t is intended fo
-000038e0: 720a 7065 6f70 6c65 206c 6f6f 6b69 6e67  r.people looking
-000038f0: 2074 6f20 6c65 6172 6e20 6162 6f75 7420   to learn about 
-00003900: 4d4c 4f70 7320 6765 6e65 7261 6c6c 792c  MLOps generally,
-00003910: 2061 6e64 2061 6c73 6f20 666f 7220 4d4c   and also for ML
-00003920: 2070 7261 6374 6974 696f 6e65 7273 2077   practitioners w
-00003930: 686f 0a77 616e 7420 746f 2067 6574 2073  ho.want to get s
-00003940: 7461 7274 6564 2077 6974 6820 5a65 6e4d  tarted with ZenM
-00003950: 4c2e 0a0a 4166 7465 7220 796f 7527 7665  L...After you've
-00003960: 2072 756e 2061 6e64 2075 6e64 6572 7374   run and underst
-00003970: 6f6f 6420 7468 6520 7369 6d70 6c65 2065  ood the simple e
-00003980: 7861 6d70 6c65 2061 626f 7665 2c20 796f  xample above, yo
-00003990: 7572 206e 6578 7420 706f 7274 206f 6620  ur next port of 
-000039a0: 6361 6c6c 0a69 7320 7072 6f62 6162 6c79  call.is probably
-000039b0: 2065 6974 6865 7220 7468 6520 5b66 756c   either the [ful
-000039c0: 6c79 2d66 6c65 7368 6564 2d6f 7574 2071  ly-fleshed-out q
-000039d0: 7569 636b 7374 6172 740a 6578 616d 706c  uickstart.exampl
-000039e0: 655d 2868 7474 7073 3a2f 2f67 6974 6875  e](https://githu
-000039f0: 622e 636f 6d2f 7a65 6e6d 6c2d 696f 2f7a  b.com/zenml-io/z
-00003a00: 656e 6d6c 2f74 7265 652f 6d61 696e 2f65  enml/tree/main/e
-00003a10: 7861 6d70 6c65 732f 7175 6963 6b73 7461  xamples/quicksta
-00003a20: 7274 2920 616e 640a 7468 656e 2074 6f20  rt) and.then to 
-00003a30: 6c6f 6f6b 2061 7420 5b74 6865 205a 656e  look at [the Zen
-00003a40: 4279 7465 7320 7265 706f 7369 746f 7279  Bytes repository
-00003a50: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
-00003a60: 2e63 6f6d 2f7a 656e 6d6c 2d69 6f2f 7a65  .com/zenml-io/ze
-00003a70: 6e62 7974 6573 290a 616e 6420 6e6f 7465  nbytes).and note
-00003a80: 626f 6f6b 732e 0a0a 2320 f09f 9782 efb8  books...# ......
-00003a90: 8f20 5a65 6e46 696c 6573 0a0a 5a65 6e46  . ZenFiles..ZenF
-00003aa0: 696c 6573 2061 7265 2070 726f 6475 6374  iles are product
-00003ab0: 696f 6e2d 6772 6164 6520 4d4c 2075 7365  ion-grade ML use
-00003ac0: 2d63 6173 6573 2070 6f77 6572 6564 2062  -cases powered b
-00003ad0: 7920 5a65 6e4d 4c2e 2054 6865 7920 6172  y ZenML. They ar
-00003ae0: 6520 6675 6c6c 790a 666c 6573 6865 6420  e fully.fleshed 
-00003af0: 6f75 742c 2065 6e64 2d74 6f2d 656e 642c  out, end-to-end,
-00003b00: 2070 726f 6a65 6374 7320 7468 6174 2073   projects that s
-00003b10: 686f 7763 6173 6520 5a65 6e4d 4c27 7320  howcase ZenML's 
-00003b20: 6361 7061 6269 6c69 7469 6573 2e20 5468  capabilities. Th
-00003b30: 6579 2063 616e 0a61 6c73 6f20 7365 7276  ey can.also serv
-00003b40: 6520 6173 2061 2074 656d 706c 6174 6520  e as a template 
-00003b50: 6672 6f6d 2077 6869 6368 2074 6f20 7374  from which to st
-00003b60: 6172 7420 7369 6d69 6c61 7220 7072 6f6a  art similar proj
-00003b70: 6563 7473 2e0a 0a54 6865 205a 656e 4669  ects...The ZenFi
-00003b80: 6c65 7320 7072 6f6a 6563 7420 6973 2066  les project is f
-00003b90: 756c 6c79 206d 6169 6e74 6169 6e65 6420  ully maintained 
-00003ba0: 616e 6420 6361 6e20 6265 2076 6965 7765  and can be viewe
-00003bb0: 6420 6173 2061 2073 6973 7465 720a 7265  d as a sister.re
-00003bc0: 706f 7369 746f 7279 206f 6620 5a65 6e4d  pository of ZenM
-00003bd0: 4c2e 2043 6865 636b 2069 7420 6f75 7420  L. Check it out 
-00003be0: 5b68 6572 655d 2868 7474 7073 3a2f 2f67  [here](https://g
-00003bf0: 6974 6875 622e 636f 6d2f 7a65 6e6d 6c2d  ithub.com/zenml-
-00003c00: 696f 2f7a 656e 6669 6c65 7329 2e0a 0a23  io/zenfiles)...#
-00003c10: 20f0 9f97 ba20 526f 6164 6d61 700a 0a5a   .... Roadmap..Z
-00003c20: 656e 4d4c 2069 7320 6265 696e 6720 6275  enML is being bu
-00003c30: 696c 7420 696e 2070 7562 6c69 632e 2054  ilt in public. T
-00003c40: 6865 205b 726f 6164 6d61 705d 2868 7474  he [roadmap](htt
-00003c50: 7073 3a2f 2f7a 656e 6d6c 2e69 6f2f 726f  ps://zenml.io/ro
-00003c60: 6164 6d61 7029 2069 7320 610a 7265 6775  admap) is a.regu
-00003c70: 6c61 726c 7920 7570 6461 7465 6420 736f  larly updated so
-00003c80: 7572 6365 206f 6620 7472 7574 6820 666f  urce of truth fo
-00003c90: 7220 7468 6520 5a65 6e4d 4c20 636f 6d6d  r the ZenML comm
-00003ca0: 756e 6974 7920 746f 2075 6e64 6572 7374  unity to underst
-00003cb0: 616e 6420 7768 6572 650a 7468 6520 7072  and where.the pr
-00003cc0: 6f64 7563 7420 6973 2067 6f69 6e67 2069  oduct is going i
-00003cd0: 6e20 7468 6520 7368 6f72 742c 206d 6564  n the short, med
-00003ce0: 6975 6d2c 2061 6e64 206c 6f6e 6720 7465  ium, and long te
-00003cf0: 726d 2e0a 0a5a 656e 4d4c 2069 7320 6d61  rm...ZenML is ma
-00003d00: 6e61 6765 6420 6279 2061 205b 636f 7265  naged by a [core
-00003d10: 2074 6561 6d5d 2868 7474 7073 3a2f 2f7a   team](https://z
-00003d20: 656e 6d6c 2e69 6f2f 7465 616d 2920 6f66  enml.io/team) of
-00003d30: 2064 6576 656c 6f70 6572 7320 7468 6174   developers that
-00003d40: 2061 7265 0a72 6573 706f 6e73 6962 6c65   are.responsible
-00003d50: 2066 6f72 206d 616b 696e 6720 6b65 7920   for making key 
-00003d60: 6465 6369 7369 6f6e 7320 616e 6420 696e  decisions and in
-00003d70: 636f 7270 6f72 6174 696e 6720 6665 6564  corporating feed
-00003d80: 6261 636b 2066 726f 6d20 7468 650a 636f  back from the.co
-00003d90: 6d6d 756e 6974 792e 2054 6865 2074 6561  mmunity. The tea
-00003da0: 6d20 6f76 6572 7365 6573 2066 6565 6462  m oversees feedb
-00003db0: 6163 6b20 7669 6120 7661 7269 6f75 7320  ack via various 
-00003dc0: 6368 616e 6e65 6c73 2c20 616e 6420 796f  channels, and yo
-00003dd0: 7520 6361 6e20 6469 7265 6374 6c79 0a69  u can directly.i
-00003de0: 6e66 6c75 656e 6365 2074 6865 2072 6f61  nfluence the roa
-00003df0: 646d 6170 2061 7320 666f 6c6c 6f77 733a  dmap as follows:
-00003e00: 0a0a 2d20 566f 7465 206f 6e20 796f 7572  ..- Vote on your
-00003e10: 206d 6f73 7420 7761 6e74 6564 2066 6561   most wanted fea
-00003e20: 7475 7265 206f 6e20 6f75 7220 5b44 6973  ture on our [Dis
-00003e30: 6375 7373 696f 6e0a 2020 626f 6172 645d  cussion.  board]
-00003e40: 2868 7474 7073 3a2f 2f7a 656e 6d6c 2e69  (https://zenml.i
-00003e50: 6f2f 6469 7363 7573 7369 6f6e 292e 2059  o/discussion). Y
-00003e60: 6f75 2063 616e 2061 6c73 6f20 7265 7175  ou can also requ
-00003e70: 6573 7420 666f 7220 6e65 7720 6665 6174  est for new feat
-00003e80: 7572 6573 2068 6572 652e 0a2d 2053 7461  ures here..- Sta
-00003e90: 7274 2061 2074 6872 6561 6420 696e 206f  rt a thread in o
-00003ea0: 7572 205b 536c 6163 6b20 6368 616e 6e65  ur [Slack channe
-00003eb0: 6c5d 2868 7474 7073 3a2f 2f7a 656e 6d6c  l](https://zenml
-00003ec0: 2e69 6f2f 736c 6163 6b2d 696e 7669 7465  .io/slack-invite
-00003ed0: 292e 0a0a 2320 f09f 998b e280 8de2 9980  )...# ..........
-00003ee0: efb8 8f20 436f 6e74 7269 6275 7469 6e67  ... Contributing
-00003ef0: 2026 2043 6f6d 6d75 6e69 7479 0a0a 5765   & Community..We
-00003f00: 2077 6f75 6c64 206c 6f76 6520 746f 2064   would love to d
-00003f10: 6576 656c 6f70 205a 656e 4d4c 2074 6f67  evelop ZenML tog
-00003f20: 6574 6865 7220 7769 7468 206f 7572 2063  ether with our c
-00003f30: 6f6d 6d75 6e69 7479 2120 4265 7374 2077  ommunity! Best w
-00003f40: 6179 2074 6f20 6765 740a 7374 6172 7465  ay to get.starte
-00003f50: 6420 6973 2074 6f20 7365 6c65 6374 2061  d is to select a
-00003f60: 6e79 2069 7373 7565 2066 726f 6d20 7468  ny issue from th
-00003f70: 6520 5b60 676f 6f64 2d66 6972 7374 2d69  e [`good-first-i
-00003f80: 7373 7565 600a 6c61 6265 6c5d 2868 7474  ssue`.label](htt
-00003f90: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00003fa0: 7a65 6e6d 6c2d 696f 2f7a 656e 6d6c 2f6c  zenml-io/zenml/l
-00003fb0: 6162 656c 732f 676f 6f64 2532 3066 6972  abels/good%20fir
-00003fc0: 7374 2532 3069 7373 7565 292e 2049 6620  st%20issue). If 
-00003fd0: 796f 750a 776f 756c 6420 6c69 6b65 2074  you.would like t
-00003fe0: 6f20 636f 6e74 7269 6275 7465 2c20 706c  o contribute, pl
-00003ff0: 6561 7365 2072 6576 6965 7720 6f75 7220  ease review our 
-00004000: 5b43 6f6e 7472 6962 7574 696e 670a 4775  [Contributing.Gu
-00004010: 6964 655d 2843 4f4e 5452 4942 5554 494e  ide](CONTRIBUTIN
-00004020: 472e 6d64 2920 666f 7220 616c 6c20 7265  G.md) for all re
-00004030: 6c65 7661 6e74 2064 6574 6169 6c73 2e0a  levant details..
-00004040: 0a3c 6272 3e0a 0a21 5b52 6570 6f62 6561  .<br>..![Repobea
-00004050: 7473 2061 6e61 6c79 7469 6373 0a69 6d61  ts analytics.ima
-00004060: 6765 5d28 6874 7470 733a 2f2f 7265 706f  ge](https://repo
-00004070: 6265 6174 732e 6178 696f 6d2e 636f 2f61  beats.axiom.co/a
-00004080: 7069 2f65 6d62 6564 2f36 3335 6335 3762  pi/embed/635c57b
-00004090: 3734 3365 6665 3634 3963 6164 6365 6261  743efe649cadceba
-000040a0: 3661 3265 3661 3935 3636 3633 6639 3664  6a2e6a956663f96d
-000040b0: 642e 7376 670a 2252 6570 6f62 6561 7473  d.svg."Repobeats
-000040c0: 2061 6e61 6c79 7469 6373 2069 6d61 6765   analytics image
-000040d0: 2229 0a0a 0a23 20f0 9f86 9820 5768 6572  ")...# .... Wher
-000040e0: 6520 746f 2067 6574 2068 656c 700a 0a46  e to get help..F
-000040f0: 6972 7374 2070 6f69 6e74 206f 6620 6361  irst point of ca
-00004100: 6c6c 2073 686f 756c 6420 6265 205b 6f75  ll should be [ou
-00004110: 7220 536c 6163 6b20 6772 6f75 705d 2868  r Slack group](h
-00004120: 7474 7073 3a2f 2f7a 656e 6d6c 2e69 6f2f  ttps://zenml.io/
-00004130: 736c 6163 6b2d 696e 7669 7465 2f29 2e0a  slack-invite/)..
-00004140: 4173 6b20 796f 7572 2071 7565 7374 696f  Ask your questio
-00004150: 6e73 2061 626f 7574 2062 7567 7320 6f72  ns about bugs or
-00004160: 2073 7065 6369 6669 6320 7573 6520 6361   specific use ca
-00004170: 7365 7320 616e 6420 736f 6d65 6f6e 6520  ses and someone 
-00004180: 6672 6f6d 2074 6865 2063 6f72 650a 7465  from the core.te
-00004190: 616d 2077 696c 6c20 7265 7370 6f6e 642e  am will respond.
-000041a0: 0a0a 2320 f09f 939c 204c 6963 656e 7365  ..# .... License
-000041b0: 0a0a 5a65 6e4d 4c20 6973 2064 6973 7472  ..ZenML is distr
-000041c0: 6962 7574 6564 2075 6e64 6572 2074 6865  ibuted under the
-000041d0: 2074 6572 6d73 206f 6620 7468 6520 4170   terms of the Ap
-000041e0: 6163 6865 204c 6963 656e 7365 2056 6572  ache License Ver
-000041f0: 7369 6f6e 2032 2e30 2e20 410a 636f 6d70  sion 2.0. A.comp
-00004200: 6c65 7465 2076 6572 7369 6f6e 206f 6620  lete version of 
-00004210: 7468 6520 6c69 6365 6e73 6520 6973 2061  the license is a
-00004220: 7661 696c 6162 6c65 2069 6e20 7468 6520  vailable in the 
-00004230: 5b4c 4943 454e 5345 2e6d 645d 284c 4943  [LICENSE.md](LIC
-00004240: 454e 5345 2e6d 6429 2069 6e0a 7468 6973  ENSE.md) in.this
-00004250: 2072 6570 6f73 6974 6f72 792e 2041 6e79   repository. Any
-00004260: 2063 6f6e 7472 6962 7574 696f 6e20 6d61   contribution ma
-00004270: 6465 2074 6f20 7468 6973 2070 726f 6a65  de to this proje
-00004280: 6374 2077 696c 6c20 6265 206c 6963 656e  ct will be licen
-00004290: 7365 6420 756e 6465 720a 7468 6520 4170  sed under.the Ap
-000042a0: 6163 6865 204c 6963 656e 7365 2056 6572  ache License Ver
-000042b0: 7369 6f6e 2032 2e30 2e0a 0a              sion 2.0...
+00000020: 6c0a 5665 7273 696f 6e3a 2030 2e39 2e30  l.Version: 0.9.0
+00000030: 0a53 756d 6d61 7279 3a20 5a65 6e4d 4c3a  .Summary: ZenML:
+00000040: 2057 7269 7465 2070 726f 6475 6374 696f   Write productio
+00000050: 6e2d 7265 6164 7920 4d4c 2063 6f64 652e  n-ready ML code.
+00000060: 0a48 6f6d 652d 7061 6765 3a20 6874 7470  .Home-page: http
+00000070: 733a 2f2f 7a65 6e6d 6c2e 696f 0a4c 6963  s://zenml.io.Lic
+00000080: 656e 7365 3a20 4170 6163 6865 2d32 2e30  ense: Apache-2.0
+00000090: 0a4b 6579 776f 7264 733a 206d 6163 6869  .Keywords: machi
+000000a0: 6e65 206c 6561 726e 696e 672c 7072 6f64  ne learning,prod
+000000b0: 7563 7469 6f6e 2c70 6970 656c 696e 652c  uction,pipeline,
+000000c0: 6d6c 6f70 732c 6465 766f 7073 0a41 7574  mlops,devops.Aut
+000000d0: 686f 723a 205a 656e 4d4c 2047 6d62 480a  hor: ZenML GmbH.
+000000e0: 4175 7468 6f72 2d65 6d61 696c 3a20 696e  Author-email: in
+000000f0: 666f 407a 656e 6d6c 2e69 6f0a 5265 7175  fo@zenml.io.Requ
+00000100: 6972 6573 2d50 7974 686f 6e3a 203e 3d33  ires-Python: >=3
+00000110: 2e37 2e31 2c3c 332e 3130 0a43 6c61 7373  .7.1,<3.10.Class
+00000120: 6966 6965 723a 2044 6576 656c 6f70 6d65  ifier: Developme
+00000130: 6e74 2053 7461 7475 7320 3a3a 2034 202d  nt Status :: 4 -
+00000140: 2042 6574 610a 436c 6173 7369 6669 6572   Beta.Classifier
+00000150: 3a20 496e 7465 6e64 6564 2041 7564 6965  : Intended Audie
+00000160: 6e63 6520 3a3a 2044 6576 656c 6f70 6572  nce :: Developer
+00000170: 730a 436c 6173 7369 6669 6572 3a20 496e  s.Classifier: In
+00000180: 7465 6e64 6564 2041 7564 6965 6e63 6520  tended Audience 
+00000190: 3a3a 2053 6369 656e 6365 2f52 6573 6561  :: Science/Resea
+000001a0: 7263 680a 436c 6173 7369 6669 6572 3a20  rch.Classifier: 
+000001b0: 496e 7465 6e64 6564 2041 7564 6965 6e63  Intended Audienc
+000001c0: 6520 3a3a 2053 7973 7465 6d20 4164 6d69  e :: System Admi
+000001d0: 6e69 7374 7261 746f 7273 0a43 6c61 7373  nistrators.Class
+000001e0: 6966 6965 723a 204c 6963 656e 7365 203a  ifier: License :
+000001f0: 3a20 4f53 4920 4170 7072 6f76 6564 203a  : OSI Approved :
+00000200: 3a20 4170 6163 6865 2053 6f66 7477 6172  : Apache Softwar
+00000210: 6520 4c69 6365 6e73 650a 436c 6173 7369  e License.Classi
+00000220: 6669 6572 3a20 5072 6f67 7261 6d6d 696e  fier: Programmin
+00000230: 6720 4c61 6e67 7561 6765 203a 3a20 5079  g Language :: Py
+00000240: 7468 6f6e 203a 3a20 330a 436c 6173 7369  thon :: 3.Classi
+00000250: 6669 6572 3a20 5072 6f67 7261 6d6d 696e  fier: Programmin
+00000260: 6720 4c61 6e67 7561 6765 203a 3a20 5079  g Language :: Py
+00000270: 7468 6f6e 203a 3a20 3320 3a3a 204f 6e6c  thon :: 3 :: Onl
+00000280: 790a 436c 6173 7369 6669 6572 3a20 5072  y.Classifier: Pr
+00000290: 6f67 7261 6d6d 696e 6720 4c61 6e67 7561  ogramming Langua
+000002a0: 6765 203a 3a20 5079 7468 6f6e 203a 3a20  ge :: Python :: 
+000002b0: 332e 370a 436c 6173 7369 6669 6572 3a20  3.7.Classifier: 
+000002c0: 5072 6f67 7261 6d6d 696e 6720 4c61 6e67  Programming Lang
+000002d0: 7561 6765 203a 3a20 5079 7468 6f6e 203a  uage :: Python :
+000002e0: 3a20 332e 380a 436c 6173 7369 6669 6572  : 3.8.Classifier
+000002f0: 3a20 5072 6f67 7261 6d6d 696e 6720 4c61  : Programming La
+00000300: 6e67 7561 6765 203a 3a20 5079 7468 6f6e  nguage :: Python
+00000310: 203a 3a20 332e 390a 436c 6173 7369 6669   :: 3.9.Classifi
+00000320: 6572 3a20 546f 7069 6320 3a3a 2053 6f66  er: Topic :: Sof
+00000330: 7477 6172 6520 4465 7665 6c6f 706d 656e  tware Developmen
+00000340: 7420 3a3a 204c 6962 7261 7269 6573 203a  t :: Libraries :
+00000350: 3a20 5079 7468 6f6e 204d 6f64 756c 6573  : Python Modules
+00000360: 0a43 6c61 7373 6966 6965 723a 2054 6f70  .Classifier: Top
+00000370: 6963 203a 3a20 5379 7374 656d 203a 3a20  ic :: System :: 
+00000380: 4469 7374 7269 6275 7465 6420 436f 6d70  Distributed Comp
+00000390: 7574 696e 670a 436c 6173 7369 6669 6572  uting.Classifier
+000003a0: 3a20 5479 7069 6e67 203a 3a20 5479 7065  : Typing :: Type
+000003b0: 640a 5072 6f76 6964 6573 2d45 7874 7261  d.Provides-Extra
+000003c0: 3a20 7365 7276 6572 0a52 6571 7569 7265  : server.Require
+000003d0: 732d 4469 7374 3a20 616e 616c 7974 6963  s-Dist: analytic
+000003e0: 732d 7079 7468 6f6e 2028 3e3d 312e 342e  s-python (>=1.4.
+000003f0: 302c 3c32 2e30 2e30 290a 5265 7175 6972  0,<2.0.0).Requir
+00000400: 6573 2d44 6973 743a 2061 7061 6368 652d  es-Dist: apache-
+00000410: 6265 616d 2028 3e3d 322e 3330 2e30 2c3c  beam (>=2.30.0,<
+00000420: 332e 302e 3029 0a52 6571 7569 7265 732d  3.0.0).Requires-
+00000430: 4469 7374 3a20 636c 6963 6b20 283e 3d38  Dist: click (>=8
+00000440: 2e30 2e31 2c3c 392e 302e 3029 0a52 6571  .0.1,<9.0.0).Req
+00000450: 7569 7265 732d 4469 7374 3a20 636c 6963  uires-Dist: clic
+00000460: 6b2d 7061 7261 6d73 2028 3e3d 302e 332e  k-params (>=0.3.
+00000470: 302c 3c30 2e34 2e30 290a 5265 7175 6972  0,<0.4.0).Requir
+00000480: 6573 2d44 6973 743a 2064 6973 7472 6f20  es-Dist: distro 
+00000490: 283e 3d31 2e36 2e30 2c3c 322e 302e 3029  (>=1.6.0,<2.0.0)
+000004a0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+000004b0: 6661 7374 6170 6920 283e 3d30 2e37 352e  fastapi (>=0.75.
+000004c0: 302c 3c30 2e37 362e 3029 3b20 6578 7472  0,<0.76.0); extr
+000004d0: 6120 3d3d 2022 7365 7276 6572 220a 5265  a == "server".Re
+000004e0: 7175 6972 6573 2d44 6973 743a 2067 6974  quires-Dist: git
+000004f0: 7079 7468 6f6e 2028 3e3d 332e 312e 3138  python (>=3.1.18
+00000500: 2c3c 342e 302e 3029 0a52 6571 7569 7265  ,<4.0.0).Require
+00000510: 732d 4469 7374 3a20 6874 7470 6c69 6232  s-Dist: httplib2
+00000520: 2028 3e3d 302e 3139 2e31 2c3c 302e 3230   (>=0.19.1,<0.20
+00000530: 290a 5265 7175 6972 6573 2d44 6973 743a  ).Requires-Dist:
+00000540: 206d 6172 6b75 7073 6166 6520 283d 3d31   markupsafe (==1
+00000550: 2e31 2e31 290a 5265 7175 6972 6573 2d44  .1.1).Requires-D
+00000560: 6973 743a 206d 6c2d 7069 7065 6c69 6e65  ist: ml-pipeline
+00000570: 732d 7364 6b20 283d 3d31 2e38 2e30 290a  s-sdk (==1.8.0).
+00000580: 5265 7175 6972 6573 2d44 6973 743a 206e  Requires-Dist: n
+00000590: 6263 6f6e 7665 7274 2028 3d3d 362e 342e  bconvert (==6.4.
+000005a0: 3429 0a52 6571 7569 7265 732d 4469 7374  4).Requires-Dist
+000005b0: 3a20 7061 6e64 6173 2028 3e3d 312e 312e  : pandas (>=1.1.
+000005c0: 352c 3c32 2e30 2e30 290a 5265 7175 6972  5,<2.0.0).Requir
+000005d0: 6573 2d44 6973 743a 2070 7964 616e 7469  es-Dist: pydanti
+000005e0: 6320 283e 3d31 2e39 2e30 2c3c 322e 302e  c (>=1.9.0,<2.0.
+000005f0: 3029 0a52 6571 7569 7265 732d 4469 7374  0).Requires-Dist
+00000600: 3a20 7079 7061 7273 696e 6720 283e 3d32  : pyparsing (>=2
+00000610: 2e34 2e30 2c3c 3329 0a52 6571 7569 7265  .4.0,<3).Require
+00000620: 732d 4469 7374 3a20 7079 7468 6f6e 2d64  s-Dist: python-d
+00000630: 6174 6575 7469 6c20 283e 3d32 2e38 2e31  ateutil (>=2.8.1
+00000640: 2c3c 332e 302e 3029 0a52 6571 7569 7265  ,<3.0.0).Require
+00000650: 732d 4469 7374 3a20 7079 7961 6d6c 2028  s-Dist: pyyaml (
+00000660: 3e3d 352e 342e 312c 3c36 2e30 2e30 290a  >=5.4.1,<6.0.0).
+00000670: 5265 7175 6972 6573 2d44 6973 743a 2072  Requires-Dist: r
+00000680: 6963 685b 6a75 7079 7465 725d 2028 3e3d  ich[jupyter] (>=
+00000690: 3132 2e30 2e30 2c3c 3133 2e30 2e30 290a  12.0.0,<13.0.0).
+000006a0: 5265 7175 6972 6573 2d44 6973 743a 2073  Requires-Dist: s
+000006b0: 716c 6d6f 6465 6c20 283e 3d30 2e30 2e36  qlmodel (>=0.0.6
+000006c0: 2c3c 302e 312e 3029 0a52 6571 7569 7265  ,<0.1.0).Require
+000006d0: 732d 4469 7374 3a20 7576 6963 6f72 6e5b  s-Dist: uvicorn[
+000006e0: 7374 616e 6461 7264 5d20 283e 3d30 2e31  standard] (>=0.1
+000006f0: 372e 352c 3c30 2e31 382e 3029 3b20 6578  7.5,<0.18.0); ex
+00000700: 7472 6120 3d3d 2022 7365 7276 6572 220a  tra == "server".
+00000710: 5072 6f6a 6563 742d 5552 4c3a 2044 6f63  Project-URL: Doc
+00000720: 756d 656e 7461 7469 6f6e 2c20 6874 7470  umentation, http
+00000730: 733a 2f2f 646f 6373 2e7a 656e 6d6c 2e69  s://docs.zenml.i
+00000740: 6f0a 5072 6f6a 6563 742d 5552 4c3a 2052  o.Project-URL: R
+00000750: 6570 6f73 6974 6f72 792c 2068 7474 7073  epository, https
+00000760: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
+00000770: 6e6d 6c2d 696f 2f7a 656e 6d6c 0a44 6573  nml-io/zenml.Des
+00000780: 6372 6970 7469 6f6e 2d43 6f6e 7465 6e74  cription-Content
+00000790: 2d54 7970 653a 2074 6578 742f 6d61 726b  -Type: text/mark
+000007a0: 646f 776e 0a0a 3c64 6976 2061 6c69 676e  down..<div align
+000007b0: 3d22 6365 6e74 6572 223e 0a20 2020 203c  ="center">.    <
+000007c0: 696d 6720 7372 633d 2264 6f63 732f 626f  img src="docs/bo
+000007d0: 6f6b 2f61 7373 6574 732f 6f73 732d 6865  ok/assets/oss-he
+000007e0: 6164 6572 2e73 7667 223e 0a3c 2f64 6976  ader.svg">.</div
+000007f0: 3e0a 0a23 203a 6661 6d69 6c79 5f6d 616e  >..# :family_man
+00000800: 5f77 6f6d 616e 5f62 6f79 5f62 6f79 3a20  _woman_boy_boy: 
+00000810: 5a65 6e4d 4c3a 204d 6565 7420 7468 6520  ZenML: Meet the 
+00000820: 5465 616d 0a0a 4869 205a 656e 436f 6d6d  Team..Hi ZenComm
+00000830: 756e 6974 7921 2044 6964 2079 6f75 2065  unity! Did you e
+00000840: 7665 7220 6861 7665 2061 2071 7565 7374  ver have a quest
+00000850: 696f 6e20 7468 6174 2773 2074 6f6f 2068  ion that's too h
+00000860: 6172 6420 746f 2065 7870 7265 7373 206f  ard to express o
+00000870: 6e20 6f75 7220 536c 6163 6b3f 2049 7320  n our Slack? Is 
+00000880: 6974 206a 7573 7420 746f 6f20 6d75 6368  it just too much
+00000890: 2065 6666 6f72 7420 746f 2073 6179 2065   effort to say e
+000008a0: 7665 7279 7468 696e 6720 6f6e 2061 200a  verything on a .
+000008b0: 6c6f 6e67 2047 6974 4875 6220 6973 7375  long GitHub issu
+000008c0: 653f 204f 7220 6172 6520 796f 7520 6a75  e? Or are you ju
+000008d0: 7374 2063 7572 696f 7573 2077 6861 7420  st curious what 
+000008e0: 5a65 6e4d 4c20 6861 7320 6265 656e 2075  ZenML has been u
+000008f0: 7020 746f 2069 6e20 7468 6520 7061 7374  p to in the past
+00000900: 2077 6565 6b3f 2057 656c 6c2c 2072 6567   week? Well, reg
+00000910: 6973 7465 7220 6e6f 7720 666f 7220 7468  ister now for th
+00000920: 6520 5a65 6e4d 4c20 4f66 6669 6365 200a  e ZenML Office .
+00000930: 2848 616c 6629 2048 6f75 7220 746f 2067  (Half) Hour to g
+00000940: 6574 2079 6f75 7220 616e 7377 6572 7320  et your answers 
+00000950: 616e 6420 6d6f 7265 210a 0a45 7665 7279  and more!..Every
+00000960: 2077 6565 6b2c 2070 6172 7420 6f66 2074   week, part of t
+00000970: 6865 205a 656e 4d4c 2063 6f72 6520 7465  he ZenML core te
+00000980: 616d 2077 696c 6c20 706f 7020 696e 2066  am will pop in f
+00000990: 6f72 2033 3020 6d69 6e75 7465 7320 746f  or 30 minutes to
+000009a0: 2069 6e74 6572 6163 7420 6469 7265 6374   interact direct
+000009b0: 6c79 2077 6974 6820 7468 6520 636f 6d6d  ly with the comm
+000009c0: 756e 6974 792e 2053 6f6d 6574 696d 6573  unity. Sometimes
+000009d0: 2077 6527 6c6c 2062 6520 7072 6573 656e   we'll be presen
+000009e0: 7469 6e67 2061 200a 6665 6174 7572 652c  ting a .feature,
+000009f0: 206f 7468 6572 2074 696d 6573 206a 7573   other times jus
+00000a00: 7420 7461 6b69 6e67 2071 7565 7374 696f  t taking questio
+00000a10: 6e73 2c20 616e 6420 6861 7669 6e67 2066  ns, and having f
+00000a20: 756e 2e20 4a6f 696e 2075 7320 6966 2079  un. Join us if y
+00000a30: 6f75 2061 7265 2063 7572 696f 7573 2061  ou are curious a
+00000a40: 626f 7574 205a 656e 4d4c 2c20 6f72 206a  bout ZenML, or j
+00000a50: 7573 7420 7761 6e74 2074 6f20 7461 6c6b  ust want to talk
+00000a60: 2073 686f 7020 6162 6f75 7420 4d4c 4f70   shop about MLOp
+00000a70: 732e 0a0a 5765 2077 696c 6c20 686f 7374  s...We will host
+00000a80: 2074 6865 2067 6174 6865 7269 6e67 2065   the gathering e
+00000a90: 7665 7279 2057 6564 6e65 7364 6179 2038  very Wednesday 8
+00000aa0: 3a33 3041 4d20 5054 2028 353a 3330 504d  :30AM PT (5:30PM
+00000ab0: 2043 4554 292e 2052 6567 6973 7465 7220   CET). Register 
+00000ac0: 6e6f 7720 7468 726f 7567 6820 5b74 6869  now through [thi
+00000ad0: 7320 6c69 6e6b 5d28 6874 7470 733a 2f2f  s link](https://
+00000ae0: 7777 772e 6576 656e 7462 7269 7465 2e63  www.eventbrite.c
+00000af0: 6f6d 2f65 2f7a 656e 6d6c 2d6d 6565 742d  om/e/zenml-meet-
+00000b00: 7468 652d 636f 6d6d 756e 6974 792d 7469  the-community-ti
+00000b10: 636b 6574 732d 3335 3434 3236 3638 3837  ckets-3544266887
+00000b20: 3637 292c 200a 6f72 2073 7562 7363 7269  67), .or subscri
+00000b30: 6265 2074 6f20 7468 6520 5b70 7562 6c69  be to the [publi
+00000b40: 6320 6576 656e 7473 2063 616c 656e 6461  c events calenda
+00000b50: 725d 2868 7474 7073 3a2f 2f63 616c 656e  r](https://calen
+00000b60: 6461 722e 676f 6f67 6c65 2e63 6f6d 2f63  dar.google.com/c
+00000b70: 616c 656e 6461 722f 752f 302f 723f 6369  alendar/u/0/r?ci
+00000b80: 643d 5931 3969 6144 4a30 5a6d 3434 5a7a  d=Y19iaDJ0Zm44Zz
+00000b90: 646f 6458 426c 626e 427a 6157 706c 5933  dodXBlbnBzaWplY3
+00000ba0: 5577 4d6d 4e6a 5a30 426e 636d 3931 6343  UwMmNjZ0Bncm91cC
+00000bb0: 356a 5957 786c 626d 5268 6369 356e 6232  5jYWxlbmRhci5nb2
+00000bc0: 396e 6247 5575 5932 3974 2920 746f 2067  9nbGUuY29t) to g
+00000bd0: 6574 206e 6f74 6966 6965 6420 0a62 6566  et notified .bef
+00000be0: 6f72 6520 6576 6572 7920 636f 6d6d 756e  ore every commun
+00000bf0: 6974 7920 6761 7468 6572 696e 672e 0a0a  ity gathering...
+00000c00: 2320 f09f 9180 2057 6861 7420 6973 205a  # .... What is Z
+00000c10: 656e 4d4c 3f0a 0a2a 2a5a 656e 4d4c 2a2a  enML?..**ZenML**
+00000c20: 2069 7320 616e 2065 7874 656e 7369 626c   is an extensibl
+00000c30: 652c 206f 7065 6e2d 736f 7572 6365 204d  e, open-source M
+00000c40: 4c4f 7073 2066 7261 6d65 776f 726b 2066  LOps framework f
+00000c50: 6f72 2063 7265 6174 696e 6720 0a70 6f72  or creating .por
+00000c60: 7461 626c 652c 2070 726f 6475 6374 696f  table, productio
+00000c70: 6e2d 7265 6164 7920 4d4c 4f70 7320 7069  n-ready MLOps pi
+00000c80: 7065 6c69 6e65 732e 2042 7569 6c74 2074  pelines. Built t
+00000c90: 6f20 656e 6162 6c65 2063 6f6c 6c61 626f  o enable collabo
+00000ca0: 7261 7469 6f6e 2061 6d6f 6e67 2064 6174  ration among dat
+00000cb0: 6120 7363 6965 6e74 6973 7473 2c20 4d4c  a scientists, ML
+00000cc0: 2045 6e67 696e 6565 7273 2c20 616e 6420   Engineers, and 
+00000cd0: 4d4c 4f70 7320 4465 7665 6c6f 7065 7273  MLOps Developers
+00000ce0: 2c0a 6974 2068 6173 2061 2073 696d 706c  ,.it has a simpl
+00000cf0: 652c 2066 6c65 7869 626c 6520 7379 6e74  e, flexible synt
+00000d00: 6178 2c20 6973 202a 2a63 6c6f 7564 2d2a  ax, is **cloud-*
+00000d10: 2a20 616e 6420 0a2a 2a74 6f6f 6c2d 6167  * and .**tool-ag
+00000d20: 6e6f 7374 6963 2a2a 2c20 616e 6420 6861  nostic**, and ha
+00000d30: 7320 696e 7465 7266 6163 6573 2f61 6273  s interfaces/abs
+00000d40: 7472 6163 7469 6f6e 7320 7468 6174 2061  tractions that a
+00000d50: 7265 2074 686f 7567 6874 6675 6c6c 7920  re thoughtfully 
+00000d60: 6465 7369 676e 6564 2066 6f72 200a 4d4c  designed for .ML
+00000d70: 2077 6f72 6b66 6c6f 7773 2e20 0a0a 4174   workflows. ..At
+00000d80: 2069 7473 2063 6f72 652c 202a 2a5a 656e   its core, **Zen
+00000d90: 4d4c 2070 6970 656c 696e 6573 2065 7865  ML pipelines exe
+00000da0: 6375 7465 204d 4c2d 7370 6563 6966 6963  cute ML-specific
+00000db0: 2077 6f72 6b66 6c6f 7773 2a2a 2066 726f   workflows** fro
+00000dc0: 6d20 736f 7572 6369 6e67 0a64 6174 6120  m sourcing.data 
+00000dd0: 746f 2073 706c 6974 7469 6e67 2c20 7072  to splitting, pr
+00000de0: 6570 726f 6365 7373 696e 672c 2074 7261  eprocessing, tra
+00000df0: 696e 696e 672c 2061 6c6c 2074 6865 2077  ining, all the w
+00000e00: 6179 2074 6f20 7365 7276 696e 6720 616e  ay to serving an
+00000e10: 6420 6d6f 6e69 746f 7269 6e67 200a 4d4c  d monitoring .ML
+00000e20: 206d 6f64 656c 7320 696e 2070 726f 6475   models in produ
+00000e30: 6374 696f 6e2e 2054 6865 7265 2061 7265  ction. There are
+00000e40: 206d 616e 7920 6275 696c 742d 696e 2066   many built-in f
+00000e50: 6561 7475 7265 7320 746f 2073 7570 706f  eatures to suppo
+00000e60: 7274 0a63 6f6d 6d6f 6e20 4d4c 2064 6576  rt.common ML dev
+00000e70: 656c 6f70 6d65 6e74 2074 6173 6b73 2e20  elopment tasks. 
+00000e80: 5a65 6e4d 4c20 6973 206e 6f74 2068 6572  ZenML is not her
+00000e90: 6520 746f 2072 6570 6c61 6365 2074 6865  e to replace the
+00000ea0: 2067 7265 6174 2074 6f6f 6c73 2074 6861   great tools tha
+00000eb0: 740a 736f 6c76 6520 7468 6573 6520 696e  t.solve these in
+00000ec0: 6469 7669 6475 616c 2070 726f 626c 656d  dividual problem
+00000ed0: 732e 2052 6174 6865 722c 2069 7420 6f66  s. Rather, it of
+00000ee0: 6665 7273 2061 6e20 2a2a 6578 7465 6e73  fers an **extens
+00000ef0: 6962 6c65 2066 7261 6d65 776f 726b 2a2a  ible framework**
+00000f00: 2061 6e64 2061 0a73 7461 6e64 6172 6420   and a.standard 
+00000f10: 6162 7374 7261 6374 696f 6e20 746f 2077  abstraction to w
+00000f20: 7269 7465 2061 6e64 2062 7569 6c64 2079  rite and build y
+00000f30: 6f75 7220 776f 726b 666c 6f77 732e 0a0a  our workflows...
+00000f40: f09f 8e89 202a 2a56 6572 7369 6f6e 2030  .... **Version 0
+00000f50: 2e39 2e30 206f 7574 206e 6f77 212a 2a20  .9.0 out now!** 
+00000f60: 5b43 6865 636b 206f 7574 2074 6865 2072  [Check out the r
+00000f70: 656c 6561 7365 206e 6f74 6573 0a68 6572  elease notes.her
+00000f80: 655d 2868 7474 7073 3a2f 2f67 6974 6875  e](https://githu
+00000f90: 622e 636f 6d2f 7a65 6e6d 6c2d 696f 2f7a  b.com/zenml-io/z
+00000fa0: 656e 6d6c 2f72 656c 6561 7365 7329 2e0a  enml/releases)..
+00000fb0: 0a5b 215b 5079 5049 202d 2050 7974 686f  .[![PyPI - Pytho
+00000fc0: 6e0a 5665 7273 696f 6e5d 2868 7474 7073  n.Version](https
+00000fd0: 3a2f 2f69 6d67 2e73 6869 656c 6473 2e69  ://img.shields.i
+00000fe0: 6f2f 7079 7069 2f70 7976 6572 7369 6f6e  o/pypi/pyversion
+00000ff0: 732f 7a65 6e6d 6c29 5d28 6874 7470 733a  s/zenml)](https:
+00001000: 2f2f 7079 7069 2e6f 7267 2f70 726f 6a65  //pypi.org/proje
+00001010: 6374 2f7a 656e 6d6c 2f29 0a5b 215b 5079  ct/zenml/).[![Py
+00001020: 5049 2053 7461 7475 735d 2868 7474 7073  PI Status](https
+00001030: 3a2f 2f70 6570 792e 7465 6368 2f62 6164  ://pepy.tech/bad
+00001040: 6765 2f7a 656e 6d6c 295d 2868 7474 7073  ge/zenml)](https
+00001050: 3a2f 2f70 6570 792e 7465 6368 2f70 726f  ://pepy.tech/pro
+00001060: 6a65 6374 2f7a 656e 6d6c 290a 215b 4769  ject/zenml).![Gi
+00001070: 7448 7562 5d28 6874 7470 733a 2f2f 696d  tHub](https://im
+00001080: 672e 7368 6965 6c64 732e 696f 2f67 6974  g.shields.io/git
+00001090: 6875 622f 6c69 6365 6e73 652f 7a65 6e6d  hub/license/zenm
+000010a0: 6c2d 696f 2f7a 656e 6d6c 290a 5b21 5b43  l-io/zenml).[![C
+000010b0: 6f64 6563 6f76 5d28 6874 7470 733a 2f2f  odecov](https://
+000010c0: 636f 6465 636f 762e 696f 2f67 682f 7a65  codecov.io/gh/ze
+000010d0: 6e6d 6c2d 696f 2f7a 656e 6d6c 2f62 7261  nml-io/zenml/bra
+000010e0: 6e63 682f 6d61 696e 2f67 7261 7068 2f62  nch/main/graph/b
+000010f0: 6164 6765 2e73 7667 295d 2868 7474 7073  adge.svg)](https
+00001100: 3a2f 2f63 6f64 6563 6f76 2e69 6f2f 6768  ://codecov.io/gh
+00001110: 2f7a 656e 6d6c 2d69 6f2f 7a65 6e6d 6c29  /zenml-io/zenml)
+00001120: 0a5b 215b 496e 7465 7272 6f67 6174 655d  .[![Interrogate]
+00001130: 2864 6f63 732f 626f 6f6b 2f61 7373 6574  (docs/book/asset
+00001140: 732f 696e 7465 7272 6f67 6174 652e 7376  s/interrogate.sv
+00001150: 6729 5d28 6874 7470 733a 2f2f 696e 7465  g)](https://inte
+00001160: 7272 6f67 6174 652e 7265 6164 7468 6564  rrogate.readthed
+00001170: 6f63 732e 696f 2f65 6e2f 6c61 7465 7374  ocs.io/en/latest
+00001180: 2f29 0a5b 215b 4d61 696e 2057 6f72 6b66  /).[![Main Workf
+00001190: 6c6f 770a 5465 7374 735d 2868 7474 7073  low.Tests](https
+000011a0: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
+000011b0: 6e6d 6c2d 696f 2f7a 656e 6d6c 2f61 6374  nml-io/zenml/act
+000011c0: 696f 6e73 2f77 6f72 6b66 6c6f 7773 2f63  ions/workflows/c
+000011d0: 692e 796d 6c2f 6261 6467 652e 7376 673f  i.yml/badge.svg?
+000011e0: 6272 616e 6368 3d6d 6169 6e29 5d28 6874  branch=main)](ht
+000011f0: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
+00001200: 2f7a 656e 6d6c 2d69 6f2f 7a65 6e6d 6c2f  /zenml-io/zenml/
+00001210: 6163 7469 6f6e 732f 776f 726b 666c 6f77  actions/workflow
+00001220: 732f 6369 2e79 6d6c 290a 0a3c 6469 7620  s/ci.yml)..<div 
+00001230: 616c 6967 6e3d 2263 656e 7465 7222 3e0a  align="center">.
+00001240: 4a6f 696e 206f 7572 203c 6120 6872 6566  Join our <a href
+00001250: 3d22 6874 7470 733a 2f2f 7a65 6e6d 6c2e  ="https://zenml.
+00001260: 696f 2f73 6c61 636b 2d69 6e76 6974 6522  io/slack-invite"
+00001270: 2074 6172 6765 743d 225f 626c 616e 6b22   target="_blank"
+00001280: 3e0a 2020 2020 3c69 6d67 2077 6964 7468  >.    <img width
+00001290: 3d22 3235 2220 7372 633d 2268 7474 7073  ="25" src="https
+000012a0: 3a2f 2f63 646e 332e 6963 6f6e 6669 6e64  ://cdn3.iconfind
+000012b0: 6572 2e63 6f6d 2f64 6174 612f 6963 6f6e  er.com/data/icon
+000012c0: 732f 6c6f 676f 732d 616e 642d 6272 616e  s/logos-and-bran
+000012d0: 6473 2d61 646f 6265 2f35 3132 2f33 3036  ds-adobe/512/306
+000012e0: 5f53 6c61 636b 2d35 3132 2e70 6e67 2220  _Slack-512.png" 
+000012f0: 616c 743d 2253 6c61 636b 222f 3e0a 3c62  alt="Slack"/>.<b
+00001300: 3e53 6c61 636b 2043 6f6d 6d75 6e69 7479  >Slack Community
+00001310: 3c2f 623e 203c 2f61 3e20 616e 6420 6265  </b> </a> and be
+00001320: 636f 6d65 2070 6172 7420 6f66 2074 6865  come part of the
+00001330: 205a 656e 4d4c 2066 616d 696c 790a 3c2f   ZenML family.</
+00001340: 6469 763e 0a3c 6469 7620 616c 6967 6e3d  div>.<div align=
+00001350: 2263 656e 7465 7222 3e20 4769 7665 2075  "center"> Give u
+00001360: 7320 6120 0a20 2020 203c 696d 6720 7769  s a .    <img wi
+00001370: 6474 683d 2232 3522 2073 7263 3d22 6874  dth="25" src="ht
+00001380: 7470 733a 2f2f 6364 6e2e 6963 6f6e 7363  tps://cdn.iconsc
+00001390: 6f75 742e 636f 6d2f 6963 6f6e 2f66 7265  out.com/icon/fre
+000013a0: 652f 706e 672d 3235 362f 6769 7468 7562  e/png-256/github
+000013b0: 2d31 3533 2d36 3735 3532 332e 706e 6722  -153-675523.png"
+000013c0: 2061 6c74 3d22 536c 6163 6b22 2f3e 0a3c   alt="Slack"/>.<
+000013d0: 623e 4769 7448 7562 2073 7461 723c 2f62  b>GitHub star</b
+000013e0: 3e20 746f 2073 686f 7720 796f 7572 206c  > to show your l
+000013f0: 6f76 650a 3c2f 6469 763e 0a3c 6469 7620  ove.</div>.<div 
+00001400: 616c 6967 6e3d 2263 656e 7465 7222 3e20  align="center"> 
+00001410: 0a20 2020 203c 623e 4e45 573a 203c 2f62  .    <b>NEW: </b
+00001420: 3e20 3c61 2068 7265 663d 2268 7474 7073  > <a href="https
+00001430: 3a2f 2f7a 656e 6d6c 2e69 6f2f 6469 7363  ://zenml.io/disc
+00001440: 7573 7369 6f6e 2220 7461 7267 6574 3d22  ussion" target="
+00001450: 5f62 6c61 6e6b 223e 3c69 6d67 2077 6964  _blank"><img wid
+00001460: 7468 3d22 3235 2220 7372 633d 2268 7474  th="25" src="htt
+00001470: 7073 3a2f 2f63 646e 312e 6963 6f6e 6669  ps://cdn1.iconfi
+00001480: 6e64 6572 2e63 6f6d 2f64 6174 612f 6963  nder.com/data/ic
+00001490: 6f6e 732f 736f 6369 616c 2d31 372f 3438  ons/social-17/48
+000014a0: 2f6c 696b 652d 3531 322e 706e 6722 2061  /like-512.png" a
+000014b0: 6c74 3d22 566f 7465 222f 3e3c 623e 2056  lt="Vote"/><b> V
+000014c0: 6f74 653c 2f62 3e3c 2f61 3e20 6f6e 2074  ote</b></a> on t
+000014d0: 6865 206e 6578 7420 5a65 6e4d 4c20 6665  he next ZenML fe
+000014e0: 6174 7572 6573 200a 3c2f 6469 763e 0a0a  atures .</div>..
+000014f0: 3c62 723e 0a0a 2320 f09f a496 2057 6879  <br>..# .... Why
+00001500: 2075 7365 205a 656e 4d4c 3f0a 0a5a 656e   use ZenML?..Zen
+00001510: 4d4c 2070 6970 656c 696e 6573 2061 7265  ML pipelines are
+00001520: 2064 6573 6967 6e65 6420 746f 2062 6520   designed to be 
+00001530: 7772 6974 7465 6e20 6561 726c 7920 6f6e  written early on
+00001540: 2074 6865 2064 6576 656c 6f70 6d65 6e74   the development
+00001550: 206c 6966 6563 7963 6c65 2e0a 4461 7461   lifecycle..Data
+00001560: 2073 6369 656e 7469 7374 7320 6361 6e20   scientists can 
+00001570: 6578 706c 6f72 6520 7468 6569 7220 7069  explore their pi
+00001580: 7065 6c69 6e65 7320 6173 2074 6865 7920  pelines as they 
+00001590: 6465 7665 6c6f 7020 746f 7761 7264 7320  develop towards 
+000015a0: 7072 6f64 7563 7469 6f6e 2c0a 7377 6974  production,.swit
+000015b0: 6368 696e 6720 7374 6163 6b73 2066 726f  ching stacks fro
+000015c0: 6d20 6c6f 6361 6c20 746f 2063 6c6f 7564  m local to cloud
+000015d0: 2064 6570 6c6f 796d 656e 7473 2077 6974   deployments wit
+000015e0: 6820 6561 7365 2e20 596f 7520 6361 6e20  h ease. You can 
+000015f0: 7265 6164 206d 6f72 650a 6162 6f75 7420  read more.about 
+00001600: 7768 7920 7765 2073 7461 7274 6564 2062  why we started b
+00001610: 7569 6c64 696e 6720 5a65 6e4d 4c20 5b6f  uilding ZenML [o
+00001620: 6e20 6f75 720a 626c 6f67 5d28 6874 7470  n our.blog](http
+00001630: 733a 2f2f 626c 6f67 2e7a 656e 6d6c 2e69  s://blog.zenml.i
+00001640: 6f2f 7768 792d 7a65 6e6d 6c2f 292e 2042  o/why-zenml/). B
+00001650: 7920 7573 696e 6720 5a65 6e4d 4c20 696e  y using ZenML in
+00001660: 2074 6865 2065 6172 6c79 2073 7461 6765   the early stage
+00001670: 7320 6f66 0a79 6f75 7220 7072 6f6a 6563  s of.your projec
+00001680: 742c 2079 6f75 2067 6574 2074 6865 2066  t, you get the f
+00001690: 6f6c 6c6f 7769 6e67 2062 656e 6566 6974  ollowing benefit
+000016a0: 733a 0a0a 2d20 2a2a 4578 7465 6e73 6962  s:..- **Extensib
+000016b0: 6c65 2a2a 2073 6f20 796f 7520 6361 6e20  le** so you can 
+000016c0: 6275 696c 6420 6f75 7420 7468 6520 6672  build out the fr
+000016d0: 616d 6577 6f72 6b20 746f 2073 7569 7420  amework to suit 
+000016e0: 796f 7572 2073 7065 6369 6669 6320 6e65  your specific ne
+000016f0: 6564 730a 2d20 2a2a 5265 7072 6f64 7563  eds.- **Reproduc
+00001700: 6962 696c 6974 792a 2a20 6f66 2074 7261  ibility** of tra
+00001710: 696e 696e 6720 616e 6420 696e 6665 7265  ining and infere
+00001720: 6e63 6520 776f 726b 666c 6f77 730a 2d20  nce workflows.- 
+00001730: 4120 2a2a 7369 6d70 6c65 2061 6e64 2063  A **simple and c
+00001740: 6c65 6172 2a2a 2077 6179 2074 6f20 7265  lear** way to re
+00001750: 7072 6573 656e 7420 7468 6520 7374 6570  present the step
+00001760: 7320 6f66 2079 6f75 7220 7069 7065 6c69  s of your pipeli
+00001770: 6e65 2069 6e20 636f 6465 0a2d 202a 2a42  ne in code.- **B
+00001780: 6174 7465 7269 6573 2d69 6e63 6c75 6465  atteries-include
+00001790: 6420 696e 7465 6772 6174 696f 6e73 2a2a  d integrations**
+000017a0: 3a20 6272 696e 6720 616c 6c20 796f 7572  : bring all your
+000017b0: 2066 6176 6f72 6974 6520 746f 6f6c 7320   favorite tools 
+000017c0: 746f 6765 7468 6572 0a2d 2045 6173 7920  together.- Easy 
+000017d0: 7377 6974 6368 2062 6574 7765 656e 206c  switch between l
+000017e0: 6f63 616c 2061 6e64 2063 6c6f 7564 2073  ocal and cloud s
+000017f0: 7461 636b 730a 2d20 5061 696e 6c65 7373  tacks.- Painless
+00001800: 202a 2a64 6570 6c6f 796d 656e 7420 616e   **deployment an
+00001810: 6420 636f 6e66 6967 7572 6174 696f 6e2a  d configuration*
+00001820: 2a20 6f66 2069 6e66 7261 7374 7275 6374  * of infrastruct
+00001830: 7572 650a 0a23 20f0 9f93 9620 4c65 6172  ure..# .... Lear
+00001840: 6e20 4d6f 7265 0a0a 7c20 5a65 6e4d 4c20  n More..| ZenML 
+00001850: 5265 736f 7572 6365 7320 7c20 4465 7363  Resources | Desc
+00001860: 7269 7074 696f 6e20 7c0a 7c20 2d2d 2d2d  ription |.| ----
+00001870: 2d2d 2d2d 2d2d 2d2d 2d20 7c20 2d20 7c0a  --------- | - |.
+00001880: 7c20 f09f a798 e280 8de2 9980 efb8 8f20  | ............. 
+00001890: 2a2a 5b5a 656e 4d4c 2031 3031 5d2a 2a20  **[ZenML 101]** 
+000018a0: 7c20 4e65 7720 746f 205a 656e 4d4c 3f20  | New to ZenML? 
+000018b0: 4865 7265 2773 2065 7665 7279 7468 696e  Here's everythin
+000018c0: 6720 796f 7520 6e65 6564 2074 6f20 6b6e  g you need to kn
+000018d0: 6f77 2120 7c0a 7c20 e29a 9bef b88f 202a  ow! |.| ...... *
+000018e0: 2a5b 436f 7265 2043 6f6e 6365 7074 735d  *[Core Concepts]
+000018f0: 2a2a 207c 2053 6f6d 6520 6b65 7920 7465  ** | Some key te
+00001900: 726d 7320 616e 6420 636f 6e63 6570 7473  rms and concepts
+00001910: 2077 6520 7573 652e 207c 0a7c 20f0 9f97   we use. |.| ...
+00001920: 8320 2a2a 5b46 756e 6374 696f 6e61 6c20  . **[Functional 
+00001930: 4150 4920 4775 6964 655d 2a2a 207c 2042  API Guide]** | B
+00001940: 7569 6c64 2070 726f 6475 6374 696f 6e20  uild production 
+00001950: 4d4c 2070 6970 656c 696e 6573 2077 6974  ML pipelines wit
+00001960: 6820 7369 6d70 6c65 2066 756e 6374 696f  h simple functio
+00001970: 6e73 2e20 7c0a 7c20 f09f 9a80 202a 2a5b  ns. |.| .... **[
+00001980: 4e65 7720 696e 2076 302e 392e 305d 2a2a  New in v0.9.0]**
+00001990: 207c 204e 6577 2066 6561 7475 7265 732c   | New features,
+000019a0: 2062 7567 2066 6978 6573 2e20 7c0a 7c20   bug fixes. |.| 
+000019b0: f09f 97b3 202a 2a5b 566f 7465 2066 6f72  .... **[Vote for
+000019c0: 2046 6561 7475 7265 735d 2a2a 207c 2050   Features]** | P
+000019d0: 6963 6b20 7768 6174 2077 6520 776f 726b  ick what we work
+000019e0: 206f 6e20 6e65 7874 2120 7c0a 7c20 f09f   on next! |.| ..
+000019f0: 9393 202a 2a5b 446f 6373 5d2a 2a20 7c20  .. **[Docs]** | 
+00001a00: 4675 6c6c 2064 6f63 756d 656e 7461 7469  Full documentati
+00001a10: 6f6e 2066 6f72 2063 7265 6174 696e 6720  on for creating 
+00001a20: 796f 7572 206f 776e 205a 656e 4d4c 2070  your own ZenML p
+00001a30: 6970 656c 696e 6573 2e20 7c0a 7c20 f09f  ipelines. |.| ..
+00001a40: 9392 202a 2a5b 4150 4920 5265 6665 7265  .. **[API Refere
+00001a50: 6e63 655d 2a2a 207c 2054 6865 2064 6574  nce]** | The det
+00001a60: 6169 6c65 6420 7265 6665 7265 6e63 6520  ailed reference 
+00001a70: 666f 7220 5a65 6e4d 4c27 7320 4150 492e  for ZenML's API.
+00001a80: 207c 0a7c 20f0 9f8d b020 2a2a 5b5a 656e   |.| .... **[Zen
+00001a90: 4279 7465 735d 2a2a 207c 2041 2067 7569  Bytes]** | A gui
+00001aa0: 6465 6420 616e 6420 696e 2d64 6570 7468  ded and in-depth
+00001ab0: 2074 7574 6f72 6961 6c20 6f6e 204d 4c4f   tutorial on MLO
+00001ac0: 7073 2061 6e64 205a 656e 4d4c 2e20 7c0a  ps and ZenML. |.
+00001ad0: 7c20 f09f 9782 efb8 8fef b88f 202a 2a5b  | .......... **[
+00001ae0: 5a65 6e46 696c 6573 5d2a 2a20 7c20 456e  ZenFiles]** | En
+00001af0: 642d 746f 2d65 6e64 2070 726f 6a65 6374  d-to-end project
+00001b00: 7320 7573 696e 6720 5a65 6e4d 4c2e 207c  s using ZenML. |
+00001b10: 0a7c 20e2 9abd efb8 8f20 2a2a 5b45 7861  .| ...... **[Exa
+00001b20: 6d70 6c65 735d 2a2a 207c 204c 6561 726e  mples]** | Learn
+00001b30: 2062 6573 7420 7468 726f 7567 6820 6578   best through ex
+00001b40: 616d 706c 6573 2077 6865 7265 205a 656e  amples where Zen
+00001b50: 4d4c 2069 7320 7573 6564 3f20 5765 2776  ML is used? We'v
+00001b60: 6520 676f 7420 796f 7520 636f 7665 7265  e got you covere
+00001b70: 642e 207c 0a7c 20f0 9f93 ac20 2a2a 5b42  d. |.| .... **[B
+00001b80: 6c6f 675d 2a2a 207c 2055 7365 2063 6173  log]** | Use cas
+00001b90: 6573 206f 6620 5a65 6e4d 4c20 616e 6420  es of ZenML and 
+00001ba0: 7465 6368 6e69 6361 6c20 6465 6570 2064  technical deep d
+00001bb0: 6976 6573 206f 6e20 686f 7720 7765 2062  ives on how we b
+00001bc0: 7569 6c74 2069 742e 207c 0a7c 20f0 9f94  uilt it. |.| ...
+00001bd0: 8820 2a2a 5b50 6f64 6361 7374 5d2a 2a20  . **[Podcast]** 
+00001be0: 7c20 436f 6e76 6572 7361 7469 6f6e 7320  | Conversations 
+00001bf0: 7769 7468 206c 6561 6465 7273 2069 6e20  with leaders in 
+00001c00: 4d4c 2c20 7265 6c65 6173 6564 2065 7665  ML, released eve
+00001c10: 7279 2032 2077 6565 6b73 2e20 7c0a 7c20  ry 2 weeks. |.| 
+00001c20: f09f 93a3 202a 2a5b 4e65 7773 6c65 7474  .... **[Newslett
+00001c30: 6572 5d2a 2a20 7c20 5765 2062 7569 6c64  er]** | We build
+00001c40: 205a 656e 4d4c 2069 6e20 7075 626c 6963   ZenML in public
+00001c50: 2e20 5375 6273 6372 6962 6520 746f 206c  . Subscribe to l
+00001c60: 6561 726e 2068 6f77 2077 6520 776f 726b  earn how we work
+00001c70: 2e20 7c0a 7c20 f09f 92ac 202a 2a5b 4a6f  . |.| .... **[Jo
+00001c80: 696e 2053 6c61 636b 5d2a 2a20 7c20 4e65  in Slack]** | Ne
+00001c90: 6564 2068 656c 7020 7769 7468 2079 6f75  ed help with you
+00001ca0: 7220 7370 6563 6966 6963 2075 7365 2063  r specific use c
+00001cb0: 6173 653f 2053 6179 2068 6920 6f6e 2053  ase? Say hi on S
+00001cc0: 6c61 636b 2120 7c0a 7c20 f09f 97ba 202a  lack! |.| .... *
+00001cd0: 2a5b 526f 6164 6d61 705d 2a2a 207c 2053  *[Roadmap]** | S
+00001ce0: 6565 2077 6865 7265 205a 656e 4d4c 2069  ee where ZenML i
+00001cf0: 7320 776f 726b 696e 6720 746f 2062 7569  s working to bui
+00001d00: 6c64 206e 6577 2066 6561 7475 7265 732e  ld new features.
+00001d10: 207c 0a7c 20f0 9f99 8be2 808d e299 80ef   |.| ...........
+00001d20: b88f 202a 2a5b 436f 6e74 7269 6275 7465  .. **[Contribute
+00001d30: 5d2a 2a20 7c20 486f 7720 746f 2063 6f6e  ]** | How to con
+00001d40: 7472 6962 7574 6520 746f 2074 6865 205a  tribute to the Z
+00001d50: 656e 4d4c 2070 726f 6a65 6374 2061 6e64  enML project and
+00001d60: 2063 6f64 6520 6261 7365 2e20 7c0a 0a5b   code base. |..[
+00001d70: 5a65 6e4d 4c20 3130 315d 3a20 6874 7470  ZenML 101]: http
+00001d80: 733a 2f2f 646f 6373 2e7a 656e 6d6c 2e69  s://docs.zenml.i
+00001d90: 6f2f 0a5b 436f 7265 2043 6f6e 6365 7074  o/.[Core Concept
+00001da0: 735d 3a20 6874 7470 733a 2f2f 646f 6373  s]: https://docs
+00001db0: 2e7a 656e 6d6c 2e69 6f2f 636f 7265 2d63  .zenml.io/core-c
+00001dc0: 6f6e 6365 7074 730a 5b46 756e 6374 696f  oncepts.[Functio
+00001dd0: 6e61 6c20 4150 4920 4775 6964 655d 3a20  nal API Guide]: 
+00001de0: 6874 7470 733a 2f2f 646f 6373 2e7a 656e  https://docs.zen
+00001df0: 6d6c 2e69 6f2f 762f 646f 6373 2f67 7569  ml.io/v/docs/gui
+00001e00: 6465 732f 6675 6e63 7469 6f6e 616c 2d61  des/functional-a
+00001e10: 7069 0a5b 4e65 7720 696e 2076 302e 392e  pi.[New in v0.9.
+00001e20: 305d 3a20 6874 7470 733a 2f2f 6769 7468  0]: https://gith
+00001e30: 7562 2e63 6f6d 2f7a 656e 6d6c 2d69 6f2f  ub.com/zenml-io/
+00001e40: 7a65 6e6d 6c2f 7265 6c65 6173 6573 0a5b  zenml/releases.[
+00001e50: 566f 7465 2066 6f72 2046 6561 7475 7265  Vote for Feature
+00001e60: 735d 3a20 6874 7470 733a 2f2f 7a65 6e6d  s]: https://zenm
+00001e70: 6c2e 696f 2f64 6973 6375 7373 696f 6e0a  l.io/discussion.
+00001e80: 5b44 6f63 735d 3a20 6874 7470 733a 2f2f  [Docs]: https://
+00001e90: 646f 6373 2e7a 656e 6d6c 2e69 6f2f 0a5b  docs.zenml.io/.[
+00001ea0: 4150 4920 5265 6665 7265 6e63 655d 3a20  API Reference]: 
+00001eb0: 6874 7470 733a 2f2f 6170 6964 6f63 732e  https://apidocs.
+00001ec0: 7a65 6e6d 6c2e 696f 2f0a 5b5a 656e 4279  zenml.io/.[ZenBy
+00001ed0: 7465 735d 3a20 6874 7470 733a 2f2f 6769  tes]: https://gi
+00001ee0: 7468 7562 2e63 6f6d 2f7a 656e 6d6c 2d69  thub.com/zenml-i
+00001ef0: 6f2f 7a65 6e62 7974 6573 0a5b 5a65 6e46  o/zenbytes.[ZenF
+00001f00: 696c 6573 5d3a 2068 7474 7073 3a2f 2f67  iles]: https://g
+00001f10: 6974 6875 622e 636f 6d2f 7a65 6e6d 6c2d  ithub.com/zenml-
+00001f20: 696f 2f7a 656e 6669 6c65 730a 5b45 7861  io/zenfiles.[Exa
+00001f30: 6d70 6c65 735d 3a20 6874 7470 733a 2f2f  mples]: https://
+00001f40: 6769 7468 7562 2e63 6f6d 2f7a 656e 6d6c  github.com/zenml
+00001f50: 2d69 6f2f 7a65 6e6d 6c2f 7472 6565 2f6d  -io/zenml/tree/m
+00001f60: 6169 6e2f 6578 616d 706c 6573 0a5b 426c  ain/examples.[Bl
+00001f70: 6f67 5d3a 2068 7474 7073 3a2f 2f62 6c6f  og]: https://blo
+00001f80: 672e 7a65 6e6d 6c2e 696f 2f0a 5b50 6f64  g.zenml.io/.[Pod
+00001f90: 6361 7374 5d3a 2068 7474 7073 3a2f 2f70  cast]: https://p
+00001fa0: 6f64 6361 7374 2e7a 656e 6d6c 2e69 6f2f  odcast.zenml.io/
+00001fb0: 0a5b 4e65 7773 6c65 7474 6572 5d3a 2068  .[Newsletter]: h
+00001fc0: 7474 7073 3a2f 2f7a 656e 6d6c 2e69 6f2f  ttps://zenml.io/
+00001fd0: 6e65 7773 6c65 7474 6572 2f0a 5b4a 6f69  newsletter/.[Joi
+00001fe0: 6e20 536c 6163 6b5d 3a20 6874 7470 733a  n Slack]: https:
+00001ff0: 2f2f 7a65 6e6d 6c2e 696f 2f73 6c61 636b  //zenml.io/slack
+00002000: 2d69 6e76 6974 652f 0a5b 526f 6164 6d61  -invite/.[Roadma
+00002010: 705d 3a20 6874 7470 733a 2f2f 7a65 6e6d  p]: https://zenm
+00002020: 6c2e 696f 2f72 6f61 646d 6170 0a5b 436f  l.io/roadmap.[Co
+00002030: 6e74 7269 6275 7465 5d3a 2068 7474 7073  ntribute]: https
+00002040: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
+00002050: 6e6d 6c2d 696f 2f7a 656e 6d6c 2f62 6c6f  nml-io/zenml/blo
+00002060: 622f 6d61 696e 2f43 4f4e 5452 4942 5554  b/main/CONTRIBUT
+00002070: 494e 472e 6d64 0a0a 2320 f09f 8eae 2046  ING.md..# .... F
+00002080: 6561 7475 7265 730a 0a23 2323 2031 2e20  eatures..### 1. 
+00002090: f09f 92aa 2057 7269 7465 206c 6f63 616c  .... Write local
+000020a0: 2c20 7275 6e20 616e 7977 6865 7265 0a0a  , run anywhere..
+000020b0: 596f 7520 6f6e 6c79 206e 6565 6420 746f  You only need to
+000020c0: 2077 7269 7465 2079 6f75 7220 636f 7265   write your core
+000020d0: 206d 6163 6869 6e65 206c 6561 726e 696e   machine learnin
+000020e0: 6720 776f 726b 666c 6f77 2063 6f64 6520  g workflow code 
+000020f0: 6f6e 6365 2c20 6275 7420 796f 750a 6361  once, but you.ca
+00002100: 6e20 7275 6e20 6974 2061 6e79 7768 6572  n run it anywher
+00002110: 652e 2057 6520 6465 636f 7570 6c65 2079  e. We decouple y
+00002120: 6f75 7220 636f 6465 2066 726f 6d20 7468  our code from th
+00002130: 6520 656e 7669 726f 6e6d 656e 7420 616e  e environment an
+00002140: 640a 696e 6672 6173 7472 7563 7475 7265  d.infrastructure
+00002150: 206f 6e20 7768 6963 6820 7468 6973 2063   on which this c
+00002160: 6f64 6520 7275 6e73 2e0a 0a53 7769 7463  ode runs...Switc
+00002170: 6869 6e67 2066 726f 6d20 6c6f 6361 6c20  hing from local 
+00002180: 6578 7065 7269 6d65 6e74 7320 746f 2063  experiments to c
+00002190: 6c6f 7564 2d62 6173 6564 2070 6970 656c  loud-based pipel
+000021a0: 696e 6573 2064 6f65 736e 2774 206e 6565  ines doesn't nee
+000021b0: 6420 746f 2062 650a 636f 6d70 6c69 6361  d to be.complica
+000021c0: 7465 642e 205a 656e 4d4c 2073 7570 706f  ted. ZenML suppo
+000021d0: 7274 7320 7275 6e6e 696e 6720 7069 7065  rts running pipe
+000021e0: 6c69 6e65 7320 7768 6572 6576 6572 2079  lines wherever y
+000021f0: 6f75 2077 616e 742c 2066 6f72 2065 7861  ou want, for exa
+00002200: 6d70 6c65 2062 790a 7573 696e 6720 4b75  mple by.using Ku
+00002210: 6265 666c 6f77 2c20 6f6e 6520 6f66 206f  beflow, one of o
+00002220: 7572 2062 7569 6c74 2d69 6e20 696e 7465  ur built-in inte
+00002230: 6772 6174 696f 6e73 2c20 6f72 2061 6e79  grations, or any
+00002240: 206f 7263 6865 7374 7261 746f 7220 6f66   orchestrator of
+00002250: 2079 6f75 720a 6368 6f69 6365 2e20 5377   your.choice. Sw
+00002260: 6974 6368 696e 6720 6672 6f6d 2079 6f75  itching from you
+00002270: 7220 6c6f 6361 6c20 7374 6163 6b20 746f  r local stack to
+00002280: 2061 2063 6c6f 7564 2073 7461 636b 2069   a cloud stack i
+00002290: 7320 6561 7379 2074 6f20 646f 2077 6974  s easy to do wit
+000022a0: 6820 6f75 720a 434c 4920 746f 6f6c 2e0a  h our.CLI tool..
+000022b0: 0a21 5b59 6f75 2063 616e 2072 756e 2079  .![You can run y
+000022c0: 6f75 7220 7069 7065 6c69 6e65 7320 6c6f  our pipelines lo
+000022d0: 6361 6c6c 7920 6f72 2069 6e20 7468 650a  cally or in the.
+000022e0: 636c 6f75 645d 2864 6f63 732f 626f 6f6b  cloud](docs/book
+000022f0: 2f61 7373 6574 732f 636f 7265 5f63 6f6e  /assets/core_con
+00002300: 6365 7074 732f 636f 6e63 6570 7473 2d33  cepts/concepts-3
+00002310: 2e70 6e67 290a 0a23 2323 2032 2e20 f09f  .png)..### 2. ..
+00002320: 8c88 2041 6c6c 2079 6f75 7220 4d4c 4f70  .. All your MLOp
+00002330: 7320 7374 6163 6b73 2069 6e20 6f6e 6520  s stacks in one 
+00002340: 706c 6163 650a 0a4f 6e63 6520 636f 6465  place..Once code
+00002350: 2069 7320 6f72 6761 6e69 7a65 6420 696e   is organized in
+00002360: 746f 2061 205a 656e 4d4c 2070 6970 656c  to a ZenML pipel
+00002370: 696e 652c 2079 6f75 2063 616e 2073 7570  ine, you can sup
+00002380: 6572 6368 6172 6765 2079 6f75 7220 4d4c  ercharge your ML
+00002390: 0a64 6576 656c 6f70 6d65 6e74 2077 6974  .development wit
+000023a0: 6820 5b70 6f77 6572 6675 6c0a 696e 7465  h [powerful.inte
+000023b0: 6772 6174 696f 6e73 5d28 6874 7470 733a  grations](https:
+000023c0: 2f2f 646f 6373 2e7a 656e 6d6c 2e69 6f2f  //docs.zenml.io/
+000023d0: 6665 6174 7572 6573 2f69 6e74 6567 7261  features/integra
+000023e0: 7469 6f6e 7329 206f 6e20 6d75 6c74 6970  tions) on multip
+000023f0: 6c65 205b 4d4c 4f70 730a 7374 6163 6b73  le [MLOps.stacks
+00002400: 5d28 6874 7470 733a 2f2f 646f 6373 2e7a  ](https://docs.z
+00002410: 656e 6d6c 2e69 6f2f 636f 7265 2d63 6f6e  enml.io/core-con
+00002420: 6365 7074 7329 2e20 5468 6572 6520 6172  cepts). There ar
+00002430: 6520 6c6f 7473 206f 6620 6d6f 7669 6e67  e lots of moving
+00002440: 2070 6172 7473 2066 6f72 0a61 6c6c 2074   parts for.all t
+00002450: 6865 204d 4c4f 7073 2074 6f6f 6c69 6e67  he MLOps tooling
+00002460: 2061 6e64 2069 6e66 7261 7374 7275 6374   and infrastruct
+00002470: 7572 6520 796f 7520 7265 7175 6972 6520  ure you require 
+00002480: 666f 7220 4d4c 2069 6e20 7072 6f64 7563  for ML in produc
+00002490: 7469 6f6e 2061 6e64 0a5a 656e 4d4c 2061  tion and.ZenML a
+000024a0: 696d 7320 746f 2062 7269 6e67 2069 7420  ims to bring it 
+000024b0: 616c 6c20 746f 6765 7468 6572 2075 6e64  all together und
+000024c0: 6572 206f 6e65 2072 6f6f 662e 0a0a 5765  er one roof...We
+000024d0: 2061 6c72 6561 6479 2073 7570 706f 7274   already support
+000024e0: 2063 6f6d 6d6f 6e20 7573 6520 6361 7365   common use case
+000024f0: 7320 616e 6420 696e 7465 6772 6174 696f  s and integratio
+00002500: 6e73 2074 6f20 7374 616e 6461 7264 204d  ns to standard M
+00002510: 4c20 746f 6f6c 7320 7669 610a 6f75 7220  L tools via.our 
+00002520: 7374 6163 6b20 636f 6d70 6f6e 656e 7473  stack components
+00002530: 2c20 6672 6f6d 206f 7263 6865 7374 7261  , from orchestra
+00002540: 746f 7273 206c 696b 6520 4169 7266 6c6f  tors like Airflo
+00002550: 7720 616e 6420 4b75 6265 666c 6f77 2074  w and Kubeflow t
+00002560: 6f20 6d6f 6465 6c0a 6465 706c 6f79 6d65  o model.deployme
+00002570: 6e74 2076 6961 204d 4c66 6c6f 7720 6f72  nt via MLflow or
+00002580: 2053 656c 646f 6e20 436f 7265 2c20 746f   Seldon Core, to
+00002590: 2063 7573 746f 6d20 696e 6672 6173 7472   custom infrastr
+000025a0: 7563 7475 7265 2066 6f72 2074 7261 696e  ucture for train
+000025b0: 696e 6720 796f 7572 0a6d 6f64 656c 7320  ing your.models 
+000025c0: 696e 2074 6865 2063 6c6f 7564 2061 6e64  in the cloud and
+000025d0: 2073 6f20 6f6e 2e20 4966 2079 6f75 2077   so on. If you w
+000025e0: 616e 7420 746f 206c 6561 726e 206d 6f72  ant to learn mor
+000025f0: 6520 6162 6f75 7420 6f75 7220 696e 7465  e about our inte
+00002600: 6772 6174 696f 6e73 2c0a 6368 6563 6b20  grations,.check 
+00002610: 6f75 7420 5b6f 7572 2045 7861 6d70 6c65  out [our Example
+00002620: 735d 2868 7474 7073 3a2f 2f67 6974 6875  s](https://githu
+00002630: 622e 636f 6d2f 7a65 6e6d 6c2d 696f 2f7a  b.com/zenml-io/z
+00002640: 656e 6d6c 2f74 7265 652f 6d61 696e 2f65  enml/tree/main/e
+00002650: 7861 6d70 6c65 7329 0a74 6f20 7365 6520  xamples).to see 
+00002660: 686f 7720 7468 6579 2077 6f72 6b2e 0a0a  how they work...
+00002670: 215b 5a65 6e4d 4c20 6973 2074 6865 2067  ![ZenML is the g
+00002680: 6c75 655d 2864 6f63 732f 626f 6f6b 2f61  lue](docs/book/a
+00002690: 7373 6574 732f 7374 6163 6b2d 6c69 7374  ssets/stack-list
+000026a0: 2e70 6e67 290a 0a23 2323 2033 2e20 f09f  .png)..### 3. ..
+000026b0: 9ba0 2045 7874 656e 7369 6269 6c69 7479  .. Extensibility
+000026c0: 0a0a 5a65 6e4d 4c27 7320 5374 6163 6b20  ..ZenML's Stack 
+000026d0: 436f 6d70 6f6e 656e 7473 2061 7265 2062  Components are b
+000026e0: 7569 6c74 2074 6f20 7375 7070 6f72 7420  uilt to support 
+000026f0: 6d6f 7374 206d 6163 6869 6e65 206c 6561  most machine lea
+00002700: 726e 696e 6720 7573 6520 6361 7365 732e  rning use cases.
+00002710: 0a57 6520 6f66 6665 7220 6120 6261 7474  .We offer a batt
+00002720: 6572 6965 732d 696e 636c 7564 6564 2069  eries-included i
+00002730: 6e69 7469 616c 2069 6e73 7461 6c6c 6174  nitial installat
+00002740: 696f 6e20 7468 6174 2073 686f 756c 6420  ion that should 
+00002750: 7365 7276 6520 6d61 6e79 206e 6565 6473  serve many needs
+00002760: 0a61 6e64 2077 6f72 6b66 6c6f 7773 2c20  .and workflows, 
+00002770: 6275 7420 6966 2079 6f75 206e 6565 6420  but if you need 
+00002780: 6120 7370 6563 6961 6c20 6b69 6e64 206f  a special kind o
+00002790: 6620 6d6f 6e69 746f 7269 6e67 2074 6f6f  f monitoring too
+000027a0: 6c20 6164 6465 642c 2066 6f72 0a65 7861  l added, for.exa
+000027b0: 6d70 6c65 2c20 6f72 2061 2064 6966 6665  mple, or a diffe
+000027c0: 7265 6e74 206f 7263 6865 7374 7261 746f  rent orchestrato
+000027d0: 7220 746f 2072 756e 2079 6f75 7220 7069  r to run your pi
+000027e0: 7065 6c69 6e65 732c 205a 656e 4d4c 2069  pelines, ZenML i
+000027f0: 7320 6275 696c 7420 6173 2061 0a66 7261  s built as a.fra
+00002800: 6d65 776f 726b 206d 616b 696e 6720 6974  mework making it
+00002810: 2065 6173 7920 746f 2065 7874 656e 6420   easy to extend 
+00002820: 616e 6420 6275 696c 6420 6f75 7420 7768  and build out wh
+00002830: 6174 6576 6572 2079 6f75 206e 6565 642e  atever you need.
+00002840: 0a0a 215b 5a65 6e4d 4c20 6973 2066 756c  ..![ZenML is ful
+00002850: 6c79 2065 7874 656e 7369 626c 655d 2864  ly extensible](d
+00002860: 6f63 732f 626f 6f6b 2f61 7373 6574 732f  ocs/book/assets/
+00002870: 6578 7465 6e73 6962 696c 6974 792e 6769  extensibility.gi
+00002880: 6629 0a0a 2323 2320 342e 20f0 9f94 8d20  f)..### 4. .... 
+00002890: 4175 746f 6d61 7465 6420 6d65 7461 6461  Automated metada
+000028a0: 7461 2074 7261 636b 696e 670a 0a5a 656e  ta tracking..Zen
+000028b0: 4d4c 2074 7261 636b 7320 6d65 7461 6461  ML tracks metada
+000028c0: 7461 2066 6f72 2061 6c6c 2074 6865 2070  ta for all the p
+000028d0: 6970 656c 696e 6573 2079 6f75 2072 756e  ipelines you run
+000028e0: 2e20 5468 6973 2065 6e73 7572 6573 2074  . This ensures t
+000028f0: 6861 743a 0a0a 2d20 436f 6465 2069 7320  hat:..- Code is 
+00002900: 7665 7273 696f 6e65 640a 2d20 4461 7461  versioned.- Data
+00002910: 2069 7320 7665 7273 696f 6e65 640a 2d20   is versioned.- 
+00002920: 4d6f 6465 6c73 2061 7265 2076 6572 7369  Models are versi
+00002930: 6f6e 6564 0a2d 2043 6f6e 6669 6775 7261  oned.- Configura
+00002940: 7469 6f6e 7320 6172 6520 7665 7273 696f  tions are versio
+00002950: 6e65 640a 0a54 6869 7320 616c 736f 2065  ned..This also e
+00002960: 6e61 626c 6573 2063 6163 6869 6e67 206f  nables caching o
+00002970: 6620 7468 6520 6461 7461 2074 6861 7420  f the data that 
+00002980: 706f 7765 7273 2079 6f75 7220 7069 7065  powers your pipe
+00002990: 6c69 6e65 7320 7768 6963 6820 6865 6c70  lines which help
+000029a0: 7320 796f 750a 6974 6572 6174 6520 7175  s you.iterate qu
+000029b0: 6963 6b6c 7920 7468 726f 7567 6820 4d4c  ickly through ML
+000029c0: 2065 7870 6572 696d 656e 7473 2e20 2852   experiments. (R
+000029d0: 6561 6420 5b6f 7572 0a62 6c6f 6770 6f73  ead [our.blogpos
+000029e0: 745d 2868 7474 7073 3a2f 2f62 6c6f 672e  t](https://blog.
+000029f0: 7a65 6e6d 6c2e 696f 2f63 6163 6869 6e67  zenml.io/caching
+00002a00: 2d6d 6c2d 7069 7065 6c69 6e65 732f 2920  -ml-pipelines/) 
+00002a10: 746f 206c 6561 726e 206d 6f72 6521 290a  to learn more!).
+00002a20: 0a21 5b56 6973 7561 6c69 7a65 2079 6f75  .![Visualize you
+00002a30: 7220 7069 7065 6c69 6e65 2073 7465 7073  r pipeline steps
+00002a40: 5d28 646f 6373 2f62 6f6f 6b2f 6173 7365  ](docs/book/asse
+00002a50: 7473 2f64 6167 2d76 6973 7561 6c69 7a65  ts/dag-visualize
+00002a60: 722e 706e 6729 0a0a 2323 2320 352e 20e2  r.png)..### 5. .
+00002a70: 9ebf 2043 6f6e 7469 6e75 6f75 7320 5472  .. Continuous Tr
+00002a80: 6169 6e69 6e67 2061 6e64 2043 6f6e 7469  aining and Conti
+00002a90: 6e75 6f75 7320 4465 706c 6f79 6d65 6e74  nuous Deployment
+00002aa0: 2028 4354 2f43 4429 0a0a 436f 6e74 696e   (CT/CD)..Contin
+00002ab0: 756f 7573 2054 7261 696e 696e 6720 2843  uous Training (C
+00002ac0: 5429 2072 6566 6572 7320 746f 2074 6865  T) refers to the
+00002ad0: 2070 6172 6164 6967 6d20 7768 6572 6520   paradigm where 
+00002ae0: 6120 7465 616d 2064 6570 6c6f 7973 2074  a team deploys t
+00002af0: 7261 696e 696e 6720 7069 7065 6c69 6e65  raining pipeline
+00002b00: 7320 0a74 6861 7420 7275 6e20 6175 746f  s .that run auto
+00002b10: 6d61 7469 6361 6c6c 7920 746f 2074 7261  matically to tra
+00002b20: 696e 206d 6f64 656c 7320 6f6e 206e 6577  in models on new
+00002b30: 2028 6672 6573 6829 2064 6174 612e 2043   (fresh) data. C
+00002b40: 6f6e 7469 6e75 6f75 7320 4465 706c 6f79  ontinuous Deploy
+00002b50: 6d65 6e74 2028 4344 2920 0a72 6566 6572  ment (CD) .refer
+00002b60: 7320 746f 2074 6865 2070 6172 6164 6967  s to the paradig
+00002b70: 6d20 7768 6572 6520 6e65 776c 7920 7472  m where newly tr
+00002b80: 6169 6e65 6420 6d6f 6465 6c73 2061 7265  ained models are
+00002b90: 2061 7574 6f6d 6174 6963 616c 6c79 2064   automatically d
+00002ba0: 6570 6c6f 7965 6420 746f 2061 2070 7265  eployed to a pre
+00002bb0: 6469 6374 696f 6e20 0a73 6572 7669 6365  diction .service
+00002bc0: 2f73 6572 7665 720a 0a5a 656e 4d4c 2065  /server..ZenML e
+00002bd0: 6e61 626c 6564 2043 542f 4344 2062 7920  nabled CT/CD by 
+00002be0: 656e 6162 6c69 6e67 2074 6865 206d 6f64  enabling the mod
+00002bf0: 656c 2070 7265 7061 7261 7469 6f6e 2061  el preparation a
+00002c00: 6e64 206d 6f64 656c 2074 7261 696e 696e  nd model trainin
+00002c10: 6720 7769 7468 206d 6f64 656c 2064 6570  g with model dep
+00002c20: 6c6f 796d 656e 742e 200a 5769 7468 2074  loyment. .With t
+00002c30: 6865 2062 7569 6c74 2d69 6e20 6675 6e63  he built-in func
+00002c40: 7469 6f6e 616c 6974 6965 7320 6c69 6b65  tionalities like
+00002c50: 2053 6368 6564 756c 6573 2c20 4d6f 6465   Schedules, Mode
+00002c60: 6c20 4465 706c 6f79 6572 7320 616e 6420  l Deployers and 
+00002c70: 5365 7276 6963 6573 2079 6f75 2063 616e  Services you can
+00002c80: 200a 6372 6561 7465 2065 6e64 2d74 6f2d   .create end-to-
+00002c90: 656e 6420 4d4c 2077 6f72 6b66 6c6f 7773  end ML workflows
+00002ca0: 2077 6974 6820 436f 6e74 696e 756f 7573   with Continuous
+00002cb0: 2054 7261 696e 696e 6720 616e 6420 4465   Training and De
+00002cc0: 706c 6f79 6d65 6e74 2074 6861 7420 6465  ployment that de
+00002cd0: 706c 6f79 7320 796f 7572 200a 6d6f 6465  ploys your .mode
+00002ce0: 6c20 696e 2061 206c 6f63 616c 2065 6e76  l in a local env
+00002cf0: 6972 6f6e 6d65 6e74 2077 6974 6820 4d4c  ironment with ML
+00002d00: 466c 6f77 2069 6e74 6567 7261 7469 6f6e  Flow integration
+00002d10: 206f 7220 6576 656e 2069 6e20 6120 7072   or even in a pr
+00002d20: 6f64 7563 7469 6f6e 2d67 7261 6465 2065  oduction-grade e
+00002d30: 6e76 6972 6f6e 6d65 6e74 200a 6c69 6b65  nvironment .like
+00002d40: 204b 7562 6572 6e65 7465 7320 7769 7468   Kubernetes with
+00002d50: 206f 7572 2053 656c 646f 6e20 436f 7265   our Seldon Core
+00002d60: 2069 6e74 6567 7261 7469 6f6e 2e20 596f   integration. Yo
+00002d70: 7520 6361 6e20 616c 736f 206c 6973 7465  u can also liste
+00002d80: 6420 7365 7276 6564 206d 6f64 656c 7320  d served models 
+00002d90: 7769 7468 2074 6865 2043 4c49 3a0a 0a21  with the CLI:..!
+00002da0: 5b43 492f 4344 2f43 5420 696e 205a 656e  [CI/CD/CT in Zen
+00002db0: 4d4c 5d28 646f 6373 2f62 6f6f 6b2f 6173  ML](docs/book/as
+00002dc0: 7365 7473 2f63 745f 6364 5f7a 656e 6d6c  sets/ct_cd_zenml
+00002dd0: 2e67 6966 290a 0a60 6060 0a7a 656e 6d6c  .gif)..```.zenml
+00002de0: 2073 6572 7665 642d 6d6f 6465 6c73 206c   served-models l
+00002df0: 6973 740a 6060 600a 0a52 6561 6420 6d6f  ist.```..Read mo
+00002e00: 7265 2061 626f 7574 2043 542f 4344 2069  re about CT/CD i
+00002e10: 6e20 5a65 6e4d 4c20 5b68 6572 655d 2868  n ZenML [here](h
+00002e20: 7474 7073 3a2f 2f62 6c6f 672e 7a65 6e6d  ttps://blog.zenm
+00002e30: 6c2e 696f 2f63 692d 6374 2d63 642d 7769  l.io/ci-ct-cd-wi
+00002e40: 7468 2d7a 656e 6d6c 2f29 2e0a 0a23 20f0  th-zenml/)...# .
+00002e50: 9fa4 b820 4765 7474 696e 6720 5374 6172  ... Getting Star
+00002e60: 7465 640a 0a23 2320 f09f 92be 2049 6e73  ted..## .... Ins
+00002e70: 7461 6c6c 205a 656e 4d4c 0a0a 2a52 6571  tall ZenML..*Req
+00002e80: 7569 7265 6d65 6e74 732a 3a20 5a65 6e4d  uirements*: ZenM
+00002e90: 4c20 7375 7070 6f72 7473 2050 7974 686f  L supports Pytho
+00002ea0: 6e20 332e 372c 2033 2e38 2c20 616e 6420  n 3.7, 3.8, and 
+00002eb0: 332e 392e 0a0a 5a65 6e4d 4c20 6973 2061  3.9...ZenML is a
+00002ec0: 7661 696c 6162 6c65 2066 6f72 2065 6173  vailable for eas
+00002ed0: 7920 696e 7374 616c 6c61 7469 6f6e 2069  y installation i
+00002ee0: 6e74 6f20 796f 7572 2065 6e76 6972 6f6e  nto your environ
+00002ef0: 6d65 6e74 2076 6961 2050 7950 493a 0a0a  ment via PyPI:..
+00002f00: 6060 6062 6173 680a 7069 7020 696e 7374  ```bash.pip inst
+00002f10: 616c 6c20 7a65 6e6d 6c0a 6060 600a 0a41  all zenml.```..A
+00002f20: 6c74 6572 6e61 7469 7665 6c79 2c20 6966  lternatively, if
+00002f30: 2079 6f75 e280 9972 6520 6665 656c 696e   you...re feelin
+00002f40: 6720 6272 6176 652c 2066 6565 6c20 6672  g brave, feel fr
+00002f50: 6565 2074 6f20 696e 7374 616c 6c20 7468  ee to install th
+00002f60: 6520 626c 6565 6469 6e67 2065 6467 653a  e bleeding edge:
+00002f70: 0a2a 2a4e 4f54 453a 2a2a 2044 6f20 736f  .**NOTE:** Do so
+00002f80: 206f 6e20 796f 7572 206f 776e 2072 6973   on your own ris
+00002f90: 6b2c 206e 6f20 6775 6172 616e 7465 6573  k, no guarantees
+00002fa0: 2067 6976 656e 210a 0a60 6060 6261 7368   given!..```bash
+00002fb0: 0a70 6970 2069 6e73 7461 6c6c 2067 6974  .pip install git
+00002fc0: 2b68 7474 7073 3a2f 2f67 6974 6875 622e  +https://github.
+00002fd0: 636f 6d2f 7a65 6e6d 6c2d 696f 2f7a 656e  com/zenml-io/zen
+00002fe0: 6d6c 2e67 6974 406d 6169 6e20 2d2d 7570  ml.git@main --up
+00002ff0: 6772 6164 650a 6060 600a 0a5a 656e 4d4c  grade.```..ZenML
+00003000: 2069 7320 616c 736f 2061 7661 696c 6162   is also availab
+00003010: 6c65 2061 7320 6120 446f 636b 6572 2069  le as a Docker i
+00003020: 6d61 6765 2068 6f73 7465 6420 7075 626c  mage hosted publ
+00003030: 6963 6c79 206f 6e0a 5b44 6f63 6b65 7248  icly on.[DockerH
+00003040: 7562 5d28 6874 7470 733a 2f2f 6875 622e  ub](https://hub.
+00003050: 646f 636b 6572 2e63 6f6d 2f72 2f7a 656e  docker.com/r/zen
+00003060: 6d6c 646f 636b 6572 2f7a 656e 6d6c 292e  mldocker/zenml).
+00003070: 2055 7365 2074 6865 2066 6f6c 6c6f 7769   Use the followi
+00003080: 6e67 0a63 6f6d 6d61 6e64 2074 6f20 6765  ng.command to ge
+00003090: 7420 7374 6172 7465 6420 696e 2061 2062  t started in a b
+000030a0: 6173 6820 656e 7669 726f 6e6d 656e 743a  ash environment:
+000030b0: 0a0a 6060 6073 6865 6c6c 0a64 6f63 6b65  ..```shell.docke
+000030c0: 7220 7275 6e20 2d69 7420 7a65 6e6d 6c64  r run -it zenmld
+000030d0: 6f63 6b65 722f 7a65 6e6d 6c20 2f62 696e  ocker/zenml /bin
+000030e0: 2f62 6173 680a 6060 600a 0a23 2323 20f0  /bash.```..### .
+000030f0: 9f90 9b20 4b6e 6f77 6e20 696e 7374 616c  ... Known instal
+00003100: 6c61 7469 6f6e 2069 7373 7565 7320 666f  lation issues fo
+00003110: 7220 4d31 204d 6163 2055 7365 7273 0a0a  r M1 Mac Users..
+00003120: 4966 2079 6f75 2068 6176 6520 6120 4d31  If you have a M1
+00003130: 204d 6163 206d 6163 6869 6e65 2061 6e64   Mac machine and
+00003140: 2079 6f75 2061 7265 2065 6e63 6f75 6e74   you are encount
+00003150: 6572 696e 6720 616e 2065 7272 6f72 2077  ering an error w
+00003160: 6869 6c65 2074 7279 696e 6720 746f 2069  hile trying to i
+00003170: 6e73 7461 6c6c 205a 656e 4d4c 2c20 0a70  nstall ZenML, .p
+00003180: 6c65 6173 6520 7472 7920 746f 2073 6574  lease try to set
+00003190: 7570 2060 6272 6577 6020 616e 6420 6070  up `brew` and `p
+000031a0: 7965 6e76 6020 7769 7468 2052 6f73 6574  yenv` with Roset
+000031b0: 7461 2032 2061 6e64 2074 6865 6e20 696e  ta 2 and then in
+000031c0: 7374 616c 6c20 5a65 6e4d 4c2e 2054 6865  stall ZenML. The
+000031d0: 2069 7373 7565 2061 7269 7365 7320 6265   issue arises be
+000031e0: 6361 7573 6520 736f 6d65 206f 6620 7468  cause some of th
+000031f0: 6520 6465 7065 6e64 656e 6369 6573 200a  e dependencies .
+00003200: 6172 656e e280 9974 2066 756c 6c79 2063  aren...t fully c
+00003210: 6f6d 7061 7469 626c 6520 7769 7468 2074  ompatible with t
+00003220: 6865 2076 616e 696c 6c61 2041 524d 3634  he vanilla ARM64
+00003230: 2041 7263 6869 7465 6374 7572 652e 2054   Architecture. T
+00003240: 6865 2066 6f6c 6c6f 7769 6e67 206c 696e  he following lin
+00003250: 6b73 206d 6179 2062 6520 6865 6c70 6675  ks may be helpfu
+00003260: 6c20 2854 6861 6e6b 2079 6f75 2040 5265  l (Thank you @Re
+00003270: 6964 2046 616c 636f 6e65 7229 203a 0a0a  id Falconer) :..
+00003280: 2d20 5b50 7965 6e76 2077 6974 6820 4170  - [Pyenv with Ap
+00003290: 706c 6520 5369 6c69 636f 6e5d 2868 7474  ple Silicon](htt
+000032a0: 703a 2f2f 7369 7874 792d 6e6f 7274 682e  p://sixty-north.
+000032b0: 636f 6d2f 626c 6f67 2f70 7965 6e76 2d61  com/blog/pyenv-a
+000032c0: 7070 6c65 2d73 696c 6963 6f6e 2e68 746d  pple-silicon.htm
+000032d0: 6c29 0a2d 205b 496e 7374 616c 6c20 5079  l).- [Install Py
+000032e0: 7468 6f6e 2055 6e64 6572 2052 6f73 6574  thon Under Roset
+000032f0: 7461 2032 5d28 6874 7470 733a 2f2f 6d65  ta 2](https://me
+00003300: 6469 756d 2e63 6f6d 2f74 6869 6e6b 6e75  dium.com/thinknu
+00003310: 6d2f 686f 772d 746f 2d69 6e73 7461 6c6c  m/how-to-install
+00003320: 2d70 7974 686f 6e2d 756e 6465 722d 726f  -python-under-ro
+00003330: 7365 7474 612d 322d 6639 3863 3038 3635  setta-2-f98c0865
+00003340: 6530 3132 290a 0a23 2320 f09f 9a85 2051  e012)..## .... Q
+00003350: 7569 636b 7374 6172 740a 0a54 6865 2071  uickstart..The q
+00003360: 7569 636b 6573 7420 7761 7920 746f 2067  uickest way to g
+00003370: 6574 2073 7461 7274 6564 2069 7320 746f  et started is to
+00003380: 2063 7265 6174 6520 6120 7369 6d70 6c65   create a simple
+00003390: 2070 6970 656c 696e 652e 0a0a 2323 2323   pipeline...####
+000033a0: 2053 7465 7020 313a 2049 6e69 7469 616c   Step 1: Initial
+000033b0: 697a 6520 6120 5a65 6e4d 4c20 7265 706f  ize a ZenML repo
+000033c0: 0a0a 6060 6062 6173 680a 7a65 6e6d 6c20  ..```bash.zenml 
+000033d0: 696e 6974 0a7a 656e 6d6c 2069 6e74 6567  init.zenml integ
+000033e0: 7261 7469 6f6e 2069 6e73 7461 6c6c 2073  ration install s
+000033f0: 6b6c 6561 726e 202d 7920 2320 7765 2075  klearn -y # we u
+00003400: 7365 2073 6369 6b69 742d 6c65 6172 6e20  se scikit-learn 
+00003410: 666f 7220 7468 6973 2065 7861 6d70 6c65  for this example
+00003420: 0a60 6060 0a0a 2323 2323 2053 7465 7020  .```..#### Step 
+00003430: 323a 2041 7373 656d 626c 652c 2072 756e  2: Assemble, run
+00003440: 2c20 616e 6420 6576 616c 7561 7465 2079  , and evaluate y
+00003450: 6f75 7220 7069 7065 6c69 6e65 206c 6f63  our pipeline loc
+00003460: 616c 6c79 0a0a 6060 6070 7974 686f 6e0a  ally..```python.
+00003470: 696d 706f 7274 206e 756d 7079 2061 7320  import numpy as 
+00003480: 6e70 0a66 726f 6d20 736b 6c65 6172 6e2e  np.from sklearn.
+00003490: 6261 7365 2069 6d70 6f72 7420 436c 6173  base import Clas
+000034a0: 7369 6669 6572 4d69 7869 6e0a 0a66 726f  sifierMixin..fro
+000034b0: 6d20 7a65 6e6d 6c2e 696e 7465 6772 6174  m zenml.integrat
+000034c0: 696f 6e73 2e73 6b6c 6561 726e 2e68 656c  ions.sklearn.hel
+000034d0: 7065 7273 2e64 6967 6974 7320 696d 706f  pers.digits impo
+000034e0: 7274 2067 6574 5f64 6967 6974 732c 2067  rt get_digits, g
+000034f0: 6574 5f64 6967 6974 735f 6d6f 6465 6c0a  et_digits_model.
+00003500: 6672 6f6d 207a 656e 6d6c 2e70 6970 656c  from zenml.pipel
+00003510: 696e 6573 2069 6d70 6f72 7420 7069 7065  ines import pipe
+00003520: 6c69 6e65 0a66 726f 6d20 7a65 6e6d 6c2e  line.from zenml.
+00003530: 7374 6570 7320 696d 706f 7274 2073 7465  steps import ste
+00003540: 702c 204f 7574 7075 740a 0a40 7374 6570  p, Output..@step
+00003550: 0a64 6566 2069 6d70 6f72 7465 7228 2920  .def importer() 
+00003560: 2d3e 204f 7574 7075 7428 0a20 2020 2058  -> Output(.    X
+00003570: 5f74 7261 696e 3d6e 702e 6e64 6172 7261  _train=np.ndarra
+00003580: 792c 2058 5f74 6573 743d 6e70 2e6e 6461  y, X_test=np.nda
+00003590: 7272 6179 2c20 795f 7472 6169 6e3d 6e70  rray, y_train=np
+000035a0: 2e6e 6461 7272 6179 2c20 795f 7465 7374  .ndarray, y_test
+000035b0: 3d6e 702e 6e64 6172 7261 790a 293a 0a20  =np.ndarray.):. 
+000035c0: 2020 2022 2222 4c6f 6164 7320 7468 6520     """Loads the 
+000035d0: 6469 6769 7473 2061 7272 6179 2061 7320  digits array as 
+000035e0: 6e6f 726d 616c 206e 756d 7079 2061 7272  normal numpy arr
+000035f0: 6179 732e 2222 220a 2020 2020 585f 7472  ays.""".    X_tr
+00003600: 6169 6e2c 2058 5f74 6573 742c 2079 5f74  ain, X_test, y_t
+00003610: 7261 696e 2c20 795f 7465 7374 203d 2067  rain, y_test = g
+00003620: 6574 5f64 6967 6974 7328 290a 2020 2020  et_digits().    
+00003630: 7265 7475 726e 2058 5f74 7261 696e 2c20  return X_train, 
+00003640: 585f 7465 7374 2c20 795f 7472 6169 6e2c  X_test, y_train,
+00003650: 2079 5f74 6573 740a 0a0a 4073 7465 700a   y_test...@step.
+00003660: 6465 6620 7472 6169 6e65 7228 0a20 2020  def trainer(.   
+00003670: 2058 5f74 7261 696e 3a20 6e70 2e6e 6461   X_train: np.nda
+00003680: 7272 6179 2c0a 2020 2020 795f 7472 6169  rray,.    y_trai
+00003690: 6e3a 206e 702e 6e64 6172 7261 792c 0a29  n: np.ndarray,.)
+000036a0: 202d 3e20 436c 6173 7369 6669 6572 4d69   -> ClassifierMi
+000036b0: 7869 6e3a 0a20 2020 2022 2222 5472 6169  xin:.    """Trai
+000036c0: 6e20 6120 7369 6d70 6c65 2073 6b6c 6561  n a simple sklea
+000036d0: 726e 2063 6c61 7373 6966 6965 7220 666f  rn classifier fo
+000036e0: 7220 7468 6520 6469 6769 7473 2064 6174  r the digits dat
+000036f0: 6173 6574 2e22 2222 0a20 2020 206d 6f64  aset.""".    mod
+00003700: 656c 203d 2067 6574 5f64 6967 6974 735f  el = get_digits_
+00003710: 6d6f 6465 6c28 290a 2020 2020 6d6f 6465  model().    mode
+00003720: 6c2e 6669 7428 585f 7472 6169 6e2c 2079  l.fit(X_train, y
+00003730: 5f74 7261 696e 290a 2020 2020 7265 7475  _train).    retu
+00003740: 726e 206d 6f64 656c 0a0a 0a40 7374 6570  rn model...@step
+00003750: 0a64 6566 2065 7661 6c75 6174 6f72 280a  .def evaluator(.
+00003760: 2020 2020 585f 7465 7374 3a20 6e70 2e6e      X_test: np.n
+00003770: 6461 7272 6179 2c0a 2020 2020 795f 7465  darray,.    y_te
+00003780: 7374 3a20 6e70 2e6e 6461 7272 6179 2c0a  st: np.ndarray,.
+00003790: 2020 2020 6d6f 6465 6c3a 2043 6c61 7373      model: Class
+000037a0: 6966 6965 724d 6978 696e 2c0a 2920 2d3e  ifierMixin,.) ->
+000037b0: 2066 6c6f 6174 3a0a 2020 2020 2222 2243   float:.    """C
+000037c0: 616c 6375 6c61 7465 2074 6865 2061 6363  alculate the acc
+000037d0: 7572 6163 7920 6f6e 2074 6865 2074 6573  uracy on the tes
+000037e0: 7420 7365 7422 2222 0a20 2020 2074 6573  t set""".    tes
+000037f0: 745f 6163 6320 3d20 6d6f 6465 6c2e 7363  t_acc = model.sc
+00003800: 6f72 6528 585f 7465 7374 2c20 795f 7465  ore(X_test, y_te
+00003810: 7374 290a 2020 2020 7072 696e 7428 6622  st).    print(f"
+00003820: 5465 7374 2061 6363 7572 6163 793a 207b  Test accuracy: {
+00003830: 7465 7374 5f61 6363 7d22 290a 2020 2020  test_acc}").    
+00003840: 7265 7475 726e 2074 6573 745f 6163 630a  return test_acc.
+00003850: 0a0a 4070 6970 656c 696e 650a 6465 6620  ..@pipeline.def 
+00003860: 6d6e 6973 745f 7069 7065 6c69 6e65 280a  mnist_pipeline(.
+00003870: 2020 2020 696d 706f 7274 6572 2c0a 2020      importer,.  
+00003880: 2020 7472 6169 6e65 722c 0a20 2020 2065    trainer,.    e
+00003890: 7661 6c75 6174 6f72 2c0a 293a 0a20 2020  valuator,.):.   
+000038a0: 2022 2222 4c69 6e6b 7320 616c 6c20 7468   """Links all th
+000038b0: 6520 7374 6570 7320 746f 6765 7468 6572  e steps together
+000038c0: 2069 6e20 6120 7069 7065 6c69 6e65 2222   in a pipeline""
+000038d0: 220a 2020 2020 585f 7472 6169 6e2c 2058  ".    X_train, X
+000038e0: 5f74 6573 742c 2079 5f74 7261 696e 2c20  _test, y_train, 
+000038f0: 795f 7465 7374 203d 2069 6d70 6f72 7465  y_test = importe
+00003900: 7228 290a 2020 2020 6d6f 6465 6c20 3d20  r().    model = 
+00003910: 7472 6169 6e65 7228 585f 7472 6169 6e3d  trainer(X_train=
+00003920: 585f 7472 6169 6e2c 2079 5f74 7261 696e  X_train, y_train
+00003930: 3d79 5f74 7261 696e 290a 2020 2020 6576  =y_train).    ev
+00003940: 616c 7561 746f 7228 585f 7465 7374 3d58  aluator(X_test=X
+00003950: 5f74 6573 742c 2079 5f74 6573 743d 795f  _test, y_test=y_
+00003960: 7465 7374 2c20 6d6f 6465 6c3d 6d6f 6465  test, model=mode
+00003970: 6c29 0a0a 0a70 6970 656c 696e 6520 3d20  l)...pipeline = 
+00003980: 6d6e 6973 745f 7069 7065 6c69 6e65 280a  mnist_pipeline(.
+00003990: 2020 2020 696d 706f 7274 6572 3d69 6d70      importer=imp
+000039a0: 6f72 7465 7228 292c 0a20 2020 2074 7261  orter(),.    tra
+000039b0: 696e 6572 3d74 7261 696e 6572 2829 2c0a  iner=trainer(),.
+000039c0: 2020 2020 6576 616c 7561 746f 723d 6576      evaluator=ev
+000039d0: 616c 7561 746f 7228 292c 0a29 0a70 6970  aluator(),.).pip
+000039e0: 656c 696e 652e 7275 6e28 290a 6060 600a  eline.run().```.
+000039f0: 0a23 203a 7261 6365 686f 7273 653a 2047  .# :racehorse: G
+00003a00: 6574 2061 2067 7569 6465 6420 746f 7572  et a guided tour
+00003a10: 2077 6974 6820 607a 656e 6d6c 2067 6f60   with `zenml go`
+00003a20: 0a0a 466f 7220 6120 736c 6967 6874 6c79  ..For a slightly
+00003a30: 206d 6f72 6520 696e 2d64 6570 7468 2069   more in-depth i
+00003a40: 6e74 726f 6475 6374 696f 6e20 746f 205a  ntroduction to Z
+00003a50: 656e 4d4c 2c20 7461 7567 6874 2074 6872  enML, taught thr
+00003a60: 6f75 6768 204a 7570 7974 6572 0a6e 6f74  ough Jupyter.not
+00003a70: 6562 6f6f 6b73 2c20 696e 7374 616c 6c20  ebooks, install 
+00003a80: 607a 656e 6d6c 6020 7669 6120 7069 7020  `zenml` via pip 
+00003a90: 6173 2064 6573 6372 6962 6564 2061 626f  as described abo
+00003aa0: 7665 2061 6e64 2074 7970 653a 0a0a 6060  ve and type:..``
+00003ab0: 6073 6865 6c6c 0a7a 656e 6d6c 2067 6f0a  `shell.zenml go.
+00003ac0: 6060 600a 0a54 6869 7320 7769 6c6c 2073  ```..This will s
+00003ad0: 7069 6e20 7570 2061 204a 7570 7974 6572  pin up a Jupyter
+00003ae0: 206e 6f74 6562 6f6f 6b20 7468 6174 2073   notebook that s
+00003af0: 686f 7763 6173 6573 2074 6865 2061 626f  howcases the abo
+00003b00: 7665 2065 7861 6d70 6c65 2070 6c75 7320  ve example plus 
+00003b10: 6d6f 7265 0a6f 6e20 686f 7720 746f 2075  more.on how to u
+00003b20: 7365 2061 6e64 2065 7874 656e 6420 5a65  se and extend Ze
+00003b30: 6e4d 4c2e 0a0a 2320 f09f 91ad 2043 6f6c  nML...# .... Col
+00003b40: 6c61 626f 7261 7465 2077 6974 6820 796f  laborate with yo
+00003b50: 7572 2074 6561 6d0a 0a5a 656e 4d4c 2069  ur team..ZenML i
+00003b60: 7320 6275 696c 7420 746f 2073 7570 706f  s built to suppo
+00003b70: 7274 2074 6561 6d73 2077 6f72 6b69 6e67  rt teams working
+00003b80: 2074 6f67 6574 6865 722e 2054 6865 2075   together. The u
+00003b90: 6e64 6572 6c79 696e 6720 696e 6672 6173  nderlying infras
+00003ba0: 7472 7563 7475 7265 0a6f 6e20 7768 6963  tructure.on whic
+00003bb0: 6820 796f 7572 204d 4c20 776f 726b 666c  h your ML workfl
+00003bc0: 6f77 7320 7275 6e20 6361 6e20 6265 2073  ows run can be s
+00003bd0: 6861 7265 642c 2061 7320 6361 6e20 7468  hared, as can th
+00003be0: 6520 6461 7461 2c20 6173 7365 7473 2061  e data, assets a
+00003bf0: 6e64 0a61 7274 6966 6163 7473 2074 6861  nd.artifacts tha
+00003c00: 7420 796f 7520 6e65 6564 2074 6f20 656e  t you need to en
+00003c10: 6162 6c65 2079 6f75 7220 776f 726b 2e20  able your work. 
+00003c20: 5a65 6e4d 4c20 5072 6f66 696c 6573 206f  ZenML Profiles o
+00003c30: 6666 6572 2061 6e20 6561 7379 2077 6179  ffer an easy way
+00003c40: 2074 6f0a 6d61 6e61 6765 2061 6e64 2073   to.manage and s
+00003c50: 7769 7463 6820 6265 7477 6565 6e20 796f  witch between yo
+00003c60: 7572 2073 7461 636b 732e 2054 6865 205a  ur stacks. The Z
+00003c70: 656e 4d4c 2053 6572 7665 7220 6861 6e64  enML Server hand
+00003c80: 6c65 7320 616c 6c20 7468 650a 696e 7465  les all the.inte
+00003c90: 7261 6374 696f 6e20 616e 6420 7368 6172  raction and shar
+00003ca0: 696e 6720 616e 6420 796f 7520 6361 6e20  ing and you can 
+00003cb0: 686f 7374 2069 7420 7768 6572 6576 6572  host it wherever
+00003cc0: 2079 6f75 2764 206c 696b 652e 0a0a 6060   you'd like...``
+00003cd0: 600a 2320 4d61 6b65 2073 7572 6520 746f  `.# Make sure to
+00003ce0: 2069 6e73 7461 6c6c 205a 656e 4d4c 2077   install ZenML w
+00003cf0: 6974 6820 616c 6c20 6e65 6365 7373 6172  ith all necessar
+00003d00: 7920 7265 7175 6972 656d 656e 7473 2066  y requirements f
+00003d10: 6f72 2074 6865 205a 656e 5365 7276 6572  or the ZenServer
+00003d20: 0a70 6970 2069 6e73 7461 6c6c 207a 656e  .pip install zen
+00003d30: 6d6c 5b73 6572 7665 725d 0a7a 656e 6d6c  ml[server].zenml
+00003d40: 2073 6572 7665 7220 7570 0a60 6060 0a0a   server up.```..
+00003d50: 5265 6164 206d 6f72 6520 6162 6f75 7420  Read more about 
+00003d60: 636f 6c6c 6162 6f72 6174 696f 6e20 696e  collaboration in
+00003d70: 205a 656e 4d4c 205b 6865 7265 5d28 6874   ZenML [here](ht
+00003d80: 7470 733a 2f2f 646f 6373 2e7a 656e 6d6c  tps://docs.zenml
+00003d90: 2e69 6f2f 636f 6c6c 6162 6f72 6174 652f  .io/collaborate/
+00003da0: 636f 6c6c 6162 6f72 6174 6529 2e0a 0a23  collaborate)...#
+00003db0: 20f0 9f8d b020 5a65 6e42 7974 6573 0a0a   .... ZenBytes..
+00003dc0: 5b5a 656e 4279 7465 735d 2868 7474 7073  [ZenBytes](https
+00003dd0: 3a2f 2f67 6974 6875 622e 636f 6d2f 7a65  ://github.com/ze
+00003de0: 6e6d 6c2d 696f 2f7a 656e 6279 7465 7329  nml-io/zenbytes)
+00003df0: 2069 7320 6120 7365 7269 6573 206f 6620   is a series of 
+00003e00: 7368 6f72 7420 7072 6163 7469 6361 6c0a  short practical.
+00003e10: 4d4c 4f70 7320 6c65 7373 6f6e 7320 7468  MLOps lessons th
+00003e20: 726f 7567 6820 5a65 6e4d 4c20 616e 6420  rough ZenML and 
+00003e30: 6974 7320 7661 7269 6f75 7320 696e 7465  its various inte
+00003e40: 6772 6174 696f 6e73 2e20 4974 2069 7320  grations. It is 
+00003e50: 696e 7465 6e64 6564 2066 6f72 0a70 656f  intended for.peo
+00003e60: 706c 6520 6c6f 6f6b 696e 6720 746f 206c  ple looking to l
+00003e70: 6561 726e 2061 626f 7574 204d 4c4f 7073  earn about MLOps
+00003e80: 2067 656e 6572 616c 6c79 2c20 616e 6420   generally, and 
+00003e90: 616c 736f 2066 6f72 204d 4c20 7072 6163  also for ML prac
+00003ea0: 7469 7469 6f6e 6572 7320 7768 6f0a 7761  titioners who.wa
+00003eb0: 6e74 2074 6f20 6765 7420 7374 6172 7465  nt to get starte
+00003ec0: 6420 7769 7468 205a 656e 4d4c 2e0a 0a41  d with ZenML...A
+00003ed0: 6674 6572 2079 6f75 2776 6520 7275 6e20  fter you've run 
+00003ee0: 616e 6420 756e 6465 7273 746f 6f64 2074  and understood t
+00003ef0: 6865 2073 696d 706c 6520 6578 616d 706c  he simple exampl
+00003f00: 6520 6162 6f76 652c 2079 6f75 7220 6e65  e above, your ne
+00003f10: 7874 2070 6f72 7420 6f66 2063 616c 6c0a  xt port of call.
+00003f20: 6973 2070 726f 6261 626c 7920 6569 7468  is probably eith
+00003f30: 6572 2074 6865 205b 6675 6c6c 792d 666c  er the [fully-fl
+00003f40: 6573 6865 642d 6f75 7420 7175 6963 6b73  eshed-out quicks
+00003f50: 7461 7274 0a65 7861 6d70 6c65 5d28 6874  tart.example](ht
+00003f60: 7470 733a 2f2f 6769 7468 7562 2e63 6f6d  tps://github.com
+00003f70: 2f7a 656e 6d6c 2d69 6f2f 7a65 6e6d 6c2f  /zenml-io/zenml/
+00003f80: 7472 6565 2f6d 6169 6e2f 6578 616d 706c  tree/main/exampl
+00003f90: 6573 2f71 7569 636b 7374 6172 7429 2061  es/quickstart) a
+00003fa0: 6e64 0a74 6865 6e20 746f 206c 6f6f 6b20  nd.then to look 
+00003fb0: 6174 205b 7468 6520 5a65 6e42 7974 6573  at [the ZenBytes
+00003fc0: 2072 6570 6f73 6974 6f72 795d 2868 7474   repository](htt
+00003fd0: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
+00003fe0: 7a65 6e6d 6c2d 696f 2f7a 656e 6279 7465  zenml-io/zenbyte
+00003ff0: 7329 0a61 6e64 206e 6f74 6562 6f6f 6b73  s).and notebooks
+00004000: 2e0a 0a23 20f0 9f97 82ef b88f 205a 656e  ...# ....... Zen
+00004010: 4669 6c65 730a 0a5a 656e 4669 6c65 7320  Files..ZenFiles 
+00004020: 6172 6520 7072 6f64 7563 7469 6f6e 2d67  are production-g
+00004030: 7261 6465 204d 4c20 7573 652d 6361 7365  rade ML use-case
+00004040: 7320 706f 7765 7265 6420 6279 205a 656e  s powered by Zen
+00004050: 4d4c 2e20 5468 6579 2061 7265 2066 756c  ML. They are ful
+00004060: 6c79 0a66 6c65 7368 6564 206f 7574 2c20  ly.fleshed out, 
+00004070: 656e 642d 746f 2d65 6e64 2c20 7072 6f6a  end-to-end, proj
+00004080: 6563 7473 2074 6861 7420 7368 6f77 6361  ects that showca
+00004090: 7365 205a 656e 4d4c 2773 2063 6170 6162  se ZenML's capab
+000040a0: 696c 6974 6965 732e 2054 6865 7920 6361  ilities. They ca
+000040b0: 6e0a 616c 736f 2073 6572 7665 2061 7320  n.also serve as 
+000040c0: 6120 7465 6d70 6c61 7465 2066 726f 6d20  a template from 
+000040d0: 7768 6963 6820 746f 2073 7461 7274 2073  which to start s
+000040e0: 696d 696c 6172 2070 726f 6a65 6374 732e  imilar projects.
+000040f0: 0a0a 5468 6520 5a65 6e46 696c 6573 2070  ..The ZenFiles p
+00004100: 726f 6a65 6374 2069 7320 6675 6c6c 7920  roject is fully 
+00004110: 6d61 696e 7461 696e 6564 2061 6e64 2063  maintained and c
+00004120: 616e 2062 6520 7669 6577 6564 2061 7320  an be viewed as 
+00004130: 6120 7369 7374 6572 0a72 6570 6f73 6974  a sister.reposit
+00004140: 6f72 7920 6f66 205a 656e 4d4c 2e20 4368  ory of ZenML. Ch
+00004150: 6563 6b20 6974 206f 7574 205b 6865 7265  eck it out [here
+00004160: 5d28 6874 7470 733a 2f2f 6769 7468 7562  ](https://github
+00004170: 2e63 6f6d 2f7a 656e 6d6c 2d69 6f2f 7a65  .com/zenml-io/ze
+00004180: 6e66 696c 6573 292e 0a0a 2320 f09f 97ba  nfiles)...# ....
+00004190: 2052 6f61 646d 6170 0a0a 5a65 6e4d 4c20   Roadmap..ZenML 
+000041a0: 6973 2062 6569 6e67 2062 7569 6c74 2069  is being built i
+000041b0: 6e20 7075 626c 6963 2e20 5468 6520 5b72  n public. The [r
+000041c0: 6f61 646d 6170 5d28 6874 7470 733a 2f2f  oadmap](https://
+000041d0: 7a65 6e6d 6c2e 696f 2f72 6f61 646d 6170  zenml.io/roadmap
+000041e0: 2920 6973 2061 0a72 6567 756c 6172 6c79  ) is a.regularly
+000041f0: 2075 7064 6174 6564 2073 6f75 7263 6520   updated source 
+00004200: 6f66 2074 7275 7468 2066 6f72 2074 6865  of truth for the
+00004210: 205a 656e 4d4c 2063 6f6d 6d75 6e69 7479   ZenML community
+00004220: 2074 6f20 756e 6465 7273 7461 6e64 2077   to understand w
+00004230: 6865 7265 0a74 6865 2070 726f 6475 6374  here.the product
+00004240: 2069 7320 676f 696e 6720 696e 2074 6865   is going in the
+00004250: 2073 686f 7274 2c20 6d65 6469 756d 2c20   short, medium, 
+00004260: 616e 6420 6c6f 6e67 2074 6572 6d2e 0a0a  and long term...
+00004270: 5a65 6e4d 4c20 6973 206d 616e 6167 6564  ZenML is managed
+00004280: 2062 7920 6120 5b63 6f72 6520 7465 616d   by a [core team
+00004290: 5d28 6874 7470 733a 2f2f 7a65 6e6d 6c2e  ](https://zenml.
+000042a0: 696f 2f74 6561 6d29 206f 6620 6465 7665  io/team) of deve
+000042b0: 6c6f 7065 7273 2074 6861 7420 6172 650a  lopers that are.
+000042c0: 7265 7370 6f6e 7369 626c 6520 666f 7220  responsible for 
+000042d0: 6d61 6b69 6e67 206b 6579 2064 6563 6973  making key decis
+000042e0: 696f 6e73 2061 6e64 2069 6e63 6f72 706f  ions and incorpo
+000042f0: 7261 7469 6e67 2066 6565 6462 6163 6b20  rating feedback 
+00004300: 6672 6f6d 2074 6865 0a63 6f6d 6d75 6e69  from the.communi
+00004310: 7479 2e20 5468 6520 7465 616d 206f 7665  ty. The team ove
+00004320: 7273 6565 7320 6665 6564 6261 636b 2076  rsees feedback v
+00004330: 6961 2076 6172 696f 7573 2063 6861 6e6e  ia various chann
+00004340: 656c 732c 2061 6e64 2079 6f75 2063 616e  els, and you can
+00004350: 2064 6972 6563 746c 790a 696e 666c 7565   directly.influe
+00004360: 6e63 6520 7468 6520 726f 6164 6d61 7020  nce the roadmap 
+00004370: 6173 2066 6f6c 6c6f 7773 3a0a 0a2d 2056  as follows:..- V
+00004380: 6f74 6520 6f6e 2079 6f75 7220 6d6f 7374  ote on your most
+00004390: 2077 616e 7465 6420 6665 6174 7572 6520   wanted feature 
+000043a0: 6f6e 206f 7572 205b 4469 7363 7573 7369  on our [Discussi
+000043b0: 6f6e 0a20 2062 6f61 7264 5d28 6874 7470  on.  board](http
+000043c0: 733a 2f2f 7a65 6e6d 6c2e 696f 2f64 6973  s://zenml.io/dis
+000043d0: 6375 7373 696f 6e29 2e20 596f 7520 6361  cussion). You ca
+000043e0: 6e20 616c 736f 2072 6571 7565 7374 2066  n also request f
+000043f0: 6f72 206e 6577 2066 6561 7475 7265 7320  or new features 
+00004400: 6865 7265 2e0a 2d20 5374 6172 7420 6120  here..- Start a 
+00004410: 7468 7265 6164 2069 6e20 6f75 7220 5b53  thread in our [S
+00004420: 6c61 636b 2063 6861 6e6e 656c 5d28 6874  lack channel](ht
+00004430: 7470 733a 2f2f 7a65 6e6d 6c2e 696f 2f73  tps://zenml.io/s
+00004440: 6c61 636b 2d69 6e76 6974 6529 2e0a 0a23  lack-invite)...#
+00004450: 20f0 9f99 8be2 808d e299 80ef b88f 2043   ............. C
+00004460: 6f6e 7472 6962 7574 696e 6720 2620 436f  ontributing & Co
+00004470: 6d6d 756e 6974 790a 0a57 6520 776f 756c  mmunity..We woul
+00004480: 6420 6c6f 7665 2074 6f20 6465 7665 6c6f  d love to develo
+00004490: 7020 5a65 6e4d 4c20 746f 6765 7468 6572  p ZenML together
+000044a0: 2077 6974 6820 6f75 7220 636f 6d6d 756e   with our commun
+000044b0: 6974 7921 2042 6573 7420 7761 7920 746f  ity! Best way to
+000044c0: 2067 6574 0a73 7461 7274 6564 2069 7320   get.started is 
+000044d0: 746f 2073 656c 6563 7420 616e 7920 6973  to select any is
+000044e0: 7375 6520 6672 6f6d 2074 6865 205b 6067  sue from the [`g
+000044f0: 6f6f 642d 6669 7273 742d 6973 7375 6560  ood-first-issue`
+00004500: 0a6c 6162 656c 5d28 6874 7470 733a 2f2f  .label](https://
+00004510: 6769 7468 7562 2e63 6f6d 2f7a 656e 6d6c  github.com/zenml
+00004520: 2d69 6f2f 7a65 6e6d 6c2f 6c61 6265 6c73  -io/zenml/labels
+00004530: 2f67 6f6f 6425 3230 6669 7273 7425 3230  /good%20first%20
+00004540: 6973 7375 6529 2e20 4966 2079 6f75 0a77  issue). If you.w
+00004550: 6f75 6c64 206c 696b 6520 746f 2063 6f6e  ould like to con
+00004560: 7472 6962 7574 652c 2070 6c65 6173 6520  tribute, please 
+00004570: 7265 7669 6577 206f 7572 205b 436f 6e74  review our [Cont
+00004580: 7269 6275 7469 6e67 0a47 7569 6465 5d28  ributing.Guide](
+00004590: 434f 4e54 5249 4255 5449 4e47 2e6d 6429  CONTRIBUTING.md)
+000045a0: 2066 6f72 2061 6c6c 2072 656c 6576 616e   for all relevan
+000045b0: 7420 6465 7461 696c 732e 0a0a 3c62 723e  t details...<br>
+000045c0: 0a0a 215b 5265 706f 6265 6174 7320 616e  ..![Repobeats an
+000045d0: 616c 7974 6963 730a 696d 6167 655d 2868  alytics.image](h
+000045e0: 7474 7073 3a2f 2f72 6570 6f62 6561 7473  ttps://repobeats
+000045f0: 2e61 7869 6f6d 2e63 6f2f 6170 692f 656d  .axiom.co/api/em
+00004600: 6265 642f 3633 3563 3537 6237 3433 6566  bed/635c57b743ef
+00004610: 6536 3439 6361 6463 6562 6136 6132 6536  e649cadceba6a2e6
+00004620: 6139 3536 3636 3366 3936 6464 2e73 7667  a956663f96dd.svg
+00004630: 0a22 5265 706f 6265 6174 7320 616e 616c  ."Repobeats anal
+00004640: 7974 6963 7320 696d 6167 6522 290a 0a0a  ytics image")...
+00004650: 2320 f09f 8698 2057 6865 7265 2074 6f20  # .... Where to 
+00004660: 6765 7420 6865 6c70 0a0a 4669 7273 7420  get help..First 
+00004670: 706f 696e 7420 6f66 2063 616c 6c20 7368  point of call sh
+00004680: 6f75 6c64 2062 6520 5b6f 7572 2053 6c61  ould be [our Sla
+00004690: 636b 2067 726f 7570 5d28 6874 7470 733a  ck group](https:
+000046a0: 2f2f 7a65 6e6d 6c2e 696f 2f73 6c61 636b  //zenml.io/slack
+000046b0: 2d69 6e76 6974 652f 292e 0a41 736b 2079  -invite/)..Ask y
+000046c0: 6f75 7220 7175 6573 7469 6f6e 7320 6162  our questions ab
+000046d0: 6f75 7420 6275 6773 206f 7220 7370 6563  out bugs or spec
+000046e0: 6966 6963 2075 7365 2063 6173 6573 2061  ific use cases a
+000046f0: 6e64 2073 6f6d 656f 6e65 2066 726f 6d20  nd someone from 
+00004700: 7468 6520 636f 7265 0a74 6561 6d20 7769  the core.team wi
+00004710: 6c6c 2072 6573 706f 6e64 2e0a 0a23 20f0  ll respond...# .
+00004720: 9f93 9c20 4c69 6365 6e73 650a 0a5a 656e  ... License..Zen
+00004730: 4d4c 2069 7320 6469 7374 7269 6275 7465  ML is distribute
+00004740: 6420 756e 6465 7220 7468 6520 7465 726d  d under the term
+00004750: 7320 6f66 2074 6865 2041 7061 6368 6520  s of the Apache 
+00004760: 4c69 6365 6e73 6520 5665 7273 696f 6e20  License Version 
+00004770: 322e 302e 2041 0a63 6f6d 706c 6574 6520  2.0. A.complete 
+00004780: 7665 7273 696f 6e20 6f66 2074 6865 206c  version of the l
+00004790: 6963 656e 7365 2069 7320 6176 6169 6c61  icense is availa
+000047a0: 626c 6520 696e 2074 6865 205b 4c49 4345  ble in the [LICE
+000047b0: 4e53 452e 6d64 5d28 4c49 4345 4e53 452e  NSE.md](LICENSE.
+000047c0: 6d64 2920 696e 0a74 6869 7320 7265 706f  md) in.this repo
+000047d0: 7369 746f 7279 2e20 416e 7920 636f 6e74  sitory. Any cont
+000047e0: 7269 6275 7469 6f6e 206d 6164 6520 746f  ribution made to
+000047f0: 2074 6869 7320 7072 6f6a 6563 7420 7769   this project wi
+00004800: 6c6c 2062 6520 6c69 6365 6e73 6564 2075  ll be licensed u
+00004810: 6e64 6572 0a74 6865 2041 7061 6368 6520  nder.the Apache 
+00004820: 4c69 6365 6e73 6520 5665 7273 696f 6e20  License Version 
+00004830: 322e 302e 0a0a                           2.0...
```

