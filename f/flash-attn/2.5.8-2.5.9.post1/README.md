# Comparing `tmp/flash_attn-2.5.8.tar.gz` & `tmp/flash_attn-2.5.9.post1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "flash_attn-2.5.8.tar", last modified: Fri Apr 26 23:45:48 2024, max compression
+gzip compressed data, was "flash_attn-2.5.9.post1.tar", last modified: Mon May 27 05:19:12 2024, max compression
```

## Comparing `flash_attn-2.5.8.tar` & `flash_attn-2.5.9.post1.tar`

### file list

```diff
@@ -1,1935 +1,2033 @@
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.869799 flash_attn-2.5.8/
--rw-r--r--   0 runner    (1001) docker     (127)       29 2024-04-26 23:45:14.000000 flash_attn-2.5.8/AUTHORS
--rw-r--r--   0 runner    (1001) docker     (127)     1558 2024-04-26 23:45:14.000000 flash_attn-2.5.8/LICENSE
--rw-r--r--   0 runner    (1001) docker     (127)      315 2024-04-26 23:45:14.000000 flash_attn-2.5.8/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (127)    19056 2024-04-26 23:45:48.869799 flash_attn-2.5.8/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    18583 2024-04-26 23:45:14.000000 flash_attn-2.5.8/README.md
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/cmake/
--rw-r--r--   0 runner    (1001) docker     (127)     2023 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/cmake/nop.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.569799 flash_attn-2.5.8/csrc/cutlass/examples/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/00_basic_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    14698 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/01_cutlass_utilities/
--rw-r--r--   0 runner    (1001) docker     (127)    13255 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/02_dump_reg_shmem/
--rw-r--r--   0 runner    (1001) docker     (127)     7157 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/
--rw-r--r--   0 runner    (1001) docker     (127)     4478 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/options.h
--rw-r--r--   0 runner    (1001) docker     (127)     7081 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/register_layout.cu
--rw-r--r--   0 runner    (1001) docker     (127)     2691 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/register_layout.h
--rw-r--r--   0 runner    (1001) docker     (127)     5819 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    11415 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/04_tile_iterator/
--rw-r--r--   0 runner    (1001) docker     (127)     8226 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/05_batched_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    15161 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.581798 flash_attn-2.5.8/csrc/cutlass/examples/06_splitK_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    17570 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/07_volta_tensorop_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    18283 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/08_turing_tensorop_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    18228 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/
--rw-r--r--   0 runner    (1001) docker     (127)    28142 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/10_planar_complex/
--rw-r--r--   0 runner    (1001) docker     (127)    21947 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/10_planar_complex/planar_complex.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/11_planar_complex_array/
--rw-r--r--   0 runner    (1001) docker     (127)    23244 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.585798 flash_attn-2.5.8/csrc/cutlass/examples/12_gemm_bias_relu/
--rw-r--r--   0 runner    (1001) docker     (127)    13152 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.589799 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    26102 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
--rw-r--r--   0 runner    (1001) docker     (127)    24557 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
--rw-r--r--   0 runner    (1001) docker     (127)    18662 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_grouped_gemm_run.h
--rw-r--r--   0 runner    (1001) docker     (127)    28268 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
--rw-r--r--   0 runner    (1001) docker     (127)    26174 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.589799 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/device/
--rw-r--r--   0 runner    (1001) docker     (127)    12711 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    11520 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)     8756 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8759 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8712 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8762 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8782 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8785 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8711 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8775 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7269 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7338 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7294 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7359 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10064 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_grouped_f16_sm80_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7358 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7424 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11029 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7619 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.589799 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)    30457 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     6120 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm_grouped_problem_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    18151 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)     3973 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
--rw-r--r--   0 runner    (1001) docker     (127)    26762 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    26775 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    28422 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    28073 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    19973 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    15092 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)     6380 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/grouped.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.561798 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.589799 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/
--rw-r--r--   0 runner    (1001) docker     (127)    14663 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
--rw-r--r--   0 runner    (1001) docker     (127)     3577 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    31616 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    31443 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)    21012 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)    20494 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)     7983 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
--rw-r--r--   0 runner    (1001) docker     (127)     6047 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)    34515 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    34226 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)    21820 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)    21434 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)    27144 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    27400 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)     5719 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/grouped_threadblock_swizzle.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    18020 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    15042 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15957 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm_with_visitor.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/
--rw-r--r--   0 runner    (1001) docker     (127)    27844 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/17_fprop_per_channel_bias/
--rw-r--r--   0 runner    (1001) docker     (127)    12580 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    14007 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/19_tensorop_canonical/
--rw-r--r--   0 runner    (1001) docker     (127)    13401 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/20_simt_canonical/
--rw-r--r--   0 runner    (1001) docker     (127)    12556 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/21_quaternion_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    17319 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/22_quaternion_conv/
--rw-r--r--   0 runner    (1001) docker     (127)    21423 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.593798 flash_attn-2.5.8/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    27556 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/24_gemm_grouped/
--rw-r--r--   0 runner    (1001) docker     (127)    50890 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    26547 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25628 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    25538 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    30446 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
--rw-r--r--   0 runner    (1001) docker     (127)    28159 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    28382 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_3xtf32_complex_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/30_wgrad_split_k/
--rw-r--r--   0 runner    (1001) docker     (127)    27304 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/31_basic_syrk/
--rw-r--r--   0 runner    (1001) docker     (127)    15205 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/32_basic_trmm/
--rw-r--r--   0 runner    (1001) docker     (127)    15906 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
--rw-r--r--   0 runner    (1001) docker     (127)    31803 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/34_transposed_conv2d/
--rw-r--r--   0 runner    (1001) docker     (127)    22378 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/
--rw-r--r--   0 runner    (1001) docker     (127)    23114 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16723 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    19055 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/36_gather_scatter_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    21008 2024-04-26 23:45:46.000000 flash_attn-2.5.8/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    31111 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13982 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    33900 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.597798 flash_attn-2.5.8/csrc/cutlass/examples/38_syr2k_grouped/
--rw-r--r--   0 runner    (1001) docker     (127)    47457 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.601798 flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/
--rw-r--r--   0 runner    (1001) docker     (127)    48551 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15309 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/layouts.h
--rw-r--r--   0 runner    (1001) docker     (127)    11985 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/permute_info.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.601798 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/
--rw-r--r--   0 runner    (1001) docker     (127)    11865 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
--rw-r--r--   0 runner    (1001) docker     (127)    10832 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.601798 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/
--rw-r--r--   0 runner    (1001) docker     (127)    22356 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     9162 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
--rw-r--r--   0 runner    (1001) docker     (127)     6118 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
--rw-r--r--   0 runner    (1001) docker     (127)    37522 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)     6666 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    11208 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multi_head_attention_backward.cu
--rw-r--r--   0 runner    (1001) docker     (127)    38218 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
--rw-r--r--   0 runner    (1001) docker     (127)    40003 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.601798 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/
--rw-r--r--   0 runner    (1001) docker     (127)     3994 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
--rw-r--r--   0 runner    (1001) docker     (127)     6248 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    26933 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    14105 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     6782 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    13959 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    68653 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
--rw-r--r--   0 runner    (1001) docker     (127)    11075 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/
--rw-r--r--   0 runner    (1001) docker     (127)     5776 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/default_warp_iterator_from_smem.h
--rw-r--r--   0 runner    (1001) docker     (127)    23862 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     3142 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
--rw-r--r--   0 runner    (1001) docker     (127)    64473 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
--rw-r--r--   0 runner    (1001) docker     (127)    64507 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
--rw-r--r--   0 runner    (1001) docker     (127)     2512 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    10063 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
--rw-r--r--   0 runner    (1001) docker     (127)    97621 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_backward.h
--rw-r--r--   0 runner    (1001) docker     (127)    52615 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/transform/
--rw-r--r--   0 runner    (1001) docker     (127)     3761 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/42_ampere_tensorop_group_conv/
--rw-r--r--   0 runner    (1001) docker     (127)    23901 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/43_ell_block_sparse_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    23867 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.565798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.565798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)     6370 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4099 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
--rw-r--r--   0 runner    (1001) docker     (127)     8285 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)    10439 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
--rw-r--r--   0 runner    (1001) docker     (127)     6848 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.565798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
--rw-r--r--   0 runner    (1001) docker     (127)    14747 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    10231 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
--rw-r--r--   0 runner    (1001) docker     (127)     3745 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.605798 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/device/
--rw-r--r--   0 runner    (1001) docker     (127)    16953 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    12642 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu
--rw-r--r--   0 runner    (1001) docker     (127)     2366 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h
--rw-r--r--   0 runner    (1001) docker     (127)    31509 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)    18413 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     3577 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/test_run.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     5818 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    15613 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)     7920 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    29897 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/
--rw-r--r--   0 runner    (1001) docker     (127)    24772 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/
--rw-r--r--   0 runner    (1001) docker     (127)    22676 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
--rw-r--r--   0 runner    (1001) docker     (127)    30694 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk_broadcast.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    17286 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/
--rw-r--r--   0 runner    (1001) docker     (127)    30447 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/49_collective_builder.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/
--rw-r--r--   0 runner    (1001) docker     (127)    18806 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/51_hopper_gett/
--rw-r--r--   0 runner    (1001) docker     (127)    17340 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/51_hopper_gett/51_hopper_gett.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5572 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/51_hopper_gett/gett_kernel.cuh
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    27580 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/52_hopper_gather_scatter_fusion.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17835 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_gemm.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5606 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_kernel.cuh
--rw-r--r--   0 runner    (1001) docker     (127)     7018 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_tensor.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8533 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/scatter_epilogue.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.609799 flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/
--rw-r--r--   0 runner    (1001) docker     (127)    45351 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/53_hopper_gemm_permute.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4078 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/permute_kernel.cuh
--rw-r--r--   0 runner    (1001) docker     (127)    11441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/permute_traits.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    22065 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/54_hopper_fp8_warp_specialized_gemm.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/hopper_fp8_commandline.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    31597 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/55_hopper_mixed_dtype_gemm.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7838 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/unfused_weight_dequantize.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    19510 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/56_hopper_ptr_array_batched_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/57_hopper_grouped_gemm/
--rw-r--r--   0 runner    (1001) docker     (127)    26735 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/60_cutlass_import/
--rw-r--r--   0 runner    (1001) docker     (127)     2849 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/60_cutlass_import/main.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/common/
--rw-r--r--   0 runner    (1001) docker     (127)     4469 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/common/helper.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.569799 flash_attn-2.5.8/csrc/cutlass/examples/cute/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/examples/cute/tutorial/
--rw-r--r--   0 runner    (1001) docker     (127)    14342 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9550 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/examples/cute/tutorial/tiled_copy.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.569799 flash_attn-2.5.8/csrc/cutlass/include/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.613798 flash_attn-2.5.8/csrc/cutlass/include/cute/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.617798 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/
--rw-r--r--   0 runner    (1001) docker     (127)     3026 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/axpby.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2351 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/clear.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13582 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/copy.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2906 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/fill.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    10843 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/functional.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    26851 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/gemm.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2124 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/prefer.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5248 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28067 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.621798 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/
--rw-r--r--   0 runner    (1001) docker     (127)     7606 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/cluster_sm90.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3248 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7703 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm75.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6832 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm80.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7530 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm90.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    14108 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    36138 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2393 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3160 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm61.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    12452 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm70.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4262 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm75.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    68426 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm80.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    47771 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6172 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp
--rw-r--r--   0 runner    (1001) docker     (127)   944978 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8212 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/arch/util.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.625799 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/
--rw-r--r--   0 runner    (1001) docker     (127)    27553 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_atom.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5975 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5087 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7107 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4589 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    51919 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2860 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma_swizzle.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    33411 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_atom.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8677 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2773 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6092 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3303 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    14128 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5049 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp
--rw-r--r--   0 runner    (1001) docker     (127)   189975 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5419 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/config.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.625799 flash_attn-2.5.8/csrc/cutlass/include/cute/container/
--rw-r--r--   0 runner    (1001) docker     (127)     2982 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/alignment.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9557 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/array.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2082 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/array_aligned.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    18172 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/array_subbyte.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5480 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/bit_field.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4609 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/cuda_types.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    21158 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/tuple.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4224 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/container/type_list.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/int_tuple.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    58037 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/layout.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    17749 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/layout_composed.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.625799 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/
--rw-r--r--   0 runner    (1001) docker     (127)    15563 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2170 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/bfloat.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2694 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/complex.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2033 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/float8.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     1997 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/half.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4871 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/int.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4671 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integer_sequence.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7216 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13004 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integral_constant.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7214 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integral_ratio.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9013 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/math.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2259 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/real.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2170 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/tfloat.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7531 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/uint128.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8403 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/pointer.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8326 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_base.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5510 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_flagged.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6136 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_swizzle.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    15939 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/stride.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    15341 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/swizzle.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    21354 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/swizzle_layout.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    35169 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/tensor.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2595 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/tensor_predicate.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2279 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/tile.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6203 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/underscore.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.629799 flash_attn-2.5.8/csrc/cutlass/include/cute/util/
--rw-r--r--   0 runner    (1001) docker     (127)     5010 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/util/debug.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4310 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/util/print.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7775 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cute/util/type_traits.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.637798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/
--rw-r--r--   0 runner    (1001) docker     (127)     3793 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/aligned_buffer.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.641798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/
--rw-r--r--   0 runner    (1001) docker     (127)     3564 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/arch.h
--rw-r--r--   0 runner    (1001) docker     (127)    19807 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/barrier.h
--rw-r--r--   0 runner    (1001) docker     (127)     2691 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/cache_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    18266 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory.h
--rw-r--r--   0 runner    (1001) docker     (127)     8260 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    15163 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     9252 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    11096 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm50.h
--rw-r--r--   0 runner    (1001) docker     (127)     7040 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm60.h
--rw-r--r--   0 runner    (1001) docker     (127)     4193 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm61.h
--rw-r--r--   0 runner    (1001) docker     (127)    16554 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)    31990 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    57636 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     8419 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm90.h
--rw-r--r--   0 runner    (1001) docker     (127)    43978 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     2621 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/reg_reconfig.h
--rw-r--r--   0 runner    (1001) docker     (127)     3998 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd.h
--rw-r--r--   0 runner    (1001) docker     (127)     3590 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd_sm60.h
--rw-r--r--   0 runner    (1001) docker     (127)     5102 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd_sm61.h
--rw-r--r--   0 runner    (1001) docker     (127)     8473 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma.h
--rw-r--r--   0 runner    (1001) docker     (127)     5286 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)     7746 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm72.h
--rw-r--r--   0 runner    (1001) docker     (127)     7616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    66810 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/array.h
--rw-r--r--   0 runner    (1001) docker     (127)     3662 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/array_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    13552 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/array_subbyte.h
--rw-r--r--   0 runner    (1001) docker     (127)    12443 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/barrier.h
--rw-r--r--   0 runner    (1001) docker     (127)    14278 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/bfloat16.h
--rw-r--r--   0 runner    (1001) docker     (127)     5294 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/blas3.h
--rw-r--r--   0 runner    (1001) docker     (127)     3263 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/blas3_types.h
--rw-r--r--   0 runner    (1001) docker     (127)     9386 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/block_striped.h
--rw-r--r--   0 runner    (1001) docker     (127)     8853 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/cluster_launch.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    20146 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    47943 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/constants.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.641798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/
--rw-r--r--   0 runner    (1001) docker     (127)    23019 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h
--rw-r--r--   0 runner    (1001) docker     (127)    16660 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h
--rw-r--r--   0 runner    (1001) docker     (127)     7140 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/convolution.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.641798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/
--rw-r--r--   0 runner    (1001) docker     (127)     9743 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)    12078 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)    10044 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.645799 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)     7671 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h
--rw-r--r--   0 runner    (1001) docker     (127)    53546 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)    56838 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
--rw-r--r--   0 runner    (1001) docker     (127)    11953 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)     4689 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)     4659 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    19603 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
--rw-r--r--   0 runner    (1001) docker     (127)    28745 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)    10459 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)     9324 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)    14864 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
--rw-r--r--   0 runner    (1001) docker     (127)    11980 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)    14883 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)    19293 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
--rw-r--r--   0 runner    (1001) docker     (127)    18026 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)    15413 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)    15690 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)    17222 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)    16730 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.645799 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     9689 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.653798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    15306 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    19735 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    18940 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    26136 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    10977 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    11529 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
--rw-r--r--   0 runner    (1001) docker     (127)    11333 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
--rw-r--r--   0 runner    (1001) docker     (127)    13688 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    10651 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)     9314 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
--rw-r--r--   0 runner    (1001) docker     (127)     9018 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
--rw-r--r--   0 runner    (1001) docker     (127)    10411 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    30197 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
--rw-r--r--   0 runner    (1001) docker     (127)    11202 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    10349 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    11519 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     9043 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    10832 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     8450 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)     9569 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    11020 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    15014 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     9634 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    15132 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     7945 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)     8891 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    18249 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
--rw-r--r--   0 runner    (1001) docker     (127)     9971 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    12024 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     8821 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 runner    (1001) docker     (127)    10744 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)     8871 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
--rw-r--r--   0 runner    (1001) docker     (127)    10747 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
--rw-r--r--   0 runner    (1001) docker     (127)     9899 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    20899 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)     8921 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
--rw-r--r--   0 runner    (1001) docker     (127)    12745 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     8097 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    36697 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
--rw-r--r--   0 runner    (1001) docker     (127)    30106 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    19823 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    12175 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)    26320 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    16915 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    12476 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     8050 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.653798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/
--rw-r--r--   0 runner    (1001) docker     (127)    12392 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)    30655 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     8704 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
--rw-r--r--   0 runner    (1001) docker     (127)    12221 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/coord.h
--rw-r--r--   0 runner    (1001) docker     (127)    11385 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/core_io.h
--rw-r--r--   0 runner    (1001) docker     (127)     6322 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/cuda_host_adapter.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6872 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/cutlass.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.653798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/
--rw-r--r--   0 runner    (1001) docker     (127)     3048 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/collective.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3710 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/dependent_false.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5745 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/helper_macros.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9629 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/layout.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3089 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/mma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4321 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/device_kernel.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.653798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.657798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/
--rw-r--r--   0 runner    (1001) docker     (127)     4407 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/collective_builder.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2957 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9109 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    10398 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue_array.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8237 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/detail.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    11300 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/epilogue_tensor_broadcast.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13967 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm70_epilogue_vectorized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    33929 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5369 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized_bias_elementwise.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     6054 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.657798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/
--rw-r--r--   0 runner    (1001) docker     (127)     4128 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/callbacks.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    12104 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/operations.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    49837 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28095 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_compute_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    31364 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_load_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    45042 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_store_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    37837 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_tma_warpspecialized.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.661798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/
--rw-r--r--   0 runner    (1001) docker     (127)    17386 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/activation.h
--rw-r--r--   0 runner    (1001) docker     (127)     4691 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     2281 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/detail.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    18989 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h
--rw-r--r--   0 runner    (1001) docker     (127)     9323 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
--rw-r--r--   0 runner    (1001) docker     (127)    18161 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
--rw-r--r--   0 runner    (1001) docker     (127)    23752 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
--rw-r--r--   0 runner    (1001) docker     (127)     9066 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
--rw-r--r--   0 runner    (1001) docker     (127)    15195 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
--rw-r--r--   0 runner    (1001) docker     (127)     3669 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
--rw-r--r--   0 runner    (1001) docker     (127)    10056 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
--rw-r--r--   0 runner    (1001) docker     (127)     3693 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
--rw-r--r--   0 runner    (1001) docker     (127)     8399 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
--rw-r--r--   0 runner    (1001) docker     (127)     3046 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
--rw-r--r--   0 runner    (1001) docker     (127)     9351 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    20596 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
--rw-r--r--   0 runner    (1001) docker     (127)    19458 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
--rw-r--r--   0 runner    (1001) docker     (127)    11995 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
--rw-r--r--   0 runner    (1001) docker     (127)     3688 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
--rw-r--r--   0 runner    (1001) docker     (127)     3669 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
--rw-r--r--   0 runner    (1001) docker     (127)     9786 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_tensor_broadcast.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8662 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
--rw-r--r--   0 runner    (1001) docker     (127)     3416 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     3048 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.669798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)     9142 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     9441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
--rw-r--r--   0 runner    (1001) docker     (127)     3234 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
--rw-r--r--   0 runner    (1001) docker     (127)     7209 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    13385 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)    28290 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7129 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
--rw-r--r--   0 runner    (1001) docker     (127)    10846 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7424 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)     5763 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)     5947 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4409 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)     7398 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7303 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4098 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4678 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    19249 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)     8279 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
--rw-r--r--   0 runner    (1001) docker     (127)     7455 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
--rw-r--r--   0 runner    (1001) docker     (127)    13424 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
--rw-r--r--   0 runner    (1001) docker     (127)    13933 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
--rw-r--r--   0 runner    (1001) docker     (127)     7401 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    14610 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     9073 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
--rw-r--r--   0 runner    (1001) docker     (127)    15321 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    16804 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
--rw-r--r--   0 runner    (1001) docker     (127)    58727 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    29199 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    13454 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    17169 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h
--rw-r--r--   0 runner    (1001) docker     (127)     7308 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.669798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/
--rw-r--r--   0 runner    (1001) docker     (127)    14544 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_2x.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4387 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_compute.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    17161 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_load.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    24942 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_store.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2171 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitors.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    14359 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)     4741 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
--rw-r--r--   0 runner    (1001) docker     (127)    19842 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
--rw-r--r--   0 runner    (1001) docker     (127)    40972 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    18821 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
--rw-r--r--   0 runner    (1001) docker     (127)     5636 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
--rw-r--r--   0 runner    (1001) docker     (127)    21249 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
--rw-r--r--   0 runner    (1001) docker     (127)    13873 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
--rw-r--r--   0 runner    (1001) docker     (127)    15397 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
--rw-r--r--   0 runner    (1001) docker     (127)     9146 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
--rw-r--r--   0 runner    (1001) docker     (127)    15534 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
--rw-r--r--   0 runner    (1001) docker     (127)     7487 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    18100 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
--rw-r--r--   0 runner    (1001) docker     (127)     7394 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.673798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/
--rw-r--r--   0 runner    (1001) docker     (127)     7055 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7736 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     5880 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)     9883 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     8924 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     6045 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4864 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)     5979 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)    25658 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)    20290 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    22921 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
--rw-r--r--   0 runner    (1001) docker     (127)    14250 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7704 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     7485 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)     3916 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)    29056 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/fast_math.h
--rw-r--r--   0 runner    (1001) docker     (127)    36163 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/float8.h
--rw-r--r--   0 runner    (1001) docker     (127)     2645 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/floating_point_nvrtc.h
--rw-r--r--   0 runner    (1001) docker     (127)    17280 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/functional.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.673798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.677798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/
--rw-r--r--   0 runner    (1001) docker     (127)     3589 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3668 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4768 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/fp8_accumulation.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    22247 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    27570 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    33101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28282 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_rs_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    19361 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    33171 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    66973 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized_mixed_input.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    22389 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    23844 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    23982 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized_fp8.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.681799 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/
--rw-r--r--   0 runner    (1001) docker     (127)    16881 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    24262 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
--rw-r--r--   0 runner    (1001) docker     (127)    27616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    25202 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    22367 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h
--rw-r--r--   0 runner    (1001) docker     (127)    22375 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h
--rw-r--r--   0 runner    (1001) docker     (127)    22725 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     2591 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    13736 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)    17329 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h
--rw-r--r--   0 runner    (1001) docker     (127)    11362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    20436 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
--rw-r--r--   0 runner    (1001) docker     (127)    15600 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    23658 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
--rw-r--r--   0 runner    (1001) docker     (127)    15624 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    14027 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_streamk_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    13968 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    14853 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)     5961 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemv.h
--rw-r--r--   0 runner    (1001) docker     (127)    18127 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h
--rw-r--r--   0 runner    (1001) docker     (127)     2747 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    16719 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_k.h
--rwxr-xr-x   0 runner    (1001) docker     (127)    21050 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/symm.h
--rw-r--r--   0 runner    (1001) docker     (127)    26464 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/trmm.h
--rw-r--r--   0 runner    (1001) docker     (127)     9823 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4630 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     3568 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/gemm_enumerated_types.h
--rw-r--r--   0 runner    (1001) docker     (127)     4265 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/group_array_problem_shape.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.693798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)    29360 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    39181 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    16130 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    12385 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)     6592 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)     5848 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)    11104 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     7983 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
--rw-r--r--   0 runner    (1001) docker     (127)     8175 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)     4932 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
--rw-r--r--   0 runner    (1001) docker     (127)     5446 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_streamk_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    12332 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     5697 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)     8123 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)     6457 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)     8084 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
--rwxr-xr-x   0 runner    (1001) docker     (127)     5349 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h
--rw-r--r--   0 runner    (1001) docker     (127)    11560 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
--rw-r--r--   0 runner    (1001) docker     (127)    20509 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    12470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    10620 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     9872 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
--rw-r--r--   0 runner    (1001) docker     (127)    16990 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     9444 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
--rwxr-xr-x   0 runner    (1001) docker     (127)    13375 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h
--rwxr-xr-x   0 runner    (1001) docker     (127)    21830 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
--rwxr-xr-x   0 runner    (1001) docker     (127)    10315 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    10873 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h
--rw-r--r--   0 runner    (1001) docker     (127)    10730 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    10850 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    28916 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    13362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     8698 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h
--rw-r--r--   0 runner    (1001) docker     (127)     8766 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
--rw-r--r--   0 runner    (1001) docker     (127)    14692 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)     4690 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    15623 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)    27663 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
--rwxr-xr-x   0 runner    (1001) docker     (127)     6144 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h
--rw-r--r--   0 runner    (1001) docker     (127)     5150 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)    23352 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    18941 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
--rw-r--r--   0 runner    (1001) docker     (127)     8142 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
--rw-r--r--   0 runner    (1001) docker     (127)    80099 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_streamk_with_fused_epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)     4291 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
--rw-r--r--   0 runner    (1001) docker     (127)    23597 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     4374 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    39277 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
--rw-r--r--   0 runner    (1001) docker     (127)    10423 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    28721 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor_streamk.h
--rw-r--r--   0 runner    (1001) docker     (127)    48041 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
--rw-r--r--   0 runner    (1001) docker     (127)    23866 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    18393 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h
--rwxr-xr-x   0 runner    (1001) docker     (127)     8954 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
--rw-r--r--   0 runner    (1001) docker     (127)    16765 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)     3988 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/params_sparse_base.h
--rw-r--r--   0 runner    (1001) docker     (127)     8404 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    23381 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    16100 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)     4334 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
--rw-r--r--   0 runner    (1001) docker     (127)    24584 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    17989 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    11073 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    35090 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_array_tma_warpspecialized_cooperative.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13122 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    18498 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28936 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_cooperative.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    28129 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_pingpong.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    18144 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    22969 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_cooperative.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    23044 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_pingpong.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4832 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    18485 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_group.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    39022 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_stream_k.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13183 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     8144 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_visitor.h
--rw-r--r--   0 runner    (1001) docker     (127)    16057 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/static_tile_scheduler.hpp
--rwxr-xr-x   0 runner    (1001) docker     (127)    23881 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     4414 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    58068 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler_params.h
--rw-r--r--   0 runner    (1001) docker     (127)    19518 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.693798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     3567 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    15399 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h
--rw-r--r--   0 runner    (1001) docker     (127)    29987 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h
--rw-r--r--   0 runner    (1001) docker     (127)     8142 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.701799 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    31930 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
--rwxr-xr-x   0 runner    (1001) docker     (127)     6979 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
--rw-r--r--   0 runner    (1001) docker     (127)    35582 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h
--rw-r--r--   0 runner    (1001) docker     (127)     5123 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
--rw-r--r--   0 runner    (1001) docker     (127)    57426 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)    19257 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)    42310 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)   102804 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    32106 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    12650 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
--rw-r--r--   0 runner    (1001) docker     (127)     7387 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    20975 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
--rw-r--r--   0 runner    (1001) docker     (127)     7998 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)     5110 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)     4627 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     7113 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
--rw-r--r--   0 runner    (1001) docker     (127)     6323 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)     7121 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     4959 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
--rw-r--r--   0 runner    (1001) docker     (127)    65005 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    25495 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     8509 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    19515 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
--rw-r--r--   0 runner    (1001) docker     (127)    24233 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    13837 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
--rwxr-xr-x   0 runner    (1001) docker     (127)     4726 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h
--rw-r--r--   0 runner    (1001) docker     (127)     3652 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h
--rw-r--r--   0 runner    (1001) docker     (127)     7823 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    27600 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    32816 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    27801 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    15995 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     6901 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    22839 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    14747 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
--rw-r--r--   0 runner    (1001) docker     (127)     9864 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
--rw-r--r--   0 runner    (1001) docker     (127)    27246 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)     9210 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
--rw-r--r--   0 runner    (1001) docker     (127)    25557 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    20395 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
--rw-r--r--   0 runner    (1001) docker     (127)    15041 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
--rw-r--r--   0 runner    (1001) docker     (127)    26627 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.709798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/
--rw-r--r--   0 runner    (1001) docker     (127)    20553 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     6684 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     5178 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    12142 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     4053 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     4685 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     5691 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
--rw-r--r--   0 runner    (1001) docker     (127)     2619 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma.h
--rw-r--r--   0 runner    (1001) docker     (127)    37767 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    23132 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
--rw-r--r--   0 runner    (1001) docker     (127)    78519 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    21178 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    14589 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    20271 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_mixed_input_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)     6144 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     8419 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h
--rw-r--r--   0 runner    (1001) docker     (127)     3079 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)    59793 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    13497 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    13956 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    15721 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
--rw-r--r--   0 runner    (1001) docker     (127)    20472 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     2939 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
--rw-r--r--   0 runner    (1001) docker     (127)     8966 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)    11017 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)   135937 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    99553 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)    75040 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)    13151 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
--rw-r--r--   0 runner    (1001) docker     (127)    27101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
--rw-r--r--   0 runner    (1001) docker     (127)     7241 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
--rw-r--r--   0 runner    (1001) docker     (127)    17303 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    19101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     4610 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
--rw-r--r--   0 runner    (1001) docker     (127)     8728 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    10599 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm_coord.h
--rw-r--r--   0 runner    (1001) docker     (127)     2875 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm_coord.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    24024 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/half.h
--rw-r--r--   0 runner    (1001) docker     (127)     7353 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/integer_subbyte.h
--rw-r--r--   0 runner    (1001) docker     (127)     3194 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_hardware_info.h
--rw-r--r--   0 runner    (1001) docker     (127)     2006 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2801 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_launch.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.709798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/
--rw-r--r--   0 runner    (1001) docker     (127)     3020 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/layout.h
--rw-r--r--   0 runner    (1001) docker     (127)    35129 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/matrix.h
--rw-r--r--   0 runner    (1001) docker     (127)    24906 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/permute.h
--rw-r--r--   0 runner    (1001) docker     (127)     5107 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/pitch_linear.h
--rw-r--r--   0 runner    (1001) docker     (127)    18798 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor.h
--rw-r--r--   0 runner    (1001) docker     (127)    29599 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)    33137 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
--rw-r--r--   0 runner    (1001) docker     (127)    29336 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     3354 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/vector.h
--rw-r--r--   0 runner    (1001) docker     (127)   364115 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix.h
--rw-r--r--   0 runner    (1001) docker     (127)     4991 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix_coord.h
--rw-r--r--   0 runner    (1001) docker     (127)     2726 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix_shape.h
--rw-r--r--   0 runner    (1001) docker     (127)   122014 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_conversion.h
--rw-r--r--   0 runner    (1001) docker     (127)     3605 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_size.h
--rw-r--r--   0 runner    (1001) docker     (127)     3711 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_types.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/pipeline/
--rw-r--r--   0 runner    (1001) docker     (127)     2091 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/pipeline/pipeline.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    37270 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/pipeline/sm90_pipeline.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5492 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/pitch_linear_coord.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/platform/
--rw-r--r--   0 runner    (1001) docker     (127)    28315 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/platform/platform.h
--rw-r--r--   0 runner    (1001) docker     (127)    16279 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/predicate_vector.h
--rw-r--r--   0 runner    (1001) docker     (127)    20891 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/quaternion.h
--rw-r--r--   0 runner    (1001) docker     (127)     2369 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/real.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/
--rw-r--r--   0 runner    (1001) docker     (127)     6823 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h
--rw-r--r--   0 runner    (1001) docker     (127)     8152 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h
--rw-r--r--   0 runner    (1001) docker     (127)    11579 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
--rw-r--r--   0 runner    (1001) docker     (127)    11448 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)     8762 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
--rw-r--r--   0 runner    (1001) docker     (127)     7897 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
--rw-r--r--   0 runner    (1001) docker     (127)    20685 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
--rw-r--r--   0 runner    (1001) docker     (127)    21662 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     7208 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/thread/reduce.h
--rw-r--r--   0 runner    (1001) docker     (127)     6790 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h
--rw-r--r--   0 runner    (1001) docker     (127)     2936 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h
--rw-r--r--   0 runner    (1001) docker     (127)     6572 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/relatively_equal.h
--rw-r--r--   0 runner    (1001) docker     (127)     3984 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/semaphore.h
--rw-r--r--   0 runner    (1001) docker     (127)    38253 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/subbyte_reference.h
--rw-r--r--   0 runner    (1001) docker     (127)     8964 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_coord.h
--rw-r--r--   0 runner    (1001) docker     (127)    12207 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_ref.h
--rw-r--r--   0 runner    (1001) docker     (127)    11201 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     9509 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_view.h
--rw-r--r--   0 runner    (1001) docker     (127)    10250 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    13017 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/tfloat32.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     5893 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/thread/matrix.h
--rw-r--r--   0 runner    (1001) docker     (127)     2581 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/trace.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/collective/
--rw-r--r--   0 runner    (1001) docker     (127)    33948 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/collective/sm90_wgmma_transpose.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    33349 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.713798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     3835 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/thread/transpose.h
--rw-r--r--   0 runner    (1001) docker     (127)     4309 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/thread/unary_op.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.717798 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)     6181 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    44443 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    44309 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    12890 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    11097 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    72537 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    28232 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
--rwxr-xr-x   0 runner    (1001) docker     (127)    10805 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
--rw-r--r--   0 runner    (1001) docker     (127)    31412 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
--rw-r--r--   0 runner    (1001) docker     (127)    62949 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    27175 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
--rw-r--r--   0 runner    (1001) docker     (127)    28064 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
--rw-r--r--   0 runner    (1001) docker     (127)    13088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     8232 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     2638 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    13283 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
--rw-r--r--   0 runner    (1001) docker     (127)    18623 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
--rw-r--r--   0 runner    (1001) docker     (127)    27922 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    47789 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
--rw-r--r--   0 runner    (1001) docker     (127)     2616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)    16508 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
--rw-r--r--   0 runner    (1001) docker     (127)    15486 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
--rw-r--r--   0 runner    (1001) docker     (127)    36050 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
--rw-r--r--   0 runner    (1001) docker     (127)    43663 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
--rw-r--r--   0 runner    (1001) docker     (127)     5226 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.721799 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/warp/
--rw-r--r--   0 runner    (1001) docker     (127)     8828 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
--rw-r--r--   0 runner    (1001) docker     (127)     8322 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/uint128.h
--rw-r--r--   0 runner    (1001) docker     (127)     2899 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/version.h
--rw-r--r--   0 runner    (1001) docker     (127)     4540 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/wmma_array.h
--rw-r--r--   0 runner    (1001) docker     (127)     4964 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/include/cutlass/workspace.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.573799 flash_attn-2.5.8/csrc/cutlass/test/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.721799 flash_attn-2.5.8/csrc/cutlass/test/unit/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.721799 flash_attn-2.5.8/csrc/cutlass/test/unit/cluster_launch/
--rw-r--r--   0 runner    (1001) docker     (127)    12088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cluster_launch/cluster_launch.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.721799 flash_attn-2.5.8/csrc/cutlass/test/unit/common/
--rw-r--r--   0 runner    (1001) docker     (127)     4900 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/common/cutlass_unit_test.h
--rw-r--r--   0 runner    (1001) docker     (127)     5381 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/common/filter_architecture.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.721799 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/
--rw-r--r--   0 runner    (1001) docker     (127)    22534 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/cache_testbed_output.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.729798 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/
--rw-r--r--   0 runner    (1001) docker     (127)     5344 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5443 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5239 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9110 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8485 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5243 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5378 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12054 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9603 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5267 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5357 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5089 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13690 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5390 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5191 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11136 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5291 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3551 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rwxr-xr-x   0 runner    (1001) docker     (127)     8278 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20553 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20647 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5150 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5239 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    26113 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    26210 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5106 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5194 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5738 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5439 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7363 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3984 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    39407 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_problems.h
--rw-r--r--   0 runner    (1001) docker     (127)    14471 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4173 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_swizzling4_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4662 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    26218 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    22110 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
--rw-r--r--   0 runner    (1001) docker     (127)     5179 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5358 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5264 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3615 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7591 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10514 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5772 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    23528 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    21514 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)     5135 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5347 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3736 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6560 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5257 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12276 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_problems.h
--rw-r--r--   0 runner    (1001) docker     (127)    21645 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)     3622 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6560 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5256 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17700 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    18451 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)    22194 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9383 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20090 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.733798 flash_attn-2.5.8/csrc/cutlass/test/unit/core/
--rw-r--r--   0 runner    (1001) docker     (127)     7365 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/array.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7353 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/bfloat16.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6981 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/complex.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3806 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/cpp11.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6534 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/fast_numeric_conversion.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4608 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/float8.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13001 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/functional.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3553 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/half.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5295 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/matrix.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8592 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/matrix_coord.cu
--rw-r--r--   0 runner    (1001) docker     (127)    22710 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/numeric_conversion.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8148 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/predicate_vector.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5777 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/quaternion.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/tensor_ref.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8885 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/tensor_view.cu
--rw-r--r--   0 runner    (1001) docker     (127)     2050 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/test_unit_core.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     7088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/core/tfloat32.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.573799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.733798 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/ampere/
--rw-r--r--   0 runner    (1001) docker     (127)     3527 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/ampere/cp_async.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14320 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/ampere/ldsm.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.737799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/
--rw-r--r--   0 runner    (1001) docker     (127)     6891 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/array_subbyte.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     3493 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/bitfield.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     4861 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/coalesce.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     8195 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/compact_xmajor.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     5620 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/compare.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     7588 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/complement.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    12456 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/composition.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     3195 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/constants.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2007 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/core_unit.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     5000 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/int_tuple.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     4856 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/inverse_left.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     6867 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/inverse_right.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     6733 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/logical_divide.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     5830 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/logical_product.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     4668 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/math.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2956 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/mixedbits.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     3267 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/nullspace.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     3947 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/pointer.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     4971 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/reverse.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2342 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/transform.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    13304 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/tuple.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.737799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/
--rw-r--r--   0 runner    (1001) docker     (127)     7008 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/bulk_load.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6369 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/bulk_store.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14367 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/stsm.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18081 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_load.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8089 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_load_testbed.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    13192 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_store.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7624 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_store_testbed.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.737799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/layout/
--rw-r--r--   0 runner    (1001) docker     (127)     4544 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/layout/layout_operator.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.737799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/msvc_compilation/
--rw-r--r--   0 runner    (1001) docker     (127)     6533 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/msvc_compilation/tuple.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.737799 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/volta/
--rw-r--r--   0 runner    (1001) docker     (127)     5409 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/cute/volta/vectorization_auto.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.573799 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.741798 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/
--rw-r--r--   0 runner    (1001) docker     (127)    15818 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/activation.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6534 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9964 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.741798 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    13824 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
--rw-r--r--   0 runner    (1001) docker     (127)    27176 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12061 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25275 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
--rw-r--r--   0 runner    (1001) docker     (127)    84612 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)    70486 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25293 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13012 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)     7743 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    19178 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
--rw-r--r--   0 runner    (1001) docker     (127)    28433 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11038 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    11734 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.741798 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/
--rw-r--r--   0 runner    (1001) docker     (127)     6783 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7275 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.573799 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.809798 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/
--rw-r--r--   0 runner    (1001) docker     (127)    53507 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    10188 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    33161 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8933 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10162 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17912 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8914 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16447 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16575 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8318 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8317 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6714 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7895 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7929 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6516 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6548 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9016 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9051 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4627 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6165 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6124 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9634 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16357 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13189 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8845 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13583 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13464 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9571 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16239 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6140 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9544 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16417 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13075 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8775 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6156 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6116 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3528 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3539 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7965 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13273 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3648 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8608 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13518 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3645 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6096 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7845 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18135 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13008 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8505 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11497 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11090 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6156 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6116 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11066 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17080 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3528 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3540 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7964 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16457 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13266 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8933 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13551 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13540 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6130 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8160 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7847 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16131 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13014 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8754 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11497 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6147 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6107 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13518 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13398 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7845 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16149 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6119 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7827 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9526 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7898 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3584 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3473 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12967 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12931 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12930 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12895 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8349 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7299 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8348 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7290 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10240 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    26102 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11339 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7346 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12397 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6857 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7239 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8119 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16882 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8405 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17111 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12637 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8387 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10938 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10911 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9586 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11288 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3514 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_f16t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7975 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16531 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5693 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7957 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16691 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12408 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6864 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8538 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6675 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8543 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17312 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6663 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4663 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4945 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10581 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    65693 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    47257 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_evt.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    20069 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_tensor_broadcast.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    16950 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16902 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15131 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16855 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6854 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10186 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6686 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6755 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6687 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4726 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4718 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3955 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_s8n_f16t_mixed_input_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3956 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_u8n_f16t_mixed_input_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13843 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3958 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3959 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_u8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16715 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12841 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4544 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17409 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemv.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6028 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6031 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6064 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6067 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4908 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6037 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6040 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5382 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5406 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5401 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13055 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13027 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5388 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6939 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7677 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7725 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3853 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6396 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10123 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    10272 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
--rw-r--r--   0 runner    (1001) docker     (127)    11186 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    46795 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    54085 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8318 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    46687 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8411 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    46578 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    40533 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    47656 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    40441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    40354 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3513 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    89517 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    89304 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    89304 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    89091 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    69175 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    71438 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    67796 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    70056 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7156 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6067 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9063 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
--rw-r--r--   0 runner    (1001) docker     (127)    35894 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    35813 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    35813 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    35732 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    70872 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    73136 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8870 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    69488 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8865 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    71755 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    33231 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    33156 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    33156 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    33081 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5238 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5253 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5357 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5479 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5238 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5253 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3875 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3734 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6264 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18186 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_evt_operations.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5474 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6888 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6966 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6939 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_pingpong.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8187 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14314 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)    19733 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20045 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)    19937 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_pingpong.cu
--rw-r--r--   0 runner    (1001) docker     (127)    34699 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25032 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25544 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)    35785 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9618 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_load.cu
--rw-r--r--   0 runner    (1001) docker     (127)    29579 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_store.cu
--rw-r--r--   0 runner    (1001) docker     (127)    24337 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_bias_elementwise.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7247 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_dag.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8438 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_reduce.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6863 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_row_broadcast.cu
--rw-r--r--   0 runner    (1001) docker     (127)    53040 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9549 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_aux_load.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20249 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_bias_elementwise.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7216 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_dag.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8392 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_reduce.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6832 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_row_broadcast.cu
--rw-r--r--   0 runner    (1001) docker     (127)    40264 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cooperative_stream_k.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11938 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_tensor_broadcast.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9732 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6675 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6382 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32_tensor_broadcast.cu
--rw-r--r--   0 runner    (1001) docker     (127)    22739 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8436 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32_evt.cu
--rw-r--r--   0 runner    (1001) docker     (127)    22313 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8382 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative_evt.cu
--rw-r--r--   0 runner    (1001) docker     (127)    23697 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cooperative_stream_k.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9764 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)    22879 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_fp32.cu
--rw-r--r--   0 runner    (1001) docker     (127)    54175 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8468 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32_evt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5295 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6593 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6662 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6644 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_pingpong.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15719 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4566 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32_tensor_broadcast.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12616 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_stream_k_scheduler.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5297 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6590 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6659 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_cooperative.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6641 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_pingpong.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7972 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
--rw-r--r--   0 runner    (1001) docker     (127)    21505 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32_gmma_rs_cluster_warpspecialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5923 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5926 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5959 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5962 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4838 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5983 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5932 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5935 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15203 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8623 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15104 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4777 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8103 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8108 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8088 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8093 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8073 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8078 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8058 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8063 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15071 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8551 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14972 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5386 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5432 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5456 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5378 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12952 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5444 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7208 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7199 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7190 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4794 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4783 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4739 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    19145 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7991 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    11015 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7976 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12342 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7961 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12321 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4786 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4775 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4993 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5017 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4987 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5011 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5023 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4996 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3793 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4990 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16083 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16041 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4529 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7451 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9401 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16027 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15985 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20431 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)     8264 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    20702 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
--rw-r--r--   0 runner    (1001) docker     (127)    19445 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
--rw-r--r--   0 runner    (1001) docker     (127)    16502 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h
--rw-r--r--   0 runner    (1001) docker     (127)    16562 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
--rw-r--r--   0 runner    (1001) docker     (127)    17002 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
--rw-r--r--   0 runner    (1001) docker     (127)    14698 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
--rw-r--r--   0 runner    (1001) docker     (127)    10228 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h
--rw-r--r--   0 runner    (1001) docker     (127)     9481 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    20898 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    15652 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     8639 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h
--rw-r--r--   0 runner    (1001) docker     (127)    15833 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h
--rw-r--r--   0 runner    (1001) docker     (127)     6124 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h
--rw-r--r--   0 runner    (1001) docker     (127)    19993 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    20230 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)    17613 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_universal.h
--rw-r--r--   0 runner    (1001) docker     (127)     2626 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_utils.h
--rw-r--r--   0 runner    (1001) docker     (127)     9916 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9988 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4988 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4992 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9762 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15614 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8733 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14089 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14444 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4607 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12798 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12809 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12764 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12768 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12779 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15504 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8673 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13989 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14520 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.809798 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/kernel/
--rwxr-xr-x   0 runner    (1001) docker     (127)    46470 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu
--rwxr-xr-x   0 runner    (1001) docker     (127)    14362 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.809798 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     4847 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12503 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3109 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.809798 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/host/
--rw-r--r--   0 runner    (1001) docker     (127)     5198 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7161 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h
--rw-r--r--   0 runner    (1001) docker     (127)     7124 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/testbed.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.813799 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    25036 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4345 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
--rw-r--r--   0 runner    (1001) docker     (127)   135043 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4644 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
--rw-r--r--   0 runner    (1001) docker     (127)    94442 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16988 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    13829 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    14471 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
--rw-r--r--   0 runner    (1001) docker     (127)    49052 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8407 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18705 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    78121 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    21051 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13703 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    14171 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
--rw-r--r--   0 runner    (1001) docker     (127)    29772 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12395 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3502 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12070 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    16308 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12501 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/
--rw-r--r--   0 runner    (1001) docker     (127)    22128 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10914 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9873 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15234 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_mixed_input_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    18220 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4920 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6291 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9297 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)    37940 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu
--rw-r--r--   0 runner    (1001) docker     (127)    81657 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9087 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu
--rw-r--r--   0 runner    (1001) docker     (127)    48928 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    49273 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/testbed.h
--rw-r--r--   0 runner    (1001) docker     (127)    25780 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7541 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6486 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/layout/
--rw-r--r--   0 runner    (1001) docker     (127)     5788 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/layout/matrix.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5984 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/layout/tensor.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7081 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/layout/tensor_nhwc.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/cutlass/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/
--rw-r--r--   0 runner    (1001) docker     (127)     2096 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     5373 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/thread/contraction.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     2915 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/stdlib/
--rw-r--r--   0 runner    (1001) docker     (127)     1828 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h
--rw-r--r--   0 runner    (1001) docker     (127)     4250 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     2833 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_contraction.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5727 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_gemm.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12365 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/testbed.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.817798 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/
--rw-r--r--   0 runner    (1001) docker     (127)    15387 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_async.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15083 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17024 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
--rw-r--r--   0 runner    (1001) docker     (127)    19827 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7644 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4327 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/testbed.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/device/
--rw-r--r--   0 runner    (1001) docker     (127)    14684 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
--rw-r--r--   0 runner    (1001) docker     (127)    15609 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)    11316 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
--rw-r--r--   0 runner    (1001) docker     (127)     2228 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     3110 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6657 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/thread/testbed.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/substrate/
--rw-r--r--   0 runner    (1001) docker     (127)     3312 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/substrate/dependent_false.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2047 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/test_unit.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/test/unit/transform/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/transform/threadblock/
--rw-r--r--   0 runner    (1001) docker     (127)    25527 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
--rw-r--r--   0 runner    (1001) docker     (127)     9501 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/test/unit/util/
--rw-r--r--   0 runner    (1001) docker     (127)     2663 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/util/cutlass_test_levels.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4515 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/util/rms_norm.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7474 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/test/unit/util/tensor_reduce.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/library/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/library/include/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.821798 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/
--rw-r--r--   0 runner    (1001) docker     (127)     4272 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h
--rw-r--r--   0 runner    (1001) docker     (127)    18334 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/descriptions.h
--rw-r--r--   0 runner    (1001) docker     (127)    16150 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/handle.h
--rw-r--r--   0 runner    (1001) docker     (127)    20135 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/library.h
--rw-r--r--   0 runner    (1001) docker     (127)     4251 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/manifest.h
--rw-r--r--   0 runner    (1001) docker     (127)    19027 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h
--rw-r--r--   0 runner    (1001) docker     (127)     2724 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/singleton.h
--rw-r--r--   0 runner    (1001) docker     (127)     5908 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/types.h
--rw-r--r--   0 runner    (1001) docker     (127)     8140 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/util.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.825798 flash_attn-2.5.8/csrc/cutlass/tools/library/src/
--rw-r--r--   0 runner    (1001) docker     (127)    22377 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/conv2d_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    13850 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/conv3d_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    42608 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/gemm_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    13766 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    36802 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/handle.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13269 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/library_internal.h
--rw-r--r--   0 runner    (1001) docker     (127)     3634 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/manifest.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     5551 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/operation_table.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12873 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/rank_2k_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    11367 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/rank_k_operation.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.825798 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/
--rw-r--r--   0 runner    (1001) docker     (127)     3482 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8435 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/reduction_device.cu
--rw-r--r--   0 runner    (1001) docker     (127)    10269 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/reduction_operation.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.829798 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/
--rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv2d.cu
--rw-r--r--   0 runner    (1001) docker     (127)     6286 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv3d.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17347 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)     5473 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e4m3out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e5m2out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e4m3out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e5m2out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3633 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp32out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4262 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_bf16out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4260 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp16out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4260 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp32out.cu
--rw-r--r--   0 runner    (1001) docker     (127)     4056 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp_mixed_input.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3140 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp_other.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3729 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int4.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3683 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_canonical.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3721 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_32.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3744 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_64.cu
--rw-r--r--   0 runner    (1001) docker     (127)    16453 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)     4810 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu
--rw-r--r--   0 runner    (1001) docker     (127)     2669 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/singleton.cu
--rw-r--r--   0 runner    (1001) docker     (127)    13134 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/symm_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    11698 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/trmm_operation.h
--rw-r--r--   0 runner    (1001) docker     (127)    46579 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/library/src/util.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/profiler/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.833799 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/
--rw-r--r--   0 runner    (1001) docker     (127)    18227 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv2d_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)    16101 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv3d_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)    10623 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cublas_helpers.h
--rw-r--r--   0 runner    (1001) docker     (127)    20435 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cudnn_helpers.h
--rw-r--r--   0 runner    (1001) docker     (127)     3233 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cutlass_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     2454 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/debug.h
--rw-r--r--   0 runner    (1001) docker     (127)     7576 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_allocation.h
--rw-r--r--   0 runner    (1001) docker     (127)     4290 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_context.h
--rw-r--r--   0 runner    (1001) docker     (127)     6421 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/enumerated_types.h
--rw-r--r--   0 runner    (1001) docker     (127)     8749 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/gemm_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     2725 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/gpu_timer.h
--rw-r--r--   0 runner    (1001) docker     (127)     7924 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     9273 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/options.h
--rw-r--r--   0 runner    (1001) docker     (127)     4337 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_report.h
--rw-r--r--   0 runner    (1001) docker     (127)     3941 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_result.h
--rw-r--r--   0 runner    (1001) docker     (127)    28189 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/problem_space.h
--rw-r--r--   0 runner    (1001) docker     (127)     6891 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_2k_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     6830 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_k_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     5452 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/reduction_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     6471 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/sparse_gemm_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     6933 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/symm_operation_profiler.h
--rw-r--r--   0 runner    (1001) docker     (127)     6599 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/trmm_operation_profiler.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.837798 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/
--rw-r--r--   0 runner    (1001) docker     (127)    54272 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    48776 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    37138 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cublas_helpers.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17066 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     7391 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    78653 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/device_allocation.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8359 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/device_context.cu
--rw-r--r--   0 runner    (1001) docker     (127)     8313 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/enumerated_types.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    43920 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)     3892 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/gpu_timer.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2374 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/main.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    22898 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    28314 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/options.cu
--rw-r--r--   0 runner    (1001) docker     (127)    14227 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/performance_report.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     2528 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/performance_result.cu
--rw-r--r--   0 runner    (1001) docker     (127)    38798 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/problem_space.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    25183 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    24378 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    20915 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    26753 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu
--rw-r--r--   0 runner    (1001) docker     (127)    24567 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/util/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.841798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/
--rw-r--r--   0 runner    (1001) docker     (127)     2410 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9777 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/command_line.h
--rw-r--r--   0 runner    (1001) docker     (127)    19866 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     5104 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/debug.h
--rw-r--r--   0 runner    (1001) docker     (127)     5953 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h
--rw-r--r--   0 runner    (1001) docker     (127)    17696 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
--rw-r--r--   0 runner    (1001) docker     (127)    20881 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h
--rw-r--r--   0 runner    (1001) docker     (127)    10561 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h
--rw-r--r--   0 runner    (1001) docker     (127)     5219 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
--rw-r--r--   0 runner    (1001) docker     (127)    11075 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
--rw-r--r--   0 runner    (1001) docker     (127)    18653 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
--rw-r--r--   0 runner    (1001) docker     (127)     5214 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
--rw-r--r--   0 runner    (1001) docker     (127)     7096 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_rmsnorm.h
--rw-r--r--   0 runner    (1001) docker     (127)     4007 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h
--rw-r--r--   0 runner    (1001) docker     (127)     4846 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/distribution.h
--rw-r--r--   0 runner    (1001) docker     (127)     2674 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h
--rw-r--r--   0 runner    (1001) docker     (127)    13740 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/gett_commandline.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     3946 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4821 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h
--rw-r--r--   0 runner    (1001) docker     (127)    18299 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h
--rw-r--r--   0 runner    (1001) docker     (127)    20354 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     5890 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h
--rw-r--r--   0 runner    (1001) docker     (127)     1962 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h
--rw-r--r--   0 runner    (1001) docker     (127)     4686 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    11254 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.577798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.841798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/
--rw-r--r--   0 runner    (1001) docker     (127)     4606 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
--rw-r--r--   0 runner    (1001) docker     (127)     3527 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.841798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/
--rw-r--r--   0 runner    (1001) docker     (127)    48350 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)    14296 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)    10652 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     9652 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     5444 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gett.hpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.841798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
--rw-r--r--   0 runner    (1001) docker     (127)     5381 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     6198 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
--rw-r--r--   0 runner    (1001) docker     (127)     5127 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
--rw-r--r--   0 runner    (1001) docker     (127)    11615 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     7278 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
--rw-r--r--   0 runner    (1001) docker     (127)    49624 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
--rw-r--r--   0 runner    (1001) docker     (127)     5454 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
--rw-r--r--   0 runner    (1001) docker     (127)    15964 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
--rw-r--r--   0 runner    (1001) docker     (127)     4589 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.841798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/
--rw-r--r--   0 runner    (1001) docker     (127)     5872 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.845798 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/
--rw-r--r--   0 runner    (1001) docker     (127)    28652 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
--rw-r--r--   0 runner    (1001) docker     (127)     2766 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
--rw-r--r--   0 runner    (1001) docker     (127)    20938 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
--rw-r--r--   0 runner    (1001) docker     (127)     7161 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     7708 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    22747 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     9441 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
--rw-r--r--   0 runner    (1001) docker     (127)    11444 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     8148 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    10509 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
--rw-r--r--   0 runner    (1001) docker     (127)    12296 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)    11235 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
--rw-r--r--   0 runner    (1001) docker     (127)     3339 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     8317 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
--rw-r--r--   0 runner    (1001) docker     (127)     9027 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
--rw-r--r--   0 runner    (1001) docker     (127)    46990 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
--rw-r--r--   0 runner    (1001) docker     (127)    12875 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     4757 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
--rw-r--r--   0 runner    (1001) docker     (127)     2133 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
--rw-r--r--   0 runner    (1001) docker     (127)     6111 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
--rw-r--r--   0 runner    (1001) docker     (127)     5987 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp
--rw-r--r--   0 runner    (1001) docker     (127)     7670 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
--rw-r--r--   0 runner    (1001) docker     (127)     9874 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
--rw-r--r--   0 runner    (1001) docker     (127)     8341 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
--rw-r--r--   0 runner    (1001) docker     (127)     8809 2024-04-26 23:45:47.000000 flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.845798 flash_attn-2.5.8/csrc/flash_attn/
--rw-r--r--   0 runner    (1001) docker     (127)    72592 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/flash_api.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.853798 flash_attn-2.5.8/csrc/flash_attn/src/
--rw-r--r--   0 runner    (1001) docker     (127)     2824 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/alibi.h
--rw-r--r--   0 runner    (1001) docker     (127)     2260 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/block_info.h
--rw-r--r--   0 runner    (1001) docker     (127)     5773 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/dropout.h
--rw-r--r--   0 runner    (1001) docker     (127)     5738 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash.h
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    47687 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_kernel.h
--rw-r--r--   0 runner    (1001) docker     (127)    17327 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_launch_template.h
--rw-r--r--   0 runner    (1001) docker     (127)    20382 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_preprocess_kernel.h
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      386 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      384 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      376 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    72721 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_kernel.h
--rw-r--r--   0 runner    (1001) docker     (127)    23602 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_launch_template.h
--rw-r--r--   0 runner    (1001) docker     (127)      335 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      331 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      335 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      331 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      335 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      331 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      335 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim224_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      331 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim224_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      335 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      331 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      334 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      330 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      334 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      330 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      334 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)      330 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.cu
--rw-r--r--   0 runner    (1001) docker     (127)    17210 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/kernel_traits.h
--rw-r--r--   0 runner    (1001) docker     (127)    11224 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/mask.h
--rw-r--r--   0 runner    (1001) docker     (127)     1679 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/philox.cuh
--rw-r--r--   0 runner    (1001) docker     (127)     8960 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/rotary.h
--rw-r--r--   0 runner    (1001) docker     (127)     9324 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/softmax.h
--rw-r--r--   0 runner    (1001) docker     (127)     3767 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/static_switch.h
--rw-r--r--   0 runner    (1001) docker     (127)    17698 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/flash_attn/src/utils.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.857798 flash_attn-2.5.8/csrc/ft_attention/
--rw-r--r--   0 runner    (1001) docker     (127)     8253 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/cuda_bf16_fallbacks.cuh
--rw-r--r--   0 runner    (1001) docker     (127)      867 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/cuda_bf16_wrapper.h
--rw-r--r--   0 runner    (1001) docker     (127)     6827 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention.cu
--rw-r--r--   0 runner    (1001) docker     (127)     7733 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention.h
--rw-r--r--   0 runner    (1001) docker     (127)    57953 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp
--rw-r--r--   0 runner    (1001) docker     (127)    64946 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
--rw-r--r--   0 runner    (1001) docker     (127)    10432 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/ft_attention/ft_attention.cpp
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.857798 flash_attn-2.5.8/csrc/fused_dense_lib/
--rw-r--r--   0 runner    (1001) docker     (127)    10179 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_dense_lib/fused_dense.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    24690 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_dense_lib/fused_dense_cuda.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.857798 flash_attn-2.5.8/csrc/fused_softmax/
--rw-r--r--   0 runner    (1001) docker     (127)     5037 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/fused_softmax.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    23616 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/scaled_masked_softmax.h
--rw-r--r--   0 runner    (1001) docker     (127)     4209 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
--rw-r--r--   0 runner    (1001) docker     (127)    24659 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
--rw-r--r--   0 runner    (1001) docker     (127)     3154 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1216 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/fused_softmax/type_shim.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/csrc/layer_norm/
--rw-r--r--   0 runner    (1001) docker     (127)     7248 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln.h
--rw-r--r--   0 runner    (1001) docker     (127)    36420 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_api.cpp
--rw-r--r--   0 runner    (1001) docker     (127)      987 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1024.cu
--rw-r--r--   0 runner    (1001) docker     (127)      987 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1280.cu
--rw-r--r--   0 runner    (1001) docker     (127)      977 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1536.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_2048.cu
--rw-r--r--   0 runner    (1001) docker     (127)      977 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_256.cu
--rw-r--r--   0 runner    (1001) docker     (127)      977 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_2560.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_3072.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_4096.cu
--rw-r--r--   0 runner    (1001) docker     (127)      977 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_512.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_5120.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_6144.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_7168.cu
--rw-r--r--   0 runner    (1001) docker     (127)      977 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_768.cu
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_8192.cu
--rw-r--r--   0 runner    (1001) docker     (127)    25647 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_bwd_kernels.cuh
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1024.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1280.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1536.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_2048.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_256.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_2560.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_3072.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_4096.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_512.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_5120.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_6144.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_7168.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_768.cu
--rw-r--r--   0 runner    (1001) docker     (127)      925 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_8192.cu
--rw-r--r--   0 runner    (1001) docker     (127)    12721 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_fwd_kernels.cuh
--rw-r--r--   0 runner    (1001) docker     (127)     6655 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_kernel_traits.h
--rw-r--r--   0 runner    (1001) docker     (127)     1095 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1024.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1095 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1280.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1536.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_2048.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_256.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_2560.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_3072.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1145 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_4096.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_512.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1145 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_5120.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_6144.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_7168.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_768.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_8192.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1024.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1280.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1536.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_2048.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1032 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_256.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_2560.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_3072.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_4096.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_512.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_5120.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_6144.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_7168.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_768.cu
--rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_8192.cu
--rw-r--r--   0 runner    (1001) docker     (127)    24916 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
--rw-r--r--   0 runner    (1001) docker     (127)    12530 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
--rw-r--r--   0 runner    (1001) docker     (127)    29989 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/ln_utils.cuh
--rw-r--r--   0 runner    (1001) docker     (127)     1278 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/layer_norm/static_switch.h
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/csrc/rotary/
--rw-r--r--   0 runner    (1001) docker     (127)     1806 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/rotary/rotary.cpp
--rw-r--r--   0 runner    (1001) docker     (127)     1984 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/rotary/rotary_cuda.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/csrc/xentropy/
--rw-r--r--   0 runner    (1001) docker     (127)     2290 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/xentropy/interface.cpp
--rw-r--r--   0 runner    (1001) docker     (127)    25783 2024-04-26 23:45:14.000000 flash_attn-2.5.8/csrc/xentropy/xentropy_kernel.cu
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/flash_attn/
--rw-r--r--   0 runner    (1001) docker     (127)      285 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     9535 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/bert_padding.py
--rw-r--r--   0 runner    (1001) docker     (127)    45333 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/flash_attn_interface.py
--rw-r--r--   0 runner    (1001) docker     (127)    41112 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/flash_attn_triton.py
--rw-r--r--   0 runner    (1001) docker     (127)    11328 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/flash_attn_triton_og.py
--rw-r--r--   0 runner    (1001) docker     (127)     7469 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/flash_blocksparse_attention.py
--rw-r--r--   0 runner    (1001) docker     (127)     7265 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/flash_blocksparse_attn_interface.py
--rw-r--r--   0 runner    (1001) docker     (127)     7793 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/fused_softmax.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/flash_attn/layers/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2136 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/layers/patch_embed.py
--rw-r--r--   0 runner    (1001) docker     (127)    18874 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/layers/rotary.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/flash_attn/losses/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3130 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/losses/cross_entropy.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/flash_attn/models/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5730 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/baichuan.py
--rw-r--r--   0 runner    (1001) docker     (127)    33241 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/bert.py
--rw-r--r--   0 runner    (1001) docker     (127)     9383 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/bigcode.py
--rw-r--r--   0 runner    (1001) docker     (127)     4631 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/btlm.py
--rw-r--r--   0 runner    (1001) docker     (127)     6033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/falcon.py
--rw-r--r--   0 runner    (1001) docker     (127)    47663 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/gpt.py
--rw-r--r--   0 runner    (1001) docker     (127)     5159 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/gpt_neox.py
--rw-r--r--   0 runner    (1001) docker     (127)     4436 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/gptj.py
--rw-r--r--   0 runner    (1001) docker     (127)    16581 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/llama.py
--rw-r--r--   0 runner    (1001) docker     (127)     5164 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/opt.py
--rw-r--r--   0 runner    (1001) docker     (127)    14074 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/models/vit.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.869799 flash_attn-2.5.8/flash_attn/modules/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    17349 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/modules/block.py
--rw-r--r--   0 runner    (1001) docker     (127)     8693 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/modules/embedding.py
--rw-r--r--   0 runner    (1001) docker     (127)    43295 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/modules/mha.py
--rw-r--r--   0 runner    (1001) docker     (127)     6033 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/modules/mlp.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.869799 flash_attn-2.5.8/flash_attn/ops/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3936 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/activations.py
--rw-r--r--   0 runner    (1001) docker     (127)    27907 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/fused_dense.py
--rw-r--r--   0 runner    (1001) docker     (127)    22443 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/layer_norm.py
--rw-r--r--   0 runner    (1001) docker     (127)     3988 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/rms_norm.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.869799 flash_attn-2.5.8/flash_attn/ops/triton/
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    12531 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/cross_entropy.py
--rw-r--r--   0 runner    (1001) docker     (127)     4034 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/k_activations.py
--rw-r--r--   0 runner    (1001) docker     (127)    35020 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/layer_norm.py
--rw-r--r--   0 runner    (1001) docker     (127)    20841 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/linear.py
--rw-r--r--   0 runner    (1001) docker     (127)     6068 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/mlp.py
--rw-r--r--   0 runner    (1001) docker     (127)     8582 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/ops/triton/rotary.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.869799 flash_attn-2.5.8/flash_attn/utils/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7369 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/utils/benchmark.py
--rw-r--r--   0 runner    (1001) docker     (127)     5825 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/utils/distributed.py
--rw-r--r--   0 runner    (1001) docker     (127)    30466 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/utils/generation.py
--rw-r--r--   0 runner    (1001) docker     (127)     3246 2024-04-26 23:45:14.000000 flash_attn-2.5.8/flash_attn/utils/pretrained.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-26 23:45:48.865798 flash_attn-2.5.8/flash_attn.egg-info/
--rw-r--r--   0 runner    (1001) docker     (127)    19056 2024-04-26 23:45:48.000000 flash_attn-2.5.8/flash_attn.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)   114785 2024-04-26 23:45:48.000000 flash_attn-2.5.8/flash_attn.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-04-26 23:45:48.000000 flash_attn-2.5.8/flash_attn.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (127)       29 2024-04-26 23:45:48.000000 flash_attn-2.5.8/flash_attn.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (127)       11 2024-04-26 23:45:48.000000 flash_attn-2.5.8/flash_attn.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (127)       38 2024-04-26 23:45:48.869799 flash_attn-2.5.8/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (127)    15348 2024-04-26 23:45:14.000000 flash_attn-2.5.8/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.693900 flash_attn-2.5.9.post1/
+-rw-r--r--   0 runner    (1001) docker     (127)       29 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/AUTHORS
+-rw-r--r--   0 runner    (1001) docker     (127)     1558 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (127)      315 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (127)    19062 2024-05-27 05:19:12.693900 flash_attn-2.5.9.post1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)    18583 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/README.md
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/cmake/
+-rw-r--r--   0 runner    (1001) docker     (127)     2023 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/cmake/nop.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.413905 flash_attn-2.5.9.post1/csrc/cutlass/examples/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/00_basic_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    14698 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/01_cutlass_utilities/
+-rw-r--r--   0 runner    (1001) docker     (127)    13255 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/02_dump_reg_shmem/
+-rw-r--r--   0 runner    (1001) docker     (127)     7157 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/
+-rw-r--r--   0 runner    (1001) docker     (127)     4478 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/options.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7081 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     2691 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5819 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    11425 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/04_tile_iterator/
+-rw-r--r--   0 runner    (1001) docker     (127)     8229 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/05_batched_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    15185 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/06_splitK_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    17570 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    18283 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    18228 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/
+-rw-r--r--   0 runner    (1001) docker     (127)    28142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/10_planar_complex/
+-rw-r--r--   0 runner    (1001) docker     (127)    21947 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/11_planar_complex_array/
+-rw-r--r--   0 runner    (1001) docker     (127)    23244 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.425905 flash_attn-2.5.9.post1/csrc/cutlass/examples/12_gemm_bias_relu/
+-rw-r--r--   0 runner    (1001) docker     (127)    13152 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.429905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    26102 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24557 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18662 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_grouped_gemm_run.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28268 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26174 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.429905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    12711 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11520 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8756 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8759 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8712 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8762 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8782 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8785 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8711 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8775 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7269 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7338 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7294 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7359 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10064 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_grouped_f16_sm80_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7358 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7424 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11029 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7619 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)    30434 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6120 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm_grouped_problem_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18151 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3973 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26762 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26775 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28422 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28073 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19973 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15092 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6380 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/grouped.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.405905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    14663 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3577 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    31616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    31443 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21012 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20494 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7983 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6047 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    34515 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    34226 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21820 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21434 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27144 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27400 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5719 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/grouped_threadblock_swizzle.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    18020 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    15042 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15957 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm_with_visitor.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/
+-rw-r--r--   0 runner    (1001) docker     (127)    28030 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.433905 flash_attn-2.5.9.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/
+-rw-r--r--   0 runner    (1001) docker     (127)    12580 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    14007 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/19_tensorop_canonical/
+-rw-r--r--   0 runner    (1001) docker     (127)    13401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/20_simt_canonical/
+-rw-r--r--   0 runner    (1001) docker     (127)    12556 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/21_quaternion_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    17319 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/22_quaternion_conv/
+-rw-r--r--   0 runner    (1001) docker     (127)    21423 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    27556 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/24_gemm_grouped/
+-rw-r--r--   0 runner    (1001) docker     (127)    50898 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    26547 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25628 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    25538 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    30398 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
+-rw-r--r--   0 runner    (1001) docker     (127)    28159 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    28338 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_3xtf32_complex_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/30_wgrad_split_k/
+-rw-r--r--   0 runner    (1001) docker     (127)    27304 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/31_basic_syrk/
+-rw-r--r--   0 runner    (1001) docker     (127)    15202 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/32_basic_trmm/
+-rw-r--r--   0 runner    (1001) docker     (127)    15906 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
+-rw-r--r--   0 runner    (1001) docker     (127)    31765 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/34_transposed_conv2d/
+-rw-r--r--   0 runner    (1001) docker     (127)    22378 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/
+-rw-r--r--   0 runner    (1001) docker     (127)    23120 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16723 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19055 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/36_gather_scatter_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    21008 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    31111 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13982 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    33900 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.437904 flash_attn-2.5.9.post1/csrc/cutlass/examples/38_syr2k_grouped/
+-rw-r--r--   0 runner    (1001) docker     (127)    47468 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.441904 flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/
+-rw-r--r--   0 runner    (1001) docker     (127)    48551 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15309 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/layouts.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11985 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/permute_info.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.441904 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/
+-rw-r--r--   0 runner    (1001) docker     (127)    11871 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10832 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.441904 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/
+-rw-r--r--   0 runner    (1001) docker     (127)    22356 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9162 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6118 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
+-rw-r--r--   0 runner    (1001) docker     (127)    37291 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6666 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11208 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multi_head_attention_backward.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    38221 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    40006 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.441904 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)     3994 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6248 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26967 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14105 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6782 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13959 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    68653 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11075 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/
+-rw-r--r--   0 runner    (1001) docker     (127)     5776 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/default_warp_iterator_from_smem.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23862 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
+-rw-r--r--   0 runner    (1001) docker     (127)    64473 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
+-rw-r--r--   0 runner    (1001) docker     (127)    64507 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2512 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10063 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
+-rw-r--r--   0 runner    (1001) docker     (127)    97640 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_backward.h
+-rw-r--r--   0 runner    (1001) docker     (127)    52585 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/
+-rw-r--r--   0 runner    (1001) docker     (127)     3761 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/
+-rw-r--r--   0 runner    (1001) docker     (127)    23901 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    23867 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.409905 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.409905 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)     6370 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4099 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8285 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10439 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)     6848 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.409905 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)    14747 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10231 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3745 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    16953 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12642 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     2366 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h
+-rw-r--r--   0 runner    (1001) docker     (127)    31509 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)    18413 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3577 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/test_run.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     5818 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    15613 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7920 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29897 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.445904 flash_attn-2.5.9.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/
+-rw-r--r--   0 runner    (1001) docker     (127)    24772 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/
+-rw-r--r--   0 runner    (1001) docker     (127)    22676 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    30694 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk_broadcast.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    17286 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/
+-rw-r--r--   0 runner    (1001) docker     (127)    30447 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/49_collective_builder.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/
+-rw-r--r--   0 runner    (1001) docker     (127)    18806 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/51_hopper_gett/
+-rw-r--r--   0 runner    (1001) docker     (127)    17340 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/51_hopper_gett/51_hopper_gett.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5599 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/51_hopper_gett/gett_kernel.cuh
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    27605 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/52_hopper_gather_scatter_fusion.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17965 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_gemm.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5606 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_kernel.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)     8543 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/scatter_epilogue.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/
+-rw-r--r--   0 runner    (1001) docker     (127)    45401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/53_hopper_gemm_permute.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4084 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/permute_kernel.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)    11441 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/permute_traits.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    22065 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/54_hopper_fp8_warp_specialized_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/hopper_fp8_commandline.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    31597 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/55_hopper_mixed_dtype_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7838 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/unfused_weight_dequantize.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    19510 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/56_hopper_ptr_array_batched_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/57_hopper_grouped_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    26735 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/58_ada_fp8_gemm/
+-rw-r--r--   0 runner    (1001) docker     (127)    28799 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/58_ada_fp8_gemm/ada_fp8_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/59_ampere_gather_scatter_conv/
+-rw-r--r--   0 runner    (1001) docker     (127)    12530 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/59_ampere_gather_scatter_conv/ampere_conv_kernel.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17356 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/59_ampere_gather_scatter_conv/ampere_gather_scatter_conv.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/60_cutlass_import/
+-rw-r--r--   0 runner    (1001) docker     (127)     2849 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/60_cutlass_import/main.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.449904 flash_attn-2.5.9.post1/csrc/cutlass/examples/common/
+-rw-r--r--   0 runner    (1001) docker     (127)     7085 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/common/gather_tensor.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4469 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/common/helper.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.413905 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.453904 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/
+-rw-r--r--   0 runner    (1001) docker     (127)    17292 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/sgemm_1.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19286 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/sgemm_2.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18881 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/sgemm_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19981 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/sgemm_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9890 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/tiled_copy.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.413905 flash_attn-2.5.9.post1/csrc/cutlass/include/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.453904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.457904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/
+-rw-r--r--   0 runner    (1001) docker     (127)     3276 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/axpby.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2351 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/clear.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9711 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/cooperative_copy.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    22774 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/cooperative_gemm.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13575 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/copy.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2906 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/fill.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10890 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/functional.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18275 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/gemm.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2124 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/prefer.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5742 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/prefetch.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5238 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    27396 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.461904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/
+-rw-r--r--   0 runner    (1001) docker     (127)     7642 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3474 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2686 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm50.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7739 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm75.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6856 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm80.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7566 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm90.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    14193 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    49750 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2393 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3172 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm61.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    12500 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm70.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4274 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm75.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    68808 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm80.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    53627 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6172 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)   946916 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8810 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/util.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.461904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/
+-rw-r--r--   0 runner    (1001) docker     (127)    27595 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_atom.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5684 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2512 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm50.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5087 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7107 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4589 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    37568 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_im2col.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    56618 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2860 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma_swizzle.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    33597 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_atom.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8749 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2773 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6092 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3303 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    14088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5049 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)   189998 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5368 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/config.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.461904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/
+-rw-r--r--   0 runner    (1001) docker     (127)     2992 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/alignment.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9549 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2082 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array_aligned.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18091 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array_subbyte.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5490 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/bit_field.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4615 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/cuda_types.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    20607 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/tuple.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4225 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/type_list.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    28072 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/int_tuple.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    61599 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/layout.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18072 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/layout_composed.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.465904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/
+-rw-r--r--   0 runner    (1001) docker     (127)    14952 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2796 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/complex.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3880 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/int.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4671 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13829 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integral_constant.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7312 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integral_ratio.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9038 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/math.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2949 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/numeric_types.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2259 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/real.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8583 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8336 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_base.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5725 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_flagged.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6136 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_swizzle.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    16790 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/stride.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    15513 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/swizzle.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    21354 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/swizzle_layout.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    35447 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/tensor.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2595 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/tensor_predicate.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6246 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/underscore.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.465904 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/
+-rw-r--r--   0 runner    (1001) docker     (127)     5010 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/debug.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4310 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/print.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8197 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/type_traits.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.473904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/
+-rw-r--r--   0 runner    (1001) docker     (127)     3793 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/aligned_buffer.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.477904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/
+-rw-r--r--   0 runner    (1001) docker     (127)     3628 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/arch.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20151 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/barrier.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2691 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/cache_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18305 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8260 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15163 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9800 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11096 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm50.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7040 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm60.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4193 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm61.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16554 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)    31990 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    57636 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11290 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm89.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8419 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm90.h
+-rw-r--r--   0 runner    (1001) docker     (127)    43978 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12126 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm89.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2621 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3998 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3590 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd_sm60.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5102 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd_sm61.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8473 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5286 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7746 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    67892 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3463 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13434 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array_subbyte.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12433 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/barrier.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13884 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/bfloat16.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5294 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/blas3.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3263 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/blas3_types.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9386 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/block_striped.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cluster_launch.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    19734 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    47943 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/constants.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.477904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.477904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/
+-rw-r--r--   0 runner    (1001) docker     (127)     3783 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/collective_builder.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2853 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/collective_conv.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10716 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/detail.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    27380 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/sm90_implicit_gemm_gmma_ss_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23132 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18158 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22931 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/convnd_problem_shape.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7293 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/convolution.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.477904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    16194 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/conv_universal_adapter.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9743 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13380 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10044 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3636 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/dispatch_policy.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.481904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)     2888 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/conv_universal.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8632 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h
+-rw-r--r--   0 runner    (1001) docker     (127)    53546 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)    57134 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11951 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4609 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6978 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4657 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19662 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28745 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10459 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20919 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27125 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11978 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6953 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26380 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27986 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_deconv2d.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8912 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_deconv2d_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15389 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_deconv3d.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8917 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_deconv3d_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19289 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18078 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15458 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15729 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17257 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16581 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16738 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16865 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/sm90_implicit_gemm_tma_warpspecialized.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.481904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     9689 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.489904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    15306 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19735 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18940 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26136 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10977 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11529 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11333 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13688 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11164 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9314 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9018 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10689 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    30197 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11202 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10349 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11519 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9043 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10832 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8450 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9569 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11020 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15014 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9634 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15132 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8307 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9126 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18249 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9971 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12024 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8821 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10744 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8871 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10747 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9899 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20899 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8921 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12745 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8097 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    36697 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
+-rw-r--r--   0 runner    (1001) docker     (127)    30106 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19808 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12175 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26320 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16915 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12476 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8050 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.489904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)    12392 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)    30655 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8704 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11827 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/coord.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10992 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/core_io.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7249 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cuda_host_adapter.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6478 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cutlass.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.489904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/
+-rw-r--r--   0 runner    (1001) docker     (127)     3048 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/collective.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3710 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/dependent_false.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5745 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/helper_macros.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    12305 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/layout.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3089 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/mma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4321 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/device_kernel.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.489904 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.493903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/
+-rw-r--r--   0 runner    (1001) docker     (127)     4425 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_builder.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2957 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9243 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10494 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue_array.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9625 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/detail.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    11386 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue_tensor_broadcast.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    14012 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm70_epilogue_vectorized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    34828 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5427 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized_bias_elementwise.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6133 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.493903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)     4128 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/callbacks.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    12105 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/operations.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    55072 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    28888 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_compute_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    32867 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_load_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    57933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_store_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    39461 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_tma_warpspecialized.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.497903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)    17909 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4691 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2281 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/detail.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18989 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13180 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18161 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23370 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9066 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15195 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3669 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10056 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13185 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic_with_scaling.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3693 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8399 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3046 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9278 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20596 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19458 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11995 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3688 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3669 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9786 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_tensor_broadcast.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8662 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3416 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3048 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.505903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)     9142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9441 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3234 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7209 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14255 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29301 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7134 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10846 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4264 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10301 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5763 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5947 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4409 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7398 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7303 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4098 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4678 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19249 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8279 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7455 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13424 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14610 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9073 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15321 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16804 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    34018 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    58727 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29199 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13454 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17169 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7308 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.505903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/
+-rw-r--r--   0 runner    (1001) docker     (127)    14524 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_2x.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4387 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_compute.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    17753 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_load.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    25534 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_store.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2171 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitors.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    14359 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6881 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19842 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
+-rw-r--r--   0 runner    (1001) docker     (127)    41699 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18821 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5636 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21249 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17563 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_conv.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13873 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14985 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9146 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15534 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7487 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18100 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7396 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_linear.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.505903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)     7055 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7736 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5880 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9883 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8924 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6045 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4864 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5979 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25658 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20290 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    33300 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14250 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7704 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7485 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3916 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28949 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/fast_math.h
+-rw-r--r--   0 runner    (1001) docker     (127)    37129 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/float8.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2645 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17870 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/functional.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.505903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.509903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/
+-rw-r--r--   0 runner    (1001) docker     (127)     3771 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3668 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4768 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/fp8_accumulation.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    22247 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    27955 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    33255 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    28408 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_rs_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    19434 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    33465 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    63323 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized_mixed_input.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    22544 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    24000 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    24138 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized_fp8.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.513903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    16881 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27521 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27618 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25202 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22367 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22375 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22725 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2591 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13736 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17329 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12258 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11362 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20436 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15630 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24236 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15624 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14027 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_streamk_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13785 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13968 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14853 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5961 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemv.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18127 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2747 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16719 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)    21050 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/symm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26464 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/trmm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10458 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4630 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3174 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/gemm_enumerated_types.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4265 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/group_array_problem_shape.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.525903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)    29360 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    42401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16130 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12385 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6592 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5848 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11104 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10526 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6102 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8175 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4932 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5446 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_streamk_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12332 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5697 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5115 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8123 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6457 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8084 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)     5349 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11560 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20509 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12480 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10630 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9872 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16990 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9454 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)    13375 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)    21830 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)    10325 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10873 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10730 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10860 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28837 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13362 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8698 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8746 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14394 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4690 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15268 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27550 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)     5979 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5150 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23348 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18886 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
+-rw-r--r--   0 runner    (1001) docker     (127)    80158 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_streamk_with_fused_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4291 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23549 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4374 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    39338 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10423 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28827 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor_streamk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24030 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)    47839 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23866 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18393 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)     8954 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16765 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3934 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_sparse_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8456 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23027 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16100 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4334 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24214 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17597 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11132 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    35170 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_array_tma_warpspecialized_cooperative.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13178 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18554 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    29017 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_cooperative.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    28200 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_pingpong.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18200 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23028 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_cooperative.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23103 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_pingpong.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5511 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18488 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_group.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    39150 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_stream_k.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13183 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16350 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8144 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_visitor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16041 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/static_tile_scheduler.hpp
+-rwxr-xr-x   0 runner    (1001) docker     (127)    23516 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4414 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    58093 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19233 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.525903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     3567 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15399 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29390 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.533903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    31930 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)     6979 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
+-rw-r--r--   0 runner    (1001) docker     (127)    35582 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5123 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
+-rw-r--r--   0 runner    (1001) docker     (127)    57426 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19257 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)    44176 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)   104675 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    32106 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12650 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7387 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20975 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7998 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5110 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4627 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7113 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6323 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7121 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4959 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
+-rw-r--r--   0 runner    (1001) docker     (127)    65005 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25495 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8509 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19515 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24233 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13837 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)     4726 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3652 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7823 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27600 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    32816 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27786 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15995 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6901 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22839 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14747 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9864 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27246 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9210 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25557 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20395 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15041 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
+-rw-r--r--   0 runner    (1001) docker     (127)    26219 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.537903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)    20553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6684 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5178 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12142 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4053 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4685 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5691 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2619 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    37767 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23132 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
+-rw-r--r--   0 runner    (1001) docker     (127)    78519 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21178 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14589 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20271 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_mixed_input_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6144 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8419 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3079 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)    59793 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13497 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13956 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15721 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20472 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2939 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8966 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11017 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)   162811 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    99553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)    75040 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13151 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27101 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7241 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17303 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19101 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4610 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8728 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10599 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm_coord.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2875 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm_coord.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23630 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/half.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7942 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/integer_subbyte.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2784 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2006 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2801 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_launch.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/
+-rw-r--r--   0 runner    (1001) docker     (127)     3020 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/layout.h
+-rw-r--r--   0 runner    (1001) docker     (127)    34719 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/matrix.h
+-rw-r--r--   0 runner    (1001) docker     (127)    24906 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/permute.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4697 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/pitch_linear.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19044 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29599 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)    33494 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29336 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3354 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/vector.h
+-rw-r--r--   0 runner    (1001) docker     (127)   364115 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4991 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix_coord.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2726 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix_shape.h
+-rw-r--r--   0 runner    (1001) docker     (127)   125928 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_conversion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3129 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_size.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3385 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_types.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pipeline/
+-rw-r--r--   0 runner    (1001) docker     (127)     2091 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pipeline/pipeline.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    37271 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pipeline/sm90_pipeline.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5492 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pitch_linear_coord.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/platform/
+-rw-r--r--   0 runner    (1001) docker     (127)    27863 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/platform/platform.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16279 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/predicate_vector.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20891 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/quaternion.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2369 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/real.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/
+-rw-r--r--   0 runner    (1001) docker     (127)     6749 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8152 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11579 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11448 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)     8815 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7897 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20690 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21672 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     7208 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6790 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2936 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6572 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/relatively_equal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3984 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/semaphore.h
+-rw-r--r--   0 runner    (1001) docker     (127)    38253 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/subbyte_reference.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8964 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_coord.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12207 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_ref.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11201 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9509 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_view.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10250 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13017 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tfloat32.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     5893 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/thread/matrix.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2581 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/trace.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/collective/
+-rw-r--r--   0 runner    (1001) docker     (127)    33948 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/collective/sm90_wgmma_transpose.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    33349 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.541903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     3835 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/thread/transpose.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4309 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.545903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)     6181 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    44443 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    44309 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12890 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11097 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    72537 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28232 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
+-rwxr-xr-x   0 runner    (1001) docker     (127)    10395 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
+-rw-r--r--   0 runner    (1001) docker     (127)    31412 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
+-rw-r--r--   0 runner    (1001) docker     (127)    62949 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27175 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28064 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8232 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2638 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13283 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18623 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
+-rw-r--r--   0 runner    (1001) docker     (127)    27938 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    47789 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16508 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15486 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
+-rw-r--r--   0 runner    (1001) docker     (127)    35956 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
+-rw-r--r--   0 runner    (1001) docker     (127)    43663 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5226 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.545903 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)     8828 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7899 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/uint128.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2899 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/version.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4540 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/wmma_array.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5116 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/workspace.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.417905 flash_attn-2.5.9.post1/csrc/cutlass/test/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.545903 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.545903 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cluster_launch/
+-rw-r--r--   0 runner    (1001) docker     (127)    12088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cluster_launch/cluster_launch.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.545903 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/common/
+-rw-r--r--   0 runner    (1001) docker     (127)     4900 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/common/cutlass_unit_test.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5419 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/common/filter_architecture.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.549903 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/
+-rw-r--r--   0 runner    (1001) docker     (127)    24671 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/cache_testbed_output.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.557902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/
+-rw-r--r--   0 runner    (1001) docker     (127)     5344 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5443 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5239 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9110 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8485 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5243 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5378 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12054 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9603 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5267 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5357 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5089 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13690 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5390 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5191 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11136 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5323 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3551 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14009 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f8nhwc_f8nhwc_f8nhwc_tensor_op_f32_sm89.cu
+-rwxr-xr-x   0 runner    (1001) docker     (127)     8278 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20647 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5150 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5239 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    26113 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    26210 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5106 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5194 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5738 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6919 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_simt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5439 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7363 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3984 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    43173 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14471 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4173 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_swizzling4_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4662 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    26536 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22108 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5179 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5358 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5264 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3615 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7591 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10514 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5157 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5772 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    23205 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_absmax_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25144 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21512 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5135 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5331 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5347 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3736 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6604 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5162 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5257 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6931 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_with_broadcast_simt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13487 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22559 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3622 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6560 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5161 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5256 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24454 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_with_broadcast_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5198 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/deconv2d_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6908 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/deconv2d_with_broadcast_simt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5288 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/deconv3d_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6922 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/deconv3d_with_broadcast_simt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17721 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18451 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    22194 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9383 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20090 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.557902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/
+-rw-r--r--   0 runner    (1001) docker     (127)    29258 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/conv_problem_sizes.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.561902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/
+-rw-r--r--   0 runner    (1001) docker     (127)    15995 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv1d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15914 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv1d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16058 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv2d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15917 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv2d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16054 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv3d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15973 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv3d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.561902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/
+-rw-r--r--   0 runner    (1001) docker     (127)    16566 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16485 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15966 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15549 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16629 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16549 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16029 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15613 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16685 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16605 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16085 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15669 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20893 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/testbed_conv.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.561902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/
+-rw-r--r--   0 runner    (1001) docker     (127)    16011 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv1d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv1d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16074 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv2d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15997 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv2d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16131 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv3d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16053 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv3d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.565902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/
+-rw-r--r--   0 runner    (1001) docker     (127)     7410 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/array.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7353 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/bfloat16.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6981 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/complex.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6534 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/fast_numeric_conversion.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4608 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/float8.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13001 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/functional.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/half.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5295 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/matrix.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8592 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/matrix_coord.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    22908 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/numeric_conversion.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8148 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/predicate_vector.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5777 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/quaternion.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tensor_ref.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8885 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tensor_view.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     2050 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/test_unit_core.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tfloat32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4215 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/uint128.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.565902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.565902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/
+-rw-r--r--   0 runner    (1001) docker     (127)    11094 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/cooperative_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3527 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14320 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6658 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/tiled_cp_async.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5837 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/tiled_cp_async_testbed.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    18240 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/cooperative_gemm_common.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/
+-rw-r--r--   0 runner    (1001) docker     (127)     6976 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/array_subbyte.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3493 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/bitfield.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4861 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/coalesce.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8195 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/compact_xmajor.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5620 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/compare.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8150 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/complement.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    12836 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/composition.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3195 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/constants.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2007 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/core_unit.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5000 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/int_tuple.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4856 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     6867 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7029 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5830 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/logical_product.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4668 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/math.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2956 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3267 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/nullspace.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3947 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/pointer.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4971 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/reverse.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2342 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/transform.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13304 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/tuple.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/
+-rw-r--r--   0 runner    (1001) docker     (127)     7025 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/bulk_load.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6386 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/bulk_store.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14367 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/stsm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18033 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7992 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_load_testbed.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3537 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_mcast_load.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8992 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_mcast_load_testbed.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    13192 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7572 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_store_testbed.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/layout/
+-rw-r--r--   0 runner    (1001) docker     (127)     4544 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/msvc_compilation/
+-rw-r--r--   0 runner    (1001) docker     (127)     6533 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/msvc_compilation/tuple.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/turing/
+-rw-r--r--   0 runner    (1001) docker     (127)     2474 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/turing/cooperative_gemm.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/volta/
+-rw-r--r--   0 runner    (1001) docker     (127)    20948 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/volta/cooperative_copy.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13971 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/volta/cooperative_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5409 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/volta/vectorization_auto.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.417905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.569902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)    15818 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/activation.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6534 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9965 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.573902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    13824 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    27176 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12061 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25275 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    84612 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    70486 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25293 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12624 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7743 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19178 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    28433 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10852 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11734 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.573902 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)     6783 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7315 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.417905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.629901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    53507 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10188 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33161 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10162 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17912 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8914 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16447 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16575 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8318 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8317 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6714 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7895 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7929 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6516 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6548 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9016 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9051 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4627 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6165 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6124 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9634 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16357 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13189 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8845 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13583 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13464 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9571 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16239 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6140 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9544 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16417 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13075 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8775 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6156 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6116 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3528 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3539 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15092 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16470 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13273 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13900 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8608 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13518 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3645 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6096 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7845 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18135 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13008 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8505 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11497 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11090 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6156 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6116 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11066 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17080 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3528 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3540 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7964 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16457 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13266 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12317 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    27384 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13551 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13540 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6130 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8160 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7847 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16131 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13014 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8754 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11497 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6147 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6107 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13518 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13398 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7845 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16149 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6119 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7827 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16101 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9526 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7898 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11470 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3584 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3473 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12967 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12931 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12930 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12895 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8349 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7299 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8348 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7290 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7093 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f32t_tensor_op_f32_sm89.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7206 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f32t_tensor_op_f32_sparse_sm89.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18766 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f8t_tensor_op_f32_sm89.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18936 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f8t_tensor_op_f32_sparse_sm89.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10240 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    26102 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11339 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7346 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12397 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6857 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7239 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8119 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16882 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8405 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8101 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17111 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12637 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8387 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10938 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18441 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17410 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33782 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9586 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11288 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3514 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_f16t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7975 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16531 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5693 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7957 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16691 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12408 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6864 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8538 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18204 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6675 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18325 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    43279 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6663 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4663 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4945 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10581 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    68253 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    47284 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_evt.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    20070 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_tensor_broadcast.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    16950 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16902 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15131 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16855 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6854 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10186 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6686 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6755 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6687 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4726 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4718 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3955 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_s8n_f16t_mixed_input_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3956 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_u8n_f16t_mixed_input_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13843 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3958 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3959 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_u8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17827 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12841 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4544 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17409 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemv.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6028 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6031 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6064 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6067 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4908 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6037 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6040 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5382 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5406 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13055 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13027 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5388 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6939 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7677 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7725 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3853 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6396 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10121 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10270 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11186 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    46795 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    54085 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8318 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    46687 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8411 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    46578 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    40533 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    47656 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    40441 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    40354 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3513 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    89517 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    89304 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    89304 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    89091 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    69175 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    71438 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    67796 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    70056 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7156 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6067 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9063 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    35894 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    35813 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    35813 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    35732 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    70872 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    73136 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8870 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    69488 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8865 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    71755 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33231 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33156 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33156 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    33081 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5238 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5253 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5357 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5479 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5238 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5253 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3875 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3734 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6264 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19552 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_evt_operations.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5474 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6888 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6966 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6939 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_pingpong.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8187 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14314 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19733 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20045 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19937 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_pingpong.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    34699 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25032 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25544 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    35857 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9672 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_load.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    29570 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_store.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24553 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_bias_elementwise.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7283 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_dag.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8513 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_reduce.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6899 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_row_broadcast.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    53256 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9603 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_aux_load.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20429 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_bias_elementwise.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7252 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_dag.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8467 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_reduce.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6868 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_row_broadcast.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    40354 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cooperative_stream_k.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11938 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_tensor_broadcast.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9732 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8365 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6382 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32_tensor_broadcast.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    22739 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8472 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32_evt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    22313 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8418 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative_evt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    23697 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cooperative_stream_k.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9764 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    22879 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_fp32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    54394 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8504 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32_evt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5295 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6593 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6662 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6644 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_pingpong.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15791 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4566 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32_tensor_broadcast.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12616 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_stream_k_scheduler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5297 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6590 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6659 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_cooperative.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6641 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_pingpong.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7972 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    21505 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32_gmma_rs_cluster_warpspecialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5923 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5926 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5959 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5962 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4838 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5983 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5932 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5935 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15203 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8623 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15104 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4777 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8103 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8108 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8088 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8093 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8073 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8078 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8058 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8063 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15071 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8551 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14972 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5362 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5386 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5432 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5456 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5378 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12952 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5444 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7208 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5362 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7199 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7190 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4794 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4783 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4739 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19145 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7991 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    11015 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7976 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12342 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7961 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12321 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4786 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4775 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4993 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5017 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4987 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5011 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5023 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4996 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3793 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4990 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16083 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16041 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4529 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7451 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9401 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16027 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15985 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20429 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8262 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20929 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19443 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16502 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16562 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17002 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14698 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10226 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9479 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20896 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15650 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8639 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15831 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6122 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19991 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20228 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17611 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2626 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20970 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_with_absmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9916 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9988 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4988 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4992 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9762 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15614 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8733 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14089 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14444 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4607 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12798 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12809 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12764 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12768 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12779 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15504 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8673 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13989 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14520 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.629901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/kernel/
+-rwxr-xr-x   0 runner    (1001) docker     (127)    46470 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu
+-rwxr-xr-x   0 runner    (1001) docker     (127)    14362 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.629901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     4847 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12503 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3109 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.629901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/host/
+-rw-r--r--   0 runner    (1001) docker     (127)     5198 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7161 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7124 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/testbed.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.633901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    25036 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4345 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
+-rw-r--r--   0 runner    (1001) docker     (127)   139907 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4644 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    94442 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16988 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13829 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14471 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    49052 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8407 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18705 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    78121 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    21051 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13703 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14171 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
+-rw-r--r--   0 runner    (1001) docker     (127)    29772 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12395 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3502 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12070 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16308 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12501 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/
+-rw-r--r--   0 runner    (1001) docker     (127)    22128 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10914 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9873 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15234 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_mixed_input_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    18220 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4920 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6291 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9297 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    38840 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    83461 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9087 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    48928 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    49294 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/testbed.h
+-rw-r--r--   0 runner    (1001) docker     (127)    25780 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7541 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6486 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/
+-rw-r--r--   0 runner    (1001) docker     (127)     5788 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/matrix.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5984 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/tensor.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7081 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.417905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/cutlass/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/
+-rw-r--r--   0 runner    (1001) docker     (127)     2096 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     5373 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/contraction.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2915 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/stdlib/
+-rw-r--r--   0 runner    (1001) docker     (127)     1828 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4250 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.637901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     2833 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_contraction.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5727 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_gemm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12365 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/
+-rw-r--r--   0 runner    (1001) docker     (127)    15387 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15083 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17024 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    19827 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7644 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4355 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/testbed.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    14684 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    15609 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)    11316 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     2228 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     3110 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6657 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/thread/testbed.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/substrate/
+-rw-r--r--   0 runner    (1001) docker     (127)     3312 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/substrate/dependent_false.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2047 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/test_unit.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/threadblock/
+-rw-r--r--   0 runner    (1001) docker     (127)    25530 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     9501 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/
+-rw-r--r--   0 runner    (1001) docker     (127)     2663 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4515 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/rms_norm.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7474 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/tensor_reduce.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.641901 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/
+-rw-r--r--   0 runner    (1001) docker     (127)     4414 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18334 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/descriptions.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16150 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/handle.h
+-rw-r--r--   0 runner    (1001) docker     (127)    21225 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/library.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4251 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19073 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2724 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5908 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/types.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8140 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/util.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.645901 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/
+-rw-r--r--   0 runner    (1001) docker     (127)    22377 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/conv2d_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13850 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/conv3d_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    35804 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/conv_operation_3x.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    42608 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/gemm_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13834 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    36802 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/handle.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13270 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/library_internal.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3634 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/manifest.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5551 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/operation_table.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12873 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/rank_2k_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11367 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/rank_k_operation.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.645901 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/
+-rw-r--r--   0 runner    (1001) docker     (127)     3482 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8435 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    10269 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.649901 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/
+-rw-r--r--   0 runner    (1001) docker     (127)     6746 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv2d.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     6286 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv3d.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17347 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5473 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e4m3out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e5m2out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e4m3out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     5070 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e5m2out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3633 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp32out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4262 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_bf16out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4260 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp16out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4260 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp32out.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     4056 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp_mixed_input.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3140 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp_other.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3729 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int4.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3683 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_canonical.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3721 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_32.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3744 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_64.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    16453 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4810 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     2669 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/singleton.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    13134 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/symm_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11698 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/trmm_operation.h
+-rw-r--r--   0 runner    (1001) docker     (127)    46683 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/util.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.649901 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/
+-rw-r--r--   0 runner    (1001) docker     (127)    18227 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv2d_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)    16101 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv3d_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10623 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cublas_helpers.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20435 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cudnn_helpers.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3233 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cutlass_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2454 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/debug.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7576 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_allocation.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4290 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_context.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6428 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/enumerated_types.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8590 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/gemm_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2725 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/gpu_timer.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7924 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9273 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/options.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4337 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_report.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3941 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_result.h
+-rw-r--r--   0 runner    (1001) docker     (127)    28189 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/problem_space.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6891 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_2k_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6830 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_k_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5452 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/reduction_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6471 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/sparse_gemm_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6933 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/symm_operation_profiler.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6599 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/trmm_operation_profiler.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.653900 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/
+-rw-r--r--   0 runner    (1001) docker     (127)    54272 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    48776 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    37138 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17066 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7351 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    78653 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/device_allocation.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8359 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/device_context.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     8313 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    44294 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     3892 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2374 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/main.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    26023 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    28314 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/options.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    14227 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/performance_report.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     2528 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/performance_result.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    38798 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/problem_space.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    25183 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24378 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    20915 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    26757 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24567 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.657900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/
+-rw-r--r--   0 runner    (1001) docker     (127)     2410 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9780 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h
+-rw-r--r--   0 runner    (1001) docker     (127)    19875 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5104 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/debug.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5958 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17696 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20881 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10561 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5219 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11075 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18653 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5214 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7237 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_rmsnorm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4007 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4846 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2674 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h
+-rw-r--r--   0 runner    (1001) docker     (127)    13740 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/gett_commandline.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     3946 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4821 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18542 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20354 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5890 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h
+-rw-r--r--   0 runner    (1001) docker     (127)     1962 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h
+-rw-r--r--   0 runner    (1001) docker     (127)    18060 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    12399 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.421905 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.657900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/
+-rw-r--r--   0 runner    (1001) docker     (127)     4606 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3521 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.661900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/
+-rw-r--r--   0 runner    (1001) docker     (127)    48350 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)    14296 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10652 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9652 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5444 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gett.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.661900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
+-rw-r--r--   0 runner    (1001) docker     (127)     5381 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6198 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5127 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11615 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7278 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
+-rw-r--r--   0 runner    (1001) docker     (127)    49333 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5454 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
+-rw-r--r--   0 runner    (1001) docker     (127)    15983 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4589 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.661900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/
+-rw-r--r--   0 runner    (1001) docker     (127)     5872 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.661900 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/
+-rw-r--r--   0 runner    (1001) docker     (127)    26866 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/conv.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    29064 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2766 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20938 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7161 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     7708 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    22815 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9441 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11444 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8148 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10509 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12296 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11235 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3339 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8317 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9027 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
+-rw-r--r--   0 runner    (1001) docker     (127)    47111 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
+-rw-r--r--   0 runner    (1001) docker     (127)    12875 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4757 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2133 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6129 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5987 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7670 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9874 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8341 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
+-rw-r--r--   0 runner    (1001) docker     (127)     8809 2024-05-27 05:19:10.000000 flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.661900 flash_attn-2.5.9.post1/csrc/flash_attn/
+-rw-r--r--   0 runner    (1001) docker     (127)    72592 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/flash_api.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.669900 flash_attn-2.5.9.post1/csrc/flash_attn/src/
+-rw-r--r--   0 runner    (1001) docker     (127)     2824 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/alibi.h
+-rw-r--r--   0 runner    (1001) docker     (127)     2260 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/block_info.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5773 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/dropout.h
+-rw-r--r--   0 runner    (1001) docker     (127)     5738 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash.h
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    47679 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_kernel.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17327 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_launch_template.h
+-rw-r--r--   0 runner    (1001) docker     (127)    20374 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_preprocess_kernel.h
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      384 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      376 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    72713 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_kernel.h
+-rw-r--r--   0 runner    (1001) docker     (127)    23602 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_launch_template.h
+-rw-r--r--   0 runner    (1001) docker     (127)      335 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      331 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      335 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      331 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      335 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      331 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      335 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim224_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      331 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim224_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      335 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      331 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      334 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      330 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      334 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      330 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      334 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      330 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    17202 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/kernel_traits.h
+-rw-r--r--   0 runner    (1001) docker     (127)    11224 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/mask.h
+-rw-r--r--   0 runner    (1001) docker     (127)     1679 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/philox.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)     8952 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/rotary.h
+-rw-r--r--   0 runner    (1001) docker     (127)     9324 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/softmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3767 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/static_switch.h
+-rw-r--r--   0 runner    (1001) docker     (127)    17655 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/flash_attn/src/utils.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.669900 flash_attn-2.5.9.post1/csrc/ft_attention/
+-rw-r--r--   0 runner    (1001) docker     (127)     8253 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/cuda_bf16_fallbacks.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)      867 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/cuda_bf16_wrapper.h
+-rw-r--r--   0 runner    (1001) docker     (127)     6827 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     7733 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention.h
+-rw-r--r--   0 runner    (1001) docker     (127)    57953 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    64946 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
+-rw-r--r--   0 runner    (1001) docker     (127)    10432 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/ft_attention/ft_attention.cpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.669900 flash_attn-2.5.9.post1/csrc/fused_dense_lib/
+-rw-r--r--   0 runner    (1001) docker     (127)    10179 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_dense_lib/fused_dense.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    24690 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_dense_lib/fused_dense_cuda.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.673900 flash_attn-2.5.9.post1/csrc/fused_softmax/
+-rw-r--r--   0 runner    (1001) docker     (127)     5037 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/fused_softmax.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23616 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_masked_softmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     4209 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24659 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
+-rw-r--r--   0 runner    (1001) docker     (127)     3154 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1216 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/fused_softmax/type_shim.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/csrc/layer_norm/
+-rw-r--r--   0 runner    (1001) docker     (127)     7248 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln.h
+-rw-r--r--   0 runner    (1001) docker     (127)    36420 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_api.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)      987 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1024.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      987 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1280.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      977 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1536.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_2048.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      977 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_256.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      977 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_2560.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_3072.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_4096.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      977 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_512.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_5120.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_6144.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_7168.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      977 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_768.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_8192.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    25647 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_kernels.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1024.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1280.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1536.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_2048.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_256.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_2560.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_3072.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_4096.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_512.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_5120.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_6144.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_7168.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_768.cu
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_8192.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    12721 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_kernels.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)     6655 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_kernel_traits.h
+-rw-r--r--   0 runner    (1001) docker     (127)     1095 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1024.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1095 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1280.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1536.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_2048.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_256.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_2560.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_3072.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1145 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_4096.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_512.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1145 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_5120.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_6144.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_7168.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_768.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1084 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_8192.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1024.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1280.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1536.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_2048.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1032 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_256.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_2560.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_3072.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_4096.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_512.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_5120.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_6144.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_7168.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_768.cu
+-rw-r--r--   0 runner    (1001) docker     (127)     1033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_8192.cu
+-rw-r--r--   0 runner    (1001) docker     (127)    24916 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)    12530 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)    29989 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/ln_utils.cuh
+-rw-r--r--   0 runner    (1001) docker     (127)     1278 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/layer_norm/static_switch.h
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/csrc/rotary/
+-rw-r--r--   0 runner    (1001) docker     (127)     1806 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/rotary/rotary.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)     1984 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/rotary/rotary_cuda.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/csrc/xentropy/
+-rw-r--r--   0 runner    (1001) docker     (127)     2290 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/xentropy/interface.cpp
+-rw-r--r--   0 runner    (1001) docker     (127)    25783 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/csrc/xentropy/xentropy_kernel.cu
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/flash_attn/
+-rw-r--r--   0 runner    (1001) docker     (127)      291 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9535 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/bert_padding.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45333 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/flash_attn_interface.py
+-rw-r--r--   0 runner    (1001) docker     (127)    41112 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/flash_attn_triton.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11328 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/flash_attn_triton_og.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7469 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/flash_blocksparse_attention.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7265 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/flash_blocksparse_attn_interface.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7793 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/fused_softmax.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/flash_attn/layers/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2136 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/layers/patch_embed.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18874 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/layers/rotary.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/flash_attn/losses/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3130 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/losses/cross_entropy.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.689900 flash_attn-2.5.9.post1/flash_attn/models/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5730 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/baichuan.py
+-rw-r--r--   0 runner    (1001) docker     (127)    33241 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/bert.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9383 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/bigcode.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4631 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/btlm.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/falcon.py
+-rw-r--r--   0 runner    (1001) docker     (127)    47663 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/gpt.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5159 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/gpt_neox.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4436 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/gptj.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16581 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/llama.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5164 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/opt.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14074 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/models/vit.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.689900 flash_attn-2.5.9.post1/flash_attn/modules/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17349 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/modules/block.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8693 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/modules/embedding.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43295 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/modules/mha.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6033 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/modules/mlp.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.689900 flash_attn-2.5.9.post1/flash_attn/ops/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3936 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/activations.py
+-rw-r--r--   0 runner    (1001) docker     (127)    27907 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/fused_dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22443 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/layer_norm.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3988 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/rms_norm.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.689900 flash_attn-2.5.9.post1/flash_attn/ops/triton/
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12501 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/cross_entropy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4034 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/k_activations.py
+-rw-r--r--   0 runner    (1001) docker     (127)    35020 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/layer_norm.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20841 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/linear.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6068 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/mlp.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8582 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/ops/triton/rotary.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.693900 flash_attn-2.5.9.post1/flash_attn/utils/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7369 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/utils/benchmark.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5825 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/utils/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30466 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/utils/generation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3246 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/flash_attn/utils/pretrained.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-27 05:19:12.685900 flash_attn-2.5.9.post1/flash_attn.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)    19062 2024-05-27 05:19:11.000000 flash_attn-2.5.9.post1/flash_attn.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)   121925 2024-05-27 05:19:12.000000 flash_attn-2.5.9.post1/flash_attn.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-27 05:19:11.000000 flash_attn-2.5.9.post1/flash_attn.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       13 2024-05-27 05:19:11.000000 flash_attn-2.5.9.post1/flash_attn.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       11 2024-05-27 05:19:11.000000 flash_attn-2.5.9.post1/flash_attn.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       38 2024-05-27 05:19:12.693900 flash_attn-2.5.9.post1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (127)    15374 2024-05-27 05:18:36.000000 flash_attn-2.5.9.post1/setup.py
```

### Comparing `flash_attn-2.5.8/LICENSE` & `flash_attn-2.5.9.post1/LICENSE`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/PKG-INFO` & `flash_attn-2.5.9.post1/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: flash_attn
-Version: 2.5.8
+Version: 2.5.9.post1
 Summary: Flash Attention: Fast and Memory-Efficient Exact Attention
 Home-page: https://github.com/Dao-AILab/flash-attention
 Author: Tri Dao
 Author-email: trid@cs.stanford.edu
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Operating System :: Unix
```

### Comparing `flash_attn-2.5.8/README.md` & `flash_attn-2.5.9.post1/README.md`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/cmake/nop.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/cmake/nop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/options.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/options.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/register_layout.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/register_layout.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h`

 * *Files 1% similar despite different names*

```diff
@@ -256,15 +256,15 @@
     //  exactly one rank is changing AND 
     //  elements are consecutive)
 
     // Don't need vectorization.
     if (options.vectorize <= 2) return std::make_pair(false, -1);
 
     // Boundary check.
-    if (i > elements.size() || (i + options.vectorize - 1) > elements.size())
+    if (i > int(elements.size()) || (i + options.vectorize - 1) > int(elements.size()))
       return std::make_pair(false, -1);
 
     // Check if either all elements are valid or invalid.
     bool all_elements_invalid = std::all_of(
         elements.begin() + i, elements.begin() + i + options.vectorize,
         [](Element const &e) { return !e.valid(); });
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu`

 * *Files 0% similar despite different names*

```diff
@@ -90,15 +90,15 @@
     // PredicatedTileIterator uses PitchLinear layout and therefore takes in a PitchLinearShape.
     // The contiguous dimension can be accessed via Iterator::Shape::kContiguous and the strided
     // dimension can be accessed via Iterator::Shape::kStrided
     int iterations = (extent[1] + Iterator::Shape::kStrided - 1) / Iterator::Shape::kStrided;
 
     typename Iterator::Fragment fragment;
 
-    for(int i = 0; i < fragment.size(); ++i) {
+    for(size_t i = 0; i < fragment.size(); ++i) {
       fragment[i] = 0;
     }
 
     src_iterator.load(fragment);
     dst_iterator.store(fragment);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -203,23 +203,23 @@
   int batch_count) {
   /*
   strided batched gemm NN
   */
   
   cudaError_t result = cudaSuccess;
 
-  if (A.size() < lda * k * batch_count) {
+  if (A.size() < size_t(lda * k * batch_count)) {
     std::cout << "the size of A is too small" << std::endl;
     return cudaErrorInvalidValue;
   }
-  if (B.size() < ldb * n) {
+  if (B.size() < size_t(ldb * n)) {
     std::cout << "the size of B is too small" << std::endl;
     return cudaErrorInvalidValue;
   }
-  if (C.size() < ldc * n * batch_count) {
+  if (C.size() < size_t(ldc * n * batch_count)) {
     std::cout << "the size of C is too small" << std::endl;
     return cudaErrorInvalidValue;
   }
   
   for (int batch_idx = 0; batch_idx < batch_count; batch_idx++) {
     for (int n_idx = 0; n_idx < n; n_idx++) {
       for (int m_idx = 0; m_idx < m; m_idx++) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/10_planar_complex/planar_complex.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_grouped_gemm_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_grouped_gemm_run.h`

 * *Files 0% similar despite different names*

```diff
@@ -98,15 +98,15 @@
     cutlass::TensorView<Element, Layout> view, 
     cutlass::Distribution::Kind dist_kind,
     uint64_t seed) {
 
     if (dist_kind == cutlass::Distribution::Uniform) {
 
       cutlass::reference::host::TensorFillRandomUniform(
-        view, seed, 2, -2, 0);
+        view, seed, 1, -1, 0);
     } 
     else if (dist_kind == cutlass::Distribution::Identity) {
 
       cutlass::reference::host::TensorFillIdentity(view);
     } 
     else if (dist_kind == cutlass::Distribution::Gaussian) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_grouped_f16_sm80_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_grouped_f16_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h`

 * *Files 3% similar despite different names*

```diff
@@ -153,43 +153,42 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size_0;
-    GemmCoord problem_size_1;
-    typename B2bMma::IteratorA0::TensorRef ref_A0;
-    typename B2bMma::IteratorB0::TensorRef ref_B0;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C0;
-    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Scale0;
-    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Bias0;
-    typename B2bMma::IteratorB1::TensorRef ref_B1;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C1;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D1;
-    int64_t batch_stride_A0;
-    int64_t batch_stride_B0;
-    int64_t batch_stride_B1;
-    int64_t batch_stride_C1;
-    int64_t batch_stride_D1;
-    int64_t batch_stride_Bias0;
-    int64_t batch_stride_Scale0;
-    typename OutputOp0::Params epilogue0;
-    typename OutputOp1::Params epilogue1;
-    int batch_count;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    GemmCoord problem_size_0{0,0,0};
+    GemmCoord problem_size_1{0,0,0};
+    typename B2bMma::IteratorA0::TensorRef ref_A0{};
+    typename B2bMma::IteratorB0::TensorRef ref_B0{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C0{};
+    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Scale0{};
+    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Bias0{};
+    typename B2bMma::IteratorB1::TensorRef ref_B1{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C1{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_D1{};
+    int64_t batch_stride_A0{0};
+    int64_t batch_stride_B0{0};
+    int64_t batch_stride_B1{0};
+    int64_t batch_stride_C1{0};
+    int64_t batch_stride_D1{0};
+    int64_t batch_stride_Bias0{0};
+    int64_t batch_stride_Scale0{0};
+    typename OutputOp0::Params epilogue0 {};
+    typename OutputOp1::Params epilogue1 {};
+    int batch_count{1};
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments() : mode(mode), problem_size_0(0, 0, 0), problem_size_1(0, 0, 0), batch_count(1) {}
+    Arguments() = default;
 
     /// Constructs an Arguments structure
     CUTLASS_HOST_DEVICE
     Arguments(
       GemmUniversalMode mode_,
       GemmCoord problem_size_0_,
       GemmCoord problem_size_1_,
@@ -281,55 +280,53 @@
         problem_count(problem_count),
         threadblock_count(threadblock_count)
         {}
   };
 
   /// Parameters structure
   struct Params {
-    cutlass::gemm::GemmUniversalMode mode;
-    cutlass::gemm::GemmCoord problem_size_0;
-    cutlass::gemm::GemmCoord problem_size_1;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    typename B2bMma::IteratorA0::Params params_A0;
-    typename B2bMma::IteratorA0::TensorRef ref_A0;
-    typename B2bMma::IteratorB0::Params params_B0;
-    typename B2bMma::IteratorB0::TensorRef ref_B0;
-    typename Epilogue::OutputTileIterator::Params params_C0;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C0;
-    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Scale0;
-    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Bias0;
-    typename B2bMma::IteratorB1::Params params_B1;
-    typename B2bMma::IteratorB1::TensorRef ref_B1;
-    typename Epilogue::OutputTileIterator::Params params_C1;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C1;
-    typename Epilogue::OutputTileIterator::Params params_D1;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D1;
-    typename OutputOp0::Params output_op_0;
-    typename OutputOp1::Params output_op_1;
-    int64_t batch_stride_A0;
-    int64_t batch_stride_B0;
-    int64_t batch_stride_B1;
-    int64_t batch_stride_C1;
-    int64_t batch_stride_D1;
-    int64_t batch_stride_Bias0;
-    int64_t batch_stride_Scale0;
-    int *semaphore;
-    int gemm_k_iterations_0;
-    int gemm_k_size_0;
-    int gemm_k_iterations_1;
-    int gemm_k_size_1;
+    cutlass::gemm::GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    cutlass::gemm::GemmCoord problem_size_0{};
+    cutlass::gemm::GemmCoord problem_size_1{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
+    typename B2bMma::IteratorA0::Params params_A0{};
+    typename B2bMma::IteratorA0::TensorRef ref_A0{};
+    typename B2bMma::IteratorB0::Params params_B0{};
+    typename B2bMma::IteratorB0::TensorRef ref_B0{};
+    typename Epilogue::OutputTileIterator::Params params_C0{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C0{};
+    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Scale0{};
+    typename B2bMma::IteratorAccumulatorScaleBias::TensorRef ref_Bias0{};
+    typename B2bMma::IteratorB1::Params params_B1{};
+    typename B2bMma::IteratorB1::TensorRef ref_B1{};
+    typename Epilogue::OutputTileIterator::Params params_C1{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C1{};
+    typename Epilogue::OutputTileIterator::Params params_D1{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_D1{};
+    typename OutputOp0::Params output_op_0{};
+    typename OutputOp1::Params output_op_1{};
+    int64_t batch_stride_A0{0};
+    int64_t batch_stride_B0{0};
+    int64_t batch_stride_B1{0};
+    int64_t batch_stride_C1{0};
+    int64_t batch_stride_D1{0};
+    int64_t batch_stride_Bias0{0};
+    int64_t batch_stride_Scale0{0};
+    int *semaphore = nullptr;
+    int gemm_k_iterations_0{0};
+    int gemm_k_size_0{0};
+    int gemm_k_iterations_1{0};
+    int gemm_k_size_1{0};
 
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params(): mode(mode), swizzle_log_tile(0), semaphore(0), gemm_k_iterations_0(0), gemm_k_size_0(0),
-        gemm_k_iterations_1(0), gemm_k_size_1(0) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       cutlass::gemm::GemmUniversalMode mode,
       cutlass::gemm::GemmCoord const & problem_size_0,
       cutlass::gemm::GemmCoord const & problem_size_1,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm_grouped_problem_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/grouped_threadblock_swizzle.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/grouped_threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm_with_visitor.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm_with_visitor.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu`

 * *Files 1% similar despite different names*

```diff
@@ -261,14 +261,18 @@
 
 // Number of pipeline stages to use
 constexpr int NumStages = 3;
 
 // Which iterator algorithm to use: Analytic or Optimized
 static cutlass::conv::IteratorAlgorithm const IteratorAlgorithm = cutlass::conv::IteratorAlgorithm::kOptimized;
 
+// Is the output packed or strided
+// Use kStride if using strided output
+static cutlass::conv::StrideSupport const OutputStride = cutlass::conv::StrideSupport::kUnity;
+
 // The epilogue part of the kernel
 using EpilogueOp = cutlass::epilogue::thread::LinearCombination<
     ElementOutput,                                     // Data type of output matrix.
     128 / cutlass::sizeof_bits<ElementOutput>::value,  // The number of elements per vectorized
                                                        // memory access. This becomes the vector width of
                                                        // math instructions in the epilogue too.
     ElementAccumulator,                                // Data type of accumulator
@@ -285,15 +289,16 @@
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOp,
   SwizzleThreadBlock,
   NumStages,
   cutlass::arch::OpMultiplyAdd,
-  IteratorAlgorithm
+  IteratorAlgorithm,
+  OutputStride
 >::Kernel;
 
 // Type of the actual kernel
 using ImplicitGemm = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -373,30 +373,30 @@
   cutlass::HostTensor<ElementOutput, LayoutGemmKReduction> tensor_reduction({reduce_vector_length, 1});
   cutlass::HostTensor<ElementOutput, LayoutGemmKReduction> tensor_ref_reduction({reduce_vector_length, 1});
 
   // Fill input and output matrices on host using CUTLASS helper functions
   cutlass::reference::host::TensorFillRandomUniform(
       tensor_a.host_view(),
       1997,
-      ElementInputA(2),
-      ElementInputA(-2),
+      ElementInputA(1),
+      ElementInputA(-1),
       0);  // <- Fill tensor A on host with uniform-distribution random data
 
   cutlass::reference::host::TensorFillRandomUniform(
       tensor_b.host_view(),
       2003,
-      ElementInputB(2),
-      ElementInputB(-2),
+      ElementInputB(1),
+      ElementInputB(-1),
       0);  // <- Fill tensor B on host with uniform-distribution random data
 
   cutlass::reference::host::TensorFillRandomUniform(
       tensor_c.host_view(),
       2017,
-      ElementOutput(2),
-      ElementOutput(-2),
+      ElementOutput(1),
+      ElementOutput(-1),
       0);  // <- Fill matrix C on host with uniform-distribution random data
   cutlass::reference::host::TensorFill(
       tensor_d.host_view());  // <- fill matrix D on host with zeros
   cutlass::reference::host::TensorFill(
       tensor_ref_d.host_view());  // <- fill matrix D for reference on host with zeros
 
   cutlass::reference::host::TensorFill(
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu`

 * *Files 0% similar despite different names*

```diff
@@ -785,15 +785,15 @@
         << bin.first.m() << "-by-" << bin.first.n() << "-by-" << bin.first.k()
         << ", batch count: " << bin.second.size() << "\n";
 
       ++bin_idx;
       problem_count_check += bin.second.size();
     }
 
-    if (problem_count_check != this->problem_count()) {
+    if (problem_count_check != size_t(this->problem_count())) {
       std::cout << "\n***\nERROR in BINNING LOGIC!\n***\n" << std::endl;
     }
 
     std::cout << std::endl;
   }
 
   /// Executes a batched kernel and measures runtime
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -32,28 +32,28 @@
 /**
 NVIDIA Ampere architecture starts supporting tfloat32 (see include/cutlass/tfloat32.h)
 data types in tensor cores.  One big advantage is that we can load in fp32 data and convert them
 implicitly to tf32 inside the GEMM kernel which means no change is needed to accelerate traditional
 fp32 data by using NVIDIA Ampere architecture.
 
 We can use the tf32 mode of tensor core to emulate a fast accurate SGEMM kernel which is accelerated
-using Ampere Tensor Cores (see include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h). 
+using Ampere Tensor Cores (see include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h).
 
 The trick is very simple
   a x b = (a_big + a_small) x (b_big + b_small) = a_big x b_big + a_big x b_small + a_small x b_big
   big = convert_to_tf32(fp32)
   small = convert_to_tf32(fp32 - big)
 
 a_small x b_small is discarded because they are too small.
 
-This example demonstrates usage of this kernel, along with accuracy measurements w.r.t. actual FP32 
+This example demonstrates usage of this kernel, along with accuracy measurements w.r.t. actual FP32
 results (SGEMM using SIMT) and against FP64 results (DGEMM)
 
-To enable this feature, the only change needs to make is to change the default OpMultiplyAdd to 
-OpMultiplyAddFastF32. 
+To enable this feature, the only change needs to make is to change the default OpMultiplyAdd to
+OpMultiplyAddFastF32.
 
 Now, we have several different flavors of sgemm now in the profiler for Ampere.  Here are the difference
 
   sgemm           // CUDA core SIMT kernel.  FP32 in, accumulated in FP32, FP32 out.
   s1688gemm       // Use 3xTF32 to emulate FP32.  FP32 in, converted in TF32-big and TF32-small internally,
                   // accumulated in FP32, FP32 out.
   s1688tf32gemm   // Use 1xTF32.  FP32 in, converted to one TF32 internally, accumulated in FP32, FP32 out.
@@ -93,22 +93,22 @@
 
   int m, n, k;
   double l2_norm_3xtf32_vs_fp64;
   double l2_norm_1xtf32_vs_fp64;
   double l2_norm_fp32_vs_fp64;
 
   // ctor
-  Result(  
+  Result(
     int m, int n, int k,
     double runtime_ms, double gflops,
     double l2_norm_3xtf32_vs_fp64,
     double l2_norm_1xtf32_vs_fp64,
-    double l2_norm_fp32_vs_fp64) : 
+    double l2_norm_fp32_vs_fp64) :
     m(m), n(n), k(k),
-    runtime_ms(runtime_ms), gflops(gflops), 
+    runtime_ms(runtime_ms), gflops(gflops),
     l2_norm_3xtf32_vs_fp64(l2_norm_3xtf32_vs_fp64),
     l2_norm_1xtf32_vs_fp64(l2_norm_1xtf32_vs_fp64),
     l2_norm_fp32_vs_fp64(l2_norm_fp32_vs_fp64)   {}
 
   Result() {}
 
   //
@@ -143,15 +143,15 @@
   float alpha;
   float beta;
   std::string rand_mode;
 
   int iterations;
   int seed;
   bool benchmark;
-  
+
   Options():
     help(false),
     problem_size({3456, 4096, 4096}),
     iterations(20),
     seed(1),
     alpha(1),
     beta(),
@@ -186,15 +186,15 @@
 
     cmd.get_cmd_line_argument("m", problem_size.m());
     cmd.get_cmd_line_argument("n", problem_size.n());
     cmd.get_cmd_line_argument("k", problem_size.k());
 
     cmd.get_cmd_line_argument("alpha", alpha);
     cmd.get_cmd_line_argument("beta", beta);
-    
+
     cmd.get_cmd_line_argument("iterations", iterations);
     cmd.get_cmd_line_argument("seed", seed);
     cmd.get_cmd_line_argument("rand_mode", rand_mode);
 
     if (cmd.check_cmd_line_flag("benchmark")) {
       benchmark = true;
     }
@@ -223,17 +223,17 @@
 
     return out;
   }
 
   /// Compute performance in GFLOP/s
   double gflops(double runtime_s) const {
 
-    // Number of real-valued multiply-adds 
+    // Number of real-valued multiply-adds
     int64_t fmas = problem_size.product();
-    
+
     // Two flops per multiply-add
     return 2.0 * double(fmas) / double(1.0e9) / runtime_s;
   }
 };
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -268,18 +268,18 @@
                                                        // elements. This becomes the vector width of
                                                        // math instructions in the epilogue too
     float,                                   // <- data type of accumulator
     float>;                                  // <- data type for alpha/beta in linear combination function
 
 // Number of pipelines you want to use
 constexpr int NumStages = 3;
-// Alignment 
+// Alignment
 constexpr int Alignment = 4;
 
-// 
+//
 // Gemm Operators (Gemm_3xTF32, Gemm_1xTF32, GEMM_F32, GEMM_F64)
 //
 
 // Gemm_3xTF32
 using Gemm_3xTF32 = cutlass::gemm::device::Gemm<
                                               float,
                                               LayoutInputA,
@@ -292,15 +292,15 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              Alignment, 
+                                              Alignment,
                                               Alignment,
                                               false,
                                               cutlass::arch::OpMultiplyAddFastF32>;
 
 // Gemm_1xTF32
 using Gemm_1xTF32 = cutlass::gemm::device::Gemm<
                                               float,
@@ -314,15 +314,15 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              Alignment, 
+                                              Alignment,
                                               Alignment,
                                               false,
                                               cutlass::arch::OpMultiplyAdd>;
 
 // Gemm_F64
 using Gemm_F64 = cutlass::reference::device::Gemm<
                                               double,
@@ -352,15 +352,15 @@
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 1. Initialize F32 Precision input tensors using CUTLASS helper functions
   ////////////////////////////////////////////////////////////////////////////////
   cutlass::HostTensor<float, LayoutInputA> tensor_a_F32(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<float, LayoutInputB> tensor_b_F32(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<float, LayoutOutput> tensor_c_F32(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  cutlass::HostTensor<float, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N 
+  cutlass::HostTensor<float, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N
 
   if (options.rand_mode == "uniform") {
     const float min = -1;
     const float max =  1;
     // Fill input and output matrices on host using CUTLASS helper functions
     cutlass::reference::host::TensorFillRandomUniform(
         tensor_a_F32.host_view(),
@@ -393,44 +393,44 @@
         tensor_c_F32.host_view(),
         options.seed,
         double(0),
         double(5));      // <- Fill matrix C on host with gaussian-distribution random data
   }
   cutlass::reference::host::TensorFill(
       tensor_d_F32.host_view());  // <- fill matrix D on host with zeros
-  
+
   // Copy data from host to GPU
   tensor_a_F32.sync_device();
   tensor_b_F32.sync_device();
   tensor_c_F32.sync_device();
   tensor_d_F32.sync_device();
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 2. Initialize F64 tensors using the same values used for F32
   ////////////////////////////////////////////////////////////////////////////////
   // Gemm input operands (A, B, C)
   cutlass::HostTensor<double, LayoutInputA> tensor_a_F64(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<double, LayoutInputB> tensor_b_F64(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<double, LayoutOutput> tensor_c_F64(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  
+
   // Gemm output (D) for GEMM_F64
   cutlass::HostTensor<double, LayoutOutput> tensor_d_F64(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Gemm output (D) for GEMM_3xTF32
   cutlass::HostTensor<float, LayoutOutput> tensor_d_3xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Gemm output (D) for GEMM_1xTF32
   cutlass::HostTensor<float, LayoutOutput> tensor_d_1xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
 
   // Copy values from the DP tensors
   cutlass::reference::host::TensorCopy(tensor_a_F64.host_view(), tensor_a_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_b_F64.host_view(), tensor_b_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_c_F64.host_view(), tensor_c_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_F64.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_3xTF32.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_1xTF32.host_view(), tensor_d_F32.host_view());
-  
+
   // Copy data from host to GPU
   tensor_a_F64.sync_device();
   tensor_b_F64.sync_device();
   tensor_c_F64.sync_device();
   tensor_d_F64.sync_device();
   tensor_d_3xTF32.sync_device();
   tensor_d_1xTF32.sync_device();
@@ -460,15 +460,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_3xtf32(workspace_size_3xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Gemm_3xTF32 gemm_op_3xTF32;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_3xtf32 = gemm_op_3xTF32.can_implement(arguments_3xtf32);
   CUTLASS_CHECK(status_3xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_3xtf32 = gemm_op_3xTF32.initialize(arguments_3xtf32, workspace_3xtf32.get());
   CUTLASS_CHECK(status_3xtf32);
 
@@ -564,15 +564,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_1xtf32(workspace_size_1xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Gemm_1xTF32 gemm_op_1xtf32;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_1xtf32 = gemm_op_1xtf32.can_implement(arguments_1xtf32);
   CUTLASS_CHECK(status_1xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_1xtf32 = gemm_op_1xtf32.initialize(arguments_1xtf32, workspace_1xtf32.get());
   CUTLASS_CHECK(status_1xtf32);
 
@@ -623,15 +623,15 @@
   // Wait for kernels to finish
   cudaDeviceSynchronize();
 
   // Copy output data from CUTLASS and reference kernel to host for comparison
   tensor_d_F32.sync_host();
 
   ////////////////////////////////////////////////////////////////////////////////
-  ///////               Compute l2 norms 
+  ///////               Compute l2 norms
   ////////////////////////////////////////////////////////////////////////////////
 
   // l2 norm 3xTF32 vs F64
   cutlass::HostTensor<double, LayoutOutput> tensor_d_3xTF32_in_F64(problem_size.mn());
   cutlass::reference::host::TensorCopy(tensor_d_3xTF32_in_F64.host_view(), tensor_d_3xTF32.host_view());
 
   result.l2_norm_3xtf32_vs_fp64 = cutlass::reference::host::TensorRelativeErrorMetric(
@@ -660,41 +660,41 @@
   std::cout << std::fixed;
   std::cout.precision(4);
   std::cout << "Runtime: " << result.runtime_ms << " ms" << std::endl;
   std::cout.precision(2);
   std::cout << "GFLOPs: " << result.gflops << std::endl;
   std::cout << "Normalized L2 norm of" << std::endl;
   std::cout.precision(8);
-  std::cout << std::scientific 
+  std::cout << std::scientific
             << " - 3xTF32 error with FP64 reference : " << result.l2_norm_3xtf32_vs_fp64 << std::endl
             << " - 1xTF32 error with FP64 reference : " << result.l2_norm_1xtf32_vs_fp64 << std::endl
             << " - FP32 error with FP64 reference   : " << result.l2_norm_fp32_vs_fp64 << std::endl;
 
   return true;
 }
 
 int main(int argc, const char **argv) {
-  
+
   bool notSupported = false;
 
   // Ampere Tensor Core operations exposed with mma.sync and ldmatrix are first available
-  // in CUDA 11.0. 
+  // in CUDA 11.0.
   //
   // CUTLASS must be compiled with CUDA 11.0 Toolkit to run these examples.
   if (!(__CUDACC_VER_MAJOR__ >= 11)) {
     std::cerr << "Ampere Tensor Core operations must be compiled with CUDA 11.0 Toolkit or later." << std::endl;
     notSupported = true;
   }
 
   cudaDeviceProp props;
 
   cudaError_t error = cudaGetDeviceProperties(&props, 0);
   if (error != cudaSuccess) {
     std::cerr << "cudaGetDeviceProperties() returned an error: " << cudaGetErrorString(error) << std::endl;
-    return false;
+    return -1;
   }
 
   if (!((props.major * 10 + props.minor) >= 80)) {
     std::cerr << "Ampere Tensor Core operations must be run on a machine with compute capability at least 80."
               << std::endl;
     notSupported = true;
   }
@@ -712,25 +712,25 @@
     return 0;
   }
 
   bool result = true;
 
   if (options.benchmark) {
     for (int k = 4; k <= 65536; k *= 2) {
-  
+
       options.problem_size[2] = k;
-  
+
       printf("Gemm problem size: %d x %d x %d\n", \
         options.problem_size.m(), options.problem_size.n(), options.problem_size.k());
-  
+
       if (!options.valid()) {
         std::cerr << "Invalid problem." << std::endl;
         return -1;
       }
-  
+
       result &= run(options);
     }
   } else {
     // Execute one problem size
     if (!options.valid()) {
       std::cerr << "Invalid problem." << std::endl;
       return -1;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_3xtf32_complex_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_3xtf32_complex_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -30,15 +30,15 @@
  **************************************************************************************************/
 
 /**
   This example is almost the same as example 27 which uses 3xTF32 to run GEMM.  The only
   difference is that this example uses 3xtf32 on complex gemm.
 
   To enable this feature, the only change needs to make is to change OpMultiplyAddComplex
-  to OpMultiplyAddComplexFastF32. 
+  to OpMultiplyAddComplexFastF32.
 */
 
 #include <iostream>
 #include <vector>
 #include <limits>
 
 #include "cutlass/cutlass.h"
@@ -70,22 +70,22 @@
 
   int m, n, k;
   double l2_norm_3xtf32_vs_fp64;
   double l2_norm_1xtf32_vs_fp64;
   double l2_norm_fp32_vs_fp64;
 
   // ctor
-  Result(  
+  Result(
     int m, int n, int k,
     double runtime_ms, double gflops,
     double l2_norm_3xtf32_vs_fp64,
     double l2_norm_1xtf32_vs_fp64,
-    double l2_norm_fp32_vs_fp64) : 
+    double l2_norm_fp32_vs_fp64) :
     m(m), n(n), k(k),
-    runtime_ms(runtime_ms), gflops(gflops), 
+    runtime_ms(runtime_ms), gflops(gflops),
     l2_norm_3xtf32_vs_fp64(l2_norm_3xtf32_vs_fp64),
     l2_norm_1xtf32_vs_fp64(l2_norm_1xtf32_vs_fp64),
     l2_norm_fp32_vs_fp64(l2_norm_fp32_vs_fp64)   {}
 
   Result() {}
 
   //
@@ -120,15 +120,15 @@
   float alpha;
   float beta;
   std::string rand_mode;
 
   int iterations;
   int seed;
   bool benchmark;
-  
+
   Options():
     help(false),
     problem_size({3456, 4096, 4096}),
     iterations(20),
     seed(1),
     alpha(1),
     beta(),
@@ -149,15 +149,15 @@
 
     cmd.get_cmd_line_argument("m", problem_size.m());
     cmd.get_cmd_line_argument("n", problem_size.n());
     cmd.get_cmd_line_argument("k", problem_size.k());
 
     cmd.get_cmd_line_argument("alpha", alpha);
     cmd.get_cmd_line_argument("beta", beta);
-    
+
     cmd.get_cmd_line_argument("iterations", iterations);
     cmd.get_cmd_line_argument("seed", seed);
     cmd.get_cmd_line_argument("rand_mode", rand_mode);
 
     if (cmd.check_cmd_line_flag("benchmark")) {
       benchmark = true;
     }
@@ -186,17 +186,17 @@
 
     return out;
   }
 
   /// Compute performance in GFLOP/s
   double gflops(double runtime_s) const {
 
-    // Number of real-valued multiply-adds 
+    // Number of real-valued multiply-adds
     int64_t fmas = problem_size.product();
-    
+
     // Two flops per multiply-add
     return 2.0 * double(fmas) / double(1.0e9) / runtime_s;
   }
 };
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -235,15 +235,15 @@
 
 // Number of pipelines you want to use
 constexpr int NumStages = 3;
 // Transform
 constexpr cutlass::ComplexTransform TransformA = cutlass::ComplexTransform::kNone;
 constexpr cutlass::ComplexTransform TransformB = cutlass::ComplexTransform::kNone;
 
-// 
+//
 // Gemm Operators (Gemm_3xTF32, Gemm_1xTF32, GEMM_F32, GEMM_F64)
 //
 
 // Gemm_3xTF32
 using Gemm_3xTF32 = cutlass::gemm::device::GemmComplex<
                                               cutlass::complex<float>,
                                               LayoutInputA,
@@ -256,15 +256,15 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              TransformA, 
+                                              TransformA,
                                               TransformB,
                                               cutlass::arch::OpMultiplyAddComplexFastF32>;
 
 // Gemm_1xTF32
 using Gemm_1xTF32 = cutlass::gemm::device::GemmComplex<
                                               cutlass::complex<float>,
                                               LayoutInputA,
@@ -277,30 +277,30 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              TransformA, 
+                                              TransformA,
                                               TransformB,
                                               cutlass::arch::OpMultiplyAddComplex>;
 
 bool run(Options &options) {
 
   // Create a tuple of problem size for matrix multiplication
   cutlass::gemm::GemmCoord problem_size = options.problem_size;
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 1. Initialize F32 Precision input tensors using CUTLASS helper functions
   ////////////////////////////////////////////////////////////////////////////////
   cutlass::HostTensor<cutlass::complex<float>, LayoutInputA> tensor_a_F32(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<cutlass::complex<float>, LayoutInputB> tensor_b_F32(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<cutlass::complex<float>, LayoutOutput> tensor_c_F32(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  cutlass::HostTensor<cutlass::complex<float>, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N 
+  cutlass::HostTensor<cutlass::complex<float>, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N
 
   if (options.rand_mode == "uniform") {
     const float min = -1;
     const float max =  1;
     // Fill input and output matrices on host using CUTLASS helper functions
     cutlass::reference::host::TensorFillRandomUniform(
         tensor_a_F32.host_view(),
@@ -333,44 +333,44 @@
         tensor_c_F32.host_view(),
         options.seed,
         double(0),
         double(5));      // <- Fill matrix C on host with gaussian-distribution random data
   }
   cutlass::reference::host::TensorFill(
       tensor_d_F32.host_view());  // <- fill matrix D on host with zeros
-  
+
   // Copy data from host to GPU
   tensor_a_F32.sync_device();
   tensor_b_F32.sync_device();
   tensor_c_F32.sync_device();
   tensor_d_F32.sync_device();
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 2. Initialize F64 tensors using the same values used for F32
   ////////////////////////////////////////////////////////////////////////////////
   // Gemm input operands (A, B, C)
   cutlass::HostTensor<cutlass::complex<double>, LayoutInputA> tensor_a_F64(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<cutlass::complex<double>, LayoutInputB> tensor_b_F64(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<cutlass::complex<double>, LayoutOutput> tensor_c_F64(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  
+
   // Gemm output (D) for GEMM_F64
   cutlass::HostTensor<cutlass::complex<double>, LayoutOutput> tensor_d_F64(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Gemm output (D) for GEMM_3xTF32
   cutlass::HostTensor<cutlass::complex<float>, LayoutOutput> tensor_d_3xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Gemm output (D) for GEMM_1xTF32
   cutlass::HostTensor<cutlass::complex<float>, LayoutOutput> tensor_d_1xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
 
   // Copy values from the DP tensors
   cutlass::reference::host::TensorCopy(tensor_a_F64.host_view(), tensor_a_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_b_F64.host_view(), tensor_b_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_c_F64.host_view(), tensor_c_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_F64.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_3xTF32.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_1xTF32.host_view(), tensor_d_F32.host_view());
-  
+
   // Copy data from host to GPU
   tensor_a_F64.sync_device();
   tensor_b_F64.sync_device();
   tensor_c_F64.sync_device();
   tensor_d_F64.sync_device();
   tensor_d_3xTF32.sync_device();
   tensor_d_1xTF32.sync_device();
@@ -400,15 +400,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_3xtf32(workspace_size_3xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Gemm_3xTF32 gemm_op;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_3xtf32 = gemm_op.can_implement(arguments_3xtf32);
   CUTLASS_CHECK(status_3xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_3xtf32 = gemm_op.initialize(arguments_3xtf32, workspace_3xtf32.get());
   CUTLASS_CHECK(status_3xtf32);
 
@@ -504,15 +504,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_1xtf32(workspace_size_1xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Gemm_1xTF32 gemm_op_1xtf32;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_1xtf32 = gemm_op_1xtf32.can_implement(arguments_1xtf32);
   CUTLASS_CHECK(status_1xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_1xtf32 = gemm_op_1xtf32.initialize(arguments_1xtf32, workspace_1xtf32.get());
   CUTLASS_CHECK(status_1xtf32);
 
@@ -565,15 +565,15 @@
   // Wait for kernels to finish
   cudaDeviceSynchronize();
 
   // Copy output data from CUTLASS and reference kernel to host for comparison
   tensor_d_F32.sync_host();
 
   ////////////////////////////////////////////////////////////////////////////////
-  ///////               Compute l2 norms 
+  ///////               Compute l2 norms
   ////////////////////////////////////////////////////////////////////////////////
 
   // l2 norm 3xTF32 vs F64
   cutlass::HostTensor<cutlass::complex<double>, LayoutOutput> tensor_d_3xTF32_in_F64(problem_size.mn());
   cutlass::reference::host::TensorCopy(tensor_d_3xTF32_in_F64.host_view(), tensor_d_3xTF32.host_view());
 
   result.l2_norm_3xtf32_vs_fp64 = cutlass::reference::host::TensorRelativeErrorMetric(
@@ -602,41 +602,41 @@
   std::cout << std::fixed;
   std::cout.precision(4);
   std::cout << "Runtime: " << result.runtime_ms << " ms" << std::endl;
   std::cout.precision(2);
   std::cout << "GFLOPs: " << result.gflops << std::endl;
   std::cout << "Normalized L2 norm of" << std::endl;
   std::cout.precision(8);
-  std::cout << std::scientific 
+  std::cout << std::scientific
             << " - 3xTF32 error with FP64 reference : " << result.l2_norm_3xtf32_vs_fp64 << std::endl
             << " - 1xTF32 error with FP64 reference : " << result.l2_norm_1xtf32_vs_fp64 << std::endl
             << " - FP32 error with FP64 reference   : " << result.l2_norm_fp32_vs_fp64 << std::endl;
 
   return true;
 }
 
 int main(int argc, const char **argv) {
-  
+
   bool notSupported = false;
 
   // Ampere Tensor Core operations exposed with mma.sync and ldmatrix are first available
-  // in CUDA 11.0. 
+  // in CUDA 11.0.
   //
   // CUTLASS must be compiled with CUDA 11.0 Toolkit to run these examples.
   if (!(__CUDACC_VER_MAJOR__ >= 11)) {
     std::cerr << "Ampere Tensor Core operations must be compiled with CUDA 11.0 Toolkit or later." << std::endl;
     notSupported = true;
   }
 
   cudaDeviceProp props;
 
   cudaError_t error = cudaGetDeviceProperties(&props, 0);
   if (error != cudaSuccess) {
     std::cerr << "cudaGetDeviceProperties() returned an error: " << cudaGetErrorString(error) << std::endl;
-    return false;
+    return -1;
   }
 
   if (!((props.major * 10 + props.minor) >= 80)) {
     std::cerr << "Ampere Tensor Core operations must be run on a machine with compute capability at least 80."
               << std::endl;
     notSupported = true;
   }
@@ -654,25 +654,25 @@
     return 0;
   }
 
   bool result = true;
 
   if (options.benchmark) {
     for (int k = 4; k <= 65536; k *= 2) {
-  
+
       options.problem_size[2] = k;
-  
+
       printf("Gemm problem size: %d x %d x %d\n", \
         options.problem_size.m(), options.problem_size.n(), options.problem_size.k());
-  
+
       if (!options.valid()) {
         std::cerr << "Invalid problem." << std::endl;
         return -1;
       }
-  
+
       result &= run(options);
     }
   } else {
     // Execute one problem size
     if (!options.valid()) {
       std::cerr << "Invalid problem." << std::endl;
       return -1;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu`

 * *Files 0% similar despite different names*

```diff
@@ -109,18 +109,18 @@
       double,
       1,
       double,
       double
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
     5,     // Stages
-    1,     // AligmentA
+    1,     // AlignmentA
     false, // SplitKSerail
-    cutlass::arch::OpMultiplyAdd, 
-    cutlass::ComplexTransform::kNone, 
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::ComplexTransform::kNone,
     cutlass::BlasMode::kSymmetric
   >;
 
   // Define a CUTLASS SYRK type
   CutlassSyrk syrk_operator;
 
   // Construct the CUTLASS SYRK arguments object.
@@ -145,15 +145,15 @@
                               lda,
                               ldc,
                               ldc);
 
   //
   // Launch the CUTLASS SYRK kernel.
   //
-  
+
   cutlass::Status status = syrk_operator(args);
 
   //
   // Return a cudaError_t if the CUTLASS SYRK operator returned an error code.
   //
 
   if (status != cutlass::Status::kSuccess) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu`

 * *Files 2% similar despite different names*

```diff
@@ -32,28 +32,28 @@
 /**
 NVIDIA Ampere architecture starts supporting tfloat32 (see include/cutlass/tfloat32.h)
 data types in tensor cores.  One big advantage is that we can load in F32 data and convert them
 implicitly to tf32 inside the SYMM kernel which means no change is needed to accelerate traditional
 F32 data by using NVIDIA Ampere architecture.
 
 We can use the tf32 mode of tensor core to emulate a fast accurate SYMM kernel which is accelerated
-using Ampere Tensor Cores (see include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h). 
+using Ampere Tensor Cores (see include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h).
 
 The trick is very simple
   a x b = (a_big + a_small) x (b_big + b_small) = a_big x b_big + a_big x b_small + a_small x b_big
   big = convert_to_tf32(F32)
   small = convert_to_tf32(F32 - big)
 
 a_small x b_small is discarded because they are too small.
 
-This example demonstrates usage of this kernel, along with accuracy measurements w.r.t. actual F32 
+This example demonstrates usage of this kernel, along with accuracy measurements w.r.t. actual F32
 results (SSYMM from cuBLAS) and against F64 results (DSYMM from CUTLASS)
 
-To enable this feature, the only change needs to make is to change the default OpMultiplyAdd to 
-OpMultiplyAddFastF32. 
+To enable this feature, the only change needs to make is to change the default OpMultiplyAdd to
+OpMultiplyAddFastF32.
 
 Now, we have two different flavors of SSYMM in the profiler for Ampere:
 
   s1688symm       // Use 3xTF32 to emulate F32.  F32 in, converted in TF32-big and TF32-small internally,
                   // accumulated in F32, F32 out.
   s1688tf32symm   // Use 1xTF32.  F32 in, converted to one TF32 internally, accumulated in F32, F32 out.
 */
@@ -91,15 +91,15 @@
   bool help;
 
   cutlass::gemm::GemmCoord problem_size;
   float alpha;
   float beta;
   std::string rand_mode;
   int seed;
-  
+
   Options():
     help(false),
     problem_size({4096, 4096, 4096}),
     seed(1),
     alpha(1),
     beta(),
     rand_mode("uniform") { }
@@ -133,15 +133,15 @@
     cmd.get_cmd_line_argument("m", problem_size.m());
     cmd.get_cmd_line_argument("n", problem_size.n());
     // Since the kernels in this example are in Left Side Mode
     cmd.get_cmd_line_argument("m", problem_size.k());
 
     cmd.get_cmd_line_argument("alpha", alpha);
     cmd.get_cmd_line_argument("beta", beta);
-    
+
     cmd.get_cmd_line_argument("seed", seed);
     cmd.get_cmd_line_argument("rand_mode", rand_mode);
 
   }
 
   /// Prints the usage statement.
   std::ostream & print_usage(std::ostream &out) const {
@@ -203,18 +203,18 @@
                                                        // elements. This becomes the vector width of
                                                        // math instructions in the epilogue too
     float,                                   // <- data type of accumulator
     float>;                                  // <- data type for alpha/beta in linear combination function
 
 // Number of pipelines you want to use
 constexpr int NumStages = 3;
-// Alignment 
+// Alignment
 constexpr int Alignment = 4;
 
-// 
+//
 // CUTLASS Symm Operators (SSYM: Symm_3xTF32, Symm_1xTF32, DSYMM: Symm_F64)
 //
 
 // Symm_3xTF32
 using Symm_3xTF32 = cutlass::gemm::device::Symm<
                                               float,
                                               LayoutInputA,
@@ -229,15 +229,15 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              1, // Symmetric matrix is always align 1 
+                                              1, // Symmetric matrix is always align 1
                                               Alignment,
                                               false,
                                               cutlass::arch::OpMultiplyAddFastF32>;
 
 // Symm_1xTF32
 using Symm_1xTF32 = cutlass::gemm::device::Symm<
                                               float,
@@ -253,15 +253,15 @@
                                               SmArch,
                                               ShapeMMAThreadBlock,
                                               ShapeMMAWarp,
                                               ShapeMMAOp,
                                               EpilogueOp,
                                               SwizzleThreadBlock,
                                               NumStages,
-                                              1, // Symmetric matrix is always align 1 
+                                              1, // Symmetric matrix is always align 1
                                               Alignment,
                                               false,
                                               cutlass::arch::OpMultiplyAdd>;
 
 // Symm_F64
 using Symm_F64 = cutlass::gemm::device::Symm<
                                               double,
@@ -294,15 +294,15 @@
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 1. Initialize F32 Precision input tensors using CUTLASS helper functions
   ////////////////////////////////////////////////////////////////////////////////
   cutlass::HostTensor<float, LayoutInputA> tensor_a_F32(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<float, LayoutInputB> tensor_b_F32(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<float, LayoutOutput> tensor_c_F32(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  cutlass::HostTensor<float, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N 
+  cutlass::HostTensor<float, LayoutOutput> tensor_d_F32(problem_size.mn());  // <- Create matrix D with dimensions M x N
 
   if (options.rand_mode == "uniform") {
     const float min = -1;
     const float max =  1;
     // Fill input and output matrices on host using CUTLASS helper functions
     cutlass::reference::host::TensorFillRandomUniform(
         tensor_a_F32.host_view(),
@@ -335,29 +335,29 @@
         tensor_c_F32.host_view(),
         options.seed,
         double(0),
         double(5));      // <- Fill matrix C on host with gaussian-distribution random data
   }
   cutlass::reference::host::TensorFill(
       tensor_d_F32.host_view());  // <- fill matrix D on host with zeros
-  
+
   // Copy data from host to GPU
   tensor_a_F32.sync_device();
   tensor_b_F32.sync_device();
   tensor_c_F32.sync_device();
   tensor_d_F32.sync_device();
 
   ////////////////////////////////////////////////////////////////////////////////
   /// 2. Initialize F64 tensors, Output tensors and setup arguments
   ////////////////////////////////////////////////////////////////////////////////
   // Symm F64 input operands (A, B, C)
   cutlass::HostTensor<double, LayoutInputA> tensor_a_F64(problem_size.mk());  // <- Create matrix A with dimensions M x K
   cutlass::HostTensor<double, LayoutInputB> tensor_b_F64(problem_size.kn());  // <- Create matrix B with dimensions K x N
   cutlass::HostTensor<double, LayoutOutput> tensor_c_F64(problem_size.mn());  // <- Create matrix C with dimensions M x N
-  
+
   // Symm output (D) for SYMM_3xTF32
   cutlass::HostTensor<float, LayoutOutput> tensor_d_3xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Symm output (D) for SYMM_1xTF32
   cutlass::HostTensor<float, LayoutOutput> tensor_d_1xTF32(problem_size.mn());  // <- Create matrix D with dimensions M x N
   // Symm output (D) for SYMM_F64
   cutlass::HostTensor<double, LayoutOutput> tensor_d_F64(problem_size.mn());  // <- Create matrix D with dimensions M x N
 #if CUTLASS_ENABLE_CUBLAS
@@ -371,15 +371,15 @@
   cutlass::reference::host::TensorCopy(tensor_c_F64.host_view(), tensor_c_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_F64.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_3xTF32.host_view(), tensor_d_F32.host_view());
   cutlass::reference::host::TensorCopy(tensor_d_1xTF32.host_view(), tensor_d_F32.host_view());
 #if CUTLASS_ENABLE_CUBLAS
   cutlass::reference::host::TensorCopy(tensor_d_cublasF32.host_view(), tensor_d_F32.host_view());
 #endif
-  
+
   // Copy data from host to GPU
   tensor_a_F64.sync_device();
   tensor_b_F64.sync_device();
   tensor_c_F64.sync_device();
   tensor_d_F64.sync_device();
   tensor_d_3xTF32.sync_device();
   tensor_d_1xTF32.sync_device();
@@ -426,15 +426,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_3xtf32(workspace_size_3xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Symm_3xTF32 symm_op_3xtf32;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_3xtf32 = symm_op_3xtf32.can_implement(arguments_3xtf32);
   CUTLASS_CHECK(status_3xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_3xtf32 = symm_op_3xtf32.initialize(arguments_3xtf32, workspace_3xtf32.get());
   CUTLASS_CHECK(status_3xtf32);
 
@@ -473,15 +473,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_1xtf32(workspace_size_1xtf32);
 
   // Instantiate CUTLASS kernel depending on templates
   Symm_1xTF32 symm_op_1xtf32;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_1xtf32 = symm_op_1xtf32.can_implement(arguments_1xtf32);
   CUTLASS_CHECK(status_1xtf32);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_1xtf32 = symm_op_1xtf32.initialize(arguments_1xtf32, workspace_1xtf32.get());
   CUTLASS_CHECK(status_1xtf32);
 
@@ -520,15 +520,15 @@
 
   // Allocate workspace memory
   cutlass::device_memory::allocation<uint8_t> workspace_f64(workspace_size_f64);
 
   // Instantiate CUTLASS kernel depending on templates
   Symm_F64 symm_op_f64;
 
-  // Check the problem size is supported or not 
+  // Check the problem size is supported or not
   cutlass::Status status_f64 = symm_op_f64.can_implement(arguments_f64);
   CUTLASS_CHECK(status_f64);
 
   // Initialize CUTLASS kernel with arguments and workspace pointer
   status_f64 = symm_op_f64.initialize(arguments_f64, workspace_f64.get());
   CUTLASS_CHECK(status_f64);
 
@@ -564,23 +564,23 @@
       static_cast<const float*>(tensor_a_F32.device_data()),
       int(tensor_a_F32.layout().stride(0)),
       static_cast<const float*>(tensor_b_F32.device_data()),
       int(tensor_b_F32.layout().stride(0)),
       static_cast<const float*>(&beta),
       static_cast<float*>(tensor_d_cublasF32.device_data()),
       int(tensor_d_cublasF32.layout().stride(0))
-    );   
+    );
 
   cudaDeviceSynchronize();
 
   tensor_d_cublasF32.sync_host();
 #endif
 
   ////////////////////////////////////////////////////////////////////////////////
-  /// 7. Compute l2 norms 
+  /// 7. Compute l2 norms
   ////////////////////////////////////////////////////////////////////////////////
 
 #if CUTLASS_ENABLE_CUBLAS
   // l2 norm cuBLAS F32 vs F64
   cutlass::HostTensor<double, LayoutOutput> tensor_d_cublasF32_in_F64(problem_size.mn());
   cutlass::reference::host::TensorCopy(tensor_d_cublasF32_in_F64.host_view(), tensor_d_cublasF32.host_view());
 
@@ -601,60 +601,60 @@
     tensor_d_1xTF32_in_F64.host_view(), tensor_d_F64.host_view());
 
 #if CUTLASS_ENABLE_CUBLAS
   // l2 norm 3xTF32 vs cuBLAS F32
   double l2_norm_3xtf32_vs_cublasf32 = cutlass::reference::host::TensorRelativeErrorMetric(
     tensor_d_3xTF32.host_view(), tensor_d_cublasF32.host_view());
 #endif
-  
+
   // l2 norm 3xTF32 vs 1xTF32
   double l2_norm_3xtf32_vs_1xtf32 = cutlass::reference::host::TensorRelativeErrorMetric(
     tensor_d_3xTF32.host_view(), tensor_d_1xTF32.host_view());
 
   ///////////////////////////////////////////////////////////////////////////////
 
-  // Print kernel info and L2 norms 
+  // Print kernel info and L2 norms
   std::cout << "Problem Size: (" << problem_size.m() << "," << problem_size.n() << "," << problem_size.k() << ") "
             << "Alpha: "  << alpha << "," << " Beta: "  << beta << std::endl;
   std::cout << std::fixed;
   std::cout << "Normalized L2 norm of" << std::endl;
   std::cout.precision(8);
-  std::cout << std::scientific 
+  std::cout << std::scientific
 #if CUTLASS_ENABLE_CUBLAS
             << " - cuBLAS F32 error with F64 reference    : " << l2_norm_cublasf32_vs_f64 << std::endl
 #endif
             << " - 3xTF32 error with F64 reference        : " << l2_norm_3xtf32_vs_f64 << std::endl
             << " - 1xTF32 error with F64 reference        : " << l2_norm_1xtf32_vs_f64 << std::endl
 #if CUTLASS_ENABLE_CUBLAS
             << " - 3xTF32 error with cuBLAS F32 reference : " << l2_norm_3xtf32_vs_cublasf32 << std::endl
 #endif
             << " - 3xTF32 error with 1xTF32 reference     : " << l2_norm_3xtf32_vs_1xtf32 << std::endl;
 
   return true;
 }
 
 int main(int argc, const char **argv) {
-  
+
   bool notSupported = false;
 
   // Ampere Tensor Core operations exposed with mma.sync and ldmatrix are first available
-  // in CUDA 11.0. 
+  // in CUDA 11.0.
   //
   // CUTLASS must be compiled with CUDA 11.0 Toolkit to run these examples.
   if (!(__CUDACC_VER_MAJOR__ >= 11)) {
     std::cerr << "Ampere Tensor Core operations must be compiled with CUDA 11.0 Toolkit or later." << std::endl;
     notSupported = true;
   }
 
   cudaDeviceProp props;
 
   cudaError_t error = cudaGetDeviceProperties(&props, 0);
   if (error != cudaSuccess) {
     std::cerr << "cudaGetDeviceProperties() returned an error: " << cudaGetErrorString(error) << std::endl;
-    return false;
+    return -1;
   }
 
   if (!((props.major * 10 + props.minor) >= 80)) {
     std::cerr << "Ampere Tensor Core operations must be run on a machine with compute capability at least 80."
               << std::endl;
     notSupported = true;
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu`

 * *Files 0% similar despite different names*

```diff
@@ -452,15 +452,15 @@
     return status;
   }
 
   template<typename Element>
   bool verify_tensor(std::vector<Element> vector_Input, \
                        std::vector<Element> vector_Input_Ref) {
 
-    int64_t size = (vector_Input.size() < vector_Input_Ref.size()) ? vector_Input.size() : vector_Input_Ref.size();
+    auto size = int64_t((vector_Input.size() < vector_Input_Ref.size()) ? vector_Input.size() : vector_Input_Ref.size());
     float abs_tol = options.tolerance;
     float rel_tol = options.tolerance;
     
     for (int64_t i = 0; i < size; ++i) {
       float diff = (float)(vector_Input.at(i) - vector_Input_Ref.at(i));
       float abs_diff = fabs(diff);
       float abs_ref = fabs((float)vector_Input_Ref.at(i));
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -450,56 +450,56 @@
 
   /// Random initialization
   void initialize() {
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_A0.host_view(),
         options.seed,
-        ElementInputA0(5),
-        ElementInputA0(-5),
+        ElementInputA0(4),
+        ElementInputA0(-4),
         0
       );
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_B0.host_view(),
         options.seed + 1,
-        ElementInputB0(5),
-        ElementInputB0(-5),
+        ElementInputB0(4),
+        ElementInputB0(-4),
         0
       );
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_A1.host_view(),
         options.seed + 2,
-        ElementInputA1(5),
-        ElementInputA1(-5),
+        ElementInputA1(4),
+        ElementInputA1(-4),
         0
       );
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_Beta.host_view(),
         options.seed + 3,
-        ElementInputScaleBias(5),
-        ElementInputScaleBias(-5),
+        ElementInputScaleBias(4),
+        ElementInputScaleBias(-4),
         0
       );
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_Gamma.host_view(),
         options.seed + 4,
-        ElementInputScaleBias(5),
-        ElementInputScaleBias(-5),
+        ElementInputScaleBias(4),
+        ElementInputScaleBias(-4),
         0
       );
 
     cutlass::reference::host::TensorFillRandomUniform(
       tensor_Shifted_K.host_view(),
         options.seed + 5,
-        ElementOutput(5),
-        ElementOutput(-6),
+        ElementOutput(4),
+        ElementOutput(-5),
         0
       );
 
     tensor_A0.sync_device();
     tensor_B0.sync_device();
     tensor_A1.sync_device();
     tensor_Beta.sync_device();
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu`

 * *Files 1% similar despite different names*

```diff
@@ -799,15 +799,15 @@
     else {
       cuda_streams.push_back(nullptr);
     }
 
     // Use 'D' for the in/out workspace
     this->block_D.copy_from_device(this->block_C.get());
 
-    for (int i = 0; i < this->options.problem_sizes.size(); ++i) {
+    for (size_t i = 0; i < this->options.problem_sizes.size(); ++i) {
       cutlass::gemm::GemmCoord const & problem = this->options.problem_sizes[i];
       int32_t batch_count = 1;
       int64_t lda = this->lda_host.at(i);
       int64_t ldb = this->ldb_host.at(i);
       int64_t ldc = this->ldc_host.at(i);
       typename Rank2K::ElementA* ptrA = this->block_A.get() + this->offset_A.at(i);
       typename Rank2K::ElementB* ptrB = this->block_B.get() + this->offset_B.at(i);
@@ -900,18 +900,18 @@
       return result;
     }
 
     //
     // Run profiling loop
     //
 
-    int last_stream_idx = 0;
+    size_t last_stream_idx = 0;
 
     for (int iter = 0; iter < this->options.iterations; ++iter) {
-      for (int i = 0; i < this->options.problem_sizes.size(); ++i) {
+      for (size_t i = 0; i < this->options.problem_sizes.size(); ++i) {
         cutlass::gemm::GemmCoord const & problem = this->options.problem_sizes[i];
         int32_t batch_count = 1;
         int64_t lda = this->lda_host.at(i);
         int64_t ldb = this->ldb_host.at(i);
         int64_t ldc = this->ldc_host.at(i);
         typename Rank2K::ElementA* ptrA = this->block_A.get() + this->offset_A.at(i);
         typename Rank2K::ElementB* ptrB = this->block_B.get() + this->offset_B.at(i);
@@ -1142,15 +1142,15 @@
       this->ldb.get(),
       this->ldc.get(),
       this->ldd.get(),
       this->options.problem_sizes.data()
     );
 
     // Initialize the Rank2K object
-    Rank2K rank2k;
+    Rank2K rank2k{};
     size_t workspace_size = rank2k.get_workspace_size(args);
     cutlass::DeviceAllocation<uint8_t> workspace(workspace_size);
 
     result.status = rank2k.initialize(args, workspace.get());
 
     if (result.status != cutlass::Status::kSuccess) {
       std::cerr << "Failed to initialize CUTLASS Grouped Rank2K kernel." << std::endl;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/layouts.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/layouts.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/39_gemm_permute/permute_info.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/39_gemm_permute/permute_info.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h`

 * *Files 1% similar despite different names*

```diff
@@ -36,15 +36,15 @@
 
 ////////////////////////////////////////////////////////////////////////////////
 // Debugging functions
 ////////////////////////////////////////////////////////////////////////////////
 // Nans & inf detection
 #define NANCHECK(frag)                         \
   {                                            \
-    for (int _i = 0; _i < frag.size(); ++_i) { \
+    for (size_t _i = 0; _i < frag.size(); ++_i) { \
       assert(std::isfinite(float(frag[_i])));  \
       assert(!std::isnan(float(frag[_i])));    \
     }                                          \
   }
 
 // Print on the first thread of the first block
 #if 1
@@ -143,15 +143,15 @@
       float(accum[start + 6]),                        \
       float(accum[start + 7]));
 #define PRINT_ACCUM8_T0_L0(name, accum) PRINT_ACCUM8_T0_L0_START(name, accum, 0)
 #define PRINT_FRAG_T0_L0(name, frag)                          \
   {                                                           \
     auto typeStr = __get_type_name<decltype(frag)>();         \
     PRINT_B0_T0("printing %s (%s)", name, typeStr.data);      \
-    for (int _start = 0; _start < frag.size(); _start += 8) { \
+    for (size_t _start = 0; _start < frag.size(); _start += 8) { \
       PRINT_ACCUM8_T0_L0_START("  ", frag, _start);           \
     }                                                         \
     /*__syncthreads();                                        \
     NANCHECK(frag); */                                        \
   }
 #define PRINT_ARRAY_T0_L0_INCR(name, array, length, incr)   \
   {                                                         \
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h`

 * *Files 2% similar despite different names*

```diff
@@ -163,66 +163,47 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmCoord *problem_sizes0;
-    GemmCoord *problem_sizes1;
+    GemmCoord *problem_sizes0{nullptr};
+    GemmCoord *problem_sizes1{nullptr};
 
-    int problem_count;
-    int threadblock_count;
+    int problem_count{0};
+    int threadblock_count{0};
 
-    ElementQ ** ptr_Q;
-    ElementK ** ptr_K;
-    ElementP ** ptr_P;
-    ElementV ** ptr_V;
-    ElementO ** ptr_O;
-    ElementOAccum ** ptr_O_accum;
-
-    typename LayoutQ::Stride::LongIndex *ldq;
-    typename LayoutK::Stride::LongIndex *ldk;
-    typename LayoutP::Stride::LongIndex *ldv;
-    typename LayoutO::Stride::LongIndex *ldo;
-
-    // Scale
-    ElementAccumulator scale;
+    ElementQ ** ptr_Q{nullptr};
+    ElementK ** ptr_K{nullptr};
+    ElementP ** ptr_P{nullptr};
+    ElementV ** ptr_V{nullptr};
+    ElementO ** ptr_O{nullptr};
+    ElementOAccum ** ptr_O_accum{nullptr};
+
+    typename LayoutQ::Stride::LongIndex *ldq{nullptr};
+    typename LayoutK::Stride::LongIndex *ldk{nullptr};
+    typename LayoutP::Stride::LongIndex *ldv{nullptr};
+    typename LayoutO::Stride::LongIndex *ldo{nullptr};
 
     // Whether causal masking is to be performed
-    bool causal;
+    bool causal{false};
+
+    // Scale
+    ElementAccumulator scale{0};
 
     // Only used by device-level operator
-    GemmCoord *host_problem_sizes;
+    GemmCoord *host_problem_sizes{nullptr};
 
     //
     // Methods
     //
-
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments():
-      problem_count(0),
-      threadblock_count(0),
-      ptr_Q(nullptr),
-      ptr_K(nullptr),
-      ptr_P(nullptr),
-      ptr_V(nullptr),
-      ptr_O(nullptr),
-      ptr_O_accum(nullptr),
-      ldq(nullptr),
-      ldk(nullptr),
-      ldv(nullptr),
-      ldo(nullptr),
-      scale(0),
-      causal(false),
-      host_problem_sizes(nullptr)
-    {
-
-    }
+  
+      /// Default ctor
+    Arguments() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     Arguments(
       GemmCoord *problem_sizes0,
       GemmCoord *problem_sizes1,
       int problem_count,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multi_head_attention_backward.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multi_head_attention_backward.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu`

 * *Files 0% similar despite different names*

```diff
@@ -282,15 +282,15 @@
 
   /// Compute performance in GFLOP/s
   double gflops(double runtime_s) const {
 
     // Number of real-valued multiply-adds 
     int64_t fops = int64_t();
 
-    for (int i = 0; i < problem_sizes0.size(); ++i) {
+    for (size_t i = 0; i < problem_sizes0.size(); ++i) {
       auto const& problem0 = problem_sizes0[i];
       auto const& problem1 = problem_sizes1[i];
       for (int row = 0; row < problem0.m(); ++row) {
         int num_cols0 = problem0.n();
         if (causal) {
           num_cols0 = std::min(row + 1, num_cols0);
         }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu`

 * *Files 1% similar despite different names*

```diff
@@ -336,15 +336,15 @@
 
   /// Compute performance in GFLOP/s
   double gflops(double runtime_s) const {
 
     // Number of real-valued multiply-adds 
     int64_t fops = int64_t();
 
-    for (int i = 0; i < problem_sizes0.size(); ++i) {
+    for (size_t i = 0; i < problem_sizes0.size(); ++i) {
       auto const& problem0 = problem_sizes0[i];
       auto const& problem1 = problem_sizes1[i];
 
       for (int row = 0; row < problem0.m(); ++row) {
         int num_cols0 = problem0.n();
         if (causal) {
           num_cols0 = std::min(row + 1, num_cols0);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -240,19 +240,21 @@
             thread_idx,
             warp_idx,
             lane_idx) {}
 
   CUTLASS_DEVICE
   bool set_prologue_done(bool value) {
     prologue_done_ = value;
+    return true;
   }
 
   CUTLASS_DEVICE
   bool set_zero_outside_bounds(bool value) {
     zero_outside_bounds_ = value;
+    return true;
   }
 
   template <bool kLoadA = true, bool kLoadB = true>
   CUTLASS_DEVICE static void prologue(
       typename Base::SharedStorage& shared_storage,
       ///< iterator over A operand in global memory
       IteratorA iterator_A,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/default_warp_iterator_from_smem.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/default_warp_iterator_from_smem.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_backward.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_backward.h`

 * *Files 0% similar despite different names*

```diff
@@ -1442,15 +1442,15 @@
       int32_t query_start,
       int32_t key_start,
       const curandStatePhilox4_32_10_t& curand_state_init,
       uint8_t warp_id,
       uint8_t lane_id) {
     cutlass::Array<cutlass::uint1b_t, MatmulDOIVJ::Mma::FragmentC::kElements>
         dropout_keep_mask_doivj;
-    dropout_keep_mask_doivj.fill(1);
+    dropout_keep_mask_doivj.fill(cutlass::uint1b_t{1});
     const float dropout_scale =
         kApplyDropout ? 1.0 / (1.0 - p.dropout_prob) : 1.0f;
 
     cutlass::MatrixCoord no_offset{0, 0};
     accum_t scale = p.scale;
     int16_t thread_id = 32 * warp_id + lane_id;
 
@@ -1740,15 +1740,15 @@
         auto lane_offset = MatmulDOIVJ::AccumLambdaIterator::get_lane_offset(
             lane_id, warp_id, output_tile_coords_doivj);
         MatmulDOIVJ::AccumLambdaIterator::iterateRows(
             lane_offset,
             [&](int accum_m) {},
             [&](int accum_m /*q*/, int accum_n /*k*/, int idx) {
               if (zij.at({accum_n, accum_m}) == scalar_t(0)) {
-                dropout_keep_mask_doivj[idx] = cutlass::uint1b_t(0);
+                dropout_keep_mask_doivj[idx] = cutlass::uint1b_t{0};
               }
             },
             [&](int accum_m) {});
       }
       __syncthreads();
     }
     rematerializeThreadIds();
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h`

 * *Files 0% similar despite different names*

```diff
@@ -36,15 +36,14 @@
 #include <ATen/cuda/CUDAGraphsUtils.cuh>
 #endif
 
 #include <curand_kernel.h>
 #include <cmath>
 #include <vector>
 
-#include "cutlass/bfloat16.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/layout/vector.h"
 #include "cutlass/matrix.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/tensor_ref.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -448,15 +448,15 @@
   /// Returns the number of threadblocks to launch if the kernel can run on the target
   /// device. Otherwise, returns zero.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
@@ -505,15 +505,15 @@
       options.a_ell_num_columns,
       options.a_ell_blocksize,
       options.a_base,
       epilogue_op 
     );
 
     // Initialize the GEMM object
-    Gemm gemm;
+    Gemm gemm{};
 
     result.status = gemm.initialize(args);
 
     if (result.status != cutlass::Status::kSuccess) {
       std::cerr << "Failed to initialize CUTLASS BlockedEll SpMM kernel." << std::endl;
       return result;
     }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/test_run.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/test_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk_broadcast.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/49_collective_builder.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/49_collective_builder.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/51_hopper_gett/51_hopper_gett.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/51_hopper_gett/51_hopper_gett.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/51_hopper_gett/gett_kernel.cuh` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/51_hopper_gett/gett_kernel.cuh`

 * *Files 1% similar despite different names*

```diff
@@ -98,15 +98,16 @@
   // CollectiveMma for GETTs can be built using the CollectiveBuilders
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, StrideA, 128 / cutlass::sizeof_bits<ElementA>::value,
       ElementB, StrideB, 128 / cutlass::sizeof_bits<ElementB>::value,
       ElementAccumulator,
       TileShape, Shape<_1,_2,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<
+        static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::collective::KernelScheduleAuto
     >::CollectiveOp;
 
   // The GETT kernel is a composition of a collective mainloop and epilogue, just like any 3.x GEMM
   using GettKernel = cutlass::gemm::kernel::GemmUniversal<
       ProblemShapeMNKL,
       CollectiveMainloop,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/52_hopper_gather_scatter_fusion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/52_hopper_gather_scatter_fusion.cu`

 * *Files 1% similar despite different names*

```diff
@@ -285,15 +285,16 @@
   using MainloopOpt = typename cutlass::gemm::collective::CollectiveBuilder<
     cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
     ElementA, LayoutA, 128 / cutlass::sizeof_bits<ElementA>::value,
     ElementB, LayoutB, 128 / cutlass::sizeof_bits<ElementB>::value,
     ElementAccumulator,
     Shape<_128,_128,_64>,
     Shape<_2,_2,_1>,
-    cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename EpilogueOpt::SharedStorage)>,
+    cutlass::gemm::collective::StageCountAutoCarveout<
+      static_cast<int>(sizeof(typename EpilogueOpt::SharedStorage))>,
     cutlass::gemm::collective::KernelScheduleAuto
   >::CollectiveOp;
 
   using KernelOpt = cutlass::gemm::kernel::GemmUniversal<
     ProblemShape,
     MainloopOpt,
     EpilogueOpt,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_gemm.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_gemm.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -35,14 +35,19 @@
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/dispatch_policy.hpp"
 
 #include "cute/tensor.hpp"
 
 #include "gather_tensor.hpp"
 
+namespace cutlass {
+  ///Forward declaration
+  struct CudaHostAdapter;
+}
+
 namespace cutlass::gemm::kernel {
 
 ///////////////////////////////////////////////////////////////////////////////
 
 template <
   class ProblemShape_,
   class CollectiveMainloop_,
@@ -139,18 +144,18 @@
     TileSchedulerArguments scheduler{};
     GatherA gather_A{};
     GatherB gather_B{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
     GatherA gather_A{};
     GatherB gather_B{};
   };
 
   //
   // Methods
   //
@@ -187,22 +192,23 @@
     }
     implementable &= CollectiveMainloop::can_implement(args.problem_shape, args.mainloop);
     implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
     return implementable;
   }
 
   static
-  int
+  size_t
   get_workspace_size(Arguments const& args) {
     return 0;
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return Status::kSuccess;
   }
 
   // Computes the kernel launch grid shape based on runtime parameters
   static dim3
   get_grid_shape(Params const& params) {
     auto cluster_shape = Shape<_1,_1,_1>{};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_kernel.cuh` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_kernel.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_tensor.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/common/gather_tensor.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -28,14 +28,15 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cute/layout.hpp"
 #include "cute/tensor.hpp"
+#include "cute/util/print.hpp"
 
 namespace example {
 
 using namespace cute;
 
 // Empty type used to disable gather/scatter for a GEMM argument
 struct NoGather
@@ -55,15 +56,15 @@
   CUTE_HOST_DEVICE constexpr
   Index
   operator()(I i) const { return indices_[i]; }
 
   CUTE_HOST_DEVICE friend
   void 
   print(IndexedGather const &s) {
-    print("Indexed");
+    cute::print("Indexed");
   }
 
   Index const *indices_;
 };
 
 /// Function object that applies a stride to its argument
 /// Example: StridedFunc<int,_2> gathers every other row/column
@@ -77,17 +78,17 @@
   CUTE_HOST_DEVICE constexpr
   auto
   operator()(I i) const { return i * stride_; }
 
   CUTE_HOST_DEVICE friend
   void 
   print(StridedGather const &s) {
-    print("Strided{");
+    cute::print("Strided{");
     print(s.stride_);
-    print("}");
+    cute::print("}");
   }
 
   Stride stride_;
 };
 
 /// Custom stride object that applies a function followed by a stride
 template <class Func, class Stride>
@@ -105,19 +106,19 @@
   CUTE_HOST_DEVICE constexpr friend
   auto
   operator*(CustomStride const &s, I i) { return s.func_(i) * s.stride_; }
 
   CUTE_HOST_DEVICE friend
   void
   print(CustomStride const & s) {
-    print("Custom{");
+    cute::print("Custom{");
     print(s.func_);
-    print(",");
+    cute::print(",");
     print(s.stride_);
-    print("}");
+    cute::print("}");
   }
 
   template<class Div>
   CUTE_HOST_DEVICE constexpr friend
   auto
   safe_div(CustomStride const &s, Div const &div)
   {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/scatter_epilogue.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/52_hopper_gather_scatter_fusion/scatter_epilogue.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -35,15 +35,15 @@
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/dispatch_policy.hpp"
 #include "cutlass/epilogue/collective/detail.hpp"
 
 #include "cute/tensor.hpp"
-#include "cute/numeric/int.hpp"
+#include "cute/numeric/numeric_types.hpp"
 
 #include "gather_tensor.hpp"
 
 namespace cutlass::epilogue::collective {
 
 /// Applies an element wise operation to all elements within the fragment
 /// and scatter-writes them out to destination storage.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/53_hopper_gemm_permute.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/53_hopper_gemm_permute.cu`

 * *Files 0% similar despite different names*

```diff
@@ -389,25 +389,27 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
     cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
     ElementA, StrideA, 128 / cutlass::sizeof_bits<ElementA>::value,
     ElementB, StrideB, 128 / cutlass::sizeof_bits<ElementB>::value,
     ElementAccumulator,
     TileShape, ClusterShape,
-    cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+    cutlass::gemm::collective::StageCountAutoCarveout<
+      static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
     cutlass::gemm::collective::KernelScheduleAuto
   >::CollectiveOp;
 
   using CollectiveMainloopPermute = typename cutlass::gemm::collective::CollectiveBuilder<
     cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
     ElementA, StrideAPermute, 128 / cutlass::sizeof_bits<ElementA>::value,
     ElementB, StrideBPermute, 128 / cutlass::sizeof_bits<ElementB>::value,
     ElementAccumulator,
     TileShapePermute, ClusterShape,
-    cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpiloguePermute::SharedStorage)>,
+    cutlass::gemm::collective::StageCountAutoCarveout<
+      static_cast<int>(sizeof(typename CollectiveEpiloguePermute::SharedStorage))>,
     cutlass::gemm::collective::KernelScheduleAuto
   >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
     ProblemShape,
     CollectiveMainloop,
     CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/permute_kernel.cuh` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/permute_kernel.cuh`

 * *Files 1% similar despite different names*

```diff
@@ -33,15 +33,15 @@
     \brief Simple permutation kernel implementation.
 */
 
 #include "cutlass/layout/pitch_linear.h"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/tensor_view.h"
 #include "cutlass/fast_math.h"
-#include "cute/numeric/uint128.hpp"
+#include "cute/numeric/numeric_types.hpp"
 
 namespace example
 {
 
 /**
  * Assumes column-major input (M mode is contiguous, N mode is strided).
  * For row major, the inputs must be switched accordingly.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/53_hopper_gemm_permute/permute_traits.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/53_hopper_gemm_permute/permute_traits.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/54_hopper_fp8_warp_specialized_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/54_hopper_fp8_warp_specialized_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/hopper_fp8_commandline.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/hopper_fp8_commandline.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/55_hopper_mixed_dtype_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/55_hopper_mixed_dtype_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/unfused_weight_dequantize.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/unfused_weight_dequantize.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/56_hopper_ptr_array_batched_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/56_hopper_ptr_array_batched_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/60_cutlass_import/main.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/60_cutlass_import/main.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/common/helper.h` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/common/helper.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm70_epilogue_vectorized.hpp`

 * *Files 26% similar despite different names*

```diff
@@ -24,403 +24,334 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#include <thrust/host_vector.h>
-#include <thrust/device_vector.h>
-
-#include <cute/tensor.hpp>
-
-#include "cutlass/util/print_error.hpp"
-#include "cutlass/util/GPU_Clock.hpp"
-#if defined(CUTLASS_ENABLE_CUBLAS) && CUTLASS_ENABLE_CUBLAS != 0
-#  include "cutlass/util/cublas_wrappers.hpp"
-#endif
-#include "cutlass/util/helper_cuda.hpp"
-
-template <class MShape, class NShape, class KShape,
-          class TA, class AStride, class ABlockLayout, class AThreadLayout,
-          class TB, class BStride, class BBlockLayout, class BThreadLayout,
-          class TC, class CStride, class CBlockLayout, class CThreadLayout,
-          class Alpha, class Beta>
-__global__ static
-__launch_bounds__(decltype(size(CThreadLayout{}))::value)
-void
-gemm_device(MShape M, NShape N, KShape K,
-            TA const* A, AStride dA, ABlockLayout blockA, AThreadLayout tA,
-            TB const* B, BStride dB, BBlockLayout blockB, BThreadLayout tB,
-            TC      * C, CStride dC, CBlockLayout       , CThreadLayout tC,
-            Alpha alpha, Beta beta)
-{
-  using namespace cute;
-  using X = Underscore;
-
-  // Preconditions
-  CUTE_STATIC_ASSERT(is_static<ABlockLayout>::value);
-  CUTE_STATIC_ASSERT(is_static<BBlockLayout>::value);
-  CUTE_STATIC_ASSERT(is_static<CBlockLayout>::value);
-
-  CUTE_STATIC_ASSERT(is_static<AThreadLayout>::value);
-  CUTE_STATIC_ASSERT(is_static<BThreadLayout>::value);
-  CUTE_STATIC_ASSERT(is_static<CThreadLayout>::value);
-
-  CUTE_STATIC_ASSERT_V(size(tA) == size(tC));
-  CUTE_STATIC_ASSERT_V(size(tB) == size(tC));
-
-  //CUTE_STATIC_ASSERT_V(shape<0>(blockA) == shape<0>(blockC));      // BLK_M
-  //CUTE_STATIC_ASSERT_V(shape<0>(blockB) == shape<1>(blockC));      // BLK_N
-  CUTE_STATIC_ASSERT_V(shape<1>(blockA) == shape<1>(blockB));        // BLK_K
-
-  // Shared memory buffers
-  __shared__ TA smemA[cosize_v<ABlockLayout>];
-  __shared__ TB smemB[cosize_v<BBlockLayout>];
-  auto sA = make_tensor(make_smem_ptr(smemA), blockA);               // (BLK_M,BLK_K)
-  auto sB = make_tensor(make_smem_ptr(smemB), blockB);               // (BLK_N,BLK_K)
-
-  // Represent the full tensors
-  auto mA = make_tensor(make_gmem_ptr(A), make_shape(M,K), dA);      // (M,K)
-  auto mB = make_tensor(make_gmem_ptr(B), make_shape(N,K), dB);      // (N,K)
-  auto mC = make_tensor(make_gmem_ptr(C), make_shape(M,N), dC);      // (M,N)
-
-  // Get the appropriate blocks for this thread block --
-  // potential for thread block locality
-  auto blk_shape = make_shape(size<0>(sA), size<0>(sB), size<1>(sB));// (BLK_M,BLK_N,BLK_K)
-  auto blk_coord = make_coord(blockIdx.x, blockIdx.y, _);            // (m,n,k)
-
-  auto gA = local_tile(mA, blk_shape, blk_coord, Step<_1, X,_1>{});  // (BLK_M,BLK_K,k)
-  auto gB = local_tile(mB, blk_shape, blk_coord, Step< X,_1,_1>{});  // (BLK_N,BLK_K,k)
-  auto gC = local_tile(mC, blk_shape, blk_coord, Step<_1,_1, X>{});  // (BLK_M,BLK_N)
-
+/*! \file
+  \brief Functor performing elementwise operations used by epilogues.
+*/
+
+#pragma once
+
+#include "cutlass/cutlass.h"
+
+#include "cute/tensor.hpp"
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+namespace cutlass {
+namespace epilogue {
+namespace collective {
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Applies an element wise operation to all elements within the fragment
+/// and writes it out to destination storage.
+///
+/// Ways to generalize this:
+/// - CTA tile shape
+/// - vectorization requirements (GMEM)
+/// - vectoriz(able) transform()
+///
+template <
+  class StrideC_,
+  class StrideD_,
+  class ThreadEpilogueOp_,
+  class SmemLayout_,
+  class CopyAtomR2S_,
+  class TiledCopyS2R_,
+  class CopyAtomR2G_
+>
+class Epilogue {
+public:
   //
-  // Partition the copying of A and B tiles across the threads
+  // Type Aliases
   //
+  // derived types of output thread level operator
+  using ThreadEpilogueOp = ThreadEpilogueOp_;
+  using ElementAccumulator = typename ThreadEpilogueOp::ElementAccumulator;
+  using ElementCompute = typename ThreadEpilogueOp::ElementCompute;
+  using ElementScalar = ElementCompute;
+  using ElementOutput = typename ThreadEpilogueOp::ElementOutput;
+  using ElementC = typename ThreadEpilogueOp::ElementC;
+  using StrideC = StrideC_;
+  using ElementD = typename ThreadEpilogueOp::ElementD;
+  using StrideD = StrideD_;
+
+  using SmemLayout   = SmemLayout_;
+  using CopyAtomR2S  = CopyAtomR2S_;
+  using TiledCopyS2R = TiledCopyS2R_;
+  using CopyAtomR2G  = CopyAtomR2G_;
 
-  // TUTORIAL: Example of simple partitioning of A|B tiles over tA|tB
-  //   Default is a raked partition, but can be changed with Step<X,Y> parameter
+  static const int kOutputAlignment = ThreadEpilogueOp::kCount;
 
-  auto tAgA = local_partition(gA, tA, threadIdx.x);                  // (THR_M,THR_K,k)
-  auto tAsA = local_partition(sA, tA, threadIdx.x);                  // (THR_M,THR_K)
+  using AlignmentType = typename cute::uint_bit<sizeof_bits<ElementOutput>::value * kOutputAlignment>::type;
 
-  auto tBgB = local_partition(gB, tB, threadIdx.x);                  // (THR_N,THR_K,k)
-  auto tBsB = local_partition(sB, tB, threadIdx.x);                  // (THR_N,THR_K)
+  static_assert(cute::rank(StrideC{}) == 3, "StrideCD must be rank-3: [M, N, L]");
+  static_assert(cute::rank(StrideD{}) == 3, "StrideCD must be rank-3: [M, N, L]");
 
-  //
-  // Define C accumulators and A/B partitioning
-  //
-
-  // TUTORIAL: Example of partitioning via projections of tC
+  struct SharedStorage
+  {
+    cute::array_aligned<ElementAccumulator, cute::cosize_v<SmemLayout>> smem_epilogue;
+  };
 
-  // Partition sA (M,K) by the rows of tC
-  auto tCsA = local_partition(sA, tC, threadIdx.x, Step<_1, X>{});   // (THR_M,BLK_K)
-  // Partition sB (N,K) by the cols of tC
-  auto tCsB = local_partition(sB, tC, threadIdx.x, Step< X,_1>{});   // (THR_N,BLK_K)
-  // Partition gC (M,N) by the tile of tC
-  auto tCgC = local_partition(gC, tC, threadIdx.x, Step<_1,_1>{});   // (THR_M,THR_N)
+  // Host side epilogue arguments
+  struct Arguments {
+    typename ThreadEpilogueOp::Params thread{};
+    ElementC const* ptr_C = nullptr;
+    StrideC dC{};
+    ElementD* ptr_D = nullptr;
+    StrideD dD{};
+  };
 
-  // Allocate the accumulators -- same size as the projected data
-  auto tCrC = make_fragment_like(tCgC);                              // (THR_M,THR_N)
+  // Device side epilogue params
+  using Params = Arguments;
 
-  // Clear the accumulators
-  clear(tCrC);
+  //
+  // Methods
+  //
 
-#if 0
-  if(thread0()) {
-    print("mA\n");
-    print(mA.shape()); print("\n"); print(mA.stride());
-    print("\n\ngA\n");
-    print(gA.shape()); print("\n"); print(gA.stride());
-    print("\n\ntAgA\n");
-    print(tAgA.shape()); print("\n"); print(tAgA.stride());
-    print("\n\nsA\n");
-    print(sA.shape()); print("\n"); print(sA.stride());
-    print("\n\ntAsA\n");
-    print(tAsA.shape()); print("\n"); print(tAsA.stride());
-    print("\n\n");
+  template <class ProblemShape>
+  static constexpr Params
+  to_underlying_arguments(
+      [[maybe_unused]] ProblemShape const& _,
+      Arguments const& args,
+      [[maybe_unused]] void* workspace) {
+    return args;
   }
-#endif
 
-#if 0
-  if(thread0()) {
-    print("mB\n");
-    print(mB.shape()); print("\n"); print(mB.stride());
-    print("\n\ngB\n");
-    print(gB.shape()); print("\n"); print(gB.stride());
-    print("\n\ntBgB\n");
-    print(tBgB.shape()); print("\n"); print(tBgB.stride());
-    print("\n\nsB\n");
-    print(sB.shape()); print("\n"); print(sB.stride());
-    print("\n\ntBsB\n");
-    print(tBsB.shape()); print("\n"); print(tBsB.stride());
-    print("\n\n");
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
   }
-#endif
 
-#if 0
-  if(thread0()) {
-    print("mC\n");
-    print(mC.shape()); print("\n"); print(mC.stride());
-    print("\n\ngC\n");
-    print(gC.shape()); print("\n"); print(gC.stride());
-    print("\n\ntCsA\n");
-    print(tCsA.shape()); print("\n"); print(tCsA.stride());
-    print("\n\ntCsB\n");
-    print(tCsB.shape()); print("\n"); print(tCsB.stride());
-    print("\n\ntCgC\n");
-    print(tCgC.shape()); print("\n"); print(tCgC.stride());
-    print("\n\ntCrC\n");
-    print(tCrC.shape()); print("\n"); print(tCrC.stride());
-    print("\n\n");
+  template <class ProblemShape>
+  static cutlass::Status
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
+    return cutlass::Status::kSuccess;
   }
-#endif
 
-#if 1
-
-  // TUTORIAL: Example of a very simple compute loop
-  //   Data is read from global to shared memory via the tA|tB partitioning
-  //   gemm(.) operates on the shared memory directly via the tC partitioning
+  template <class ProblemShape>
+  CUTLASS_HOST_DEVICE static bool
+  can_implement(
+      [[maybe_unused]] ProblemShape const& problem_shape,
+      [[maybe_unused]] Arguments const& args) {
+    return true;
+  }
 
-  auto k_max = size<2>(tAgA);
+  CUTLASS_HOST_DEVICE
+  Epilogue(Params const& params_)
+      : params(params_), epilogue_op(params_.thread) { }
+
+  CUTLASS_DEVICE
+  bool
+  is_source_needed() {
+    return epilogue_op.is_source_needed();
+  }
 
-  for (int k = 0; k < k_max; ++k)
+  template<
+    class ProblemShapeMNKL,
+    class BlockShapeMNK,
+    class BlockCoordMNKL,
+    class FrgEngine, class FrgLayout,
+    class TiledMma,
+    class ResidueMNK
+  >
+  CUTLASS_DEVICE void
+  operator()(
+      ProblemShapeMNKL problem_shape_mnkl,
+      BlockShapeMNK blk_shape_MNK,
+      BlockCoordMNKL blk_coord_mnkl,
+      cute::Tensor<FrgEngine,FrgLayout> const& accumulators,                   // (MMA,MMA_M,MMA_N)
+      TiledMma tiled_mma,
+      ResidueMNK residue_mnk,
+      int thread_idx,
+      char* smem_buf)
   {
-    // Copy gmem to smem
-    copy(tAgA(_,_,k), tAsA);
-    copy(tBgB(_,_,k), tBsB);
-
-    // In case copy uses cp.async, make sure that the cp.async
-    // instructions are ordered with respect to other cp.async
-    // instructions (fence), then wait on all the outstanding copy
-    // operations (wait<0>()).  __syncthreads() alone does not do
-    // this.
-    //
-    // NOTE: cp_async_wait<0>() currently issues cp.async.wait_all.
-    // This is equivalent to cp.async.commit_group followed by
-    // cp.async_wait_group 0.  This should make the first
-    // cp_async_fence() (which also issues cp.async.commit_group)
-    // redundant.  The tutorial works as-is, so we'll leave the
-    // redundant fence in for now and study its removal later.
-    cp_async_fence();
-    cp_async_wait<0>();
-
-    __syncthreads();
-
-    // Compute gemm on smem
-    gemm(tCsA, tCsB, tCrC);
-
-    __syncthreads();
-  }
+    using namespace cute;
+    using X = Underscore;
 
+    static_assert(cute::rank(ProblemShapeMNKL{}) == 4, "ProblemShapeMNKL must be rank 4");
+    static_assert(is_static<BlockShapeMNK>::value, "ThreadBlock tile shape must be static");
+    static_assert(cute::rank(BlockShapeMNK{}) == 3, "BlockShapeMNK must be rank 3");
+    static_assert(cute::rank(BlockCoordMNKL{}) == 4, "BlockCoordMNKL must be rank 3");
+
+    // synchronizing function for smem reads/writes
+#if CUDA_BARRIER_ENABLED
+    auto synchronize = [] () { cutlass::arch::NamedBarrier::sync(typename TiledCopyS2R::TiledNumThr{}, cutlass::arch::ReservedNamedBarriers::EpilogueBarrier); };
+#else
+    auto synchronize = [] () { __syncthreads(); };
 #endif
 
-  //
-  // Epilogue
-  //
-
-  axpby(alpha, tCrC, beta, tCgC);
-}
+    // Separate out problem shape for convenience
+    auto M = get<0>(problem_shape_mnkl);
+    auto N = get<1>(problem_shape_mnkl);
+    auto L = get<3>(problem_shape_mnkl);
+
+    // Represent the full output tensor
+    Tensor mC_mnl = make_tensor(make_gmem_ptr(params.ptr_C), make_shape(M,N,L), params.dC);      //             (m,n,l)
+    Tensor mD_mnl = make_tensor(make_gmem_ptr(params.ptr_D), make_shape(M,N,L), params.dD);      //             (m,n,l)
+    Tensor gC_mnl = local_tile(mC_mnl, blk_shape_MNK, make_coord(_,_,_), Step<_1,_1, X>{});      // (BLK_M,BLK_N,m,n,l)
+    Tensor gD_mnl = local_tile(mD_mnl, blk_shape_MNK, make_coord(_,_,_), Step<_1,_1, X>{});      // (BLK_M,BLK_N,m,n,l)
+
+    // Slice to get the tile this CTA is responsible for
+    auto [m_coord, n_coord, k_coord, l_coord] = blk_coord_mnkl;
+    Tensor gC = gC_mnl(_,_,m_coord,n_coord,l_coord);                                                   // (BLK_M,BLK_N)
+    Tensor gD = gD_mnl(_,_,m_coord,n_coord,l_coord);                                                   // (BLK_M,BLK_N)
+
+    // Construct a tensor in SMEM that we can partition for rearranging data
+    SharedStorage& storage = *reinterpret_cast<SharedStorage*>(smem_buf);
+    Tensor sC = make_tensor(make_smem_ptr(storage.smem_epilogue.data()), SmemLayout{});              // (SMEM_M,SMEM_N)
+
+    // Partition sC to match the accumulator partitioning
+    auto tiled_r2s = make_tiled_copy_C(CopyAtomR2S{}, tiled_mma);
+    auto tC     = tiled_r2s.get_thread_slice(thread_idx);
+    Tensor tCaC = tC.retile_S(accumulators);                                          // ((Atom,AtomNum), MMA_M, MMA_N)
+    Tensor tCsC = tC.partition_D(sC);                                                 // ((Atom,AtomNum),PIPE_M,PIPE_N)
+
+    // Tile gD and gC by the shape of SmemLayout first
+    auto tile  = make_shape(size<0>(sC), size<1>(sC));
+    Tensor gCt = flat_divide(gC, tile);                                                // (SMEM_M,SMEM_N,TILE_M,TILE_N)
+    Tensor gDt = flat_divide(gD, tile);                                                // (SMEM_M,SMEM_N,TILE_M,TILE_N)
+
+    // Partition sC, gC, and gD for the output
+    auto tiled_s2r = TiledCopyS2R{};
+    auto tD     = tiled_s2r.get_thread_slice(thread_idx);
+    Tensor tDsC = tD.partition_S(sC);                                   //               ((Atom,AtomNum),ATOM_M,ATOM_N)
+    Tensor tDgC = tD.partition_D(gCt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
+    Tensor tDgD = tD.partition_D(gDt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
+
+    // Allocate intermediate registers on the dst tensors
+    Tensor tDrC = make_tensor<ElementAccumulator>(take<0,3>(shape(tDgC)));            // ((Atom,AtomNum),ATOM_M,ATOM_N)
+    Tensor tDrD = make_tensor<ElementOutput>(shape(tDrC));                            // ((Atom,AtomNum),ATOM_M,ATOM_N)
+
+    // Repeat the D-partitioning for coordinates and predication
+    Tensor cD   = make_identity_tensor(make_shape(size<0>(gD),size<1>(gD)));          // (BLK_M,BLK_N) -> (blk_m,blk_n)
+    Tensor cDt  = flat_divide(cD, tile);                                //                (SMEM_M,SMEM_N,TILE_M,TILE_N)
+    Tensor tDcD = tD.partition_D(cDt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
+
+    CUTE_STATIC_ASSERT(size<1>(tCaC) % size<3>(tDgC) == 0);  // TILE_M divides MMA_M
+    CUTE_STATIC_ASSERT(size<2>(tCaC) % size<4>(tDgC) == 0);  // TILE_N divides MMA_N
+    CUTE_STATIC_ASSERT(typename TiledCopyS2R::TiledNumThr{} == size<0>(typename TiledMma::AtomLayoutC_TV{}));
 
+#if 0
+    if (thread_idx == 0 && m_coord == 0 && n_coord == 0) {
+      print("aC   : "); print(accumulators.layout()); print("\n");
+      print("gC   : "); print(gC.layout()); print("\n");
+      print("gD   : "); print(gD.layout()); print("\n");
+      print("sC   : "); print(sC.layout()); print("\n");
+      print("\n");
+      print("tCsC : "); print(tCsC.layout()); print("\n");
+      print("tCaC : "); print(tCaC.layout()); print("\n");
+      print("\n");
+      print("gDt  : "); print(gDt.layout()); print("\n");
+      print("tDsC : "); print(tDsC.layout()); print("\n");
+      print("tDrC : "); print(tDrC.layout()); print("\n");
+      print("\n");
+      print("tDrD : "); print(tDrD.layout()); print("\n");
+      print("tDgC : "); print(tDgC.layout()); print("\n");
+      print("tDgD : "); print(tDgD.layout()); print("\n");
+      print("\n");
+    }
+#endif
 
-template <typename TA, typename TB, typename TC,
-          typename Alpha, typename Beta>
-void
-gemm(int m, int n, int k,
-     Alpha alpha,
-     TA const* A, int ldA,
-     TB const* B, int ldB,
-     Beta beta,
-     TC      * C, int ldC,
-     cudaStream_t stream = 0)
-{
-  using namespace cute;
-
-  // Define shapes (dynamic)
-  auto M = int(m);
-  auto N = int(n);
-  auto K = int(k);
-
-  // Define strides (mixed)
-  auto dA = make_stride(Int<1>{}, ldA);
-  auto dB = make_stride(Int<1>{}, ldB);
-  auto dC = make_stride(Int<1>{}, ldC);
-
-  // Define block sizes (static)
-  auto bM = Int<128>{};
-  auto bN = Int<128>{};
-  auto bK = Int<  8>{};
-
-  // Define the block layouts (static)
-  auto sA = make_layout(make_shape(bM,bK));
-  auto sB = make_layout(make_shape(bN,bK));
-  auto sC = make_layout(make_shape(bM,bN));
-
-  // Define the thread layouts (static)
-  auto tA = make_layout(make_shape(Int<32>{}, Int< 8>{}));
-  auto tB = make_layout(make_shape(Int<32>{}, Int< 8>{}));
-  auto tC = make_layout(make_shape(Int<16>{}, Int<16>{}));
-
-  dim3 dimBlock(size(tC));
-  dim3 dimGrid(ceil_div(size(M), size(bM)),
-               ceil_div(size(N), size(bN)));
-  gemm_device
-      <<< dimGrid, dimBlock, 0, stream >>>
-      (M,  N,  K,
-       A, dA, sA, tA,
-       B, dB, sB, tB,
-       C, dC, sC, tC,
-       alpha, beta);
-}
-
-#include <cstdlib>
-#include <cstdio>
-#include <cassert>
-
-void test_gemm(int m, int n, int k)
-{
-  cute::device_init(0);
-
-  std::cout << "M = " << m << std::endl;
-  std::cout << "N = " << n << std::endl;
-  std::cout << "K = " << k << std::endl;
-
-  using TA = float;
-  using TB = float;
-  using TC = float;
-  using TI = float;
-
-  thrust::host_vector<TA> h_A(m*k);
-  thrust::host_vector<TB> h_B(n*k);
-  thrust::host_vector<TC> h_C(m*n);
-
-  for (int j = 0; j < m*k; ++j) h_A[j] = static_cast<TA>( 2*(rand() / double(RAND_MAX)) - 1 );
-  for (int j = 0; j < n*k; ++j) h_B[j] = static_cast<TB>( 2*(rand() / double(RAND_MAX)) - 1 );
-  for (int j = 0; j < m*n; ++j) h_C[j] = static_cast<TC>(-1);
-
-  thrust::device_vector<TA> d_A = h_A;
-  thrust::device_vector<TB> d_B = h_B;
-  thrust::device_vector<TC> d_C = h_C;
-
-  TI alpha = 1.0;
-  TI beta  = 0.0;
-
-  double gflops = (2.0*m*n*k) * 1e-9;
-
-  const int timing_iterations = 100;
-  GPU_Clock timer;
-
-#if defined(CUTLASS_ENABLE_CUBLAS) && CUTLASS_ENABLE_CUBLAS != 0
-  //
-  // cuBLas
-  //
-
-  cublasHandle_t handle;
-  cublasCreate(&handle);
-
-  // Run once
-  d_C = h_C;
-  blam::cublas::gemm(handle, CUBLAS_OP_N, CUBLAS_OP_T,
-                     m, n, k,
-                     &alpha,
-                     d_A.data().get(), m,
-                     d_B.data().get(), n,
-                     &beta,
-                     d_C.data().get(), m);
-  CUTE_CHECK_LAST();
-
-  thrust::host_vector<TC> cublas_result = d_C;
-
-  // Timing iterations
-  timer.start();
-  for (int i = 0; i < timing_iterations; ++i) {
-    blam::cublas::gemm(handle, CUBLAS_OP_N, CUBLAS_OP_T,
-                       m, n, k,
-                       &alpha,
-                       d_A.data().get(), m,
-                       d_B.data().get(), n,
-                       &beta,
-                       d_C.data().get(), m);
+    // For each tiling needed for SmemLayout to cover shape(gD)
+    CUTLASS_PRAGMA_UNROLL
+    for (int step_m = 0; step_m < size<2>(cDt); ++step_m)
+    {
+      CUTLASS_PRAGMA_UNROLL
+      for (int step_n = 0; step_n < size<3>(cDt); ++step_n)
+      {
+        // Step 1. Copy to SMEM
+        CUTLASS_PRAGMA_UNROLL
+        for (int pipe_m = 0; pipe_m < size<1>(tCsC); ++pipe_m) {
+          CUTLASS_PRAGMA_UNROLL
+          for (int pipe_n = 0; pipe_n < size<2>(tCsC); ++pipe_n) {
+            int mma_m = step_m * size<1>(tCsC) + pipe_m;
+            int mma_n = step_n * size<2>(tCsC) + pipe_n;
+
+            copy(tiled_r2s, tCaC(_,mma_m,mma_n), tCsC(_,pipe_m,pipe_n));
+          }
+        }
+
+        // Step 2. Wait for SMEM writes to complete
+        synchronize();
+
+        // Step 3. Copy from SMEM into a fragment
+        copy(tiled_s2r, tDsC, tDrC);
+
+        // Step 4. Wait for SMEM reads to complete
+        synchronize();
+
+        Tensor tDgDmn = tDgD(_,_,_,step_m,step_n);
+        Tensor tDcDmn = tDcD(_,_,_,step_m,step_n);
+
+        if (epilogue_op.is_source_needed()) {
+          // source is needed
+          Tensor tDgCmn = tDgC(_,_,_,step_m,step_n);
+          CUTLASS_PRAGMA_UNROLL
+          for (int m = 0; m < size<1>(tDgDmn); ++m)
+          {
+            CUTLASS_PRAGMA_UNROLL
+            for (int n = 0; n < size<2>(tDgDmn); ++n)
+            {
+              // Predication
+              if (get<0>(tDcDmn(0,m,n)) < get<0>(residue_mnk) &&
+                  get<1>(tDcDmn(0,m,n)) < get<1>(residue_mnk))
+              {
+                // Step 5. Elementwise operation with conversion
+                CUTLASS_PRAGMA_UNROLL
+                for (int i = 0; i < size<0>(tDrC); ++i) {
+                  tDrD(i,m,n) = epilogue_op(tDrC(i,m,n), tDgCmn(i,m,n));
+                }
+                // Step 6. Copy to GMEM
+                copy(CopyAtomR2G{}, tDrD(_,m,n), tDgDmn(_,m,n));
+              }
+            }
+          }
+        }
+        else {
+          // source is not needed, avoid load and lift compute
+
+          // Step 5. Elementwise operation with conversion
+          CUTLASS_PRAGMA_UNROLL
+          for (int i = 0; i < size(tDrC); ++i) {
+            tDrD(i) = epilogue_op(tDrC(i));
+          }
+
+          CUTLASS_PRAGMA_UNROLL
+          for (int m = 0; m < size<1>(tDgDmn); ++m)
+          {
+            CUTLASS_PRAGMA_UNROLL
+            for (int n = 0; n < size<2>(tDgDmn); ++n)
+            {
+              // Predication
+              if (get<0>(tDcDmn(0,m,n)) < get<0>(residue_mnk) &&
+                  get<1>(tDcDmn(0,m,n)) < get<1>(residue_mnk))
+              {
+                // Step 6. Copy to GMEM
+                copy(CopyAtomR2G{}, tDrD(_,m,n), tDgDmn(_,m,n));
+              }
+            }
+          }
+        }
+      }
+    }
   }
-  double cublas_time = timer.seconds() / timing_iterations;
-  CUTE_CHECK_LAST();
-  printf("CUBLAS_GEMM:   [%6.1f]GFlop/s  (%6.4f)ms\n", gflops / cublas_time, cublas_time*1000);
-
-#else
 
-  std::cout << "Verification by comparison with cuBLAS is disabled, "
-    "either because the CMake option CUTLASS_ENABLE_CUBLAS "
-    "was explicitly set to OFF, or because CMake could not find cuBLAS.  "
-    "If you would like to enable verification with cuBLAS, "
-    "please set the CMake option CUTLASS_ENABLE_CUBLAS to ON, "
-    "rerun CMake, and recompile this example.\n";
+private:
+  Params params;
+  ThreadEpilogueOp epilogue_op;
+};
 
-#endif // CUTLASS_ENABLE_CUBLAS
 
-  //
-  // CuTe
-  //
-
-  // Run once (and check)
-  d_C = h_C;
-  gemm(m, n, k,
-       alpha,
-       d_A.data().get(), m,
-       d_B.data().get(), n,
-       beta,
-       d_C.data().get(), m);
-  CUTE_CHECK_LAST();
-  thrust::host_vector<TC> cute_result = d_C;
-
-  // Timing iterations
-  timer.start();
-  for (int i = 0; i < timing_iterations; ++i) {
-    gemm(m, n, k,
-         alpha,
-         d_A.data().get(), m,
-         d_B.data().get(), n,
-         beta,
-         d_C.data().get(), m);
-  }
-  double cute_time = timer.seconds() / timing_iterations;
-  CUTE_CHECK_LAST();
-  printf("CUTE_GEMM:     [%6.1f]GFlop/s  (%6.4f)ms\n", gflops / cute_time, cute_time*1000);
-
-#if defined(CUTLASS_ENABLE_CUBLAS) && CUTLASS_ENABLE_CUBLAS != 0
-  printf("Empirical Perf: %.1f%%\n", (cublas_time / cute_time) * 100);
-
-  auto host_matrix_to_const_column_major_cute_tensor =
-    [](const auto& X, int num_rows, int num_cols, int LDX) {
-      const auto shape = cute::Shape<int, int>{num_rows, num_cols};
-      const auto strides = cute::Stride<int, int>{1, LDX};
-      return cute::make_tensor(X.data(), cute::make_layout(shape, strides));
-    };
-
-  const auto A_view = host_matrix_to_const_column_major_cute_tensor(h_A, m, k, m);
-  // B^T is k x n, so B is n x k.
-  const auto B_view = host_matrix_to_const_column_major_cute_tensor(h_B, n, k, n);
-  const auto C_computed_view = host_matrix_to_const_column_major_cute_tensor(cute_result, m, n, m);
-  const auto C_expected_view = host_matrix_to_const_column_major_cute_tensor(cublas_result, m, n, m);
-  print_matrix_multiply_mollified_relative_error("float", A_view, B_view, C_computed_view, C_expected_view);
-
-#endif // CUTLASS_ENABLE_CUBLAS
-}
-
-
-int main(int argc, char** argv)
-{
-  int m = 5120;
-  if (argc >= 2)
-    sscanf(argv[1], "%d", &m);
-
-  int n = 5120;
-  if (argc >= 3)
-    sscanf(argv[2], "%d", &n);
-
-  int k = 4096;
-  if (argc >= 4)
-    sscanf(argv[3], "%d", &k);
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  test_gemm(m, n, k);
+} // namespace collective
+} // namespace epilogue
+} // namespace cutlass
 
-  return 0;
-}
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/examples/cute/tutorial/tiled_copy.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/examples/cute/tutorial/tiled_copy.cu`

 * *Files 5% similar despite different names*

```diff
@@ -63,53 +63,54 @@
 // does not perform predication.
 
 
 /// Simple copy kernel.
 //
 // Uses local_partition() to partition a tile among threads arranged as (THR_M, THR_N).
 template <class TensorS, class TensorD, class ThreadLayout>
-__global__ void copy_kernel(TensorS S, TensorD D, ThreadLayout) 
+__global__ void copy_kernel(TensorS S, TensorD D, ThreadLayout)
 {
   using namespace cute;
 
   // Slice the tiled tensors
   Tensor tile_S = S(make_coord(_,_), blockIdx.x, blockIdx.y);   // (BlockShape_M, BlockShape_N)
   Tensor tile_D = D(make_coord(_,_), blockIdx.x, blockIdx.y);   // (BlockShape_M, BlockShape_N)
 
   // Construct a partitioning of the tile among threads with the given thread arrangement.
 
-  // Concept:                       Tensor    Layout          Index
-  Tensor thr_tile_S = local_partition(tile_S, ThreadLayout{}, threadIdx.x);
-  Tensor thr_tile_D = local_partition(tile_D, ThreadLayout{}, threadIdx.x);
+  // Concept:                         Tensor  ThrLayout       ThrIndex
+  Tensor thr_tile_S = local_partition(tile_S, ThreadLayout{}, threadIdx.x);  // (ThrValM, ThrValN)
+  Tensor thr_tile_D = local_partition(tile_D, ThreadLayout{}, threadIdx.x);  // (ThrValM, ThrValN)
 
   // Construct a register-backed Tensor with the same shape as each thread's partition
-  auto fragment = make_fragment_like(thr_tile_S);
+  // Use make_tensor to try to match the layout of thr_tile_S
+  Tensor fragment = make_tensor_like(thr_tile_S);               // (ThrValM, ThrValN)
 
   // Copy from GMEM to RMEM and from RMEM to GMEM
   copy(thr_tile_S, fragment);
   copy(fragment, thr_tile_D);
 }
 
 /// Vectorized copy kernel.
 ///
 /// Uses `make_tiled_copy()` to perform a copy using vector instructions. This operation
 /// has the precondition that pointers are aligned to the vector size.
 ///
 template <class TensorS, class TensorD, class ThreadLayout, class VecLayout>
-__global__ void copy_kernel_vectorized(TensorS S, TensorD D, ThreadLayout, VecLayout) 
+__global__ void copy_kernel_vectorized(TensorS S, TensorD D, ThreadLayout, VecLayout)
 {
   using namespace cute;
   using Element = typename TensorS::value_type;
 
   // Slice the tensors to obtain a view into each tile.
-  Tensor tile_S = S(make_coord(_, _), blockIdx.x, blockIdx.y);   // (BlockShape_M, BlockShape_N)
-  Tensor tile_D = D(make_coord(_, _), blockIdx.x, blockIdx.y);   // (BlockShape_M, BlockShape_N)
+  Tensor tile_S = S(make_coord(_, _), blockIdx.x, blockIdx.y);  // (BlockShape_M, BlockShape_N)
+  Tensor tile_D = D(make_coord(_, _), blockIdx.x, blockIdx.y);  // (BlockShape_M, BlockShape_N)
 
   // Define `AccessType` which controls the size of the actual memory access.
-  using AccessType = cutlass::AlignedArray<Element, size(shape(VecLayout{}))>;
+  using AccessType = cutlass::AlignedArray<Element, size(VecLayout{})>;
 
   // A copy atom corresponds to one hardware memory access.
   using Atom = Copy_Atom<UniversalCopy<AccessType>, Element>;
 
   // Construct tiled copy, a tiling of copy atoms.
   //
   // Note, this assumes the vector and thread layouts are aligned with contigous data
@@ -121,114 +122,106 @@
       Atom{},                       // access size
       ThreadLayout{},               // thread layout
       VecLayout{});                 // vector layout (e.g. 4x1)
 
   // Construct a Tensor corresponding to each thread's slice.
   auto thr_copy = tiled_copy.get_thread_slice(threadIdx.x);
 
-  Tensor thr_tile_S = thr_copy.partition_S(tile_S);
-  Tensor thr_tile_D = thr_copy.partition_D(tile_D);
+  Tensor thr_tile_S = thr_copy.partition_S(tile_S);             // (CopyOp, CopyM, CopyN)
+  Tensor thr_tile_D = thr_copy.partition_D(tile_D);             // (CopyOp, CopyM, CopyN)
 
   // Construct a register-backed Tensor with the same shape as each thread's partition
-  auto fragment = make_fragment_like(thr_tile_D);
+  // Use make_fragment because the first mode is the instruction-local mode
+  Tensor fragment = make_fragment_like(thr_tile_D);             // (CopyOp, CopyM, CopyN)
 
   // Copy from GMEM to RMEM and from RMEM to GMEM
   copy(tiled_copy, thr_tile_S, fragment);
   copy(tiled_copy, fragment, thr_tile_D);
 }
 
-/// Helper to convert a shape to a dim3
-template <class Shape>
-dim3 shape_to_dim3(Shape shape)
-{
-  using namespace cute;
-
-  CUTE_STATIC_ASSERT_V(rank(shape) <= Int<3>{});
-  auto result = append<3>(product_each(shape), 1u);
-
-  return dim3(get<0>(result), get<1>(result), get<2>(result));
-}
-
 /// Main function
 int main(int argc, char** argv)
 {
   //
   // Given a 2D shape, perform an efficient copy
   //
 
   using namespace cute;
   using Element = float;
 
   // Define a tensor shape with dynamic extents (m, n)
   auto tensor_shape = make_shape(256, 512);
 
-  thrust::host_vector<Element> h_S(size(tensor_shape));
-  thrust::host_vector<Element> h_D(size(tensor_shape));
-
   //
-  // Initialize
+  // Allocate and initialize
   //
 
+  thrust::host_vector<Element> h_S(size(tensor_shape));
+  thrust::host_vector<Element> h_D(size(tensor_shape));
+
   for (size_t i = 0; i < h_S.size(); ++i) {
     h_S[i] = static_cast<Element>(i);
     h_D[i] = Element{};
   }
 
   thrust::device_vector<Element> d_S = h_S;
   thrust::device_vector<Element> d_D = h_D;
 
   //
   // Make tensors
   //
 
-  Tensor tensor_S = make_tensor(make_gmem_ptr(d_S.data().get()), make_layout(tensor_shape));  
-  Tensor tensor_D = make_tensor(make_gmem_ptr(d_D.data().get()), make_layout(tensor_shape));
+  Tensor tensor_S = make_tensor(make_gmem_ptr(thrust::raw_pointer_cast(d_S.data())), make_layout(tensor_shape));
+  Tensor tensor_D = make_tensor(make_gmem_ptr(thrust::raw_pointer_cast(d_D.data())), make_layout(tensor_shape));
 
   //
-  // Partition
+  // Tile tensors
   //
 
-
   // Define a statically sized block (M, N).
-  //
   // Note, by convention, capital letters are used to represent static modes.
   auto block_shape = make_shape(Int<128>{}, Int<64>{});
 
-  if ((get<0>(tensor_shape) % get<0>(block_shape)) || (get<1>(tensor_shape) % get<1>(block_shape))) {
+  if ((size<0>(tensor_shape) % size<0>(block_shape)) || (size<1>(tensor_shape) % size<1>(block_shape))) {
     std::cerr << "The tensor shape must be divisible by the block shape." << std::endl;
     return -1;
   }
+  // Equivalent check to the above
+  if (not weakly_compatible(block_shape, tensor_shape)) {
+    std::cerr << "Expected the tensors to be weakly compatible with the block_shape." << std::endl;
+    return -1;
+  }
 
-  // Tile the tensor (m, m) ==> ((M, N), m', n') where (M, N) is the static tile
+  // Tile the tensor (m, n) ==> ((M, N), m', n') where (M, N) is the static tile
   // shape, and modes (m', n') correspond to the number of tiles.
-  // 
-  // These will be used to determine the CUDA kernel grid dimensinos.
-  Tensor tiled_tensor_S = tiled_divide(tensor_S, block_shape);
-  Tensor tiled_tensor_D = tiled_divide(tensor_D, block_shape);
+  //
+  // These will be used to determine the CUDA kernel grid dimensions.
+  Tensor tiled_tensor_S = tiled_divide(tensor_S, block_shape);      // ((M, N), m', n')
+  Tensor tiled_tensor_D = tiled_divide(tensor_D, block_shape);      // ((M, N), m', n')
 
   // Thread arrangement
-  Layout thr_layout = make_layout(make_shape(Int<32>{}, Int< 8>{}));
+  Layout thr_layout = make_layout(make_shape(Int<32>{}, Int<8>{}));
 
   // Vector dimensions
   Layout vec_layout = make_layout(make_shape(Int<4>{}, Int<1>{}));
 
   //
   // Determine grid and block dimensions
   //
 
-  dim3 gridDim = shape_to_dim3(select<1,2>(shape(tiled_tensor_D))); // Grid shape corresponds to  modes m' and n'
-  dim3 blockDim(size(shape(thr_layout)));
+  dim3 gridDim (size<1>(tiled_tensor_D), size<2>(tiled_tensor_D));   // Grid shape corresponds to modes m' and n'
+  dim3 blockDim(size(thr_layout));
 
   //
   // Launch the kernel
   //
   copy_kernel_vectorized<<< gridDim, blockDim >>>(
-    tiled_tensor_S, 
-    tiled_tensor_D, 
-    thr_layout, 
+    tiled_tensor_S,
+    tiled_tensor_D,
+    thr_layout,
     vec_layout);
 
   cudaError result = cudaDeviceSynchronize();
   if (result != cudaSuccess) {
     std::cerr << "CUDA Runtime error: " << cudaGetErrorString(result) << std::endl;
     return -1;
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/axpby.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/axpby.hpp`

 * *Files 10% similar despite different names*

```diff
@@ -29,60 +29,67 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/tensor.hpp>
+#include <cute/tensor_predicate.hpp>
 
 namespace cute
 {
 
 //
 // Accept mutable temporaries
 //
 template <class Alpha,
           class XEngine, class XLayout,
           class Beta,
-          class YEngine, class YLayout>
+          class YEngine, class YLayout,
+          class PrdTensor = TrivialPredTensor>
 CUTE_HOST_DEVICE
 void
 axpby(Alpha                    const& alpha,
       Tensor<XEngine, XLayout> const& x,
       Beta                     const& beta,
-      Tensor<YEngine, YLayout>     && y)
+      Tensor<YEngine, YLayout>     && y,
+      PrdTensor                const& p = {})
 {
-  return axpby(alpha, x, beta, y);
+  return axpby(alpha, x, beta, y, p);
 }
 
 //
 // AXPBY
 //
 template <class Alpha,
           class XEngine, class XLayout,
           class Beta,
-          class YEngine, class YLayout>
+          class YEngine, class YLayout,
+          class PrdTensor = TrivialPredTensor>
 CUTE_HOST_DEVICE
 void
 axpby(Alpha                    const& alpha,
       Tensor<XEngine, XLayout> const& x,
       Beta                     const& beta,
-      Tensor<YEngine, YLayout>      & y)
+      Tensor<YEngine, YLayout>      & y,
+      PrdTensor                const& p = {})
 {
   auto isBetaZero = [&] () {
     if constexpr (is_complex<Beta>::value) {
       return beta.real() == Int<0>{} && beta.imag() == Int<0>{};
     }
     else {
       return beta == Int<0>{};
     }
 
     CUTE_GCC_UNREACHABLE;
   } ();
 
   CUTE_UNROLL
   for (int i = 0; i < size(x); ++i) {
-    y(i) = (isBetaZero ? alpha * x(i) : alpha * x(i) + beta * y(i));
+    if (p(i)) {
+      y(i) = (isBetaZero ? alpha * x(i) : alpha * x(i) + beta * y(i));
+    }
   }
 }
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/clear.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/clear.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/copy.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/copy.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -141,18 +141,18 @@
 //
 // copy_if -- Predicated CopyAtom
 //
 
 namespace detail {
 
 // Trait that detects if atom's traits has a member function with(bool)
-template<typename, typename Enable = void>
+template <class, class Enable = void>
 constexpr bool has_with_bool = false;
 
-template<typename T>
+template <class T>
 constexpr bool has_with_bool<T, cute::void_t<decltype(declval<typename T::Traits>().with(declval<bool>()))>> = true;
 
 } // end namespace detail
 
 template <class... CopyArgs,
           class PredTensor,
           class SrcEngine, class SrcLayout,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/fill.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/fill.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/functional.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/functional.hpp`

 * *Files 7% similar despite different names*

```diff
@@ -29,28 +29,29 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/util/type_traits.hpp>
+#include <cute/numeric/complex.hpp>
 
 /** C++14 <functional> extensions */
 
 namespace cute {
 
 /**************/
 /** Identity **/
 /**************/
 
 struct identity {
   template <class T>
   CUTE_HOST_DEVICE constexpr
   decltype(auto) operator()(T&& arg) const {
-    return std::forward<T>(arg);
+    return static_cast<T&&>(arg);
   }
 };
 
 template <class R>
 struct constant_fn {
   template <class... T>
   CUTE_HOST_DEVICE constexpr
@@ -65,31 +66,31 @@
 /***********/
 
 #define CUTE_LEFT_UNARY_OP(NAME,OP)                                  \
   struct NAME {                                                      \
     template <class T>                                               \
     CUTE_HOST_DEVICE constexpr                                       \
     decltype(auto) operator()(T&& arg) const {                       \
-      return OP std::forward<T>(arg);                                \
+      return OP static_cast<T&&>(arg);                                \
     }                                                                \
   }
 #define CUTE_RIGHT_UNARY_OP(NAME,OP)                                 \
   struct NAME {                                                      \
     template <class T>                                               \
     CUTE_HOST_DEVICE constexpr                                       \
     decltype(auto) operator()(T&& arg) const {                       \
-      return std::forward<T>(arg) OP ;                               \
+      return static_cast<T&&>(arg) OP ;                               \
     }                                                                \
   }
 #define CUTE_NAMED_UNARY_OP(NAME,OP)                                 \
   struct NAME {                                                      \
     template <class T>                                               \
     CUTE_HOST_DEVICE constexpr                                       \
     decltype(auto) operator()(T&& arg) const {                       \
-      return OP (std::forward<T>(arg));                              \
+      return OP (static_cast<T&&>(arg));                              \
     }                                                                \
   }
 
 CUTE_LEFT_UNARY_OP(unary_plus,       +);
 CUTE_LEFT_UNARY_OP(negate,           -);
 CUTE_LEFT_UNARY_OP(bit_not,          ~);
 CUTE_LEFT_UNARY_OP(logical_not,      !);
@@ -111,47 +112,47 @@
 template <int Shift_>
 struct shift_right_const {
   static constexpr int Shift = Shift_;
 
   template <class T>
   CUTE_HOST_DEVICE constexpr
   decltype(auto) operator()(T&& arg) const {
-    return std::forward<T>(arg) >> Shift;
+    return static_cast<T&&>(arg) >> Shift;
   }
 };
 
 template <int Shift_>
 struct shift_left_const {
   static constexpr int Shift = Shift_;
 
   template <class T>
   CUTE_HOST_DEVICE constexpr
   decltype(auto) operator()(T&& arg) const {
-    return std::forward<T>(arg) << Shift;
+    return static_cast<T&&>(arg) << Shift;
   }
 };
 
 /************/
 /** Binary **/
 /************/
 
 #define CUTE_BINARY_OP(NAME,OP)                                      \
   struct NAME {                                                      \
     template <class T, class U>                                      \
     CUTE_HOST_DEVICE constexpr                                       \
     decltype(auto) operator()(T&& lhs, U&& rhs) const {              \
-      return std::forward<T>(lhs) OP std::forward<U>(rhs);           \
+      return static_cast<T&&>(lhs) OP static_cast<U&&>(rhs);           \
     }                                                                \
   }
 #define CUTE_NAMED_BINARY_OP(NAME,OP)                                \
   struct NAME {                                                      \
     template <class T, class U>                                      \
     CUTE_HOST_DEVICE constexpr                                       \
     decltype(auto) operator()(T&& lhs, U&& rhs) const {              \
-      return OP (std::forward<T>(lhs), std::forward<U>(rhs));        \
+      return OP (static_cast<T&&>(lhs), static_cast<U&&>(rhs));        \
     }                                                                \
   }
 
 
 CUTE_BINARY_OP(plus,                 +);
 CUTE_BINARY_OP(minus,                -);
 CUTE_BINARY_OP(multiplies,           *);
@@ -269,15 +270,15 @@
 template <class Fn, class Arg>
 struct bound_fn {
 
   template <class T>
   CUTE_HOST_DEVICE constexpr
   decltype(auto)
   operator()(T&& arg) {
-    return fn_(arg_, std::forward<T>(arg));
+    return fn_(arg_, static_cast<T&&>(arg));
   }
 
   Fn fn_;
   Arg arg_;
 };
 
 template <class Fn, class Arg>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/gemm.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/gemm.hpp`

 * *Files 24% similar despite different names*

```diff
@@ -248,15 +248,15 @@
   CUTE_STATIC_ASSERT_V(size<1>(A) == size<1>(B));  // AK == BK
   CUTE_STATIC_ASSERT_V(size<0>(C) == size<0>(D) && size<1>(C) == size<1>(D));
 
   // Assert this is a 1-value MMA
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutC_TV{}) == Int<1>{});
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutA_TV{}) == Int<1>{});
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutB_TV{}) == Int<1>{});
-  
+
   gemm(mma,
        make_tensor(D.data(), prepend<3>(D.layout())),      // (1,M,N)
        make_tensor(A.data(), prepend<3>(A.layout())),      // (1,M,K)
        make_tensor(B.data(), prepend<3>(B.layout())),      // (1,N,K)
        make_tensor(C.data(), prepend<3>(C.layout())));     // (1,M,N)
 }
 
@@ -447,14 +447,15 @@
   CUTE_STATIC_ASSERT_V(size<1>(A) == size<1>(B));  // AK == BK
   CUTE_STATIC_ASSERT_V(size<0>(C) == size<0>(D) && size<1>(C) == size<1>(D));
 
   // Assert this is a 1-value MMA
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutC_TV{}) == Int<1>{});
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutA_TV{}) == Int<1>{});
   CUTE_STATIC_ASSERT_V(size<1>(typename MMA_Atom<MMA>::LayoutB_TV{}) == Int<1>{});
+
   gemm(mma,
        make_tensor(D.data(), prepend<3>(D.layout())),      // (1,M,N)
        make_tensor(A.data(), prepend<3>(A.layout())),      // (1,M,K)
        make_tensor(B.data(), prepend<3>(B.layout())),      // (1,N,K)
        make_tensor(C.data(), prepend<3>(C.layout())));     // (1,M,N)
 }
 
@@ -492,249 +493,8 @@
     copy(A(_,_,k), rA(_,_,k));
     copy(B(_,_,k), rB(_,_,k));
     // Thread-level register gemm for k
     gemm(mma, D, rA(_,_,k), rB(_,_,k), C);
   }
 }
 
-//
-// Collective Shared-Memory GEMMs
-//
-
-template <class... Args,
-          class Alpha, class TA, class ALayout, class TB, class BLayout,
-          class Beta,  class TC, class CLayout,
-          class ALoadTransformOp, class BLoadTransformOp,
-          __CUTE_REQUIRES(ALayout::rank == 2 && is_smem<TA>::value &&
-                          BLayout::rank == 2 && is_smem<TB>::value &&
-                          CLayout::rank == 2 && is_smem<TC>::value)>
-CUTE_HOST_DEVICE
-void
-gemm(ThrMMA<Args...> const& thr_mma,
-     Alpha const& alpha,
-     Tensor<TA, ALayout> sA,
-     Tensor<TB, BLayout> sB,
-     Beta  const& beta,
-     Tensor<TC, CLayout> sC,
-     ALoadTransformOp const& sA_load_op /* transforms A values before used in GEMM */,
-     BLoadTransformOp const& sB_load_op /* transforms B values before used in GEMM */)
-{
-  CUTE_STATIC_ASSERT_V(size<0>(sA) == size<0>(sC));  // AM == CM
-  CUTE_STATIC_ASSERT_V(size<0>(sB) == size<1>(sC));  // BN == CN
-  CUTE_STATIC_ASSERT_V(size<1>(sA) == size<1>(sB));  // AK == BK
-
-  using TypeA = typename TA::value_type;
-  using TypeB = typename TB::value_type;
-  using TypeC = typename TC::value_type;
-
-  static_assert(is_same_v<decay_t<invoke_result_t<ALoadTransformOp, TypeA>>, TypeA>,
-    "ALoadTransformOp functor must accept and return value of type TA::value_type");
-  static_assert(is_same_v<decay_t<invoke_result_t<BLoadTransformOp, TypeB>>, TypeB>,
-    "BLoadTransformOp functor must accept and return value of type TB::value_type");
-
-  // Original, static size of the problem
-  auto M = size<0>(sC);
-  auto N = size<1>(sC);
-  auto K = size<1>(sA);
-
-  // Block size of the compute tile
-  auto BLK_M = tile_size<0>(thr_mma);
-  auto BLK_N = tile_size<1>(thr_mma);
-  auto BLK_K = tile_size<2>(thr_mma);
-
-  // Compute the "residues"
-  auto m_residue = M - BLK_M * (ceil_div(M, BLK_M) - Int<1>{});  //  (0,BLK_M]
-  auto n_residue = N - BLK_N * (ceil_div(N, BLK_N) - Int<1>{});  //  (0,BLK_N]
-  auto k_residue = K - BLK_K * (ceil_div(K, BLK_K)           );  // (-BLK_K,0]
-
-  // Shift the origin so k_residue is zeroth tile
-  sA.data() = &sA(0,k_residue);
-  sB.data() = &sB(0,k_residue);
-
-#if 0
-  if (thread0()) {
-    printf("%d in BLK_M (%d)\n", int(m_residue), int(BLK_M));
-    printf("%d in BLK_N (%d)\n", int(n_residue), int(BLK_N));
-    printf("%d in BLK_K (%d)\n", int(k_residue), int(BLK_K));
-  }
-#endif
-
-  //
-  // MMA Partitioning
-  //
-
-  // Round the layout extents up to BLK_X
-  Tensor rounded_sA = sA.compose(make_shape(ceil_div(M, BLK_M) * BLK_M, ceil_div(K, BLK_K) * BLK_K));
-  Tensor rounded_sB = sB.compose(make_shape(ceil_div(N, BLK_N) * BLK_N, ceil_div(K, BLK_K) * BLK_K));
-  Tensor rounded_sC = sC.compose(make_shape(ceil_div(M, BLK_M) * BLK_M, ceil_div(N, BLK_N) * BLK_N));
-
-#if 0
-  if (thread0()) {
-    print(rounded_sA.layout()); print("\n");
-    print(rounded_sB.layout()); print("\n");
-    print(rounded_sC.layout()); print("\n");
-  }
-#endif
-
-  // Partition the sA and sB tiles across the threads for the MMA
-  Tensor tCsA = thr_mma.partition_A(rounded_sA);                    // (MMA,MMA_M,MMA_K)
-  Tensor tCsB = thr_mma.partition_B(rounded_sB);                    // (MMA,MMA_N,MMA_K)
-  Tensor tCsC = thr_mma.partition_C(rounded_sC);                    // (MMA,MMA_M,MMA_N)
-  // Create register tensors for the MMA to operate on
-  Tensor tCrA = thr_mma.make_fragment_A(tCsA);                      // (MMA,MMA_M,MMA_K)
-  Tensor tCrB = thr_mma.make_fragment_B(tCsB);                      // (MMA,MMA_N,MMA_K)
-  Tensor tCrC = thr_mma.make_fragment_C(tCsC);                      // (MMA,MMA_M,MMA_N)
-
-#if 0
-  if (thread0()) {
-    print(tCsA.layout()); print("\n");
-    print(tCsB.layout()); print("\n");
-    print(tCsC.layout()); print("\n");
-    print(tCrA.layout()); print("\n");
-    print(tCrB.layout()); print("\n");
-    print(tCrC.layout()); print("\n");
-  }
-#endif
-
-  //
-  // PREDICATION
-  //
-
-  // Allocate the preds for only the MMA-mode of tCsA and tCsB
-  Tensor tCpA = make_tensor<bool>(size<0>(tCsA));
-  Tensor tCpB = make_tensor<bool>(size<0>(tCsB));
-
-  // Create coordinate tensors on a single compute block for predication
-  Tensor cA = make_identity_tensor(make_shape(BLK_M, BLK_K));        // (BLK_M,BLK_K) -> (blk_m,blk_k)
-  Tensor cB = make_identity_tensor(make_shape(BLK_N, BLK_K));        // (BLK_M,BLK_K) -> (blk_n,blk_k)
-
-  // Repeat partitioning with thr_mma
-  Tensor tCcA = thr_mma.partition_A(cA);                             // (MMA,1,1) -> (blk_m,blk_k)
-  Tensor tCcB = thr_mma.partition_B(cB);                             // (MMA,1,1) -> (blk_n,blk_k)
-
-  // Populate the m and n predicates
-  CUTE_UNROLL
-  for (int i = 0; i < size(tCpA); ++i) {
-    tCpA(i) = elem_less(get<0>(tCcA(i)), m_residue);
-  }
-  CUTE_UNROLL
-  for (int i = 0; i < size(tCpB); ++i) {
-    tCpB(i) = elem_less(get<0>(tCcB(i)), n_residue);
-  }
-
-#if 0
-  printf("Thr %d: A(%d,%d):%d  B(%d,%d):%d\n",
-         threadIdx.x,
-         int(get<0>(tCcA(0))), int(get<1>(tCcA(0))), int(tCpA(0)),
-         int(get<0>(tCcB(0))), int(get<1>(tCcB(0))), int(tCpB(0)));
-#endif
-
-  //
-  // PREFETCH k_block = 0 (with k-predication)
-  //
-
-  CUTE_UNROLL
-  for (int i = 0; i < size<0>(tCsA); ++i) {                // Copy MMA_I
-    if (k_residue == 0 || get<1>(tCcA(i)) >= -k_residue) { // k_block = 0, predicated on k
-      CUTE_UNROLL
-      for (int m = 0; m < size<1>(tCsA); ++m) {            // Copy MMA_M, predicated on m
-        tCrA(i,m,0) = (m_residue == BLK_M || m < size<1>(tCsA)-1 || tCpA(i)) ? sA_load_op(tCsA(i,m,0)) : TypeA{};
-      }
-    }
-  }
-
-  CUTE_UNROLL
-  for (int i = 0; i < size<0>(tCsB); ++i) {                // Copy MMA_I
-    if (k_residue == 0 || get<1>(tCcB(i)) >= -k_residue) { // k_block = 0, predicated on k
-      CUTE_UNROLL
-      for (int n = 0; n < size<1>(tCsB); ++n) {            // Copy MMA_N, predicated on n
-        tCrB(i,n,0) = (n_residue == BLK_N || n < size<1>(tCsB)-1 || tCpB(i)) ? sB_load_op(tCsB(i,n,0)) : TypeB{};
-      }
-    }
-  }
-  //
-  // MAINLOOP
-  //
-
-  // Clear accumulators
-  clear(tCrC);
-
-  constexpr int K_BLOCK_MAX = size<2>(tCrA);
-
-  CUTE_UNROLL
-  for (int k_block = 0; k_block < K_BLOCK_MAX; ++k_block)
-  {
-    // static-if load the next k_block. No k-predication required on these loads.
-    if (k_block < K_BLOCK_MAX-1)
-    {
-      // Load the next k_block
-      int k_next = k_block + 1;
-
-      CUTE_UNROLL
-      for (int m = 0; m < size<1>(tCsA); ++m) {            // Copy MMA_M
-        CUTE_UNROLL
-        for (int i = 0; i < size<0>(tCsA); ++i) {          // Copy_if MMA_I predicated on m
-          tCrA(i,m,k_next) = (m_residue == BLK_M || m < size<1>(tCsA)-1 || tCpA(i)) ? sA_load_op(tCsA(i,m,k_next)) : TypeA{};
-        }
-      }
-
-      CUTE_UNROLL
-      for (int n = 0; n < size<1>(tCsB); ++n) {            // Copy MMA_N
-        CUTE_UNROLL
-        for (int i = 0; i < size<0>(tCsB); ++i) {          // Copy MMA_I predicated on n
-          tCrB(i,n,k_next) = (n_residue == BLK_N || n < size<1>(tCsB)-1 || tCpB(i)) ? sB_load_op(tCsB(i,n,k_next)) : TypeB{};
-        }
-      }
-    }
-
-    // GEMM on k_block in registers
-    gemm(thr_mma, tCrA(_,_,k_block), tCrB(_,_,k_block), tCrC);
-  }
-
-  //
-  // Epilogue
-  //
-
-  Tensor cC   = make_identity_tensor(make_shape(BLK_M, BLK_N));      // (BLK_M,BLK_N) -> (blk_m,blk_n)
-  Tensor tCcC = thr_mma.partition_C(cC);                             // (MMA, 1, 1)   -> (blk_m,blk_n)
-
-  const bool isBetaZero = (beta == Beta{});
-
-  // Custom axpby_if for now
-  CUTE_UNROLL
-  for (int m = 0; m < size<1>(tCsC); ++m)
-  {
-    CUTE_UNROLL
-    for (int n = 0; n < size<2>(tCsC); ++n)
-    {
-      CUTE_UNROLL
-      for (int i = 0; i < size<0>(tCsC); ++i)
-      {
-        if ((m_residue == BLK_M || m < size<1>(tCrC)-1 || get<0>(tCcC(i)) < m_residue) &&
-            (n_residue == BLK_N || n < size<2>(tCrC)-1 || get<1>(tCcC(i)) < n_residue))
-        {
-          tCsC(i,m,n) = isBetaZero ? alpha * tCrC(i,m,n) : alpha * tCrC(i,m,n) + beta * tCsC(i,m,n);
-        }
-      }
-    }
-  }
-}
-
-template <class... Args,
-          class Alpha, class TA, class ALayout, class TB, class BLayout,
-          class Beta,  class TC, class CLayout,
-          __CUTE_REQUIRES(ALayout::rank == 2 && is_smem<TA>::value &&
-                          BLayout::rank == 2 && is_smem<TB>::value &&
-                          CLayout::rank == 2 && is_smem<TC>::value)>
-CUTE_HOST_DEVICE
-void
-gemm(ThrMMA<Args...> const& thr_mma,
-     Alpha const& alpha,
-     Tensor<TA, ALayout> sA,
-     Tensor<TB, BLayout> sB,
-     Beta  const& beta,
-     Tensor<TC, CLayout> sC)
-{
-  gemm(thr_mma, alpha, sA, sB, beta, sC, identity() /* sA_load_op */, identity() /* sB_load_op */);
-}
-
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/prefer.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/prefer.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -46,113 +46,122 @@
 template <class Engine, class Layout, class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
 for_each(Tensor<Engine,Layout> const& tensor, UnaryOp&& op)
 {
   CUTE_UNROLL
   for (int i = 0; i < size(tensor); ++i) {
-    static_cast<UnaryOp&&>(op)(tensor(i));
+    op(tensor(i));
   }
 }
 
 template <class Engine, class Layout, class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
 for_each(Tensor<Engine,Layout>& tensor, UnaryOp&& op)
 {
   CUTE_UNROLL
   for (int i = 0; i < size(tensor); ++i) {
-    static_cast<UnaryOp&&>(op)(tensor(i));
+    op(tensor(i));
   }
 }
 
 // Accept mutable temporaries
 template <class Engine, class Layout, class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
 for_each(Tensor<Engine,Layout>&& tensor, UnaryOp&& op)
 {
-  return for_each(tensor, static_cast<UnaryOp&&>(op));
+  return for_each(tensor, op);
 }
 
 //
 // transform
 //
 
 // Similar to std::transform but does not return number of elements affected
 template <class Engine, class Layout, class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
 transform(Tensor<Engine,Layout>& tensor, UnaryOp&& op)
 {
   CUTE_UNROLL
   for (int i = 0; i < size(tensor); ++i) {
-    tensor(i) = static_cast<UnaryOp&&>(op)(tensor(i));
+    tensor(i) = op(tensor(i));
   }
 }
 
 // Accept mutable temporaries
 template <class Engine, class Layout, class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
 transform(Tensor<Engine,Layout>&& tensor, UnaryOp&& op)
 {
-  return transform(tensor, std::forward<UnaryOp>(op));
+  return transform(tensor, op);
 }
 
 // Similar to std::transform transforms one tensors and assigns it to another
-template <class EngineIn, class LayoutIn, class EngineOut, class LayoutOut, class UnaryOp>
+template <class EngineIn, class LayoutIn, 
+          class EngineOut, class LayoutOut, 
+          class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
-transform(Tensor<EngineIn,LayoutIn>& tensor_in, Tensor<EngineOut,LayoutOut>& tensor_out, UnaryOp&& op)
+transform(Tensor<EngineIn, LayoutIn > const& tensor_in, 
+          Tensor<EngineOut,LayoutOut>      & tensor_out, 
+          UnaryOp&& op)
 {
   CUTE_UNROLL
   for (int i = 0; i < size(tensor_in); ++i) {
-    tensor_out(i) = static_cast<UnaryOp&&>(op)(tensor_in(i));
+    tensor_out(i) = op(tensor_in(i));
   }
 }
 
 // Accept mutable temporaries
 template <class EngineIn, class LayoutIn,
-          class EngineOut, class LayoutOut, class UnaryOp>
+          class EngineOut, class LayoutOut, 
+          class UnaryOp>
 CUTE_HOST_DEVICE constexpr
 void
-transform(Tensor<EngineIn,LayoutIn>&& tensor_in, Tensor<EngineOut,LayoutOut>&& tensor_out, UnaryOp&& op)
+transform(Tensor<EngineIn, LayoutIn > const& tensor_in, 
+          Tensor<EngineOut,LayoutOut>     && tensor_out, 
+          UnaryOp&& op)
 {
   return transform(tensor_in, tensor_out, op);
 }
 
 // Similar to std::transform with a binary operation
 // Takes two tensors as input and one tensor as output. 
 // Applies the binary_op to tensor_in1 and tensor_in2 and
 // assigns it to tensor_out
 template <class EngineIn1, class LayoutIn1,
           class EngineIn2, class LayoutIn2,
-          class EngineOut, class LayoutOut, class BinaryOp>
+          class EngineOut, class LayoutOut, 
+          class BinaryOp>
 CUTE_HOST_DEVICE constexpr
 void
-transform(Tensor<EngineIn1,LayoutIn1>& tensor_in1,
-          Tensor<EngineIn2,LayoutIn2>& tensor_in2,
-          Tensor<EngineOut,LayoutOut>& tensor_out, 
+transform(Tensor<EngineIn1,LayoutIn1> const& tensor_in1,
+          Tensor<EngineIn2,LayoutIn2> const& tensor_in2,
+          Tensor<EngineOut,LayoutOut>      & tensor_out, 
           BinaryOp&& op)
 {
   CUTE_UNROLL
   for (int i = 0; i < size(tensor_in1); ++i) {
-    tensor_out(i) = static_cast<BinaryOp&&>(op)(tensor_in1(i), tensor_in2(i));
+    tensor_out(i) = op(tensor_in1(i), tensor_in2(i));
   }
 }
 
 // Accept mutable temporaries
 template <class EngineIn1, class LayoutIn1,
           class EngineIn2, class LayoutIn2,
-          class EngineOut, class LayoutOut, class BinaryOp>
+          class EngineOut, class LayoutOut, 
+          class BinaryOp>
 CUTE_HOST_DEVICE constexpr
 void
-transform(Tensor<EngineIn1,LayoutIn1>&& tensor_in1, 
-          Tensor<EngineIn2,LayoutIn2>&& tensor_in2,
-          Tensor<EngineOut,LayoutOut>&& tensor_out,
+transform(Tensor<EngineIn1,LayoutIn1> const& tensor_in1, 
+          Tensor<EngineIn2,LayoutIn2> const& tensor_in2,
+          Tensor<EngineOut,LayoutOut>     && tensor_out,
           BinaryOp&& op)
 {
   return transform(tensor_in1, tensor_in2, tensor_out, op);
 }
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -201,44 +201,14 @@
     return f(static_cast<T&&>(t));
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 //
-// For Sequence
-// (s, t, f) => (f(t[s_0]),f(t[s_1]),...,f(t[s_n]))
-//
-
-namespace detail {
-
-template <int... I, class F>
-CUTE_HOST_DEVICE constexpr
-void
-for_sequence(seq<I...> const&, F&& f) {
-  (f(Int<I>{}), ...);
-}
-
-}; // end namespace detail
-
-template <int... I, class T, class F>
-CUTE_HOST_DEVICE constexpr
-void
-for_sequence(seq<I...> const& s, T&& t, F&& f) {
-  detail::for_sequence(s, [&](auto&& i){ f(get<remove_cvref_t<decltype(i)>::value>(static_cast<T&&>(t))); });
-}
-
-template <int I, class T, class F>
-CUTE_HOST_DEVICE constexpr
-void
-for_sequence(T&& t, F&& f) {
-  for_sequence(make_seq<I>{}, static_cast<T&&>(t), static_cast<F&&>(f));
-}
-
-//
 // Transform
 // (t, f) => (f(t_0),f(t_1),...,f(t_n))
 //
 
 template <class T, class F>
 CUTE_HOST_DEVICE constexpr
 auto
@@ -547,23 +517,23 @@
 //
 // Select tuple elements with given indices.
 //
 
 template <int... I, class T>
 CUTE_HOST_DEVICE constexpr
 auto
-select(T const & t)
+select(T const& t)
 {
   return cute::make_tuple(get<I>(t)...);
 }
 
-template <class T, typename Indices>
+template <class T, class Indices>
 CUTE_HOST_DEVICE constexpr
 auto
-select(T const & t, Indices const & indices)
+select(T const& t, Indices const& indices)
 {
   if constexpr (is_tuple<Indices>::value) {
     return cute::transform(indices, [&t](auto i) { return select(t, i); });
   } else {
     static_assert(is_static<Indices>::value, "Order must be static");
     return get<Indices::value>(t);
   }
@@ -651,15 +621,15 @@
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 namespace detail {
 
-template<class FlatTuple, class TargetProfile>
+template <class FlatTuple, class TargetProfile>
 CUTE_HOST_DEVICE constexpr
 auto
 unflatten_impl(FlatTuple const& flat_tuple, TargetProfile const& target_profile)
 {
   if constexpr (is_tuple<TargetProfile>::value) {
     return fold(target_profile, cute::make_tuple(cute::make_tuple(), flat_tuple), [](auto const& v, auto const& t) {
       auto [result, remaining_tuple] = v;
@@ -676,15 +646,15 @@
 }  // end namespace detail
 
 // Unflatten a flat tuple into a hierarchical tuple
 // @pre flatten(@a flat_tuple) == @a flat_tuple
 // @pre rank(flatten(@a target_profile)) == rank(@a flat_tuple)
 // @post congruent(@a result, @a target_profile)
 // @post flatten(@a result) == @a flat_tuple
-template<class FlatTuple, class TargetProfile>
+template <class FlatTuple, class TargetProfile>
 CUTE_HOST_DEVICE constexpr
 auto
 unflatten(FlatTuple const& flat_tuple, TargetProfile const& target_profile)
 {
   auto [unflatten_tuple, flat_remainder] = detail::unflatten_impl(flat_tuple, target_profile);
   CUTE_STATIC_ASSERT_V(rank(flat_remainder) == Int<0>{});
   return unflatten_tuple;
@@ -861,14 +831,15 @@
     } else {
       return detail::construct(cute::make_tuple(a), x, seq<0>{}, make_seq<N-1>{}, seq<>{});
     }
   }
 
   CUTE_GCC_UNREACHABLE;
 }
+
 template <class T, class X>
 CUTE_HOST_DEVICE constexpr
 auto
 append(T const& a, X const& x)
 {
   if constexpr (is_tuple<T>::value) {
     return detail::construct(a, x, make_seq<tuple_size<T>::value>{}, seq<0>{}, seq<>{});
@@ -898,14 +869,15 @@
       static_assert(N > 1);
       return detail::construct(cute::make_tuple(a), x, seq<>{}, make_seq<N-1>{}, seq<0>{});
     }
   }
 
   CUTE_GCC_UNREACHABLE;
 }
+
 template <class T, class X>
 CUTE_HOST_DEVICE constexpr
 auto
 prepend(T const& a, X const& x)
 {
   if constexpr (is_tuple<T>::value) {
     return detail::construct(a, x, seq<>{}, seq<0>{}, make_seq<tuple_size<T>::value>{});
@@ -1101,20 +1073,19 @@
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 /// @return A tuple of the elements of @c t in reverse order.
 template <class T>
-CUTE_HOST_DEVICE constexpr auto
-reverse(T const& t) {
+CUTE_HOST_DEVICE constexpr 
+auto
+reverse(T const& t) 
+{
   if constexpr (is_tuple<T>::value) {
-    return detail::apply(t, [] (auto const&... a) {
-        return cute::make_tuple(a...);
-      }, tuple_rseq<T>{});
-  }
-  else {
+    return detail::apply(t, [](auto const&... a){ return cute::make_tuple(a...); }, tuple_rseq<T>{});
+  } else {
     return t;
   }
 }
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/cluster_sm90.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -45,43 +45,43 @@
 namespace cute {
 
 CUTE_DEVICE void cluster_arrive_relaxed()
 {
 #if defined(CUTE_ARCH_CLUSTER_SM90_ENABLED)
   asm volatile("barrier.cluster.arrive.relaxed.aligned;\n" : : );
 #else
-  CUTE_RUNTIME_ASSERT("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
+  CUTE_INVALID_CONTROL_PATH("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
 #endif
 }
 
 CUTE_DEVICE void cluster_arrive()
 {
 #if defined(CUTE_ARCH_CLUSTER_SM90_ENABLED)
   asm volatile("barrier.cluster.arrive.aligned;\n" : : );
 #else
-  CUTE_RUNTIME_ASSERT("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
+  CUTE_INVALID_CONTROL_PATH("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
 #endif
 }
 
 CUTE_DEVICE void cluster_wait()
 {
 #if defined(CUTE_ARCH_CLUSTER_SM90_ENABLED)
   asm volatile("barrier.cluster.wait.aligned;\n" : : );
 #else
-  CUTE_RUNTIME_ASSERT("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
+  CUTE_INVALID_CONTROL_PATH("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
 #endif
 }
 
 CUTE_DEVICE void cluster_sync()
 {
 #if defined(CUTE_ARCH_CLUSTER_SM90_ENABLED)
   cluster_arrive();
   cluster_wait();
 #else
-  CUTE_RUNTIME_ASSERT("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
+  CUTE_INVALID_CONTROL_PATH("CUTE_ARCH_CLUSTER_SM90_ENABLED is not defined");
 #endif
 }
 
 // Returns the dim3 grid size in terms of number of clusters.
 CUTE_DEVICE dim3 cluster_grid_dims()
 {
 #if defined(CUTE_ARCH_CLUSTER_SM90_ENABLED)
@@ -90,15 +90,15 @@
   asm volatile("mov.u32 %0, %%nclusterid.y;\n" : "=r"(y) : );
   asm volatile("mov.u32 %0, %%nclusterid.z;\n" : "=r"(z) : );
   return {x, y, z};
 #elif defined(__CUDA_ARCH__)
   // MSVC requires protecting use of gridDim with __CUDA_ARCH__.
   return gridDim;
 #elif defined(_MSC_VER)
-  CUTE_RUNTIME_ASSERT("cluster_grid_dims() can only be called on device");
+  CUTE_INVALID_CONTROL_PATH("cluster_grid_dims() can only be called on device");
   return {0, 0, 0};
 #else
   return {0, 0, 0};
 #endif
 }
 
 // Returns the dim3 cluster rank in the grid.
@@ -110,15 +110,15 @@
   asm volatile("mov.u32 %0, %%clusterid.y;\n" : "=r"(y) : );
   asm volatile("mov.u32 %0, %%clusterid.z;\n" : "=r"(z) : );
   return {x, y, z};
 #elif defined(__CUDA_ARCH__)
   // MSVC requires protecting use of blockIdx with __CUDA_ARCH__.
   return blockIdx;
 #elif defined(_MSC_VER)
-  CUTE_RUNTIME_ASSERT("cluster_id_in_grid() can only be called on device");
+  CUTE_INVALID_CONTROL_PATH("cluster_id_in_grid() can only be called on device");
   return {0, 0, 0};
 #else
   return {0, 0, 0};
 #endif
 }
 
 // Returns the relative dim3 block rank local to the cluster.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -29,15 +29,15 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/arch/util.hpp>
-#include <cute/numeric/int.hpp>
+#include <cute/numeric/numeric_types.hpp>
 
 namespace cute
 {
 
 //
 // Direct Copy for any type
 //
@@ -85,8 +85,21 @@
 //
 
 using AutoVectorizingCopy = AutoVectorizingCopyWithAssumedAlignment<8>;
 
 // Alias
 using DefaultCopy = AutoVectorizingCopy;
 
+
+//
+// Global memory prefetch into L2
+//
+
+CUTE_HOST_DEVICE static void
+prefetch(void const* gmem_ptr)
+{
+#if defined(__CUDA_ARCH__)
+  asm volatile("prefetch.global.L2 [%0];\n" : : "l"(gmem_ptr) : "memory");
+#endif
+}
+
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm75.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm75.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -74,15 +74,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x1.m8n8.shared.b16 {%0}, [%1];\n"
         : "=r"(dst)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 struct SM75_U32x2_LDSM_N
 {
   using SRegisters = uint128_t[1];
@@ -94,15 +94,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x2.m8n8.shared.b16 {%0, %1}, [%2];\n"
         : "=r"(dst0), "=r"(dst1)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 struct SM75_U32x4_LDSM_N
 {
   using SRegisters = uint128_t[1];
@@ -114,15 +114,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%0, %1, %2, %3}, [%4];\n"
         : "=r"(dst0), "=r"(dst1), "=r"(dst2), "=r"(dst3)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 struct SM75_U16x2_LDSM_T
 {
   using SRegisters = uint128_t[1];
@@ -134,15 +134,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x1.trans.m8n8.shared.b16 {%0}, [%1];\n"
         : "=r"(dst)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 struct SM75_U16x4_LDSM_T
 {
   using SRegisters = uint128_t[1];
@@ -154,15 +154,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x2.trans.m8n8.shared.b16 {%0, %1}, [%2];\n"
         : "=r"(dst0), "=r"(dst1)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 struct SM75_U16x8_LDSM_T
 {
   using SRegisters = uint128_t[1];
@@ -174,15 +174,15 @@
   {
 #if defined(CUTE_ARCH_LDSM_SM75_ACTIVATED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_src);
     asm volatile ("ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%0, %1, %2, %3}, [%4];\n"
         : "=r"(dst0), "=r"(dst1), "=r"(dst2), "=r"(dst3)
         :  "r"(smem_int_ptr));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use ldmatrix without CUTE_ARCH_LDSM_SM75_ACTIVATED.");
 #endif
   }
 };
 
 //
 // Legacy LDSM interfaces that aren't very useful
 //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm80.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm80.hpp`

 * *Files 10% similar despite different names*

```diff
@@ -60,15 +60,15 @@
     TS const* gmem_ptr    = &gmem_src;
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile("cp.async.ca.shared.global.L2::128B [%0], [%1], %2;\n"
         :: "r"(smem_int_ptr),
            "l"(gmem_ptr),
            "n"(sizeof(TS)));
 #else
-    CUTE_RUNTIME_ASSERT("Support for cp.async instructions has not been enabled");
+    CUTE_INVALID_CONTROL_PATH("Support for cp.async instructions has not been enabled");
 #endif
   }
 };
 
 /// Copy via cp.async with caching at global level
 template <class TS, class TD = TS>
 struct SM80_CP_ASYNC_CACHEGLOBAL
@@ -87,15 +87,15 @@
     TS const* gmem_ptr    = &gmem_src;
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile("cp.async.cg.shared.global.L2::128B [%0], [%1], %2;\n"
         :: "r"(smem_int_ptr),
            "l"(gmem_ptr),
            "n"(sizeof(TS)));
 #else
-    CUTE_RUNTIME_ASSERT("Support for cp.async instructions has not been enabled");
+    CUTE_INVALID_CONTROL_PATH("Support for cp.async instructions has not been enabled");
 #endif
   }
 };
 
 /// Copy via cp.async with caching at all levels
 template <class TS, class TD = TS>
 struct SM80_CP_ASYNC_CACHEALWAYS_ZFILL
@@ -117,15 +117,15 @@
     int src_size = pred ? sizeof(TS) : 0;
     asm volatile("cp.async.ca.shared.global.L2::128B [%0], [%1], %2, %3;\n"
         :: "r"(smem_int_ptr),
            "l"(gmem_ptr),
            "n"(sizeof(TS)),
            "r"(src_size));
 #else
-    CUTE_RUNTIME_ASSERT("Support for cp.async instructions has not been enabled");
+    CUTE_INVALID_CONTROL_PATH("Support for cp.async instructions has not been enabled");
 #endif
   }
 };
 
 /// Copy via cp.async with caching at global level
 template <class TS, class TD = TS>
 struct SM80_CP_ASYNC_CACHEGLOBAL_ZFILL
@@ -147,15 +147,15 @@
     int src_size = pred ? sizeof(TS) : 0;
     asm volatile("cp.async.cg.shared.global.L2::128B [%0], [%1], %2, %3;\n"
         :: "r"(smem_int_ptr),
            "l"(gmem_ptr),
            "n"(sizeof(TS)),
            "r"(src_size));
 #else
-    CUTE_RUNTIME_ASSERT("Support for cp.async instructions has not been enabled");
+    CUTE_INVALID_CONTROL_PATH("Support for cp.async instructions has not been enabled");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Establishes an ordering w.r.t previously issued cp.async instructions. Does not block.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm90.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm90.hpp`

 * *Files 7% similar despite different names*

```diff
@@ -59,15 +59,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x1.m8n8.shared.b16 [%0], {%1};\n"
         :: "r"(smem_int_ptr),
            "r"(src));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 struct SM90_U32x2_STSM_N
 {
   using SRegisters = uint32_t[2];
@@ -79,15 +79,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x2.m8n8.shared.b16 [%0], {%1, %2};\n"
         :: "r"(smem_int_ptr),
            "r"(src0), "r"(src1));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 struct SM90_U32x4_STSM_N
 {
   using SRegisters = uint32_t[4];
@@ -99,15 +99,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x4.m8n8.shared.b16 [%0], {%1, %2, %3, %4};\n"
         :: "r"(smem_int_ptr),
           "r"(src0), "r"(src1), "r"(src2), "r"(src3));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 struct SM90_U16x2_STSM_T
 {
   using SRegisters = uint32_t[1];
@@ -119,15 +119,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x1.trans.m8n8.shared.b16 [%0], {%1};\n"
         :: "r"(smem_int_ptr),
            "r"(src));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 struct SM90_U16x4_STSM_T
 {
   using SRegisters = uint32_t[2];
@@ -139,15 +139,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x2.trans.m8n8.shared.b16 [%0], {%1, %2};\n"
         :: "r"(smem_int_ptr),
            "r"(src0), "r"(src1));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 struct SM90_U16x8_STSM_T
 {
   using SRegisters = uint32_t[4];
@@ -159,15 +159,15 @@
   {
 #if defined(CUTE_ARCH_STSM_SM90_ENABLED)
     uint32_t smem_int_ptr = cast_smem_ptr_to_uint(&smem_dst);
     asm volatile ("stmatrix.sync.aligned.x4.trans.m8n8.shared.b16 [%0], {%1, %2, %3, %4};\n"
         :: "r"(smem_int_ptr),
           "r"(src0), "r"(src1), "r"(src2), "r"(src3));
 #else
-    CUTE_RUNTIME_ASSERT("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
+    CUTE_INVALID_CONTROL_PATH("Trying to use stmatrix without CUTE_ARCH_STSM_SM90_ENABLED.");
 #endif
   }
 };
 
 //
 // Legacy STSM interfaces that aren't very useful
 //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -39,16 +39,15 @@
 
 #include <cute/arch/copy.hpp>
 #include <cute/arch/copy_sm90.hpp>
 
 #include <cute/container/alignment.hpp>
 #include <cute/container/bit_field.hpp>
 #include <cute/container/array.hpp>
-#include <cute/numeric/int.hpp>   // to_Format<[u]intX>
-#include <cute/numeric/half.hpp>  // to_Format<half_t>
+#include <cute/numeric/numeric_types.hpp>
 
 namespace cute
 {
 
 //////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Barriers are 64-bit of user-managed information used in broadly two types syncronization patterns
 /// 1) arrive/wait on threads (usage: cp.async and warp-specialized kernels)
@@ -173,16 +172,18 @@
 
 #endif // (__CUDACC_VER_MAJOR__ >= 12)
 
 } // end namespace TMA
 
 #if (__CUDACC_VER_MAJOR__ >= 12) && !defined(__CUDACC_RTC__)
   using TmaDescriptor = CUtensorMap;
+  using Im2ColTmaDescriptor = CUtensorMap;
 #else
   using TmaDescriptor = struct alignas(64) { char bytes[128]; };
+  using Im2ColTmaDescriptor = struct alignas(64) { char bytes[128]; };
 #endif
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Initiates a TensorMap Prefetch
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 CUTE_HOST_DEVICE
 void
@@ -193,57 +194,57 @@
   // Prefetch TMA Descriptor using generic addressing (i.e. no specific state space: const or param)
   asm volatile (
     "prefetch.tensormap [%0];"
     :
     : "l"(gmem_int_desc)
     : "memory");
 #else
-  CUTE_RUNTIME_ASSERT("Trying to use TMA Descriptor Prefetch without CUTE_ARCH_TMA_SM90_ENABLED.");
+  CUTE_INVALID_CONTROL_PATH("Trying to use TMA Descriptor Prefetch without CUTE_ARCH_TMA_SM90_ENABLED.");
 #endif
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Perform a TensorMap modification (by each field)
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Replace tensor pointer directly in GMEM
 CUTE_HOST_DEVICE
 void
-tma_descriptor_replace_addr_in_global_mem(TmaDescriptor const* desc_ptr, 
+tma_descriptor_replace_addr_in_global_mem(TmaDescriptor const* desc_ptr,
                                           void const* const new_tensor_ptr)
 {
 #if defined(CUTE_ARCH_DEVICE_MODIFIABLE_TMA_SM90_ENABLED)
   uint64_t gmem_int_desc = reinterpret_cast<uint64_t>(desc_ptr);
   uint64_t const new_desc_addr = reinterpret_cast<uint64_t>(new_tensor_ptr);
   asm volatile (
     "tensormap.replace.tile.global_address.global.b1024.b64 [%0], %1;"
     :: "l"(gmem_int_desc), "l"(new_desc_addr));
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 // Replace tensor pointer by bringing the tensormap from GMEM into the shared memory
 CUTE_HOST_DEVICE
 void
-tma_descriptor_replace_addr_in_shared_mem(TmaDescriptor& smem_desc, 
+tma_descriptor_replace_addr_in_shared_mem(TmaDescriptor& smem_desc,
                                           void const* const new_tensor_ptr)
 {
 #if defined(CUTE_ARCH_DEVICE_MODIFIABLE_TMA_SM90_ENABLED)
   uint32_t smem_int_desc = cast_smem_ptr_to_uint(&smem_desc);
   uint64_t const new_desc_addr = reinterpret_cast<uint64_t>(new_tensor_ptr);
   uint64_t const smem_int64_desc = 0;
   asm volatile (
     "cvt.u64.u32 %0, %1;"
     :: "l"(smem_int64_desc), "r"(smem_int_desc));
   asm volatile (
     "tensormap.replace.tile.global_address.shared::cta.b1024.b64 [%0], %1;"
     :: "l"(smem_int64_desc), "l"(new_desc_addr));
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 // Replace tensor dims and strides for GEMMs by bringing the tensormap from GMEM into the shared memory
 CUTE_HOST_DEVICE
 void
 tma_descriptor_replace_dims_strides_in_shared_mem(TmaDescriptor                 & smem_desc,
@@ -269,15 +270,15 @@
     asm volatile (
       "tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [%0], 0, %1;"
       :: "l"(smem_int64_desc), "l"(prob_stride[1] >> 4));
     asm volatile (
       "tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [%0], 1, %1;"
       :: "l"(smem_int64_desc), "l"(prob_stride[2] >> 4));
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Perform a fused copy and fence operation (needed when modifying tensormap in shared memory)
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -288,30 +289,30 @@
 #if defined(CUTE_ARCH_DEVICE_MODIFIABLE_TMA_SM90_ENABLED)
   uint64_t gmem_int_desc = reinterpret_cast<uint64_t>(gmem_desc_ptr);
   uint32_t smem_int_desc = cast_smem_ptr_to_uint(&smem_desc);
   asm volatile (
     "tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [%0], [%1], 128;"
     :: "l"(gmem_int_desc), "r"(smem_int_desc));
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Perform a release fence operation (needed when modifying tensormap directly in GMEM)
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 CUTE_HOST_DEVICE
 void
 tma_descriptor_fence_release()
 {
 #if defined(CUTE_ARCH_DEVICE_MODIFIABLE_TMA_SM90_ENABLED)
   asm volatile ("fence.proxy.tensormap::generic.release.gpu;");
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 /// Perform a acquire fence operation
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -328,14 +329,14 @@
     : "memory");
   asm volatile (
     "cvta.global.u64 %0, %0;"
     :
     : "l"(gmem_int_desc), "l"(gmem_int_desc)
     : "memory");
 #else
-  CUTE_RUNTIME_ASSERT("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
+  CUTE_INVALID_CONTROL_PATH("Using TMA Descriptor modification without CUTE_ARCH_TMA_SM90_ENABLED and CUDA 12.3");
 #endif
 }
 
 ///////////////////////////////////////////////////////////////////////////////
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm61.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm61.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -54,15 +54,15 @@
   fma(int32_t& d, uint32_t const& a, uint32_t const& b, int32_t const& c)
   {
 #if defined(CUTE_ARCH_MMA_SM61_ENABLED)
     asm volatile("dp4a.s32.s32 %0, %1, %2, %3;"
                  : "=r"(d)
                  : "r"(a), "r"(b), "r"(c));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM61_DP4A without CUTE_ARCH_MMA_SM61_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM61_DP4A without CUTE_ARCH_MMA_SM61_ENABLED");
 #endif
   }
 };
 
 struct SM61_DP2A
 {
   using DRegisters = int32_t[1];
@@ -75,13 +75,13 @@
   fma(int32_t& d, uint32_t const& a, uint32_t const& b, int32_t const& c)
   {
 #if defined(CUTE_ARCH_MMA_SM61_ENABLED)
     asm volatile("dp2a.s32.s32 %0, %1, %2, %3;"
                  : "=r"(d)
                  : "r"(a), "r"(b), "r"(c));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM61_DP2A without CUTE_ARCH_MMA_SM61_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM61_DP2A without CUTE_ARCH_MMA_SM61_ENABLED");
 #endif
   }
 };
 
 } // namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm70.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm70.hpp`

 * *Files 12% similar despite different names*

```diff
@@ -70,15 +70,15 @@
                  "{%6, %7},"
                  "{%8, %9, %10, %11};\n"
         : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F16F16F16F16_TN without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F16F16F16F16_TN without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F16F16F16F16_NT
@@ -102,15 +102,15 @@
                  "{%6, %7},"
                  "{%8, %9, %10, %11};\n"
         : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F16F16F16F16_NT without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F16F16F16F16_NT without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F16F16F16F16_NN
@@ -134,15 +134,15 @@
                  "{%6, %7},"
                  "{%8, %9, %10, %11};\n"
         : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F16F16F16F16_NN without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F16F16F16F16_NN without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F16F16F16F16_TT
@@ -166,15 +166,15 @@
                  "{%6, %7},"
                  "{%8, %9, %10, %11};\n"
         : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F16F16F16F16_TT without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F16F16F16F16_TT without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 //
@@ -206,15 +206,15 @@
         : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3),
           "=f"(d4), "=f"(d5), "=f"(d6), "=f"(d7)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3),
            "f"(c4),  "f"(c5),  "f"(c6),  "f"(c7));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F32F16F16F32_TN without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F32F16F16F32_TN without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F32F16F16F32_NT
@@ -242,15 +242,15 @@
         : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3),
           "=f"(d4), "=f"(d5), "=f"(d6), "=f"(d7)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3),
            "f"(c4),  "f"(c5),  "f"(c6),  "f"(c7));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F32F16F16F32_NT without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F32F16F16F32_NT without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F32F16F16F32_NN
@@ -278,15 +278,15 @@
         : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3),
           "=f"(d4), "=f"(d5), "=f"(d6), "=f"(d7)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3),
            "f"(c4),  "f"(c5),  "f"(c6),  "f"(c7));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F32F16F16F32_NN without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F32F16F16F32_NN without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct SM70_8x8x4_F32F16F16F32_TT
@@ -314,15 +314,15 @@
         : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3),
           "=f"(d4), "=f"(d5), "=f"(d6), "=f"(d7)
         :  "r"(a0),  "r"(a1),
            "r"(b0),  "r"(b1),
            "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3),
            "f"(c4),  "f"(c5),  "f"(c6),  "f"(c7));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM70_8x8x4_F32F16F16F32_TT without CUTE_ARCH_MMA_SM70_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM70_8x8x4_F32F16F16F32_TT without CUTE_ARCH_MMA_SM70_ENABLED");
 #endif
   }
 
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm75.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm75.hpp`

 * *Files 7% similar despite different names*

```diff
@@ -70,15 +70,15 @@
                  "{%6},"
                  "{%7, %8, %9, %10};\n"
         : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
         :  "r"(a0),  "r"(a1),
            "r"(b0),
            "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM75_16x8x8_F32F16F16F32_TN without CUTE_ARCH_MMA_SM75_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM75_16x8x8_F32F16F16F32_TN without CUTE_ARCH_MMA_SM75_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 //
@@ -106,15 +106,15 @@
                  "{%3},"
                  "{%4, %5};\n"
         : "=r"(d0), "=r"(d1)
         :  "r"(a0),
            "r"(b0),
            "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM75_8x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM75_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM75_8x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM75_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm80.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm80.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -29,14 +29,15 @@
  *
  **************************************************************************************************/
 
 #pragma once
 
 #include <cute/config.hpp>
 #include <cute/arch/mma.hpp>
+#include <cute/numeric/complex.hpp>
 
 // Config
 #if (defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800))
 #  define CUTE_ARCH_MMA_SM80_ENABLED
 
 #if (__CUDA_ARCH__ <= 900)
 #define CUTE_ARCH_MMA_B1_AND_SM80_ENABLED
@@ -76,15 +77,15 @@
       "{%4},"
       "{%5, %6};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x8_F16F16F16F16_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x8_F16F16F16F16_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -109,15 +110,15 @@
       "{%6,  %7},"
       "{%8,  %9};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_F16F16F16F16_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_F16F16F16F16_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x8 TN
@@ -142,15 +143,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x8_F32F16F16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x8_F32F16F16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -175,15 +176,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_F32F16F16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_F32F16F16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x8 TN
@@ -208,15 +209,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x8_F32BF16BF16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x8_F32BF16BF16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -241,15 +242,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_F32BF16BF16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_F32BF16BF16F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x4 TN
@@ -274,15 +275,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x4_F32TF32TF32F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x4_F32TF32TF32F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x8 TN
@@ -307,15 +308,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x8_F32TF32TF32F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x8_F32TF32TF32F32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x4 TN
@@ -340,15 +341,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=d"(d0), "=d"(d1)
       :  "d"(a0),
          "d"(b0),
          "d"(c0),  "d"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x4_F64F64F64F64_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x4_F64F64F64F64_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 // MMA 8x8x4 TN with Planar Complex multiplication
 struct SM80_8x8x4_C64C64C64C64_TN
 {
@@ -381,22 +382,22 @@
       id0, id1,
       a0.imag(),
       b0.real(),
       c0.imag(), c1.imag());
 
     // d.real() = -a.imag() * b.imag() + d.real();
     SM80_8x8x4_F64F64F64F64_TN::fma(
-      rd0, rd1, 
+      rd0, rd1,
       -a0.imag(),
       b0.imag(),
       d0.real(), d1.real());
 
     // d.imag() =  a.real() * b.imag() + d.imag();
     SM80_8x8x4_F64F64F64F64_TN::fma(
-      id0, id1, 
+      id0, id1,
       a0.real(),
       b0.imag(),
       d0.imag(), d1.imag());
   }
 };
 
 // MMA 8x8x4 TN with Gaussian Complex multiplication:
@@ -408,23 +409,23 @@
 //  then
 //    re = t0 - t1
 //    im = t2 - t0 - t1
 struct SM80_8x8x4_GC64C64C64GC64_TN
 {
   struct GaussComplex {
     double t0, t1, t2;
-    
+
     CUTE_HOST_DEVICE //constexpr
     operator complex<double>() const { return complex<double>(t0 - t1, t2 - t0 - t1); }
-    
+
     CUTE_HOST_DEVICE friend //constexpr
     complex<double> operator*(GaussComplex const& a, complex<double> const& b) { return static_cast<complex<double>>(a) * b; }
     CUTE_HOST_DEVICE friend //constexpr
     complex<double> operator*(complex<double> const& a, GaussComplex const& b) { return b * a; }
-    
+
     CUTE_HOST_DEVICE friend //constexpr
     complex<double> operator+(GaussComplex const& a, complex<double> const& b) { return static_cast<complex<double>>(a) + b; }
     CUTE_HOST_DEVICE friend //constexpr
     complex<double> operator+(complex<double> const& a, GaussComplex const& b) { return b + a; }
   };
 
   using DRegisters = GaussComplex[2];
@@ -477,15 +478,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -510,15 +511,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -543,15 +544,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -576,15 +577,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -609,15 +610,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -642,15 +643,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -675,15 +676,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -708,15 +709,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -741,15 +742,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -774,15 +775,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -807,15 +808,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -840,15 +841,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -873,15 +874,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -906,15 +907,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -939,15 +940,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -972,15 +973,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1005,15 +1006,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U8S8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1038,15 +1039,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U8S8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -1071,15 +1072,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x16 TN
@@ -1104,15 +1105,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x16_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x16_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -1137,15 +1138,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -1170,15 +1171,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x16_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x16_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1203,15 +1204,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U8U8S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1236,15 +1237,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U8U8S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1269,15 +1270,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1302,15 +1303,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1335,15 +1336,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1368,15 +1369,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1401,15 +1402,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32S4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1434,15 +1435,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32S4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1467,15 +1468,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1500,15 +1501,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1533,15 +1534,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1566,15 +1567,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1599,15 +1600,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32S4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1632,15 +1633,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32S4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1665,15 +1666,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1698,15 +1699,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1731,15 +1732,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1764,15 +1765,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1797,15 +1798,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32U4S4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1830,15 +1831,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32U4S4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1863,15 +1864,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 8x8x32 TN
@@ -1896,15 +1897,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x32_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x32_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1929,15 +1930,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x32 TN
@@ -1962,15 +1963,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x32_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x32_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -1995,15 +1996,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32U4U4S32_TN without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x64 TN
@@ -2028,15 +2029,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x64_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x64_S32U4U4S32_TN_SATURATE without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -2063,15 +2064,15 @@
       "{%3},"
       "{%4, %5};\n"
       : "=r"(d0), "=r"(d1)
       :  "r"(a0),
          "r"(b0),
          "r"(c0),  "r"(c1));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_8x8x128_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_8x8x128_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x128 TN
@@ -2096,15 +2097,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),
          "r"(b0),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x128_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x128_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x256 TN
@@ -2129,15 +2130,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=r"(d0), "=r"(d1), "=r"(d2), "=r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "r"(b0),  "r"(b1),
          "r"(c0),  "r"(c1),  "r"(c2),  "r"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM80_16x8x256_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM80_16x8x256_S32U1U1S32_TN_XORPOPC without CUTE_ARCH_MMA_SM80_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -69,15 +69,15 @@
       "{%6},"
       "{%7,  %8,  %9,  %10};\n"
       : "=d"(d0), "=d"(d1), "=d"(d2), "=d"(d3)
       :  "d"(a0),  "d"(a1),
          "d"(b0),
          "d"(c0),  "d"(c1),  "d"(c2),  "d"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_16x8x4_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_16x8x4_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x8 TN
@@ -102,15 +102,15 @@
       "{%8,  %9},"
       "{%10, %11, %12, %13};\n"
       : "=d"(d0), "=d"(d1), "=d"(d2), "=d"(d3)
       :  "d"(a0),  "d"(a1),  "d"(a2),  "d"(a3),
          "d"(b0),  "d"(b1),
          "d"(c0),  "d"(c1),  "d"(c2),  "d"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_16x8x8_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_16x8x8_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x16 TN
@@ -137,15 +137,15 @@
       "{%16, %17, %18, %19};\n"
       : "=d"(d0), "=d"(d1), "=d"(d2), "=d"(d3)
       :  "d"(a0),  "d"(a1),  "d"(a2),  "d"(a3),
          "d"(a4),  "d"(a5),  "d"(a6),  "d"(a7),
          "d"(b0),  "d"(b1),  "d"(b2),  "d"(b3),
          "d"(c0),  "d"(c1),  "d"(c2),  "d"(c3));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_16x8x16_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_16x8x16_F64F64F64F64_TN without CUTE_ARCH_MMA_SM90_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // MMA 16x8x4 TN
@@ -360,45 +360,193 @@
   static_assert(is_static<TileShape_MNK>::value, "TileShape_MNK must be static.");
   static_assert(rank(TileShape_MNK{}) == 3, "TileShape_MNK must be rank 3.");
   static_assert(size<0>(TileShape_MNK{}) % 64 == 0, "Tile_M must be a multiple of 64.");
   auto Tile_N = size<1>(TileShape_MNK{});
 
   // FP16 accumulator
   if constexpr (is_same_v<ElementC, half_t>) {
-    static_assert(is_same_v<ElementA, half_t>, "Element types for AB must be half if ElementC is half.");
-    static_assert(is_same_v<ElementB, half_t>, "Element types for AB must be half if ElementC is half.");
-    static_assert(size<2>(TileShape_MNK{}) % 16 == 0, "Tile_K must be a multiple of 16.");
-
-    // Dispatch against the Tile N mode size
-    if constexpr (Tile_N % 256 == 0) {
-      return SM90_64x256x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
-    }
-    else if constexpr (Tile_N % 192 == 0) {
-      return SM90_64x192x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
-    }
-    else if constexpr (Tile_N % 128 == 0) {
-      return SM90_64x128x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
-    }
-    else if constexpr (Tile_N % 96 == 0) {
-      return SM90_64x96x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+    if constexpr (is_same_v<ElementA, half_t> && is_same_v<ElementB, half_t>) {
+      static_assert(size<2>(TileShape_MNK{}) % 16 == 0, "Tile_K must be a multiple of 16.");
+
+      // Dispatch against the Tile N mode size
+      if constexpr (Tile_N % 256 == 0) {
+        return SM90_64x256x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 192 == 0) {
+        return SM90_64x192x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 128 == 0) {
+        return SM90_64x128x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 96 == 0) {
+        return SM90_64x96x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 64 == 0) {
+        return SM90_64x64x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 32 == 0) {
+        return SM90_64x32x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 16 == 0) {
+        return SM90_64x16x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else if constexpr (Tile_N % 8 == 0) {
+        return SM90_64x8x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+      }
+      else {
+          static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      }
     }
-    else if constexpr (Tile_N % 64 == 0) {
-      return SM90_64x64x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+
+    // FP8
+    // Input A: float_e4m3_t ; Input B: float_e4m3_t
+    else if constexpr (is_same_v<ElementA, float_e4m3_t> && is_same_v<ElementB, float_e4m3_t>) {
+      static_assert(MajorA == GMMA::Major::K, "MajorA must be GMMA::Major::K for this config.");
+      static_assert(MajorB == GMMA::Major::K, "MajorB must be GMMA::Major::K for this config.");
+      static_assert(size<2>(TileShape_MNK{}) % 32 == 0, "Tile_K must be a multiple of 32.");
+
+      if constexpr (Tile_N % 256 == 0) {
+        return SM90_64x256x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 192 == 0) {
+        return SM90_64x192x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 128 == 0) {
+        return SM90_64x128x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 96 == 0) {
+        return SM90_64x96x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 64 == 0) {
+        return SM90_64x64x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 32 == 0) {
+        return SM90_64x32x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 16 == 0) {
+        return SM90_64x16x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 8 == 0) {
+        return SM90_64x8x32_F16E4M3E4M3_SS_TN<Args...>{};
+      }
+      else {
+        static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      }
     }
-    else if constexpr (Tile_N % 32 == 0) {
-      return SM90_64x32x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+
+    // FP8
+    // Input A: float_e4m3_t ; Input B: float_e5m2_t
+    else if constexpr (is_same_v<ElementA, float_e4m3_t> && is_same_v<ElementB, float_e5m2_t>) {
+      static_assert(MajorA == GMMA::Major::K, "MajorA must be GMMA::Major::K for this config.");
+      static_assert(MajorB == GMMA::Major::K, "MajorB must be GMMA::Major::K for this config.");
+      static_assert(size<2>(TileShape_MNK{}) % 32 == 0, "Tile_K must be a multiple of 32.");
+
+      if constexpr (Tile_N % 256 == 0) {
+        return SM90_64x256x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 192 == 0) {
+        return SM90_64x192x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 128 == 0) {
+        return SM90_64x128x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 96 == 0) {
+        return SM90_64x96x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 64 == 0) {
+        return SM90_64x64x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 32 == 0) {
+        return SM90_64x32x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 16 == 0) {
+        return SM90_64x16x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 8 == 0) {
+        return SM90_64x8x32_F16E4M3E5M2_SS_TN<Args...>{};
+      }
+      else {
+        static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      }
     }
-    else if constexpr (Tile_N % 16 == 0) {
-      return SM90_64x16x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+
+    // FP8
+    // Input A: float_e5m2_t ; Input B: float_e5m2_t
+    else if constexpr (is_same_v<ElementA, float_e5m2_t> && is_same_v<ElementB, float_e5m2_t>) {
+      static_assert(MajorA == GMMA::Major::K, "MajorA must be GMMA::Major::K for this config.");
+      static_assert(MajorB == GMMA::Major::K, "MajorB must be GMMA::Major::K for this config.");
+      static_assert(size<2>(TileShape_MNK{}) % 32 == 0, "Tile_K must be a multiple of 32.");
+
+      if constexpr (Tile_N % 256 == 0) {
+        return SM90_64x256x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 192 == 0) {
+        return SM90_64x192x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 128 == 0) {
+        return SM90_64x128x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 96 == 0) {
+        return SM90_64x96x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 64 == 0) {
+        return SM90_64x64x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 32 == 0) {
+        return SM90_64x32x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 16 == 0) {
+        return SM90_64x16x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 8 == 0) {
+        return SM90_64x8x32_F16E5M2E5M2_SS_TN<Args...>{};
+      }
+      else {
+        static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      }
     }
-    else if constexpr (Tile_N % 8 == 0) {
-      return SM90_64x8x16_F16F16F16_SS<MajorA, MajorB, Args...>{};
+
+    // FP8
+    // Input A: float_e5m2_t ; Input B: float_e4m3_t
+    else if constexpr (is_same_v<ElementA, float_e5m2_t> && is_same_v<ElementB, float_e4m3_t>) {
+      static_assert(MajorA == GMMA::Major::K, "MajorA must be GMMA::Major::K for this config.");
+      static_assert(MajorB == GMMA::Major::K, "MajorB must be GMMA::Major::K for this config.");
+      static_assert(size<2>(TileShape_MNK{}) % 32 == 0, "Tile_K must be a multiple of 32.");
+
+      if constexpr (Tile_N % 256 == 0) {
+        return SM90_64x256x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 192 == 0) {
+        return SM90_64x192x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 128 == 0) {
+        return SM90_64x128x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 96 == 0) {
+        return SM90_64x96x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 64 == 0) {
+        return SM90_64x64x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 32 == 0) {
+        return SM90_64x32x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 16 == 0) {
+        return SM90_64x16x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else if constexpr (Tile_N % 8 == 0) {
+        return SM90_64x8x32_F16E5M2E4M3_SS_TN<Args...>{};
+      }
+      else {
+        static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      }
     }
+
     else {
-        static_assert(Tile_N % 8 == 0, "Tile_N must be a multiple of 8.");
+      static_assert(sizeof(ElementA) == 0, "No eligible GMMA operator for request configuration.");
     }
   }
 
   // FP32 accumulator
   else if constexpr (is_same_v<ElementC, float>) {
 
     // FP16 inputs
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -45,40 +45,40 @@
 CUTE_HOST_DEVICE
 void
 warpgroup_arrive()
 {
 #if defined(CUTE_ARCH_MMA_SM90A_ENABLED)
   asm volatile ("wgmma.fence.sync.aligned;\n" ::: "memory");
 #else
-  CUTE_RUNTIME_ASSERT("Attempting to use wgmma.fence without CUTE_ARCH_MMA_SM90A_ENABLED");
+  CUTE_INVALID_CONTROL_PATH("Attempting to use wgmma.fence without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
 }
 
 template <int N>
 CUTE_HOST_DEVICE
 void
 warpgroup_wait()
 {
   static_assert(N >= 0 && N <= 7, "WGMMA wait: N must be in range [0, 7]");
 #if defined(CUTE_ARCH_MMA_SM90A_ENABLED)
   asm volatile("wgmma.wait_group.sync.aligned %0;\n" :: "n"(N) : "memory");
 #else
-  CUTE_RUNTIME_ASSERT("Attempting to use wgmma.wait_group<N> without CUTE_ARCH_MMA_SM90A_ENABLED");
+  CUTE_INVALID_CONTROL_PATH("Attempting to use wgmma.wait_group<N> without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
 }
 
 // Marks the commit point for one or more sized batch of warpgroup MMAs.
 CUTE_HOST_DEVICE
 void
 warpgroup_commit_batch()
 {
 #if defined(CUTE_ARCH_MMA_SM90A_ENABLED)
   asm volatile("wgmma.commit_group.sync.aligned;\n" ::: "memory");
 #else
-  CUTE_RUNTIME_ASSERT("Attempting to use wgmma.commit_group without CUTE_ARCH_MMA_SM90A_ENABLED");
+  CUTE_INVALID_CONTROL_PATH("Attempting to use wgmma.commit_group without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
 }
 
 CUTE_HOST_DEVICE
 void
 warpgroup_fence_operand(uint32_t& reg) {
   // MSVC emits a build error for 'asm volatile'
@@ -152,15 +152,15 @@
       " p,  %5, %6, %7, %8;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x16 F16+=F16*F16
@@ -198,15 +198,15 @@
       " p,   %8,  %9,  %10;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F16+=F16*F16
@@ -241,15 +241,15 @@
       " p,   %7,  %8,  %9,  %10;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F16+=F16*F16
@@ -287,15 +287,15 @@
       " p,   %10, %11, %12;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F16+=F16*F16
@@ -332,15 +332,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F16+=F16*F16
@@ -380,15 +380,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F16+=F16*F16
@@ -430,15 +430,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F16+=F16*F16
@@ -483,15 +483,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F16+=F16*F16
@@ -538,15 +538,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F16+=F16*F16
@@ -596,15 +596,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F16+=F16*F16
@@ -656,15 +656,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F16+=F16*F16
@@ -719,15 +719,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F16+=F16*F16
@@ -789,15 +789,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F16+=F16*F16
@@ -862,15 +862,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F16+=F16*F16
@@ -942,15 +942,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F16F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F16+=F16*F16
@@ -1025,15 +1025,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F16F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x16 F32+=F16*F16
@@ -1068,15 +1068,15 @@
       " p,   %7,  %8,  %9,  %10;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x16 F32+=F16*F16
@@ -1114,15 +1114,15 @@
       " p,   %10, %11, %12;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F32+=F16*F16
@@ -1159,15 +1159,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F32+=F16*F16
@@ -1207,15 +1207,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F32+=F16*F16
@@ -1257,15 +1257,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F32+=F16*F16
@@ -1310,15 +1310,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F32+=F16*F16
@@ -1370,15 +1370,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F32+=F16*F16
@@ -1433,15 +1433,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F32+=F16*F16
@@ -1503,15 +1503,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F32+=F16*F16
@@ -1576,15 +1576,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F32+=F16*F16
@@ -1656,15 +1656,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F32+=F16*F16
@@ -1739,15 +1739,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F32+=F16*F16
@@ -1839,15 +1839,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F32+=F16*F16
@@ -1942,15 +1942,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F32+=F16*F16
@@ -2062,15 +2062,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F32F16F16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F32+=F16*F16
@@ -2185,15 +2185,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F32F16F16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x16 F32+=BF16*BF16
@@ -2228,15 +2228,15 @@
       " p,   %7,  %8,  %9,  %10;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x16 F32+=BF16*BF16
@@ -2274,15 +2274,15 @@
       " p,   %10, %11, %12;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F32+=BF16*BF16
@@ -2319,15 +2319,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x16 F32+=BF16*BF16
@@ -2367,15 +2367,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F32+=BF16*BF16
@@ -2417,15 +2417,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x16 F32+=BF16*BF16
@@ -2470,15 +2470,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F32+=BF16*BF16
@@ -2530,15 +2530,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x16 F32+=BF16*BF16
@@ -2593,15 +2593,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F32+=BF16*BF16
@@ -2663,15 +2663,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x16 F32+=BF16*BF16
@@ -2736,15 +2736,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F32+=BF16*BF16
@@ -2816,15 +2816,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x16 F32+=BF16*BF16
@@ -2899,15 +2899,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F32+=BF16*BF16
@@ -2999,15 +2999,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x16 F32+=BF16*BF16
@@ -3102,15 +3102,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F32+=BF16*BF16
@@ -3222,15 +3222,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspA)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F32BF16BF16_SS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x16 F32+=BF16*BF16
@@ -3345,15 +3345,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)), "n"(int32_t(tnspB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x16_F32BF16BF16_RS without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x8 TN F32+=TF32*TF32
@@ -3386,15 +3386,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x8 TN F32+=TF32*TF32
@@ -3427,15 +3427,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x8 TN F32+=TF32*TF32
@@ -3470,15 +3470,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x8 TN F32+=TF32*TF32
@@ -3513,15 +3513,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x8 TN F32+=TF32*TF32
@@ -3561,15 +3561,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x8 TN F32+=TF32*TF32
@@ -3609,15 +3609,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x8 TN F32+=TF32*TF32
@@ -3667,15 +3667,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x8 TN F32+=TF32*TF32
@@ -3725,15 +3725,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x8 TN F32+=TF32*TF32
@@ -3793,15 +3793,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x8 TN F32+=TF32*TF32
@@ -3861,15 +3861,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x8 TN F32+=TF32*TF32
@@ -3939,15 +3939,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x8 TN F32+=TF32*TF32
@@ -4017,15 +4017,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x8 TN F32+=TF32*TF32
@@ -4115,15 +4115,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x8 TN F32+=TF32*TF32
@@ -4213,15 +4213,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x8 TN F32+=TF32*TF32
@@ -4331,15 +4331,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x8_F32TF32TF32_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x8 TN F32+=TF32*TF32
@@ -4449,15 +4449,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x8_F32TF32TF32_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*S8
@@ -4486,15 +4486,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*S8
@@ -4523,15 +4523,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*S8
@@ -4562,15 +4562,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*S8
@@ -4601,15 +4601,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*S8
@@ -4645,15 +4645,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*S8
@@ -4689,15 +4689,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*S8
@@ -4743,15 +4743,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*S8
@@ -4797,15 +4797,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*S8
@@ -4861,15 +4861,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*S8
@@ -4925,15 +4925,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*S8
@@ -4999,15 +4999,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*S8
@@ -5073,15 +5073,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*S8
@@ -5167,15 +5167,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*S8
@@ -5261,15 +5261,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*S8
@@ -5375,15 +5375,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*S8
@@ -5489,15 +5489,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*S8
@@ -5526,15 +5526,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*S8
@@ -5563,15 +5563,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*S8
@@ -5602,15 +5602,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*S8
@@ -5641,15 +5641,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*S8
@@ -5685,15 +5685,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*S8
@@ -5729,15 +5729,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*S8
@@ -5783,15 +5783,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*S8
@@ -5837,15 +5837,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*S8
@@ -5901,15 +5901,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*S8
@@ -5965,15 +5965,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*S8
@@ -6039,15 +6039,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*S8
@@ -6113,15 +6113,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*S8
@@ -6207,15 +6207,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*S8
@@ -6301,15 +6301,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*S8
@@ -6415,15 +6415,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*S8
@@ -6529,15 +6529,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*U8
@@ -6566,15 +6566,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*U8
@@ -6603,15 +6603,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*U8
@@ -6642,15 +6642,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*U8
@@ -6681,15 +6681,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*U8
@@ -6725,15 +6725,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*U8
@@ -6769,15 +6769,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*U8
@@ -6823,15 +6823,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*U8
@@ -6877,15 +6877,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*U8
@@ -6941,15 +6941,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*U8
@@ -7005,15 +7005,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*U8
@@ -7079,15 +7079,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*U8
@@ -7153,15 +7153,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*U8
@@ -7247,15 +7247,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*U8
@@ -7341,15 +7341,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*U8
@@ -7455,15 +7455,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*U8
@@ -7569,15 +7569,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*U8
@@ -7606,15 +7606,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=S8*U8
@@ -7643,15 +7643,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*U8
@@ -7682,15 +7682,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=S8*U8
@@ -7721,15 +7721,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*U8
@@ -7765,15 +7765,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=S8*U8
@@ -7809,15 +7809,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*U8
@@ -7863,15 +7863,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=S8*U8
@@ -7917,15 +7917,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*U8
@@ -7981,15 +7981,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=S8*U8
@@ -8045,15 +8045,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*U8
@@ -8119,15 +8119,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=S8*U8
@@ -8193,15 +8193,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*U8
@@ -8287,15 +8287,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=S8*U8
@@ -8381,15 +8381,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*U8
@@ -8495,15 +8495,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=S8*U8
@@ -8609,15 +8609,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32S8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*S8
@@ -8646,15 +8646,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*S8
@@ -8683,15 +8683,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*S8
@@ -8722,15 +8722,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*S8
@@ -8761,15 +8761,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*S8
@@ -8805,15 +8805,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*S8
@@ -8849,15 +8849,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*S8
@@ -8903,15 +8903,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*S8
@@ -8957,15 +8957,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*S8
@@ -9021,15 +9021,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*S8
@@ -9085,15 +9085,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*S8
@@ -9159,15 +9159,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*S8
@@ -9233,15 +9233,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*S8
@@ -9327,15 +9327,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*S8
@@ -9421,15 +9421,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*S8
@@ -9535,15 +9535,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8S8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*S8
@@ -9649,15 +9649,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8S8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*S8
@@ -9686,15 +9686,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*S8
@@ -9723,15 +9723,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*S8
@@ -9762,15 +9762,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*S8
@@ -9801,15 +9801,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*S8
@@ -9845,15 +9845,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*S8
@@ -9889,15 +9889,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*S8
@@ -9943,15 +9943,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*S8
@@ -9997,15 +9997,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*S8
@@ -10061,15 +10061,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*S8
@@ -10125,15 +10125,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*S8
@@ -10199,15 +10199,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*S8
@@ -10273,15 +10273,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*S8
@@ -10367,15 +10367,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*S8
@@ -10461,15 +10461,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*S8
@@ -10575,15 +10575,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8S8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*S8
@@ -10689,15 +10689,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8S8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*U8
@@ -10726,15 +10726,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*U8
@@ -10763,15 +10763,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*U8
@@ -10802,15 +10802,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*U8
@@ -10841,15 +10841,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*U8
@@ -10885,15 +10885,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*U8
@@ -10929,15 +10929,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*U8
@@ -10983,15 +10983,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*U8
@@ -11037,15 +11037,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*U8
@@ -11101,15 +11101,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*U8
@@ -11165,15 +11165,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*U8
@@ -11239,15 +11239,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*U8
@@ -11313,15 +11313,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*U8
@@ -11407,15 +11407,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*U8
@@ -11501,15 +11501,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*U8
@@ -11615,15 +11615,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8U8_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*U8
@@ -11729,15 +11729,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8U8_SS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*U8
@@ -11766,15 +11766,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN S32+=U8*U8
@@ -11803,15 +11803,15 @@
       " p;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*U8
@@ -11842,15 +11842,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN S32+=U8*U8
@@ -11881,15 +11881,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*U8
@@ -11925,15 +11925,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN S32+=U8*U8
@@ -11969,15 +11969,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*U8
@@ -12023,15 +12023,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN S32+=U8*U8
@@ -12077,15 +12077,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*U8
@@ -12141,15 +12141,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN S32+=U8*U8
@@ -12205,15 +12205,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*U8
@@ -12279,15 +12279,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN S32+=U8*U8
@@ -12353,15 +12353,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*U8
@@ -12447,15 +12447,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN S32+=U8*U8
@@ -12541,15 +12541,15 @@
         "+r"(d84), "+r"(d85), "+r"(d86), "+r"(d87),
         "+r"(d88), "+r"(d89), "+r"(d90), "+r"(d91),
         "+r"(d92), "+r"(d93), "+r"(d94), "+r"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*U8
@@ -12655,15 +12655,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8U8_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN S32+=U8*U8
@@ -12769,15 +12769,15 @@
         "+r"(d116), "+r"(d117), "+r"(d118), "+r"(d119),
         "+r"(d120), "+r"(d121), "+r"(d122), "+r"(d123),
         "+r"(d124), "+r"(d125), "+r"(d126), "+r"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_S32U8U8_RS_TN_SATURATE without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E4M3*E4M3
@@ -12810,15 +12810,15 @@
       " p,  %5, %6;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E4M3*E4M3
@@ -12851,15 +12851,15 @@
       " p,   %8,  %9;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E4M3*E4M3
@@ -12892,15 +12892,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E4M3*E4M3
@@ -12933,15 +12933,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E4M3*E4M3
@@ -12974,15 +12974,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E4M3*E4M3
@@ -13015,15 +13015,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E4M3*E4M3
@@ -13058,15 +13058,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E4M3*E4M3
@@ -13101,15 +13101,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E4M3*E4M3
@@ -13144,15 +13144,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E4M3*E4M3
@@ -13187,15 +13187,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E4M3*E4M3
@@ -13235,15 +13235,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E4M3*E4M3
@@ -13283,15 +13283,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E4M3*E4M3
@@ -13331,15 +13331,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E4M3*E4M3
@@ -13379,15 +13379,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E4M3*E4M3
@@ -13437,15 +13437,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E4M3*E4M3
@@ -13495,15 +13495,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E4M3*E4M3
@@ -13548,15 +13548,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E4M3*E4M3
@@ -13601,15 +13601,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E4M3*E4M3
@@ -13669,15 +13669,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E4M3*E4M3
@@ -13737,15 +13737,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E4M3*E4M3
@@ -13795,15 +13795,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E4M3*E4M3
@@ -13853,15 +13853,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E4M3*E4M3
@@ -13931,15 +13931,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E4M3*E4M3
@@ -14009,15 +14009,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E4M3*E4M3
@@ -14077,15 +14077,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E4M3*E4M3
@@ -14145,15 +14145,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E4M3*E4M3
@@ -14243,15 +14243,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E4M3*E4M3
@@ -14341,15 +14341,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E4M3*E4M3
@@ -14419,15 +14419,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E4M3*E4M3
@@ -14497,15 +14497,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E4M3*E4M3
@@ -14615,15 +14615,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E4M3E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E4M3*E4M3
@@ -14733,15 +14733,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E4M3E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E4M3*E5M2
@@ -14774,15 +14774,15 @@
       " p,  %5, %6;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E4M3*E5M2
@@ -14815,15 +14815,15 @@
       " p,   %8,  %9;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E4M3*E5M2
@@ -14856,15 +14856,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E4M3*E5M2
@@ -14897,15 +14897,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E4M3*E5M2
@@ -14938,15 +14938,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E4M3*E5M2
@@ -14979,15 +14979,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E4M3*E5M2
@@ -15022,15 +15022,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E4M3*E5M2
@@ -15065,15 +15065,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E4M3*E5M2
@@ -15108,15 +15108,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E4M3*E5M2
@@ -15151,15 +15151,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E4M3*E5M2
@@ -15199,15 +15199,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E4M3*E5M2
@@ -15247,15 +15247,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E4M3*E5M2
@@ -15295,15 +15295,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E4M3*E5M2
@@ -15343,15 +15343,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E4M3*E5M2
@@ -15401,15 +15401,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E4M3*E5M2
@@ -15459,15 +15459,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E4M3*E5M2
@@ -15512,15 +15512,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E4M3*E5M2
@@ -15565,15 +15565,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E4M3*E5M2
@@ -15633,15 +15633,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E4M3*E5M2
@@ -15701,15 +15701,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E4M3*E5M2
@@ -15759,15 +15759,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E4M3*E5M2
@@ -15817,15 +15817,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E4M3*E5M2
@@ -15895,15 +15895,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E4M3*E5M2
@@ -15973,15 +15973,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E4M3*E5M2
@@ -16041,15 +16041,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E4M3*E5M2
@@ -16109,15 +16109,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E4M3*E5M2
@@ -16207,15 +16207,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E4M3*E5M2
@@ -16305,15 +16305,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E4M3*E5M2
@@ -16383,15 +16383,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E4M3*E5M2
@@ -16461,15 +16461,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E4M3*E5M2
@@ -16579,15 +16579,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E4M3E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E4M3*E5M2
@@ -16697,15 +16697,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E4M3E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E5M2*E4M3
@@ -16738,15 +16738,15 @@
       " p,  %5, %6;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E5M2*E4M3
@@ -16779,15 +16779,15 @@
       " p,   %8,  %9;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E5M2*E4M3
@@ -16820,15 +16820,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E5M2*E4M3
@@ -16861,15 +16861,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E5M2*E4M3
@@ -16902,15 +16902,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E5M2*E4M3
@@ -16943,15 +16943,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E5M2*E4M3
@@ -16986,15 +16986,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E5M2*E4M3
@@ -17029,15 +17029,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E5M2*E4M3
@@ -17072,15 +17072,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E5M2*E4M3
@@ -17115,15 +17115,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E5M2*E4M3
@@ -17163,15 +17163,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E5M2*E4M3
@@ -17211,15 +17211,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E5M2*E4M3
@@ -17259,15 +17259,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E5M2*E4M3
@@ -17307,15 +17307,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E5M2*E4M3
@@ -17365,15 +17365,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E5M2*E4M3
@@ -17423,15 +17423,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E5M2*E4M3
@@ -17476,15 +17476,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E5M2*E4M3
@@ -17529,15 +17529,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E5M2*E4M3
@@ -17597,15 +17597,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E5M2*E4M3
@@ -17665,15 +17665,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E5M2*E4M3
@@ -17723,15 +17723,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E5M2*E4M3
@@ -17781,15 +17781,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E5M2*E4M3
@@ -17859,15 +17859,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E5M2*E4M3
@@ -17937,15 +17937,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E5M2*E4M3
@@ -18005,15 +18005,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E5M2*E4M3
@@ -18073,15 +18073,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E5M2*E4M3
@@ -18171,15 +18171,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E5M2*E4M3
@@ -18269,15 +18269,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E5M2*E4M3
@@ -18347,15 +18347,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E5M2*E4M3
@@ -18425,15 +18425,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E5M2*E4M3
@@ -18543,15 +18543,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E5M2E4M3_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E5M2*E4M3
@@ -18661,15 +18661,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E5M2E4M3_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E5M2*E5M2
@@ -18702,15 +18702,15 @@
       " p,  %5, %6;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F16+=E5M2*E5M2
@@ -18743,15 +18743,15 @@
       " p,   %8,  %9;\n"
     "}\n"
       : "+r"(d0), "+r"(d1)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E5M2*E5M2
@@ -18784,15 +18784,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x8x32 TN F32+=E5M2*E5M2
@@ -18825,15 +18825,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x8x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x8x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E5M2*E5M2
@@ -18866,15 +18866,15 @@
       " p,   %7,  %8;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F16+=E5M2*E5M2
@@ -18907,15 +18907,15 @@
       " p,   %10, %11;\n"
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E5M2*E5M2
@@ -18950,15 +18950,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x16x32 TN F32+=E5M2*E5M2
@@ -18993,15 +18993,15 @@
     "}\n"
       : "+f"(d0), "+f"(d1), "+f"(d2), "+f"(d3),
         "+f"(d4), "+f"(d5), "+f"(d6), "+f"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x16x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x16x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E5M2*E5M2
@@ -19036,15 +19036,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F16+=E5M2*E5M2
@@ -19079,15 +19079,15 @@
     "}\n"
       : "+r"(d0), "+r"(d1), "+r"(d2), "+r"(d3),
         "+r"(d4), "+r"(d5), "+r"(d6), "+r"(d7)
       :  "r"(a0),  "r"(a1),  "r"(a2),  "r"(a3),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E5M2*E5M2
@@ -19127,15 +19127,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x32x32 TN F32+=E5M2*E5M2
@@ -19175,15 +19175,15 @@
         "+f"(d04), "+f"(d05), "+f"(d06), "+f"(d07),
         "+f"(d08), "+f"(d09), "+f"(d10), "+f"(d11),
         "+f"(d12), "+f"(d13), "+f"(d14), "+f"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x32x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x32x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E5M2*E5M2
@@ -19223,15 +19223,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F16+=E5M2*E5M2
@@ -19271,15 +19271,15 @@
         "+r"(d04), "+r"(d05), "+r"(d06), "+r"(d07),
         "+r"(d08), "+r"(d09), "+r"(d10), "+r"(d11),
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E5M2*E5M2
@@ -19329,15 +19329,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x64x32 TN F32+=E5M2*E5M2
@@ -19387,15 +19387,15 @@
         "+f"(d20), "+f"(d21), "+f"(d22), "+f"(d23),
         "+f"(d24), "+f"(d25), "+f"(d26), "+f"(d27),
         "+f"(d28), "+f"(d29), "+f"(d30), "+f"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x64x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x64x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E5M2*E5M2
@@ -19440,15 +19440,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F16+=E5M2*E5M2
@@ -19493,15 +19493,15 @@
         "+r"(d12), "+r"(d13), "+r"(d14), "+r"(d15),
         "+r"(d16), "+r"(d17), "+r"(d18), "+r"(d19),
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E5M2*E5M2
@@ -19561,15 +19561,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x96x32 TN F32+=E5M2*E5M2
@@ -19629,15 +19629,15 @@
         "+f"(d36), "+f"(d37), "+f"(d38), "+f"(d39),
         "+f"(d40), "+f"(d41), "+f"(d42), "+f"(d43),
         "+f"(d44), "+f"(d45), "+f"(d46), "+f"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x96x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x96x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E5M2*E5M2
@@ -19687,15 +19687,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F16+=E5M2*E5M2
@@ -19745,15 +19745,15 @@
         "+r"(d20), "+r"(d21), "+r"(d22), "+r"(d23),
         "+r"(d24), "+r"(d25), "+r"(d26), "+r"(d27),
         "+r"(d28), "+r"(d29), "+r"(d30), "+r"(d31)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E5M2*E5M2
@@ -19823,15 +19823,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x128x32 TN F32+=E5M2*E5M2
@@ -19901,15 +19901,15 @@
         "+f"(d52), "+f"(d53), "+f"(d54), "+f"(d55),
         "+f"(d56), "+f"(d57), "+f"(d58), "+f"(d59),
         "+f"(d60), "+f"(d61), "+f"(d62), "+f"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x128x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x128x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E5M2*E5M2
@@ -19969,15 +19969,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F16+=E5M2*E5M2
@@ -20037,15 +20037,15 @@
         "+r"(d36), "+r"(d37), "+r"(d38), "+r"(d39),
         "+r"(d40), "+r"(d41), "+r"(d42), "+r"(d43),
         "+r"(d44), "+r"(d45), "+r"(d46), "+r"(d47)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E5M2*E5M2
@@ -20135,15 +20135,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x192x32 TN F32+=E5M2*E5M2
@@ -20233,15 +20233,15 @@
         "+f"(d84), "+f"(d85), "+f"(d86), "+f"(d87),
         "+f"(d88), "+f"(d89), "+f"(d90), "+f"(d91),
         "+f"(d92), "+f"(d93), "+f"(d94), "+f"(d95)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x192x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x192x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E5M2*E5M2
@@ -20311,15 +20311,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F16+=E5M2*E5M2
@@ -20389,15 +20389,15 @@
         "+r"(d52), "+r"(d53), "+r"(d54), "+r"(d55),
         "+r"(d56), "+r"(d57), "+r"(d58), "+r"(d59),
         "+r"(d60), "+r"(d61), "+r"(d62), "+r"(d63)
       :  "r"(a00),  "r"(a01),  "r"(a02),  "r"(a03),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F16E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E5M2*E5M2
@@ -20507,15 +20507,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "l"(desc_a),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E5M2E5M2_SS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 // GMMA 64x256x32 TN F32+=E5M2*E5M2
@@ -20625,15 +20625,15 @@
         "+f"(d116), "+f"(d117), "+f"(d118), "+f"(d119),
         "+f"(d120), "+f"(d121), "+f"(d122), "+f"(d123),
         "+f"(d124), "+f"(d125), "+f"(d126), "+f"(d127)
       :  "r"(a000),  "r"(a001),  "r"(a002),  "r"(a003),
          "l"(desc_b),
          "r"(int32_t(scale_D)), "n"(int32_t(scaleA)), "n"(int32_t(scaleB)));
 #else
-    CUTE_RUNTIME_ASSERT("Attempting to use SM90_64x256x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
+    CUTE_INVALID_CONTROL_PATH("Attempting to use SM90_64x256x32_F32E5M2E5M2_RS_TN without CUTE_ARCH_MMA_SM90A_ENABLED");
 #endif
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/arch/util.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/arch/util.hpp`

 * *Files 17% similar despite different names*

```diff
@@ -113,34 +113,70 @@
   return __nvvm_get_smem_pointer(ptr);
 
 #elif defined(__CUDA_ARCH__)
 
   uint32_t smem_ptr;
 
   asm(
-  "{ .reg .u64 smem_ptr; cvta.to.shared.u64 smem_ptr, %1; cvt.u32.u64 %0, smem_ptr; }\n" 
+  "{ .reg .u64 smem_ptr; cvta.to.shared.u64 smem_ptr, %1; cvt.u32.u64 %0, smem_ptr; }\n"
     : "=r"(smem_ptr) : "l"(ptr));
 
   return smem_ptr;
 
 #else
 
 
   (void) ptr;
   printf("ERROR: cast_smem_ptr_to_uint not supported but used.\n");
   return 0;
 
 #endif
 }
 
+namespace detail {
+
 //
-// Utility for pointer interfaces
+// Wrapper for MMAOp::fma
 //
 
-namespace detail {
+template <class MmaOp>
+struct CallFMA {
+  template <class... Args>
+  CUTE_HOST_DEVICE constexpr void
+  operator()(Args&&... args) const {
+    return MmaOp::fma(static_cast<Args&&>(args)...);
+  }
+};
+
+//
+// Wrapper for CopyOp::copy
+//
+
+template <class CopyOp>
+struct CallCOPY {
+  template <class... Args>
+  CUTE_HOST_DEVICE constexpr void
+  operator()(Args&&... args) const {
+    return CopyOp::copy(static_cast<Args&&>(args)...);
+  }
+};
+
+//
+// Utility for exploding pointers/arrays/tensors into functions
+//
+
+template <class Fn,
+          class PtrA, int... I>
+CUTE_HOST_DEVICE constexpr
+void
+explode(Fn fn,
+        PtrA&& a, int_sequence<I...>)
+{
+  return fn(a[I]...);
+}
 
 template <class Fn,
           class PtrS, int... Is,
           class PtrD, int... Id>
 CUTE_HOST_DEVICE constexpr
 void
 explode(Fn fn,
@@ -177,79 +213,86 @@
         PtrB&& b, int_sequence<Ib...>,
         PtrC&& c, int_sequence<Ic...>)
 {
   return fn(d[Id]..., a[Ia]..., b[Ib]..., c[Ic]...);
 }
 
 template <class Fn,
+          class PtrD, int... Id,
           class PtrA, int... Ia,
           class PtrB, int... Ib,
           class PtrC, int... Ic,
-          class ParamType>
+          class PtrE, int... Ie>
 CUTE_HOST_DEVICE constexpr
 void
-explode_with_d_scaling(Fn fn,
+explode(Fn fn,
+        PtrD&& d, int_sequence<Id...>,
         PtrA&& a, int_sequence<Ia...>,
         PtrB&& b, int_sequence<Ib...>,
         PtrC&& c, int_sequence<Ic...>,
-        ParamType&& p0)
+        PtrE&& e, int_sequence<Ie...>)
 {
-  return fn(a[Ia]..., b[Ib]..., c[Ic]..., p0);
+  return fn(d[Id]..., a[Ia]..., b[Ib]..., c[Ic]..., e[Ie]...);
 }
 
 template <class Fn,
-          class PtrD, int... Id,
-          class PtrA, int... Ia,
-          class PtrB, int... Ib,
-          class PtrC, int... Ic,
-          class ParamType>
+          class PtrD,   int... Id,
+          class PtrA,   int... Ia,
+          class PtrB,   int... Ib,
+          class PtrC,   int... Ic,
+          class PtrSFA, int... Isfa,
+          class PtrSFB, int... Isfb>
 CUTE_HOST_DEVICE constexpr
 void
-explode_with_d_scaling(Fn fn,
-        PtrD&& d, int_sequence<Id...>,
-        PtrA&& a, int_sequence<Ia...>,
-        PtrB&& b, int_sequence<Ib...>,
-        PtrC&& c, int_sequence<Ic...>,
-        ParamType&& p0)
+explode(Fn fn,
+        PtrD&& d,     int_sequence<Id...>,
+        PtrA&& a,     int_sequence<Ia...>,
+        PtrB&& b,     int_sequence<Ib...>,
+        PtrC&& c,     int_sequence<Ic...>,
+        PtrSFA&& sfa, int_sequence<Isfa...>,
+        PtrSFB&& sfb, int_sequence<Isfb...>)
 {
-  return fn(d[Id]..., a[Ia]..., b[Ib]..., c[Ic]..., p0);
+  return fn(d[Id]..., a[Ia]..., b[Ib]..., c[Ic]..., sfa[Isfa]..., sfb[Isfb]...);
 }
+//
+// Utility for exploding tuples into functions
+//
 
-} // end namespace detail
-
-template <int SRegCount, int DRegCount,
-          class Fn, class PtrS, class PtrD>
+template <class Fn,
+          class TupleA, int... I>
 CUTE_HOST_DEVICE constexpr
 void
-explode(Fn fn, PtrS&& s, PtrD&& d)
+explode_tuple(Fn fn,
+              TupleA&& a, int_sequence<I...>)
 {
-  return detail::explode(fn,
-                         s, make_int_sequence<SRegCount>{},
-                         d, make_int_sequence<DRegCount>{});
+  return fn(get<I>(a)...);
 }
 
-template <int ARegCount, int BRegCount, int CRegCount, 
-          class Fn, class PtrA, class PtrB, class PtrC>
+template <class Fn,
+          class TupleA, int... Ia,
+          class TupleB, int... Ib>
 CUTE_HOST_DEVICE constexpr
 void
-explode(Fn fn, PtrA&& a, PtrB&& b, PtrC&& c)
+explode_tuple(Fn fn,
+              TupleA&& a, int_sequence<Ia...>,
+              TupleB&& b, int_sequence<Ib...>)
 {
-  return detail::explode(fn,
-                         a, make_int_sequence<ARegCount>{},
-                         b, make_int_sequence<BRegCount>{},
-                         c, make_int_sequence<CRegCount>{});
+  return fn(get<Ia>(a)..., get<Ib>(b)...);
 }
 
-template <int DRegCount, int ARegCount, int BRegCount, int CRegCount,
-          class Fn, class PtrD, class PtrA, class PtrB, class PtrC>
+template <class Fn,
+          class TupleA, int... Ia,
+          class TupleB, int... Ib,
+          class TupleC, int... Ic>
 CUTE_HOST_DEVICE constexpr
 void
-explode(Fn fn, PtrD&& d, PtrA&& a, PtrB&& b, PtrC&& c)
+explode_tuple(Fn fn,
+              TupleA&& a, int_sequence<Ia...>,
+              TupleB&& b, int_sequence<Ib...>,
+              TupleC&& c, int_sequence<Ic...>)
 {
-  return detail::explode(fn,
-                         d, make_int_sequence<DRegCount>{},
-                         a, make_int_sequence<ARegCount>{},
-                         b, make_int_sequence<BRegCount>{},
-                         c, make_int_sequence<CRegCount>{});
+  return fn(get<Ia>(a)..., get<Ib>(b)..., get<Ic>(c)...);
 }
 
+} // end namespace detail
+
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_atom.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_atom.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -77,15 +77,15 @@
   static constexpr int NumValDst = size<1>(ValLayoutDst{});
 
   // Additional Trait parameters/transformations
   template <class... TraitsArgs>
   CUTE_HOST_DEVICE
   auto
   with(TraitsArgs&&... args) const {
-    auto traits = Traits::with(std::forward<TraitsArgs>(args)...);
+    auto traits = Traits::with(static_cast<TraitsArgs&&>(args)...);
     return Copy_Atom<decltype(traits), CopyInternalType>{traits};
   }
 
   //
   // Tensor call interfaces
   //
 
@@ -347,44 +347,44 @@
 
   template <class STensor>
   CUTE_HOST_DEVICE
   auto
   partition_S(STensor&& stensor) const {
     //static_assert(sizeof(typename remove_cvref_t<STensor>::value_type) == sizeof(typename TiledCopy::ValType),
     //              "Expected ValType for tiling SrcTensor.");
-    auto thr_tensor = make_tensor(std::forward<STensor>(stensor).data(), TiledCopy::tidfrg_S(stensor.layout()));
+    auto thr_tensor = make_tensor(static_cast<STensor&&>(stensor).data(), TiledCopy::tidfrg_S(stensor.layout()));
     return thr_tensor(thr_idx_, _, repeat<rank_v<STensor>>(_));
   }
 
   template <class DTensor>
   CUTE_HOST_DEVICE
   auto
   partition_D(DTensor&& dtensor) const {
     //static_assert(sizeof(typename remove_cvref_t<DTensor>::value_type) == sizeof(typename TiledCopy::ValType),
     //              "Expected ValType for tiling DstTensor.");
-    auto thr_tensor = make_tensor(std::forward<DTensor>(dtensor).data(), TiledCopy::tidfrg_D(dtensor.layout()));
+    auto thr_tensor = make_tensor(static_cast<DTensor&&>(dtensor).data(), TiledCopy::tidfrg_D(dtensor.layout()));
     return thr_tensor(thr_idx_, _, repeat<rank_v<DTensor>>(_));
   }
 
   template <class STensor>
   CUTE_HOST_DEVICE static
   auto
   retile_S(STensor&& stensor) {
     // static_assert(sizeof(typename remove_cvref_t<STensor>::value_type) == sizeof(typename TiledCopy::ValType),
     //               "Expected ValType for tiling SrcTensor.");
-    return make_tensor(std::forward<STensor>(stensor).data(), TiledCopy::retile(stensor.layout()));
+    return make_tensor(static_cast<STensor&&>(stensor).data(), TiledCopy::retile(stensor.layout()));
   }
 
   template <class DTensor>
   CUTE_HOST_DEVICE static
   auto
   retile_D(DTensor&& dtensor) {
     // static_assert(sizeof(typename remove_cvref_t<DTensor>::value_type) == sizeof(typename TiledCopy::ValType),
     //               "Expected ValType for tiling DstTensor.");
-    return make_tensor(std::forward<DTensor>(dtensor).data(), TiledCopy::retile(dtensor.layout()));
+    return make_tensor(static_cast<DTensor&&>(dtensor).data(), TiledCopy::retile(dtensor.layout()));
   }
 };
 
 
 template <class... Args,
           class LayoutCopy_TV,
           class Tiler>
@@ -595,15 +595,15 @@
 
 // The logical size of a TileCopy
 template <int... I, class... Args>
 CUTE_HOST_DEVICE constexpr
 auto
 tile_size(TiledCopy<Args...> const&)
 {
-  return size<I...>(typename TiledCopy<Args...>::TiledShape_MN{});
+  return size<I...>(typename TiledCopy<Args...>::Tiler_MN{});
 }
 
 // The number of threads involved in a TiledCopy
 template <class... Args>
 CUTE_HOST_DEVICE constexpr
 auto
 size(TiledCopy<Args...> const&)
@@ -752,14 +752,15 @@
   printf(latex_footer);
 }
 
 } // end namespace cute
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
+#include <cute/atom/copy_traits_sm50.hpp>
 #include <cute/atom/copy_traits_sm75.hpp>
 #include <cute/atom/copy_traits_sm80.hpp>
 #include <cute/atom/copy_traits_sm90.hpp>
 
 // Config
 #if (__CUDACC_VER_MAJOR__ >= 12)
 #  define CUTE_COPY_ATOM_TMA_SM90_ENABLED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -88,29 +88,14 @@
   // Map from (dst-thr,dst-val) to bit
   using DstLayout = Layout<Shape<_1,_1>, Stride<_0,_0>>;
 
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 };
 
-namespace detail {
-
-template <class Operation,
-          class PtrS, int... Is,
-          class PtrD, int... Id>
-CUTE_HOST_DEVICE constexpr
-void
-copy_explode(PtrS&& s, int_sequence<Is...>,
-             PtrD&& d, int_sequence<Id...>)
-{
-  return Operation::copy(s[Is]..., d[Id]...);
-}
-
-} // end namespace detail
-
 //
 // Generic copy_unpack for common argument-based Copy_Traits
 //
 
 template <class CopyOp, class... Args,
           class SEngine, class SLayout,
           class DEngine, class DLayout>
@@ -135,16 +120,17 @@
   Tensor rD = recast<RegTypeDst>(dst);
 
   CUTE_STATIC_ASSERT_V(size(rS) == Int<RegNumSrc>{},
     "Copy_Traits: src failed to vectorize into registers. Layout is incompatible with this CopyOp.");
   CUTE_STATIC_ASSERT_V(size(rD) == Int<RegNumDst>{},
     "Copy_Traits: dst failed to vectorize into registers. Layout is incompatible with this CopyOp.");
 
-  detail::copy_explode<CopyOp>(rS, make_int_sequence<RegNumSrc>{},
-                               rD, make_int_sequence<RegNumDst>{});
+  detail::explode(detail::CallCOPY<CopyOp>{},
+                  rS, make_int_sequence<RegNumSrc>{},
+                  rD, make_int_sequence<RegNumDst>{});
 }
 
 //
 // Accept mutable temporaries
 //
 
 template <class CopyOp, class... Args,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -34,14 +34,16 @@
 #include <cuda.h>
 #endif
 
 #include <cute/atom/copy_traits_sm90_tma_swizzle.hpp>
 #include <cute/atom/copy_traits.hpp>
 #include <cute/atom/copy_atom.hpp>
 
+#include <cute/algorithm/prefetch.hpp>
+
 #include <cute/numeric/integral_ratio.hpp>
 
 namespace cute
 {
 
 template <class GmemTmaBasisStrides_, class TmaGmemBasis_, class TmaSwizzle_>
 struct AuxTmaParams {
@@ -49,85 +51,65 @@
   GmemStrides g_stride_;
   using TmaGmemBasis = TmaGmemBasis_;           // Layout for Tma box shape -> Gmem mode(s), always static
   static_assert(is_static<TmaGmemBasis>::value);
   using TmaSwizzle   = TmaSwizzle_;             // Tma swizzle, always Swizzle<B,M,S>
   static_assert(is_static<TmaSwizzle>::value);
 };
 
-//////////////////////////////////////////////////////////////////////////////
-///////////////////////////// TMA_LOAD ///////////////////////////////////////
-//////////////////////////////////////////////////////////////////////////////
-
-struct SM90_TMA_LOAD_OP : SM90_TMA_LOAD {};
-
-// The executable SM90_TMA_LOAD with tma_desc and tma_mbar
-template <class NumBitsPerTMA>
-struct Copy_Traits<SM90_TMA_LOAD_OP, NumBitsPerTMA>
+// Utility for unpacking TMA_LOAD arguments into a CopyOp
+template <class CopyOp>
+struct TMA_LOAD_Unpack
 {
-  using ThrID   = Layout<_1>;
-
-  // Map from (src-thr,src-val) to bit
-  using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
-  // Map from (dst-thr,dst-val) to bit
-  using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
-
-  // Reference map from (thr,val) to bit
-  using RefLayout = SrcLayout;
-
-  // SM90_TMA_LOAD arguments
-  TmaDescriptor const& tma_desc_;
-  uint64_t& tma_load_mbar_;
-
-  template <class Coord, int... Is>
-  CUTE_HOST_DEVICE constexpr
-  void
-  copy_unpack_(void const* const dst_ptr,
-               Coord const& src_coord, seq<Is...>) const
+  template <class... Args,
+            class TS, class SLayout,
+            class TD, class DLayout>
+  CUTE_HOST_DEVICE friend constexpr void
+  copy_unpack(Copy_Traits<CopyOp, Args...> const& traits,
+              Tensor<TS,SLayout>           const& src,
+              Tensor<TD,DLayout>                & dst)
   {
+    auto src_coord = src.data().coord_;
+    if constexpr (detail::is_prefetch<CopyOp>) {
+      return detail::explode_tuple(detail::CallCOPY<CopyOp>{},
+                                   traits.opargs_, tuple_seq<decltype(traits.opargs_)>{},
+                                   src_coord, tuple_seq<decltype(src_coord)>{});
+    } else {
+      static_assert(is_smem<TD>::value, "SM90_TMA_LOAD requires the destination be shared memory.");
+      void* dst_ptr = cute::raw_pointer_cast(dst.data());
 #if 0
-    auto [c0,c1,c2,c3,c4] = append<5>(src_coord, 0);
-    printf("THR (%d,%d,%d) BLK (%d,%d,%d) TMACRD (%d,%d,%d,%d,%d) SMEMADDR (%p)\n",
-           threadIdx.x, threadIdx.y, threadIdx.z,
-           blockIdx.x, blockIdx.y, blockIdx.z,
-           int32_t(c0), int32_t(c1), int32_t(c2), int32_t(c3), int32_t(c4), dst_ptr);
+      auto [c0,c1,c2,c3,c4] = append<5>(src_coord, 0);
+      printf("THR (%d,%d,%d) BLK (%d,%d,%d) TMACRD (%d,%d,%d,%d,%d) SMEMADDR (%p)\n",
+            threadIdx.x, threadIdx.y, threadIdx.z,
+            blockIdx.x, blockIdx.y, blockIdx.z,
+            int32_t(c0), int32_t(c1), int32_t(c2), int32_t(c3), int32_t(c4), dst_ptr);
 #endif
-
-    SM90_TMA_LOAD::copy(&tma_desc_, tma_load_mbar_,
-                        dst_ptr, get<Is>(src_coord)...);
+      return detail::explode_tuple(detail::CallCOPY<CopyOp>{},
+                                   traits.opargs_, tuple_seq<decltype(traits.opargs_)>{},
+                                   make_tuple(dst_ptr), seq<0>{},
+                                   src_coord, tuple_seq<decltype(src_coord)>{});
+    }
   }
+};
 
-  // This is the copy_unpack dispatch for this Copy_Traits
-  // Src needs to be a gmem tensor with TmaCoordIterator .data()
-  // Dst needs to be a smem tensor
-  template <class TS, class SLayout,
-            class TD, class DLayout>
-  CUTE_HOST_DEVICE friend constexpr
-  void
-  copy_unpack(Copy_Traits        const& traits,
-              Tensor<TS,SLayout> const& src,
-              Tensor<TD,DLayout>      & dst)
-  {
-    static_assert(is_smem<TD>::value, "Expected smem dst for SM90_TMA_LOAD");
+//////////////////////////////////////////////////////////////////////////////
+///////////////////////////// TMA_LOAD ///////////////////////////////////////
+//////////////////////////////////////////////////////////////////////////////
 
-    traits.copy_unpack_(cute::raw_pointer_cast(dst.data()), src.data().coord_, tuple_seq<decltype(src.data().coord_)>{});
-  }
-};
+struct SM90_TMA_LOAD_OP : SM90_TMA_LOAD {};
 
 // The non-executable SM90_TMA_LOAD with tma_desc and no tma_mbar
 // Use .with(tma_mbar) to construct an executable version
 template <class NumBitsPerTMA, class AuxParams_>
 struct Copy_Traits<SM90_TMA_LOAD, NumBitsPerTMA, AuxParams_>
 {
-  using ThrID   = Layout<_1>;
-
+  using ThrID     = Layout<_1>;
   // Map from (src-thr,src-val) to bit
   using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
   // Map from (dst-thr,dst-val) to bit
   using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
-
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 
   // SM90_TMA_LOAD arguments
   TmaDescriptor tma_desc_;
   using AuxParams = AuxParams_;
   AuxParams aux_params_;
@@ -140,23 +122,23 @@
   }
 
   // Construct an executable SM90_TMA_LOAD with tma_mbar
   CUTE_HOST_DEVICE constexpr
   Copy_Traits<SM90_TMA_LOAD_OP, NumBitsPerTMA>
   with(uint64_t& tma_mbar, [[maybe_unused]] uint16_t const& multicast_mask = 0) const {
     // We accept multicast_mask here to keep the API for both atoms consistent
-    return {tma_desc_, tma_mbar};
+    return {{}, {&tma_desc_, &tma_mbar}};
   }
 
   // Construct an executable SM90_TMA_LOAD with tma_mbar (temp. overloaded for grouped gemm/ptr array gemm)
   CUTE_HOST_DEVICE constexpr
   Copy_Traits<SM90_TMA_LOAD_OP, NumBitsPerTMA>
   with(TmaDescriptor const* new_tma_desc, uint64_t& tma_mbar, [[maybe_unused]] uint16_t const& multicast_mask = 0) const {
     // We accept multicast_mask here to keep the API for both atoms consistent
-    return {*new_tma_desc, tma_mbar};
+    return {{}, {new_tma_desc, &tma_mbar}};
   }
 
   // Generate the TMA coord tensor
   template <class GShape>
   CUTE_HOST_DEVICE constexpr
   auto
   get_tma_tensor(GShape const& g_shape) const {
@@ -169,80 +151,73 @@
             class TD, class DLayout>
   CUTE_HOST_DEVICE friend constexpr void
   copy_unpack(Copy_Traits        const& traits,
               Tensor<TS,SLayout> const& src,
               Tensor<TD,DLayout>      & dst) = delete;
 };
 
-//////////////////////////////////////////////////////////////////////////////
-///////////////////////////// TMA_LOAD_MULTICAST /////////////////////////////
-//////////////////////////////////////////////////////////////////////////////
-
-struct SM90_TMA_LOAD_MULTICAST_OP : SM90_TMA_LOAD_MULTICAST {};
-
+// The executable SM90_TMA_LOAD with tma_desc and tma_mbar
 template <class NumBitsPerTMA>
-struct Copy_Traits<SM90_TMA_LOAD_MULTICAST_OP, NumBitsPerTMA>
+struct Copy_Traits<SM90_TMA_LOAD_OP, NumBitsPerTMA>
+     : TMA_LOAD_Unpack<SM90_TMA_LOAD_OP>
 {
-  using ThrID   = Layout<_1>;
-
+  using ThrID     = Layout<_1>;
   // Map from (src-thr,src-val) to bit
   using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
   // Map from (dst-thr,dst-val) to bit
   using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
-
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 
-  // SM90_TMA_LOAD_MULTICAST arguments
-  TmaDescriptor const& tma_desc_;
-  uint64_t& tma_load_mbar_;
-  uint16_t const& multicast_mask_;
-
-  template <class Coord, int... Is>
-  CUTE_HOST_DEVICE constexpr
-  void
-  copy_unpack_(void const* const dst_ptr,
-               Coord const& src_coord, seq<Is...>) const
-  {
-#if 0
-    auto [c0,c1,c2,c3,c4] = append<5>(src_coord, 0);
-    printf("THR (%d,%d,%d) BLK (%d,%d,%d) TMACRD (%d,%d,%d,%d,%d) SMEMADDR (%p)\n",
-           threadIdx.x, threadIdx.y, threadIdx.z,
-           blockIdx.x, blockIdx.y, blockIdx.z,
-           int32_t(c0), int32_t(c1), int32_t(c2), int32_t(c3), int32_t(c4), dst_ptr);
-#endif
+  // SM90_TMA_LOAD arguments
+  tuple<
+  TmaDescriptor const*,
+  uint64_t* // smem mbarrier
+  > const opargs_;
+};
 
-    SM90_TMA_LOAD_MULTICAST::copy(&tma_desc_, tma_load_mbar_, multicast_mask_,
-                                  dst_ptr, get<Is>(src_coord)...);
-  }
+// The prefetch for SM90_TMA_LOAD with tma_desc
+template <class NumBitsPerTMA, class... Args>
+struct Copy_Traits<SM90_TMA_LOAD::PREFETCH, NumBitsPerTMA, Args...>
+     : TMA_LOAD_Unpack<SM90_TMA_LOAD::PREFETCH>
+{
+  using ThrID     = Layout<_1>;
+  // Map from (src-thr,src-val) to bit
+  using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Map from (dst-thr,dst-val) to bit
+  using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Reference map from (thr,val) to bit
+  using RefLayout = SrcLayout;
 
-  template <class TS, class SLayout,
-            class TD, class DLayout>
-  CUTE_HOST_DEVICE friend constexpr
-  void
-  copy_unpack(Copy_Traits        const& traits,
-              Tensor<TS,SLayout> const& src,
-              Tensor<TD,DLayout>      & dst)
-  {
-    static_assert(is_smem<TD>::value, "Expected smem dst for SM90_TMA_LOAD_MULTICAST");
+  // SM90_TMA_LOAD::PREFETCH arguments
+  tuple<TmaDescriptor const*> const opargs_;
 
-    traits.copy_unpack_(cute::raw_pointer_cast(dst.data()), src.data().coord_, tuple_seq<decltype(src.data().coord_)>{});
-  }
+  // Construct with any other Traits' TMA Desc
+  template <class... CopyArgs>
+  CUTE_HOST_DEVICE
+  Copy_Traits(Copy_Traits<CopyArgs...> const& traits)
+    : opargs_({&traits.tma_desc_}) {}
 };
 
+//////////////////////////////////////////////////////////////////////////////
+///////////////////////////// TMA_LOAD_MULTICAST /////////////////////////////
+//////////////////////////////////////////////////////////////////////////////
+
+struct SM90_TMA_LOAD_MULTICAST_OP : SM90_TMA_LOAD_MULTICAST {};
+
+// The non-executable SM90_TMA_LOAD_MULTICAST with tma_desc and no tma_mbar
+// Use .with(tma_mbar, multicast_mask) to construct an executable version
 template <class NumBitsPerTMA, class AuxParams_>
 struct Copy_Traits<SM90_TMA_LOAD_MULTICAST, NumBitsPerTMA, AuxParams_>
 {
-  using ThrID   = Layout<_1>;
-
+  using ThrID     = Layout<_1>;
   // Map from (src-thr,src-val) to bit
   using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
   // Map from (dst-thr,dst-val) to bit
   using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
-
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 
   // SM90_TMA_LOAD_MULTICAST arguments
   TmaDescriptor tma_desc_;
   using AuxParams = AuxParams_;
   AuxParams aux_params_;
@@ -254,22 +229,22 @@
     return &tma_desc_;
   }
 
   // Construct an executable SM90_TMA_LOAD_MULTICAST with tma_mbar
   CUTE_HOST_DEVICE constexpr
   Copy_Traits<SM90_TMA_LOAD_MULTICAST_OP, NumBitsPerTMA>
   with(uint64_t& tma_load_mbar, uint16_t const& multicast_mask) const {
-    return {tma_desc_, tma_load_mbar, multicast_mask};
+    return {{}, {&tma_desc_, &tma_load_mbar, multicast_mask}};
   }
 
   // Construct an executable SM90_TMA_LOAD_MULTICAST_OP with tma_mbar (temp. overloaded for grouped gemm/ptr array gemm)
   CUTE_HOST_DEVICE constexpr
   Copy_Traits<SM90_TMA_LOAD_MULTICAST_OP, NumBitsPerTMA>
   with(TmaDescriptor const* new_tma_desc, uint64_t& tma_load_mbar, uint16_t const& multicast_mask) const {
-    return {*new_tma_desc, tma_load_mbar, multicast_mask};
+    return {{}, {new_tma_desc, &tma_load_mbar, multicast_mask}};
   }
 
   // Generate the TMA coord tensor
   template <class GShape>
   CUTE_HOST_DEVICE constexpr
   auto
   get_tma_tensor(GShape const& g_shape) const {
@@ -282,33 +257,117 @@
             class TD, class DLayout>
   CUTE_HOST_DEVICE friend constexpr void
   copy_unpack(Copy_Traits        const& traits,
               Tensor<TS,SLayout> const& src,
               Tensor<TD,DLayout>      & dst) = delete;
 };
 
+// The executable SM90_TMA_LOAD_MULTICAST with tma_desc and tma_mbar and multicast_mask
+template <class NumBitsPerTMA>
+struct Copy_Traits<SM90_TMA_LOAD_MULTICAST_OP, NumBitsPerTMA>
+     : TMA_LOAD_Unpack<SM90_TMA_LOAD_MULTICAST_OP>
+{
+  using ThrID     = Layout<_1>;
+  // Map from (src-thr,src-val) to bit
+  using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Map from (dst-thr,dst-val) to bit
+  using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Reference map from (thr,val) to bit
+  using RefLayout = SrcLayout;
+
+  // SM90_TMA_LOAD_MULTICAST arguments
+  tuple<
+  TmaDescriptor const*,
+  uint64_t*, // smem mbarrier
+  uint16_t   // multicast mask
+  > const opargs_;
+};
+
 //////////////////////////////////////////////////////////////////////////////
 ///////////////////////////// TMA_STORE //////////////////////////////////////
 //////////////////////////////////////////////////////////////////////////////
 
 // The executable SM90_TMA_STORE with tma_desc
 template <class NumBitsPerTMA, class AuxParams_>
 struct Copy_Traits<SM90_TMA_STORE, NumBitsPerTMA, AuxParams_>
 {
+  using ThrID     = Layout<_1>;
+  // Map from (src-thr,src-val) to bit
+  using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Map from (dst-thr,dst-val) to bit
+  using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
+  // Reference map from (thr,val) to bit
+  using RefLayout = SrcLayout;
+
+  // SM90_TMA_STORE arguments
+  TmaDescriptor tma_desc_;
+  using AuxParams = AuxParams_;
+  AuxParams aux_params_;
+
+  // Return TmaDescriptor/TensorMap
+  CUTE_HOST_DEVICE constexpr
+  TmaDescriptor const*
+  get_tma_descriptor() const {
+    return &tma_desc_;
+  }
+
+  // Generate the TMA coord tensor
+  template <class GShape>
+  CUTE_HOST_DEVICE constexpr
+  auto
+  get_tma_tensor(GShape const& g_shape) const {
+    static_assert(is_congruent<decltype(g_shape), decltype(aux_params_.g_stride_)>::value);
+    return make_counting_tensor(make_layout(g_shape, aux_params_.g_stride_));
+  }
+
+  template <class TS, class SLayout,
+            class TD, class DLayout>
+  CUTE_HOST_DEVICE friend constexpr void
+  copy_unpack(Copy_Traits        const& traits,
+              Tensor<TS,SLayout> const& src,
+              Tensor<TD,DLayout>      & dst)
+  {
+    static_assert(is_smem<TS>::value, "Expected smem src for SM90_TMA_STORE");
+    //static_assert(is_gmem<TD>::value, "Expected gmem dst for SM90_TMA_STORE");  // TMA spoofed src tensor
+
+    void const* const desc_ptr = &(traits.tma_desc_);
+    void const* const src_ptr  = cute::raw_pointer_cast(src.data());
+    auto dst_coord = dst.data().coord_;
+#if 0
+    auto [c0,c1,c2,c3,c4] = append<5>(dst_coord, 0);
+    printf("THR (%d,%d,%d) BLK (%d,%d,%d) TMACRD (%d,%d,%d,%d,%d) SMEMADDR (%p)\n",
+           threadIdx.x, threadIdx.y, threadIdx.z,
+           blockIdx.x, blockIdx.y, blockIdx.z,
+           int32_t(c0), int32_t(c1), int32_t(c2), int32_t(c3), int32_t(c4), src_ptr);
+#endif
+    return detail::explode_tuple(detail::CallCOPY<SM90_TMA_STORE>{},
+                                 make_tuple(desc_ptr, src_ptr), seq<0,1>{},
+                                 dst_coord, tuple_seq<decltype(dst_coord)>{});
+  }
+};
+
+//////////////////////////////////////////////////////////////////////////////
+///////////////////////////// TMA_REDUCE_ADD //////////////////////////////////////
+//////////////////////////////////////////////////////////////////////////////
+
+// The executable SM90_TMA_REDUCE_ADD with tma_desc
+template <class NumBitsPerTMA, class AuxParams_>
+struct Copy_Traits<SM90_TMA_REDUCE_ADD, NumBitsPerTMA, AuxParams_>
+{
   using ThrID   = Layout<_1>;
 
   // Map from (src-thr,src-val) to bit
   using SrcLayout = Layout<Shape<_1,NumBitsPerTMA>>;
   // Map from (dst-thr,dst-val) to bit
   using DstLayout = Layout<Shape<_1,NumBitsPerTMA>>;
 
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 
-  // SM90_TMA_STORE arguments
+  // SM90_TMA_REDUCE_ADD arguments
   TmaDescriptor tma_desc_;
   using AuxParams = AuxParams_;
   AuxParams aux_params_;
 
   // Return TmaDescriptor/TensorMap
   CUTE_HOST_DEVICE constexpr
   TmaDescriptor const*
@@ -335,31 +394,31 @@
     auto [c0,c1,c2,c3,c4] = append<5>(dst_coord, 0);
     printf("THR (%d,%d,%d) BLK (%d,%d,%d) TMACRD (%d,%d,%d,%d,%d) SMEMADDR (%p)\n",
            threadIdx.x, threadIdx.y, threadIdx.z,
            blockIdx.x, blockIdx.y, blockIdx.z,
            int32_t(c0), int32_t(c1), int32_t(c2), int32_t(c3), int32_t(c4), src_ptr);
 #endif
 
-    SM90_TMA_STORE::copy(&tma_desc_,
+    SM90_TMA_REDUCE_ADD::copy(&tma_desc_,
                          src_ptr, get<Is>(dst_coord)...);
   }
 
   // This is the copy_unpack dispatch for this Copy_Traits
   // Src needs to be a smem tensor
   // Dst needs to be a gmem tensor with TmaCoordIterator .data()
   template <class TS, class SLayout,
             class TD, class DLayout>
   CUTE_HOST_DEVICE friend constexpr
   void
   copy_unpack(Copy_Traits        const& traits,
               Tensor<TS,SLayout> const& src,
               Tensor<TD,DLayout>      & dst)
   {
-    static_assert(is_smem<TS>::value, "Expected smem src for SM90_TMA_STORE");
-    //static_assert(is_gmem<TD>::value, "Expected gmem dst for SM90_TMA_STORE");  // TMA spoofed src tensor
+    static_assert(is_smem<TS>::value, "Expected smem src for SM90_TMA_REDUCE_ADD");
+    //static_assert(is_gmem<TD>::value, "Expected gmem dst for SM90_TMA_REDUCE_ADD");  // TMA spoofed src tensor
 
     traits.copy_unpack_(cute::raw_pointer_cast(src.data()), dst.data().coord_, tuple_seq<decltype(dst.data().coord_)>{});
   }
 };
 
 //////////////////////////////////////////////////////////////////////////////
 ///////////////////////////// BULK COPY //////////////////////////////////////
@@ -379,35 +438,56 @@
   // Reference map from (thr,val) to bit
   using RefLayout = SrcLayout;
 
   // SM90_BULK_COPY_G2S arguments
   // 0: uint64_t* bulk_load_memory_barrier
   cute::tuple<OpArgs...> bulk_load_mbar_;
 
+  // Record the memory barrier for the instruction
+  CUTE_HOST_DEVICE constexpr
+  Copy_Traits<SM90_BULK_COPY_G2S, NumBitsPerTMA, uint64_t*>
+  with(uint64_t& bulk_mbar) const {
+    return {{&bulk_mbar}};
+  }
+
   template <class TS, class SLayout,
             class TD, class DLayout>
   CUTE_HOST_DEVICE friend constexpr
   void
   copy_unpack(Copy_Traits        const& traits,
               Tensor<TS,SLayout> const& src,
               Tensor<TD,DLayout>      & dst)
   {
     static_assert(is_same<cute::tuple<OpArgs...>, cute::tuple<uint64_t*>>::value,
                   "Extra arguments not set. Set .with() before use.");
     static_assert(is_gmem<TS>::value, "Expected gmem src for SM90_BULK_COPY_G2S");
     static_assert(is_smem<TD>::value, "Expected smem dst for SM90_BULK_COPY_G2S");
-    SM90_BULK_COPY_G2S::copy(raw_pointer_cast(src.data()), *get<0>(traits.bulk_load_mbar_),
+    SM90_BULK_COPY_G2S::copy(raw_pointer_cast(src.data()), get<0>(traits.bulk_load_mbar_),
                              raw_pointer_cast(dst.data()), int32_t(NumBitsPerTMA::value / 8));
   }
+};
 
-  // Record the memory barrier for the instruction
-  CUTE_HOST_DEVICE constexpr
-  Copy_Traits<SM90_BULK_COPY_G2S, NumBitsPerTMA, uint64_t*>
-  with(uint64_t& bulk_mbar) const {
-    return {{&bulk_mbar}};
+template <class NumBitsPerTMA, class... Args>
+struct Copy_Traits<SM90_BULK_COPY_G2S::PREFETCH, NumBitsPerTMA, Args...>
+     : Copy_Traits<SM90_BULK_COPY_G2S, NumBitsPerTMA>
+{
+  template <class... CopyArgs>
+  CUTE_HOST_DEVICE
+  Copy_Traits(Copy_Traits<CopyArgs...> const& traits) {}
+
+  template <class TS, class SLayout,
+            class TD, class DLayout>
+  CUTE_HOST_DEVICE friend constexpr
+  void
+  copy_unpack(Copy_Traits        const& traits,
+              Tensor<TS,SLayout> const& src,
+              Tensor<TD,DLayout>      & dst)
+  {
+    static_assert(is_gmem<TS>::value, "Expected gmem src for SM90_BULK_PREFETCH");
+    SM90_BULK_COPY_G2S::PREFETCH::copy(raw_pointer_cast(src.data()), int32_t(NumBitsPerTMA::value / 8));
   }
 };
 
 template <class NumBitsPerTMA>
 struct Copy_Traits<SM90_BULK_COPY_S2G, NumBitsPerTMA>
 {
   static_assert(int32_t(NumBitsPerTMA::value / 8) % 16 == 0,
@@ -649,25 +729,25 @@
 
 template <class GEngine, class GLayout,
           class TmaGmemBasisStride,
           class ShapeT, size_t TmaRank>
 CUTE_HOST_DEVICE constexpr
 void
 fill_tma_gmem_shape_stride(Tensor<GEngine,GLayout>   const& gtensor,           // Gmem Shapes and Strides, in units of TmaInternalType
-                           TmaGmemBasisStride        const& tma_gbasis_stride, // Map Tma mode idx -> Gmem mode(s) 
+                           TmaGmemBasisStride        const& tma_gbasis_stride, // Map Tma mode idx -> Gmem mode(s)
                            cute::array<ShapeT,   TmaRank> & gmem_prob_shape,   // Tma Shapes, uint32_t or uin64_t
                            cute::array<uint64_t, TmaRank> & gmem_prob_stride)  // Tma Strides
 {
   static_assert(is_tuple<TmaGmemBasisStride>::value);
   static_assert(is_same<uint32_t, ShapeT>::value || is_same<uint64_t, ShapeT>::value);
 
   using TmaInternalType = typename GEngine::value_type;
   constexpr int tma_rank = decltype(rank(tma_gbasis_stride))::value;
   static_assert(TmaRank >= tma_rank);
-  
+
   auto gmem_shape  =  shape(gtensor);
   auto gmem_stride = stride(gtensor);
   // Use the indirections in tma_gbasis_stride into gtensor to construct the tma gmem shapes/strides
   for_each(make_seq<tma_rank>{}, [&](auto i) {
     constexpr int tma_i_rank = decltype(rank<i>(tma_gbasis_stride))::value;
     if constexpr (tma_i_rank == 1) {
       // Trivial contribution of this gmem mode to this tma mode
@@ -699,20 +779,20 @@
 
 // Overload for an existing Copy_Traits
 template <class GEngine, class GLayout,
           class Op, class Bits, class Aux,
           class ShapeT, size_t TmaRank>
 CUTE_HOST_DEVICE constexpr
 void
-fill_tma_gmem_shape_stride(Copy_Traits<Op,Bits,Aux>  const& tma_traits,    
+fill_tma_gmem_shape_stride(Copy_Traits<Op,Bits,Aux>  const& tma_traits,
                            Tensor<GEngine,GLayout>   const& gtensor,           // Gmem Shapes and Strides, value_type = TmaInternalType
                            cute::array<ShapeT,   TmaRank> & gmem_prob_shape,   // Tma Shapes, uint32_t or uin64_t
                            cute::array<uint64_t, TmaRank> & gmem_prob_stride)  // Tma Strides
 {
-  return fill_tma_gmem_shape_stride(gtensor, stride(typename Aux::TmaGmemBasis{}), 
+  return fill_tma_gmem_shape_stride(gtensor, stride(typename Aux::TmaGmemBasis{}),
                                     gmem_prob_shape, gmem_prob_stride);
 }
 
 // Use a sidx2gmode to read through the GMEM tensor
 //   and construct a TMA Descriptor for the resulting instruction
 // At the same time, construct the Tma Tensor's Stride to generate
 //   the TMA coordinates that the instruction consumes.
@@ -820,15 +900,15 @@
   assert(smem_box_stride[4] >= (uint32_t(1)));               // Stride must be min 1
   assert(smem_box_stride[4] <= (uint32_t(8)));               // Stride must be max 2^3 = 8
 
     //
     // Construct the descriptor
     //
 
-    TmaDescriptor tma_desc = {0};
+    TmaDescriptor tma_desc{};
 
     //
     // TMA general info
     //
 
   #if (__CUDACC_VER_MAJOR__ >= 12) && !defined(__CUDACC_RTC__)
 
@@ -893,15 +973,15 @@
       if constexpr (decltype(j == Int<0>{})::value) {
         auto scale = recast_ratio * basis_get(ei, stride(gtensor));
         return E<j>{} * scale;         // Return TMA Coord basis -- with a recast scale factor
       } else
       if constexpr (decltype(rank<j>(tma_gmem_basis_stride) == Int<1>{})::value) {
         return E<j>{};                 // Return TMA Coord basis -- known scale of Int<1>{}
       } else {
-        int32_t scale = ceil_div(int32_t(di * sizeof_bits_v<TmaInternalType> / cute::max(gmem_prob_stride[j], 16)), 8);
+        int32_t scale = ceil_div(int32_t(di * sizeof_bits_v<TmaInternalType> / cute::max(gmem_prob_stride[j], uint64_t{16})), 8);
         return E<j>{} * scale;         // Return TMA Coord basis -- with a dynamic scale factor
       }
     }
   });
 
 #if 0
     print("gmem_tma_basis_stride : "); print(gmem_tma_basis_stride); print("\n");
@@ -944,15 +1024,15 @@
                                                                             smem_swizzle,
                                                                             num_multicast);
 
   //
   // Construct the Copy_Traits
   //
 
-  constexpr int num_bits_per_tma = size(tma_gbasis) * sizeof_bits<TmaInternalType>::value;
+  constexpr int num_bits_per_tma = size(tma_gbasis) * sizeof_bits_v<TmaInternalType>;
   using Traits = Copy_Traits<CopyOp, cute::C<num_bits_per_tma>, decltype(aux_params)>;
   using Atom   = Copy_Atom<Traits, typename GEngine::value_type>;
 
   Traits tma_traits{tma_desc, aux_params};
 
 #if 0
   print("num_bits_per_tma :  "); print(num_bits_per_tma); print("\n");
@@ -1101,21 +1181,30 @@
 auto
 make_tma_copy(CopyOp                  const& copy_op,
               Tensor<GEngine,GLayout> const& gtensor,
               SLayout                 const& slayout,
               CTA_Tiler               const& cta_tiler,
               Cluster_Size            const& cluster_size)
 {
+  if constexpr (cute::is_same_v<CopyOp, SM90_TMA_LOAD_IM2COL> ||
+                cute::is_same_v<CopyOp, SM90_TMA_STORE_IM2COL>) {
+    return make_im2col_tma_copy(copy_op,
+                                gtensor,
+                                slayout,
+                                cta_tiler,
+                                cluster_size);
+  } else {
     auto cta_v_tile = make_identity_layout(shape(gtensor)).compose(cta_tiler);
     auto cta_t_tile = make_layout(cluster_size);
     // Prefer TmaInternalType if specified. Fallback to GEngine::value_type
     using TmaType = conditional_t<is_same<void, TmaInternalType>::value, typename GEngine::value_type, TmaInternalType>;
     return detail::make_tma_copy_tiled<TmaType>(copy_op,
                                                 gtensor, slayout,
                                                 cta_t_tile, cta_v_tile);
+  }
 }
 
 // Explicit defaulting
 template <class CopyOp,
           class GEngine, class GLayout,
           class SLayout>
 CUTE_HOST_RTC
@@ -1175,53 +1264,72 @@
           class SEngine, class SLayout,
           class GEngine, class GLayout>
 CUTE_DEVICE
 auto
 tma_partition(Copy_Atom<Args...>      const& copy_atom,
               CtaCoord                const& cta_coord,
               Layout<TShape,TStride>  const& cta_layout,  // T: CTA coord -> logical multicast id
-              Tensor<SEngine,SLayout> const& stensor,     // SMEM Tensor (TMATile, Iter)
-              Tensor<GEngine,GLayout> const& gtensor)     // GMEM Tensor (TMATile, Iter)
+              Tensor<SEngine,SLayout> const& stensor,     // SMEM Tensor (TMATile, Rest...)
+              Tensor<GEngine,GLayout> const& gtensor)     // GMEM Tensor (TMATile, Rest...)
 {
+  CUTE_STATIC_ASSERT_V(size<0>(stensor) == size<0>(gtensor));
+
   // Invert the smem to get the largest contiguous vector in the smem layout
   Layout inv_smem_layout = right_inverse(get_nonswizzle_portion(layout<0>(stensor)));
   // Scale that up to cover all of the smem_coords
   Layout layout_v = tile_to_shape(make_layout(inv_smem_layout), size<0>(stensor));
 
   // Factor out the single-instrucion portion
   Layout tma_layout_v = make_layout(Int<Copy_Atom<Args...>::NumValSrc>{});
-  Layout layout_V = logical_divide(layout_v, tma_layout_v);
+  auto layout_V = make_tile(logical_divide(layout_v, tma_layout_v));
 
+  // Append with _ until we cover all Rest... modes
+  auto glayout_V = append<rank_v<decltype(gtensor)>>(layout_V, _);
+  auto slayout_V = append<rank_v<decltype(stensor)>>(layout_V, _);
   // Transform tile mode and coalesce
-  Tensor gtensor_v = coalesce(gtensor.compose(layout_V, _), Shape<Shape<_1,_1>,_1>{});   // ((TMA,TMA_Iter),Iter)
-  Tensor stensor_v = coalesce(stensor.compose(layout_V, _), Shape<Shape<_1,_1>,_1>{});   // ((TMA,TMA_Iter),Iter)
+  Tensor gtensor_v = coalesce(gtensor.compose(glayout_V), Shape<Shape<_1,_1>>{});    // ((TMA,TMA_Iter), Rest...)
+  Tensor stensor_v = coalesce(stensor.compose(slayout_V), Shape<Shape<_1,_1>>{});    // ((TMA,TMA_Iter), Rest...)
 
 #if 0
   if (thread0()) {
+    print("cta_coord  : "); print(cta_coord); print("\n");
+    print("cta_layout : "); print(cta_layout); print("\n");
+    print("gtensor   : "); print(gtensor); print("\n");
+    print("stensor   : "); print(stensor); print("\n");
     print("layout_V  : "); print(layout_V); print("\n");
     print("gtensor_v : "); print(gtensor_v); print("\n");
     print("stensor_v : "); print(stensor_v); print("\n");
   }
 #endif
 
-  // Restride the cta-into-tma-instr layout
-  Layout tma_layout_t  = composition(make_layout(Int<1>{}, shape_div(size(tma_layout_v), cosize(cta_layout))), cta_layout);
-  Layout tma_layout_tv = make_layout(tma_layout_t, tma_layout_v);
-
-  // Transform TMA mode
-  Tensor gtensor_tv = gtensor_v.compose(make_tile(tma_layout_tv, _), _);                 // (((Thr,Frg),TMA_Iter),Iter)
-  Tensor stensor_tv = stensor_v.compose(make_tile(tma_layout_tv, _), _);                 // (((Thr,Frg),TMA_Iter),Iter)
+  // Offset inside the TMA-mode for the multicast
+  auto multicast_offset = cta_layout(cta_coord) * (size(tma_layout_v) / cosize(cta_layout));
+  auto multicast_coord  = make_coord(make_coord(multicast_offset, Int<0>{}));
+  auto scoord = append<SLayout::rank>(multicast_coord, Int<0>{});
+  auto gcoord = append<GLayout::rank>(multicast_coord, Int<0>{});
 
-#if 0
-  if (thread0()) {
-    print("tma_layout_tv : "); print(tma_layout_tv); print("\n");
-    print("gtensor_tv : "); print(gtensor_tv); print("\n");
-    print("stensor_tv : "); print(stensor_tv); print("\n");
-  }
-#endif
+  Tensor gresult = domain_offset(gcoord, gtensor_v);
+  Tensor sresult = domain_offset(scoord, stensor_v);
+
+  return cute::make_tuple(gresult, sresult);
+}
 
-  // Slice and group Frg,TMA_Iter and return
-  auto c = make_coord(make_coord(make_coord(cta_coord, _), _), _);
-  return cute::make_tuple(group_modes<0,2>(gtensor_tv(c)), group_modes<0,2>(stensor_tv(c)));
+// TMA Multicast Masks Calculation
+template <int Mode, class CtaLayout, class CtaCoord>
+CUTE_HOST_DEVICE constexpr
+auto
+create_tma_multicast_mask(CtaLayout const& cta_layout_vmnk,
+                          CtaCoord  const& cta_coord_vmnk)
+{
+  auto cta_coord_slicer = replace<Mode>(cta_coord_vmnk, _);
+  auto [cta_layout, elected_cta] = slice_and_offset(cta_coord_slicer, cta_layout_vmnk);
+  // Get the instruction code
+  uint16_t mcast_mask = 0;
+  for (int i = 0; i < size(cta_layout); ++i) {
+    mcast_mask |= uint16_t(1) << cta_layout(i);
+  }
+  // Shift by the instruction's elected block rank (dynamic)
+  mcast_mask <<= elected_cta;
+  return mcast_mask;
 }
 
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma_swizzle.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma_swizzle.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_atom.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_atom.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -31,15 +31,14 @@
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/arch/mma.hpp>
 
 #include <cute/atom/mma_traits.hpp>
-
 #include <cute/tensor.hpp>
 #include <cute/util/type_traits.hpp>
 
 namespace cute {
 
 template <class... Args>
 struct MMA_Atom;
@@ -74,15 +73,15 @@
   using FrgTypeC = typename detail::FrgTypeC_or_Default<Traits>::type;
 
   // Additional Trait parameters/transformations
   template <class... TraitsArgs>
   CUTE_HOST_DEVICE
   auto
   with(TraitsArgs&&... args) const {
-    auto traits = Traits::with(std::forward<TraitsArgs>(args)...);
+    auto traits = Traits::with(static_cast<TraitsArgs&&>(args)...);
     return MMA_Atom<decltype(traits)>{traits};
   }
 
   //
   // Tensor call interfaces
   //
 
@@ -153,15 +152,15 @@
     CUTE_STATIC_ASSERT_V(rank(atensor) >= Int<3>{});  // VMK
     CUTE_STATIC_ASSERT_V(size<0>(atensor) == size<1>(LayoutA_TV{}));
 
     if constexpr (has_dereference<FrgTypeA>::value) {
       // If the intended FrgTypeA is a view (of the current tensor), forward the whole
       static_assert(is_same<ValTypeA, typename remove_cvref_t<ATensor>::value_type>::value
                       , "Expecting ValTypeA type");
-      return make_tensor<FrgTypeA>(std::forward<ATensor>(atensor));
+      return make_tensor<FrgTypeA>(static_cast<ATensor&&>(atensor));
     } else {
       // Else, the intended FrgTypeA is a value type, construct a new tensor with a fragment layout
       return make_fragment_like<FrgTypeA>(atensor);
     }
 
     CUTE_GCC_UNREACHABLE;
   }
@@ -175,15 +174,15 @@
     CUTE_STATIC_ASSERT_V(rank(btensor) >= Int<3>{});  // VNK
     CUTE_STATIC_ASSERT_V(size<0>(btensor) == size<1>(LayoutB_TV{}));
 
     if constexpr (has_dereference<FrgTypeB>::value) {
       // If the intended FrgTypeB is a view (of the current tensor), forward the whole
       static_assert(is_same<ValTypeB, typename remove_cvref_t<BTensor>::value_type>::value
                       , "Expecting ValTypeB type");
-      return make_tensor<FrgTypeB>(std::forward<BTensor>(btensor));
+      return make_tensor<FrgTypeB>(static_cast<BTensor&&>(btensor));
     } else {
       // Else, the intended FrgTypeB is a value type, construct a new tensor with a fragment layout
       return make_fragment_like<FrgTypeB>(btensor);
     }
 
     CUTE_GCC_UNREACHABLE;
   }
@@ -209,15 +208,15 @@
   using AtomThrID      = typename MMA_Atom::ThrID;
   using AtomLayoutC_TV = typename MMA_Atom::LayoutC_TV;
   using AtomLayoutA_TV = typename MMA_Atom::LayoutA_TV;
   using AtomLayoutB_TV = typename MMA_Atom::LayoutB_TV;
 
   static_assert(   rank_v<AtomLayoutMNK>  == 3,   "TiledMMA requires rank-3 AtomLayoutMNK");
   static_assert(   rank_v<PermutationMNK> == 3,   "TiledMMA requires rank-3 PermutationMNK");
-  static_assert(  is_tile<PermutationMNK>::value, "TiledMMA requires independent permutations of MNK.");
+  static_assert( is_tuple<PermutationMNK>::value, "TiledMMA requires independent permutations of MNK.");
   static_assert(is_static<PermutationMNK>::value, "TiledMMA requires static permutations of MNK.");
 
   using ThrLayoutVMNK = decltype(tiled_product(AtomThrID{}, AtomLayoutMNK{}));
   ThrLayoutVMNK thr_layout_vmnk_;
 
   CUTE_HOST_DEVICE constexpr
   TiledMMA(MMA_Atom const& mma_atom = {}, AtomLayoutMNK const& thr_layout_mnk = {})
@@ -387,15 +386,15 @@
     auto core_size = size<I>(AtomShape_MNK{}) * size<I+1>(get_thr_layout_vmnk());
     [[maybe_unused]] auto perm_size = size<I>(PermutationMNK{});
     if constexpr (is_underscore<decltype(perm_size)>::value) {
       return core_size;
     } else {
       return cute::max(core_size, perm_size);
     }
-  
+
     CUTE_GCC_UNREACHABLE;
   }
 
   CUTE_HOST_DEVICE constexpr
   auto
   get_layoutC_MN() const
   {
@@ -513,37 +512,37 @@
   ThrVMNK thr_vmnk_;
 
   template <class CTensor>
   CUTE_HOST_DEVICE constexpr
   auto
   partition_C(CTensor&& ctensor) const
   {
-    auto thr_tensor = make_tensor(std::forward<CTensor>(ctensor).data(), this->thrfrg_C(ctensor.layout()));
+    auto thr_tensor = make_tensor(static_cast<CTensor&&>(ctensor).data(), this->thrfrg_C(ctensor.layout()));
 
     auto thr_vmn = make_coord(get<0>(thr_vmnk_), make_coord(get<1>(thr_vmnk_), get<2>(thr_vmnk_)));
     return thr_tensor(thr_vmn, make_coord(_, repeat<rank<1,1>(thr_tensor)>(_)));
   }
 
   template <class ATensor>
   CUTE_HOST_DEVICE constexpr
   auto
   partition_A(ATensor&& atensor) const
   {
-    auto thr_tensor = make_tensor(std::forward<ATensor>(atensor).data(), this->thrfrg_A(atensor.layout()));
+    auto thr_tensor = make_tensor(static_cast<ATensor&&>(atensor).data(), this->thrfrg_A(atensor.layout()));
 
     auto thr_vmk = make_coord(get<0>(thr_vmnk_), make_coord(get<1>(thr_vmnk_), get<3>(thr_vmnk_)));
     return thr_tensor(thr_vmk, make_coord(_, repeat<rank<1,1>(thr_tensor)>(_)));
   }
 
   template <class BTensor>
   CUTE_HOST_DEVICE constexpr
   auto
   partition_B(BTensor&& btensor) const
   {
-    auto thr_tensor = make_tensor(std::forward<BTensor>(btensor).data(), this->thrfrg_B(btensor.layout()));
+    auto thr_tensor = make_tensor(static_cast<BTensor&&>(btensor).data(), this->thrfrg_B(btensor.layout()));
 
     auto thr_vnk = make_coord(get<0>(thr_vmnk_), make_coord(get<2>(thr_vmnk_), get<3>(thr_vmnk_)));
     return thr_tensor(thr_vnk, make_coord(_, repeat<rank<1,1>(thr_tensor)>(_)));
   }
 
   template <class CTensor>
   CUTE_HOST_DEVICE constexpr
@@ -712,14 +711,15 @@
 CUTE_HOST_DEVICE
 void
 print(MMA_Atom<MMA_Traits<Args...>> const&)
 {
   using Atom = MMA_Atom<MMA_Traits<Args...>>;
   print("MMA_Atom\n");
   print("  ThrID:      "); print(typename Atom::ThrID{});      print("\n");
+  print("  Shape_MNK:  "); print(typename Atom::Shape_MNK{});  print("\n");
   print("  LayoutA_TV: "); print(typename Atom::LayoutA_TV{}); print("\n");
   print("  LayoutB_TV: "); print(typename Atom::LayoutB_TV{}); print("\n");
   print("  LayoutC_TV: "); print(typename Atom::LayoutC_TV{}); print("\n");
 }
 
 template <class Atom, class TiledThr, class TiledPerm>
 CUTE_HOST_DEVICE
@@ -740,15 +740,23 @@
   print("ThrMMA\n");
   print("  Thr VMNK: "); print(thr_mma.thr_vmnk_); print("\n");
   print(static_cast<TiledMMA>(thr_mma));
 }
 
 template <class... Args>
 CUTE_HOST_DEVICE
-auto
+void
+print_latex(MMA_Atom<Args...> const& mma_atom)
+{
+  print_latex(make_tiled_mma(mma_atom));
+}
+
+template <class... Args>
+CUTE_HOST_DEVICE
+void
 print_latex(TiledMMA<Args...> const& mma)
 {
   auto layout_and_thrid_C = mma.get_layoutC_MN();
   auto layoutC_MN = get<0>(layout_and_thrid_C);
   auto thrID_C    = get<1>(layout_and_thrid_C);
 
   auto layout_and_thrid_A = mma.get_layoutA_MK();
@@ -760,15 +768,15 @@
   auto thrID_B    = get<1>(layout_and_thrid_B);
 
   print_latex_mma(layoutC_MN, thrID_C,
                   layoutA_MK, thrID_A,
                   layoutB_NK, thrID_B);
 }
 
-// MNK MMA Layout to console printer -- 8-value color coded by thread
+// MNK MMA Layout to console printer
 template <class LayoutC, class ThrIDC,
           class LayoutA, class ThrIDA,
           class LayoutB, class ThrIDB>
 CUTE_HOST_DEVICE
 void
 print_layout_mma(LayoutC const& C, ThrIDC const& TC,  // (m,n) -> (tid,vid)  and  tid -> thr_idx
                  LayoutA const& A, ThrIDA const& TA,  // (m,k) -> (tid,vid)  and  tid -> thr_idx
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -145,47 +145,47 @@
     // assert((void*)&C == (void*)&D);
 
     Tensor rC = recast<RegTypeC>(D);  // NOTE: D and C are same, so use mutable D
 
     //CUTE_STATIC_ASSERT_V(size(rC) == Int<RegNumC>{});
 
     if constexpr (detail::supports_output_scaling<MMATraits>::value) {
-      detail::explode_with_d_scaling(MMA_Op::fma,
-            rA, make_int_sequence<RegNumA>{},
-            rB, make_int_sequence<RegNumB>{},
-            rC, make_int_sequence<RegNumC>{},
-            traits.accumulate_);
+      detail::explode(MMA_Op::fma,
+                      rA, make_int_sequence<RegNumA>{},
+                      rB, make_int_sequence<RegNumB>{},
+                      rC, make_int_sequence<RegNumC>{},
+                      &(traits.accumulate_), seq<0>{});
     }
     else {
       detail::explode(MMA_Op::fma,
-                  rA, make_int_sequence<RegNumA>{},
-                  rB, make_int_sequence<RegNumB>{},
-                  rC, make_int_sequence<RegNumC>{});
+                      rA, make_int_sequence<RegNumA>{},
+                      rB, make_int_sequence<RegNumB>{},
+                      rC, make_int_sequence<RegNumC>{});
     }
   }
   else {
       Tensor rD = recast<RegTypeD>(D);
       Tensor rC = recast<RegTypeC>(C);
 
       CUTE_STATIC_ASSERT_V(size(rD) == Int<RegNumD>{});
       CUTE_STATIC_ASSERT_V(size(rC) == Int<RegNumC>{});
       if constexpr (detail::supports_output_scaling<MMATraits>::value) {
-        detail::explode_with_d_scaling(MMA_Op::fma,
+        detail::explode(MMA_Op::fma,
                         rD, make_int_sequence<RegNumD>{},
                         rA, make_int_sequence<RegNumA>{},
                         rB, make_int_sequence<RegNumB>{},
                         rC, make_int_sequence<RegNumC>{},
-                        traits.accumulate_);
+                        &(traits.accumulate_), seq<0>{});
       }
       else {
         detail::explode(MMA_Op::fma,
-                  rD, make_int_sequence<RegNumD>{},
-                  rA, make_int_sequence<RegNumA>{},
-                  rB, make_int_sequence<RegNumB>{},
-                  rC, make_int_sequence<RegNumC>{});
+                        rD, make_int_sequence<RegNumD>{},
+                        rA, make_int_sequence<RegNumA>{},
+                        rB, make_int_sequence<RegNumB>{},
+                        rC, make_int_sequence<RegNumC>{});
       }
   }
 }
 
 //
 // Accept mutable temporaries
 //
@@ -194,15 +194,15 @@
           class TD, class DLayout,
           class TA, class ALayout,
           class TB, class BLayout,
           class TC, class CLayout>
 CUTE_HOST_DEVICE constexpr
 void
 mma_unpack(MMA_Traits<MMA_Op, MMA_Args...> const& traits,
-           Tensor<TD, DLayout>      && D,
+           Tensor<TD, DLayout>     &&  D,
            Tensor<TA, ALayout> const&  A,
            Tensor<TB, BLayout> const&  B,
            Tensor<TC, CLayout> const&  C)
 {
   mma_unpack(traits, D, A, B, C);
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -28,20 +28,16 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/arch/mma_sm80.hpp>
 #include <cute/atom/mma_traits.hpp>
-
 #include <cute/layout.hpp>
-
-#include <cute/numeric/integer_subbyte.hpp>
-
-#include <cutlass/numeric_types.h>
+#include <cute/numeric/numeric_types.hpp>
 
 namespace cute
 {
 
 namespace {
 
 // (T32,V1) -> (M8,N8)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -204,15 +204,15 @@
 
   // Layout type
   constexpr GMMA::LayoutType LAYOUT_TYPE = GMMA::layout_type(u128_tensor);
   desc.bitfield.layout_type_ = uint8_t(LAYOUT_TYPE);
 
   // Start address (4LSB not included)
   uint32_t start_address = cast_smem_ptr_to_uint(raw_pointer_cast(u128_tensor.data()));
-  desc.bitfield.start_address_ = start_address >> 4;
+  desc.bitfield.start_address_ = static_cast<uint16_t>(start_address >> 4);
 
   constexpr uint8_t base_offset = 0;
   desc.bitfield.base_offset_ = base_offset;
 
   // LayoutType meta
   constexpr int W = LAYOUT_TYPE == GMMA::LayoutType::INTERLEAVE ? 1 :
                     LAYOUT_TYPE == GMMA::LayoutType::B32        ? 2 :
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/config.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/config.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -87,80 +87,76 @@
 // constexpr ... else" statement must actually return.  Thus, GCC
 // emits spurious "missing return statement" build warnings.
 // Developers can suppress these warnings by using the
 // CUTE_GCC_UNREACHABLE macro, which must be followed by a semicolon.
 // It's harmless to use the macro for other GCC versions or other
 // compilers, but it has no effect.
 #if ! defined(CUTE_GCC_UNREACHABLE)
-#  if defined(__clang__) || defined(__GNUC__)
+#  if defined(__GNUC__)
 #    define CUTE_GCC_UNREACHABLE __builtin_unreachable()
 #  else
 #    define CUTE_GCC_UNREACHABLE
 #  endif
 #endif
 
-#ifdef _MSC_VER
+#if defined(_MSC_VER)
 // Provides support for alternative operators 'and', 'or', and 'not'
-#include <iso646.h>
+#  include <iso646.h>
 #endif // _MSC_VER
 
 #if defined(__CUDACC_RTC__)
-#define CUTE_STL_NAMESPACE cuda::std
-#define CUTE_STL_NAMESPACE_IS_CUDA_STD
+#  define CUTE_STL_NAMESPACE cuda::std
+#  define CUTE_STL_NAMESPACE_IS_CUDA_STD
 #else
-#define CUTE_STL_NAMESPACE std
+#  define CUTE_STL_NAMESPACE std
 #endif
 
 //
 // Assertion helpers
 //
 
 #if defined(__CUDACC_RTC__)
-#include <cuda/std/cassert>
+#  include <cuda/std/cassert>
 #else
-#include <cassert>
+#  include <cassert>
 #endif
 
 #define CUTE_STATIC_V(x)            decltype(x)::value
 
 #define CUTE_STATIC_ASSERT          static_assert
 #define CUTE_STATIC_ASSERT_V(x,...) static_assert(decltype(x)::value, ##__VA_ARGS__)
 
+// Fail and print a message. Typically used for notification of a compiler misconfiguration.
 #if defined(__CUDA_ARCH__)
-#  define CUTE_RUNTIME_ASSERT(x) __brkpt()
+#  define CUTE_INVALID_CONTROL_PATH(x) assert(0 && x); printf(x); __brkpt()
 #else
-#  define CUTE_RUNTIME_ASSERT(x) assert(0 && x)
+#  define CUTE_INVALID_CONTROL_PATH(x) assert(0 && x); printf(x)
 #endif
 
 //
 // IO
 //
 
 #if !defined(__CUDACC_RTC__)
-#include <cstdio>
-#include <iostream>
-#include <iomanip>
+#  include <cstdio>
+#  include <iostream>
+#  include <iomanip>
 #endif
 
 //
 // Support
 //
 
 #include <cute/util/type_traits.hpp>
 
 //
 // Basic types
 //
 
-#include <cute/numeric/int.hpp>
-#include <cute/numeric/real.hpp>
-#include <cute/numeric/half.hpp>
-#include <cute/numeric/float8.hpp>
-#include <cute/numeric/bfloat.hpp>
-#include <cute/numeric/tfloat.hpp>
-#include <cute/numeric/complex.hpp>
+#include <cute/numeric/numeric_types.hpp>
+
 //
 // Debugging utilities
 //
 
 #include <cute/util/print.hpp>
 #include <cute/util/debug.hpp>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/alignment.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/alignment.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,15 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
-#include <cute/numeric/int.hpp>
+#include <cute/numeric/numeric_types.hpp>
 #include <cute/numeric/math.hpp>
 
 namespace cute
 {
 
 // Test if a pointer is aligned to N bytes
 template <int N>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/array.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -351,37 +351,37 @@
 template <class T, size_t N>
 CUTE_HOST_DEVICE constexpr
 void clear(array<T,N>& a)
 {
   a.fill(T(0));
 }
 
-template <typename T, size_t N>
+template <class T, size_t N>
 CUTE_HOST_DEVICE constexpr
 void fill(array<T,N>& a, T const& value)
 {
   a.fill(value);
 }
 
 template <class T, size_t N>
 CUTE_HOST_DEVICE constexpr
 void swap(array<T,N>& a, array<T,N>& b)
 {
   a.swap(b);
 }
 
 /// @return A cute::array of the elements of @c t in reverse order.
-template <typename T, size_t N>
-CUTE_HOST_DEVICE constexpr cute::array<T, N>
-reverse(cute::array<T, N> const& t) {
+template <class T, size_t N>
+CUTE_HOST_DEVICE constexpr
+cute::array<T,N> reverse(cute::array<T,N> const& t) 
+{
   if constexpr (N == 0u) {
     return t;
-  }
-  else {
-    cute::array<T, N> t_r{};
+  } else {
+    cute::array<T,N> t_r{};
     for (size_t k = 0; k < N; ++k) {
       t_r[k] = t[N - k - 1];
     }
     return t_r;
   }
 }
 
@@ -418,15 +418,15 @@
 }
 
 template <size_t I, class T, size_t N>
 CUTE_HOST_DEVICE constexpr
 T&& get(array<T,N>&& a)
 {
   static_assert(I < N, "Index out of range");
-  return std::move(a[I]);
+  return cute::move(a[I]);
 }
 
 } // end namespace cute
 
 namespace CUTE_STL_NAMESPACE
 {
 
@@ -438,35 +438,35 @@
 template <size_t I, class T, size_t N>
 struct tuple_element<I, cute::array<T,N>>
 {
   using type = T;
 };
 
 template <class T, size_t N>
-struct tuple_size<const cute::array<T,N>>
+struct tuple_size<cute::array<T,N> const>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, N>
 {};
 
 template <size_t I, class T, size_t N>
-struct tuple_element<I, const cute::array<T,N>>
+struct tuple_element<I, cute::array<T,N> const>
 {
   using type = T;
 };
 
 } // end namespace CUTE_STL_NAMESPACE
 
 #ifdef CUTE_STL_NAMESPACE_IS_CUDA_STD
 namespace std
 {
 
 #if defined(__CUDACC_RTC__)
 template <class... _Tp>
 struct tuple_size;
 
-template<size_t _Ip, class... _Tp>
+template <size_t _Ip, class... _Tp>
 struct tuple_element;
 #endif
 
 template <class T, size_t N>
 struct tuple_size<cute::array<T,N>>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, N>
 {};
@@ -474,19 +474,19 @@
 template <size_t I, class T, size_t N>
 struct tuple_element<I, cute::array<T,N>>
 {
   using type = T;
 };
 
 template <class T, size_t N>
-struct tuple_size<const cute::array<T,N>>
+struct tuple_size<cute::array<T,N> const>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, N>
 {};
 
 template <size_t I, class T, size_t N>
-struct tuple_element<I, const cute::array<T,N>>
+struct tuple_element<I, cute::array<T,N> const>
 {
   using type = T;
 };
 
 } // end namespace std
 #endif // CUTE_STL_NAMESPACE_IS_CUDA_STD
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/array_aligned.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array_aligned.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/array_subbyte.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/array_subbyte.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -33,37 +33,28 @@
            in a packed storage.
 */
 
 #pragma once
 
 #include <cute/config.hpp>
 
-#include <cute/numeric/int.hpp>           // sizeof_bits
+#include <cute/numeric/numeric_types.hpp>
 #include <cute/numeric/integral_constant.hpp>
 
 namespace cute
 {
-
-template <class T>
-struct is_subbyte {
-  static constexpr bool value = sizeof_bits_v<T> < 8;
-};
-
-template <class T>
-constexpr bool is_subbyte_v = is_subbyte<T>::value;
-
 //
 // Underlying subbyte storage type
 //
 template <class T>
-using subbyte_storage_type_t = conditional_t<(sizeof_bits_v<T> <=   8), uint8_t,
-                               conditional_t<(sizeof_bits_v<T> <=  16), uint16_t,
-                               conditional_t<(sizeof_bits_v<T> <=  32), uint32_t,
-                               conditional_t<(sizeof_bits_v<T> <=  64), uint64_t,
-                               conditional_t<(sizeof_bits_v<T> <= 128), uint128_t,
+using subbyte_storage_type_t = conditional_t<(cute::sizeof_bits_v<T> <=   8), uint8_t,
+                               conditional_t<(cute::sizeof_bits_v<T> <=  16), uint16_t,
+                               conditional_t<(cute::sizeof_bits_v<T> <=  32), uint32_t,
+                               conditional_t<(cute::sizeof_bits_v<T> <=  64), uint64_t,
+                               conditional_t<(cute::sizeof_bits_v<T> <= 128), uint128_t,
                                T>>>>>;
 
 template <class T> struct subbyte_iterator;
 template <class, class> struct swizzle_ptr;
 
 //
 // subbyte_reference
@@ -179,14 +170,19 @@
   }
 
   // Extract to type element_type
   CUTE_HOST_DEVICE constexpr
   operator element_type() const {
     return get();
   }
+
+  // Address
+  subbyte_iterator<T> operator&() const {
+    return {ptr_, idx_};
+  }
 };
 
 //
 // subbyte_iterator
 //   Random-access iterator over subbyte references
 //
 template <class T>
@@ -310,24 +306,24 @@
   }
 
   // Conversion to NewT_ with possible loss of subbyte index
   template <class NewT_>
   CUTE_HOST_DEVICE constexpr friend
   auto recast_ptr(subbyte_iterator const& x) {
     using NewT = conditional_t<(is_const_v<T>), NewT_ const, NewT_>;
-    if constexpr (is_subbyte<NewT>::value) {       // Making subbyte_iter, preserve the subbyte idx
+    if constexpr (cute::is_subbyte_v<NewT>) {       // Making subbyte_iter, preserve the subbyte idx
       return subbyte_iterator<NewT>(x.ptr_, x.idx_);
     } else {                                       // Not subbyte, assume/assert subbyte idx 0
       return reinterpret_cast<NewT*>(raw_pointer_cast(x));
     }
     CUTE_GCC_UNREACHABLE;
   }
 
   CUTE_HOST_DEVICE friend void print(subbyte_iterator x) {
-    printf("subptr[%db](%p.%u)", int(sizeof_bits<T>::value), x.ptr_, x.idx_);
+    printf("subptr[%db](%p.%u)", int(sizeof_bits_v<T>), x.ptr_, x.idx_);
   }
 };
 
 //
 // array_subbyte
 //   Statically sized array for non-byte-aligned data types
 //
@@ -365,16 +361,16 @@
   static constexpr size_type StorageElements = (N * sizeof_bits_v<value_type> + sizeof_bits_v<storage_type> - 1) / sizeof_bits_v<storage_type>;
 
   // Internal storage
   storage_type storage[StorageElements];
 
 public:
 
-  CUTE_HOST_DEVICE constexpr
-  array_subbyte() {}
+  constexpr
+  array_subbyte() = default;
 
   CUTE_HOST_DEVICE constexpr
   array_subbyte(array_subbyte const& x) {
     CUTE_UNROLL
     for (size_type i = 0; i < StorageElements; ++i) {
       storage[i] = x.storage[i];
     }
@@ -558,15 +554,15 @@
 }
 
 template <size_t I, class T, size_t N>
 CUTE_HOST_DEVICE constexpr
 T&& get(array_subbyte<T,N>&& a)
 {
   static_assert(I < N, "Index out of range");
-  return std::move(a[I]);
+  return cute::move(a[I]);
 }
 
 } // end namespace cute
 
 namespace CUTE_STL_NAMESPACE
 {
 
@@ -604,15 +600,15 @@
 namespace std
 {
 
 #if defined(__CUDACC_RTC__)
 template <class... _Tp>
 struct tuple_size;
 
-template<size_t _Ip, class... _Tp>
+template <size_t _Ip, class... _Tp>
 struct tuple_element;
 #endif
 
 template <class T, size_t N>
 struct tuple_size<cute::array_subbyte<T,N>>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, N>
 {};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/bit_field.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/bit_field.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -33,15 +33,15 @@
            be used in unions to bit-wise define parameters.
 */
 
 #pragma once
 
 #include <cute/config.hpp>
 
-#include <cute/numeric/int.hpp>   // uint_bit_t
+#include <cute/numeric/numeric_types.hpp>   // uint_bit_t
 
 namespace cute
 {
 
 class dummy_type {};
 
 template <uint32_t BitStart, uint32_t NumBits, class OtherValueType = dummy_type>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/cuda_types.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/cuda_types.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -92,19 +92,19 @@
 #if ! defined(_MSC_VER)
 constexpr
 #endif
 uint32_t&& get(dim3&& a)
 {
   static_assert(I < 3, "Index out of range");
   if constexpr (I == 0) {
-    return std::move(a.x);
+    return cute::move(a.x);
   } else if constexpr (I == 1) {
-    return std::move(a.y);
+    return cute::move(a.y);
   } else if constexpr (I == 2) {
-    return std::move(a.z);
+    return cute::move(a.z);
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 // Specialize cute::tuple-traits for external types
 template <>
@@ -158,19 +158,19 @@
 
 template <size_t I>
 CUTE_HOST_DEVICE constexpr
 uint32_t&& get(uint3&& a)
 {
   static_assert(I < 3, "Index out of range");
   if constexpr (I == 0) {
-    return std::move(a.x);
+    return cute::move(a.x);
   } else if constexpr (I == 1) {
-    return std::move(a.y);
+    return cute::move(a.y);
   } else if constexpr (I == 2) {
-    return std::move(a.z);
+    return cute::move(a.z);
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 // Specialize cute::tuple-traits for external types
 template <>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/tuple.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/tuple.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -122,26 +122,22 @@
 
 template <size_t N, class T>
 CUTE_HOST_DEVICE constexpr T& getv(EBO<N, T, false>& x)
 { return x.t_; }
 
 template <size_t N, class T>
 CUTE_HOST_DEVICE constexpr T&& getv(EBO<N, T, false>&& x)
-{ return static_cast<T&&>(x.t_); }
+{ return cute::move(x.t_); }
 
 template <class IdxSeq, class... T>
 struct TupleBase;
 
-// Base class of cute::tuple.
-// It inherits from EBO<i, t> for each (i, t) in (I..., T...).
-// The actual storage (for nonempty t) lives in the base classes.
-// index_sequence is a way to wrap up a sequence of zero or more
-// compile-time integer values in a single type.
-// We only ever use index_sequence<0, 1, ..., sizeof...(T)> in practice,
-// as the type alias TupleBase below indicates.
+// Base class of cute::tuple binds each element to an index
+// by inheriting from EBO<i, t> for each (i, t) in (I..., T...).
+// The storage (for nonempty t) lives in the base classes.
 template <size_t... I, class... T>
 struct TupleBase<index_sequence<I...>, T...>
     : EBO<I,T>...
 {
   CUTE_HOST_DEVICE constexpr
   TupleBase() {}
 
@@ -165,19 +161,14 @@
 //using TupleBase = detail::TupleBase<make_index_sequence<sizeof...(T)>, T...>;
 
 // This is the actual cute::tuple class.
 // The storage (if any) lives in TupleBase's EBO base classes.
 //
 // Inheriting from the above alias TupleBase
 // causes MSVC 2022 build errors when assigning one tuple to another:
-//
-// illegal member initialization:
-// 'TupleBase< /* template arguments */ >' is not a base or member
-//
-// Not using the alias or any kind of alias fixed the errors.
 // In summary: this is verbose as a work-around for MSVC build errors.
 template <class... T>
 struct tuple : detail::TupleBase<make_index_sequence<sizeof...(T)>, T...>
 {
   CUTE_HOST_DEVICE constexpr
   tuple() {}
 
@@ -361,18 +352,18 @@
 auto
 tuple_cat(T0 const& t0, T1 const& t1, T2 const& t2, T3 const& t3, T4 const& t4,
           index_sequence<I0...>, index_sequence<I1...>, index_sequence<I2...>, index_sequence<I3...>, index_sequence<I4...>)
 {
   return cute::make_tuple(get<I0>(t0)..., get<I1>(t1)..., get<I2>(t2)..., get<I3>(t3)..., get<I4>(t4)...);
 }
 
-template<class T0, class T1>
+template <class T0, class T1>
 struct tuple_cat_static;
 
-template<class... T0s, class... T1s>
+template <class... T0s, class... T1s>
 struct tuple_cat_static<tuple<T0s...>, tuple<T1s...>> {
   using type = tuple<T0s..., T1s...>;
 };
 
 } // end namespace detail
 
 CUTE_HOST_DEVICE constexpr
@@ -626,31 +617,25 @@
 
 namespace detail {
 
 template <class Tuple, size_t... Is>
 CUTE_HOST_DEVICE void print_tuple(Tuple const& t,
                                   index_sequence<Is...>, char s = '(', char e = ')')
 {
-  using eat = int[];
   using cute::print;
-  (void) eat {(print(s), 0),
-              (print(Is == 0 ? "" : ","), print(get<Is>(t)), 0)...,
-              (print(e), 0)};
+  ((void(print(Is == 0 ? s : ',')), void(print(get<Is>(t)))), ...); print(e);
 }
 
 #if !defined(__CUDACC_RTC__)
 template <class Tuple, std::size_t... Is>
 CUTE_HOST std::ostream& print_tuple_os(std::ostream& os, Tuple const& t,
                                        index_sequence<Is...>, char s = '(', char e = ')')
 {
-  using eat = int[];
-  (void) eat {(void(os << s), 0),
-              (void(os << (Is == 0 ? "" : ",") << get<Is>(t)), 0)...,
-              (void(os << e), 0)};
-  return os;
+  (void(os << (Is == 0 ? s : ',') << get<Is>(t)), ...);
+  return os << e;
 }
 #endif // !defined(__CUDACC_RTC__)
 
 } // end namespace detail
 
 template <class Tuple,
           __CUTE_REQUIRES(is_tuple<Tuple>::value)>
@@ -703,15 +688,15 @@
 namespace std
 {
 
 #if defined(__CUDACC_RTC__)
 template <class... _Tp>
 struct tuple_size;
 
-template<size_t _Ip, class... _Tp>
+template <size_t _Ip, class... _Tp>
 struct tuple_element;
 #endif
 
 template <class... T>
 struct tuple_size<cute::tuple<T...>>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, sizeof...(T)>
 {};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/container/type_list.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/container/type_list.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -104,15 +104,15 @@
 namespace std
 {
 
 #if defined(__CUDACC_RTC__)
 template <class... _Tp>
 struct tuple_size;
 
-template<size_t _Ip, class... _Tp>
+template <size_t _Ip, class... _Tp>
 struct tuple_element;
 #endif
 
 template <class... T>
 struct tuple_size<cute::type_list<T...>>
     : CUTE_STL_NAMESPACE::integral_constant<size_t, sizeof...(T)>
 {};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/int_tuple.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/int_tuple.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -214,29 +214,29 @@
 template <class Tuple>
 static constexpr int depth_v = depth_t<Tuple>::value;
 
 //
 // product
 //
 
-// Implementation of product (see below) as a function object
+// Implementation of product as a function object
 struct Product
 {
   template <class IntTuple>
   CUTE_HOST_DEVICE constexpr
   auto
   operator()(IntTuple const& a) const
   {
     if constexpr (is_tuple<IntTuple>::value) {
       if constexpr (tuple_size<IntTuple>::value == 0) {
         return Int<1>{};
       } else {
         return cute::transform_apply(a, Product{}, multiplies_unary_lfold{});
       }
-    } else {
+    } else if constexpr (cute::is_integral<IntTuple>::value) {
       return a;
     }
 
     CUTE_GCC_UNREACHABLE;
   }
 };
 // Callable product function object
@@ -244,15 +244,15 @@
 
 // Return a rank(t) tuple @a result such that get<i>(@a result) = product(get<i>(@a t))
 template <class Tuple>
 CUTE_HOST_DEVICE constexpr
 auto
 product_each(Tuple const& t)
 {
-  return transform(wrap(t), [](auto const& x) { return product(x); });
+  return transform(wrap(t), product);
 }
 
 // Take the product of Tuple at the leaves of TupleG
 template <class Tuple, class TupleG>
 CUTE_HOST_DEVICE constexpr
 auto
 product_like(Tuple const& tuple, TupleG const& guide)
@@ -321,18 +321,29 @@
 //
 
 template <class IntTupleA, class IntTupleB>
 CUTE_HOST_DEVICE constexpr
 auto
 ceil_div(IntTupleA const& a, IntTupleB const& b)
 {
-  if constexpr (is_tuple<IntTupleA>::value && is_tuple<IntTupleB>::value) {
-    static_assert(tuple_size<IntTupleA>::value >= tuple_size<IntTupleB>::value, "Mismatched ranks");
-    constexpr int R = tuple_size<IntTupleA>::value;        // Missing ranks in TupleB are implicitly 1
-    return transform(a, append<R>(b,Int<1>{}), [](auto const& x, auto const& y) { return ceil_div(x,y); });
+  if constexpr (is_tuple<IntTupleA>::value) {
+    if constexpr (is_tuple<IntTupleB>::value) {  // tuple tuple
+      static_assert(tuple_size<IntTupleA>::value >= tuple_size<IntTupleB>::value, "Mismatched ranks");
+      constexpr int R = tuple_size<IntTupleA>::value;        // Missing ranks in TupleB are implicitly 1
+      return transform(a, append<R>(b,Int<1>{}), [](auto const& x, auto const& y) { return ceil_div(x,y); });
+    } else {                                     // tuple int
+      auto const [result, rest] = fold(a, cute::make_tuple(cute::make_tuple(), b),
+        [] (auto const& init, auto const& ai) {
+          return cute::make_tuple(append(get<0>(init), ceil_div(ai, get<1>(init))), ceil_div(get<1>(init), ai));
+        });
+      return result;
+    }
+  } else
+  if constexpr (is_tuple<IntTupleB>::value) {    // int tuple
+    return ceil_div(a, product(b));
   } else {
     return (a + b - Int<1>{}) / b;
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
@@ -390,15 +401,15 @@
   if constexpr (is_tuple<IntTupleB>::value) {    // int tuple
     return shape_div(a, product(b));
   } else
   if constexpr (is_static<IntTupleA>::value && is_static<IntTupleB>::value) {
     static_assert(IntTupleA::value % IntTupleB::value == 0 || IntTupleB::value % IntTupleA::value == 0, "Static shape_div failure");
     return C<shape_div(IntTupleA::value, IntTupleB::value)>{};
   } else {                                       // int int
-    //assert(a % b == 0 || b % a == 0);          // Wave dynamic assertion
+    //assert(a % b == 0 || b % a == 0);          // Waive dynamic assertion
     return a / b != 0 ? a / b : signum(a) * signum(b);  // Division with rounding away from zero
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 /** Minimum for Shapes
@@ -851,78 +862,63 @@
 template <class T, class U>
 CUTE_HOST_DEVICE constexpr
 auto
 elem_geq(T const& t, U const& u) {
   return !elem_less(t, u);
 }
 
+namespace detail {
+
 /** Increment a (dynamic) coord lexicographically within a shape
+ * @pre is_congruent<Coord,Shape>::value
  * \code
  *    auto shape = make_shape(1,2,make_shape(2,3),3);
  *
  *   int i = 0;
  *   for (auto coord = repeat_like(shape, 0); back(coord) != back(shape); increment(coord, shape)) {
  *      std::cout << i++ << ": " << coord << std::endl;
  *   }
  *   assert(i == size(shape));
  * \endcode
  */
-template <class Coord, class Shape>
-CUTE_HOST_DEVICE constexpr
-void
-increment(Coord& coord, Shape const& shape);
-
-namespace detail {
-
-template <class Coord, class Shape, int I0, int... Is>
-CUTE_HOST_DEVICE constexpr
-void
-increment(Coord& coord, Shape const& shape, seq<I0,Is...>)
-{
-  cute::increment(get<I0>(coord), get<I0>(shape));
-  if constexpr (sizeof...(Is) != 0) {
-    if (back(get<I0>(coord)) == back(get<I0>(shape))) {
-      back(get<I0>(coord)) = 0;
-      increment(coord, shape, seq<Is...>{});
-    }
-  }
-}
-
-} // end namespace detail
-
-template <class Coord, class Shape>
+template <int I = 0, class Coord, class Shape>
 CUTE_HOST_DEVICE constexpr
 void
 increment(Coord& coord, Shape const& shape)
 {
-  if constexpr (is_integral<Coord>::value && is_integral<Shape>::value) {
+  if constexpr (is_integral<Coord>::value) {
     ++coord;
-  } else if constexpr (is_tuple<Coord>::value && is_tuple<Shape>::value) {
-    static_assert(tuple_size<Coord>::value == tuple_size<Shape>::value, "Mismatched ranks");
-    detail::increment(coord, shape, tuple_seq<Coord>{});
   } else {
-    static_assert(sizeof(Coord) == 0, "Invalid parameters");
+    increment(get<I>(coord), get<I>(shape));
+    if constexpr (I+1 < tuple_size<Coord>::value) {
+      if (back(get<I>(coord)) == back(get<I>(shape))) {
+        back(get<I>(coord)) = 0;
+        increment<I+1>(coord, shape);
+      }
+    }
   }
 }
 
+} // end namespace detail
+
 struct ForwardCoordIteratorSentinal
 {};
 
 // A forward iterator for a starting coordinate in a shape's domain, and a shape.
 // The starting coordinate may be zero but need not necessarily be.
 template <class Coord, class Shape>
 struct ForwardCoordIterator
 {
   static_assert(is_congruent<Coord, Shape>::value);
 
   CUTE_HOST_DEVICE constexpr
   Coord const& operator*() const { return coord; }
 
   CUTE_HOST_DEVICE constexpr
-  ForwardCoordIterator& operator++() { increment(coord, shape); return *this; }
+  ForwardCoordIterator& operator++() { detail::increment(coord, shape); return *this; }
 
   // Sentinel for the end of the implied range
   CUTE_HOST_DEVICE constexpr
   bool operator< (ForwardCoordIteratorSentinal const&) const { return back(coord) <  back(shape); }
   CUTE_HOST_DEVICE constexpr
   bool operator==(ForwardCoordIteratorSentinal const&) const { return back(coord) == back(shape); }
   CUTE_HOST_DEVICE constexpr
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/layout.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/layout.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -52,14 +52,17 @@
 
 template <class... Strides>
 using Step = cute::tuple<Strides...>;
 
 template <class... Coords>
 using Coord = cute::tuple<Coords...>;
 
+template <class... Layouts>
+using Tile = cute::tuple<Layouts...>;
+
 template <class... Ts>
 CUTE_HOST_DEVICE constexpr
 Shape<Ts...>
 make_shape(Ts const&... t) {
   return {t...};
 }
 template <class... Ts>
@@ -76,15 +79,25 @@
 }
 template <class... Ts>
 CUTE_HOST_DEVICE constexpr
 Coord<Ts...>
 make_coord(Ts const&... t) {
   return {t...};
 }
+template <class... Ts>
+CUTE_HOST_DEVICE constexpr
+Tile<Ts...>
+make_tile(Ts const&... t)
+{
+  return {t...};
+}
 
+//
+// Layout
+//
 
 template <class Shape, class Stride = LayoutLeft::Apply<Shape> >
 struct Layout
     : private cute::tuple<Shape, Stride>   // EBO for static layouts
 {
   // Expensive in compilation time...
   //static_assert(is_congruent<Shape, Stride>::value, "Shape and Stride must be congruent");
@@ -362,67 +375,65 @@
 CUTE_HOST_DEVICE constexpr
 auto
 make_layout(Shape const& shape, GenRowMajor)
 {
   return make_layout(shape, compact_row_major(shape));
 }
 
-// Follow the same ordering induced by the strides, but make the layout compact
+//
+// Advanced Layout constructions
+//
+
+// Make a compact layout with shape @a shape and strides following the order induced by @a order.
+// Dynamic values in @a order are ignored, considered large, and considered ordered from left to right.
+// Example:
+//   make_ordered_layout(Shape<_2,_2,_2,_2>{}, Step<_0,_2,_3,_1>{})
+//     ->  (_2,_2,_2,_2):(_1,_4,_8,_2)
+//   make_ordered_layout(make_shape(2,3,4,5), make_step(Int<2>{}, 67, 42, Int<50>{}))
+//     -> (2,3,4,5):(_1,10,30,2)
 template <class Shape, class Order>
 CUTE_HOST_DEVICE constexpr
 auto
 make_ordered_layout(Shape const& shape, Order const& order)
 {
-  static_assert(is_static<Order>::value);
   return make_layout(shape, compact_order(shape, order));
 }
 
-template <class Shape, class Stride>
-CUTE_HOST_DEVICE constexpr
-auto
-make_ordered_layout(Layout<Shape,Stride> const& layout)
-{
-  return make_ordered_layout(layout.shape(), layout.stride());
-}
-
-// Make a layout of the same shape that is either ordered or colmajor depending on staticness
+// Make a compact layout with the same shape as @a layout
+//   and strides following the order induced by @a layout.stride().
+// Static-0 strides in the input @a layout are preserved in the output.
+// Example:
+//   make_layout_like(Layout<Shape<_2,_2,_2,_2>, Stride<_0,_2,_4,_1>>{})
+//     ->  (_2,_2,_2,_2):(_0,_2,_4,_1)
+//   make_layout_like(make_layout(make_shape(2,3,4,5), make_stride(Int<0>{},42,Int<1>{},Int<0>{})))
+//     -> (2,3,4,5):(_0,4,_1,_0)
 template <class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 make_layout_like(Layout<Shape,Stride> const& layout)
 {
-  auto any_zero = any_of(layout.stride(), [](auto d) { return is_constant<0, decltype(d)>{}; });
-  if constexpr (any_zero) {
-    // If there are static-0 strides, then make a col-major layout that keeps those 0s
-    return make_layout(layout.shape(),
-                       compact_col_major(filter_zeros(layout.stride(), layout.shape())));
-  } else
-  if constexpr (is_static<Shape>::value && is_static<Stride>::value) {
-    // If the layout is fully static, then make a layout that follows the same order as the strides
-    // Assumes the strides are unique
-    return make_ordered_layout(layout.shape(), layout.stride());
-  } else {
-    return make_layout(layout.shape());
-  }
-
-  CUTE_GCC_UNREACHABLE;
+  return make_layout(layout.shape(),
+                     compact_order(filter_zeros(layout.stride(), layout.shape()), layout.stride()));
 }
 
-//
-// Make a layout of the same shape,
-//   with mode-0 being colmajor then following the mode order in layout
-//
+// Make a compact layout with the same shape as @a layout
+//   and strides following the order induced by @a layout.stride(),
+//   except mode-0 is always stride-1 and generated column-major.
+// The 0th mode is commonly used for MMA_Atoms or Copy_Atoms so this
+//   generates the 0th mode with LayoutLeft (preserving stride-0s) regardless of the reference layout
 template <class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 make_fragment_like(Layout<Shape,Stride> const& layout)
 {
   constexpr int R = Layout<Shape,Stride>::rank;
-  if constexpr (R > 1 && is_static<Shape>::value && is_static<Stride>::value) {
-    return tiled_product(make_layout(shape<0>(layout)), make_ordered_layout(take<1,R>(layout)));
+  if constexpr (R > 1 && is_static<Shape>::value) {
+    return tiled_product(make_layout(get<0>(layout.shape()),
+                                     compact_col_major(filter_zeros(get<0>(layout.stride()), get<0>(layout.shape())))),
+                         make_ordered_layout(take<1,R>(layout.shape()), take<1,R>(layout.stride())));
   } else {
     return make_layout(layout.shape());
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
@@ -454,27 +465,27 @@
 // Return the Is...th sublayout.
 // For Is... = <I0,I1,...,IN>, equivalent to get<IN>(...get<I1>(get<I0>(layout)))
 template <size_t... Is, class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 get(Layout<Shape,Stride> const& layout)
 {
-  return make_layout(get<Is...>(layout.shape()), 
+  return make_layout(get<Is...>(layout.shape()),
                      get<Is...>(layout.stride()));
 }
 
-// Return a new layout with only the modes in the range [B,E) 
+// Return a new layout with only the modes in the range [B,E)
 template <int B, int E, class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 take(Layout<Shape,Stride> const& layout)
 {
   static_assert(B < E, "take: empty range error");
   static_assert(0 <= B && E <= Layout<Shape,Stride>::rank, "take: range out of bounds");
-  return make_layout(take<B,E>(layout.shape()), 
+  return make_layout(take<B,E>(layout.shape()),
                      take<B,E>(layout.stride()));
 }
 
 // Return a new layout with only the modes Is... = <I0,I1,...,IN>
 template <int... Is, class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
@@ -486,15 +497,15 @@
 
 // Return a layout with depth at most 1
 template <class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 flatten(Layout<Shape,Stride> const& layout)
 {
-  return make_layout(flatten(layout.shape()), 
+  return make_layout(flatten(layout.shape()),
                      flatten(layout.stride()));
 }
 
 // Return a layout whose profile is congruent to TargetProfile
 // @pre Input layout is flat, flatten(@a layout) == @a layout
 // @pre Input layout can be folded to profile, rank(@a layout) == rank(flatten(@a target_profile))
 // @post congruent(@a result, @a target_profile)
@@ -743,29 +754,69 @@
     }
   } else if constexpr (is_constant<1, decltype(get<I>(old_shape))>::value) {
     // shape<I>(layout) == _1, skip it and continue
     return bw_coalesce<I-1>(old_shape, old_stride, new_shape, new_stride);
   } else if constexpr (is_constant<1, NewShape>::value) {
     // Replace our shape-1 with anything (Can only happen on input new_shape/new_stride)
     return bw_coalesce<I-1>(old_shape, old_stride, get<I>(old_shape), get<I>(old_stride));
-  } else if constexpr (is_constant<true, decltype(get<I>(old_shape) * get<I>(old_stride) == get<0>(new_stride))>::value) {
+  } else if constexpr (is_static<decltype(get<0>(new_shape))>::value &&
+                       is_constant<true, decltype(get<I>(old_shape) * get<I>(old_stride) == get<0>(new_stride))>::value) {
     // Merge modes because the shapes and strides match
     return bw_coalesce<I-1>(old_shape, old_stride,
                             replace_front(new_shape,  get<I>(old_shape) * get<0>(new_shape)),
                             replace_front(new_stride, get<I>(old_stride)));
   } else {
     // Can't replace or merge, so prepend a new mode
     return bw_coalesce<I-1>(old_shape, old_stride,
                             prepend(new_shape,  get<I>(old_shape)),
                             prepend(new_stride, get<I>(old_stride)));
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
+// cute::coalesce promises to not change the Layout as a function from integers to codomain.
+// It accomplishes this inside of the Layout's domain, but not always outside of the domain.
+//   Example: (_4,_1):(_1,_0) coalesces to _4:_1.
+// detail::coalesce_x preserves the Layout function inside its domain and outside.
+//
+// @post depth(@a result) <= 1
+// @post for all i, 0 <= i, @a layout(i) == @a result(i)
+template <class Shape, class Stride>
+CUTE_HOST_DEVICE constexpr
+auto
+coalesce_x(Layout<Shape,Stride> const& layout)
+{
+  auto flat_shape  = flatten(layout.shape());
+  auto flat_stride = flatten(layout.stride());
+
+  constexpr int R = decltype(rank(flat_shape))::value;
+  if constexpr (is_constant<1, decltype(get<R-1>(flat_shape))>::value) {
+    return detail::bw_coalesce<R-2>(flat_shape, flat_stride,             Int<2>{}, get<R-1>(flat_stride));
+  } else {
+    return detail::bw_coalesce<R-2>(flat_shape, flat_stride, get<R-1>(flat_shape), get<R-1>(flat_stride));
+  }
+}
+
+// Apply coalesce_x at the terminals of trg_profile
+template <class Shape, class Stride, class IntTuple>
+CUTE_HOST_DEVICE constexpr
+auto
+coalesce_x(Layout<Shape,Stride> const& layout, IntTuple const& trg_profile)
+{
+  if constexpr (is_tuple<IntTuple>::value) {
+    static_assert(tuple_size<IntTuple>::value <= Layout<Shape,Stride>::rank);
+    return cute::transform_layout(layout, trg_profile, [](auto const& l, auto const& t) { return coalesce_x(l,t); });
+  } else {
+    return coalesce_x(layout);
+  }
+
+  CUTE_GCC_UNREACHABLE;
+}
+
 } // end namespace detail
 
 // "Simplify" the layout by combining modes that are possible to combine
 // Does not respect the shape of the layout, but does preserve total size
 // @post size(@a result) == size(@a layout)
 // @post depth(@a result) <= 1
 // @post for all i, 0 <= i < size(@a layout), @a layout(i) == @a result(i)
@@ -793,14 +844,33 @@
   } else {
     return coalesce(layout);
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
+// Combine static and dynamic modes of a shape.
+// @post size(@a result) == size(@a shape)
+// @post depth(@a result) <= 1
+template <class Shape>
+CUTE_HOST_DEVICE constexpr
+auto
+coalesce(Shape const& shape)
+{
+  static_assert(is_integral<Shape>::value || is_tuple<Shape>::value);
+
+  return cute::fold_first(flatten(shape), [](auto const& init, auto const& a) {
+    if constexpr (is_static<decltype(back(init))>::value == is_static<decltype(a)>::value) {
+      return replace_back(init, back(init) * a);  // Both static or both dynamic, coalesce and replace
+    } else {
+      return append(init, a);                     // Can't coalesce, so append
+    }
+  });
+}
+
 // Replace the modes in layout that have a 0-stride with a 1-size
 template <class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 filter_zeros(Layout<Shape,Stride> const& layout)
 {
   return make_layout(filter_zeros(layout.stride(), layout.shape()), layout.stride());
@@ -904,93 +974,89 @@
 
 namespace detail {
 
 template <class LShape, class LStride,
           class RShape, class RStride>
 CUTE_HOST_DEVICE constexpr
 auto
-composition_impl(Layout<LShape,LStride> const& lhs,
+composition_impl(LShape const& lhs_shape, LStride const& lhs_stride,
                  RShape const& rhs_shape, RStride const& rhs_stride)
 {
   if constexpr (is_tuple<RShape>::value) {
     // Apply the right-distributivity of Layout composition
-    return transform_layout(rhs_shape, rhs_stride, [&](auto const& s, auto const& d) { return composition_impl(lhs, s, d); });
+    return transform_layout(rhs_shape, rhs_stride, [&](auto const& s, auto const& d) {
+      return composition_impl(lhs_shape, lhs_stride, s, d);
+    });
   } else
   if constexpr (is_scaled_basis<RStride>::value) {
     // Special case for a ScaledBasis stride
-    return composition_impl(get<RStride::mode()>(lhs), rhs_shape, rhs_stride.value());
+    return composition_impl(basis_get(rhs_stride, lhs_shape), basis_get(rhs_stride, lhs_stride),
+                            rhs_shape, basis_value(rhs_stride));
+  } else
+  if constexpr (is_constant<0, RStride>::value) {
+    // Special case shortcut for any static stride-0
+    return Layout<RShape, RStride>{rhs_shape, rhs_stride};
   } else
-  if constexpr (is_integral<RStride>::value) {
-    // Integral Rstride (and RShape)
+  if constexpr (is_integral<decltype(lhs_shape)>::value) {
+    // Special case shortcut for any integral LShape
+    return Layout{rhs_shape, rhs_stride * lhs_stride};
+  } else
+  if constexpr (is_constant<1, RStride>::value) {
+    // Special case shortcut for any static stride-1
+    constexpr int R  = rank_v<LShape>;
+    auto result_shape_0  = take<0,R-1>(lhs_shape);
+
+    // Mod out the rhs_shape from the lhs_shape
+    auto const [result_shape_1, rest_shape]  = fold(result_shape_0, cute::make_tuple(cute::make_tuple(), rhs_shape),
+      [] (auto const& init, auto const& si) {
+        return cute::make_tuple(append(get<0>(init), shape_min(abs(si), get<1>(init))), shape_div(get<1>(init), abs(si)));
+      });
 
-    // NOTE: Should only flatten once for efficiency
-    auto flat_shape  = flatten(lhs.shape());
-    [[maybe_unused]] auto flat_stride = flatten(lhs.stride());
-    [[maybe_unused]] constexpr int R  = rank(flat_shape);
-
-    if constexpr (is_constant<0, RStride>::value) {
-      // Special case shortcut for any static stride-0
-      return Layout<RShape, RStride>{rhs_shape, rhs_stride};
-    } else
-    if constexpr (is_integral<decltype(flat_shape)>::value) {
-      // Special case shortcut for any integral LShape
-      auto result_stride = rhs_stride * flat_stride;
-      return Layout<RShape, decltype(result_stride)>{rhs_shape, result_stride};
-    } else
-    if constexpr (is_constant<1, RStride>::value) {
-      // Special case shortcut for any static stride-1
-      auto result_shape_0  = take<0,R-1>(flat_shape);
-
-      // Mod out the rhs_shape from the lhs.shape()
-      auto const [result_shape_1, rest_shape]  = fold(result_shape_0, cute::make_tuple(cute::make_tuple(), rhs_shape),
-        [] (auto const& init, auto const& si) {
-          return cute::make_tuple(append(get<0>(init), shape_min(abs(si), get<1>(init))), shape_div(get<1>(init), abs(si)));
-        });
-
-      // Jump into coalesce and append (rest_shape, get<R-1>(lhs.stride())
-      return detail::bw_coalesce<R-2>(result_shape_1, flat_stride, rest_shape, get<R-1>(flat_stride));
-    } else
-    {
-      // General case
-      auto result_shape_0  = take<0,R-1>(flat_shape);
-      auto result_stride_0 = take<0,R-1>(flat_stride);
-
-      // Divide out the rhs_stride from the lhs.shape()
-      auto const [result_shape_1, rest_stride] = fold(result_shape_0, cute::make_tuple(cute::make_tuple(), rhs_stride),
-        [] (auto const& init, auto const& di) {
-          return cute::make_tuple(append(get<0>(init), shape_div(di, get<1>(init))), shape_div(get<1>(init), di));
-        });
-
-      // Apply any lhs.shape() changes to the stride
-      auto result_stride_1 = elem_scale(result_stride_0, shape_div(result_shape_0, result_shape_1));
-
-      // Mod out the rhs_shape from the lhs.shape()
-      auto const [result_shape_2, rest_shape] = fold(result_shape_1, cute::make_tuple(cute::make_tuple(), rhs_shape),
-        [] (auto const& init, auto const& si) {
-          return cute::make_tuple(append(get<0>(init), shape_min(abs(si), get<1>(init))), shape_div(get<1>(init), abs(si)));
-        });
+    // Jump into coalesce and append (rest_shape, get<R-1>(lhs_stride))
+    return detail::bw_coalesce<R-2>(result_shape_1, lhs_stride, rest_shape, get<R-1>(lhs_stride));
+  } else {
+    // General case: integral RShape and RStride, tuple LShape and LStride
+    constexpr int R  = rank_v<LShape>;
+    auto result_shape_0  = take<0,R-1>(lhs_shape);
+    auto result_stride_0 = take<0,R-1>(lhs_stride);
+
+    // Divide out the rhs_stride from the lhs_shape
+    auto const [result_shape_1, rest_stride] = fold(result_shape_0, cute::make_tuple(cute::make_tuple(), rhs_stride),
+      [] (auto const& init, auto const& di) {
+        return cute::make_tuple(append(get<0>(init), shape_div(di, get<1>(init))), shape_div(get<1>(init), di));
+      });
+
+    // Apply any lhs_shape changes to the stride
+    auto result_stride_1 = elem_scale(result_stride_0, shape_div(result_shape_0, result_shape_1));
+
+    // Mod out the rhs_shape from the lhs_shape
+    auto const [result_shape_2, rest_shape] = fold(result_shape_1, cute::make_tuple(cute::make_tuple(), rhs_shape),
+      [] (auto const& init, auto const& si) {
+        return cute::make_tuple(append(get<0>(init), shape_min(abs(si), get<1>(init))), shape_div(get<1>(init), abs(si)));
+      });
 
-      // Jump into coalesce and append (rest_shape, rest_stride * get<R-1>(lhs.stride())
-      return detail::bw_coalesce<R-2>(result_shape_2, result_stride_1, rest_shape, rest_stride * get<R-1>(flat_stride));
-    }
+    // Jump into coalesce and append (rest_shape, rest_stride * get<R-1>(lhs_stride))
+    return detail::bw_coalesce<R-2>(result_shape_2, result_stride_1, rest_shape, rest_stride * get<R-1>(lhs_stride));
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 } // end namespace detail
 
 template <class LShape, class LStride,
           class RShape, class RStride>
 CUTE_HOST_DEVICE constexpr
 auto
 composition(Layout<LShape,LStride> const& lhs,
             Layout<RShape,RStride> const& rhs)
 {
-  return detail::composition_impl(lhs, rhs.shape(), rhs.stride());
+  auto coprofile = repeat_like(decltype(coshape(rhs)){}, Int<0>{});
+  auto flat_lhs = detail::coalesce_x(lhs, coprofile);
+  return detail::composition_impl(flat_lhs.shape(), flat_lhs.stride(), rhs.shape(), rhs.stride());
 }
 
 template <class LShape, class LStride, class Tiler>
 CUTE_HOST_DEVICE constexpr
 auto
 composition(Layout<LShape,LStride> const& lhs,
             Tiler                  const& rhs)
@@ -998,15 +1064,16 @@
   if constexpr (is_tuple<Tiler>::value) {
     static_assert(tuple_size<Tiler>::value <= Layout<LShape,LStride>::rank);
     // Drop any modes of lhs that aren't hit by rhs
     return detail::transform_layout(lhs, rhs, [](auto const& l, auto const& r) { return composition(l,r); }, make_seq<tuple_size<Tiler>::value>{}, seq<>{}, seq<>{});
   } else if constexpr (is_underscore<Tiler>::value) {
     return lhs;
   } else if constexpr (is_integral<Tiler>::value) {
-    return detail::composition_impl(lhs, rhs, Int<1>{});
+    auto flat_lhs = detail::coalesce_x(lhs);
+    return detail::composition_impl(flat_lhs.shape(), flat_lhs.stride(), rhs, Int<1>{});
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 //
 // Complement
@@ -1018,22 +1085,22 @@
 //           For all j in [0, size(@a layout)),
 //               @a result(i) != @a layout(j)
 //
 
 namespace detail {
 
 // @pre @a layout has been filtered (flattened and no stride-0 or size-1 modes).
-template <class Shape, class Stride, class CoSizeHi>
+template <class Shape, class Stride, class CoTarget>
 CUTE_HOST_DEVICE constexpr
 auto
-complement(Shape const& shape, Stride const& stride, CoSizeHi const& cosize_hi)
+complement(Shape const& shape, Stride const& stride, CoTarget const& cotarget)
 {
   if constexpr (is_constant<0, Stride>::value) {
     // Special case for irreducible rank-1 stride-0 layout
-    return make_layout(cosize_hi);
+    return make_layout(coalesce(cotarget));
   } else {
     // General case
     constexpr int R = rank_v<Shape>;
     static_assert(R == 1 || is_static<Stride>::value,
                   "Dynamic-stride complement only for rank-1 layouts");
 
     // Should just be a sort and a fold...
@@ -1041,51 +1108,52 @@
     auto [shape_, stride_, result_shape_, result_stride] =
       fold(make_seq<R-1>{},
            cute::make_tuple(shape, stride, cute::make_tuple(), cute::make_tuple(Int<1>{})),
            [](auto const& init, auto i)
            {
               auto [shape, stride, result_shape, result_stride] = init;
               auto min_stride = cute::min(stride);
-              auto min_idx    = find(stride, min_stride);
+              auto min_idx    = cute::find(stride, min_stride);
               auto new_shape  = min_stride / get<i>(result_stride);
-              auto new_stride = get<min_idx>(shape) * min_stride;
+              auto new_stride = min_stride * get<min_idx>(shape);
               static_assert(not is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
 
               return cute::make_tuple(remove<min_idx>(shape),              // Remove the min_idx from shape
                                       remove<min_idx>(stride),             // Remove the min_idx from stride
                                       append(result_shape , new_shape ),   // new shape  = min_stride / last_stride
-                                      append(result_stride, new_stride));  // new stride = curr_shape * min_stride
+                                      append(result_stride, new_stride));  // new stride = min_stride * curr_shape
             });
 
     // Append the last shape mode
-    auto new_shape    = get<0>(stride_) / get<R-1>(result_stride);
+    auto new_shape    = get<0>(stride_) / get<R-1>(result_stride);         // new shape  = min_stride / last_stride
     static_assert(not is_constant<0, decltype(new_shape)>::value, "Non-injective Layout detected in complement.");
-    auto result_shape = append(result_shape_, new_shape);                  // new shape  = min_stride / last_stride
+    auto result_shape = append(result_shape_, new_shape);
 
     // Compute the rest_shape and rest_stride
-    auto rest_stride = get<0>(shape_) * get<0>(stride_);
-    auto rest_shape  = ceil_div(cosize_hi, rest_stride);
-
-    // Jump into coalesce and append (rest_shape, rest_stride)
-    return detail::bw_coalesce<R-1>(result_shape, result_stride, rest_shape, rest_stride);
+    auto new_stride  = get<0>(stride_) * get<0>(shape_);                   // new stride = min_stride * curr_shape
+    auto rest_shape  = coalesce(ceil_div(cotarget, new_stride));
+    auto rest_stride = compact_col_major(rest_shape, new_stride);
+
+    // Coalesce and append (rest_shape, rest_stride)
+    return coalesce(make_layout(make_shape (result_shape , rest_shape ),
+                                make_stride(result_stride, rest_stride)));
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 } // end namespace detail
 
-template <class Shape, class Stride, class CoSizeHi>
+template <class Shape, class Stride, class CoTarget>
 CUTE_HOST_DEVICE constexpr
 auto
-complement(Layout<Shape,Stride> const& layout, CoSizeHi const& cosize_hi)
+complement(Layout<Shape,Stride> const& layout, CoTarget const& cotarget)
 {
-  static_assert(cute::is_integral<CoSizeHi>::value, "Expected integral codomain size in complement.");
   auto filter_layout = filter(layout);
-  return detail::complement(filter_layout.shape(), filter_layout.stride(), cosize_hi);
+  return detail::complement(filter_layout.shape(), filter_layout.stride(), shape(cotarget));
 }
 
 template <class Shape, class Stride>
 CUTE_HOST_DEVICE constexpr
 auto
 complement(Layout<Shape,Stride> const& layout)
 {
@@ -1351,15 +1419,15 @@
 template <class LShape, class LStride,
           class TShape, class TStride>
 CUTE_HOST_DEVICE constexpr
 auto
 logical_divide(Layout<LShape,LStride> const& layout,
                Layout<TShape,TStride> const& tiler)
 {
-  return composition(layout, make_layout(tiler, complement(tiler, size(layout))));
+  return composition(layout, make_layout(tiler, complement(tiler, shape(layout))));
 }
 
 template <class LShape, class LStride, class Tiler>
 CUTE_HOST_DEVICE constexpr
 auto
 logical_divide(Layout<LShape,LStride> const& layout,
                Tiler                  const& tiler)
@@ -1372,14 +1440,31 @@
   } else if constexpr (is_integral<Tiler>::value) {
     return logical_divide(layout, make_layout(tiler));
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
+// Generalization of ceil_div for Layout lhs
+//   is effectively the "rest mode" of logical_divide.
+// Occurs in the calculation of gridDim, for example, for generalized tilers
+// Example:
+//   dim3 gridDim(size(ceil_div(problem_shape_M, cta_tiler_M)),
+//                size(ceil_div(problem_shape_N, cta_tiler_N)));
+// This does not consider compositional acceptance, so it may be the case that
+//   ceil_div produces a result while logical_divide (and friends) do not.
+template <class Target, class TShape, class TStride>
+CUTE_HOST_DEVICE constexpr
+auto
+ceil_div(Target                 const& target,
+         Layout<TShape,TStride> const& tiler)
+{
+  return complement(tiler, size(target));
+}
+
 //
 // Convenience operator
 //   that produces layouts like ((BLK_A,BLK_B,...),(a,b,...,x,y))
 //   by gathering the tile modes and residuals into a rank-2 result.
 //
 
 template <class LShape, class LStride,
@@ -1421,15 +1506,14 @@
   return result(repeat<R0>(_), repeat<R1>(_));
 }
 
 //
 // Logical product
 //
 
-// @post compatible()
 template <class LShape, class LStride,
           class TShape, class TStride>
 CUTE_HOST_DEVICE constexpr
 auto
 logical_product(Layout<LShape,LStride> const& block,
                 Layout<TShape,TStride> const& tiler)
 {
@@ -1497,15 +1581,15 @@
   auto R0 = rank<0>(result);
   auto R1 = rank<1>(result);
   return result(repeat<R0>(_), repeat<R1>(_));
 }
 
 //
 // Rank-sensitive products
-// 
+//
 
 // blocked_product -- Reproduce a block over a tiler.
 // Think of every element of "tiler" as a "block"
 //   and return the layout of the resulting structure.
 // @post rank(@a result) == cute::max(rank(@a block), rank(@a tiler))
 template <class TShape, class TStride,
           class UShape, class UStride>
@@ -1513,15 +1597,15 @@
 auto
 blocked_product(Layout<TShape,TStride> const& block,
                 Layout<UShape,UStride> const& tiler)
 {
   constexpr int R = cute::max(rank_v<TShape>, rank_v<UShape>);
 
   auto result = logical_product(append<R>(block), append<R>(tiler));
-  
+
   return coalesce(zip(get<0>(result), get<1>(result)), tuple_repeat<R>(Int<1>{}));
 }
 
 // raked_product -- Reproduce a block over a tiler with block-interleaving.
 // Think of every element of "tiler" as a "block", interleave those blocks,
 //   and return the layout of the resulting structure.
 // @post rank(@a result) == cute::max(rank(@a block), rank(@a tiler))
@@ -1541,15 +1625,15 @@
 
 // tile_to_shape -- Perform a product of a layout so that the result matches a target shape.
 // This is similar to blocked_product, but specifies the result shape instead of the
 //   product shape, which is more convenient in certain circumstances.
 // @param block The layout to repeat
 // @param trg_shape The target shape of the result
 // @param ord_shape The order of the modes of @a trg_shape to tile @a layout with.
-//                  Defaults to GenColMajor, so @a layout will repeat 
+//                  Defaults to GenColMajor, so @a layout will repeat
 //                    across the first mode first, the second mode second, etc
 //                  E.g. Step<_2,_1,_3> will cause @a layout to repeat
 //                    across the second mode first, the first mode second, and the third mode last.
 // @pre rank(@a block) <= rank(@a trg_shape)
 // @post compatible(@a trg_shape, shape(@a result))
 template <class Shape, class Stride,
           class TrgShape, class ModeOrder = LayoutLeft>
@@ -1655,15 +1739,15 @@
   using scale = decltype(trait_ratio(sizeof_bits<NewType>{}, sizeof_bits<OldType>{}));
   if constexpr (scale::num == 1 && scale::den == 1) {
     return layout;
   }
   else if constexpr (scale::num == 1) {
     return downcast<scale::den>(layout);
   }
-  else if constexpr (scale::den == 1) { 
+  else if constexpr (scale::den == 1) {
     return upcast<scale::num>(layout);
   }
   else {
     static_assert(dependent_false<scale>, "Recast not supported.");
   }
 
   CUTE_GCC_UNREACHABLE;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/layout_composed.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/layout_composed.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -174,14 +174,24 @@
 
   template <class... Layouts>
   CUTE_HOST_DEVICE constexpr
   auto
   tile(Layouts const&... layouts) const {
     return tiled_divide(*this, make_tile(layouts...));
   }
+
+  // Equality, return a static or dynamic boolean
+  template <class... Args>
+  CUTE_HOST_DEVICE constexpr
+  auto
+  operator==(ComposedLayout<Args...> const& other) const {
+    return this->layout_a() == other.layout_a() &&
+           this->layout_b() == other.layout_b() &&
+           this->offset()   == other.offset();
+  }
 };
 
 template <class A, class O, class B>
 struct is_layout<ComposedLayout<A,O,B>> : true_type {};
 
 template <class T>
 struct is_composed_layout : false_type {};
@@ -378,20 +388,20 @@
   return composition(composition(a, b.layout_a()), b.layout_b());
 }
 
 //
 // complement
 //
 
-template <class A, class O, class B, class CoSizeHi>
+template <class A, class O, class B, class CoTarget>
 CUTE_HOST_DEVICE constexpr
 auto
-complement(ComposedLayout<A,O,B> const& layout, CoSizeHi const& cosize_hi)
+complement(ComposedLayout<A,O,B> const& layout, CoTarget const& cotarget)
 {
-  return complement(layout.layout_b(), cosize_hi);
+  return complement(layout.layout_b(), cotarget);
 }
 
 template <class A, class O, class B>
 CUTE_HOST_DEVICE constexpr
 auto
 complement(ComposedLayout<A,O,B> const& layout)
 {
@@ -596,15 +606,15 @@
   using scale = decltype(trait_ratio(sizeof_bits<NewType>{}, sizeof_bits<OldType>{}));
   if constexpr (scale::num == 1 && scale::den == 1) {
     return layout;
   }
   else if constexpr (scale::num == 1) {
     return downcast<scale::den>(layout);
   }
-  else if constexpr (scale::den == 1) { 
+  else if constexpr (scale::den == 1) {
     return upcast<scale::num>(layout);
   }
   else {
     static_assert(dependent_false<scale>, "Recast not supported.");
   }
   CUTE_GCC_UNREACHABLE;
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -59,40 +59,35 @@
   ArithmeticTuple(U const&... u)
     : tuple<T...>(u...) {}
 };
 
 template <class... T>
 struct is_tuple<ArithmeticTuple<T...>> : true_type {};
 
+template <class... Ts>
+struct is_flat<ArithmeticTuple<Ts...>> : is_flat<tuple<Ts...>> {};
+
 template <class... T>
 CUTE_HOST_DEVICE constexpr
 auto
 make_arithmetic_tuple(T const&... t) {
   return ArithmeticTuple<T...>(t...);
 }
 
-template <class... T>
+template <class T>
 CUTE_HOST_DEVICE constexpr
 auto
-as_arithmetic_tuple(tuple<T...> const& t) {
-  return ArithmeticTuple<T...>(t);
-}
-
-template <class T, __CUTE_REQUIRES(is_integral<T>::value)>
-CUTE_HOST_DEVICE constexpr
-T const&
 as_arithmetic_tuple(T const& t) {
-  return t;
-}
-
-template <class... T>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(ArithmeticTuple<T...> const& t) {
-  return t;
+  if constexpr (is_tuple<T>::value) {
+    return detail::tapply(t, [](auto const& x){ return as_arithmetic_tuple(x); },
+                          [](auto const&... a){ return make_arithmetic_tuple(a...); },
+                          tuple_seq<T>{});
+  } else {
+    return t;
+  }
 }
 
 //
 // Numeric operators
 //
 
 // Addition
@@ -104,43 +99,88 @@
   return transform_apply(append<R>(t,Int<0>{}), append<R>(u,Int<0>{}), plus{}, [](auto const&... a){ return make_arithmetic_tuple(a...); });
 }
 
 template <class... T, class... U>
 CUTE_HOST_DEVICE constexpr
 auto
 operator+(ArithmeticTuple<T...> const& t, tuple<U...> const& u) {
-  constexpr int R = cute::max(int(sizeof...(T)), int(sizeof...(U)));
-  return transform_apply(append<R>(t,Int<0>{}), append<R>(u,Int<0>{}), plus{}, [](auto const&... a){ return make_arithmetic_tuple(a...); });
+  return t + ArithmeticTuple<U...>(u);
 }
 
 template <class... T, class... U>
 CUTE_HOST_DEVICE constexpr
 auto
 operator+(tuple<T...> const& t, ArithmeticTuple<U...> const& u) {
+  return ArithmeticTuple<T...>(t) + u;
+}
+
+// Subtraction
+template <class... T, class... U>
+CUTE_HOST_DEVICE constexpr
+auto
+operator-(ArithmeticTuple<T...> const& t, ArithmeticTuple<U...> const& u) {
   constexpr int R = cute::max(int(sizeof...(T)), int(sizeof...(U)));
-  return transform_apply(append<R>(t,Int<0>{}), append<R>(u,Int<0>{}), plus{}, [](auto const&... a){ return make_arithmetic_tuple(a...); });
+  return transform_apply(append<R>(t,Int<0>{}), append<R>(u,Int<0>{}), minus{}, [](auto const&... a){ return make_arithmetic_tuple(a...); });
+}
+
+template <class... T, class... U>
+CUTE_HOST_DEVICE constexpr
+auto
+operator-(ArithmeticTuple<T...> const& t, tuple<U...> const& u) {
+  return t - ArithmeticTuple<U...>(u);
+}
+
+template <class... T, class... U>
+CUTE_HOST_DEVICE constexpr
+auto
+operator-(tuple<T...> const& t, ArithmeticTuple<U...> const& u) {
+  return ArithmeticTuple<T...>(t) - u;
+}
+
+// Negation
+template <class... T>
+CUTE_HOST_DEVICE constexpr
+auto
+operator-(ArithmeticTuple<T...> const& t) {
+  return transform_apply(t, negate{}, [](auto const&... a){ return make_arithmetic_tuple(a...); });
 }
 
 //
 // Special cases
 //
 
 template <auto t, class... U>
 CUTE_HOST_DEVICE constexpr
 ArithmeticTuple<U...> const&
 operator+(C<t>, ArithmeticTuple<U...> const& u) {
-  static_assert(t == 0, "Artihmetic tuple op+ error!");
+  static_assert(t == 0, "Arithmetic tuple op+ error!");
   return u;
 }
 
 template <class... T, auto u>
 CUTE_HOST_DEVICE constexpr
 ArithmeticTuple<T...> const&
 operator+(ArithmeticTuple<T...> const& t, C<u>) {
-  static_assert(u == 0, "Artihmetic tuple op+ error!");
+  static_assert(u == 0, "Arithmetic tuple op+ error!");
+  return t;
+}
+
+template <auto t, class... U>
+CUTE_HOST_DEVICE constexpr
+ArithmeticTuple<U...> const&
+operator-(C<t>, ArithmeticTuple<U...> const& u) {
+  static_assert(t == 0, "Arithmetic tuple op- error!");
+  return -u;
+}
+
+template <class... T, auto u>
+CUTE_HOST_DEVICE constexpr
+ArithmeticTuple<T...> const&
+operator-(ArithmeticTuple<T...> const& t, C<u>) {
+  static_assert(u == 0, "Arithmetic tuple op- error!");
   return t;
 }
 
 //
 // ArithmeticTupleIterator
 //
 
@@ -237,14 +277,34 @@
     return t;
   }
   CUTE_GCC_UNREACHABLE;
 }
 
 namespace detail {
 
+template <class T, int... I>
+CUTE_HOST_DEVICE constexpr
+auto
+to_atuple_i(T const& t, seq<I...>) {
+  return make_arithmetic_tuple((void(I),Int<0>{})..., t);
+}
+
+} // end namespace detail
+
+// Turn a ScaledBases<T,N> into a rank-N+1 ArithmeticTuple
+//    with N prefix 0s:  (_0,_0,...N...,_0,T)
+template <class T, int N>
+CUTE_HOST_DEVICE constexpr
+auto
+as_arithmetic_tuple(ScaledBasis<T,N> const& t) {
+  return detail::to_atuple_i(as_arithmetic_tuple(t.value()), make_seq<N>{});
+}
+
+namespace detail {
+
 template <int... Ns>
 struct Basis;
 
 template <>
 struct Basis<> {
   using type = Int<1>;
 };
@@ -263,88 +323,22 @@
 // E<0,0> := ((_1,_0,_0,...),_0,_0,...)
 // E<0,1> := ((_0,_1,_0,...),_0,_0,...)
 // E<1,0> := (_0,(_1,_0,_0,...),_0,...)
 // E<1,1> := (_0,(_0,_1,_0,...),_0,...)
 template <int... N>
 using E = typename detail::Basis<N...>::type;
 
-namespace detail {
-
-template <class T, int... I, int... J>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(T const& t, seq<I...>, seq<J...>) {
-  return make_arithmetic_tuple((void(I),Int<0>{})..., t, (void(J),Int<0>{})...);
-}
-
-template <class... T, int... I, int... J>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(ArithmeticTuple<T...> const& t, seq<I...>, seq<J...>) {
-  return make_arithmetic_tuple(get<I>(t)..., (void(J),Int<0>{})...);
-}
-
-} // end namespace detail
-
-// Turn a ScaledBases<T,N> into a rank-M ArithmeticTuple
-//    with N prefix 0s:  (_0,_0,...N...,_0,T,_0,...,_0,_0)
-template <int M, class T, int N>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(ScaledBasis<T,N> const& t) {
-  static_assert(M > N, "Mismatched ranks");
-  return detail::as_arithmetic_tuple(t.value(), make_seq<N>{}, make_seq<M-N-1>{});
-}
-
-// Turn a ScaledBases<T,N> into a rank-N ArithmeticTuple
-//    with N prefix 0s:  (_0,_0,...N...,_0,T)
-template <class T, int N>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(ScaledBasis<T,N> const& t) {
-  return as_arithmetic_tuple<N+1>(t);
-}
-
-// Turn an ArithmeticTuple into a rank-M ArithmeticTuple
-//    with postfix 0s:  (t0,t1,t2,...,_0,...,_0,_0)
-template <int M, class... T>
-CUTE_HOST_DEVICE constexpr
-auto
-as_arithmetic_tuple(ArithmeticTuple<T...> const& t) {
-  static_assert(M >= sizeof...(T), "Mismatched ranks");
-  return detail::as_arithmetic_tuple(t, make_seq<int(sizeof...(T))>{}, make_seq<M-int(sizeof...(T))>{});
-}
-
-template <class T, int M, class U>
-CUTE_HOST_DEVICE constexpr
-auto
-safe_div(ScaledBasis<T,M> const& b, U const& u)
-{
-  auto t = safe_div(b.value(), u);
-  return ScaledBasis<decltype(t),M>{t};
-}
-
-template <class T, int M, class U>
-CUTE_HOST_DEVICE constexpr
-auto
-shape_div(ScaledBasis<T,M> const& b, U const& u)
-{
-  auto t = shape_div(b.value(), u);
-  return ScaledBasis<decltype(t),M>{t};
-}
-
 template <class Shape>
 CUTE_HOST_DEVICE constexpr
 auto
 make_basis_like(Shape const& shape)
 {
   if constexpr (is_integral<Shape>::value) {
     return Int<1>{};
-  }
-  else {
+  } else {
     // Generate bases for each rank of shape
     return transform(tuple_seq<Shape>{}, shape, [](auto I, auto si) {
       // Generate bases for each rank of si and add an i on front
       using I_type = decltype(I);
       return transform_leaf(make_basis_like(si), [](auto e) {
         // MSVC has trouble capturing variables as constexpr,
         // so that they can be used as template arguments.
@@ -356,14 +350,36 @@
       });
     });
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
+//
+// Arithmetic
+//
+
+template <class T, int M, class U>
+CUTE_HOST_DEVICE constexpr
+auto
+safe_div(ScaledBasis<T,M> const& b, U const& u)
+{
+  auto t = safe_div(b.value(), u);
+  return ScaledBasis<decltype(t),M>{t};
+}
+
+template <class T, int M, class U>
+CUTE_HOST_DEVICE constexpr
+auto
+shape_div(ScaledBasis<T,M> const& b, U const& u)
+{
+  auto t = shape_div(b.value(), u);
+  return ScaledBasis<decltype(t),M>{t};
+}
+
 // Equality
 template <class T, int N, class U, int M>
 CUTE_HOST_DEVICE constexpr
 auto
 operator==(ScaledBasis<T,N> const& t, ScaledBasis<U,M> const& u) {
   return bool_constant<M == N>{} && t.value() == u.value();
 }
@@ -380,77 +396,58 @@
 CUTE_HOST_DEVICE constexpr
 false_type
 operator==(T const&, ScaledBasis<U,M> const&) {
   return {};
 }
 
 // Abs
-template <int N, class T>
+template <class T, int N>
 CUTE_HOST_DEVICE constexpr
 auto
 abs(ScaledBasis<T,N> const& e) {
   return ScaledBasis<decltype(abs(e.value())),N>{abs(e.value())};
 }
 
 // Multiplication
-template <class A, int N, class T>
+template <class A, class T, int N>
 CUTE_HOST_DEVICE constexpr
 auto
 operator*(A const& a, ScaledBasis<T,N> const& e) {
   auto r = a * e.value();
   return ScaledBasis<decltype(r),N>{r};
 }
 
-template <int N, class T, class B>
+template <class T, int N, class B>
 CUTE_HOST_DEVICE constexpr
 auto
 operator*(ScaledBasis<T,N> const& e, B const& b) {
   auto r = e.value() * b;
   return ScaledBasis<decltype(r),N>{r};
 }
 
 // Addition
-template <int N, class T, class... U>
-CUTE_HOST_DEVICE constexpr
-auto
-operator+(ScaledBasis<T,N> const& t, ArithmeticTuple<U...> const& u) {
-  constexpr int R = cute::max(N+1, int(sizeof...(U)));
-  return as_arithmetic_tuple<R>(t) + as_arithmetic_tuple<R>(u);
-}
-
-template <class... T, int M, class U>
-CUTE_HOST_DEVICE constexpr
-auto
-operator+(ArithmeticTuple<T...> const& t, ScaledBasis<U,M> const& u) {
-  constexpr int R = cute::max(int(sizeof...(T)), M+1);
-  return as_arithmetic_tuple<R>(t) + as_arithmetic_tuple<R>(u);
-}
-
-template <int N, class T, class... U>
+template <class T, int N, class U, int M>
 CUTE_HOST_DEVICE constexpr
 auto
-operator+(ScaledBasis<T,N> const& t, tuple<U...> const& u) {
-  constexpr int R = cute::max(N+1, int(sizeof...(U)));
-  return as_arithmetic_tuple<R>(t) + as_arithmetic_tuple(u);
+operator+(ScaledBasis<T,N> const& t, ScaledBasis<U,M> const& u) {
+  return as_arithmetic_tuple(t) + as_arithmetic_tuple(u);
 }
 
-template <class... T, int M, class U>
+template <class T, int N, class... U>
 CUTE_HOST_DEVICE constexpr
 auto
-operator+(tuple<T...> const& t, ScaledBasis<U,M> const& u) {
-  constexpr int R = cute::max(int(sizeof...(T)), M+1);
-  return as_arithmetic_tuple(t) + as_arithmetic_tuple<R>(u);
+operator+(ScaledBasis<T,N> const& t, ArithmeticTuple<U...> const& u) {
+  return as_arithmetic_tuple(t) + u;
 }
 
-template <int N, class T, int M, class U>
+template <class... T, class U, int M>
 CUTE_HOST_DEVICE constexpr
 auto
-operator+(ScaledBasis<T,N> const& t, ScaledBasis<U,M> const& u) {
-  constexpr int R = cute::max(N+1,M+1);
-  return as_arithmetic_tuple<R>(t) + as_arithmetic_tuple<R>(u);
+operator+(ArithmeticTuple<T...> const& t, ScaledBasis<U,M> const& u) {
+  return t + as_arithmetic_tuple(u);
 }
 
 template <auto t, class U, int M>
 CUTE_HOST_DEVICE constexpr
 auto
 operator+(C<t>, ScaledBasis<U,M> const& u) {
   static_assert(t == 0, "ScaledBasis op+ error!");
@@ -527,15 +524,15 @@
 namespace std
 {
 
 #if defined(__CUDACC_RTC__)
 template <class... _Tp>
 struct tuple_size;
 
-template<size_t _Ip, class... _Tp>
+template <size_t _Ip, class... _Tp>
 struct tuple_element;
 #endif
 
 template <class... T>
 struct tuple_size<cute::ArithmeticTuple<T...>>
   : CUTE_STL_NAMESPACE::integral_constant<size_t, sizeof...(T)>
 {};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/bfloat.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp`

 * *Files 11% similar despite different names*

```diff
@@ -26,28 +26,10 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
-#include <cute/config.hpp>
-
-#include <vector_types.h>
-#include <cutlass/numeric_types.h>
-
-namespace cute {
-
-using cutlass::bfloat16_t;
-
-//
-// Display utilities
-//
-
-#if !defined(__CUDACC_RTC__)
-CUTE_HOST std::ostream& operator<<(std::ostream& os, bfloat16_t const& v)
-{
-  return os << float(v);
-}
-#endif
-
-} // end namespace cute
+// Simply import .h version of header so as to avoid breaking any existing CUTLASS builds
+// after .hpp was changed to .h
+#include "cutlass/kernel_hardware_info.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/complex.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/complex.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -26,41 +26,44 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
-#include <cute/config.hpp>
-#include <cute/util/type_traits.hpp>
 #include <cutlass/complex.h>
+#include <cute/util/type_traits.hpp>
+#include <cute/numeric/numeric_types.hpp>
 
 namespace cute
 {
 
 using cutlass::complex;
 using cutlass::is_complex;
 using cutlass::RealType;
 using cutlass::real;
 using cutlass::imag;
 using cutlass::conj;
 
+template <class T>
+static constexpr auto is_complex_v = is_complex<T>::value;
+
 /// Fused multiply-add for complex numbers
 template <class T>
 CUTE_HOST_DEVICE constexpr
 void
 fma(complex<T>      & d,
     complex<T> const& a,
     complex<T> const& b,
     complex<T> const& c)
 {
-  d.real(fma( a.real(), b.real(), c.real()));
-  d.imag(fma( a.real(), b.imag(), c.imag()));
-  d.real(fma(-a.imag(), b.imag(), d.real()));
-  d.imag(fma( a.imag(), b.real(), d.imag()));
+  fma(d.real(),  a.real(), b.real(), c.real());
+  fma(d.imag(),  a.real(), b.imag(), c.imag());
+  fma(d.real(), -a.imag(), b.imag(), d.real());
+  fma(d.imag(),  a.imag(), b.real(), d.imag());
 }
 
 /// Fused multiply-add for triplets
 template <class T>
 CUTE_HOST_DEVICE constexpr
 void
 fma(complex<T> const& a,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/float8.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/test_unit_core.cpp`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,20 +24,18 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#pragma once
+/** \file
+    \brief Unit tests for CUTLASS core
+*/
 
-#include <cute/config.hpp>
+#include "../common/cutlass_unit_test.h"
 
-#include <vector_types.h>
-#include <cutlass/numeric_types.h>
-
-namespace cute {
-
-using cutlass::float_e4m3_t;
-using cutlass::float_e5m2_t;
-
-} // end namespace cute
+int main(int argc, char* arg[]) {
+  FilterArchitecture();
+  ::testing::InitGoogleTest(&argc, arg);
+  return RUN_ALL_TESTS();
+}
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/half.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,18 +24,15 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#pragma once
 
-#include <cute/config.hpp>
-#include <vector_types.h>
-#include <cutlass/numeric_types.h>
+#pragma once
 
-namespace cute {
+#include "cutlass/cutlass.h"
+#include "cutlass/numeric_types.h"
 
-using cutlass::half_t;
+// integer_sequence moved to cutlass/numeric_types.h
 
-} // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integer_sequence.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/integer_subbyte.h`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,212 +24,245 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*!
+    \file
+    \brief Defines a class for using integer types smaller than one byte in host or
+      device code.
+*/
+
 #pragma once
 
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/cstdint>
 #else
 #include <cstdint>
 #endif
 
-#include <cutlass/integer_subbyte.h>
-
-#include <cute/config.hpp>
-#include <cute/util/type_traits.hpp>
+#include "cutlass/cutlass.h"
+#include "cutlass/numeric_size.h"
+#include "cutlass/platform/platform.h"
 
-namespace cute {
+namespace cutlass {
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <int Bits, bool Signed = true>
-struct integer_subbyte
-{
+struct integer_subbyte {
   /// Storage type
   using Storage = uint8_t;
 
   /// Number of bits
   static_assert(Bits <= 8*sizeof(Storage), "Require a subbyte of bits in integer_subbyte");
 
   /// External type
-  using xint_t = typename conditional<Signed, int, unsigned>::type;
+  using xint_t = typename platform::conditional<Signed, int, unsigned>::type;
 
   /// Bitmask for truncation from larger integers
-  static constexpr Storage bits_mask_ = Storage((1 << Bits) - 1);
+  static constexpr Storage bits_mask_ = Storage(Storage(-1) >> (8 - Bits));
   /// Bitmask for the sign bit
   static constexpr Storage sign_mask_ = Storage((Signed ? 1 : 0) << (Bits - 1));
 
   //
   // Data members
   //
 
   Storage storage;
 
   //
   // Methods
   //
 
   /// No operation
-  CUTE_HOST_DEVICE constexpr
-  integer_subbyte() {}
+  integer_subbyte() = default;
 
   /// Conversion from integer type
-  CUTE_HOST_DEVICE constexpr
-  integer_subbyte(int value)   // NOTE: Sign extension?
+  CUTLASS_HOST_DEVICE explicit
+  integer_subbyte(int value)
       : storage(reinterpret_cast<Storage const&>(value) & bits_mask_) {}
 
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE explicit
   integer_subbyte(unsigned value)
       : storage(reinterpret_cast<Storage const&>(value) & bits_mask_) {}
 
+  CUTLASS_HOST_DEVICE explicit
+  integer_subbyte(double value) {
+    xint_t tmp = static_cast<xint_t>(value);
+    storage = reinterpret_cast<Storage const &>(tmp) & bits_mask_;
+  }
+
   /// Convert to int or unsigned
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   operator xint_t() const {
     if (sign_mask_ & storage) {  // Sign extend
       return xint_t(storage) | ~xint_t(bits_mask_);
     } else {
       return xint_t(storage);
     }
   }
 
   /// Equality
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator==(integer_subbyte const& rhs) const {
     return storage == rhs.storage;
   }
 
   /// Inequality
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator!=(integer_subbyte const& rhs) const {
     return storage != rhs.storage;
   }
 
   /// Less than or equal
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator<=(integer_subbyte const& rhs) const {
     if (sign_mask_ & storage) {
       return !(rhs.storage < storage);
     } else {
       return storage <= rhs.storage;
     }
   }
 
   /// Less than
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator<(integer_subbyte const& rhs) const {
     if (sign_mask_ & storage) {
       return !(rhs.storage <= storage);
     } else {
       return storage < rhs.storage;
     }
   }
 
   /// Greater than or equal
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator>=(integer_subbyte const& rhs) const {
     return !(*this < rhs);
   }
 
   /// Greater than
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   bool operator>(integer_subbyte const& rhs) const {
     return !(*this <= rhs);
   }
 };
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// 1-bit unsigned integer type
+/// 1-bit Unsigned integer type
 using uint1b_t = integer_subbyte<1, false>;
 
-/// 2-bit integer type
+/// 2-bit Integer type
 using int2b_t = integer_subbyte<2, true>;
 
-/// 2-bit unsigned integer type
+/// 2-bit Unsigned integer type
 using uint2b_t = integer_subbyte<2, false>;
 
-/// 4-bit integer type
+/// 4-bit Integer type
 using int4b_t = integer_subbyte<4, true>;
 
-/// 4-bit unsigned integer type
+/// 4-bit Unsigned integer type
 using uint4b_t = integer_subbyte<4, false>;
 
 /// 1-bit binary type
 using bin1_t = bool;
 
-} // namespace cute
-
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if !defined(__CUDACC_RTC__)
+template <int Bits, bool Signed>
+struct sizeof_bits<integer_subbyte<Bits,Signed>> {
+  static constexpr int value = Bits;
+};
+
+/// Defines the size of an element in bits - specialized for bin1_t
+template <>
+struct sizeof_bits<bin1_t> {
+  static constexpr int value = 1;
+};
 
-#include <limits>
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-namespace CUTE_STL_NAMESPACE {
+namespace platform {
 
 template <>
-struct numeric_limits<cute::uint1b_t> {
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint1b_t const lowest() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint1b_t const min() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint1b_t const max() noexcept { return 1; }
+struct numeric_limits<cutlass::int4b_t> {
+  CUTLASS_HOST_DEVICE static
+  cutlass::int4b_t const lowest() noexcept { return int4b_t{-8};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::int4b_t const max() noexcept { return int4b_t{7};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::int4b_t const min() noexcept { return lowest();}
+
   static constexpr bool is_integer = true;
-  static constexpr bool is_signed = false;
+  static constexpr bool is_signed = true;
 };
 
 template <>
-struct numeric_limits<cute::int2b_t> {
-  CUTE_HOST_DEVICE static constexpr
-  cute::int2b_t lowest() noexcept { return -2; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::int2b_t min() noexcept { return -2; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::int2b_t max() noexcept { return 1; }
+struct numeric_limits<cutlass::uint4b_t> {
+  CUTLASS_HOST_DEVICE static
+ cutlass::uint4b_t const lowest() noexcept { return uint4b_t{0};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint4b_t const max() noexcept { return uint4b_t{15};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint4b_t const min() noexcept { return lowest();}
+
   static constexpr bool is_integer = true;
-  static constexpr bool is_signed = true;
+  static constexpr bool is_signed = false;
 };
 
 template <>
-struct numeric_limits<cute::uint2b_t> {
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint2b_t const lowest() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint2b_t const min() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint2b_t const max() noexcept { return 3; }
+struct numeric_limits<cutlass::uint1b_t> {
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint1b_t const lowest() noexcept { return uint1b_t{0};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint1b_t const max() noexcept { return uint1b_t{1};}
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint1b_t const min() noexcept { return lowest();}
+
   static constexpr bool is_integer = true;
   static constexpr bool is_signed = false;
 };
 
 template <>
-struct numeric_limits<cute::int4b_t> {
-  CUTE_HOST_DEVICE static constexpr
-  cute::int4b_t lowest() noexcept { return -8; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::int4b_t min() noexcept { return -8; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::int4b_t max() noexcept { return 7; }
+struct numeric_limits<cutlass::int2b_t> {
+  CUTLASS_HOST_DEVICE static
+  cutlass::int2b_t lowest() noexcept { return int2b_t{-2}; }
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::int2b_t min() noexcept { return lowest(); }
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::int2b_t max() noexcept { return int2b_t{1}; }
+
   static constexpr bool is_integer = true;
   static constexpr bool is_signed = true;
 };
 
 template <>
-struct numeric_limits<cute::uint4b_t> {
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint4b_t const lowest() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint4b_t const min() noexcept { return 0; }
-  CUTE_HOST_DEVICE static constexpr
-  cute::uint4b_t const max() noexcept { return 15; }
+struct numeric_limits<cutlass::uint2b_t> {
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint2b_t const lowest() noexcept { return uint2b_t{0}; }
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint2b_t const min() noexcept { return lowest(); }
+
+  CUTLASS_HOST_DEVICE static
+  cutlass::uint2b_t const max() noexcept { return uint2b_t{3}; }
+
   static constexpr bool is_integer = true;
   static constexpr bool is_signed = false;
 };
 
-}  // namespace std
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace platform
+} // namespace cutlass
 
-#endif // !defined(__CUDACC_RTC__)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integral_constant.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integral_constant.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -439,8 +439,39 @@
 #if !defined(__CUDACC_RTC__)
 template <auto t>
 CUTE_HOST std::ostream& operator<<(std::ostream& os, C<t> const&) {
   return os << "_" << t;
 }
 #endif
 
+
+namespace detail {
+
+// parse_int_digits takes a variadic number of digits and converts them into an int
+template <class... Ts>
+constexpr uint64_t parse_int_digits(uint64_t result, int digit, Ts... digits)
+{
+  if constexpr (sizeof...(Ts) == 0) {
+    return 10 * result + digit;
+  } else {
+    return parse_int_digits(10 * result + digit, digits...);
+  }
+}
+
+} // end namespace detail
+
+
+// This user-defined literal operator allows cute::constant written as literals. For example,
+//
+//    auto var = 32_c;
+//
+//  var has type cute::constant<int,32>.
+//
+template <char... digits>
+constexpr cute::constant<int,detail::parse_int_digits(0, (digits - '0')...)> operator "" _c()
+{
+  static_assert((('0' <= digits && digits <= '9') && ...),
+                "Expected 0 <= digit <= 9 for each digit of the integer.");
+  return {};
+}
+
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/integral_ratio.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/integral_ratio.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -126,14 +126,18 @@
 template <auto a, auto b, auto c, auto d>
 CUTE_HOST_DEVICE constexpr
 R<a*d,b*c>
 nratio(R<a,b>, R<c,d>) {
   return {};
 }
 
+//
+// Operators
+//
+
 template <auto a, auto b, auto x, auto y>
 CUTE_HOST_DEVICE constexpr
 typename R<a*x,b*y>::type
 operator*(R<a,b>, R<x,y>) {
   return {};
 }
 
@@ -223,22 +227,22 @@
 typename R<abs(a),abs(b)>::type
 abs(R<a,b>) {
   return {};
 }
 
 template <auto a, auto b>
 CUTE_HOST_DEVICE constexpr
-auto
+int32_t
 log_2(R<a,b>) {
   static_assert(R<a,b>::num > 0);
   static_assert(R<a,b>::den > 0);
   return log_2(static_cast<uint32_t>(R<a,b>::num)) - log_2(static_cast<uint32_t>(R<a,b>::den));
 }
 
-
+// @return A non-reduced ratio cute::R of the Trait0::value / Trait1::value
 template <class Trait0, class Trait1>
 CUTE_HOST_DEVICE constexpr
 auto
 trait_ratio(Trait0, Trait1) {
   return nratio(static_value<Trait0>(), static_value<Trait1>());
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/math.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/math.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -312,15 +312,15 @@
 
 /**
  * log2 computation
  */
 
 template <class T>
 CUTE_HOST_DEVICE constexpr
-auto
+int32_t
 log_2(T x) {
   assert(x > 0);
   static_assert(is_unsigned<T>::value, "Only to be used for unsigned integral types.");
-  return bit_width(x) - 1;
+  return static_cast<int32_t>(bit_width(x)) - 1;
 }
 
 } // namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/real.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/real.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/tfloat.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,30 +24,38 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*!
+  \file
+  \brief Device-level grouped GEMM.
+*/
+
 #pragma once
 
-#include <cute/config.hpp>
+#include "cutlass/gemm/device/base_grouped.h"
+
+////////////////////////////////////////////////////////////////////////////////
 
-#include <vector_types.h>
-#include <cutlass/numeric_types.h>
+namespace cutlass {
+namespace gemm {
+namespace device {
 
-namespace cute {
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-using cutlass::tfloat32_t;
+/// GEMM Grouped
+template <typename GemmKernel_>
+class GemmGrouped : public BaseGrouped<GemmKernel_> {
+public:
+  using GemmKernel = GemmKernel_;
+};
 
-//
-// Display utilities
-//
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if !defined(__CUDACC_RTC__)
-CUTE_HOST std::ostream& operator<<(std::ostream& os, tfloat32_t const& v)
-{
-  return os << float(v);
-}
-#endif
+} // namespace device
+} // namespace gemm
+} // namespace cutlass
 
-} // end namespace cute
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/numeric/uint128.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/uint128.h`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,203 +24,211 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*! 
+  \file
+  \brief Defines an unsigned 128b integer with several operators to support 64-bit integer division.
+*/
 #pragma once
 
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/cstdint>
 #else
 #include <cstdint>
 #include <cstdlib>
 #include <cmath>
 #include <type_traits>
 #include <stdexcept>
 #endif
 
-#include <cute/config.hpp>
+#include "cutlass/cutlass.h"
 
 /// Optionally enable GCC's built-in type
-#if defined(__x86_64) && !defined(__CUDA_ARCH__)
-#  if defined(__GNUC__) && 0
-#    define CUTE_UINT128_NATIVE
-#  elif defined(_MSC_VER)
-#    define CUTE_INT128_ARITHMETIC
-#    include <intrin.h>
-#  endif
+#if (defined(__x86_64) || defined (__aarch64__)) && !(defined(__CUDA_ARCH__) && ((__CUDACC_VER_MAJOR__ <= 10) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ <= 4)))) && defined(__GNUC__)
+#define CUTLASS_UINT128_NATIVE
+#elif defined(_MSC_VER) && defined(_M_AMD64) && !(defined(__CUDA_ARCH__) && ((__CUDACC_VER_MAJOR__ <= 10) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ <= 4))))
+#define CUTLASS_INT128_ARITHMETIC
+#include <intrin.h>
+#if _MSC_VER >= 1920 && !defined(__CUDA_ARCH__)
+#define CUTLASS_INT128_ARITHMETIC_DIV
+#include <immintrin.h>
+#endif
 #endif
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-namespace cute {
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+namespace cutlass {
 
 ///! Unsigned 128b integer type
 struct alignas(16) uint128_t
 {
   /// Size of one part of the uint's storage in bits
   static constexpr int storage_bits_ = 64;
 
   struct hilo
   {
     uint64_t lo;
     uint64_t hi;
   };
 
   // Use a union to store either low and high parts or, if present, a built-in 128b integer type.
-  union
-  {
+  union {
     struct hilo hilo_;
 
-#if defined(CUTE_UINT128_NATIVE)
+#if defined(CUTLASS_UINT128_NATIVE)
     unsigned __int128 native;
-#endif // defined(CUTE_UINT128_NATIVE)
+#endif // defined(CUTLASS_UINT128_NATIVE)
   };
 
   //
   // Methods
   //
 
   /// Default ctor
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t() : hilo_{0, 0} {}
 
   /// Constructor from uint64
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t(uint64_t lo_) : hilo_{lo_, 0} {}
 
   /// Constructor from two 64b unsigned integers
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t(uint64_t lo_, uint64_t hi_) : hilo_{lo_, hi_} {}
 
   /// Optional constructor from native value
-#if defined(CUTE_UINT128_NATIVE)
+#if defined(CUTLASS_UINT128_NATIVE)
   uint128_t(unsigned __int128 value) : native(value) { }
 #endif
 
   /// Lossily cast to uint64
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   explicit operator uint64_t() const
   {
     return hilo_.lo;
   }
 
-  template <class Dummy = bool>
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   static void exception()
   {
-    //static_assert(sizeof(Dummy) == 0, "Not implemented exception!");
-    //abort();
-    //printf("uint128 not implemented!\n");
+#if defined(__CUDA_ARCH__)
+  asm volatile ("  brkpt;\n");
+#else
+  // throw std::runtime_error("Not yet implemented.");
+  abort();
+#endif
   }
 
   /// Add
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t operator+(uint128_t const& rhs) const
   {
-    uint128_t y;
-#if defined(CUTE_UINT128_NATIVE)
+    uint128_t y{};
+#if defined(CUTLASS_UINT128_NATIVE)
     y.native = native + rhs.native;
 #else
     y.hilo_.lo = hilo_.lo + rhs.hilo_.lo;
-    y.hilo_.hi = hilo_.hi + rhs.hilo_.hi + (!y.hilo_.lo && (rhs.hilo_.lo));
+    y.hilo_.hi = hilo_.hi + rhs.hilo_.hi + (y.hilo_.lo < hilo_.lo);
 #endif
     return y;
   }
 
   /// Subtract
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t operator-(uint128_t const& rhs) const
   {
-    uint128_t y;
-#if defined(CUTE_UINT128_NATIVE)
+    uint128_t y{};
+#if defined(CUTLASS_UINT128_NATIVE)
     y.native = native - rhs.native;
 #else
     y.hilo_.lo = hilo_.lo - rhs.hilo_.lo;
     y.hilo_.hi = hilo_.hi - rhs.hilo_.hi - (rhs.hilo_.lo && y.hilo_.lo > hilo_.lo);
 #endif
     return y;
   }
 
   /// Multiply by unsigned 64b integer yielding 128b integer
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t operator*(uint64_t const& rhs) const
   {
-    uint128_t y;
-#if defined(CUTE_UINT128_NATIVE)
+    uint128_t y{};
+#if defined(CUTLASS_UINT128_NATIVE)
     y.native = native * rhs;
-#elif defined(CUTE_INT128_ARITHMETIC)
+#elif defined(CUTLASS_INT128_ARITHMETIC)
     // Multiply by the low part
     y.hilo_.lo = _umul128(hilo_.lo, rhs, &y.hilo_.hi);
 
     // Add the high part and ignore the overflow
-    uint64_t overflow;
+    uint64_t overflow{0};
     y.hilo_.hi += _umul128(hilo_.hi, rhs, &overflow);
 #else
+    CUTLASS_UNUSED(rhs);
     exception();
 #endif
     return y;
   }
 
   /// Divide 128b operation by 64b operation yielding a 64b quotient
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint64_t operator/(uint64_t const& divisor) const
   {
-    uint64_t quotient = 0;
-#if defined(CUTE_UINT128_NATIVE)
+    uint64_t quotient{0};
+#if defined(CUTLASS_UINT128_NATIVE)
     quotient = uint64_t(native / divisor);
-#elif defined(CUTE_INT128_ARITHMETIC)
+#elif defined(CUTLASS_INT128_ARITHMETIC_DIV)
     // implemented using MSVC's arithmetic intrinsics
-    uint64_t remainder = 0;
+    uint64_t remainder{0};
     quotient = _udiv128(hilo_.hi, hilo_.lo, divisor, &remainder);
 #else
+    CUTLASS_UNUSED(divisor);
     exception();
 #endif
     return quotient;
   }
 
   /// Divide 128b operation by 64b operation yielding a 64b quotient
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint64_t operator%(uint64_t const& divisor) const
   {
-    uint64_t remainder = 0;
-#if defined(CUTE_UINT128_NATIVE)
+    uint64_t remainder{0};
+#if defined(CUTLASS_UINT128_NATIVE)
     remainder = uint64_t(native % divisor);
-#elif defined(CUTE_INT128_ARITHMETIC)
+#elif defined(CUTLASS_INT128_ARITHMETIC_DIV)
     // implemented using MSVC's arithmetic intrinsics
     (void)_udiv128(hilo_.hi, hilo_.lo, divisor, &remainder);
 #else
+    CUTLASS_UNUSED(divisor);
     exception();
 #endif
     return remainder;
   }
 
   /// Computes the quotient and remainder in a single method.
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint64_t divmod(uint64_t &remainder, uint64_t divisor) const
   {
-    uint64_t quotient = 0;
-#if defined(CUTE_UINT128_NATIVE)
+    uint64_t quotient{0};
+#if defined(CUTLASS_UINT128_NATIVE)
     quotient = uint64_t(native / divisor);
     remainder = uint64_t(native % divisor);
-#elif defined(CUTE_INT128_ARITHMETIC)
+#elif defined(CUTLASS_INT128_ARITHMETIC_DIV)
     // implemented using MSVC's arithmetic intrinsics
     quotient = _udiv128(hilo_.hi, hilo_.lo, divisor, &remainder);
 #else
+    CUTLASS_UNUSED(remainder);
+    CUTLASS_UNUSED(divisor);
     exception();
 #endif
     return quotient;
   }
 
   /// Left-shifts a 128b unsigned integer
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t operator<<(int sh) const
   {
     if (sh == 0) {
       return *this;
     }
     else if (sh >= storage_bits_) {
       return uint128_t(0, hilo_.lo << (sh - storage_bits_));
@@ -230,15 +238,15 @@
         (hilo_.lo << sh),
         (hilo_.hi << sh) | uint64_t(hilo_.lo >> (storage_bits_ - sh))
       );
     }
   }
 
   /// Right-shifts a 128b unsigned integer
-  CUTE_HOST_DEVICE constexpr
+  CUTLASS_HOST_DEVICE
   uint128_t operator>>(int sh) const
   {
     if (sh == 0) {
       return *this;
     }
     else if (sh >= storage_bits_) {
       return uint128_t((hilo_.hi >> (sh - storage_bits_)), 0);
@@ -250,10 +258,10 @@
       );
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace cute
+} // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/pointer.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -29,23 +29,22 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/util/type_traits.hpp>
-#include <cute/numeric/int.hpp>        // sizeof_bits
+#include <cute/numeric/numeric_types.hpp>        // sizeof_bits
 #include <cute/numeric/math.hpp>
 #include <cute/numeric/integral_constant.hpp>
 
 #include <cute/container/array_subbyte.hpp>
 
 #include <cute/pointer_base.hpp>
 #include <cute/pointer_swizzle.hpp>
-#include <cute/layout.hpp>
 namespace cute
 {
 
 //
 // recast_ptr<T> -- Create an iterator over values of type T.
 // For most types this will simply be T*, but certain types require more care.
 // Subbyte Types: uint2_t, uint4_t, etc
@@ -54,28 +53,28 @@
 //
 
 template <class NewT>
 CUTE_HOST_DEVICE constexpr
 auto
 recast_ptr(void* ptr)
 {
-  if constexpr (is_subbyte<NewT>::value) {
+  if constexpr (cute::is_subbyte_v<NewT>) {
     return subbyte_iterator<NewT>(ptr);
   } else {
     return reinterpret_cast<NewT*>(ptr);
   }
   CUTE_GCC_UNREACHABLE;
 }
 
 template <class NewT>
 CUTE_HOST_DEVICE constexpr
 auto
 recast_ptr(void const* ptr)
 {
-  if constexpr (is_subbyte<NewT>::value) {
+  if constexpr (cute::is_subbyte_v<NewT>) {
     return subbyte_iterator<NewT const>(ptr);
   } else {
     return reinterpret_cast<NewT const*>(ptr);
   }
   CUTE_GCC_UNREACHABLE;
 }
 
@@ -98,14 +97,16 @@
 
 template <class T, class = void>
 struct is_gmem : false_type {};
 template <class P>                     // Found the gmem
 struct is_gmem<gmem_ptr<P>> : true_type {};
 template <class P>                     // Recurse on ::iterator, if possible
 struct is_gmem<P, void_t<typename P::iterator>> : is_gmem<typename P::iterator> {};
+template <class P>
+constexpr bool is_gmem_v = is_gmem<P>::value;
 
 // Idempotent gmem tag on an iterator
 template <class Iterator>
 CUTE_HOST_DEVICE constexpr
 auto
 make_gmem_ptr(Iterator iter) {
   if constexpr (is_gmem<Iterator>::value) {
@@ -159,14 +160,16 @@
 
 template <class T, class = void>
 struct is_smem : false_type {};
 template <class P>                     // Found the smem
 struct is_smem<smem_ptr<P>> : true_type {};
 template <class P>                     // Recurse on ::iterator, if possible
 struct is_smem<P, void_t<typename P::iterator>> : is_smem<typename P::iterator> {};
+template <class P>
+constexpr bool is_smem_v = is_smem<P>::value;
 
 // Idempotent smem tag on an iterator
 template <class Iterator>
 CUTE_HOST_DEVICE constexpr
 auto
 make_smem_ptr(Iterator iter) {
   if constexpr (is_smem<Iterator>::value) {
@@ -220,14 +223,16 @@
 };
 
 // Anything that is not gmem or smem is rmem
 template <class T, class = void>
 struct is_rmem : bool_constant<not (is_gmem<T>::value || is_smem<T>::value)> {};
 template <class P>
 struct is_rmem<rmem_ptr<P>> : true_type {};
+template <class P>
+constexpr bool is_rmem_v = is_rmem<P>::value;
 
 // Idempotent rmem tag on an iterator
 template <class Iterator>
 CUTE_HOST_DEVICE constexpr
 auto
 make_rmem_ptr(Iterator iter) {
   if constexpr (is_rmem<Iterator>::value) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_base.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_base.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -29,15 +29,15 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <cute/config.hpp>
 
 #include <cute/util/type_traits.hpp>
-#include <cute/numeric/int.hpp>        // sizeof_bits
+#include <cute/numeric/numeric_types.hpp>        // sizeof_bits
 
 namespace cute
 {
 
 //
 // C++20 <iterator> iterator_traits
 //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_flagged.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_flagged.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -85,15 +85,15 @@
   return composition(layout.layout_a(), smem_ptr_flag_bits<B/N>{}, downcast<N>(layout.layout_b()));
 }
 
 //
 // Conversion with swizzle_layout
 //
 
-template <class T, class SwizzleFn, int B, class Layout>
+template <class SwizzleFn, int B, class Layout>
 CUTE_HOST_DEVICE
 auto
 as_position_independent_swizzle_layout(ComposedLayout<SwizzleFn,smem_ptr_flag_bits<B>,Layout> const& layout)
 {
   return composition(recast_layout<uint8_t,uint_bit_t<B>>(layout.layout_a()), Int<0>{}, layout.layout_b());
 }
 
@@ -105,37 +105,45 @@
   static_assert(is_smem<remove_cvref_t<Tensor>>::value, "Expected smem tensor.");
   using SwizzleFn = get_swizzle_t<remove_cvref_t<Tensor>>;
   if constexpr (SwizzleFn::num_bits == 0) {
     return tensor;
   } else {
 #if !defined(NDEBUG)
     {
-    uint32_t address = cast_smem_ptr_to_uint(raw_pointer_cast(std::forward<Tensor>(tensor).data()));
+    uint32_t address = cast_smem_ptr_to_uint(raw_pointer_cast(static_cast<Tensor&&>(tensor).data()));
     uint32_t mask    = ((uint32_t(1) << SwizzleFn::num_base) - 1) | SwizzleFn::swizzle_code;
     assert((address & mask) == 0);  // Alignment to the Base, Z, and Y of Swizzle
     }
 #endif
     using T = typename remove_cvref_t<Tensor>::value_type;
     // Recast swizzle from acting on byte-addressed pointers to elements of type-T
     auto new_swizzle = recast_layout<uint8_t, T>(SwizzleFn{});
     // Strip off everything and create a new smem_ptr for type-T
-    auto new_ptr = make_smem_ptr<T>(raw_pointer_cast(std::forward<Tensor>(tensor).data()));
+    auto new_ptr = make_smem_ptr<T>(raw_pointer_cast(static_cast<Tensor&&>(tensor).data()));
     return make_tensor(new_ptr, composition(new_swizzle, Int<0>{}, tensor.layout()));
   }
   CUTE_GCC_UNREACHABLE;
 }
 
 //
 // Display utilities
 //
 
 // Capture and cast smem_ptr_flag Layouts to offset-0 layouts
 template <class SwizzleFn, int B, class Layout>
 CUTE_HOST_DEVICE
 void
+print_layout(ComposedLayout<SwizzleFn,smem_ptr_flag_bits<B>,Layout> const& layout)
+{
+  print_layout(as_position_independent_swizzle_layout(layout));
+}
+
+template <class SwizzleFn, int B, class Layout>
+CUTE_HOST_DEVICE
+void
 print_latex(ComposedLayout<SwizzleFn,smem_ptr_flag_bits<B>,Layout> const& layout)
 {
   print_latex(as_position_independent_swizzle_layout(layout));
 }
 
 template <int B>
 CUTE_HOST_DEVICE void print(smem_ptr_flag_bits<B> ptr)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/pointer_swizzle.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/pointer_swizzle.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/stride.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/stride.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -390,49 +390,74 @@
 
 //
 // Compact Order -- compute a compact stride based on an ordering of the modes
 //
 
 namespace detail {
 
-template <class Shape, class Order, class OrigShape, class OrigOrder>
+// @pre weakly_congruent(order, shape)
+// @pre is_congruent<RefShape, RefOrder>
+// @pre is_static<Order>
+// @pre is_static<RefOrder>
+template <class Shape, class Order, class RefShape, class RefOrder>
 CUTE_HOST_DEVICE constexpr
 auto
 compact_order(Shape const& shape, Order const& order,
-              OrigShape const& orig_shape, OrigOrder const& orig_order)
+              RefShape const& ref_shape, RefOrder const& ref_order)
 {
   if constexpr (is_tuple<Order>::value) {
-    return transform(shape, order, [&](auto const& x, auto const& y) { return compact_order(x, y, orig_shape, orig_order); });
+    static_assert(tuple_size<Shape>::value == tuple_size<Order>::value, "Need equal rank of shape and order");
+    return transform(shape, order, [&](auto const& s, auto const& o) { return compact_order(s, o, ref_shape, ref_order); });
   } else {
-    auto d = product(transform(orig_shape, orig_order,
-                               [&](auto const& s, auto const& o) {
-                                  return conditional_return(o < order, product(s), Int<1>{});
-                                }));
-    return compact_col_major(shape, d);
+    // Compute the starting stride for this shape by accumulating all shapes corresponding to lesser orders
+    auto stride_start = product(transform(ref_shape, ref_order,
+                                          [&](auto const& s, auto const& o) {
+                                            return conditional_return(o < order, s, Int<1>{});
+                                          }));
+    return compact_col_major(shape, stride_start);
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 } // end namespace detail
 
 template <class Shape, class Order>
 CUTE_HOST_DEVICE constexpr
 auto
 compact_order(Shape const& shape, Order const& order)
 {
-  if constexpr(is_congruent<Shape,Order>::value) {
-    return detail::compact_order(shape, order, flatten_to_tuple(shape), flatten_to_tuple(order));
-  }
-  else
-  {
-    // Here we only want to apply order to top-level subshapes and default (col-major) order on other levels
-    static_assert(rank(Shape{}) == rank(Order{}), "Need equal rank of shape and order");
-    return detail::compact_order(shape, order, shape, order);
-  }
+  auto ref_shape = flatten_to_tuple(product_like(shape, order));
+
+  auto flat_order = flatten_to_tuple(order);
+  // Find the largest static element of order
+  auto max_order = cute::fold(flat_order, Int<0>{}, [](auto v, auto order) {
+    if constexpr (is_constant<true, decltype(v < order)>::value) {  
+      return order;
+    } else {
+      return v;
+    }
+
+    CUTE_GCC_UNREACHABLE;
+  });
+  // Replace any dynamic elements within order with large-static elements
+  auto max_seq = make_range<max_order+1, max_order+1+rank(flat_order)>{};
+  auto ref_order = cute::transform(max_seq, flat_order, [](auto seq_v, auto order) {
+    if constexpr (is_static<decltype(order)>::value) {
+      return order;
+    } else {
+      return seq_v;
+    }
+
+    CUTE_GCC_UNREACHABLE;
+  });
+
+  auto new_order = unflatten(ref_order, order);
+
+  return detail::compact_order(shape, new_order, ref_shape, ref_order);
 }
 
 template <class Shape>
 CUTE_HOST_DEVICE constexpr
 auto
 compact_order(Shape const& shape, GenColMajor const& major)
 {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/swizzle.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/swizzle.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -83,14 +83,22 @@
   template <class Offset>
   CUTE_HOST_DEVICE constexpr
   auto
   operator()(Offset const& offset) const
   {
     return apply(offset);
   }
+
+  template <int B, int M, int S>
+  CUTE_HOST_DEVICE constexpr
+  auto
+  operator==(Swizzle<B,M,S> const&) const
+  {
+    return B == BBits && M == MBase && S == SShift;
+  }
 };
 
 //
 // make_swizzle<0b1000, 0b0100>()         ->  Swizzle<1,2,1>
 // make_swizzle<0b11000000, 0b00000110>() ->  Swizzle<2,1,5>
 //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/swizzle_layout.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/swizzle_layout.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/tensor.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/tensor.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -38,15 +38,14 @@
 
 #include <cute/container/tuple.hpp>
 #include <cute/container/array_aligned.hpp>
 #include <cute/container/array_subbyte.hpp>
 
 #include <cute/pointer.hpp>
 #include <cute/layout.hpp>
-#include <cute/tile.hpp>
 
 namespace cute
 {
 
 //
 // Engine -- owning or non-owning data store
 //
@@ -313,14 +312,16 @@
   cute::tuple<layout_type, engine_type> rep_;
 };
 
 template <class T>
 struct is_tensor : false_type {};
 template <class Engine, class Layout>
 struct is_tensor<Tensor<Engine,Layout>> : true_type {};
+template <class T>
+constexpr bool is_tensor_v = is_tensor<T>::value;
 
 // Customization point for creation of owning and non-owning Tensors
 template <class T>
 struct MakeTensor
 {
   template <class Layout,
             __CUTE_REQUIRES(not has_dereference<T>::value &&
@@ -477,34 +478,24 @@
 // Return the subtensor of a mode
 template <class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 decltype(auto)
 tensor(Tensor&& tensor)
 {
-  return std::forward<Tensor>(tensor);
+  return static_cast<Tensor&&>(tensor);
 }
 
 template <int I, int... Is, class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 decltype(auto)
 tensor(Tensor&& tensor)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), get<I,Is...>(tensor.layout()));
-}
-
-// Return the subtensor of a range of modes
-template <int B, int E, class Tensor,
-          __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
-CUTE_HOST_DEVICE constexpr
-decltype(auto)
-take(Tensor&& tensor)
-{
-  return make_tensor(std::forward<Tensor>(tensor).data(), take<B,E>(tensor.layout()));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), get<I,Is...>(tensor.layout()));
 }
 
 // Return the layout of a mode
 template <int... Is, class Engine, class Layout>
 CUTE_HOST_DEVICE constexpr
 decltype(auto)
 layout(Tensor<Engine,Layout> const& tensor)
@@ -563,86 +554,96 @@
 
 template <class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 flatten(Tensor&& tensor)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), flatten(tensor.layout()));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), flatten(tensor.layout()));
 }
 
 template <class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 coalesce(Tensor&& tensor)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), coalesce(tensor.layout()));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), coalesce(tensor.layout()));
 }
 
 template <class Tensor, class Profile,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 coalesce(Tensor&& tensor, Profile const& profile)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), coalesce(tensor.layout(), profile));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), coalesce(tensor.layout(), profile));
 }
 
 template <class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 filter_zeros(Tensor&& tensor)
 {
-  return make_tensor(cute::forward<Tensor>(tensor).data(), filter_zeros(tensor.layout()));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), filter_zeros(tensor.layout()));
 }
 
 template <class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 filter(Tensor&& tensor)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), filter(tensor.layout()));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), filter(tensor.layout()));
 }
 
 template <class Tensor, class Profile,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 filter(Tensor&& tensor, Profile const& profile)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(), filter(tensor.layout(), profile));
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), filter(tensor.layout(), profile));
 }
 
 // Return a tensor with the same shape as input but offset by a given coordinate
 template <class Coord, class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 domain_offset(Coord const& coord, Tensor&& tensor)
 {
   auto [layout, ptr_offset] = domain_offset(coord, tensor.layout());
-  return make_tensor(std::forward<Tensor>(tensor).data() + ptr_offset, layout);
+  return make_tensor(static_cast<Tensor&&>(tensor).data() + ptr_offset, layout);
 }
 
 // Group the modes [B,E) into a single mode
 // e.g. group<2,4>(make_tensor<int>(Layout<Shape<_1,_2,_3,_4,_5,_6>>{}))
 //      => make_tensor<int>(Layout<Shape<_1,_2,Shape<_3,_4>,_5,_6>>{})
 template <int B, int E, class Tensor,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 group_modes(Tensor&& tensor)
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(),
+  return make_tensor(static_cast<Tensor&&>(tensor).data(),
                      group<B,E>(tensor.layout()));
 }
 
+// Return the subtensor of a range of modes
+template <int B, int E, class Tensor,
+          __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
+CUTE_HOST_DEVICE constexpr
+decltype(auto)
+take(Tensor&& tensor)
+{
+  return make_tensor(static_cast<Tensor&&>(tensor).data(), take<B,E>(tensor.layout()));
+}
+
 //
 // Recast
 //
 
 // NOTE: This is very dangerous to do
 //   -- doesn't check dynamic integer divisibility
 //   -- doesn't check alignment
@@ -658,17 +659,17 @@
 
   // If this is an upcast of a normal Layout with static negative strides, then offset as well
   if constexpr (sizeof(OldType) < sizeof(NewType) && not is_composed_layout<decltype(old_layout)>::value) {
     auto shape_diff = transform(flatten(old_layout.shape()), flatten(new_layout.shape()), minus{});
     auto extent_diff = transform(shape_diff, flatten(old_layout.stride()), multiplies{});
     auto offset = fold(extent_diff, Int<0>{}, [](auto const& i, auto const& a) { return i + cute::min(a,Int<0>{}); });
 
-    return make_tensor(recast_ptr<NewType>(std::forward<Tensor>(tensor).data() + offset), new_layout);
+    return make_tensor(recast_ptr<NewType>(static_cast<Tensor&&>(tensor).data() + offset), new_layout);
   } else {
-    return make_tensor(recast_ptr<NewType>(std::forward<Tensor>(tensor).data()         ), new_layout);
+    return make_tensor(recast_ptr<NewType>(static_cast<Tensor&&>(tensor).data()         ), new_layout);
   }
 
   CUTE_GCC_UNREACHABLE;
 }
 
 //
 // max_common_vector
@@ -784,53 +785,53 @@
 template <class Tensor, class Tiler,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 logical_divide(Tensor    && tensor,
                Tiler const& tiler)   // Layout or Tile<Layout...> or Shape
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(),
+  return make_tensor(static_cast<Tensor&&>(tensor).data(),
                      logical_divide(tensor.layout(), tiler));
 }
 
 // zipped_divide is logical_divide with Tiler modes and Rest modes gathered together: (Tiler,Rest)
 // When Tiler is Layout, this has no effect as logical_divide results in the same.
 // When Tiler is Tile<Layout...> or Shape, this zips modes into standard form ((BLK_A,BLK_B),(a,b,x,y))
 template <class Tensor, class Tiler,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 zipped_divide(Tensor    && tensor,
               Tiler const& tiler)    // Layout or Tile<Layout...> or Shape
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(),
+  return make_tensor(static_cast<Tensor&&>(tensor).data(),
                      zipped_divide(tensor.layout(), tiler));
 }
 
 // tiled_divide is zipped_divide with the second output mode flattened ((BLK_A,BLK_B),a,b,x,y)
 template <class Tensor, class Tiler,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
-tiled_divide(Tensor   && tensor,
+tiled_divide(Tensor    && tensor,
              Tiler const& tiler)     // Layout or Tile<Layout...> or Shape
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(),
+  return make_tensor(static_cast<Tensor&&>(tensor).data(),
                      tiled_divide(tensor.layout(), tiler));
 }
 
 // flat_divide is zipped_divide with the both modes flattened (BLK_A,BLK_B,a,b,x,y)
 template <class Tensor, class Tiler,
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 flat_divide(Tensor    && tensor,
             Tiler const& tiler)      // Layout or Tile<Layout...> or Shape
 {
-  return make_tensor(std::forward<Tensor>(tensor).data(),
+  return make_tensor(static_cast<Tensor&&>(tensor).data(),
                      flat_divide(tensor.layout(), tiler));
 }
 
 // logical_product on a Tensor doesn't make sense since it often increases cosize
 //   though this might make sense for creating Tensors with broadcasted (stride-0) modes
 
 //
@@ -846,15 +847,15 @@
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 inner_partition(Tensor    && tensor,
                 Tiler const& tiler,
                 Coord const& coord)
 {
-  auto tensor_tiled = zipped_divide(std::forward<Tensor>(tensor), tiler);
+  auto tensor_tiled = zipped_divide(static_cast<Tensor&&>(tensor), tiler);
   constexpr int R0 = decltype(rank<0>(tensor_tiled))::value;
 
   // The coord slices into the second mode (the "rest" mode), flatten the first
   if constexpr (is_tuple<Coord>::value) {
     // Append trailing modes if coord is tuple
     constexpr int R1 = decltype(rank<1>(tensor_tiled))::value;;
     return tensor_tiled(repeat<R0>(_), append<R1>(coord,_));
@@ -873,15 +874,15 @@
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 outer_partition(Tensor    && tensor,
                 Tiler const& tiler,
                 Coord const& coord)
 {
-  auto tensor_tiled = zipped_divide(std::forward<Tensor>(tensor), tiler);
+  auto tensor_tiled = zipped_divide(static_cast<Tensor&&>(tensor), tiler);
   constexpr int R1 = decltype(rank<1>(tensor_tiled))::value;
 
   // The coord slices into the first mode (the "tile" mode), flatten the second
   if constexpr (is_tuple<Coord>::value) {
     // Append trailing modes if coord is tuple
     constexpr int R0 = decltype(rank<0>(tensor_tiled))::value;
     return tensor_tiled(append<R0>(coord,_), repeat<R1>(_));
@@ -899,15 +900,15 @@
           __CUTE_REQUIRES(is_tensor<remove_cvref_t<Tensor>>::value)>
 CUTE_HOST_DEVICE constexpr
 auto
 local_tile(Tensor    && tensor,
            Tiler const& tiler,   // tiler to apply
            Coord const& coord)   // coord to slice into "remainder"
 {
-  return inner_partition(std::forward<Tensor>(tensor),
+  return inner_partition(static_cast<Tensor&&>(tensor),
                          tiler,
                          coord);
 }
 
 // Same as above, but with a projection parameter to strip out unwanted tiling modes for convenience
 //   when using projections of the same tiler.
 // This is typical at the CTA level where tiles of data are extracted as projections:
@@ -924,15 +925,15 @@
 CUTE_HOST_DEVICE
 auto
 local_tile(Tensor    && tensor,
            Tiler const& tiler,   // tiler to apply
            Coord const& coord,   // coord to slice into "remainder"
            Proj  const& proj)    // projection to apply to tiler and coord
 {
-  return local_tile(std::forward<Tensor>(tensor),
+  return local_tile(static_cast<Tensor&&>(tensor),
                     dice(proj, tiler),
                     dice(proj, coord));
 }
 
 // Tile a tensor according to the flat shape of a layout that provides the coordinate of the target index.
 // This is typical at the Thread level where data is partitioned across repeated patterns of threads:
 //   Tensor data = ...                                                            // (_16,_64)
@@ -942,15 +943,15 @@
 CUTE_HOST_DEVICE
 auto
 local_partition(Tensor                     && tensor,
                 Layout<LShape,LStride> const& tile,    // coord -> index
                 Index                  const& index)   // index to slice for
 {
   static_assert(is_integral<Index>::value);
-  return outer_partition(std::forward<Tensor>(tensor),
+  return outer_partition(static_cast<Tensor&&>(tensor),
                          product_each(shape(tile)),
                          tile.get_flat_coord(index));
 }
 
 // Same as above, but with a projection parameter to strip out unwanted tiling modes for convenience
 //   when using projections of the same tiler.
 // This is typical at the Thread level where data is partitioned across projected layouts of threads:
@@ -966,15 +967,15 @@
 CUTE_HOST_DEVICE
 auto
 local_partition(Tensor                     && tensor,
                 Layout<LShape,LStride> const& tile,   // coord -> index
                 Index                  const& index,  // index to slice for
                 Projection             const& proj)
 {
-  return local_partition(std::forward<Tensor>(tensor),
+  return local_partition(static_cast<Tensor&&>(tensor),
                          dice(proj, tile),
                          index);
 }
 
 //
 // Display utilities
 //
@@ -982,17 +983,19 @@
 template <class Engine, class Layout>
 CUTE_HOST_DEVICE void print(Tensor<Engine,Layout> const& tensor)
 {
   print(tensor.data()); print(" o "); print(tensor.layout());
 }
 
 template <class Engine, class Layout>
-CUTE_HOST_DEVICE void print_tensor(Tensor<Engine,Layout> const& tensor)
+CUTE_HOST_DEVICE void print_tensor(Tensor<Engine,Layout> const& tensor, bool print_type = true)
 {
-  print(tensor); print(":\n");
+  if (print_type) {
+    print(tensor); print(":\n");
+  }
 
   if constexpr (Layout::rank == 1)
   {
     for (int m = 0; m < size(tensor); ++m) {
       pretty_print(tensor(m));
       printf("\n");
     }
@@ -1004,26 +1007,26 @@
         pretty_print(tensor(m,n));
       }
       printf("\n");
     }
   } else
   if constexpr (Layout::rank == 3)
   {
-    print_tensor(tensor(_,_,0));
+    print_tensor(tensor(_,_,0), false);
     for (int k = 1; k < size<2>(tensor); ++k) {
       for (int i = 0; i < 5*size<1>(tensor); ++i) { print("-"); } print("\n");
-      print_tensor(tensor(_,_,k));
+      print_tensor(tensor(_,_,k), false);
     }
   } else
   if constexpr (Layout::rank == 4)
   {
-    print_tensor(tensor(_,_,_,0));
+    print_tensor(tensor(_,_,_,0), false);
     for (int p = 1; p < size<3>(tensor); ++p) {
       for (int i = 0; i < 5*size<1>(tensor); ++i) { print("="); } print("\n");
-      print_tensor(tensor(_,_,_,p));
+      print_tensor(tensor(_,_,_,p), false);
     }
   }
 }
 
 #if !defined(__CUDACC_RTC__)
 template <class Engine, class Layout>
 CUTE_HOST std::ostream& print_tensor_os(std::ostream& os, Tensor<Engine,Layout> const& tensor)
@@ -1077,18 +1080,21 @@
 
 //
 // Extended Engines
 //
 
 #include <cute/pointer_swizzle.hpp>
 #include <cute/pointer_flagged.hpp>
-
 //
 // Tensor Algorithms
 //
 
 #include <cute/algorithm/tensor_algorithms.hpp>
 #include <cute/algorithm/fill.hpp>
 #include <cute/algorithm/clear.hpp>
 #include <cute/algorithm/copy.hpp>
+#include <cute/algorithm/prefetch.hpp>
 #include <cute/algorithm/axpby.hpp>
 #include <cute/algorithm/gemm.hpp>
+
+#include <cute/algorithm/cooperative_copy.hpp>
+#include <cute/algorithm/cooperative_gemm.hpp>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/tensor_predicate.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/tensor_predicate.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/tile.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/mma.hpp`

 * *Files 18% similar despite different names*

```diff
@@ -26,33 +26,41 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
-#include <cute/config.hpp>
+#include "cutlass/arch/mma.h"
+#include "cute/layout.hpp"
 
-#include <cute/layout.hpp>
+////////////////////////////////////////////////////////////////////////////////////////////////////
 
-namespace cute
-{
+namespace cutlass::detail {
 
-//
-// A Tile is not a Layout, it's a tuple of Layouts or Tiles or Underscores
-//
+////////////////////////////////////////////////////////////////////////////////////////////////////
 
-template <class... Layouts>
-using Tile = tuple<Layouts...>;
+template <class TiledMma, class = void>
+struct IsSparseTensorOp : cute::false_type { };
+
+// The following metafunction is used to extract the OperatorClass from a cutlass 3.x kernel.
+template <class TiledMma>
+struct get_operator_class {
+  static constexpr bool is_sparse_op = IsSparseTensorOp<TiledMma>::value;
+  static constexpr bool is_tensor_op = cute::size<0>(typename TiledMma::AtomShape_MNK{}) >= 8;
+  using type = cute::conditional_t<
+                is_tensor_op, 
+                cute::conditional_t<
+                  is_sparse_op,
+                  cutlass::arch::OpClassSparseTensorOp,
+                    cutlass::arch::OpClassTensorOp
+                  >,
+                cutlass::arch::OpClassSimt
+                >;
+};
 
-template <class Tile>
-using is_tile = is_tuple<Tile>;
+template <class T>
+using get_operator_class_t = typename get_operator_class<T>::type;
 
-template <class... Layouts>
-CUTE_HOST_DEVICE constexpr
-auto
-make_tile(Layouts const&... layouts)
-{
-  return Tile<Layouts...>(layouts...);
-}
+////////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // end namespace cute
+} // namespace cutlass::detail
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/underscore.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/underscore.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -41,14 +41,17 @@
 {
 
 // For slicing
 struct Underscore : Int<0> {};
 
 CUTE_INLINE_CONSTANT Underscore _;
 
+// Convenient alias
+using X = Underscore;
+
 // Treat Underscore as an integral like integral_constant
 template <>
 struct is_integral<Underscore> : true_type {};
 
 template <class T>
 struct is_underscore : false_type {};
 template <>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/util/debug.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/debug.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/util/print.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/print.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cute/util/type_traits.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/util/type_traits.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -97,14 +97,17 @@
 
 using CUTE_STL_NAMESPACE::is_lvalue_reference;
 using CUTE_STL_NAMESPACE::is_lvalue_reference_v;
 
 using CUTE_STL_NAMESPACE::is_reference;
 using CUTE_STL_NAMESPACE::is_trivially_copyable;
 
+using CUTE_STL_NAMESPACE::is_convertible;
+using CUTE_STL_NAMESPACE::is_convertible_v;
+
 using CUTE_STL_NAMESPACE::is_same;
 using CUTE_STL_NAMESPACE::is_same_v;
 
 using CUTE_STL_NAMESPACE::is_arithmetic;
 using CUTE_STL_NAMESPACE::is_unsigned;
 using CUTE_STL_NAMESPACE::is_unsigned_v;
 using CUTE_STL_NAMESPACE::is_signed;
@@ -127,30 +130,29 @@
 
 using CUTE_STL_NAMESPACE::remove_pointer;
 using CUTE_STL_NAMESPACE::remove_pointer_t;
 
 // <utility>
 using CUTE_STL_NAMESPACE::declval;
 
-template< class T >
+template <class T>
 constexpr T&& forward(remove_reference_t<T>& t) noexcept
 {
   return static_cast<T&&>(t);
 }
 
-template< class T >
+template <class T>
 constexpr T&& forward(remove_reference_t<T>&& t) noexcept
 {
-  static_assert(! is_lvalue_reference_v<T>,
-    "T cannot be an lvalue reference (e.g., U&).");
+  static_assert(! is_lvalue_reference_v<T>, "T cannot be an lvalue reference (e.g., U&).");
   return static_cast<T&&>(t);
 }
 
-template< class T >
-constexpr remove_reference_t<T>&& move( T&& t ) noexcept
+template <class T>
+constexpr remove_reference_t<T>&& move(T&& t) noexcept
 {
   return static_cast<remove_reference_t<T>&&>(t);
 }
 
 // <limits>
 using CUTE_STL_NAMESPACE::numeric_limits;
 
@@ -244,8 +246,19 @@
 
 template <class F, class... Args>
 CUTE_HOST_DEVICE constexpr auto
 is_valid(F&&, Args&&...) {
   return detail::is_valid_impl<F&&, Args&&...>(int{});
 }
 
+template <bool B, template<class...> class True, template<class...> class False>
+struct conditional_template {
+  template <class... U>
+  using type = True<U...>;
+};
+
+template <template<class...> class True, template<class...> class False>
+struct conditional_template<false, True, False> {
+  template <class... U>
+  using type = False<U...>;
+};
 } // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/aligned_buffer.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/aligned_buffer.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/arch.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/arch.h`

 * *Files 2% similar despite different names*

```diff
@@ -82,14 +82,17 @@
 };
 struct Sm80 {
   static int const kMinComputeCapability = 80; 
 };
 struct Sm86 {
   static int const kMinComputeCapability = 86;
 };
+struct Sm89 {
+  static int const kMinComputeCapability = 89;
+};
 struct Sm90 {
   static int const kMinComputeCapability = 90; 
 };
 
 /// Triggers a breakpoint on the device
 CUTLASS_DEVICE
 void device_breakpoint() {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/barrier.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/barrier.h`

 * *Files 2% similar despite different names*

```diff
@@ -64,14 +64,15 @@
   // Data Members:
 
   // Range = [1 , NUM_THREADS_PER_CTA]
   // Range % warp-size (i.e 32) == 0
   uint32_t const num_threads_;
 
   // Range : [0, 15]
+  // Note that should be set to the final barrier ID, including ReserveNamedBarrierCount should be considered
   uint32_t const id_;
 
  public:
 
   // Constructor for CUTLASS developers:
   // effective barrier ID starts from 0
   CUTLASS_DEVICE
@@ -84,20 +85,22 @@
   NamedBarrier(uint32_t num_threads, uint32_t id = 0)
       : num_threads_(num_threads), id_(id + ReservedNamedBarrierCount) {
     CUTLASS_ASSERT(id + ReservedNamedBarrierCount <= HardwareMaxNumNamedBarriers && "Effective barrier_id should not exceed 16.");
   }
 
   CUTLASS_DEVICE
   void arrive_and_wait() const {
-    NamedBarrier::arrive_and_wait(num_threads_, id_);
+    // Note: The value of id_ is already the final barrier id (set correctly in the constructor).
+    NamedBarrier::arrive_and_wait_internal(num_threads_, id_);
   }
 
   CUTLASS_DEVICE
   void arrive() const {
-    NamedBarrier::arrive(num_threads_, id_);
+    // Note: The value of id_ is already the final barrier id (set correctly in the constructor).
+    NamedBarrier::arrive_internal(num_threads_, id_);
   }
 
   CUTLASS_DEVICE
   void sync() const {
     NamedBarrier::arrive_and_wait();
   }
 
@@ -380,16 +383,16 @@
   CUTLASS_DEVICE
   void arrive_and_expect_tx(uint32_t transaction_bytes) const {
     ClusterTransactionBarrier::arrive_and_expect_tx(&this->barrier_, transaction_bytes);
   }
 
   // Performs an arrive operation + expected transaction bytes increment
   CUTLASS_DEVICE
-  void arrive_and_expect_tx(uint32_t transaction_bytes, uint32_t cta_id) const {
-    ClusterTransactionBarrier::arrive_and_expect_tx(&this->barrier_, transaction_bytes , cta_id, true);
+  void arrive_and_expect_tx(uint32_t transaction_bytes, uint32_t cta_id, uint32_t pred = 1u) const {
+    ClusterTransactionBarrier::arrive_and_expect_tx(&this->barrier_, transaction_bytes , cta_id, pred);
   }
 
   // Performs an expected transaction bytes increment without doing an arrive operation
   CUTLASS_DEVICE
   void expect_transaction(uint32_t transaction_bytes) const {
     ClusterTransactionBarrier::expect_transaction(&this->barrier_, transaction_bytes);
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/cache_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/cache_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory.h`

 * *Files 1% similar despite different names*

```diff
@@ -32,14 +32,15 @@
     \brief Architecture-specific operators on memory
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/arch/cache_operation.h"
+#include "cutlass/platform/platform.h"
 
 namespace cutlass {
 namespace arch {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/memory_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/memory_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma.h`

 * *Files 2% similar despite different names*

```diff
@@ -82,20 +82,17 @@
 
 /// Tag indicating the input is converted to 2 (big and small) TF32 components
 //  Perform 3xTF32 or 4xTF32 for every complex<F32> output element
 struct OpMultiplyAddComplexFastF32 {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Helper for determining whether staged accumulation should be used for a given operator
-template <typename Operator>
-struct UseStagedAccumulation {
-  static bool const value = platform::is_same<Operator, OpMultiplyAddFastF32>::value ||
-                            platform::is_same<Operator, OpMultiplyAddComplexFastF32>::value;
-};
+/// Tag indicating that staged accumulation is not to be used. This is valid only for SM89
+/// FP8 kernels.
+struct OpMultiplyAddFastAccum;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the complex multiply-add operation
 struct OpMultiplyAddComplex {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -246,9 +243,27 @@
 #include "cutlass/arch/mma_sm50.h"
 #include "cutlass/arch/mma_sm60.h"
 #include "cutlass/arch/mma_sm61.h"
 #include "cutlass/arch/mma_sm70.h"
 #include "cutlass/arch/mma_sm75.h"
 #include "cutlass/arch/mma_sm80.h"
 #include "cutlass/arch/mma_sparse_sm80.h"
+#include "cutlass/arch/mma_sm89.h"
+#include "cutlass/arch/mma_sparse_sm89.h"
 #include "cutlass/arch/mma_sm90.h"
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
+namespace cutlass {
+namespace arch {
+namespace detail {
+/// Helper for determining whether staged accumulation should be used for a given operator
+template <typename Operator>
+struct UseStagedAccumulation {
+  static bool const value = platform::is_same<typename Operator::MathOperator, OpMultiplyAddFastF32>::value ||
+                            platform::is_same<typename Operator::MathOperator, OpMultiplyAddComplexFastF32>::value ||
+                            is_sm89_staged_policy_v<Operator>;
+};
+} // namespace detail
+} // namespace arch
+} // namespace cutlass
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm50.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm50.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm60.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm60.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm61.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sm90.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sm90.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/reg_reconfig.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd_sm60.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd_sm60.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/simd_sm61.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/simd_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm72.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/arch/wmma_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/array.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array.h`

 * *Files 1% similar despite different names*

```diff
@@ -29,52 +29,36 @@
  *
  **************************************************************************************************/
 /*! \file
     \brief Statically sized array of elements that accommodates all CUTLASS-supported numeric types
            and is safe to use in a union.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 #include "cutlass/cutlass.h"
 #include "cutlass/functional.h"
-#include "cutlass/numeric_size.h"
-#include "cutlass/half.h"
-#include "cutlass/integer_subbyte.h"
-#include "cutlass/tfloat32.h"
-#include "cutlass/bfloat16.h"
-#include "cutlass/half.h"
+#include "cutlass/numeric_types.h"
 namespace cutlass {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Statically sized array for any data type
 template <
   typename T,
   int N,
   bool RegisterSized = sizeof_bits<T>::value >= 32
 >
-class Array;
+struct Array;
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Defines the size of an Array<> in bits
 template <typename T, int N, bool RegisterSized>
 struct sizeof_bits<Array<T, N, RegisterSized> > {
-  static int const value =
-    int(sizeof(typename Array<T, N, RegisterSized>::Storage)) * 8 * int(Array<T, N, RegisterSized>::kStorageElements);
+  static constexpr int value = sizeof(Array<T, N, RegisterSized>) * 8;
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Returns true if the argument is a power of 2
 CUTLASS_HOST_DEVICE
 constexpr bool ispow2(unsigned x) {
@@ -92,29 +76,28 @@
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Statically sized array for any data type
 template <
   typename T,
   int N
 >
-class Array<T, N, true> {
-public:
+struct Array<T, N, true> {
 
   /// Storage type
   using Storage = T;
 
   /// Element type
   using Element = T;
 
   /// Number of storage elements
   //static std::size_t const kStorageElements = N;
-  static size_t const kStorageElements = N;
+  static constexpr size_t kStorageElements = N;
 
   /// Number of logical elements
-  static size_t const kElements = N;
+  static constexpr size_t kElements = N;
 
   //
   // C++ standard members
   //
 
   typedef T value_type;
   typedef size_t size_type;
@@ -348,34 +331,17 @@
 
     CUTLASS_HOST_DEVICE
     bool operator!=(const_iterator const &other) const {
       return ptr_ != other.ptr_;
     }
   };
 
-private:
-
   /// Internal storage
   Storage storage[kElements];
 
-public:
-
-  #if 0
-  CUTLASS_HOST_DEVICE
-  Array() { }
-
-  CUTLASS_HOST_DEVICE
-  Array(Array const &x) {
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kElements; ++i) {
-      storage[i] = x.storage[i];
-    }
-  }
-  #endif
-
   /// Efficient clear method
   CUTLASS_HOST_DEVICE
   void clear() {
     fill(T(0));
   }
 
   CUTLASS_HOST_DEVICE
@@ -453,15 +419,15 @@
   constexpr size_type max_size() const {
     return kElements;
   }
 
   CUTLASS_HOST_DEVICE
   void fill(T const &value) {
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kElements; ++i) {
+    for (int i = 0; i < int(kElements); ++i) {
       storage[i] = static_cast<Storage>(value);
     }
   }
 
   CUTLASS_HOST_DEVICE
   iterator begin() {
     return iterator(storage);
@@ -532,47 +498,33 @@
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 // Factories
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Element>
 CUTLASS_HOST_DEVICE
 Array<Element, 1> make_Array(Element x) {
-  Array<Element, 1> m;
-  m[0] = x;
-  return m;
+  return {x};
 }
 
 template <typename Element>
 CUTLASS_HOST_DEVICE
 Array<Element, 2> make_Array(Element x, Element y) {
-  Array<Element, 2> m;
-  m[0] = x;
-  m[1] = y;
-  return m;
+  return {x,y};
 }
 
 template <typename Element>
 CUTLASS_HOST_DEVICE
 Array<Element, 3> make_Array(Element x, Element y, Element z) {
-  Array<Element, 3> m;
-  m[0] = x;
-  m[1] = y;
-  m[2] = z;
-  return m;
+  return {x,y,z};
 }
 
 template <typename Element>
 CUTLASS_HOST_DEVICE
 Array<Element, 4> make_Array(Element x, Element y, Element z, Element w) {
-  Array<Element, 4> m;
-  m[0] = x;
-  m[1] = y;
-  m[2] = z;
-  m[3] = w;
-  return m;
+  return {x,y,z,w};
 }
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 // functional.h numeric specializations
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -1088,14 +1040,84 @@
       result[i] = scalar_op(scalar, b[i], c[i]);
     }
 
     return result;
   }
 };
 
+/// Fused square-and-plus
+template <typename T, int N>
+struct square_and_plus<Array<T, N>> {
+
+  CUTLASS_HOST_DEVICE
+  Array<T, N> operator()(Array<T, N> const &lhs, Array<T, N> const &rhs) const {
+    multiply_add<Array<T, N>, Array<T, N>, Array<T, N>> ma_op;
+    return ma_op(rhs, rhs, lhs);
+  }
+
+  CUTLASS_HOST_DEVICE
+  Array<T, N> operator()(Array<T, N> const &lhs, T const &rhs) const {
+    plus<Array<T, N>> plus_op;
+    multiplies<T> multiplies_op;
+    return plus_op(multiplies_op(rhs, rhs), lhs);
+  }
+};
+
+/// Inverse-square-root
+template <typename T, int N>
+struct inverse_square_root<Array<T, N>> {
+  CUTLASS_HOST_DEVICE
+  Array<T, N> operator()(Array<T, N> const &a) const {
+    Array<T, N> result;
+    inverse_square_root<T> scalar_op;
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < N; ++i) {
+      result[i] = scalar_op(a[i]);
+    }
+    return result;
+  }
+};
+
+template <int N>
+struct inverse_square_root<Array<half_t, N>> {
+  CUTLASS_HOST_DEVICE
+  Array<half_t, N> operator()(Array<half_t, N> const & a) const {
+    Array<half_t, N> result;
+    #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 530)
+
+    __half2 *result_ptr = reinterpret_cast<__half2 *>(&result);
+    __half2 const *a_ptr = reinterpret_cast<__half2 const *>(&a);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < N / 2; ++i) {
+      result_ptr[i] = h2rsqrt(a_ptr[i]);
+    }
+
+    if constexpr (N % 2) {
+      __half const *a_residual_ptr = reinterpret_cast<__half const *>(&a);
+      __half d_residual = hrsqrt(a_residual_ptr[N - 1]);
+      result[N - 1] = reinterpret_cast<half_t const &>(d_residual);
+    }
+
+    #else
+
+    inverse_square_root<half_t> scalar_op;
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < N; ++i) {
+      result[i] = scalar_op(a[i]);
+    }
+
+    #endif
+
+    return result;
+  }
+};
+
 /// Fused multiply-add-relu0
 template <typename T, int N>
 struct multiply_add_relu0<Array<T, N>, Array<T, N>, Array<T, N>> {
 
   CUTLASS_HOST_DEVICE
   Array<T, N> operator()(Array<T, N> const &a, Array<T, N> const &b, Array<T, N> const &c) const {
 
@@ -2497,28 +2519,41 @@
       result_data[i] = (a_data[i] ^ b_data[i]);
     }
 
     return result;
   }
 };
 
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 // Operator overloads
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename T, int N>
 CUTLASS_HOST_DEVICE
 Array<T, N> operator+(Array<T, N> const &lhs, Array<T, N> const &rhs) {
   plus<Array<T, N>> op;
   return op(lhs, rhs);
 }
 
 template <typename T, int N>
 CUTLASS_HOST_DEVICE
+Array<T, N> operator+(T const &lhs, Array<T, N> const &rhs) {
+  plus<Array<T, N>> op;
+  return op(lhs, rhs);
+}
+
+template <typename T, int N>
+CUTLASS_HOST_DEVICE
+Array<T, N> operator+(Array<T, N> const &lhs, T const &rhs) {
+  plus<Array<T, N>> op;
+  return op(lhs, rhs);
+}
+
+template <typename T, int N>
+CUTLASS_HOST_DEVICE
 Array<T, N> operator-(Array<T, N> const &lhs, Array<T, N> const &rhs) {
   minus<Array<T, N>> op;
   return op(lhs, rhs);
 }
 
 template <typename T, int N>
 CUTLASS_HOST_DEVICE
@@ -2605,15 +2640,15 @@
 /// Aligned array type
 template <
   /// Element type
   typename T,
   /// Number of elements in the array
   int N,
   /// Alignment requirement in bytes
-  int Alignment = sizeof_bits<T>::value * N / 8
+  int Alignment = ( sizeof_bits<T>::value * N + 7 ) / 8
 >
 class alignas(Alignment) AlignedArray: public Array<T, N> {
 public:
 
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/array_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array_planar_complex.h`

 * *Files 16% similar despite different names*

```diff
@@ -47,41 +47,27 @@
 template <typename Element_, int N>
 struct ArrayPlanarComplex {
 
   /// Underlying real element
   using Element = Element_;
 
   /// Number of logical elements
-  static size_t const kElements = N;
+  static constexpr size_t kElements = N;
 
   /// Underlying Fragment of real-valued elemenets
-  using ArrayReal = Array<Element, N>;
+  using ArrayReal = cutlass::Array<Element, N>;
 
 public:
-
   /// Fragment of real-valued elements representing the real part
   ArrayReal real;
 
   /// Fragment of real-valued elements representing the imaginary part
   ArrayReal imag;
 
 public:
-
-  /// Ctor
-  CUTLASS_HOST_DEVICE
-  ArrayPlanarComplex() { }
-
-  /// Ctor
-  CUTLASS_HOST_DEVICE
-  ArrayPlanarComplex(
-    ArrayReal const &real_,
-    ArrayReal const &imag_
-  ):
-    real(real_), imag(imag_) { }
-
   /// Sets the array to zero efficiently
   CUTLASS_HOST_DEVICE
   void clear() {
     real.clear();
     imag.clear();
   }
 };
@@ -89,15 +75,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Helper to deduce template arguments
 template <typename Element, int N>
 CUTLASS_HOST_DEVICE
 ArrayPlanarComplex<Element, N> 
 make_ArrayPlanarComplex(Array<Element, N> const &real, Array<Element, N> const &imag) {
-  return ArrayPlanarComplex<Element, N>(real, imag);
+  return ArrayPlanarComplex<Element, N>{real, imag};
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/array_subbyte.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/array_subbyte.h`

 * *Files 8% similar despite different names*

```diff
@@ -28,23 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Statically sized array of elements that accommodates all CUTLASS-supported numeric types
            and is safe to use in a union.
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/array.h"
 #include "cutlass/platform/platform.h"
 
@@ -53,18 +44,16 @@
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Statically sized array for any data type
 template <
   typename T,
   int N
 >
-class Array<T, N, false> {
-public:
-
-  static int const kSizeBits = sizeof_bits<T>::value * N;
+struct Array<T, N, false> {
+  static constexpr int kSizeBits = sizeof_bits<T>::value * N;
 
   /// Storage type
   using Storage = typename platform::conditional<
     ((kSizeBits % 32) != 0),
     typename platform::conditional<
       ((kSizeBits % 16) != 0),
       uint8_t,
@@ -73,24 +62,24 @@
     uint32_t
   >::type;
 
   /// Element type
   using Element = T;
 
   /// Number of logical elements per stored object
-  static int const kElementsPerStoredItem = int(sizeof(Storage) * 8) / sizeof_bits<T>::value;
+  static constexpr int kElementsPerStoredItem = int(sizeof(Storage) * 8) / sizeof_bits<T>::value;
 
   /// Number of storage elements
-  static size_t const kStorageElements = (N + kElementsPerStoredItem - 1) / kElementsPerStoredItem;
+  static constexpr size_t kStorageElements = (N + kElementsPerStoredItem - 1) / kElementsPerStoredItem;
 
   /// Number of logical elements
-  static size_t const kElements = N;
+  static constexpr size_t kElements = N;
 
   /// Bitmask for covering one item
-  static Storage const kMask = ((Storage(1) << sizeof_bits<T>::value) - 1);
+  static constexpr Storage kMask = ((Storage(1) << sizeof_bits<T>::value) - 1);
 
   //
   // C++ standard members with pointer types removed
   //
 
   typedef T value_type;
   typedef size_t size_type;
@@ -101,37 +90,62 @@
   //
   // References
   //
 
   /// Reference object inserts or extracts sub-byte items
   class reference {
     /// Pointer to storage element
-    Storage *ptr_;
+    Storage *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    reference(): ptr_(nullptr), idx_(0) { }
+    reference() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     reference(Storage *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
 
     /// Assignment
     CUTLASS_HOST_DEVICE
     reference &operator=(T x) {
+    // `*ptr_ & kUpdateMask` will read ptr_ before write to it
+    // This means code pattern like
+    //
+    // ```cpp
+    // Array<half_t, N> result;
+    // result[0] = xxx;
+    // ```
+    // 
+    // Will leads to compiler warning on use of unintialized member variable. Although we know
+    //      this read of uninitialized member variable is harmeless.
+
+#if defined(__clang__)
+#  pragma clang diagnostic push
+#  pragma clang diagnostic ignored "-Wuninitialized"
+#elif defined(__GNUC__)
+#  pragma GCC diagnostic push
+#  pragma GCC diagnostic ignored "-Wuninitialized"
+#  pragma GCC diagnostic ignored "-Wmaybe-uninitialized"
+#endif
+
       Storage item = (reinterpret_cast<Storage const &>(x) & kMask);
 
       Storage kUpdateMask = Storage(~(kMask << (idx_ * sizeof_bits<T>::value)));
+
       *ptr_ = Storage(((*ptr_ & kUpdateMask) | (item << idx_ * sizeof_bits<T>::value)));
 
+#if defined(__clang__)
+#  pragma clang diagnostic pop
+#elif defined(__GNUC__)
+#  pragma GCC diagnostic pop
+#endif
+
       return *this;
     }
 
     CUTLASS_HOST_DEVICE
     T get() const {
       Storage item = Storage((*ptr_ >> (idx_ * sizeof_bits<T>::value)) & kMask);
       return reinterpret_cast<T const &>(item);
@@ -156,24 +170,22 @@
     }
   };
 
   /// Reference object extracts sub-byte items
   class const_reference {
 
     /// Pointer to storage element
-    Storage const *ptr_;
+    Storage const *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    const_reference(): ptr_(nullptr), idx_(0) { }
+    const_reference() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     const_reference(Storage const *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
 
     CUTLASS_HOST_DEVICE
     const T get() const {
@@ -205,23 +217,22 @@
   // Iterators
   //
 
   /// Bidirectional iterator over elements
   class iterator {
 
     /// Pointer to storage element
-    Storage *ptr_;
+    Storage *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    CUTLASS_HOST_DEVICE
-    iterator(): ptr_(nullptr), idx_(0) { }
+    iterator() = default;
 
     CUTLASS_HOST_DEVICE
     iterator(Storage *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
 
     CUTLASS_HOST_DEVICE
     iterator &operator++() {
       ++idx_;
@@ -284,23 +295,22 @@
     }
   };
 
   /// Bidirectional constant iterator over elements
   class const_iterator {
 
     /// Pointer to storage element
-    Storage const *ptr_;
+    Storage const *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    CUTLASS_HOST_DEVICE
-    const_iterator(): ptr_(nullptr), idx_(0) { }
+    const_iterator() = default;
 
     CUTLASS_HOST_DEVICE
     const_iterator(Storage const *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
 
     CUTLASS_HOST_DEVICE
     iterator &operator++() {
       ++idx_;
@@ -363,66 +373,44 @@
     }
   };
 
   /// Bidirectional iterator over elements
   class reverse_iterator {
 
     /// Pointer to storage element
-    Storage *ptr_;
+    Storage *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    CUTLASS_HOST_DEVICE
-    reverse_iterator(): ptr_(nullptr), idx_(0) { }
+    reverse_iterator() = default;
 
     CUTLASS_HOST_DEVICE
     reverse_iterator(Storage *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
   };
 
   /// Bidirectional constant iterator over elements
   class const_reverse_iterator {
 
     /// Pointer to storage element
-    Storage const *ptr_;
+    Storage const *ptr_{nullptr};
 
     /// Index into elements packed into Storage object
-    int idx_;
+    int idx_{0};
 
   public:
 
-    CUTLASS_HOST_DEVICE
-    const_reverse_iterator(): ptr_(nullptr), idx_(0) { }
+    const_reverse_iterator() = default;
 
     CUTLASS_HOST_DEVICE
     const_reverse_iterator(Storage const *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
   };
 
-private:
-
-  /// Internal storage
-  Storage storage[kStorageElements];
-
-public:
-
-  #if 0
-  CUTLASS_HOST_DEVICE
-  Array() { }
-
-  CUTLASS_HOST_DEVICE
-  Array(Array const &x) {
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < int(kStorageElements); ++i) {
-      storage[i] = x.storage[i];
-    }
-  }
-  #endif
-
   /// Efficient clear method
   CUTLASS_HOST_DEVICE
   void clear() {
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < int(kStorageElements); ++i) {
       storage[i] = Storage(0);
@@ -485,15 +473,14 @@
   }
 
   CUTLASS_HOST_DEVICE
   Storage const * raw_data() const {
     return storage;
   }
 
-
   CUTLASS_HOST_DEVICE
   constexpr bool empty() const {
     return !kElements;
   }
 
   CUTLASS_HOST_DEVICE
   constexpr size_type size() const {
@@ -556,18 +543,17 @@
   }
 
   CUTLASS_HOST_DEVICE
   const_reverse_iterator crend() const {
     return const_reverse_iterator(storage);
   }
 
-  //
-  // Comparison operators
-  //
-
+private:
+  /// Internal storage
+  Storage storage[kStorageElements];
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/barrier.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/barrier.h`

 * *Files 2% similar despite different names*

```diff
@@ -272,18 +272,16 @@
   arrive_range_inc(uint32_t idx, void *lock_ptr, int thread_idx, int first_flag_idx, int count = 1, int val = 1) {
     arrive_range_inc_helper(idx, lock_ptr, thread_idx, first_flag_idx, count, val, IntegerSequence{});
   }
 
 private:
   CUTLASS_DEVICE
   static void
-  check_barrier_in_range(uint32_t idx) {
-    if (idx >= MaxNumNamedBarriers) {
-      CUTE_RUNTIME_ASSERT("Index exceeds barrier count");
-    }
+  check_barrier_in_range([[maybe_unused]] uint32_t idx) {
+    assert((idx >= MaxNumNamedBarriers) && "Index exceeds barrier count");
   }
 
   template <uint32_t... Idx>
   CUTLASS_DEVICE
   static void
   wait_lt_helper(uint32_t idx, void *lock_ptr, int thread_idx, int flag_idx, int count, cute::integer_sequence<uint32_t, Idx...>) {
     check_barrier_in_range(idx);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/bfloat16.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/bfloat16.h`

 * *Files 2% similar despite different names*

```diff
@@ -30,24 +30,14 @@
  **************************************************************************************************/
 /*!
     \file
     \brief Defines a proxy class for storing non-standard 16-bit floating point values with
           8 bits of exponent and 7 bit of mantissa.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #if defined(__CUDACC_RTC__)
 #include "cutlass/floating_point_nvrtc.h"
 #else
 #include <cmath>
 #include <limits>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/blas3.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/blas3_types.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/blas3_types.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/block_striped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/block_striped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/cluster_launch.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cluster_launch.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -34,15 +34,14 @@
 */
 
 #pragma once
 
 #include <cuda_runtime_api.h>
 #include "cutlass/cutlass.h"
 #include "cutlass/trace.h"
-
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/type_traits>
 #else
 #include <type_traits>
 #include <cstdio>
 #endif
 
@@ -94,14 +93,31 @@
 #if defined(CUTLASS_SM90_CLUSTER_LAUNCH_ENABLED)
   init(void const* kernel_function)
 #else
   init(void const* /* kernel_function */)
 #endif
   {
 #if defined(CUTLASS_SM90_CLUSTER_LAUNCH_ENABLED)
+#if defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
+    if (kernel_function == nullptr) {
+      CUTLASS_TRACE_HOST("kernel_function is null");
+      return Status::kInvalid;
+    }
+    CUTLASS_TRACE_HOST("Checking previous error state before calling cudaFuncSetAttribute");
+    cudaError_t prevStatus = cudaGetLastError();
+    if (prevStatus != cudaSuccess) {
+      fprintf(stderr,
+              "[ ERROR: CUDA Runtime ] %s:%d: %s\n",
+              __FILE__,
+              __LINE__,
+              cudaGetErrorString(prevStatus));
+      return Status::kInvalid;
+    }
+    CUTLASS_TRACE_HOST("Calling cudaFuncSetAttribute");
+#endif
     // This attribute was added in CUDA 11.8.
     cudaError_t status =
         cudaFuncSetAttribute(
           kernel_function, cudaFuncAttributeNonPortableClusterSizeAllowed, 1);
     Return_Status(status);
 #else
     return Status::kInvalid;
@@ -153,14 +169,15 @@
     cudaError_t status = cudaLaunchKernelExC(&launch_config, kernel, kernel_params);
     Return_Status(status);
 #else
     CUTLASS_TRACE_HOST("ClusterLauncher: CUTLASS_SM90_CLUSTER_LAUNCH_ENABLED not defined! Aborting cluster launch.");
     return Status::kInvalid;
 #endif
   }
+
 };
 
 namespace detail {
 
 template<class Arg>
 void* checked_addressof(Arg&& arg) {
   static_assert(! std::is_rvalue_reference_v<Arg> || ! std::is_const_v<Arg>, "You cannot take the address of a const rvalue reference (const T&&).");
@@ -208,37 +225,44 @@
 /// X x = get_x();
 /// Y y = get_y();
 /// Z z = get_z();
 ///
 /// void const* kernel_ptr =
 ///   const_cast<void const*>(reinterpret_cast<void*>(
 ///     &kernel<SharedMemory, X, Y, Z>));
-/// auto status = launch_on_cluster(
+/// auto status = launch_kernel_on_cluster(
 ///   {grid_dims, block_dims, cluster_dims, sizeof(SharedMemory)},
 ///   kernel_ptr, x, y, z);
 /// @endcode
 template<class ... Args>
 CUTLASS_HOST cutlass::Status
 launch_kernel_on_cluster(const ClusterLaunchParams& params,
   void const* kernel_ptr,
   Args&& ... args)
 {
   // Unfortunately, we find ourselves needing to pass in
   // the parameters as an array of raw pointers.
   if constexpr (sizeof...(Args) == 0) {
     return cutlass::ClusterLauncher::launch(
-      params.grid_dims, params.cluster_dims, params.block_dims,
-      params.smem_size_in_bytes, params.cuda_stream,
+      params.grid_dims,
+      params.cluster_dims,
+      params.block_dims,
+      params.smem_size_in_bytes,
+      params.cuda_stream,
       kernel_ptr, nullptr);
   }
   else {
     void* kernel_params[sizeof...(Args)] = {
       detail::checked_addressof(std::forward<Args>(args))...
     };
     return cutlass::ClusterLauncher::launch(
-      params.grid_dims, params.cluster_dims, params.block_dims,
-      params.smem_size_in_bytes, params.cuda_stream,
-      kernel_ptr, kernel_params);
+      params.grid_dims,
+      params.cluster_dims,
+      params.block_dims,
+      params.smem_size_in_bytes,
+      params.cuda_stream,
+      kernel_ptr,
+      kernel_params);
   }
 }
 
 }  // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/complex.h`

 * *Files 2% similar despite different names*

```diff
@@ -24,23 +24,14 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 #include <cuComplex.h>
 
 #include <cuda_fp16.h>
 
@@ -60,17 +51,14 @@
 
 #if !defined(__CUDACC_RTC__)
 #include <iosfwd>
 #endif
 
 namespace cutlass {
 
-
-
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Enumeraed type describing a transformation on a complex value.
 enum class ComplexTransform {
   kNone,
   kConjugate
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/constants.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/constants.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h`

 * *Files 2% similar despite different names*

```diff
@@ -31,32 +31,23 @@
 /*! \file
     \brief This file contains definitions and utility functions for describing convolution problem sizes.
 
   Conv2dProblem desciption:
     activation (NHWC), 
     filter (KRSC), 
     output (NPQK), 
-    pading (pad_h, pad_w), 
+    pading (pad_h, pad_w),
     stride (stride_h, stride_w),
     dilation (dilation_h, dilation_w).
     
   Free functions to map:
     Map tensor extents (Conv2d -> ImplicitGemm)      : implicit_gemm_tensor_[a|b|c]_extent(ConvolutionOperator)
     Map tensor sizes (Conv2d -> ImplicitGemm)        : implicit_gemm_tensor_[a|b|c]_size(ConvolutionOperator)
     Map tensor problem sizes (Conv2d -> ImplicitGemm): implicit_gemm_problem_size(ConvolutionOperator)
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/tensor_coord.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm_enumerated_types.h"
@@ -105,15 +96,15 @@
     int Q,
     int K,
     int R,
     int S,
     Mode mode
   ): 
     N(N), H(H), W(W), C(C), P(P), Q(Q), K(K), R(R), S(S),
-    pad_h(R / 2), pad_w(S / 2), stride_h(1), stride_w(1), dilation_h(1), dilation_w(1), 
+    pad_h(R / 2), pad_w(S / 2), stride_h(1), stride_w(1), dilation_h(1), dilation_w(1),
     mode(mode), split_k_slices(1), groups (1) { }
   
   /// Constructor
   CUTLASS_HOST_DEVICE
   Conv2dProblemSize(
     int N,
     int H,
@@ -129,17 +120,17 @@
     int stride_h,
     int stride_w,
     int dilation_h,
     int dilation_w,
     Mode mode,
     int split_k_slices = 1,
     int groups = 1
-  ): 
+  ):
     N(N), H(H), W(W), C(C), P(P), Q(Q), K(K), R(R), S(S),
-    pad_h(pad_h), pad_w(pad_w), stride_h(stride_h), stride_w(stride_w), 
+    pad_h(pad_h), pad_w(pad_w), stride_h(stride_h), stride_w(stride_w),
     dilation_h(dilation_h), dilation_w(dilation_w), 
     mode(mode), split_k_slices(split_k_slices), groups (groups) { }
 
   /// Constructs convolution problem size from cutlass Tensor4DCoord and MatrixCoord 
   // set user-defined output size and sets P and Q (include all data members in ctor)
   CUTLASS_HOST_DEVICE
   Conv2dProblemSize(
@@ -152,41 +143,41 @@
     cutlass::conv::Mode mode = cutlass::conv::Mode::kCrossCorrelation,
     int split_k_slices = 1,
     int groups = 1
   ):
     N(input_size.n()), H(input_size.h()), W(input_size.w()), C(input_size.c()),
     P(output_size.h()), Q(output_size.w()),
     K(filter_size.n()), R(filter_size.h()), S(filter_size.w()),
-    pad_h(padding[0]), pad_w(padding[2]), 
-    stride_h(stride.row()), stride_w(stride.column()), 
+    pad_h(padding[0]), pad_w(padding[2]),
+    stride_h(stride.row()), stride_w(stride.column()),
     dilation_h(dilation.row()), dilation_w(dilation.column()),
     mode(mode), split_k_slices(split_k_slices), groups(groups) {}
 
   /// Constructs convolution problem size from cutlass Tensor4DCoord and MatrixCoord 
   // computes output size and sets P and Q (skip output from ctor arguments)
   CUTLASS_HOST_DEVICE  
   Conv2dProblemSize(
     cutlass::Tensor4DCoord input_size,   // NHWC
     cutlass::Tensor4DCoord filter_size,  // KRSC
-    cutlass::Tensor4DCoord padding,      // pad_h, _, pad_w, _
+    cutlass::Tensor4DCoord padding,      // pad_h, upper_pad_h, pad_w, upper_pad_w
     cutlass::MatrixCoord stride,         // stride_h, stride_w
     cutlass::MatrixCoord dilation,       // dilation_h, dilation_w
     cutlass::conv::Mode mode = cutlass::conv::Mode::kCrossCorrelation,
     int split_k_slices = 1,
     int groups = 1
   ):
     N(input_size.n()), H(input_size.h()), W(input_size.w()), C(input_size.c()),
     K(filter_size.n()), R(filter_size.h()), S(filter_size.w()),
     pad_h(padding[0]), pad_w(padding[2]),
-    stride_h(stride.row()), stride_w(stride.column()), 
+    stride_h(stride.row()), stride_w(stride.column()),
     dilation_h(dilation.row()), dilation_w(dilation.column()),
     mode(mode), split_k_slices(split_k_slices), groups(groups) {
       // set output P and Q
-      P = ((H + pad_h * 2 - R * dilation_h) / stride_h) + 1;
-      Q = ((W + pad_w * 2 - S * dilation_w) / stride_w) + 1;
+      P = ((H + pad_h + padding[1] - R * dilation_h) / stride_h) + 1;
+      Q = ((W + pad_w + padding[3] - S * dilation_w) / stride_w) + 1;
     }
 
   /// Constructs convolution problem size from cutlass Tensor4DCoord and MatrixCoord 
   // set user-defined output size and sets P and Q (skip padding, striding, and dilation)
   CUTLASS_HOST_DEVICE
   Conv2dProblemSize(
     cutlass::Tensor4DCoord input_size,    // NHWC
@@ -195,15 +186,15 @@
     cutlass::conv::Mode mode = cutlass::conv::Mode::kCrossCorrelation,
     int split_k_slices = 1,
     int groups = 1
   ):
     N(input_size.n()), H(input_size.h()), W(input_size.w()), C(input_size.c()),
     P(output_size.h()), Q(output_size.w()),
     K(filter_size.n()), R(filter_size.h()), S(filter_size.w()),
-    pad_h(R / 2), pad_w(S / 2), stride_h(1), stride_w(1), 
+    pad_h(R / 2), pad_w(S / 2), stride_h(1), stride_w(1),
     dilation_h(1), dilation_w(1),
     mode(mode), split_k_slices(split_k_slices), groups(groups) {}
 
   // Reset covolution mode in the problem
   CUTLASS_HOST_DEVICE
   Conv2dProblemSize reset_mode(cutlass::conv::Mode mode_) {
     Conv2dProblemSize tmp(*this);
@@ -243,17 +234,18 @@
   cutlass::Tensor4DCoord activation_extent() const {
 
     return cutlass::Tensor4DCoord ({N, H, W, C});
   }
 
   /// Returns filter extent as Tensor4DCoord
   CUTLASS_HOST_DEVICE
-  cutlass::Tensor4DCoord filter_extent() const {
+  cutlass::Tensor4DCoord filter_extent(bool is_deconv = false) const {
 
-    return cutlass::Tensor4DCoord ({K, R, S, C / groups});
+    return is_deconv ? cutlass::Tensor4DCoord ({C, R, S, K / groups})
+        : cutlass::Tensor4DCoord ({K, R, S, C / groups});
   }
 
   /// Returns output extent as Tensor4DCoord
   CUTLASS_HOST_DEVICE
   cutlass::Tensor4DCoord output_extent() const {
 
     return cutlass::Tensor4DCoord ({N, P, Q, K});
@@ -336,14 +328,15 @@
   switch (conv_operator) {
   case Operator::kFprop:
     return gemm::GemmCoord(
       problem_size.N * problem_size.P * problem_size.Q,
       problem_size.K,
       problem_size.R * problem_size.S * problem_size.C / problem_size.groups
     );
+  case Operator::kDeconv:
   case Operator::kDgrad:
     return gemm::GemmCoord(
       problem_size.N * problem_size.H * problem_size.W,
       problem_size.C,
       problem_size.R * problem_size.S * problem_size.K
     );
   case Operator::kWgrad:
@@ -400,14 +393,15 @@
 
       switch (conv_operator) {
       case Operator::kFprop:
         elements_per_split_k_slice = (problem_size.C + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
         iterations = problem_size.R * problem_size.S * ((elements_per_split_k_slice + threadblock_K - 1) / threadblock_K);
         break;
 
+      case Operator::kDeconv:
       case Operator::kDgrad:
         elements_per_split_k_slice = (problem_size.K + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
         iterations = problem_size.R * problem_size.S * ((elements_per_split_k_slice + threadblock_K - 1) / threadblock_K);
         break;
 
       case Operator::kWgrad:
         elements_per_split_k_slice = (problem_size.N * problem_size.P * problem_size.Q + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
@@ -501,14 +495,15 @@
   int iterations = 0; //0 means not applicable
   if (algorithm == IteratorAlgorithm::kAnalytic || algorithm == IteratorAlgorithm::kOptimized) {
     switch (conv_operator) {
       case Operator::kFprop:
         iterations = problem_size.R * problem_size.S;
         break;
 
+      case Operator::kDeconv:
       case Operator::kDgrad:
         iterations = problem_size.R * problem_size.S;
         break;
 
       default:
         break;
     }
@@ -522,84 +517,90 @@
 /// Returns ImplicitGemm tensor A extent as Tensor4DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor4DCoord implicit_gemm_tensor_a_extent(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.activation_extent();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.output_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.output_extent();
     default : break;
   }
   return cutlass::Tensor4DCoord();
 }
 
 /// Returns ImplicitGemm tensor B extent as Tensor4DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor4DCoord implicit_gemm_tensor_b_extent(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.filter_extent();
+    case cutlass::conv::Operator::kDeconv: return problem_size.filter_extent(true);
     case cutlass::conv::Operator::kDgrad: return problem_size.filter_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.activation_extent();
     default : break;
   }
   return cutlass::Tensor4DCoord();
 }
 
 /// Returns ImplicitGemm tensor C extent as Tensor4DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor4DCoord implicit_gemm_tensor_c_extent(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.output_extent();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.activation_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.filter_extent();
     default : break;
   }
   return cutlass::Tensor4DCoord();
 }
 
 /// Returns ImplicitGemm tensor A size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_a_size(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.activation_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.output_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.output_size();
     default : break;
   }
   return 0;
 }
 
 /// Returns ImplicitGemm tensor B size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_b_size(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.filter_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.filter_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.activation_size();
     default : break;
   }
   return 0;
 }
 
 /// Returns ImplicitGemm tensor C size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_c_size(
   Operator conv_operator,
   Conv2dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.output_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.activation_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.filter_size();
     default : break;
   }
   return 0;
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h`

 * *Files 7% similar despite different names*

```diff
@@ -40,23 +40,14 @@
     dilation (dilation_d, dilation_h, dilation_w).
   
   Free functions to map:
     Map tensor extents (Conv3d -> ImplicitGemm)      : implicit_gemm_tensor_[a|b|c]_extent(ConvolutionOperator)
     Map tensor sizes (Conv3d -> ImplicitGemm)        : implicit_gemm_tensor_[a|b|c]_size(ConvolutionOperator)
     Map tensor problem sizes (Conv3d -> ImplicitGemm): implicit_gemm_problem_size(ConvolutionOperator)  
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 #include "cutlass/conv/convolution.h"
 #include "cutlass/conv/conv2d_problem_size.h"
 
 namespace cutlass {
@@ -87,15 +78,15 @@
   // Methods
   //
 public:
   CUTLASS_HOST_DEVICE
   Conv3dProblemSize(): 
     Conv2dProblemSize(),
     D(0), T(0), Z(0), 
-    pad_d(0), 
+    pad_d(0),
     stride_d(1), 
     dilation_d(1) { }
  
   /// Constructor for default padding, stride, dilation, and split-K
   CUTLASS_HOST_DEVICE
   Conv3dProblemSize(
     int N,
@@ -201,14 +192,42 @@
     D(input_size.d()), T(filter_size.d()),
     pad_d(padding[0]), stride_d(stride[0]), dilation_d(dilation[0])
     {
       // set output Z
       Z = ((D + pad_d * 2 - T * dilation_d) / stride_d) + 1;
     }
 
+  /// Constructs convolution problem size from cutlass Tensor5DCoord, Coord3D
+  // *computes* output size and sets Z, P and Q (include all data members in ctor)
+  CUTLASS_HOST_DEVICE
+  Conv3dProblemSize(
+    cutlass::Tensor5DCoord input_size,    // NDHWC
+    cutlass::Tensor5DCoord filter_size,   // KTRSC
+    CUTLASS_STL_NAMESPACE::tuple<Coord3D, Coord3D> padding, // Coord3D {pad_d, pad_h, pad_w} & Coord3D {far pad_d, pad_h, pad_w} to calculate o/p/q
+    Coord3D stride,                       // stride_d, stride_h, stride_w
+    Coord3D dilation,                     // dilation_d, dilation_h, dilation_w
+    cutlass::conv::Mode mode = cutlass::conv::Mode::kCrossCorrelation,
+    int split_k_slices = 1,
+    int groups = 1
+  ):
+    Conv2dProblemSize(
+      {input_size.n(), input_size.h(), input_size.w(), input_size.c()},
+      {filter_size.n(), filter_size.h(), filter_size.w(), filter_size.c()},
+      {CUTLASS_STL_NAMESPACE::get<0>(padding)[1], CUTLASS_STL_NAMESPACE::get<1>(padding)[1],
+       CUTLASS_STL_NAMESPACE::get<0>(padding)[2], CUTLASS_STL_NAMESPACE::get<1>(padding)[2]},
+      {stride[1], stride[2]},
+      {dilation[1], dilation[2]},
+      mode, split_k_slices, groups),
+    D(input_size.d()), T(filter_size.d()),
+    pad_d(CUTLASS_STL_NAMESPACE::get<0>(padding)[0]), stride_d(stride[0]), dilation_d(dilation[0])
+    {
+      // set output Z
+      Z = ((D + pad_d + CUTLASS_STL_NAMESPACE::get<1>(padding)[0] - T * dilation_d) / stride_d) + 1;
+    }
+
   /// Equality operator (ignores mode and split_k_slice)
   CUTLASS_HOST_DEVICE
   bool operator==(Conv3dProblemSize const &conv) const {
     return (
       (N == conv.N) && (D == conv.D) && (H == conv.H) && (W == conv.W) && (C == conv.C) &&
       (K == conv.K) && (T == conv.T) && (R == conv.R) && (S == conv.S) &&
       (Z == conv.Z) &&(P == conv.P) && (Q == conv.Q) &&
@@ -245,17 +264,18 @@
   cutlass::Tensor5DCoord activation_extent() const {
 
     return cutlass::Tensor5DCoord ({N, D, H, W, C});
   }
 
   /// Returns filter extent as Tensor5DCoord
   CUTLASS_HOST_DEVICE
-  cutlass::Tensor5DCoord filter_extent() const {
+  cutlass::Tensor5DCoord filter_extent(bool is_deconv = false) const {
 
-    return cutlass::Tensor5DCoord ({K, T, R, S, C});
+    return is_deconv ? cutlass::Tensor5DCoord ({C, T, R, S, K})
+        : cutlass::Tensor5DCoord ({K, T, R, S, C});
   }
 
   /// Returns output extent as Tensor5DCoord
   CUTLASS_HOST_DEVICE
   cutlass::Tensor5DCoord output_extent() const {
 
     return cutlass::Tensor5DCoord ({N, Z, P, Q, K});
@@ -278,15 +298,15 @@
   /// Returns output size in number of elements
   CUTLASS_HOST_DEVICE
   int64_t output_size() const {
 
     return (N * Z * P * Q * K);
   }
 
-  /// Returns output extent as Tensor5DCoord
+  /// Returns padding as Coord3D
   CUTLASS_HOST_DEVICE
   Coord3D padding() const {
 
     return Coord3D ({pad_d, pad_h, pad_w});
   }
 
   /// Returns stride as MatrixCoord
@@ -319,14 +339,15 @@
   switch (conv_operator) {
   case Operator::kFprop:
     return gemm::GemmCoord(
       problem_size.N * problem_size.Z * problem_size.P * problem_size.Q,
       problem_size.K,
       problem_size.T * problem_size.R * problem_size.S * problem_size.C
     );
+  case Operator::kDeconv:
   case Operator::kDgrad:
     return gemm::GemmCoord(
       problem_size.N * problem_size.D * problem_size.H * problem_size.W,
       problem_size.C,
       problem_size.T * problem_size.R * problem_size.S * problem_size.K
     );
   case Operator::kWgrad:
@@ -355,15 +376,16 @@
   int elements_per_split_k_slice = 0;
   if (group_mode == GroupMode::kNone) {
     switch (conv_operator) {
       case Operator::kFprop:
         elements_per_split_k_slice = (problem_size.C + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
         iterations = problem_size.T * problem_size.R * problem_size.S * ((elements_per_split_k_slice + threadblock_K - 1) / threadblock_K);
         break;
-    
+
+      case Operator::kDeconv:
       case Operator::kDgrad:
         elements_per_split_k_slice =  (problem_size.K + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
         iterations = problem_size.T * problem_size.R * problem_size.S * ((elements_per_split_k_slice + threadblock_K - 1) / threadblock_K);
         break;
     
       case Operator::kWgrad:
         elements_per_split_k_slice = (problem_size.N * problem_size.Z * problem_size.P * problem_size.Q + problem_size.split_k_slices - 1) / problem_size.split_k_slices;
@@ -398,84 +420,90 @@
 /// Returns ImplicitGemm tensor A extent as Tensor5DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor5DCoord implicit_gemm_tensor_a_extent(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.activation_extent();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.output_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.output_extent();
     default : break;
   }
   return cutlass::Tensor5DCoord();
 }
 
 /// Returns ImplicitGemm tensor B extent as Tensor5DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor5DCoord implicit_gemm_tensor_b_extent(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.filter_extent();
+    case cutlass::conv::Operator::kDeconv: return problem_size.filter_extent(true);
     case cutlass::conv::Operator::kDgrad: return problem_size.filter_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.activation_extent();
     default : break;
   }
   return cutlass::Tensor5DCoord();
 }
 
 /// Returns ImplicitGemm tensor C extent as Tensor5DCoord
 CUTLASS_HOST_DEVICE
 cutlass::Tensor5DCoord implicit_gemm_tensor_c_extent(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.output_extent();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.activation_extent();
     case cutlass::conv::Operator::kWgrad: return problem_size.filter_extent();
     default : break;
   }
   return cutlass::Tensor5DCoord();
 }
 
 /// Returns ImplicitGemm tensor A size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_a_size(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.activation_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.output_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.output_size();
     default : break;
   }
   return 0;
 }
 
 /// Returns ImplicitGemm tensor B size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_b_size(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.filter_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.filter_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.activation_size();
     default : break;
   }
   return 0;
 }
 
 /// Returns ImplicitGemm tensor C size in number of elements
 CUTLASS_HOST_DEVICE
 int64_t implicit_gemm_tensor_c_size(
   Operator conv_operator,
   Conv3dProblemSize const &problem_size) {
   switch (conv_operator) {
     case cutlass::conv::Operator::kFprop: return problem_size.output_size();
+    case cutlass::conv::Operator::kDeconv:
     case cutlass::conv::Operator::kDgrad: return problem_size.activation_size();
     case cutlass::conv::Operator::kWgrad: return problem_size.filter_size();
     default : break;
   }
   return 0;
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/convolution.h`

 * *Files 8% similar despite different names*

```diff
@@ -66,24 +66,14 @@
 as operating on "A, B, Output."  Instead, use the mapping functions below,
 and adhere to using either A, B, C or Activation, Filter, Output.
 
 Map elements' data types (ImplicitGemm -> Conv): GemmToConvElementMap
 Map elements' data types (Conv -> ImplicitGemm): ConvToGemmElementMap
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/layout/tensor.h"
 #include "cutlass/tensor_coord.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm_enumerated_types.h"
@@ -94,15 +84,16 @@
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Convolutional operator
 enum class Operator {
   kFprop,
   kDgrad,
-  kWgrad
+  kWgrad,
+  kDeconv
 };
 
 /// Distinguishes convolution from cross correlation
 enum class Mode {
   kCrossCorrelation,
   kConvolution
 };
@@ -167,13 +158,37 @@
   /// Returns a Coord object
   CUTLASS_HOST_DEVICE
   static Coord<4> toCoord() {
     return make_Coord(kN, kH, kW, kC);
   }
 };
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Shape of a conv2d stride, which controls how the filter convolves around the input volume
+template <
+  /// Stride in horizontal direction
+  int u = 1,
+  /// Stride in vertical direction
+  int v = 1
+>
+struct Stride2D {
+  static int const kU = u;
+  static int const kV = v;
+
+  //
+  // Static member functions
+  //
+
+  /// Returns a Coord object
+  CUTLASS_HOST_DEVICE
+  static Coord<2> toCoord() {
+    return make_Coord(kU, kV);
+  }
+};
+
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace conv
 } // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h`

 * *Files 8% similar despite different names*

```diff
@@ -35,14 +35,15 @@
 #pragma once
 
 #include <limits>
 
 #include "cutlass/cutlass.h"
 #include "cutlass/device_kernel.h"
 #include "cutlass/conv/convolution.h"
+#include "cutlass/cuda_host_adapter.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace device {
 
@@ -76,14 +77,16 @@
   using MathOperator = typename UnderlyingKernel::MathOperator; 
 
   static cutlass::conv::Operator const kConvolutionalOperator = UnderlyingKernel::kConvolutionalOperator;
   static cutlass::conv::IteratorAlgorithm const kIteratorAlgorithm = UnderlyingKernel::kIteratorAlgorithm;
   static cutlass::conv::StrideSupport const kStrideSupport = UnderlyingKernel::kStrideSupport;
   static cutlass::conv::GroupMode const kGroupMode = UnderlyingKernel::kGroupMode;
 
+  static bool const kEnableCudaHostAdapter = CUTLASS_ENABLE_CUDA_HOST_ADAPTER;
+
   static int const kWarpCount = 
     (ThreadblockShape::kM / WarpShape::kM) * 
     (ThreadblockShape::kN / WarpShape::kN) *
     (ThreadblockShape::kK / WarpShape::kK);
 
   /// Argument structure
   using Arguments = typename UnderlyingKernel::Arguments;
@@ -146,32 +149,32 @@
       }
     }
 
     static int const kAlignmentC = UnderlyingKernel::Epilogue::OutputTileIterator::kElementsPerAccess;
     if (kConvolutionalOperator == conv::Operator::kFprop) {
       if (args.problem_size.K % kAlignmentC)
         return Status::kErrorMisalignedOperand;
-    } else if (kConvolutionalOperator == conv::Operator::kDgrad) {
+    } else if (kConvolutionalOperator == conv::Operator::kDgrad || kConvolutionalOperator == conv::Operator::kDeconv) {
        if (args.problem_size.C % kAlignmentC)
         return Status::kErrorMisalignedOperand;
     } else if (kConvolutionalOperator == conv::Operator::kWgrad) {
        if (args.problem_size.C % kAlignmentC)
         return Status::kErrorMisalignedOperand;
     }
 
-    // check for unsupported problem sizes for strided dgrad implementation
-    if (kConvolutionalOperator == conv::Operator::kDgrad && 
+    // check for unsupported problem sizes for strided dgrad / deconv implementation
+    if ((kConvolutionalOperator == conv::Operator::kDgrad || kConvolutionalOperator == conv::Operator::kDeconv) &&
       kStrideSupport == conv::StrideSupport::kStrided) {
 
-      // split-k (serial or parallel) is not supported for strided dgrad
+      // split-k (serial or parallel) is not supported for strided dgrad / deconv
       if(args.problem_size.split_k_slices > 1) {
         return Status::kErrorNotSupported;
       }
-      
-      // dilation > {1x1} is not supported for strided dgrad
+
+      // dilation > {1x1} is not supported for strided dgrad / deconv
       if(args.problem_size.dilation_h > 1 || args.problem_size.dilation_w > 1) {
         return Status::kErrorNotSupported;
       }
     }
 
     // Determine grid shape
     ThreadblockSwizzle threadblock_swizzle;
@@ -226,15 +229,16 @@
     return workspace_bytes;
   }
 
   /// Initializes GEMM state from arguments.
   Status initialize(
     Arguments const &args, 
     void *workspace = nullptr, 
-    cudaStream_t stream = nullptr) {
+    cudaStream_t stream = nullptr,
+    CudaHostAdapter *cuda_adapter = nullptr) {
    
     if (args.problem_size.split_k_slices > 1) {
 
       if (!workspace) {
         return Status::kErrorWorkspaceNull;
       }
 
@@ -246,24 +250,30 @@
     }
 
     // initialize the params structure from the arguments
     params_ = typename UnderlyingKernel::Params(
     	args,
     	static_cast<int *>(workspace)
     );
-    
-    int smem_size = int(sizeof(typename UnderlyingKernel::SharedStorage));
 
-    if (smem_size >= (48 << 10)) {
-      cudaError_t result = cudaFuncSetAttribute(cutlass::Kernel<UnderlyingKernel>,
-                                    cudaFuncAttributeMaxDynamicSharedMemorySize,
-                                    smem_size);
-
-      if (result != cudaSuccess) {
-        return Status::kErrorInternal;
+    if constexpr (kEnableCudaHostAdapter) {
+      CUTLASS_ASSERT(cuda_adapter);
+      return Status::kSuccess;
+    }
+    else {
+      int smem_size = int(sizeof(typename UnderlyingKernel::SharedStorage));
+  
+      if (smem_size >= (48 << 10)) {
+        cudaError_t result = cudaFuncSetAttribute(cutlass::Kernel<UnderlyingKernel>,
+                                      cudaFuncAttributeMaxDynamicSharedMemorySize,
+                                      smem_size);
+  
+        if (result != cudaSuccess) {
+          return Status::kErrorInternal;
+        }
       }
     }
     
     return Status::kSuccess;
   }
 
   /// Initializes GEMM state from arguments.
@@ -277,46 +287,70 @@
     params_.output_op = args.output_op;
     params_.semaphore = static_cast<int *>(workspace);
 
     return Status::kSuccess;
   }
 
   /// Runs the kernel using initialized state.
-  Status run(cudaStream_t stream = nullptr) {
+  Status run(cudaStream_t stream = nullptr, CudaHostAdapter *cuda_adapter = nullptr) {
 
 
     ThreadblockSwizzle threadblock_swizzle;
 
     dim3 grid = threadblock_swizzle.get_grid_shape(params_.grid_tiled_shape);
     dim3 block(32 * kWarpCount, 1, 1);
 
     int smem_size = int(sizeof(typename UnderlyingKernel::SharedStorage));
+    cutlass::Status launch_result = cutlass::Status::kSuccess ;
 
-    cutlass::Kernel<UnderlyingKernel><<<grid, block, smem_size, stream>>>(params_);
+    if constexpr (kEnableCudaHostAdapter) {
+        //
+        // Use the cuda host adapter
+        //
+        CUTLASS_ASSERT(cuda_adapter);
+        if (cuda_adapter) {
+
+          void* kernel_params[] = {&params_};
+          launch_result = cuda_adapter->launch(
+              grid, dim3(1,1,1), block, smem_size, stream, kernel_params, 0
+              );
+        }
+        else {
+          launch_result = Status::kErrorInternal;
+        }
+    }
+    else {
+      cutlass::Kernel<UnderlyingKernel><<<grid, block, smem_size, stream>>>(params_);      
+    }
 
     cudaError_t result = cudaGetLastError();
-
-    return result == cudaSuccess ? Status::kSuccess : Status::kErrorInternal;
+    if (cudaSuccess == result && Status::kSuccess == launch_result) {
+      return Status::kSuccess;
+    }
+    else {
+      CUTLASS_TRACE_HOST("  Kernel launch failed. Reason: " << result);
+      return Status::kErrorInternal;
+    }
   }
 
   /// Runs the kernel using initialized state.
-  Status operator()(cudaStream_t stream = nullptr) {
-    return run(stream);
+  Status operator()(cudaStream_t stream = nullptr, CudaHostAdapter *cuda_adapter = nullptr) {
+    return run(stream, cuda_adapter);
   }
 
   /// Runs the kernel using initialized state.
   Status operator()(
     Arguments const &args, 
     void *workspace = nullptr, 
-    cudaStream_t stream = nullptr) {
+    cudaStream_t stream = nullptr, CudaHostAdapter *cuda_adapter = nullptr) {
     
-    Status status = initialize(args, workspace, stream);
+    Status status = initialize(args, workspace, stream, cuda_adapter);
     
     if (status == Status::kSuccess) {
-      status = run(stream);
+      status = run(stream, cuda_adapter);
     }
 
     return status;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h`

 * *Files 9% similar despite different names*

```diff
@@ -102,14 +102,57 @@
     PartitionsK,
     OutputOp,
     OutputOp::kCount
   >::Epilogue;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+template <
+  typename ArchTag,
+  typename Shape,
+  typename WarpMmaSimt,
+  typename ElementOutput,
+  typename ElementTensor,
+  typename ElementVector,
+  typename OutputOp,
+  int ElementsPerAccess
+>
+struct DefaultConvEpilogueWithBroadcastSimt {
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueWithBroadcastSimt<
+    Shape,
+    WarpMmaSimt,
+    ElementOutput,
+    ElementTensor,
+    ElementVector,
+    OutputOp,
+    ElementsPerAccess
+  >::Epilogue;
+};
+
+template <
+  typename ArchTag,
+  typename Shape,
+  typename WarpMmaSimt,
+  typename ElementOutput,
+  typename ElementTensor,
+  typename ElementVector,
+  typename OutputOp,
+  int ElementsPerAccess
+>
+struct DefaultConvEpilogueWithBroadcastSimtStridedDgrad {
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueWithBroadcastSimtStridedDgrad<
+    Shape,
+    WarpMmaSimt,
+    ElementOutput,
+    ElementTensor,
+    ElementVector,
+    OutputOp,
+    ElementsPerAccess
+  >::Epilogue;
+};
 
 template <
   typename ArchTag,
   typename Shape,
   typename WarpMmaTensorOp,
   int PartitionsK,
   typename ElementOutput,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h`

 * *Files 0% similar despite different names*

```diff
@@ -72,15 +72,15 @@
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
   /// Access granularity of A matrix in units of elements
   int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
   /// Access granularity of B matrix in units of elements
   int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
 > struct DefaultConv2dFprop;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -323,15 +323,14 @@
     Mma,
     Epilogue,
     ThreadblockSwizzle,
     conv::Operator::kFprop
   >;
 };
 
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Defines a kernel for Conv2dFprop specialization for Analytic IteratorAlgorithm and two stage
 /// pipeline.
 template <
   typename ElementA,
   typename LayoutA,
@@ -1163,15 +1162,19 @@
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
     ThreadblockShape,
     WarpMmaTensorOp,
     kPartitionsK,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount
+    EpilogueOutputOp::kCount,
+    false,
+    layout::NoPermute,
+    StrideSupport,
+    4
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
@@ -1624,15 +1627,19 @@
   >;
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount
+    EpilogueOutputOp::kCount,
+    false,
+    layout::NoPermute,
+    StrideSupport,
+    4
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
@@ -1737,25 +1744,28 @@
   >;
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount
+    EpilogueOutputOp::kCount,
+    false,
+    layout::NoPermute,
+    StrideSupport,
+    4
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
     conv::Operator::kFprop
   >;
-
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Defines a kernel for Conv2dFprop specialization for Analytic IteratorAlgorithm, 
 /// 2 stage pipeline, and FFMA-based mainloop for SM50
 template <
@@ -1849,15 +1859,19 @@
   >;
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount
+    EpilogueOutputOp::kCount,
+    false,
+    layout::NoPermute,
+    StrideSupport,
+    4
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
@@ -1963,15 +1977,19 @@
   >;
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount
+    EpilogueOutputOp::kCount,
+    false,
+    layout::NoPermute,
+    StrideSupport,
+    4
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -72,15 +72,15 @@
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity
 > struct DefaultConv2dFpropFusion;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //                         OpClassTensorOp convolutions 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Defines a kernel for Conv2dFprop specialization for Analytic IteratorAlgorithm and multistage
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_absmax.h`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,28 +26,26 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-  \brief 
-    Defines a GEMM with Reduction based on an existing UniversalGemm kernel.
-
+  \brief Defines a default configuration for convolution with absolute maximum calculation.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 
 #include "cutlass/conv/kernel/default_conv2d_fprop.h"
-#include "cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h"
+#include "cutlass/conv/kernel/implicit_gemm_convolution_with_absmax.h"
 
-#include "cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_broadcast.h"
+#include "cutlass/epilogue/threadblock/default_epilogue_with_absmax.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_absmax.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace kernel {
 
@@ -67,21 +65,21 @@
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
   /// Access granularity of A matrix in units of elements
   int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
   /// Access granularity of B matrix in units of elements
   int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
 >
-struct DefaultConv2dFpropWithBroadcast {
+struct DefaultConv2dFpropWithAbsMax {
 
   using ImplicitGemmBase = typename DefaultConv2dFprop<
     ElementA, LayoutA,
     ElementB, LayoutB,
     ElementC, LayoutC,
     ElementAccumulator,
     OperatorClass,
@@ -96,28 +94,27 @@
     IteratorAlgorithm,
     StrideSupport,
     AlignmentA,
     AlignmentB
   >::Kernel;
 
   // Define epilogue
-  using Epilogue = typename cutlass::conv::kernel::detail::DefaultConvEpilogueWithBroadcastTensorOp<
-    ArchTag,
+  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithAbsMax<
     typename ImplicitGemmBase::Epilogue::Shape,
     typename ImplicitGemmBase::Epilogue::WarpMmaOperator,
     ImplicitGemmBase::Epilogue::kPartitionsK,
     ElementC,
-    typename EpilogueOutputOp::ElementT,
-    typename EpilogueOutputOp::ElementVector,
+    typename EpilogueOutputOp::ElementAuxOutput,
+    ElementC,
     EpilogueOutputOp,
     ImplicitGemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolutionWithFusedEpilogue<
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolutionWithAbsMax<
     typename ImplicitGemmBase::Mma,
     Epilogue,
     ThreadblockSwizzle,
     conv::Operator::kFprop
   >;
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -68,15 +68,15 @@
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename EpilogueReductionOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
   /// Access granularity of A matrix in units of elements
   int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
   /// Access granularity of B matrix in units of elements
   int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
 >
 struct DefaultConv2dFpropWithReduction {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h`

 * *Files 1% similar despite different names*

```diff
@@ -53,15 +53,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Conv2dGroupFpro
+/// Defines a kernel for Conv2dGroupFprop
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -73,15 +73,15 @@
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::GroupMode GroupMode,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
   /// Access granularity of A matrix in units of elements
   int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
   /// Access granularity of B matrix in units of elements
   int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
 > struct DefaultConv2dGroupFprop;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -131,19 +131,19 @@
   GroupMode,
   IteratorAlgorithm::kAnalytic,
   StrideSupport,
   AlignmentA,
   AlignmentB
 > {
 
-  static_assert(std::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
       ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
       Stages, MathOperatorTag>;
@@ -265,19 +265,19 @@
   GroupMode,
   IteratorAlgorithm::kAnalytic,
   StrideSupport,
   AlignmentA,
   AlignmentB
 > {
 
-  static_assert(std::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
       ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
       2, MathOperatorTag>;
@@ -396,19 +396,19 @@
   GroupMode::kSingleGroup,
   IteratorAlgorithm::kOptimized,
   StrideSupport,
   AlignmentA,
   AlignmentB
 > {
 
-  static_assert(std::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
       ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
       Stages, MathOperatorTag>;
@@ -526,19 +526,19 @@
   GroupMode::kSingleGroup,
   IteratorAlgorithm::kOptimized,
   StrideSupport,
   AlignmentA,
   AlignmentB
 > {
 
-  static_assert(std::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutA, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutB, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
-  static_assert(std::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
+  static_assert(platform::is_same<LayoutC, cutlass::layout::TensorNHWC>::value,
     "Current group conv only support NHWC layout");
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
     ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
     ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
     2, MathOperatorTag>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h`

 * *Files 19% similar despite different names*

```diff
@@ -24,280 +24,229 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
     \brief 
-    Default kernel-level implicit GEMM convolution definitions combine threadblock-scoped 
-      matrix multiply-add with the appropriate threadblock-scoped epilogue.  
+      Default kernel-level GEMM definitions combine threadblock-scoped matrix multiply-add with
+      the appropriate threadblock-scoped epilogue.
+  
+      Note, CUTLASS epilogues universally target row-major outputs. Column-major outputs are
+      accommodated by exchanging A and B operands and assuming transposed layouts. Partial
+      specializations here choose 'device::GemmTransposed' to implement this functionality.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/conv/kernel/default_conv2d.h"
 
-#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h"
-#include "cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h"
+#include "cutlass/layout/matrix.h"
+#include "cutlass/numeric_types.h"
+#include "cutlass/arch/wmma.h"
+
+#include "cutlass/epilogue/threadblock/epilogue.h"
+#include "cutlass/epilogue/thread/linear_combination.h"
+
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/kernel/gemm.h"
+#include "cutlass/gemm/kernel/sparse_gemm.h"
+#include "cutlass/gemm/kernel/gemm_pipelined.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm75.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm70.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h"
+#include "cutlass/gemm/threadblock/default_sparse_mma.h"
+#include "cutlass/gemm/threadblock/default_mma_core_simt.h"
+#include "cutlass/gemm/threadblock/threadblock_swizzle.h"
+
+#include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
+#include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
+#include "cutlass/epilogue/threadblock/default_epilogue_simt.h"
+#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
+
+#if defined(CUTLASS_ARCH_WMMA_ENABLED)
+#include "cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h"
+#endif //CUTLASS_ARCH_WMMA_ENABLED
 
-#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/conv2d_tile_iterator.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
-namespace conv {
+namespace gemm {
 namespace kernel {
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Conv3dDgrad
+////////////////////////////////////////////////////////////////////////////////
+
 template <
-  typename ElementA,
-  typename LayoutA,
-  typename ElementB,
-  typename LayoutB,
-  typename ElementC,
-  typename LayoutC,
-  typename ElementAccumulator,
-  typename OperatorClass,
-  typename ArchTag,
-  typename ThreadblockShape,
-  typename WarpShape,
-  typename InstructionShape,
-  typename EpilogueOutputOp,
-  typename ThreadblockSwizzle,
-  int Stages,
-  typename MathOperatorTag,
-  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided
-> struct DefaultConv3dDgrad;
+    /// Element type for A matrix operand
+    typename ElementA_,
+    /// Layout type for A matrix operand
+    typename LayoutA_,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB_,
+    /// Layout type for B matrix operand
+    typename LayoutB_,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB,
+    /// Element type for C and D matrix operands
+    typename ElementC_,
+    /// Layout type for C and D matrix operands
+    typename LayoutC_,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Operator class tag
+    typename OperatorClass,
+    /// Tag indicating architecture to tune for
+    typename ArchTag,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// If true, kernel is configured to support serial reduction in the
+    /// epilogue
+    bool SplitKSerial,
+    /// Operation performed by GEMM
+    typename Operator>
+struct DefaultSparseGemm;
 
-/// Defines a kernel for Conv3dDgrad specialization for Analytic IteratorAlgorithm Dgrad Strided
-// and multistage pipeline.
+////////////////////////////////////////////////////////////////////////////////
+///////////////////////////////////////////////////////////////////////////////
+
+/// Partial specialization for Ampere Architecture
 template <
-  typename ElementA,
-  typename LayoutA,
-  typename ElementB,
-  typename LayoutB,
-  typename ElementC,
-  typename LayoutC,
-  typename ElementAccumulator,
-  typename OperatorClass,
-  typename ArchTag,
-  typename ThreadblockShape,
-  typename WarpShape,
-  typename InstructionShape,
-  typename EpilogueOutputOp,
-  typename ThreadblockSwizzle,
-  int Stages,
-  typename MathOperatorTag
->
-struct DefaultConv3dDgrad <
-  ElementA,
-  LayoutA,
-  ElementB,
-  LayoutB,
-  ElementC,
-  LayoutC,
-  ElementAccumulator,
-  OperatorClass,
-  ArchTag,
-  ThreadblockShape,
-  WarpShape,
-  InstructionShape,
-  EpilogueOutputOp,
-  ThreadblockSwizzle,
-  Stages,
-  MathOperatorTag,
-  IteratorAlgorithm::kAnalytic,
-  StrideSupport::kStrided
-> {
-
-  // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, MathOperatorTag>;
-
-  // Define iterators over tiles from the A operand
-  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using IteratorA =
-    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
-      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-      ElementA,
-      ThreadMapA,
-      StrideSupport::kStrided
-    >;
-
-  using SmemIteratorA = typename MmaCore::SmemIteratorA;
-
-  // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using IteratorB =
-    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorAnalytic<
-      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-      ElementB,
-      ThreadMapB
-    >;
-  
-  using SmemIteratorB = typename MmaCore::SmemIteratorB;
+    /// Element type for A matrix operand
+    typename ElementA,
+    /// Layout type for A matrix operand
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB,
+    /// Layout type for B matrix operand
+    typename LayoutB,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentB,
+    /// Element type for C and D matrix operands
+    typename ElementC,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// If true, kernel is configured to support serial reduction in the
+    /// epilogue
+    bool SplitKSerial,
+    /// Operation performed by GEMM
+    typename Operator>
+struct DefaultSparseGemm<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB, ElementC,
+                   layout::RowMajor, ElementAccumulator, arch::OpClassTensorOp,
+                   arch::Sm80, ThreadblockShape, WarpShape, InstructionShape,
+                   EpilogueOutputOp, ThreadblockSwizzle, Stages, SplitKSerial,
+                   Operator> {
+  /// Define the threadblock-scoped matrix multiply-accumulate
+  using Mma = typename cutlass::gemm::threadblock::DefaultSparseMma<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm80,
+      ThreadblockShape, WarpShape, InstructionShape, Stages,
+      Operator>::ThreadblockMma;
+
+  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+
+  /// Define the epilogue
+  using Epilogue =
+      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
+          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
+          EpilogueOutputOp::kCount>::Epilogue;
 
-  // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
-  using MmaPolicy = typename MmaCore::MmaPolicy;
-
-  // Define the Mma
-  using Mma = threadblock::ImplicitGemmMultistage<
-    ThreadblockShape,
-    IteratorA,
-    SmemIteratorA,
-    arch::CacheOperation::Always,
-    IteratorB,
-    SmemIteratorB,
-    arch::CacheOperation::Global,
-    MmaPolicy,
-    Stages 
-  >;
-
-  // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
-    ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp,
-    EpilogueOutputOp::kCount
-  >::Epilogue;
-
-  // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
-    Mma,
-    Epilogue,
-    ThreadblockSwizzle,
-    conv::Operator::kDgrad,
-    Conv3dProblemSize
-  >;
+  /// Define the kernel-level GEMM operator.
+  using GemmKernel = kernel::SparseGemm<Mma, Epilogue, ThreadblockSwizzle, SplitKSerial>;
 };
 
+///////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Defines a kernel for Conv3dDgrad specialization for Optimized IteratorAlgorithm Dgrad Strided
-// and multistage pipeline.
+/// Partial specialization for Ada Architecture
 template <
-  typename ElementA,
-  typename LayoutA,
-  typename ElementB,
-  typename LayoutB,
-  typename ElementC,
-  typename LayoutC,
-  typename ElementAccumulator,
-  typename OperatorClass,
-  typename ArchTag,
-  typename ThreadblockShape,
-  typename WarpShape,
-  typename InstructionShape,
-  typename EpilogueOutputOp,
-  typename ThreadblockSwizzle,
-  int Stages,
-  typename MathOperatorTag
->
-struct DefaultConv3dDgrad <
-  ElementA,
-  LayoutA,
-  ElementB,
-  LayoutB,
-  ElementC,
-  LayoutC,
-  ElementAccumulator,
-  OperatorClass,
-  ArchTag,
-  ThreadblockShape,
-  WarpShape,
-  InstructionShape,
-  EpilogueOutputOp,
-  ThreadblockSwizzle,
-  Stages,
-  MathOperatorTag,
-  IteratorAlgorithm::kOptimized,
-  StrideSupport::kUnity
-> {
-
-  // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, MathOperatorTag>;
-
-  // Define iterators over tiles from the A operand
-  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using IteratorA =
-    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-      ElementA,
-      ThreadMapA,
-      StrideSupport::kUnity
-    >;
-
-  using SmemIteratorA = typename MmaCore::SmemIteratorA;
-
-  // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-
-  using IteratorB =
-    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-      ElementB,
-      ThreadMapB
-    >;
-
-  using SmemIteratorB = typename MmaCore::SmemIteratorB;
-
-  // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
-  using MmaPolicy = typename MmaCore::MmaPolicy;
-
-  // Define the Mma
-  using Mma = threadblock::ImplicitGemmMultistage<
-    ThreadblockShape,
-    IteratorA,
-    SmemIteratorA,
-    arch::CacheOperation::Always,
-    IteratorB,
-    SmemIteratorB,
-    arch::CacheOperation::Global,
-    MmaPolicy,
-    Stages 
-  >;
-
-  // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
-    ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp,
-    EpilogueOutputOp::kCount
-  >::Epilogue;
-
-  // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
-    Mma,
-    Epilogue,
-    ThreadblockSwizzle,
-    conv::Operator::kDgrad,
-    Conv3dProblemSize
-  >;
-};
+    /// Element type for A matrix operand
+    typename ElementA,
+    /// Layout type for A matrix operand
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB,
+    /// Layout type for B matrix operand
+    typename LayoutB,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentB,
+    /// Element type for C and D matrix operands
+    typename ElementC,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// If true, kernel is configured to support serial reduction in the
+    /// epilogue
+    bool SplitKSerial,
+    /// Operation performed by GEMM
+    typename Operator>
+struct DefaultSparseGemm<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB, ElementC,
+                   layout::RowMajor, ElementAccumulator, arch::OpClassTensorOp,
+                   arch::Sm89, ThreadblockShape, WarpShape, InstructionShape,
+                   EpilogueOutputOp, ThreadblockSwizzle, Stages, SplitKSerial,
+                   Operator> {
+  /// Define the threadblock-scoped matrix multiply-accumulate
+  using Mma = typename cutlass::gemm::threadblock::DefaultSparseMma<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm89,
+      ThreadblockShape, WarpShape, InstructionShape, Stages,
+      Operator>::ThreadblockMma;
+
+  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+
+  /// Define the epilogue
+  using Epilogue =
+      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
+          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
+          EpilogueOutputOp::kCount>::Epilogue;
 
+  /// Define the kernel-level GEMM operator.
+  using GemmKernel = kernel::SparseGemm<Mma, Epilogue, ThreadblockSwizzle, SplitKSerial>;
+};
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-} // namespace kernel
-} // namespace conv
-} // namespace cutlass
+////////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+}  // namespace kernel
+}  // namespace gemm
+}  // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_deconv3d.h`

 * *Files 15% similar despite different names*

```diff
@@ -28,37 +28,37 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
     \brief 
     Default kernel-level implicit GEMM convolution definitions combine threadblock-scoped 
-      matrix multiply-add with the appropriate threadblock-scoped epilogue.    
+      matrix multiply-add with the appropriate threadblock-scoped epilogue.  
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/conv/kernel/default_conv2d.h"
 
-#include "cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h"
 #include "cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h"
 
-
-#include "cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h"
 #include "cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/conv2d_tile_iterator.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Conv2dFprop
+/// Defines a kernel for Deconv3d
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -70,127 +70,129 @@
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
   conv::StrideSupport StrideSupport = StrideSupport::kStrided
-> struct DefaultConv3dFprop;
+> struct DefaultDeconv3d;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+//                            OpClassSimt convolutions 
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Defines a kernel for Conv3dFprop specialization for Analytic Iterator Algorithm
-/// and 2 stage pipeline.
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename ArchTag,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
+  int Stages,
   typename MathOperatorTag
 >
-struct DefaultConv3dFprop <
+struct DefaultDeconv3d <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  arch::OpClassTensorOp,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
-  2,
+  Stages,
   MathOperatorTag,
-  IteratorAlgorithm::kAnalytic
+  IteratorAlgorithm::kAnalytic,
+  conv::StrideSupport::kStrided
 > {
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
-      2, MathOperatorTag>;
+      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      Stages, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dFpropActivationTileAccessIteratorAnalytic<
-        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-        ElementA,
-        ThreadMapA
-      >
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+      ElementA,
+      ThreadMapA,
+      conv::StrideSupport::kStrided
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
   using IteratorB =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorAnalytic<
-        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-        ElementB,
-        ThreadMapB
-      >
+    cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+      ElementB,
+      ThreadMapB,
+      true /*IsDeconv*/
     >;
-
+  
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
-  using Mma = threadblock::ImplicitGemmPipelined<
+  using Mma = threadblock::ImplicitGemmMultistage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
+    arch::CacheOperation::Always,
     IteratorB,
     SmemIteratorB,
-    ElementC,
-    LayoutC,
-    MmaPolicy
+    arch::CacheOperation::Always,
+    MmaPolicy,
+    Stages 
   >;
 
   // Define the epilogue
-  using Epilogue = typename detail::DefaultConvEpilogue<
-    ArchTag,
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
+    conv::Operator::kDeconv,
     Conv3dProblemSize
   >;
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Defines a kernel for Conv2dFprop specialization for Analytic IteratorAlgorithm and multistage
-// pipeline.
+/// Defines a kernel for Deconv3d specialization for Optimized IteratorAlgorithm, 
+/// multi-stage pipeline, and FFMA-based mainloop for SM80
+
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -200,102 +202,105 @@
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag
 >
-struct DefaultConv3dFprop <
+struct DefaultDeconv3d <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  arch::OpClassTensorOp,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   MathOperatorTag,
-  IteratorAlgorithm::kAnalytic
+  IteratorAlgorithm::kOptimized,
+  StrideSupport::kUnity
 > {
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
+      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
       Stages, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::Conv3dFpropActivationTileAccessIteratorAnalytic<
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
       cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
       ElementA,
-      ThreadMapA
+      ThreadMapA,
+      StrideSupport::kUnity
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
   using IteratorB =
-    cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorAnalytic<
+    cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorOptimized<
       cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
       ElementB,
-      ThreadMapB
+      LayoutB,
+      ThreadMapB,
+      true /*IsDeconv*/
+      // ThreadMapB,
+      // StrideSupport::kUnity
     >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
   using Mma = threadblock::ImplicitGemmMultistage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
     arch::CacheOperation::Always,
     IteratorB,
     SmemIteratorB,
-    arch::CacheOperation::Global,
+    arch::CacheOperation::Always,
     MmaPolicy,
     Stages 
   >;
 
   // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
+    WarpMmaSimtOp,
     EpilogueOutputOp,
     EpilogueOutputOp::kCount
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
+    conv::Operator::kDeconv,
     Conv3dProblemSize
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Defines a kernel for Conv3dFprop specialization for Optimized Iterator Algorithm
-/// and 2 stage pipeline.
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -304,70 +309,71 @@
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   typename MathOperatorTag
 >
-struct DefaultConv3dFprop <
+struct DefaultDeconv3d <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  arch::OpClassTensorOp,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   2,
   MathOperatorTag,
-  IteratorAlgorithm::kOptimized
+  IteratorAlgorithm::kAnalytic,
+  conv::StrideSupport::kStrided
 > {
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
+      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
       2, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dFpropActivationTileAccessIteratorOptimized<
+    // cutlass::conv::threadblock::TileIteratorStridedDgrad<
+      cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
         cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
         ElementA,
-        LayoutA,
-        ThreadMapA
-      >
+        ThreadMapA,
+        conv::StrideSupport::kStrided
+      // >
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
   using IteratorB =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorOptimized<
+    // cutlass::conv::threadblock::TileIteratorStridedDgrad<
+      cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorAnalytic<
         cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
         ElementB,
-        LayoutB,
-        ThreadMapB
-      >
+        ThreadMapB,
+        true /*IsDeconv*/
+      // >
     >;
-
+  
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
   using Mma = threadblock::ImplicitGemmPipelined<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
@@ -375,138 +381,142 @@
     SmemIteratorB,
     ElementC,
     LayoutC,
     MmaPolicy
   >;
 
   // Define the epilogue
-  using Epilogue = typename detail::DefaultConvEpilogue<
-    ArchTag,
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
+    conv::Operator::kDeconv,
     Conv3dProblemSize
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Defines a kernel for Conv3dFprop specialization for Optimized IteratorAlgorithm and multistage
-// pipeline.
+/// Defines a kernel for Deconv3d specialization for Optimized IteratorAlgorithm, 
+/// 2 stage pipeline, and FFMA-based mainloop for SM50
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename ArchTag,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
-  int Stages,
   typename MathOperatorTag
 >
-struct DefaultConv3dFprop <
+struct DefaultDeconv3d <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  arch::OpClassTensorOp,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
-  Stages,
+  2,
   MathOperatorTag,
-  IteratorAlgorithm::kOptimized
+  IteratorAlgorithm::kOptimized,
+  StrideSupport::kUnity
 > {
 
   // Define the core components from GEMM
   using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
-      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
-      Stages, MathOperatorTag>;
+      ElementB, layout::ColumnMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      2, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::Conv3dFpropActivationTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-      ElementA,
-      LayoutA,
-      ThreadMapA
+    // cutlass::conv::threadblock::TileIterator<
+      cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+        ElementA,
+        ThreadMapA,
+        StrideSupport::kUnity
+      // >
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB; 
-
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
   using IteratorB =
-    cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-      ElementB,
-      LayoutB,
-      ThreadMapB
+    // cutlass::conv::threadblock::TileIterator<
+      cutlass::conv::threadblock::Conv3dFpropFilterTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+        ElementB,
+        LayoutB,
+        ThreadMapB,
+        true /*IsDeconv*/
+        // ThreadMapB,
+        // StrideSupport::kUnity
+      // >
     >;
-
+  
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
-  using Mma = threadblock::ImplicitGemmMultistage<
+  using Mma = threadblock::ImplicitGemmPipelined<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
-    arch::CacheOperation::Always,
     IteratorB,
     SmemIteratorB,
-    arch::CacheOperation::Global,
-    MmaPolicy,
-    Stages 
+    ElementC,
+    LayoutC,
+    MmaPolicy
   >;
 
   // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
+    WarpMmaSimtOp,
     EpilogueOutputOp,
     EpilogueOutputOp::kCount
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
+    conv::Operator::kDeconv,
     Conv3dProblemSize
   >;
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
 } // namespace conv
 } // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -73,15 +73,15 @@
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
   conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity
 > struct DefaultConv3dFpropFusion;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //                         OpClassTensorOp convolutions 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Defines a kernel for Conv3dFprop specialzation for Analytic IteratorAlgorithm and multistage
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h`

 * *Files 18% similar despite different names*

```diff
@@ -27,37 +27,45 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
     \brief 
-    Default kernel-level implicit GEMM convolution definitions combine threadblock-scoped 
+    Default kernel-level Depthwise implicit GEMM convolution definitions combine threadblock-scoped 
       matrix multiply-add with the appropriate threadblock-scoped epilogue.  
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/conv/kernel/default_conv2d.h"
+#include "cutlass/conv/kernel/direct_convolution.h"
 
-#include "cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h"
-#include "cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h"
+#include "cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h"
+
+#include "cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/depthwise_fprop_pipelined.h"
+
+// Direct Conv Related Header files
+#include "cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h"
+#include "cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h"
+
+#include "cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h"
+#include "cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Defines a kernel for Conv2dWgrad
+/// Defines a kernel for DepthwiseFprop
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -67,443 +75,514 @@
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
-  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided
-> struct DefaultConv3dWgrad;
+  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kAnalytic,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
+  /// Access granularity of A matrix in units of elements
+  int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
+  /// Access granularity of B matrix in units of elements
+  int AlignmentB = cutlass::sizeof_bits<ElementB>::value / cutlass::sizeof_bits<ElementB>::value
+> struct DefaultDepthwiseFprop;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Defines a kernel for Conv3dWgrad specialization for Analytic IteratorAlgorithm and multistage 
-// pipeline.
+/// Defines a kernel for DepthwiseFprop with direct convolution algorithm
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename OperatorClass,
   typename ArchTag,
   typename ThreadblockShape,
+  typename ThreadBlockOutputShape,
+  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
-  typename MathOperatorTag
->
-struct DefaultConv3dWgrad <
-  ElementA,
-  LayoutA,
-  ElementB,
-  LayoutB,
-  ElementC,
-  LayoutC,
-  ElementAccumulator,
-  OperatorClass,
-  ArchTag,
-  ThreadblockShape,
-  WarpShape,
-  InstructionShape,
-  EpilogueOutputOp,
-  ThreadblockSwizzle,
-  Stages,
-  MathOperatorTag,
-  IteratorAlgorithm::kAnalytic
->  {
-
-  // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::ColumnMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, MathOperatorTag>;
-
-  // Define iterators over tiles from the A operand
-  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using IteratorA =
-    cutlass::conv::threadblock::Conv3dWgradOutputGradientTileAccessIteratorAnalytic<
-      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-      ElementA,
-      ThreadMapA
-    >;
-
-  using SmemIteratorA = typename MmaCore::SmemIteratorA;
-
-  // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using IteratorB =
-    cutlass::conv::threadblock::Conv3dWgradActivationTileAccessIteratorAnalytic<
-      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-      ElementB,
-      ThreadMapB
-    >;
-  
-  using SmemIteratorB = typename MmaCore::SmemIteratorB;
-
-  // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
-  using MmaPolicy = typename MmaCore::MmaPolicy;
-
-  // Define the Mma
-  using Mma = threadblock::ImplicitGemmMultistage<
-    ThreadblockShape,
-    IteratorA,
-    SmemIteratorA,
-    arch::CacheOperation::Always,
-    IteratorB,
-    SmemIteratorB,
-    arch::CacheOperation::Always,
-    MmaPolicy,
-    Stages 
-  >;
-
-  // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
-    ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp,
-    EpilogueOutputOp::kCount
-  >::Epilogue;
-
-  // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
-    Mma,
-    Epilogue,
-    ThreadblockSwizzle,
-    conv::Operator::kWgrad,
-    Conv3dProblemSize
-  >;
-};
+  typename MathOperatorTag,
+  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kAnalytic,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
+  // MatrixShape<Height, Width>
+  typename StrideShape = cutlass::MatrixShape<-1, -1>,
+  // MatrixShape< Height, Width> 
+  typename DilationShape =  cutlass::MatrixShape<-1, -1>, 
+  /// Access granularity of A matrix in units of elements
+  int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
+  /// Access granularity of B matrix in units of elements
+  int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
+> struct DefaultDepthwiseDirect2dConvFprop;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Conv3dWgrad specialization for Analytic IteratorAlgorithm and two 
-// pipeline.
+//                            OpClassSimt convolutions
+/////////////////////////////////////////////////////////////////////////////////////////////////
+/// Defines a kernel for Depthwise specialization for Analytic IteratorAlgorithm
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
-  typename OperatorClass,
   typename ArchTag,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
-  typename MathOperatorTag
+  typename MathOperatorTag,
+  conv::StrideSupport StrideSupport,
+  int AlignmentA,
+  int AlignmentB
 >
-struct DefaultConv3dWgrad <
+struct DefaultDepthwiseFprop <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  OperatorClass,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   2,
-  MathOperatorTag,
-  IteratorAlgorithm::kAnalytic
->  {
+  MathOperatorTag, //   cutlass::arch::OpMultiplyAdd
+  IteratorAlgorithm::kAnalytic,
+  StrideSupport,
+  AlignmentA,
+  AlignmentB
+> {
 
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::ColumnMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      2, MathOperatorTag>;
+  using MmaCore = typename cutlass::conv::threadblock::DepthwiseMmaCoreWithLaneAccessSize<
+      ThreadblockShape,
+      WarpShape,
+      InstructionShape,
+      ElementA,
+      layout::RowMajor,
+      ElementB,
+      layout::ColumnMajor,
+      ElementAccumulator,
+      layout::RowMajor,
+      arch::OpClassSimt,
+      128,
+      sizeof_bits<ElementB>::value,
+      2,
+      MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
     cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dWgradOutputGradientTileAccessIteratorAnalytic<
+      cutlass::conv::threadblock::Conv2dFpropActivationTileAccessIteratorAnalytic<
         cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-        ElementA,
+        ElementA, LayoutA,
         ThreadMapA
       >
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
     cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dWgradActivationTileAccessIteratorAnalytic<
+      cutlass::conv::threadblock::Conv2dFpropFilterTileAccessIteratorAnalytic<
         cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-        ElementB,
-        ThreadMapB
+        ElementB, LayoutB,
+        ThreadMapB,
+        AccessTypeB,
+        cutlass::conv::GroupMode::kDepthwise
       >
     >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
-  using Mma = threadblock::ImplicitGemmPipelined<
+  using Mma = threadblock::DepthwiseFpropPipelined<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
     IteratorB,
     SmemIteratorB,
     ElementC,
     LayoutC,
     MmaPolicy
   >;
 
   // Define the epilogue
-  using Epilogue = typename detail::DefaultConvEpilogue<
-    ArchTag,
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kWgrad,
-    Conv3dProblemSize
+    conv::Operator::kFprop,
+    Conv2dProblemSize,
+    cutlass::conv::GroupMode::kDepthwise
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Defines a kernel for Conv3dWgrad specialization for Optimized IteratorAlgorithm and multistage 
-// pipeline.
+/// Defines a kernel for Depthwise specialization for direct 2d conv implementation, 
+/// multiple stage pipeline, and SIMT-based mainloop
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
-  typename OperatorClass,
   typename ArchTag,
   typename ThreadblockShape,
+  typename ThreadBlockOutputShape,
+  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
-  typename MathOperatorTag
+  typename MathOperatorTag,
+  conv::StrideSupport StrideSupport,
+  typename StrideShape,
+  typename DilationShape,
+  int AlignmentA,
+  int AlignmentB
 >
-struct DefaultConv3dWgrad <
+struct DefaultDepthwiseDirect2dConvFprop <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  OperatorClass,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
+  ThreadBlockOutputShape,
+  FilterShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   MathOperatorTag,
-  IteratorAlgorithm::kOptimized
->  {
+  IteratorAlgorithm::kOptimized,
+  StrideSupport,
+  StrideShape,
+  DilationShape,
+  AlignmentA,
+  AlignmentB
+> {
+  // One warp handles the entrie groups per cta.
+  static_assert(ThreadblockShape::kN == WarpShape::kN,
+                "ThreadblockShape::kN should be same as WarpShape::kN ");
+  static_assert(ThreadblockShape::kK == FilterShape::kCount && WarpShape::kK == FilterShape::kCount,
+                "ThreadblockShape::kK and WarpShape::kK should be same as filter size");
+  static_assert(ThreadblockShape::kM % WarpShape::kM == 0,
+                "ThreadblockShape::kM must be divisible by WarpShape shape::kM");
+  static_assert(ThreadBlockOutputShape::kN, "ThreadBlockOutputShape::kN should be 1");
 
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::ColumnMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, MathOperatorTag>;
+  using MmaCore = typename cutlass::conv::threadblock::DepthwiseDirectConvMmaCoreWithLaneAccessSize<
+      ThreadblockShape,
+      ThreadBlockOutputShape,
+      FilterShape,
+      WarpShape,
+      InstructionShape,
+      ElementA,
+      layout::RowMajor,
+      ElementB,
+      layout::ColumnMajor,
+      ElementAccumulator,
+      layout::RowMajor,
+      arch::OpClassSimt,
+      128,
+      128,
+      Stages,
+      MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::Conv3dWgradOutputGradientTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-      ElementA,
+    cutlass::conv::threadblock::DepthwiseFpropActivationDirect2dConvTileAccessIteratorOptimized<
+      cutlass::MatrixShape<ThreadblockShape::kM,ThreadblockShape::kN>, // < outputShape:KMNK, groups per cta>
+      ThreadBlockOutputShape,
+      ElementA, LayoutA,
       ThreadMapA
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
-    cutlass::conv::threadblock::Conv3dWgradActivationTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-      ElementB,
-      ThreadMapB
-    >;
+      cutlass::conv::threadblock::DepthwiseFpropFilterDirectConvTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kN, FilterShape::kCount>,
+        ElementB, LayoutB,
+        ThreadMapB
+      >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
+  using ThreadOutputShape = typename MmaCore::ThreadOutputShape;
+  static cutlass::arch::CacheOperation::Kind const CacheOpA =
+      ((sizeof_bits<ElementA>::value * AlignmentA) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpB =
+      ((sizeof_bits<ElementB>::value * AlignmentB) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultDirectConvEpilogueSimt<
+    ThreadblockShape, // < outputShape:KMNK, groups per cta>
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount,
+    ThreadOutputShape,
+    ThreadBlockOutputShape
+  >::Epilogue;
 
   // Define the Mma
-  using Mma = threadblock::ImplicitGemmMultistage<
+  using Mma = threadblock::DepthwiseFpropDirectConvMultipleStage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
-    arch::CacheOperation::Always,
+    CacheOpA,
     IteratorB,
     SmemIteratorB,
-    arch::CacheOperation::Always,
+    CacheOpB,
     MmaPolicy,
-    Stages 
+    Stages,
+    Epilogue
   >;
 
-  // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
-    ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp,
-    EpilogueOutputOp::kCount
-  >::Epilogue;
-
   // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
+  using Kernel = cutlass::conv::kernel::DirectConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kWgrad,
-    Conv3dProblemSize
+    conv::Operator::kFprop,
+    Conv2dProblemSize,
+    cutlass::conv::GroupMode::kDepthwise,
+    ThreadBlockOutputShape
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Conv3dWgrad specialization for Optimized IteratorAlgorithm and two 
-// pipeline.
+/// Defines a kernel for Depthwise specialization for direct 2d conv implementation, 
+/// multiple stage pipeline, and SIMT-based mainloop
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
-  typename OperatorClass,
   typename ArchTag,
   typename ThreadblockShape,
+  typename ThreadBlockOutputShape,
+  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
-  typename MathOperatorTag
+  int Stages,
+  typename MathOperatorTag,
+  conv::StrideSupport StrideSupport,
+  typename StrideShape,
+  typename DilationShape,
+  int AlignmentA,
+  int AlignmentB
 >
-struct DefaultConv3dWgrad <
+struct DefaultDepthwiseDirect2dConvFprop <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
-  OperatorClass,
+  arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
+  ThreadBlockOutputShape,
+  FilterShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
-  2,
+  Stages,
   MathOperatorTag,
-  IteratorAlgorithm::kOptimized
->  {
+  IteratorAlgorithm::kFixedStrideDilation,
+  StrideSupport,
+  StrideShape,
+  DilationShape,
+  AlignmentA,
+  AlignmentB
+> {
+
+
+
+  // One warp handles the entrie groups per cta.
+  static_assert(ThreadblockShape::kN == WarpShape::kN,
+                "ThreadblockShape::kN should be same as WarpShape::kN ");
+  static_assert(ThreadblockShape::kK == FilterShape::kCount && WarpShape::kK == FilterShape::kCount,
+                "ThreadblockShape::kK and WarpShape::kK should be same as filter size");
+  static_assert(ThreadblockShape::kM % WarpShape::kM == 0,
+                "ThreadblockShape::kM must be divisible by WarpShape shape::kM");
+  static_assert(ThreadBlockOutputShape::kN, "ThreadBlockOutputShape::kN should be 1");
+
+  static_assert(StrideShape::kRow >= 0 && StrideShape::kColumn >= 0, "Stride should be fixed");
+  static_assert(DilationShape::kRow >= 0 && DilationShape::kColumn >= 0, "Stride should be fixed");
+
+  // Activations loaded by threadblock
+  static int const ActivationShapeH = (ThreadBlockOutputShape::kH - 1) * StrideShape::kRow +
+                             (FilterShape::kRow - 1) * DilationShape::kRow + 1;
+
+  static int const ActivationShapeW = (ThreadBlockOutputShape::kW - 1) * StrideShape::kColumn +
+                             (FilterShape::kColumn - 1) * DilationShape::kColumn + 1;
+
+  using ActivationShape =
+      cutlass::conv::TensorNHWCShape<1, ActivationShapeH, ActivationShapeW, ThreadblockShape::kN >;
 
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::ColumnMajor,
-      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
-      2, MathOperatorTag>;
+  using MmaCore = typename cutlass::conv::threadblock::DepthwiseDirectConvMmaCoreWithLaneAccessSize<
+      ThreadblockShape,
+      ThreadBlockOutputShape,
+      FilterShape,
+      WarpShape,
+      InstructionShape,
+      ElementA,
+      layout::RowMajor,
+      ElementB,
+      layout::ColumnMajor,
+      ElementAccumulator,
+      layout::RowMajor,
+      arch::OpClassSimt,
+      128,
+      128,
+      Stages,
+      MathOperatorTag,
+      IteratorAlgorithm::kFixedStrideDilation,
+      StrideShape,
+      DilationShape,
+      ActivationShape>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dWgradOutputGradientTileAccessIteratorOptimized<
-        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-        ElementA,
-        ThreadMapA
-      >
+    cutlass::conv::threadblock::DepthwiseFpropActivationDirect2dConvTileAccessIteratorFixedStrideDilation<
+      cutlass::MatrixShape<ThreadblockShape::kM,ThreadblockShape::kN>, // < outputShape:KMNK, groups per cta>
+      ThreadBlockOutputShape,
+      StrideShape,
+      DilationShape,
+      ActivationShape,
+      ElementA, LayoutA,
+      ThreadMapA
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv3dWgradActivationTileAccessIteratorOptimized<
-        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-        ElementB,
+      cutlass::conv::threadblock::DepthwiseFpropFilterDirectConvTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kN, FilterShape::kCount>,
+        ElementB, LayoutB,
         ThreadMapB
-      >
-    >;
+      >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
-  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
+  using ThreadOutputShape = typename MmaCore::ThreadOutputShape;
+  static cutlass::arch::CacheOperation::Kind const CacheOpA =
+      ((sizeof_bits<ElementA>::value * AlignmentA) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpB =
+      ((sizeof_bits<ElementB>::value * AlignmentB) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultDirectConvEpilogueSimt<
+    ThreadblockShape, // < outputShape:KMNK, groups per cta>
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount,
+    ThreadOutputShape,
+    ThreadBlockOutputShape
+  >::Epilogue;
 
   // Define the Mma
-  using Mma = threadblock::ImplicitGemmPipelined<
+  using Mma = threadblock::DepthwiseFpropDirectConvMultipleStage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
+    CacheOpA,
     IteratorB,
     SmemIteratorB,
-    ElementC,
-    LayoutC,
-    MmaPolicy
+    CacheOpB,
+    MmaPolicy,
+    Stages,
+    Epilogue,
+    IteratorAlgorithm::kFixedStrideDilation
   >;
 
-  // Define the epilogue
-  using Epilogue = typename detail::DefaultConvEpilogue<
-    ArchTag,
-    ThreadblockShape,
-    WarpMmaTensorOp,
-    1,
-    EpilogueOutputOp
-  >::Epilogue;
-
   // Define the kernel
-  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
+  using Kernel = cutlass::conv::kernel::DirectConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kWgrad,
-    Conv3dProblemSize
+    conv::Operator::kFprop,
+    Conv2dProblemSize,
+    cutlass::conv::GroupMode::kDepthwise,
+    ThreadBlockOutputShape
   >;
 };
-/////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
 } // namespace conv
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h`

 * *Files 15% similar despite different names*

```diff
@@ -27,45 +27,38 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
     \brief 
-    Default kernel-level Depthwise implicit GEMM convolution definitions combine threadblock-scoped 
+    Default kernel-level implicit GEMM convolution definitions combine threadblock-scoped 
       matrix multiply-add with the appropriate threadblock-scoped epilogue.  
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/conv/kernel/default_conv2d.h"
-#include "cutlass/conv/kernel/direct_convolution.h"
 
-#include "cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h"
 
-#include "cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h"
-#include "cutlass/conv/threadblock/depthwise_fprop_pipelined.h"
-
-// Direct Conv Related Header files
-#include "cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h"
-#include "cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h"
-
-#include "cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h"
-#include "cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h"
+#include "cutlass/conv/threadblock/conv2d_tile_iterator.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace conv {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for DepthwiseFprop
+/// Defines a kernel for Conv3dDgrad
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
@@ -75,161 +68,321 @@
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
   typename MathOperatorTag,
-  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kAnalytic,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
-  /// Access granularity of A matrix in units of elements
-  int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
-  /// Access granularity of B matrix in units of elements
-  int AlignmentB = cutlass::sizeof_bits<ElementB>::value / cutlass::sizeof_bits<ElementB>::value
-> struct DefaultDepthwiseFprop;
+  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
+  conv::StrideSupport StrideSupport = StrideSupport::kStrided
+> struct DefaultConv3dDgrad;
+
+/// Defines a kernel for Conv3dDgrad specialization for Analytic IteratorAlgorithm Dgrad Strided
+// and multistage pipeline.
+template <
+  typename ElementA,
+  typename LayoutA,
+  typename ElementB,
+  typename LayoutB,
+  typename ElementC,
+  typename LayoutC,
+  typename ElementAccumulator,
+  typename OperatorClass,
+  typename ArchTag,
+  typename ThreadblockShape,
+  typename WarpShape,
+  typename InstructionShape,
+  typename EpilogueOutputOp,
+  typename ThreadblockSwizzle,
+  int Stages,
+  typename MathOperatorTag
+>
+struct DefaultConv3dDgrad <
+  ElementA,
+  LayoutA,
+  ElementB,
+  LayoutB,
+  ElementC,
+  LayoutC,
+  ElementAccumulator,
+  OperatorClass,
+  ArchTag,
+  ThreadblockShape,
+  WarpShape,
+  InstructionShape,
+  EpilogueOutputOp,
+  ThreadblockSwizzle,
+  Stages,
+  MathOperatorTag,
+  IteratorAlgorithm::kAnalytic,
+  StrideSupport::kStrided
+> {
+
+  // Define the core components from GEMM
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
+      Stages, MathOperatorTag>;
+
+  // Define iterators over tiles from the A operand
+  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
+  using IteratorA =
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+      ElementA,
+      ThreadMapA,
+      StrideSupport::kStrided
+    >;
+
+  using SmemIteratorA = typename MmaCore::SmemIteratorA;
+
+  // Define iterators over tiles from the B operand
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using IteratorB =
+    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+      ElementB,
+      ThreadMapB
+    >;
+  
+  using SmemIteratorB = typename MmaCore::SmemIteratorB;
+
+  // Warp-level GEMM components
+  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using MmaPolicy = typename MmaCore::MmaPolicy;
+
+  // Define the Mma
+  using Mma = threadblock::ImplicitGemmMultistage<
+    ThreadblockShape,
+    IteratorA,
+    SmemIteratorA,
+    arch::CacheOperation::Always,
+    IteratorB,
+    SmemIteratorB,
+    arch::CacheOperation::Global,
+    MmaPolicy,
+    Stages 
+  >;
+
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
+    ThreadblockShape,
+    WarpMmaTensorOp,
+    1,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
+  >::Epilogue;
+
+  // Define the kernel
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
+    Mma,
+    Epilogue,
+    ThreadblockSwizzle,
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
+  >;
+};
+
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for DepthwiseFprop with direct convolution algorithm
+
+/// Defines a kernel for Conv3dDgrad specialization for Optimized IteratorAlgorithm Dgrad Strided
+// and multistage pipeline.
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename OperatorClass,
   typename ArchTag,
   typename ThreadblockShape,
-  typename ThreadBlockOutputShape,
-  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
-  typename MathOperatorTag,
-  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kAnalytic,
-  conv::StrideSupport StrideSupport = StrideSupport::kStrided,
-  // MatrixShape<Height, Width>
-  typename StrideShape = cutlass::MatrixShape<-1, -1>,
-  // MatrixShape< Height, Width> 
-  typename DilationShape =  cutlass::MatrixShape<-1, -1>, 
-  /// Access granularity of A matrix in units of elements
-  int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
-  /// Access granularity of B matrix in units of elements
-  int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
-> struct DefaultDepthwiseDirect2dConvFprop;
+  typename MathOperatorTag
+>
+struct DefaultConv3dDgrad <
+  ElementA,
+  LayoutA,
+  ElementB,
+  LayoutB,
+  ElementC,
+  LayoutC,
+  ElementAccumulator,
+  OperatorClass,
+  ArchTag,
+  ThreadblockShape,
+  WarpShape,
+  InstructionShape,
+  EpilogueOutputOp,
+  ThreadblockSwizzle,
+  Stages,
+  MathOperatorTag,
+  IteratorAlgorithm::kOptimized,
+  StrideSupport::kUnity
+> {
+
+  // Define the core components from GEMM
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, OperatorClass,
+      Stages, MathOperatorTag>;
+
+  // Define iterators over tiles from the A operand
+  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
+  using IteratorA =
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
+      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+      ElementA,
+      ThreadMapA,
+      StrideSupport::kUnity
+    >;
+
+  using SmemIteratorA = typename MmaCore::SmemIteratorA;
+
+  // Define iterators over tiles from the B operand
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+
+  using IteratorB =
+    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorOptimized<
+      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+      ElementB,
+      ThreadMapB
+    >;
+
+  using SmemIteratorB = typename MmaCore::SmemIteratorB;
+
+  // Warp-level GEMM components
+  using WarpMmaTensorOp = typename MmaCore::MmaTensorOp;
+  using MmaPolicy = typename MmaCore::MmaPolicy;
+
+  // Define the Mma
+  using Mma = threadblock::ImplicitGemmMultistage<
+    ThreadblockShape,
+    IteratorA,
+    SmemIteratorA,
+    arch::CacheOperation::Always,
+    IteratorB,
+    SmemIteratorB,
+    arch::CacheOperation::Global,
+    MmaPolicy,
+    Stages 
+  >;
+
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueTensorOp<
+    ThreadblockShape,
+    WarpMmaTensorOp,
+    1,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
+  >::Epilogue;
+
+  // Define the kernel
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
+    Mma,
+    Epilogue,
+    ThreadblockSwizzle,
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
+  >;
+};
+
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-//                            OpClassSimt convolutions
+//                            OpClassSimt convolutions 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Depthwise specialization for Analytic IteratorAlgorithm
+
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename ArchTag,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
-  typename MathOperatorTag,
-  conv::StrideSupport StrideSupport,
-  int AlignmentA,
-  int AlignmentB
+  int Stages,
+  typename MathOperatorTag
 >
-struct DefaultDepthwiseFprop <
+struct DefaultConv3dDgrad <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
   arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
-  2,
-  MathOperatorTag, //   cutlass::arch::OpMultiplyAdd
+  Stages,
+  MathOperatorTag,
   IteratorAlgorithm::kAnalytic,
-  StrideSupport,
-  AlignmentA,
-  AlignmentB
+  conv::StrideSupport::kStrided
 > {
 
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::conv::threadblock::DepthwiseMmaCoreWithLaneAccessSize<
-      ThreadblockShape,
-      WarpShape,
-      InstructionShape,
-      ElementA,
-      layout::RowMajor,
-      ElementB,
-      layout::ColumnMajor,
-      ElementAccumulator,
-      layout::RowMajor,
-      arch::OpClassSimt,
-      128,
-      sizeof_bits<ElementB>::value,
-      2,
-      MathOperatorTag>;
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      Stages, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv2dFpropActivationTileAccessIteratorAnalytic<
-        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-        ElementA, LayoutA,
-        ThreadMapA
-      >
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+      ElementA,
+      ThreadMapA,
+      conv::StrideSupport::kStrided
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
-    cutlass::conv::threadblock::TileIterator<
-      cutlass::conv::threadblock::Conv2dFpropFilterTileAccessIteratorAnalytic<
-        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-        ElementB, LayoutB,
-        ThreadMapB,
-        AccessTypeB,
-        cutlass::conv::GroupMode::kDepthwise
-      >
+    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorAnalytic<
+      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+      ElementB,
+      ThreadMapB
     >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
   using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
 
   // Define the Mma
-  using Mma = threadblock::DepthwiseFpropPipelined<
+  using Mma = threadblock::ImplicitGemmMultistage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
+    arch::CacheOperation::Always,
     IteratorB,
     SmemIteratorB,
-    ElementC,
-    LayoutC,
-    MmaPolicy
+    arch::CacheOperation::Always,
+    MmaPolicy,
+    Stages 
   >;
 
   // Define the epilogue
   using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
     ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
@@ -237,352 +390,347 @@
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
-    Conv2dProblemSize,
-    cutlass::conv::GroupMode::kDepthwise
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
   >;
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Depthwise specialization for direct 2d conv implementation, 
-/// multiple stage pipeline, and SIMT-based mainloop
+
+/// Defines a kernel for Conv3dDgrad specialization for Optimized IteratorAlgorithm, 
+/// multi-stage pipeline, and FFMA-based mainloop for SM80
+
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename ArchTag,
   typename ThreadblockShape,
-  typename ThreadBlockOutputShape,
-  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
   int Stages,
-  typename MathOperatorTag,
-  conv::StrideSupport StrideSupport,
-  typename StrideShape,
-  typename DilationShape,
-  int AlignmentA,
-  int AlignmentB
+  typename MathOperatorTag
 >
-struct DefaultDepthwiseDirect2dConvFprop <
+struct DefaultConv3dDgrad <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
   arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
-  ThreadBlockOutputShape,
-  FilterShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   MathOperatorTag,
   IteratorAlgorithm::kOptimized,
-  StrideSupport,
-  StrideShape,
-  DilationShape,
-  AlignmentA,
-  AlignmentB
+  StrideSupport::kUnity
 > {
-  // One warp handles the entrie groups per cta.
-  static_assert(ThreadblockShape::kN == WarpShape::kN,
-                "ThreadblockShape::kN should be same as WarpShape::kN ");
-  static_assert(ThreadblockShape::kK == FilterShape::kCount && WarpShape::kK == FilterShape::kCount,
-                "ThreadblockShape::kK and WarpShape::kK should be same as filter size");
-  static_assert(ThreadblockShape::kM % WarpShape::kM == 0,
-                "ThreadblockShape::kM must be divisible by WarpShape shape::kM");
-  static_assert(ThreadBlockOutputShape::kN, "ThreadBlockOutputShape::kN should be 1");
 
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::conv::threadblock::DepthwiseDirectConvMmaCoreWithLaneAccessSize<
-      ThreadblockShape,
-      ThreadBlockOutputShape,
-      FilterShape,
-      WarpShape,
-      InstructionShape,
-      ElementA,
-      layout::RowMajor,
-      ElementB,
-      layout::ColumnMajor,
-      ElementAccumulator,
-      layout::RowMajor,
-      arch::OpClassSimt,
-      128,
-      128,
-      Stages,
-      MathOperatorTag>;
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      Stages, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::DepthwiseFpropActivationDirect2dConvTileAccessIteratorOptimized<
-      cutlass::MatrixShape<ThreadblockShape::kM,ThreadblockShape::kN>, // < outputShape:KMNK, groups per cta>
-      ThreadBlockOutputShape,
-      ElementA, LayoutA,
-      ThreadMapA
+    cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
+      cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+      ElementA,
+      ThreadMapA,
+      StrideSupport::kUnity
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
-      cutlass::conv::threadblock::DepthwiseFpropFilterDirectConvTileAccessIteratorOptimized<
-        cutlass::MatrixShape<ThreadblockShape::kN, FilterShape::kCount>,
-        ElementB, LayoutB,
-        ThreadMapB
-      >;
+    cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorOptimized<
+      cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+      ElementB,
+      ThreadMapB
+      // ThreadMapB,
+      // StrideSupport::kUnity
+    >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
   using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
-  using ThreadOutputShape = typename MmaCore::ThreadOutputShape;
-  static cutlass::arch::CacheOperation::Kind const CacheOpA =
-      ((sizeof_bits<ElementA>::value * AlignmentA) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpB =
-      ((sizeof_bits<ElementB>::value * AlignmentB) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
-  // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultDirectConvEpilogueSimt<
-    ThreadblockShape, // < outputShape:KMNK, groups per cta>
-    WarpMmaSimtOp,
-    EpilogueOutputOp,
-    EpilogueOutputOp::kCount,
-    ThreadOutputShape,
-    ThreadBlockOutputShape
-  >::Epilogue;
 
   // Define the Mma
-  using Mma = threadblock::DepthwiseFpropDirectConvMultipleStage<
+  using Mma = threadblock::ImplicitGemmMultistage<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
-    CacheOpA,
+    arch::CacheOperation::Always,
     IteratorB,
     SmemIteratorB,
-    CacheOpB,
+    arch::CacheOperation::Always,
     MmaPolicy,
-    Stages,
-    Epilogue
+    Stages 
   >;
 
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
+    ThreadblockShape,
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
+  >::Epilogue;
+
   // Define the kernel
-  using Kernel = cutlass::conv::kernel::DirectConvolution<
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
-    Conv2dProblemSize,
-    cutlass::conv::GroupMode::kDepthwise,
-    ThreadBlockOutputShape
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Defines a kernel for Depthwise specialization for direct 2d conv implementation, 
-/// multiple stage pipeline, and SIMT-based mainloop
+
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
   typename ElementC,
   typename LayoutC,
   typename ElementAccumulator,
   typename ArchTag,
   typename ThreadblockShape,
-  typename ThreadBlockOutputShape,
-  typename FilterShape,
   typename WarpShape,
   typename InstructionShape,
   typename EpilogueOutputOp,
   typename ThreadblockSwizzle,
-  int Stages,
-  typename MathOperatorTag,
-  conv::StrideSupport StrideSupport,
-  typename StrideShape,
-  typename DilationShape,
-  int AlignmentA,
-  int AlignmentB
+  typename MathOperatorTag
 >
-struct DefaultDepthwiseDirect2dConvFprop <
+struct DefaultConv3dDgrad <
   ElementA,
   LayoutA,
   ElementB,
   LayoutB,
   ElementC,
   LayoutC,
   ElementAccumulator,
   arch::OpClassSimt,
   ArchTag,
   ThreadblockShape,
-  ThreadBlockOutputShape,
-  FilterShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
-  Stages,
+  2,
   MathOperatorTag,
-  IteratorAlgorithm::kFixedStrideDilation,
-  StrideSupport,
-  StrideShape,
-  DilationShape,
-  AlignmentA,
-  AlignmentB
+  IteratorAlgorithm::kAnalytic,
+  conv::StrideSupport::kStrided
 > {
 
-
-
-  // One warp handles the entrie groups per cta.
-  static_assert(ThreadblockShape::kN == WarpShape::kN,
-                "ThreadblockShape::kN should be same as WarpShape::kN ");
-  static_assert(ThreadblockShape::kK == FilterShape::kCount && WarpShape::kK == FilterShape::kCount,
-                "ThreadblockShape::kK and WarpShape::kK should be same as filter size");
-  static_assert(ThreadblockShape::kM % WarpShape::kM == 0,
-                "ThreadblockShape::kM must be divisible by WarpShape shape::kM");
-  static_assert(ThreadBlockOutputShape::kN, "ThreadBlockOutputShape::kN should be 1");
-
-  static_assert(StrideShape::kRow >= 0 && StrideShape::kColumn >= 0, "Stride should be fixed");
-  static_assert(DilationShape::kRow >= 0 && DilationShape::kColumn >= 0, "Stride should be fixed");
-
-  // Activations loaded by threadblock
-  static int const ActivationShapeH = (ThreadBlockOutputShape::kH - 1) * StrideShape::kRow +
-                             (FilterShape::kRow - 1) * DilationShape::kRow + 1;
-
-  static int const ActivationShapeW = (ThreadBlockOutputShape::kW - 1) * StrideShape::kColumn +
-                             (FilterShape::kColumn - 1) * DilationShape::kColumn + 1;
-
-  using ActivationShape =
-      cutlass::conv::TensorNHWCShape<1, ActivationShapeH, ActivationShapeW, ThreadblockShape::kN >;
-
   // Define the core components from GEMM
-  using MmaCore = typename cutlass::conv::threadblock::DepthwiseDirectConvMmaCoreWithLaneAccessSize<
-      ThreadblockShape,
-      ThreadBlockOutputShape,
-      FilterShape,
-      WarpShape,
-      InstructionShape,
-      ElementA,
-      layout::RowMajor,
-      ElementB,
-      layout::ColumnMajor,
-      ElementAccumulator,
-      layout::RowMajor,
-      arch::OpClassSimt,
-      128,
-      128,
-      Stages,
-      MathOperatorTag,
-      IteratorAlgorithm::kFixedStrideDilation,
-      StrideShape,
-      DilationShape,
-      ActivationShape>;
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      2, MathOperatorTag>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using IteratorA =
-    cutlass::conv::threadblock::DepthwiseFpropActivationDirect2dConvTileAccessIteratorFixedStrideDilation<
-      cutlass::MatrixShape<ThreadblockShape::kM,ThreadblockShape::kN>, // < outputShape:KMNK, groups per cta>
-      ThreadBlockOutputShape,
-      StrideShape,
-      DilationShape,
-      ActivationShape,
-      ElementA, LayoutA,
-      ThreadMapA
+    // cutlass::conv::threadblock::TileIteratorStridedDgrad<
+      cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorAnalytic<
+        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+        ElementA,
+        ThreadMapA,
+        conv::StrideSupport::kStrided
+      // >
     >;
 
   using SmemIteratorA = typename MmaCore::SmemIteratorA;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::AlignedArray<ElementB, AlignmentB>;
   using IteratorB =
-      cutlass::conv::threadblock::DepthwiseFpropFilterDirectConvTileAccessIteratorOptimized<
-        cutlass::MatrixShape<ThreadblockShape::kN, FilterShape::kCount>,
-        ElementB, LayoutB,
+    // cutlass::conv::threadblock::TileIteratorStridedDgrad<
+      cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorAnalytic<
+        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+        ElementB,
         ThreadMapB
-      >;
+      // >
+    >;
   
   using SmemIteratorB = typename MmaCore::SmemIteratorB;
 
   // Warp-level GEMM components
   using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
   using MmaPolicy = typename MmaCore::MmaPolicy;
-  using ThreadOutputShape = typename MmaCore::ThreadOutputShape;
-  static cutlass::arch::CacheOperation::Kind const CacheOpA =
-      ((sizeof_bits<ElementA>::value * AlignmentA) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpB =
-      ((sizeof_bits<ElementB>::value * AlignmentB) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
+
+  // Define the Mma
+  using Mma = threadblock::ImplicitGemmPipelined<
+    ThreadblockShape,
+    IteratorA,
+    SmemIteratorA,
+    IteratorB,
+    SmemIteratorB,
+    ElementC,
+    LayoutC,
+    MmaPolicy
+  >;
 
   // Define the epilogue
-  using Epilogue = typename epilogue::threadblock::DefaultDirectConvEpilogueSimt<
-    ThreadblockShape, // < outputShape:KMNK, groups per cta>
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
+    ThreadblockShape,
     WarpMmaSimtOp,
     EpilogueOutputOp,
-    EpilogueOutputOp::kCount,
-    ThreadOutputShape,
-    ThreadBlockOutputShape
+    EpilogueOutputOp::kCount
   >::Epilogue;
 
+  // Define the kernel
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
+    Mma,
+    Epilogue,
+    ThreadblockSwizzle,
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
+  >;
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Defines a kernel for Conv3dDgrad specialization for Optimized IteratorAlgorithm, 
+/// 2 stage pipeline, and FFMA-based mainloop for SM50
+template <
+  typename ElementA,
+  typename LayoutA,
+  typename ElementB,
+  typename LayoutB,
+  typename ElementC,
+  typename LayoutC,
+  typename ElementAccumulator,
+  typename ArchTag,
+  typename ThreadblockShape,
+  typename WarpShape,
+  typename InstructionShape,
+  typename EpilogueOutputOp,
+  typename ThreadblockSwizzle,
+  typename MathOperatorTag
+>
+struct DefaultConv3dDgrad <
+  ElementA,
+  LayoutA,
+  ElementB,
+  LayoutB,
+  ElementC,
+  LayoutC,
+  ElementAccumulator,
+  arch::OpClassSimt,
+  ArchTag,
+  ThreadblockShape,
+  WarpShape,
+  InstructionShape,
+  EpilogueOutputOp,
+  ThreadblockSwizzle,
+  2,
+  MathOperatorTag,
+  IteratorAlgorithm::kOptimized,
+  StrideSupport::kUnity
+> {
+
+  // Define the core components from GEMM
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, layout::RowMajor,
+      ElementB, layout::RowMajor, ElementAccumulator, layout::RowMajor, arch::OpClassSimt,
+      2, MathOperatorTag>;
+
+  // Define iterators over tiles from the A operand
+  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
+  using IteratorA =
+    // cutlass::conv::threadblock::TileIterator<
+      cutlass::conv::threadblock::Conv3dDgradOutputGradientTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+        ElementA,
+        ThreadMapA,
+        StrideSupport::kUnity
+      // >
+    >;
+
+  using SmemIteratorA = typename MmaCore::SmemIteratorA;
+
+  // Define iterators over tiles from the B operand
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using IteratorB =
+    // cutlass::conv::threadblock::TileIterator<
+      cutlass::conv::threadblock::Conv3dDgradFilterTileAccessIteratorOptimized<
+        cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+        ElementB,
+        ThreadMapB
+        // ThreadMapB,
+        // StrideSupport::kUnity
+      // >
+    >;
+  
+  using SmemIteratorB = typename MmaCore::SmemIteratorB;
+
+  // Warp-level GEMM components
+  using WarpMmaSimtOp = typename MmaCore::MmaWarpSimt;
+  using MmaPolicy = typename MmaCore::MmaPolicy;
+
   // Define the Mma
-  using Mma = threadblock::DepthwiseFpropDirectConvMultipleStage<
+  using Mma = threadblock::ImplicitGemmPipelined<
     ThreadblockShape,
     IteratorA,
     SmemIteratorA,
-    CacheOpA,
     IteratorB,
     SmemIteratorB,
-    CacheOpB,
-    MmaPolicy,
-    Stages,
-    Epilogue,
-    IteratorAlgorithm::kFixedStrideDilation
+    ElementC,
+    LayoutC,
+    MmaPolicy
   >;
 
+  // Define the epilogue
+  using Epilogue = typename epilogue::threadblock::DefaultEpilogueSimt<
+    ThreadblockShape,
+    WarpMmaSimtOp,
+    EpilogueOutputOp,
+    EpilogueOutputOp::kCount
+  >::Epilogue;
+
   // Define the kernel
-  using Kernel = cutlass::conv::kernel::DirectConvolution<
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolution<
     Mma,
     Epilogue,
     ThreadblockSwizzle,
-    conv::Operator::kFprop,
-    Conv2dProblemSize,
-    cutlass::conv::GroupMode::kDepthwise,
-    ThreadBlockOutputShape
+    conv::Operator::kDgrad,
+    Conv3dProblemSize
   >;
+
 };
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
 } // namespace kernel
 } // namespace conv
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -151,15 +151,15 @@
         problem_size,
         {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
         args.problem_size.split_k_slices);
 
     swizzle_log_tile = threadblock_swizzle.get_log_tile(grid_tiled_shape);
 
     // Dynamic SMEM usage because stride and dilation are runtime params.
-    smem_size_ = (iterator_A.activation_size * kStages + iterator_B.filter_size);
+    smem_size_ = (max(iterator_A.activation_size, int(sizeof(typename Epilogue::SharedStorage))) * kStages + iterator_B.filter_size);
   }
 
   CUTLASS_HOST_DEVICE
   int get_smem_size() {
     // Dynamic Smem Size
     return smem_size_;
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -57,15 +57,15 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Mma_,                                  ///! Threadblock-scoped matrix multiply-accumulate 
   typename Epilogue_,                             ///! Epilogue
   typename ThreadblockSwizzle_,                   ///! Threadblock swizzling function
-  conv::Operator ConvOperator,                    ///! Convolutional operator (Fprop, Dgrad, Wgrad)
+  conv::Operator ConvOperator,                    ///! Convolutional operator (Fprop, Dgrad, Wgrad, Deconv)
   typename ConvProblemSize_ = Conv2dProblemSize,  ///! Convolutional operator on 2D or 3D problem
   conv::GroupMode GroupMode_ = conv::GroupMode::kNone    ///! Group mode
 >
 struct ImplicitGemmConvolution {
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
@@ -229,17 +229,17 @@
     ):
       problem_size(args.problem_size),
       implicit_gemm_problem_size(cutlass::conv::implicit_gemm_problem_size(kConvolutionalOperator, args.problem_size)),
       iterator_A(Mma::IteratorA::getParams(args.problem_size, args.ref_A.layout())),
       ptr_A(args.ref_A.data()),
       iterator_B(args.problem_size, args.ref_B.layout()),
       ptr_B(args.ref_B.data()),
-      iterator_C(ConvOutputIteratorParameter::layout(args.ref_C)),
+      iterator_C(ConvOutputIteratorParameter::layout(args.ref_C), args.problem_size),
       ptr_C(args.ref_C.data()),
-      iterator_D(ConvOutputIteratorParameter::layout(args.ref_D)),
+      iterator_D(ConvOutputIteratorParameter::layout(args.ref_D), args.problem_size),
       ptr_D(args.ref_D.data()),
       output_op(args.output_op),
       semaphore(semaphore),
       split_k_mode(args.split_k_mode)
     {
       gemm_k_iterations = implicit_gemm_k_iterations(
         kConvolutionalOperator,
@@ -393,15 +393,14 @@
       params.iterator_C,
       params.ptr_C,
       ConvOutputIteratorParameter::extent(params.problem_size),
       thread_idx,
       threadblock_offset
     );
 
-
     // Construct the epilogue
     Epilogue epilogue(
       shared_storage.epilogue, 
       thread_idx, 
       warp_idx, 
       lane_idx);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h`

 * *Files 2% similar despite different names*

```diff
@@ -198,40 +198,38 @@
 
     }
 
   };
 
   /// Parameters structure
   struct Params {
-    ConvProblemSize problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    gemm::GemmCoord implicit_gemm_problem_size;
-    int swizzle_log_tile;
-    int gemm_k_iterations;
-    typename Mma::IteratorA::Params iterator_A;
-    typename Mma::IteratorA::Element const *ptr_A;
-    typename Mma::IteratorB::Params iterator_B;
-    typename Mma::IteratorB::Element const *ptr_B;
-    typename Mma::IteratorScaleBias::Params iterator_scale_bias;
-    typename Mma::IteratorScaleBias::Element const *ptr_scale;
-    typename Mma::IteratorScaleBias::Element const *ptr_bias;
-    typename Epilogue::OutputTileIterator::Params iterator_C;
-    typename Epilogue::OutputTileIterator::Element *ptr_C;
-    typename Epilogue::OutputTileIterator::Params iterator_D;
-    typename Epilogue::OutputTileIterator::Element *ptr_D;
-    typename EpilogueOutputOp::Params output_op;
-    int *semaphore;
-    SplitKMode split_k_mode;
+    ConvProblemSize problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    gemm::GemmCoord implicit_gemm_problem_size{};
+    int swizzle_log_tile{0};
+    int gemm_k_iterations{0};
+    typename Mma::IteratorA::Params iterator_A{};
+    typename Mma::IteratorA::Element const *ptr_A = nullptr;
+    typename Mma::IteratorB::Params iterator_B{};
+    typename Mma::IteratorB::Element const *ptr_B = nullptr;
+    typename Mma::IteratorScaleBias::Params iterator_scale_bias{};
+    typename Mma::IteratorScaleBias::Element const *ptr_scale = nullptr;
+    typename Mma::IteratorScaleBias::Element const *ptr_bias = nullptr;
+    typename Epilogue::OutputTileIterator::Params iterator_C {};
+    typename Epilogue::OutputTileIterator::Element *ptr_C = nullptr;
+    typename Epilogue::OutputTileIterator::Params iterator_D {};
+    typename Epilogue::OutputTileIterator::Element *ptr_D = nullptr;
+    typename EpilogueOutputOp::Params output_op {};
+    int *semaphore = nullptr;
+    SplitKMode split_k_mode {};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params(): swizzle_log_tile(0), gemm_k_iterations(0) { }
+    Params() = default;
 
     /// 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       int *semaphore = nullptr
     ):
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h`

 * *Files 3% similar despite different names*

```diff
@@ -154,29 +154,28 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    ConvProblemSize problem_size;
-    TensorRefA ref_A;
-    TensorRefB ref_B;
-    TensorRefC ref_C;
-    TensorRefC ref_D;
-    typename EpilogueOutputOp::Params output_op;
-    SplitKMode split_k_mode;
+    ConvProblemSize problem_size{};
+    TensorRefA ref_A{};
+    TensorRefB ref_B{};
+    TensorRefC ref_C{};
+    TensorRefC ref_D{};
+    typename EpilogueOutputOp::Params output_op{};
+    SplitKMode split_k_mode{};
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments() { }
+    Arguments() = default;
    
     CUTLASS_HOST_DEVICE 
     Arguments(
       ConvProblemSize const & problem_size
     ):
       problem_size(problem_size) { }
 
@@ -201,38 +200,36 @@
 
     }
 
   };
 
   /// Parameters structure
   struct Params {
-    ConvProblemSize problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    FastDivmod stride_h_divmod;
-    FastDivmod stride_w_divmod;
-    int gemm_k_iterations;
-    typename Mma::IteratorA::Params iterator_A;
-    typename Mma::IteratorA::Element const *ptr_A;
-    typename Mma::IteratorB::Params iterator_B;
-    typename Mma::IteratorB::Element const *ptr_B;
-    typename Epilogue::OutputTileIterator::Params iterator_C;
-    typename Epilogue::OutputTileIterator::Element *ptr_C;
-    typename Epilogue::OutputTileIterator::Params iterator_D;
-    typename Epilogue::OutputTileIterator::Element *ptr_D;
-    typename EpilogueOutputOp::Params output_op;
-    int *semaphore;
-    SplitKMode split_k_mode;
+    ConvProblemSize problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
+    FastDivmod stride_h_divmod{};
+    FastDivmod stride_w_divmod{};
+    int gemm_k_iterations{0};
+    typename Mma::IteratorA::Params iterator_A{};
+    typename Mma::IteratorA::Element const *ptr_A = nullptr;
+    typename Mma::IteratorB::Params iterator_B{};
+    typename Mma::IteratorB::Element const *ptr_B = nullptr;
+    typename Epilogue::OutputTileIterator::Params iterator_C{};
+    typename Epilogue::OutputTileIterator::Element *ptr_C = nullptr;
+    typename Epilogue::OutputTileIterator::Params iterator_D{};
+    typename Epilogue::OutputTileIterator::Element *ptr_D = nullptr;
+    typename EpilogueOutputOp::Params output_op {};
+    int *semaphore = nullptr;
+    SplitKMode split_k_mode {};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params(): gemm_k_iterations(0) { }
+    Params() = default;
 
     /// 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       int *semaphore = nullptr
     ):
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h`

 * *Files 0% similar despite different names*

```diff
@@ -57,15 +57,15 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Mma_,                                  ///! Threadblock-scoped matrix multiply-accumulate 
   typename Epilogue_,                             ///! Epilogue
   typename ThreadblockSwizzle_,                   ///! Threadblock swizzling function
-  conv::Operator ConvOperator,                    ///! Convolutional operator (Fprop, Dgrad, Wgrad)
+  conv::Operator ConvOperator,                    ///! Convolutional operator (Fprop, Dgrad, Wgrad, Deconv)
   typename ConvProblemSize_ = Conv2dProblemSize   ///! Convolutional operator on 2D or 3D problem
 >
 struct ImplicitGemmConvolutionWithFusedEpilogue {
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
   using EpilogueOutputOp = typename Epilogue::OutputOp;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files 6% similar despite different names*

```diff
@@ -63,15 +63,16 @@
 
 template <
   typename Shape_,
   typename Element_,
   typename Layout_,
   typename ThreadMap_,
   typename AccessType_ = cutlass::AlignedArray<Element_, ThreadMap_::kElementsPerAccess>,
-  conv::GroupMode GroupMode_ = conv::GroupMode::kNone
+  conv::GroupMode GroupMode_ = conv::GroupMode::kNone,
+  bool IsDeconv_ = false
 >
 class Conv2dFpropFilterTileAccessIteratorAnalytic {
 public:
   
   //
   // Types
   //
@@ -81,25 +82,26 @@
   using Layout = Layout_;
   using ThreadMap = ThreadMap_;
   using AccessType = AccessType_;
   using TensorRef = cutlass::TensorRef<Element, Layout>;
   using TensorCoord = typename Layout::TensorCoord;
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
+  static bool const IsDeconv = IsDeconv_;
   static IteratorAlgorithm const kIteratorAlgorithm = conv::IteratorAlgorithm::kAnalytic;
   static StrideSupport const kStrideSupport = conv::StrideSupport::kStrided;
   static int const kConvDim = 2;
   using ConvProblemSize = typename conv::Conv2dProblemSize;
   static conv::GroupMode const kGroupMode = GroupMode_;
  
   static int const kAccessesPerVector = ThreadMap::kElementsPerAccess / AccessType::kElements;
   
   static_assert(!(ThreadMap::kElementsPerAccess % AccessType::kElements), 
     "Vectors implied by the thread map must be divisible by the access type.");
- 
+
   //
   // Simplifying assertions
   //
   static_assert(ThreadMap::Iterations::kContiguous == 1,
     "Require Iterations::kContiguous == 1");
 
   //
@@ -148,30 +150,33 @@
     filter_s_(0),
     filter_c_(0) {
 
     layout::PitchLinearCoord thread_coord = ThreadMap::initial_offset(thread_idx);
 
     filter_c_ = threadblock_offset.row() + thread_coord.contiguous();
 
+    auto input_channels = (IsDeconv ? problem_size_.K : problem_size_.C);
+    auto output_channels = (IsDeconv ? problem_size_.C : problem_size_.K);
+
     if (kGroupMode != conv::GroupMode::kNone) {
       filter_c_init_ = filter_c_;
       if (kGroupMode == conv::GroupMode::kDepthwise){
         channels_per_group_ = 1;
         crs_per_group_ = problem_size_.S * problem_size_.R;
       } else {
-        channels_per_group_ = problem_size_.C / problem_size_.groups;
+        channels_per_group_ = input_channels / problem_size_.groups;
         crs_per_group_ = problem_size_.S * problem_size_.R * ((channels_per_group_ + Shape::kRow - 1) / Shape::kRow);
       }
     }
 
     CUTLASS_PRAGMA_UNROLL
     for (int s = 0; s < ThreadMap::Iterations::kStrided; ++s) {
       offset_k_[s] = threadblock_offset.column() + thread_coord.strided() + s * ThreadMap::Delta::kStrided;
       if (kGroupMode != conv::GroupMode::kNone && kGroupMode != conv::GroupMode::kDepthwise) {
-        group_idx_offset_k_[s] = (thread_coord.strided() + s * ThreadMap::Delta::kStrided) / (problem_size_.K / problem_size_.groups);
+        group_idx_offset_k_[s] = (thread_coord.strided() + s * ThreadMap::Delta::kStrided) / (output_channels / problem_size_.groups);
       }
     }
 
     set_iteration_index(0);
   }
 
   /// Overrides the internal iteration index
@@ -237,20 +242,23 @@
 
   /// Returns true if the current coordinate is within the activations tensor W
   CUTLASS_HOST_DEVICE
   bool valid() const {
 
     TensorCoord coord = at();
 
+    auto input_channels = (IsDeconv ? problem_size_.K : problem_size_.C);
+    auto output_channels = (IsDeconv ? problem_size_.C : problem_size_.K);
+
     if (kGroupMode == conv::GroupMode::kNone) {
-      return coord.n() < problem_size_.K && coord.c() < problem_size_.C;
+      return coord.n() < output_channels && coord.c() < input_channels;
     } else if (kGroupMode == conv::GroupMode::kDepthwise) {
-      return coord.n() < problem_size_.K && coord.c() < 1; // channels_per_group_ is always equal to ONE.
+      return coord.n() < output_channels && coord.c() < 1; // channels_per_group_ is always equal to ONE.
     } else {
-      return coord.n() < problem_size_.K && coord.c() < channels_per_group_ &&
+      return coord.n() < output_channels && coord.c() < channels_per_group_ &&
              group_idx_offset_c_ == group_idx_offset_k_[iteration_strided_];
     }
   }
 
   /// Returns a pointer to the vector starting at the current coordinate
   CUTLASS_HOST_DEVICE
   AccessType const *get() const {
@@ -285,27 +293,30 @@
     return *this;
   }
 
   /// Determines whether the Implicit GEMM can execute the given problem.
   CUTLASS_HOST_DEVICE
   static Status can_implement(Conv2dProblemSize const &problem_size) {
 
+    auto input_channels = (IsDeconv ? problem_size.K : problem_size.C);
+    auto output_channels = (IsDeconv ? problem_size.C : problem_size.K);
+
     // check alignment constraint on iterator's contiguous dimension
-    if ((problem_size.C / problem_size.groups) % AccessType::kElements) {
+    if ((input_channels / problem_size.groups) % AccessType::kElements) {
       return Status::kErrorInvalidProblem;
     }
 
     if (platform::is_same<Layout, layout::TensorCxRSKx<32>>::value) {
-      if (problem_size.K % 32) {
+      if (output_channels % 32) {
         return Status::kErrorInvalidProblem;
       }
     }
 
     if (platform::is_same<Layout, layout::TensorCxRSKx<64>>::value) {
-      if (problem_size.K % 64) {
+      if (output_channels % 64) {
         return Status::kErrorInvalidProblem;
       }
     }
 
     return Status::kSuccess;
   }
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files 4% similar despite different names*

```diff
@@ -63,15 +63,16 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Shape_,
   typename Element_,
   typename Layout_,
   typename ThreadMap_,
-  typename AccessType_ = cutlass::AlignedArray<Element_, ThreadMap_::kElementsPerAccess>
+  typename AccessType_ = cutlass::AlignedArray<Element_, ThreadMap_::kElementsPerAccess>,
+  bool IsDeconv_ = false
 >
 class Conv2dFpropFilterTileAccessIteratorOptimized{
 public:
   
   //
   // Types
   //
@@ -81,14 +82,15 @@
   using Layout = Layout_;
   using ThreadMap = ThreadMap_;
   using AccessType = AccessType_;
   using TensorRef = cutlass::TensorRef<Element, Layout>;
   using TensorCoord = typename Layout::TensorCoord;
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
+  static bool const IsDeconv = IsDeconv_;
   static IteratorAlgorithm const kIteratorAlgorithm = conv::IteratorAlgorithm::kOptimized;
   static StrideSupport const kStrideSupport = conv::StrideSupport::kStrided;
   static int const kConvDim = 2;
   using ConvProblemSize = typename conv::Conv2dProblemSize;
  
   static int const kAccessesPerVector = ThreadMap::kElementsPerAccess / AccessType::kElements;
   
@@ -172,19 +174,19 @@
     filter_rs_(0),
     filter_c_(0) {
 
     layout::PitchLinearCoord thread_coord = ThreadMap::initial_offset(thread_idx);
 
     filter_c_ = threadblock_offset.row() + thread_coord.contiguous();
     Index column = threadblock_offset.column() + thread_coord.strided();
-    channels_per_group_ = problem_size_.C / problem_size_.groups;
+    channels_per_group_ = (IsDeconv ? problem_size_.K : problem_size_.C) / problem_size_.groups;
 
     CUTLASS_PRAGMA_UNROLL
     for (int s = 0; s < ThreadMap::Iterations::kStrided; ++s) {
-      uint32_t pred = ((column + s * ThreadMap::Delta::kStrided < problem_size_.K) ? 1u : 0);
+      uint32_t pred = ((column + s * ThreadMap::Delta::kStrided < (IsDeconv ? problem_size_.C : problem_size_.K)) ? 1u : 0);
 
       CUTLASS_PRAGMA_UNROLL
       for (int v_idx = 0; v_idx < kAccessesPerVector; ++v_idx) {
         predicates_[v_idx] |= (pred << s);
       }
     }
 
@@ -283,27 +285,30 @@
     return *this;
   }
 
   /// Determines whether the Implicit GEMM can execute the given problem.
   CUTLASS_HOST_DEVICE
   static Status can_implement(Conv2dProblemSize const &problem_size) {
 
+    auto input_channels = (IsDeconv ? problem_size.K : problem_size.C);
+    auto output_channels = (IsDeconv ? problem_size.C : problem_size.K);
+
     // check alignment constraint on iterator's contiguous dimension
-    if ((problem_size.C / problem_size.groups) % AccessType::kElements) {
+    if ((input_channels / problem_size.groups) % AccessType::kElements) {
       return Status::kErrorInvalidProblem;
     }
 
     if (platform::is_same<Layout, layout::TensorCxRSKx<32>>::value) {
-      if (problem_size.K % 32) {
+      if (output_channels % 32) {
         return Status::kErrorInvalidProblem;
       }
     }
 
     if (platform::is_same<Layout, layout::TensorCxRSKx<64>>::value) {
-      if (problem_size.K % 64) {
+      if (output_channels % 64) {
         return Status::kErrorInvalidProblem;
       }
     }
 
     return Status::kSuccess;
   }
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files 7% similar despite different names*

```diff
@@ -60,15 +60,16 @@
 namespace threadblock {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Shape_,
   typename Element_,
-  typename ThreadMap_
+  typename ThreadMap_,
+  bool IsDeconv_ = false
 >
 class Conv3dFpropFilterTileAccessIteratorAnalytic {
 public:
   
   //
   // Types
   //
@@ -78,14 +79,15 @@
   using Layout = layout::TensorNDHWC;
   using ThreadMap = ThreadMap_;
   using AccessType = AlignedArray<Element, ThreadMap::kElementsPerAccess>;
   using TensorRef = cutlass::TensorRef<Element, Layout>;
   using TensorCoord = typename Layout::TensorCoord;
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
+  static bool const IsDeconv = IsDeconv_;
   static IteratorAlgorithm const kIteratorAlgorithm = conv::IteratorAlgorithm::kAnalytic;
   static StrideSupport const kStrideSupport = conv::StrideSupport::kStrided;
   static int const kConvDim = 3;
   using ConvProblemSize = typename conv::Conv3dProblemSize;
   static int const kAccessesPerVector = 1;
   
   //
@@ -194,16 +196,19 @@
 
   /// Returns true if the current coordinate is within the activations tensor W
   CUTLASS_HOST_DEVICE
   bool valid() const {
 
     TensorCoord coord = at();
 
-    return coord.n() < problem_size_.K &&
-      coord.c() < problem_size_.C;
+    auto input_channels = (IsDeconv ? problem_size_.K : problem_size_.C);
+    auto output_channels = (IsDeconv ? problem_size_.C : problem_size_.K);
+
+    return coord.n() < output_channels &&
+      coord.c() < input_channels;
   }
 
   /// Returns a pointer to the vector starting at the current coordinate
   CUTLASS_HOST_DEVICE
   AccessType const *get() const {
 
     TensorCoord coord = at();
@@ -230,16 +235,18 @@
     return *this;
   }
 
   /// Determines whether the Implicit GEMM can execute the given problem.
   CUTLASS_HOST_DEVICE
   static Status can_implement(ConvProblemSize const &problem_size) {
 
+    auto input_channels = (IsDeconv ? problem_size.K : problem_size.C);
+    auto output_channels = (IsDeconv ? problem_size.C : problem_size.K);
     // check alignment constraint on iterator's contiguous dimension
-    if (problem_size.K % (128/sizeof_bits<Element>::value)) {
+    if (input_channels % (128/sizeof_bits<Element>::value)) {
       return Status::kErrorInvalidProblem;
     }
     return Status::kSuccess;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files 6% similar despite different names*

```diff
@@ -62,15 +62,16 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Shape_,
   typename Element_,
   typename Layout_,
-  typename ThreadMap_
+  typename ThreadMap_,
+  bool IsDeconv_ = false
 >
 class Conv3dFpropFilterTileAccessIteratorOptimized{
 public:
   
   //
   // Types
   //
@@ -80,14 +81,15 @@
   using Layout = Layout_;
   using ThreadMap = ThreadMap_;
   using AccessType = AlignedArray<Element, ThreadMap::kElementsPerAccess>;
   using TensorRef = cutlass::TensorRef<Element, Layout>;
   using TensorCoord = typename Layout::TensorCoord;
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
+  static bool const IsDeconv = IsDeconv_;
   static IteratorAlgorithm const kIteratorAlgorithm = conv::IteratorAlgorithm::kOptimized;
   static StrideSupport const kStrideSupport = conv::StrideSupport::kStrided;
   static int const kConvDim = 3;
   using ConvProblemSize = typename conv::Conv3dProblemSize;
   static int const kAccessesPerVector = 1;
   
   //
@@ -168,19 +170,19 @@
     layout::PitchLinearCoord thread_coord = ThreadMap::initial_offset(thread_idx);
 
     filter_c_ = threadblock_offset.row() + thread_coord.contiguous();
     Index column = threadblock_offset.column() + thread_coord.strided();
 
     CUTLASS_PRAGMA_UNROLL
     for (int s = 0; s < ThreadMap::Iterations::kStrided; ++s) {
-      uint32_t pred = ((column + s * ThreadMap::Delta::kStrided < problem_size_.K) ? 1u : 0);
+      uint32_t pred = ((column + s * ThreadMap::Delta::kStrided < (IsDeconv ? problem_size_.C : problem_size_.K)) ? 1u : 0);
       predicates_ |= (pred << s);
     }
 
-    if (filter_c_ >= problem_size.C) {
+    if (filter_c_ >= (IsDeconv ? problem_size_.K : problem_size_.C)) {
       predicates_ = 0u;
     }
 
     pointer_ += (
       params_.layout({filter_c_, column}) 
     ) * sizeof_bits<Element>::value / 8;
 
@@ -210,15 +212,15 @@
     if (filter_trs_ == params_.TRS) {
 
       filter_trs_ = 0;
       next = params_.inc_next_c;
       filter_c_ += params_.filter_c_delta;
     }
       
-    if (filter_c_ >= problem_size_.C) {
+    if (filter_c_ >= (IsDeconv ? problem_size_.K : problem_size_.C)) {
       predicates_ = 0;
     }
       
     pointer_ += next;
   }
 
   /// Returns true if the current coordinate is within the filter tensor W
@@ -255,16 +257,18 @@
     return *this;
   }
 
   /// Determines whether the Implicit GEMM can execute the given problem.
   CUTLASS_HOST_DEVICE
   static Status can_implement(Conv3dProblemSize const &problem_size) {
 
+    auto input_channels = (IsDeconv ? problem_size.K : problem_size.C);
+
     // check alignment constraint on iterator's contiguous dimension
-    if (problem_size.C % (128/sizeof_bits<Element>::value)) {
+    if (input_channels % (128/sizeof_bits<Element>::value)) {
       return Status::kErrorInvalidProblem;
     }
 
     return Status::kSuccess;
   }
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -135,15 +135,15 @@
     static int const kAccessesPerGroupB =
         (AsyncCopyIterationsPerStageB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
     // Optional staged-accumulation (e.g., tf32x3 kernels) for improved numerical
     // accuracy, where each mainloop iteration first accumulates into a temporary
     // set of freshly-cleared accumulators, which are subsequently added to the
     // final accumulator set.
-    static bool const kStagedAccumulation = arch::UseStagedAccumulation<typename Operator::MathOperator>::value;
+    static bool const kStagedAccumulation = arch::detail::UseStagedAccumulation<Operator>::value;
   };
 
  private:
 
   using WarpLoadedFragmentA = typename Operator::FragmentA;
   using WarpLoadedFragmentB = typename Operator::FragmentB;
   using WarpTransformedFragmentA = typename Operator::TransformedFragmentA;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/coord.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/coord.h`

 * *Files 2% similar despite different names*

```diff
@@ -28,24 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief A Coord is a coordinate of arbitrary rank into a tensor or matrix
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/cstdint>
 #else
 #include <stdint.h>
 #endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/core_io.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/core_io.h`

 * *Files 4% similar despite different names*

```diff
@@ -27,23 +27,14 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Helpers for printing cutlass/core objects
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 #pragma once
 
 #include <iostream>
 #include <typeinfo>
 
 #include "cutlass/array.h"
 #include "cutlass/coord.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/cuda_host_adapter.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cuda_host_adapter.hpp`

 * *Files 9% similar despite different names*

```diff
@@ -176,14 +176,46 @@
     dim3 const grid_dims,
     dim3 const cluster_dims,
     dim3 const block_dims,
     size_t const smem_size,
     cudaStream_t cuda_stream,
     void** kernel_params,
     int32_t kernel_index) const = 0;
+
+protected:
+
+  /**
+   * Fills a buffer in Global Memory with a byte sequence copied from host memory.
+   * This function can be overriden to dispatch to the appropriate cuMemsetD*Async API
+  */
+  virtual Status memsetDeviceImpl(
+    void* destination, ///< Device memory pointer to be filled
+    void const* fill_value, ///< Value to be filled in the buffer
+    size_t fill_size, ///< Size of the data type to be used for filling the buffer
+    size_t count, ///< Number of elements of size fill_size
+    cudaStream_t stream) const = 0;
+
+public:
+
+  /// Fills a buffer in Global Memory with a byte sequence copied from host memory
+  template<class FillValueType>
+  Status memsetDevice(
+    void* destination,
+    FillValueType fill_value, 
+    size_t count,
+    cudaStream_t stream) const
+  {
+    return this->memsetDeviceImpl(
+      destination,
+      &fill_value,
+      sizeof(FillValueType),
+      count,
+      stream);
+  }
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/cutlass.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/cutlass.h`

 * *Files 6% similar despite different names*

```diff
@@ -29,24 +29,14 @@
  *
  **************************************************************************************************/
 
 /*! \file
     \brief Basic include for CUTLASS.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/detail/helper_macros.hpp"
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/collective.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/collective.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/dependent_false.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/dependent_false.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/helper_macros.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/helper_macros.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/layout.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/detail/layout.hpp`

 * *Files 24% similar despite different names*

```diff
@@ -28,16 +28,18 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/layout/matrix.h"
 #include "cutlass/layout/tensor.h"
+#include "cutlass/numeric_types.h"
 
 #include "cute/layout.hpp"
+#include "cute/util/type_traits.hpp"
 #include "cute/arch/copy_sm90_tma.hpp"
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::detail {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 // For each cutlass::layout, provides its corresponding cute stride types, 64b by default
@@ -81,47 +83,101 @@
 };
 
 // For each cutlass::layout *, provides its corresponding cute stride types, 64b by default
 // Used by pointer array and grouped gemm
 // Maps to modes [M, K, L]
 template <>
 struct TagToStrideA<layout::RowMajor *> {
-  using UnderlyingType = cute::Stride<int64_t, cute::Int<1>, int64_t>;
+  using UnderlyingType = cute::Stride<int64_t, cute::Int<1>, cute::Int<0>>;
   using type = UnderlyingType*;
   using tag = layout::RowMajor;
 };
 
 // Maps to modes [M, K, L]
 template <>
 struct TagToStrideA<layout::ColumnMajor *> {
-  using UnderlyingType = cute::Stride<cute::Int<1>, int64_t, int64_t>;
+  using UnderlyingType = cute::Stride<cute::Int<1>, int64_t, cute::Int<0>>;
   using type = UnderlyingType*;
   using tag = layout::ColumnMajor;
 };
 
 // Maps to modes [N, K, L]
 template <>
 struct TagToStrideB<layout::RowMajor *> {
-  using UnderlyingType = cute::Stride<cute::Int<1>, int64_t, int64_t>;
+  using UnderlyingType = cute::Stride<cute::Int<1>, int64_t, cute::Int<0>>;
   using type = UnderlyingType*;
   using tag = layout::RowMajor;
 };
 
 // Maps to modes [N, K, L]
 template <>
 struct TagToStrideB<layout::ColumnMajor *> {
-  using UnderlyingType = cute::Stride<int64_t, cute::Int<1>, int64_t>;
+  using UnderlyingType = cute::Stride<int64_t, cute::Int<1>, cute::Int<0>>;
   using type = UnderlyingType*;
   using tag = layout::ColumnMajor;
 };
 
 // Maps to modes [M, N, L]
 template <class LayoutTag>
 struct TagToStrideC : TagToStrideA<LayoutTag> { };
 
+// Conv: Maps to modes ((P,N), C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorNWC> {
+  using type = cute::Stride<cute::Stride<int64_t, int64_t>, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (PN, C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorLinearizedNWC> {
+  using type = cute::Stride<int64_t, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes ((P,Q,N), C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorNHWC> {
+  using type = cute::Stride<cute::Stride<int64_t, int64_t, int64_t>, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (PQN, C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorLinearizedNHWC> {
+  using type = cute::Stride<int64_t, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes ((P,Q,Z,N), C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorNDHWC> {
+  using type = cute::Stride<cute::Stride<int64_t, int64_t, int64_t, int64_t>, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (PQZN, C, _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorLinearizedNDHWC> {
+  using type = cute::Stride<int64_t, cute::Int<1>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (K, (C,S), _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorKCS> {
+  using type = cute::Stride<int64_t, cute::Stride<cute::Int<1>, int64_t>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (K, (C,S,R), _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorKCSR> {
+  using type = cute::Stride<int64_t, cute::Stride<cute::Int<1>, int64_t, int64_t>, cute::Int<0>>;
+};
+
+// Conv: Maps to modes (K, (C,S,R,T), _0) for compatiblity with GEMM epilogues expecting a batch mode stride
+template <>
+struct TagToStrideC<cutlass::layout::TensorKCSRT> {
+  using type = cute::Stride<int64_t, cute::Stride<cute::Int<1>, int64_t, int64_t, int64_t>, cute::Int<0>>;
+};
+
 // Convenience aliases
 template<class LayoutTag>
 using TagToStrideA_t = typename TagToStrideA<LayoutTag>::type;
 
 template<class LayoutTag>
 using TagToStrideB_t = typename TagToStrideB<LayoutTag>::type;
 
@@ -225,16 +281,23 @@
                   ) {
       return true;
     }
   }
   return false;
 }
 
+template <class X, class = void>
+struct RawDtype { using type = X; };
+
+template <class X>
+struct RawDtype<X,cute::void_t<typename X::raw_type>> { using type = typename X::raw_type; };
+
+
 // Inspects a TiledCopy and returns its alignment in terms of element count
-template <class GmemTiledCopy, class Element>
+template <class GmemTiledCopy, class Element, class ElementMma = Element>
 constexpr int
 get_alignment_count_from_gmem_tiled_copy() {
 
   if constexpr (cute::is_void_v<GmemTiledCopy>) {
     return 1;
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/detail/mma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/trace.h`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,43 +24,36 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#pragma once
-
-#include "cutlass/arch/mma.h"
-#include "cute/layout.hpp"
+/*! \file
+    \brief Helpers for optionally tracing through code when debugging.
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
+    This file is to be included after all other headers.
+*/
 
-namespace cutlass::detail {
+#pragma once
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-template <class TiledMma, class = void>
-struct IsSparseTensorOp : cute::false_type { };
-
-// The following metafunction is used to extract the OperatorClass from a cutlass 3.x kernel.
-template <class TiledMma>
-struct get_operator_class {
-  static constexpr bool is_sparse_op = IsSparseTensorOp<TiledMma>::value;
-  static constexpr bool is_tensor_op = cute::size<0>(typename TiledMma::AtomShape_MNK{}) >= 8;
-  using type = cute::conditional_t<
-                is_tensor_op, 
-                cute::conditional_t<
-                  is_sparse_op,
-                  cutlass::arch::OpClassSparseTensorOp,
-                    cutlass::arch::OpClassTensorOp
-                  >,
-                cutlass::arch::OpClassSimt
-                >;
-};
-
-template <class T>
-using get_operator_class_t = typename get_operator_class<T>::type;
+// Tracing options
+#ifndef CUTLASS_DEBUG_TRACE_LEVEL
+#define CUTLASS_DEBUG_TRACE_LEVEL 0
+#endif
+
+#if CUTLASS_DEBUG_TRACE_LEVEL
+#include <iostream>
+#include "cutlass/core_io.h"
+#if defined(__CUDA_ARCH__)
+#define CUTLASS_TRACE_HOST(x)
+#else
+#define CUTLASS_TRACE_HOST(x) { std::cout << __FILE__ << ":" << __LINE__ << "  " << x << std::endl; }
+#endif
+#else
+#define CUTLASS_TRACE_HOST(x)
+#endif
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace cutlass::detail
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/device_kernel.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/device_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/collective_builder.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_builder.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -57,15 +57,15 @@
   class ElementCompute,
   class ElementC,
   class GmemLayoutTagC,
   int AlignmentC,
   class ElementD,
   class GmemLayoutTagD,
   int AlignmentD,
-  class Schedule,
+  class EpilogueScheduleType,
   class FusionOpOrCallbacks = cutlass::epilogue::fusion::LinearCombination<ElementD,ElementCompute,ElementC,ElementCompute>,
   class Enable = void
 >
 struct CollectiveBuilder {
   static_assert(cutlass::detail::dependent_false<ArchTag>,
       "Could not build a collective epilogue for given parameters.");
 };
@@ -96,15 +96,15 @@
 >
 struct CallbacksBuilder<
   DispatchPolicy,
   FusionCallbacks,
   TileShape_MNK,
   EpilogueTile_MN,
   ElementAccumulator,
-  enable_if_t<not is_base_of_v<fusion::FusionOperation, FusionCallbacks>>
+  cute::enable_if_t<not is_base_of_v<fusion::FusionOperation, FusionCallbacks>>
 > {
   using Callbacks = FusionCallbacks;
 };
 
 } // namespace detail
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -35,15 +35,16 @@
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/dispatch_policy.hpp"
 #include "cutlass/epilogue/collective/detail.hpp"
 
 #include "cute/tensor.hpp"
-#include "cute/numeric/int.hpp"
+#include "cute/numeric/numeric_types.hpp"
+#include "cutlass/cuda_host_adapter.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace collective {
 
@@ -60,15 +61,15 @@
 class DefaultEpilogue {
 public:
   //
   // Type Aliases
   //
   using EpilogueSchedule = EpilogueSchedule_;
   using DispatchPolicy = EpilogueSchedule_;
-  
+
   // derived types of output thread level operator
   using ThreadEpilogueOp = ThreadEpilogueOp_;
   using ElementOutput = typename ThreadEpilogueOp::ElementOutput;
   using ElementAccumulator = typename ThreadEpilogueOp::ElementAccumulator;
   using ElementCompute = typename ThreadEpilogueOp::ElementCompute;
   using ElementScalar = ElementCompute;
   using ElementC = typename ThreadEpilogueOp::ElementC;
@@ -83,14 +84,16 @@
   using AlignmentType = typename cute::uint_bit<sizeof_bits<ElementOutput>::value * kOutputAlignment>::type;
 
   static_assert(cute::rank(StrideC{}) == 3, "StrideCD must be rank-3: [M, N, L]");
   static_assert(cute::rank(StrideD{}) == 3, "StrideCD must be rank-3: [M, N, L]");
 
   struct SharedStorage { };
 
+  using TensorStorage = SharedStorage;
+
   // Host side epilogue arguments
   struct Arguments {
     typename ThreadEpilogueOp::Params thread{};
     ElementC const* ptr_C = nullptr;
     StrideC dC{};
     ElementD* ptr_D = nullptr;
     StrideD dD{};
@@ -116,15 +119,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   template<class ProblemShape>
   CUTLASS_HOST_DEVICE static bool
   can_implement(
       [[maybe_unused]] ProblemShape const& problem_shape,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue_array.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue_array.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -35,17 +35,18 @@
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/dispatch_policy.hpp"
 #include "cutlass/epilogue/collective/detail.hpp"
 
 #include "cute/tensor.hpp"
-#include "cute/numeric/int.hpp"
+#include "cute/numeric/numeric_types.hpp"
 #include "cutlass/trace.h"
 
+#include "cutlass/cuda_host_adapter.hpp"
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace collective {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -119,15 +120,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   template<class ProblemShape>
   CUTLASS_HOST_DEVICE static bool
   can_implement(
       [[maybe_unused]] ProblemShape const& problem_shape,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/detail.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/detail.hpp`

 * *Files 11% similar despite different names*

```diff
@@ -34,15 +34,15 @@
 #include "cutlass/cutlass.h"
 #include "cutlass/pipeline/pipeline.hpp"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/dispatch_policy.hpp"
 #include "cutlass/epilogue/dispatch_policy.hpp"
 
 #include "cute/tensor.hpp"
-#include "cute/numeric/int.hpp"
+#include "cute/numeric/numeric_types.hpp"
 #include "cute/util/type_traits.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace collective {
@@ -59,27 +59,41 @@
 
 template <class Stride>
 constexpr bool
 is_n_major() {
   return cutlass::gemm::detail::is_major<1,Stride>();
 }
 
+template <class Stride>
+constexpr bool
+is_im2col() {
+  return cute::is_same_v<Stride, cutlass::detail::TagToStrideC_t<cutlass::layout::TensorNWC>>
+      || cute::is_same_v<Stride, cutlass::detail::TagToStrideC_t<cutlass::layout::TensorNHWC>>
+      || cute::is_same_v<Stride, cutlass::detail::TagToStrideC_t<cutlass::layout::TensorNDHWC>>;
+}
+
 using cutlass::atomic_maximum;
 
 template <class T>
 static constexpr int elements_per_access_v = cutlass::sizeof_bits<uint32_t>::value / cutlass::sizeof_bits<T>::value;
 
 template <class EpilogueSchedule>
 static constexpr bool sm90_is_cooperative_v =
   cute::is_base_of_v<cutlass::epilogue::TmaWarpSpecializedCooperative, EpilogueSchedule>;
 
 template <class EpilogueSchedule>
 static constexpr bool sm90_is_warp_specialized_v =
   cute::is_base_of_v<cutlass::epilogue::TmaWarpSpecialized, EpilogueSchedule>;
 
+template <class GmemLayoutTag>
+static constexpr bool is_im2col_mode =
+  cute::is_same_v<GmemLayoutTag, cutlass::layout::TensorNWC> ||
+  cute::is_same_v<GmemLayoutTag, cutlass::layout::TensorNHWC> ||
+  cute::is_same_v<GmemLayoutTag, cutlass::layout::TensorNDHWC>;
+
 template <class T>
 struct EmptyStorage {
   CUTLASS_HOST_DEVICE
   T* data() { return nullptr; }
 };
 
 template<class EpilogueSchedule, class Stride>
@@ -101,14 +115,36 @@
 
 template <typename ThreadEpilogueOp>
 struct IsThreadEpilogueOpWithBias <ThreadEpilogueOp, cute::void_t<typename ThreadEpilogueOp::ElementBias>> { 
   static constexpr bool value = true; 
   using type = typename ThreadEpilogueOp::ElementBias; 
 };
 
+template <typename ThreadEpilogueOp, typename = void>
+struct IsThreadEpilogueOpWithPerChannelScaling {
+  static constexpr bool value = false;
+};
+
+template <typename ThreadEpilogueOp>
+struct IsThreadEpilogueOpWithPerChannelScaling <ThreadEpilogueOp, cute::enable_if_t<ThreadEpilogueOp::IsPerChannelScalingSupported>> {
+  static constexpr bool value = true;
+};
+
+template <typename ThreadEpilogueOp, typename = void>
+struct IsThreadEpilogueOpWithActivation {
+  static constexpr bool value = false;
+  using type = void;
+};
+
+template <typename ThreadEpilogueOp>
+struct IsThreadEpilogueOpWithActivation <ThreadEpilogueOp, cute::enable_if_t<ThreadEpilogueOp::IsEltActSupported>> {
+  static constexpr bool value = true;
+  using type = typename ThreadEpilogueOp::ActivationFn;
+};
+
 // Wrapper class to use operator-style epilogues in sm90 TMA warp-specialized kernels
 template <class EpilogueOp>
 class Sm90TmaWarpSpecializedAdapter : public EpilogueOp {
 public:
   using GmemTiledCopyC = void;
   using GmemTiledCopyD = void;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/epilogue_tensor_broadcast.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue_tensor_broadcast.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -51,14 +51,15 @@
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/epilogue/collective/detail.hpp"
 
 #include "cute/tensor.hpp"
+#include "cutlass/cuda_host_adapter.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace collective {
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -138,15 +139,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   template <class ProblemShape>
   CUTLASS_HOST_DEVICE static bool
   can_implement(
       [[maybe_unused]] ProblemShape const& problem_shape,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm70_epilogue_vectorized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp`

 * *Files 25% similar despite different names*

```diff
@@ -24,333 +24,295 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-  \brief Functor performing elementwise operations used by epilogues.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
-
+#include "cutlass/fast_math.h"
+#include "cutlass/kernel_hardware_info.hpp"
+#include "cute/arch/cluster_sm90.hpp"
+#include "cutlass/arch/mma_sm90.h"
+#include "cutlass/epilogue/collective/detail.hpp"
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/gemm/kernel/sm90_tile_scheduler.hpp"
+#include "cutlass/trace.h"
 #include "cute/tensor.hpp"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+///////////////////////////////////////////////////////////////////////////////
+
+namespace cutlass::gemm::kernel {
+
+namespace detail {
+
+// IF_SWAP_AB<T>::value will be true only if:
+//   class T has member SwapAB and T::SwapAB is true
+template <typename T, typename = void>
+struct IF_SWAP_AB { static constexpr bool value = false; };
+
+template <typename T>
+struct IF_SWAP_AB <T, void_t<decltype(T::SwapAB)>>
+{ static constexpr bool value = T::SwapAB; };
+
+} // namespace
+
+///////////////////////////////////////////////////////////////////////////////
 
-namespace cutlass {
-namespace epilogue {
-namespace collective {
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Applies an element wise operation to all elements within the fragment
-/// and writes it out to destination storage.
-///
-/// Ways to generalize this:
-/// - CTA tile shape
-/// - vectorization requirements (GMEM)
-/// - vectoriz(able) transform()
-///
 template <
-  class StrideC_,
-  class StrideD_,
-  class ThreadEpilogueOp_,
-  class SmemLayout_,
-  class CopyAtomR2S_,
-  class TiledCopyS2R_,
-  class CopyAtomR2G_
+  class ProblemShape_,
+  class CollectiveMainloop_,
+  class CollectiveEpilogue_,
+  class TileScheduler_
 >
-class Epilogue {
+class GemmUniversal<
+  ProblemShape_,
+  CollectiveMainloop_,
+  CollectiveEpilogue_,
+  TileScheduler_,
+  cute::enable_if_t<cute::is_base_of_v<KernelTma, typename CollectiveMainloop_::DispatchPolicy::Schedule>>>
+{
 public:
   //
   // Type Aliases
   //
-  // derived types of output thread level operator
-  using ThreadEpilogueOp = ThreadEpilogueOp_;
-  using ElementAccumulator = typename ThreadEpilogueOp::ElementAccumulator;
-  using ElementCompute = typename ThreadEpilogueOp::ElementCompute;
-  using ElementScalar = ElementCompute;
-  using ElementOutput = typename ThreadEpilogueOp::ElementOutput;
-  using ElementC = typename ThreadEpilogueOp::ElementC;
-  using StrideC = StrideC_;
-  using ElementD = typename ThreadEpilogueOp::ElementD;
-  using StrideD = StrideD_;
-
-  using SmemLayout   = SmemLayout_;
-  using CopyAtomR2S  = CopyAtomR2S_;
-  using TiledCopyS2R = TiledCopyS2R_;
-  using CopyAtomR2G  = CopyAtomR2G_;
-
-  static const int kOutputAlignment = ThreadEpilogueOp::kCount;
-
-  using AlignmentType = typename cute::uint_bit<sizeof_bits<ElementOutput>::value * kOutputAlignment>::type;
-
-  static_assert(cute::rank(StrideC{}) == 3, "StrideCD must be rank-3: [M, N, L]");
-  static_assert(cute::rank(StrideD{}) == 3, "StrideCD must be rank-3: [M, N, L]");
-
-  struct SharedStorage
-  {
-    cute::array_aligned<ElementAccumulator, cute::cosize_v<SmemLayout>> smem_epilogue;
-  };
+  using ProblemShape = ProblemShape_;
+  static_assert(cute::rank(ProblemShape{}) == 3 or cute::rank(ProblemShape{}) == 4,
+    "ProblemShape{} should be <M,N,K> or <M,N,K,L>");
+  // Mainloop derived types
+  using CollectiveMainloop = CollectiveMainloop_;
+  using TileShape = typename CollectiveMainloop::TileShape;
+  using TiledMma  = typename CollectiveMainloop::TiledMma;
+  using ArchTag   = typename CollectiveMainloop::ArchTag;
+  using ElementA  = typename CollectiveMainloop::ElementA;
+  using StrideA   = typename CollectiveMainloop::StrideA;
+  using ElementB  = typename CollectiveMainloop::ElementB;
+  using StrideB   = typename CollectiveMainloop::StrideB;
+  using DispatchPolicy = typename CollectiveMainloop::DispatchPolicy;
+  using ElementAccumulator = typename CollectiveMainloop::ElementAccumulator;
+  using ClusterShape = typename DispatchPolicy::ClusterShape;
+  using MainloopArguments = typename CollectiveMainloop::Arguments;
+  using MainloopParams = typename CollectiveMainloop::Params;
+  static_assert(ArchTag::kMinComputeCapability >= 90);
+
+  // Epilogue derived types
+  using CollectiveEpilogue = CollectiveEpilogue_;
+  using ElementC = typename CollectiveEpilogue::ElementC;
+  using StrideC  = typename CollectiveEpilogue::StrideC;
+  using ElementD = typename CollectiveEpilogue::ElementD;
+  using StrideD  = typename CollectiveEpilogue::StrideD;
+  using EpilogueArguments = typename CollectiveEpilogue::Arguments;
+  using EpilogueParams = typename CollectiveEpilogue::Params;
+  static_assert(cute::is_same_v<ElementAccumulator, typename CollectiveEpilogue::ElementAccumulator>,
+    "Mainloop and epilogue do not agree on accumulator value type.");
+
+  static_assert(cute::is_void_v<TileScheduler_> or cute::is_same_v<TileScheduler_, PersistentScheduler>,
+    "TMA kernel does not support specializing the tile scheduler.");
+  using TileSchedulerTag = TileScheduler_;
+  using TileScheduler = typename detail::TileSchedulerSelector<
+    TileScheduler_, ArchTag, TileShape, ClusterShape>::Scheduler;
+  using TileSchedulerArguments = typename TileScheduler::Arguments;
+
+  static constexpr int SharedStorageSize = static_cast<int>(cute::max(
+      sizeof(typename CollectiveMainloop::SharedStorage),
+      sizeof(typename CollectiveEpilogue::SharedStorage)));
+
+  static constexpr uint32_t MaxThreadsPerBlock = CollectiveMainloop::ThreadCount;
 
-  // Host side epilogue arguments
+  static constexpr uint32_t MinBlocksPerMultiprocessor = 1;
+
+  // Device side arguments
   struct Arguments {
-    typename ThreadEpilogueOp::Params thread{};
-    ElementC const* ptr_C = nullptr;
-    StrideC dC{};
-    ElementD* ptr_D = nullptr;
-    StrideD dD{};
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopArguments mainloop{};
+    EpilogueArguments epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerArguments scheduler{};
   };
 
-  // Device side epilogue params
-  using Params = Arguments;
+  // Kernel entry point API
+  struct Params {
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+  };
 
   //
   // Methods
   //
 
-  template <class ProblemShape>
-  static constexpr Params
-  to_underlying_arguments(
-      [[maybe_unused]] ProblemShape const& _,
-      Arguments const& args,
-      [[maybe_unused]] void* workspace) {
-    return args;
+  // Convert to underlying arguments. In this case, a simple copy for the aliased type.
+  static
+  Params
+  to_underlying_arguments(Arguments const& args, void* workspace) {
+    (void) workspace;
+    auto problem_shape = args.problem_shape;
+    if constexpr (detail::IF_SWAP_AB<CollectiveMainloop>::value) {
+      // swap M/N
+      get<0>(problem_shape) = get<1>(args.problem_shape);
+      get<1>(problem_shape) = get<0>(args.problem_shape);
+    }
+    return {
+      args.mode,
+      problem_shape,
+      CollectiveMainloop::to_underlying_arguments(args.problem_shape, args.mainloop, workspace),
+      CollectiveEpilogue::to_underlying_arguments(args.problem_shape, args.epilogue, workspace)
+    };
+  }
+
+  CUTLASS_HOST_DEVICE static
+  bool
+  can_implement(Arguments const& args) {
+    bool implementable = (args.mode == GemmUniversalMode::kGemm) or
+        (args.mode == GemmUniversalMode::kBatched && cute::rank(ProblemShape{}) == 4);
+    if (!implementable) {
+      CUTLASS_TRACE_HOST("  CAN IMPLEMENT: Arguments or Problem Shape don't meet the requirements.\n");
+      return implementable;
+    }
+    implementable &= CollectiveMainloop::can_implement(args.problem_shape, args.mainloop);
+    implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
+    implementable &= TileScheduler::can_implement(args.scheduler);
+
+    return implementable;
   }
 
-  template <class ProblemShape>
   static size_t
-  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+  get_workspace_size(Arguments const& args) {
     return 0;
   }
 
-  template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
-    return cutlass::Status::kSuccess;
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
+    return Status::kSuccess;
   }
 
-  template <class ProblemShape>
-  CUTLASS_HOST_DEVICE static bool
-  can_implement(
-      [[maybe_unused]] ProblemShape const& problem_shape,
-      [[maybe_unused]] Arguments const& args) {
-    return true;
+  // Computes the kernel launch grid shape based on runtime parameters
+  static dim3
+  get_grid_shape(Params const& params) {
+    auto cluster_shape = ClusterShape{};
+    auto tile_shape = TileShape{};
+    auto problem_shape_MNKL = append<4>(params.problem_shape, Int<1>{});
+    return TileScheduler::get_tiled_cta_shape_mnl(
+        problem_shape_MNKL, tile_shape, cluster_shape);
   }
 
-  CUTLASS_HOST_DEVICE
-  Epilogue(Params const& params_)
-      : params(params_), epilogue_op(params_.thread) { }
-
-  CUTLASS_DEVICE
-  bool
-  is_source_needed() {
-    return epilogue_op.is_source_needed();
+  static dim3
+  get_block_shape() {
+    return dim3(MaxThreadsPerBlock, 1, 1);
   }
 
-  template<
-    class ProblemShapeMNKL,
-    class BlockShapeMNK,
-    class BlockCoordMNKL,
-    class FrgEngine, class FrgLayout,
-    class TiledMma,
-    class ResidueMNK
-  >
-  CUTLASS_DEVICE void
-  operator()(
-      ProblemShapeMNKL problem_shape_mnkl,
-      BlockShapeMNK blk_shape_MNK,
-      BlockCoordMNKL blk_coord_mnkl,
-      cute::Tensor<FrgEngine,FrgLayout> const& accumulators,                   // (MMA,MMA_M,MMA_N)
-      TiledMma tiled_mma,
-      ResidueMNK residue_mnk,
-      int thread_idx,
-      char* smem_buf)
-  {
+  CUTLASS_DEVICE
+  void
+  operator()(Params const& params, char* smem_buf) {
     using namespace cute;
     using X = Underscore;
 
-    static_assert(cute::rank(ProblemShapeMNKL{}) == 4, "ProblemShapeMNKL must be rank 4");
-    static_assert(is_static<BlockShapeMNK>::value, "ThreadBlock tile shape must be static");
-    static_assert(cute::rank(BlockShapeMNK{}) == 3, "BlockShapeMNK must be rank 3");
-    static_assert(cute::rank(BlockCoordMNKL{}) == 4, "BlockCoordMNKL must be rank 3");
-
-    // synchronizing function for smem reads/writes
-#if CUDA_BARRIER_ENABLED
-    auto synchronize = [] () { cutlass::arch::NamedBarrier::sync(typename TiledCopyS2R::TiledNumThr{}, cutlass::arch::ReservedNamedBarriers::EpilogueBarrier); };
+// Any Tensor Op MMA Atom in the WGMMA ISA is arch conditional to sm90a.
+#if ! defined(__CUDA_ARCH_FEAT_SM90_ALL)
+    printf("ERROR : Arch conditional MMA instruction used without targeting sm90a compute capability. Aborting.\n");
 #else
-    auto synchronize = [] () { __syncthreads(); };
-#endif
 
-    // Separate out problem shape for convenience
-    auto M = get<0>(problem_shape_mnkl);
-    auto N = get<1>(problem_shape_mnkl);
-    auto L = get<3>(problem_shape_mnkl);
-
-    // Represent the full output tensor
-    Tensor mC_mnl = make_tensor(make_gmem_ptr(params.ptr_C), make_shape(M,N,L), params.dC);      //             (m,n,l)
-    Tensor mD_mnl = make_tensor(make_gmem_ptr(params.ptr_D), make_shape(M,N,L), params.dD);      //             (m,n,l)
-    Tensor gC_mnl = local_tile(mC_mnl, blk_shape_MNK, make_coord(_,_,_), Step<_1,_1, X>{});      // (BLK_M,BLK_N,m,n,l)
-    Tensor gD_mnl = local_tile(mD_mnl, blk_shape_MNK, make_coord(_,_,_), Step<_1,_1, X>{});      // (BLK_M,BLK_N,m,n,l)
-
-    // Slice to get the tile this CTA is responsible for
-    auto [m_coord, n_coord, k_coord, l_coord] = blk_coord_mnkl;
-    Tensor gC = gC_mnl(_,_,m_coord,n_coord,l_coord);                                                   // (BLK_M,BLK_N)
-    Tensor gD = gD_mnl(_,_,m_coord,n_coord,l_coord);                                                   // (BLK_M,BLK_N)
-
-    // Construct a tensor in SMEM that we can partition for rearranging data
-    SharedStorage& storage = *reinterpret_cast<SharedStorage*>(smem_buf);
-    Tensor sC = make_tensor(make_smem_ptr(storage.smem_epilogue.data()), SmemLayout{});              // (SMEM_M,SMEM_N)
-
-    // Partition sC to match the accumulator partitioning
-    auto tiled_r2s = make_tiled_copy_C(CopyAtomR2S{}, tiled_mma);
-    auto tC     = tiled_r2s.get_thread_slice(thread_idx);
-    Tensor tCaC = tC.retile_S(accumulators);                                          // ((Atom,AtomNum), MMA_M, MMA_N)
-    Tensor tCsC = tC.partition_D(sC);                                                 // ((Atom,AtomNum),PIPE_M,PIPE_N)
-
-    // Tile gD and gC by the shape of SmemLayout first
-    auto tile  = make_shape(size<0>(sC), size<1>(sC));
-    Tensor gCt = flat_divide(gC, tile);                                                // (SMEM_M,SMEM_N,TILE_M,TILE_N)
-    Tensor gDt = flat_divide(gD, tile);                                                // (SMEM_M,SMEM_N,TILE_M,TILE_N)
-
-    // Partition sC, gC, and gD for the output
-    auto tiled_s2r = TiledCopyS2R{};
-    auto tD     = tiled_s2r.get_thread_slice(thread_idx);
-    Tensor tDsC = tD.partition_S(sC);                                   //               ((Atom,AtomNum),ATOM_M,ATOM_N)
-    Tensor tDgC = tD.partition_D(gCt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
-    Tensor tDgD = tD.partition_D(gDt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
-
-    // Allocate intermediate registers on the dst tensors
-    Tensor tDrC = make_tensor<ElementAccumulator>(take<0,3>(shape(tDgC)));            // ((Atom,AtomNum),ATOM_M,ATOM_N)
-    Tensor tDrD = make_tensor<ElementOutput>(shape(tDrC));                            // ((Atom,AtomNum),ATOM_M,ATOM_N)
-
-    // Repeat the D-partitioning for coordinates and predication
-    Tensor cD   = make_identity_tensor(make_shape(size<0>(gD),size<1>(gD)));          // (BLK_M,BLK_N) -> (blk_m,blk_n)
-    Tensor cDt  = flat_divide(cD, tile);                                //                (SMEM_M,SMEM_N,TILE_M,TILE_N)
-    Tensor tDcD = tD.partition_D(cDt);                                  // ((Atom,AtomNum),ATOM_M,ATOM_N,TILE_M,TILE_N)
-
-    CUTE_STATIC_ASSERT(size<1>(tCaC) % size<3>(tDgC) == 0);  // TILE_M divides MMA_M
-    CUTE_STATIC_ASSERT(size<2>(tCaC) % size<4>(tDgC) == 0);  // TILE_N divides MMA_N
-    CUTE_STATIC_ASSERT(typename TiledCopyS2R::TiledNumThr{} == size<0>(typename TiledMma::AtomLayoutC_TV{}));
-
-#if 0
-    if (thread_idx == 0 && m_coord == 0 && n_coord == 0) {
-      print("aC   : "); print(accumulators.layout()); print("\n");
-      print("gC   : "); print(gC.layout()); print("\n");
-      print("gD   : "); print(gD.layout()); print("\n");
-      print("sC   : "); print(sC.layout()); print("\n");
-      print("\n");
-      print("tCsC : "); print(tCsC.layout()); print("\n");
-      print("tCaC : "); print(tCaC.layout()); print("\n");
-      print("\n");
-      print("gDt  : "); print(gDt.layout()); print("\n");
-      print("tDsC : "); print(tDsC.layout()); print("\n");
-      print("tDrC : "); print(tDrC.layout()); print("\n");
-      print("\n");
-      print("tDrD : "); print(tDrD.layout()); print("\n");
-      print("tDgC : "); print(tDgC.layout()); print("\n");
-      print("tDgD : "); print(tDgD.layout()); print("\n");
-      print("\n");
+    // Preconditions
+    static_assert(cute::rank(StrideA{}) == 3, "StrideA must be rank-3: [M, K, L]. If batch mode is not needed, set L stride to Int<0>.");
+    static_assert(cute::rank(StrideB{}) == 3, "StrideB must be rank-3: [N, K, L]. If batch mode is not needed, set L stride to Int<0>.");
+    static_assert(cute::rank(StrideC{}) == 3, "StrideC must be rank-3: [M, N, L]. If batch mode is not needed, set L stride to Int<0>.");
+    static_assert(cute::rank(StrideD{}) == 3, "StrideD must be rank-3: [M, N, L]. If batch mode is not needed, set L stride to Int<0>.");
+
+    int thread_idx = int(threadIdx.x);
+    int warp_idx   = canonical_warp_idx_sync();
+    int lane_predicate = cute::elect_one_sync();
+    uint32_t block_rank_in_cluster = cute::block_rank_in_cluster();
+
+    // Issue Tma Descriptor Prefetch from a single thread
+    if ((warp_idx == 0) && lane_predicate) {
+      CollectiveMainloop::prefetch_tma_descriptors(params.mainloop);
     }
-#endif
 
-    // For each tiling needed for SmemLayout to cover shape(gD)
-    CUTLASS_PRAGMA_UNROLL
-    for (int step_m = 0; step_m < size<2>(cDt); ++step_m)
-    {
-      CUTLASS_PRAGMA_UNROLL
-      for (int step_n = 0; step_n < size<3>(cDt); ++step_n)
-      {
-        // Step 1. Copy to SMEM
-        CUTLASS_PRAGMA_UNROLL
-        for (int pipe_m = 0; pipe_m < size<1>(tCsC); ++pipe_m) {
-          CUTLASS_PRAGMA_UNROLL
-          for (int pipe_n = 0; pipe_n < size<2>(tCsC); ++pipe_n) {
-            int mma_m = step_m * size<1>(tCsC) + pipe_m;
-            int mma_n = step_n * size<2>(tCsC) + pipe_n;
-
-            copy(tiled_r2s, tCaC(_,mma_m,mma_n), tCsC(_,pipe_m,pipe_n));
-          }
-        }
-
-        // Step 2. Wait for SMEM writes to complete
-        synchronize();
-
-        // Step 3. Copy from SMEM into a fragment
-        copy(tiled_s2r, tDsC, tDrC);
-
-        // Step 4. Wait for SMEM reads to complete
-        synchronize();
-
-        Tensor tDgDmn = tDgD(_,_,_,step_m,step_n);
-        Tensor tDcDmn = tDcD(_,_,_,step_m,step_n);
-
-        if (epilogue_op.is_source_needed()) {
-          // source is needed
-          Tensor tDgCmn = tDgC(_,_,_,step_m,step_n);
-          CUTLASS_PRAGMA_UNROLL
-          for (int m = 0; m < size<1>(tDgDmn); ++m)
-          {
-            CUTLASS_PRAGMA_UNROLL
-            for (int n = 0; n < size<2>(tDgDmn); ++n)
-            {
-              // Predication
-              if (get<0>(tDcDmn(0,m,n)) < get<0>(residue_mnk) &&
-                  get<1>(tDcDmn(0,m,n)) < get<1>(residue_mnk))
-              {
-                // Step 5. Elementwise operation with conversion
-                CUTLASS_PRAGMA_UNROLL
-                for (int i = 0; i < size<0>(tDrC); ++i) {
-                  tDrD(i,m,n) = epilogue_op(tDrC(i,m,n), tDgCmn(i,m,n));
-                }
-                // Step 6. Copy to GMEM
-                copy(CopyAtomR2G{}, tDrD(_,m,n), tDgDmn(_,m,n));
-              }
-            }
-          }
-        }
-        else {
-          // source is not needed, avoid load and lift compute
-
-          // Step 5. Elementwise operation with conversion
-          CUTLASS_PRAGMA_UNROLL
-          for (int i = 0; i < size(tDrC); ++i) {
-            tDrD(i) = epilogue_op(tDrC(i));
-          }
-
-          CUTLASS_PRAGMA_UNROLL
-          for (int m = 0; m < size<1>(tDgDmn); ++m)
-          {
-            CUTLASS_PRAGMA_UNROLL
-            for (int n = 0; n < size<2>(tDgDmn); ++n)
-            {
-              // Predication
-              if (get<0>(tDcDmn(0,m,n)) < get<0>(residue_mnk) &&
-                  get<1>(tDcDmn(0,m,n)) < get<1>(residue_mnk))
-              {
-                // Step 6. Copy to GMEM
-                copy(CopyAtomR2G{}, tDrD(_,m,n), tDgDmn(_,m,n));
-              }
-            }
-          }
-        }
-      }
-    }
+    // Separate out problem shape for convenience
+    // Optionally append 1s until problem shape is rank-4 in case its is only rank-3 (MNK)
+    auto problem_shape_MNKL = append<4>(params.problem_shape, Int<1>{});
+    auto M = get<0>(problem_shape_MNKL);
+    auto N = get<1>(problem_shape_MNKL);
+    auto K = get<2>(problem_shape_MNKL);
+    auto L = get<3>(problem_shape_MNKL);
+
+    // TMA requires special handling of strides to deal with coord codomain mapping
+    // Represent the full tensors -- get these from TMA
+    Tensor mA_mkl = params.mainloop.tma_load_a.get_tma_tensor(make_shape(M,K,L));                            // (m,k,l)
+    Tensor mB_nkl = params.mainloop.tma_load_b.get_tma_tensor(make_shape(N,K,L));                            // (n,k,l)
+
+    // Get the appropriate blocks for this thread block -- potential for thread block locality
+    auto blk_shape = TileShape{};                                                                // (BLK_M,BLK_N,BLK_K)
+    auto blk_coord = make_coord(_,_,_);                                                   // (m,n,k) -- defer the slice
+
+    // Make tiled views
+    Tensor gA_mkl = local_tile(mA_mkl, blk_shape, blk_coord, Step<_1, X,_1>{});                  // (BLK_M,BLK_K,m,k,l)
+    Tensor gB_nkl = local_tile(mB_nkl, blk_shape, blk_coord, Step< X,_1,_1>{});                  // (BLK_N,BLK_K,n,k,l)
+
+    // Compute m_coord, n_coord, and l_coord with their post-tiled shapes
+    auto m_coord = idx2crd(int(blockIdx.x), shape<2>(gA_mkl));
+    auto n_coord = idx2crd(int(blockIdx.y), shape<2>(gB_nkl));
+    auto l_coord = idx2crd(int(blockIdx.z), shape<4>(gB_nkl));
+    auto output_tile_coord = make_coord(m_coord, n_coord, _, l_coord);
+
+    // Slice with m_coord and n_coord
+    Tensor gA = gA_mkl(_,_,m_coord,_,l_coord);                                                       // (BLK_M,BLK_K,k)
+    Tensor gB = gB_nkl(_,_,n_coord,_,l_coord);                                                       // (BLK_N,BLK_K,k)
+
+    // Allocate the tiled_mma and the accumulators for the (M,N) blk_shape
+    TiledMma tiled_mma;
+    Tensor accumulators = partition_fragment_C(tiled_mma, take<0,2>(blk_shape));                   // (MMA,MMA_M,MMA_N)
+
+    auto k_tile_iter  = cute::make_coord_iterator(shape<2>(gA));
+    auto k_tile_count = size<2>(gA);
+
+    // Perform the collective scoped MMA
+    CollectiveMainloop collective_mma;
+    collective_mma(
+      gA, params.mainloop.tma_load_a,
+      gB, params.mainloop.tma_load_b,
+      accumulators,
+      k_tile_iter, k_tile_count,
+      thread_idx,
+      block_rank_in_cluster,
+      smem_buf,
+      params.mainloop
+    );
+
+    constexpr int BLK_M_RANK = cute::rank<0>(blk_shape);
+    bool m_oob = int(blockIdx.x) >= size<2>(gA_mkl);
+    auto m_max_coord = unwrap(cute::transform(make_seq<BLK_M_RANK>{}, [&](auto i) {
+        return  m_oob ? 0 : get<i>(M) - get<0,i>(blk_shape) * get<i>(m_coord);
+      }));
+
+    constexpr int BLK_N_RANK = cute::rank<1>(blk_shape);
+    bool n_oob = int(blockIdx.y) >= size<2>(gB_nkl);
+    auto n_max_coord = unwrap(cute::transform(make_seq<BLK_N_RANK>{}, [&](auto i) {
+        return  n_oob ? 0 : get<i>(N) - get<1,i>(blk_shape) * get<i>(n_coord);
+      }));
+    auto residue_mnk = make_tuple(m_max_coord, n_max_coord, Int<0>{});
+
+    // Epilogue and write to gD
+    CollectiveEpilogue epilogue{params.epilogue};
+    epilogue(
+      problem_shape_MNKL,
+      blk_shape,
+      output_tile_coord,
+      accumulators,
+      tiled_mma,
+      residue_mnk,
+      thread_idx,
+      smem_buf
+    );
+#endif
   }
-
-private:
-  Params params;
-  ThreadEpilogueOp epilogue_op;
 };
 
+///////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-} // namespace collective
-} // namespace epilogue
-} // namespace cutlass
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+} // namespace cutlass::gemm::kernel
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -41,28 +41,30 @@
 #include "cutlass/epilogue/thread/scale_type.h"
 #include "cutlass/epilogue/fusion/callbacks.hpp"
 #include "cutlass/epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp"
 #include "cutlass/detail/layout.hpp"
 #include "cutlass/trace.h"
 
 #include "cute/tensor.hpp"
+#include "cutlass/cuda_host_adapter.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace collective {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   int StagesC_,
   int StagesD_,
   int FragmentSize_,
   bool ReuseSmemC_,
+  bool DelayTmaStore_,
   class CtaTileMNK_,   //     (CTA_M,CTA_N,CTA_K)
   class EpilogueTile_, // (EPI_TILE_M,EPI_TILE_N)
   class ElementC_,
   class StrideC_,
   class ElementD_,
   class StrideD_,
   class FusionCallbacks_,
@@ -70,15 +72,15 @@
   class SmemLayoutAtomC_,
   class CopyOpS2R_,
   class CopyOpS2G_,
   class SmemLayoutAtomD_,
   class CopyOpR2S_
 >
 class CollectiveEpilogue<
-    Sm90TmaWarpSpecialized<StagesC_,StagesD_,FragmentSize_,ReuseSmemC_>,
+    Sm90TmaWarpSpecialized<StagesC_,StagesD_,FragmentSize_,ReuseSmemC_,DelayTmaStore_>,
     CtaTileMNK_,
     EpilogueTile_,
     ElementC_,
     StrideC_,
     ElementD_,
     StrideD_,
     FusionCallbacks_,
@@ -89,15 +91,15 @@
     SmemLayoutAtomD_,
     CopyOpR2S_
 > {
 public:
   //
   // Type Aliases
   //
-  using DispatchPolicy = Sm90TmaWarpSpecialized<StagesC_,StagesD_,FragmentSize_,ReuseSmemC_>;
+  using DispatchPolicy = Sm90TmaWarpSpecialized<StagesC_,StagesD_,FragmentSize_,ReuseSmemC_,DelayTmaStore_>;
   using CtaTileMNK = CtaTileMNK_;
   using EpilogueTile = EpilogueTile_;
   using FusionCallbacks = FusionCallbacks_;
   using ElementC = ElementC_;
   using StrideC = StrideC_;
   using ElementD = ElementD_;
   using StrideD = StrideD_;
@@ -125,18 +127,22 @@
   constexpr static bool is_destination_supported = not cute::is_void_v<ElementD>;
   using SmemElementD = cute::conditional_t<not is_destination_supported,fusion::get_element_aux_t<FusionCallbacks>, ElementD>;
   static_assert(not cute::is_void_v<SmemElementD>, "SmemElementD is void");
   using SmemElementC = cute::conditional_t<not is_source_supported,SmemElementD,ElementC>; // prevents void ref breakages
   constexpr static int StagesC = StagesC_;
   constexpr static int StagesD = StagesD_;
   constexpr static bool ReuseSmemC = ReuseSmemC_ and is_destination_supported;
+  constexpr static bool DelayTmaStore = DelayTmaStore_;
 
   constexpr static bool is_m_major_C = detail::is_m_major<StrideC>();
   constexpr static bool is_m_major_D = detail::is_m_major<StrideD>();
 
+  constexpr static bool is_im2col_C = cute::is_same_v<CopyOpG2S, SM90_TMA_LOAD_IM2COL>;
+  constexpr static bool is_im2col_D = cute::is_same_v<CopyOpS2G, SM90_TMA_STORE_IM2COL>;
+
   using SmemLayoutC = decltype(tile_to_shape(
       SmemLayoutAtomC{},
       make_shape(size<0>(EpilogueTile{}), size<1>(EpilogueTile{}), Int<StagesC>{}),
       cute::conditional_t<is_m_major_C, Step<_2,_1,_3>, Step<_1,_2,_3>>{} ));
   using SmemLayoutD = decltype(tile_to_shape(
       SmemLayoutAtomD{},
       make_shape(size<0>(EpilogueTile{}), size<1>(EpilogueTile{}), Int<ReuseSmemC ? StagesC : StagesD>{}),
@@ -209,20 +215,24 @@
 
   // Device side epilogue params
   struct Params {
     using TMA_C = decltype(make_tma_copy(
         CopyOpG2S{},
         make_tensor(make_gmem_ptr(static_cast<SmemElementC const*>(nullptr)),
             repeat_like(StrideC{}, int32_t(0)), StrideC{}),
-        SmemLayoutC{}(_,_,0)));
+        take<0,2>(SmemLayoutC{}),
+        EpilogueTile{},
+        _1{}));
     using TMA_D = decltype(make_tma_copy(
         CopyOpS2G{},
         make_tensor(make_gmem_ptr(static_cast<SmemElementD const*>(nullptr)),
             repeat_like(StrideD{}, int32_t(0)), StrideD{}),
-        SmemLayoutD{}(_,_,0)));
+        take<0,2>(SmemLayoutD{}),
+        EpilogueTile{},
+        _1{}));
 
     typename FusionCallbacks::Params thread{};
     TMA_C tma_load_c;
     TMA_D tma_store_d;
   };
 
   //
@@ -234,31 +244,28 @@
   to_underlying_arguments(
       ProblemShape const& problem_shape,
       Arguments const& args,
       [[maybe_unused]] void* workspace) {
     // Optionally append 1s until problem shape is rank-4 in case its is only rank-3 (MNK)
     auto problem_shape_MNKL = append<4>(problem_shape, 1);
     auto [M, N, K, L] = problem_shape_MNKL;
-    auto M_C =
-        size(M)
-      ;
-    auto M_D =
-        size(M)
-      ;
+    // For fprop/dgrad kernel, problem shape M is multimodal which should be linearized under tiled mode
+    auto M_C = conditional_return<is_im2col_C>(M, size(M));
+    auto M_D = conditional_return<is_im2col_D>(M, size(M));
 
-    typename Params::TMA_C tma_load_c;
+    typename Params::TMA_C tma_load_c = {};
     if constexpr (is_source_supported) {
       Tensor tensor_c = make_tensor(make_gmem_ptr(args.ptr_C), make_layout(make_shape(M_C,N,L), args.dC));
-      tma_load_c = make_tma_copy(CopyOpG2S{}, tensor_c, SmemLayoutC{}(_,_,0));
+      tma_load_c = make_tma_copy(CopyOpG2S{}, tensor_c, take<0,2>(SmemLayoutC{}), EpilogueTile{}, _1{});
     }
 
     typename Params::TMA_D tma_store_d;
     if constexpr (is_destination_supported) {
       Tensor tensor_d = make_tensor(make_gmem_ptr(args.ptr_D), make_layout(make_shape(M_D,N,L), args.dD));
-      tma_store_d = make_tma_copy(CopyOpS2G{}, tensor_d, SmemLayoutD{}(_,_,0));
+      tma_store_d = make_tma_copy(CopyOpS2G{}, tensor_d, take<0,2>(SmemLayoutD{}), EpilogueTile{}, _1{});
     }
 
     return {
       FusionCallbacks::to_underlying_arguments(problem_shape, args.thread, workspace),
       tma_load_c,
       tma_store_d
     };
@@ -268,16 +275,17 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return FusionCallbacks::get_workspace_size(problem_shape, args.thread);
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
-    return FusionCallbacks::initialize_workspace(problem_shape, args.thread, workspace, stream);
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream, 
+    CudaHostAdapter* cuda_adapter = nullptr) {
+    return FusionCallbacks::initialize_workspace(problem_shape, args.thread, workspace, stream, cuda_adapter);
   }
 
   template <class ProblemShape>
   CUTLASS_HOST_DEVICE static bool
   can_implement(
       ProblemShape const& problem_shape,
       [[maybe_unused]] Arguments const& args) {
@@ -304,18 +312,15 @@
   }
 
   template<class TileShapeMNK>
   CUTLASS_HOST_DEVICE
   static constexpr int
   get_load_pipe_increment(TileShapeMNK tile_shape_MNK) {
     // Compute number of epilogue subtiles
-    constexpr int epi_m = size<0>(tile_shape_MNK) / size<0>(EpilogueTile{});
-    constexpr int epi_n = size<1>(tile_shape_MNK) / size<1>(EpilogueTile{});
-
-    return epi_m * epi_n;
+    return size<1>(zipped_divide(make_layout(take<0,2>(tile_shape_MNK)), EpilogueTile{}));
   }
 
   template<class TileShapeMNK>
   CUTLASS_HOST_DEVICE
   static constexpr int
   get_store_pipe_increment(TileShapeMNK tile_shape_MNK) {
     return get_load_pipe_increment(tile_shape_MNK);
@@ -362,26 +367,22 @@
       int subtile_idx=-1) {
     using namespace cute;
 
     // Indexing variables
     auto [M, N, K, L] = problem_shape_mnkl;
     auto [m_coord, n_coord, k_coord, l_coord] = tile_coord_mnkl;
 
-    auto coord_shape =
-        make_coord(m_coord, n_coord, l_coord)
-      ;
+    // The tma tensor C under im2col mode only has two modes (M, N) which
+    // should be local tiled with only (m_coord, n_coord).
+    auto coord_shape = conditional_return<is_im2col_C>(
+      make_coord(m_coord, n_coord),
+      make_coord(m_coord, n_coord, l_coord));
 
     // Tile residue
-    auto m_max_coord = unwrap(cute::transform(make_seq<rank<0>(tile_shape_MNK)>{}, [&](auto i) {
-      return get<0,i>(problem_shape_mnkl) - get<0,i>(tile_shape_MNK) * get<0,i>(tile_coord_mnkl);
-    }));
-    auto n_max_coord = unwrap(cute::transform(make_seq<rank<1>(tile_shape_MNK)>{}, [&](auto i) {
-      return get<1,i>(problem_shape_mnkl) - get<1,i>(tile_shape_MNK) * get<1,i>(tile_coord_mnkl);
-    }));
-    auto residue_mn = make_coord(m_max_coord, n_max_coord);
+    auto residue_mn = make_coord(M,N);
 
     // Represent the full source tensor, slice to get the tile this CTA is currently responsible for
     Tensor mC_mn = params.tma_load_c.get_tma_tensor(make_shape(M,N,L));                                //       (M,N,L)
     Tensor mC = coalesce(mC_mn, take<0,2>(CtaTileMNK{}));
     Tensor gC = local_tile(mC, take<0,2>(CtaTileMNK{}), coord_shape);                                  // (CTA_M,CTA_N)
 
     // Apply epilogue subtile, get matching smem tensor
@@ -507,17 +508,19 @@
     auto [M, N, K, L] = problem_shape_mnkl;
     auto [m_coord, n_coord, k_coord, l_coord] = tile_coord_mnkl;
     auto mma_tile_m = tile_size<0>(tiled_mma);
     auto mma_tile_n = tile_size<1>(tiled_mma);
     auto epi_tile_m = size<0>(EpilogueTile{});
     auto epi_tile_n = size<1>(EpilogueTile{});
 
-    auto coord_shape =
-        make_coord(m_coord, n_coord, l_coord)
-      ;
+    // The tma tensor D under im2col mode only has two modes (M, N) which
+    // should be local tiled with only (m_coord, n_coord).
+    auto coord_shape = conditional_return<is_im2col_D>( 
+        make_coord(m_coord, n_coord),
+        make_coord(m_coord, n_coord, l_coord));
 
     // Represent the full output tensor, slice to get the tile this CTA is responsible for
     Tensor mD_mn = params.tma_store_d.get_tma_tensor(make_shape(M,N,L));                               //       (M,N,L)
     Tensor mD = coalesce(mD_mn, take<0,2>(CtaTileMNK{}));
     Tensor gD = local_tile(mD, take<0,2>(CtaTileMNK{}), coord_shape);                                  // (CTA_M,CTA_N)
 
     // Apply epilogue subtiling
@@ -568,37 +571,30 @@
     ThrCopy thread_s2r = tiled_s2r.get_slice(thread_idx);
     Tensor tSR_sC        = thread_s2r.partition_S(sC_epi);                                  // (S2R,S2R_M,S2R_N,PIPE_C)
     Layout tSR_rC_layout = thread_s2r.retile_D(tRS_rD).layout();                            // (S2R,S2R_M,S2R_N)
 
     // Allocate C registers
     // If C smem load is a non-vectorized dst(i) = src(i) then we can allocate C registers directly in the compute type
     // to eliminate some redundant pack+unpack instruction sequences for sub-word types
-    constexpr bool IsDirectS2R = cute::is_same_v<CopyOpS2R,DefaultCopy>
+    constexpr bool IsDirectS2R = cute::is_same_v<CopyOpS2R, AutoVectorizingCopyWithAssumedAlignment<128>>
                                 && decltype(max_common_vector(tSR_rC_layout, tSR_sC.layout()))::value <= 1;
     using RegisterElementC = cute::conditional_t<IsDirectS2R, ElementCompute, SmemElementC>;
     Tensor tRS_rC = make_tensor<RegisterElementC>(tRS_rD_layout);                                  // (R2S,R2S_M,R2S_N)
     Tensor tSR_rC = thread_s2r.retile_D(tRS_rC);                                                   // (S2R,S2R_M,S2R_N)
 
     // thread(b)lock-partition for (s)mem to (g)mem copy (bSG_)
     ThrCopy thrblk_s2g = params.tma_store_d.get_slice(Int<0>{});
     Tensor bSG_sD = thrblk_s2g.partition_S(sD_epi);                                    // (S2G,S2G_M,S2G_N,PIPE_D)
     Tensor bSG_gD = thrblk_s2g.partition_D(gD_epi);                                    // (S2G,S2G_M,S2G_N,EPI_M,EPI_N)
 
-    // Coordinate tensors and residue for tile quantization
-    auto m_max_coord = unwrap(cute::transform(make_seq<rank<0>(CtaTileMNK{})>{}, [&](auto i) {
-      auto c_m = get<0,i>(problem_shape_mnkl) - get<0,i>(CtaTileMNK{}) * get<0,i>(tile_coord_mnkl);
-      return cute::max(0, c_m);
-    }));
-    auto n_max_coord = unwrap(cute::transform(make_seq<rank<1>(CtaTileMNK{})>{}, [&](auto i) {
-      auto c_n = get<1,i>(problem_shape_mnkl) - get<1,i>(CtaTileMNK{}) * get<1,i>(tile_coord_mnkl);
-      return cute::max(0, c_n);
-    }));
-    auto residue_mn = make_coord(m_max_coord, n_max_coord);
-    Tensor cD = make_identity_tensor(take<0,2>(CtaTileMNK{}));
+    // OOB predication for tile quantization "residue"
+    Tensor mD_crd = make_identity_tensor(make_shape(M,N));
+    Tensor cD = local_tile(mD_crd, take<0,2>(CtaTileMNK{}), make_coord(m_coord, n_coord));
     Tensor tRS_cD = thread_r2s.partition_S(flat_divide(cD, EpilogueTile{}));
+    auto residue_mn = make_coord(M,N);
 
     CUTE_STATIC_ASSERT(mma_tile_m == epi_tile_m, "EPI_TILE_M must equal MMA_TILE_M");
     CUTE_STATIC_ASSERT(mma_tile_n % epi_tile_n == 0, "EPI_TILE_N must divide MMA_TILE_N");
 
     // Get the fusion callbacks for the consumer store warps
     constexpr bool RefSrc = true; // Register tensors reference R2S copy src layout
     auto cst_args = cutlass::epilogue::fusion::detail::ConsumerStoreArgs{
@@ -630,26 +626,73 @@
     // store_pipe_producer_state tracks the acquire and load_pipe_consumer_state tracks the release, in circular buffer fashion.
     LoadPipelineState load_wait_state = load_pipe_consumer_state;
     if constexpr (ReuseSmemC) {
       load_wait_state = store_pipe_producer_state;
       load_wait_state.phase_ ^= 1;
     }
 
+    // We can delay issue of TMA store by one iteration to achieve better interleaving of non-TMA instructions
+    // Sync requirements of smem reuse may preclude this optimization
+    // Delayed stores cause delayed stage releases which causes deadlock when StagesC == StagesD
+    int epi_m_prev = 0, epi_n_prev = 0;
+    static_assert(not (DelayTmaStore and ReuseSmemC and StagesC == StagesD), "This TMA epilogue configuration will deadlock");
+
+    // The TMA store sequence for one subtile iteration
+    auto tma_store_fn = [&] (int epi_m, int epi_n) {
+      // Write the tile from smem to gmem with TMA
+      cutlass::arch::fence_view_async_shared(); // ensure smem writes are visible to TMA
+      synchronize(); // ensure all threads have issued their async fence
+      if constexpr (is_destination_supported) {
+        if (issue_tma_store) {
+          copy(params.tma_store_d, bSG_sD(_,_,_,store_pipe_producer_state.index()), bSG_gD(_,_,_,epi_m,epi_n));
+        }
+      }
+
+      // Post async fence, pre TMA commit callback entry point
+      cst_callbacks.tma_store(epi_m, epi_n, store_pipe_producer_state.count(), issue_tma_store);
+
+      // Commit the TMA stores for this stage
+      if (issue_tma_store) {
+        store_pipeline.producer_commit(store_pipe_producer_state);
+      }
+      ++store_pipe_producer_state;
+      ++issued_stores;
+
+      // Wait for the next smem buffer to be available
+      if (issue_tma_store) {
+        store_pipeline.producer_acquire(store_pipe_producer_state);
+      }
+      synchronize();
+
+      if constexpr (ReuseSmemC) {
+        // producer_acquire returns when at most StagesD-1 committed stores are pending
+        bool store_finished = issued_stores > StorePipeline::UnacquiredStages;
+        // Let dma warp know earliest smem buffer is consumed and empty after StagesD producer commits
+        if (store_finished) {
+          if (is_producer_load_needed) {
+            load_pipeline.consumer_release(load_pipe_consumer_state);
+          }
+          ++load_pipe_consumer_state;
+        }
+      }
+    };
+
     //
     // BEGIN EPILOGUE
     //
 
     // Pre-loop fusion callback entry point
     cst_callbacks.begin();
 
     // For each output tile
     CUTLASS_PRAGMA_UNROLL
     for (int epi_n = 0; epi_n < size<3>(gD_epi); ++epi_n) {
       CUTLASS_PRAGMA_UNROLL
       for (int epi_m = 0; epi_m < size<2>(gD_epi); ++epi_m) {
+        bool is_first_iteration = epi_m == 0 && epi_n == 0;
         bool is_last_iteration = epi_m == size<2>(gD_epi)-1 && epi_n == size<3>(gD_epi)-1;
 
         if (subtile_idx != -1 && (epi_n * static_cast<int>(size<2>(gD_epi)) + epi_m) != subtile_idx) {
           continue;
         }
         // The current tile in accumulator
         int mma_m = epi_m;
@@ -676,86 +719,57 @@
             load_pipeline.consumer_release(load_pipe_consumer_state);
             ++load_pipe_consumer_state;
           }
           ++load_wait_state;
         }
 
         // Vectorized fragment loop with visitor callback entry point
-        int r2s_v = epi_n * size(tRS_rD_frg);
+        int epi_n_in_mma = epi_n % (mma_tile_n / epi_tile_n);
+        int r2s_v = epi_n_in_mma * size(tRS_rD_frg);
         CUTLASS_PRAGMA_UNROLL
         for (int epi_v = 0; epi_v < size(tRS_rD_frg); ++epi_v) {
           tRS_rD_frg(epi_v) = cst_callbacks.visit(tRS_rAcc_frg_mn(r2s_v + epi_v), epi_v, epi_m, epi_n);
         }
 
-        // Copy tile from register to smem
-        if constexpr (is_destination_supported) {
-          copy(tiled_r2s, tRS_rD, tRS_sD(_,_,_,store_pipe_producer_state.index()));
-        }
-
-        // Post visit, pre async fence callback entry point
-        constexpr bool issue_smem_store = true; // No smem store predication
-        cst_callbacks.postvisit(epi_m, epi_n, store_pipe_producer_state.count(), issue_smem_store);
-
-        // Write the tile from smem to gmem with TMA
-        cutlass::arch::fence_view_async_shared(); // ensure smem writes are visible to TMA
-        synchronize(); // ensure all threads have issued their async fence
-        if constexpr (is_destination_supported) {
-          if (issue_tma_store) {
-            copy(params.tma_store_d, bSG_sD(_,_,_,store_pipe_producer_state.index()), bSG_gD(_,_,_,epi_m,epi_n));
+        // The latest we can delay the TMA store is right before the smem store of the next iteration
+        // since the current TMA store needs to be committed before we can acquire the next smem buffer
+        if constexpr (DelayTmaStore) {
+          // Issue TMA stores for the previous subtile
+          if (not is_first_iteration and subtile_idx == -1) {
+            tma_store_fn(epi_m_prev, epi_n_prev);
           }
+          epi_m_prev = epi_m;
+          epi_n_prev = epi_n;
         }
 
-        // Post async fence, pre TMA commit callback entry point
-        cst_callbacks.step(epi_m, epi_n, store_pipe_producer_state.count(), issue_tma_store);
+        // Smem reduction callback entry point using current store buffer for workspace
+        cst_callbacks.reduce(sD_epi(_,_,store_pipe_producer_state.index()),
+                              synchronize, epi_m, epi_n, is_last_iteration);
 
-        // Commit the TMA stores for this stage
-        if (issue_tma_store) {
-          store_pipeline.producer_commit(store_pipe_producer_state);
-        }
-        ++store_pipe_producer_state;
-        ++issued_stores;
-
-        // Wait for the next smem buffer to be available
-        if (issue_tma_store) {
-          store_pipeline.producer_acquire(store_pipe_producer_state);
+        // Copy tile from register to smem
+        if constexpr (is_destination_supported) {
+          copy(tiled_r2s, tRS_rD, tRS_sD(_,_,_,store_pipe_producer_state.index()));
         }
-        synchronize();
 
-        if constexpr (ReuseSmemC) {
-          // producer_acquire returns when at most StagesD-1 committed stores are pending
-          bool store_finished = issued_stores > StorePipeline::UnacquiredStages;
-
-          // Free an smem buffer for reduction if necessary
-          if (cst_callbacks.is_reduction_buffer_needed(epi_m, epi_n, is_last_iteration) && not store_finished) {
-            if (issue_tma_store) {
-              store_pipeline.producer_tail(store_pipe_producer_state); // wait for all TMA stores to finish
-            }
-            synchronize();
-          }
+        // Post reduction, pre TMA store callback entry point
+        constexpr bool issue_smem_store = true; // No smem store predication
+        cst_callbacks.postreduce(epi_m, epi_n, store_pipe_producer_state.count(), issue_smem_store);
 
-          // Smem reduction callback entry point using least recently acquired load buffer for workspace
-          cst_callbacks.reduce(sC_epi(_,_,load_pipe_consumer_state.index()),
-                               synchronize, epi_m, epi_n, is_last_iteration);
-
-          // Let dma warp know earliest smem buffer is consumed and empty after StagesD producer commits
-          if (store_finished) {
-            if (is_producer_load_needed) {
-              load_pipeline.consumer_release(load_pipe_consumer_state);
-            }
-            ++load_pipe_consumer_state;
-          }
-        }
-        else {
-          // Smem reduction callback entry point using most recently acquired store buffer for workspace
-          cst_callbacks.reduce(sD_epi(_,_,store_pipe_producer_state.index()),
-                               synchronize, epi_m, epi_n, is_last_iteration);
+        if constexpr (not DelayTmaStore) {
+          // Issue TMA stores for this subtile
+          tma_store_fn(epi_m, epi_n);
         }
       } // for epi_m
     } // for epi_n
 
+    if constexpr (DelayTmaStore) {
+      // Issue TMA stores for the last subtile
+      tma_store_fn(epi_m_prev, epi_n_prev);
+    }
+
     // Post-loop fusion callback entry point
     cst_callbacks.end();
 
     return cute::make_tuple(load_pipe_consumer_state, store_pipe_producer_state);
   }
 
   CUTLASS_DEVICE auto
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized_bias_elementwise.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/collective/sm90_epilogue_tma_warpspecialized_bias_elementwise.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -61,15 +61,15 @@
   class CopyOpS2R_,
   class CopyOpS2G_,
   class SmemLayoutAtomD_,
   class CopyOpR2S_
 >
 class Sm90EpilogueTmaWarpSpecializedBiasElementwise
   : public CollectiveEpilogue<
-      Sm90TmaWarpSpecialized<StagesC_, StagesD_, FragmentSize_, false>,
+      Sm90TmaWarpSpecialized<StagesC_, StagesD_, FragmentSize_, false, false>,
       BlockTileShape_,
       EpilogueTileShape_,
       ElementC_,
       StrideC_,
       ElementD_,
       StrideD_,
       FusionCallbacks_,
@@ -79,15 +79,15 @@
       CopyOpS2G_,
       SmemLayoutAtomD_,
       CopyOpR2S_
 > {
 private:
   using Impl =
     CollectiveEpilogue<
-      Sm90TmaWarpSpecialized<StagesC_, StagesD_, FragmentSize_, false>,
+      Sm90TmaWarpSpecialized<StagesC_, StagesD_, FragmentSize_, false, false>,
       BlockTileShape_,
       EpilogueTileShape_,
       ElementC_,
       StrideC_,
       ElementD_,
       StrideD_,
       FusionCallbacks_,
@@ -107,25 +107,25 @@
   // Constructor inheritance
   using Impl::Impl;
 
   // Host side epilogue arguments
   struct [[deprecated("use Sm90TmaWarpSpecialized Arguments instead")]]
   Arguments {
     struct ThreadArgs {
-      ElementCompute alpha;
-      ElementCompute beta;
-      ElementCompute const *alpha_ptr;
-      ElementCompute const *beta_ptr;
+      ElementCompute alpha{1};
+      ElementCompute beta{0};
+      ElementCompute const *alpha_ptr{nullptr};
+      ElementCompute const *beta_ptr{nullptr};
     } thread;
-    ElementC_ const* ptr_C;
-    StrideC_ dC;
-    ElementD_* ptr_D;
-    StrideD_ dD;
-    ElementBias const* ptr_Bias = nullptr;
-    ElementT* ptr_T = nullptr;
+    ElementC_ const* ptr_C{nullptr};
+    StrideC_ dC{};
+    ElementD_* ptr_D{nullptr};
+    StrideD_ dD{};
+    ElementBias const* ptr_Bias{nullptr};
+    ElementT* ptr_T{nullptr};
 
     CUTLASS_HOST_DEVICE
     operator typename Impl::Arguments() const {
       typename Impl::Arguments arguments;
       arguments.thread.alpha = thread.alpha;
       arguments.thread.beta = thread.beta;
       arguments.thread.alpha_ptr = thread.alpha_ptr;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -128,21 +128,23 @@
 //
 //////////////////////////////////////////////////////////////////////////////
 
 template<
   int StagesC_,
   int StagesD_,
   int FragmentSize_,
-  bool ReuseSmemC_
+  bool ReuseSmemC_,
+  bool DelayTmaStore_
 >
 struct Sm90TmaWarpSpecialized {
   constexpr static int StagesC = StagesC_;
   constexpr static int StagesD = StagesD_;
   constexpr static int FragmentSize = FragmentSize_;
   constexpr static bool ReuseSmemC = ReuseSmemC_;
+  constexpr static bool DelayTmaStore = DelayTmaStore_;
 };
 
 
 // DEPRECATED policies, will be removed in next release
 template<
   int StagesC_,
   int StagesD_,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/callbacks.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/callbacks.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/operations.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/operations.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -118,14 +118,15 @@
 >
 struct LinCombEltAct
     : LinearCombination<ElementOutput_, ElementCompute_, ElementSource_, ElementScalar_, RoundStyle_> {
   using ActivationFn = ActivationFn_<ElementCompute_>;
   static constexpr bool IsEltActSupported = true;
 };
 
+
 // D = alpha * acc + beta * C + per-row bias
 template<
   class ElementOutput_,
   class ElementCompute_,
   class ElementBias_ = ElementOutput_,
   class ElementSource_ = ElementOutput_,
   class ElementScalar_ = ElementCompute_,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -57,23 +57,24 @@
 
 // D = alpha * acc
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class ElementOutput,
   class ElementCompute,
   class ElementScalar,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::ScaledAcc<ElementOutput, ElementCompute, ElementScalar, RoundStyle>,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90EVT<Sm90Compute<multiplies, ElementOutput, ElementCompute, RoundStyle>,
       Sm90ScalarBroadcast<ElementScalar>,
       Sm90AccFetch
     > {
@@ -128,24 +129,25 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class ElementOutput,
   class ElementCompute,
   class ElementSource,
   class ElementScalar,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinearCombination<ElementOutput, ElementCompute, ElementSource, ElementScalar, RoundStyle>,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90LinearCombination<typename cutlass::detail::get_unpacked_element_type<ElementOutput>::type, ElementCompute, ElementSource, ElementScalar, RoundStyle> {
 
   using Impl = Sm90LinearCombination<typename cutlass::detail::get_unpacked_element_type<ElementOutput>::type, ElementCompute, ElementSource, ElementScalar, RoundStyle>;
   using Operation = fusion::LinearCombination<ElementOutput, ElementCompute, ElementSource, ElementScalar, RoundStyle>;
@@ -192,25 +194,26 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementSource,
   class ElementScalar,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombEltAct<ActivationFn, ElementOutput, ElementCompute, ElementSource, ElementScalar, RoundStyle>,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90LinCombEltAct<ActivationFn, ElementOutput, ElementCompute, ElementSource, ElementScalar, RoundStyle> {
 
   using Impl = Sm90LinCombEltAct<ActivationFn, typename cutlass::detail::get_unpacked_element_type<ElementOutput>::type, ElementCompute, ElementSource, ElementScalar, RoundStyle>;
   using Operation = fusion::LinCombEltAct<ActivationFn, ElementOutput, ElementCompute, ElementSource, ElementScalar, RoundStyle>;
@@ -271,26 +274,27 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class ElementOutput,
   class ElementCompute,
   class ElementBias,
   class ElementSource,
   class ElementScalar,
   int AlignmentBias,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombPerRowBias<ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle>,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90LinCombPerRowBias<
       CtaTileShapeMNK, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle> {
   using Impl = Sm90LinCombPerRowBias<
     CtaTileShapeMNK, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle>;
@@ -347,27 +351,28 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementBias,
   class ElementSource,
   class ElementScalar,
   int AlignmentBias,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombPerRowBiasEltAct<
       ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90LinCombPerRowBiasEltAct<
       CtaTileShapeMNK, ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle
@@ -448,14 +453,15 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class GmemLayoutTagAux,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementAux,
   class ElementBias,
   class ElementSource,
@@ -465,15 +471,15 @@
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile,
   class SmemLayoutAtom,
   class CopyOpR2S
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombPerRowBiasEltActAux<
       GmemLayoutTagAux, ActivationFn, ElementOutput, ElementCompute,
       ElementAux, ElementBias, ElementSource, ElementScalar, AlignmentAux, AlignmentBias, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile,
     SmemLayoutAtom,
@@ -549,18 +555,18 @@
   class ElementScalar = ElementCompute,
   int AlignmentBias = 128 / sizeof_bits_v<ElementBias>,
   int AlignmentScalar = 128 / sizeof_bits_v<ElementScalar>,
   FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
 >
 using Sm90PerRowLinCombPerRowBias =
   Sm90EVT<Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>, // beta * C + (alpha * acc + bias)
-    Sm90ColBroadcast<0, CtaTileShapeMNK, ElementScalar, Stride<_1,_0,_0>, AlignmentScalar>, // beta
+    Sm90ColBroadcast<0, CtaTileShapeMNK, ElementScalar, Stride<_1,_0,int>, AlignmentScalar>, // beta
     Sm90SrcFetch<ElementSource>, // C
     Sm90EVT<Sm90Compute<homogeneous_multiply_add, ElementCompute, ElementCompute, RoundStyle>, // alpha * acc + bias
-      Sm90ColBroadcast<0, CtaTileShapeMNK, ElementScalar, Stride<_1,_0,_0>, AlignmentScalar>, // alpha
+      Sm90ColBroadcast<0, CtaTileShapeMNK, ElementScalar, Stride<_1,_0,int>, AlignmentScalar>, // alpha
       Sm90AccFetch, // acc
       Sm90ColBroadcast<0, CtaTileShapeMNK, ElementBias, Stride<_1,_0,int>, AlignmentBias> // bias
     >
   >;
 
 // D = activation(per-row alpha * acc + per-row beta * C + per-row bias)
 template<
@@ -582,28 +588,29 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementBias,
   class ElementSource,
   class ElementScalar,
   int AlignmentBias,
   int AlignmentScalar,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::PerRowLinCombPerRowBiasEltAct<
       ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, AlignmentScalar, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90PerRowLinCombPerRowBiasEltAct<
       CtaTileShapeMNK, ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, AlignmentScalar, RoundStyle
@@ -615,38 +622,42 @@
     >;
   using Operation =
     fusion::PerRowLinCombPerRowBiasEltAct<
       ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, AlignmentScalar, RoundStyle
     >;
 
   struct Arguments {
+    using StrideAlpha = Stride<_1,_0,int>;
+    using StrideBeta  = Stride<_1,_0,int>;
     ElementScalar alpha = ElementScalar(1);
     ElementScalar beta = ElementScalar(0);
     ElementScalar const* alpha_ptr = nullptr;
     ElementScalar const* beta_ptr = nullptr;
+    StrideAlpha dAlpha = {};
+    StrideBeta  dBeta  = {};
 
     using StrideBias = Stride<_1,_0,int>;
     ElementBias const* bias_ptr = nullptr;
     StrideBias dBias = {};
 
     using ActivationArguments = typename Sm90Compute<ActivationFn, ElementOutput, ElementCompute, RoundStyle>::Arguments;
     ActivationArguments activation = ActivationArguments();
 
     operator typename Impl::Arguments() const {
       return
         {    // unary op : activation(beta * C + (alpha * acc + bias))
           {    // ternary op : beta * C + (alpha * acc + bias)
-            {beta_ptr, beta}, // leaf args : beta
-            {},               // leaf args : C
-            {                 // ternary op : alpha * acc + bias
-              {alpha_ptr, alpha},   // leaf args : alpha
-              {},                   // leaf args : acc
+            {beta_ptr, beta, dBeta}, // leaf args : beta
+            {},                      // leaf args : C
+            {                        // ternary op : alpha * acc + bias
+              {alpha_ptr, alpha, dAlpha}, // leaf args : alpha
+              {},                         // leaf args : acc
               {bias_ptr, ElementBias(0), dBias}, // leaf args : bias
-              {}              // ternary args : multiply_add
-            },                // end ternary op
+              {}                     // ternary args : multiply_add
+            },                       // end ternary op
             {} // ternary args : multiply_add
           },   // end ternary op
           activation // unary args : activation
         };   // end unary op
     }
   };
 
@@ -654,14 +665,17 @@
   using Impl::Impl;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace detail {
 
+template <typename T>
+constexpr bool is_fp8_v = cute::is_same_v<T,float_e4m3_t> || cute::is_same_v<T,float_e5m2_t>;
+
 // We only apply the scaling factor if output is fp8
 template <typename ElementOutput>
 struct ScaleOutOp { template <typename T> using Op = cutlass::first<T>; };
 template <>
 struct ScaleOutOp<float_e4m3_t> { template <typename T> using Op = cutlass::multiplies<T>; };
 template <>
 struct ScaleOutOp<float_e5m2_t> { template <typename T> using Op = cutlass::multiplies<T>; };
@@ -719,27 +733,28 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementBias,
   class ElementSource,
   class ElementScalar,
   int AlignmentBias,
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::ScaledLinCombPerRowBiasEltAct<
       ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile
 > : Sm90ScaledLinCombPerRowBiasEltAct<
       CtaTileShapeMNK, ActivationFn, ElementOutput, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle
@@ -818,14 +833,16 @@
 // else
 //   D = activation(Z)
 // if Aux is fp8 
 //   amax_aux = max(abs(elements in Z))
 //   Aux = scale_aux * Z
 // else
 //   Aux = Z
+
+// fp8 aux specialization
 template<
   class CtaTileShapeMNK,
   class EpilogueTile,
   int StagesD,
   class StrideAux,
   class SmemLayoutAtom,
   class CopyOpR2S,
@@ -837,43 +854,111 @@
   class ElementBias = ElementOutput,
   class ElementSource = ElementOutput,
   class ElementScalar = ElementCompute,
   int AlignmentAux = 128 / sizeof_bits_v<ElementAux>,
   int AlignmentBias = 128 / sizeof_bits_v<ElementBias>,
   FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
 >
-using Sm90ScaledLinCombPerRowBiasEltActAmaxAux =
+using Sm90ScaledLinCombPerRowBiasEltActAmaxAuxFp8 =
   Sm90SplitTreeVisitor<
     // Z = scale_a * scale_b * alpha * acc + scale_c * beta * C + per-row bias
     Sm90ScaledLinCombPerRowBias<CtaTileShapeMNK, ElementCompute, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle>,
     // D = activation(Z) * scale_d, amax_d = max(abs(elements in D))
     Sm90EVT<Sm90Compute<detail::ScaleOutOp<ElementOutput>::template Op, ElementOutput, ElementCompute, RoundStyle>, // activation(Z) * scale_d
       Sm90EVT<Sm90ScalarReduction<detail::amax, atomic_maximum, ElementAmax, ElementCompute, RoundStyle>, // amax_d
         Sm90EVT<Sm90Compute<ActivationFn, ElementCompute, ElementCompute, RoundStyle>, // activation(Z)
           Sm90SplitTreeFetch // Z
         >
       >,
       Sm90ScalarBroadcast<ElementScalar> // scale_d
     >,
     // Aux = Z * scale_aux, amax_aux = max(abs(elements in Aux))
     Sm90EVT<Sm90AuxStore<StagesD, EpilogueTile, ElementAux, RoundStyle, StrideAux, SmemLayoutAtom, CopyOpR2S, AlignmentAux>, // store(Aux)
-      Sm90EVT<Sm90Compute<detail::ScaleOutOp<ElementAux>::template Op, ElementCompute, ElementCompute, RoundStyle>, // Z * scale_aux
+      Sm90EVT<Sm90Compute<cutlass::multiplies, ElementCompute, ElementCompute, RoundStyle>, // Z * scale_aux
         Sm90EVT<Sm90ScalarReduction<detail::amax, atomic_maximum, ElementAmax, ElementCompute, RoundStyle>, // amax_aux
           Sm90SplitTreeFetch // Z
         >,
         Sm90ScalarBroadcast<ElementScalar> // scale_aux
       >
     >
   >;
 
+// non-fp8 aux specialization
+// lets us use some EVT specializations such as relu + uint1b_t aux
+template<
+  class CtaTileShapeMNK,
+  class EpilogueTile,
+  int StagesD,
+  class StrideAux,
+  class SmemLayoutAtom,
+  class CopyOpR2S,
+  template <class> class ActivationFn,
+  class ElementOutput,
+  class ElementCompute,
+  class ElementAux = ElementOutput,
+  class ElementAmax = ElementCompute,
+  class ElementBias = ElementOutput,
+  class ElementSource = ElementOutput,
+  class ElementScalar = ElementCompute,
+  int AlignmentAux = 128 / sizeof_bits_v<ElementAux>,
+  int AlignmentBias = 128 / sizeof_bits_v<ElementBias>,
+  FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
+>
+using Sm90ScaledLinCombPerRowBiasEltActAmaxAuxNotFp8 =
+  // D = activation(Z) * scale_d, amax_d = max(abs(elements in D))
+  Sm90EVT<Sm90Compute<detail::ScaleOutOp<ElementOutput>::template Op, ElementOutput, ElementCompute, RoundStyle>, // activation(Z) * scale_d
+    Sm90EVT<Sm90ScalarReduction<detail::amax, atomic_maximum, ElementAmax, ElementCompute, RoundStyle>, // amax_d
+      Sm90EVT<Sm90Compute<ActivationFn, ElementCompute, ElementCompute, RoundStyle>, // activation(Z)
+        Sm90EVT<Sm90AuxStore<StagesD, EpilogueTile, ElementAux, RoundStyle, StrideAux, SmemLayoutAtom, CopyOpR2S, AlignmentAux>, // Aux = Z
+          // Z = scale_a * scale_b * alpha * acc + scale_c * beta * C + per-row bias
+          Sm90ScaledLinCombPerRowBias<CtaTileShapeMNK, ElementCompute, ElementCompute, ElementBias, ElementSource, ElementScalar, AlignmentBias, RoundStyle>,
+        >
+      >
+    >,
+    Sm90ScalarBroadcast<ElementScalar> // scale_d
+  >;
+
+// dispatcher
+template<
+  class CtaTileShapeMNK,
+  class EpilogueTile,
+  int StagesD,
+  class StrideAux,
+  class SmemLayoutAtom,
+  class CopyOpR2S,
+  template <class> class ActivationFn,
+  class ElementOutput,
+  class ElementCompute,
+  class ElementAux = ElementOutput,
+  class ElementAmax = ElementCompute,
+  class ElementBias = ElementOutput,
+  class ElementSource = ElementOutput,
+  class ElementScalar = ElementCompute,
+  int AlignmentAux = 128 / sizeof_bits_v<ElementAux>,
+  int AlignmentBias = 128 / sizeof_bits_v<ElementBias>,
+  FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
+>
+using Sm90ScaledLinCombPerRowBiasEltActAmaxAux = conditional_t<detail::is_fp8_v<ElementAux>,
+  Sm90ScaledLinCombPerRowBiasEltActAmaxAuxFp8<
+    CtaTileShapeMNK, EpilogueTile, StagesD, StrideAux, SmemLayoutAtom, CopyOpR2S, ActivationFn,
+    ElementOutput, ElementCompute, ElementAux, ElementAmax, ElementBias, ElementSource, ElementScalar,AlignmentAux, AlignmentBias, RoundStyle
+  >,
+  Sm90ScaledLinCombPerRowBiasEltActAmaxAuxNotFp8<
+    CtaTileShapeMNK, EpilogueTile, StagesD, StrideAux, SmemLayoutAtom, CopyOpR2S, ActivationFn,
+    ElementOutput, ElementCompute, ElementAux, ElementAmax, ElementBias, ElementSource, ElementScalar, AlignmentAux, AlignmentBias, RoundStyle
+  >
+>;
+
+
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class GmemLayoutTagAux,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementAux,
   class ElementAmax,
   class ElementBias,
@@ -884,15 +969,15 @@
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile,
   class SmemLayoutAtom,
   class CopyOpR2S
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::ScaledLinCombPerRowBiasEltActAmaxAux<
       GmemLayoutTagAux, ActivationFn, ElementOutput, ElementCompute,
       ElementAux, ElementAmax, ElementBias, ElementSource, ElementScalar, AlignmentAux, AlignmentBias, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile,
     SmemLayoutAtom,
@@ -944,78 +1029,109 @@
     ElementAmax* amax_aux_ptr = nullptr;
 
     using StrideAux = cutlass::gemm::TagToStrideC_t<GmemLayoutTagAux>;
     ElementAux* aux_ptr = nullptr;
     StrideAux dAux = {};
 
     operator typename Impl::Arguments() const {
-      typename Impl::Arguments args;
-      // always use structured binding to unpack DAG args since it may or may not be a tuple
-      auto& [Z_args, aux_args, D_args] = args;
-
-      Z_args =
-        {    // ternary op : (scale_c * beta) * C + ((scale_a * scale_b * alpha) * acc + bias)
-          {{scale_c, beta},
-           {scale_c_ptr, beta_ptr}
-           },  // leaf args : (scale_c * beta)
-          {},  // leaf args : C
-          {    // ternary op : (scale_a * scale_b * alpha) * acc + bias
-            {{scale_a, scale_b, alpha}, 
-             {scale_a_ptr, scale_b_ptr, alpha_ptr}
-             },                   // leaf args : (scale_a * scale_b * alpha)
-            {},                   // leaf args : acc
-            {bias_ptr, ElementBias(0), dBias}, // leaf args : bias
-            {} // ternary args : multiply_add
-          },   // end ternary op
-          {} // ternary args : multiply_add
-        };   // end ternary op
-
       // Only compute amax_d if D is fp8
       ElementAmax* amax_D_ptr_ = nullptr;
-      if constexpr (cute::is_same_v<ElementOutput, float_e4m3_t> ||
-                    cute::is_same_v<ElementOutput, float_e5m2_t>) {
+      if constexpr (detail::is_fp8_v<ElementOutput>) {
         amax_D_ptr_ = amax_D_ptr;
       }
-      D_args =
-        {    // binary op : activation(Z) * scale_d or activation(Z)
-          {    // unary op : reduce(activation(Z))
-            {             // unary op : activation(Z)
-              {},             // leaf args : Z
-              activation      // unary args : activation
-            },                // end unary op
-            {amax_D_ptr_} // unary args : reduce
-          },              // end unary op
-          {{scale_d},
-           {scale_d_ptr}
-           },  // leaf args : scale_d
-          {} // binary args : multiplies or first
-        };   // end binary op
 
-      // Only compute amax_aux if aux is fp8
-      ElementAmax* amax_aux_ptr_ = nullptr;
-      if constexpr (cute::is_same_v<ElementAux, float_e4m3_t> ||
-                    cute::is_same_v<ElementAux, float_e5m2_t>) {
-        amax_aux_ptr_ = amax_aux_ptr;
-      }
-      aux_args =
-        {    // unary op : store(Aux)
-          {    // binary op : Z * scale_d or Z
-            {    // unary op : reduce(Z)
-              {},             // leaf args : Z
-              {amax_aux_ptr_} // unary args : reduce
-            },   // end unary op
-            {{scale_aux},
-             {scale_aux_ptr}
+      // Aux is fp8 -> DAG arguments
+      if constexpr (detail::is_fp8_v<ElementAux>) {
+        typename Impl::Arguments args;
+        // always use structured binding to unpack DAG args since it may or may not be a tuple
+        auto& [Z_args, aux_args, D_args] = args;
+
+        Z_args =
+          {    // ternary op : (scale_c * beta) * C + ((scale_a * scale_b * alpha) * acc + bias)
+            {{scale_c, beta},
+             {scale_c_ptr, beta_ptr}
+             },  // leaf args : (scale_c * beta)
+            {},  // leaf args : C
+            {    // ternary op : (scale_a * scale_b * alpha) * acc + bias
+              {{scale_a, scale_b, alpha}, 
+               {scale_a_ptr, scale_b_ptr, alpha_ptr}
+               },                   // leaf args : (scale_a * scale_b * alpha)
+              {},                   // leaf args : acc
+              {bias_ptr, ElementBias(0), dBias}, // leaf args : bias
+              {} // ternary args : multiply_add
+            },   // end ternary op
+            {} // ternary args : multiply_add
+          };   // end ternary op
+
+        D_args =
+          {    // binary op : activation(Z) * scale_d or activation(Z)
+            {    // unary op : reduce(activation(Z))
+              {             // unary op : activation(Z)
+                {},             // leaf args : Z
+                activation      // unary args : activation
+              },                // end unary op
+              {amax_D_ptr_} // unary args : reduce
+            },              // end unary op
+            {{scale_d},
+             {scale_d_ptr}
              },  // leaf args : scale_d
             {} // binary args : multiplies or first
-          },   // end binary op
-          {aux_ptr, dAux} // unary args : store
-        };   // end unary op
+          };   // end binary op
+
+        aux_args =
+          {    // unary op : store(Aux)
+            {    // binary op : Z * scale_d or Z
+              {    // unary op : reduce(Z)
+                {},            // leaf args : Z
+                {amax_aux_ptr} // unary args : reduce
+              },   // end unary op
+              {{scale_aux},
+               {scale_aux_ptr}
+               },  // leaf args : scale_d
+              {} // binary args : multiplies
+            },   // end binary op
+            {aux_ptr, dAux} // unary args : store
+          };   // end unary op
 
-      return args;
+        return args;
+      }
+
+      // Aux is not fp8 -> Tree arguments
+      else {
+        return
+          {  // binary op : activation(Z) * scale_d or activation(Z)
+            {  // unary op : reduce(activation(Z))
+              {  // unary op : activation(Z)
+                {  // unary op : store(Z)
+                  {  // ternary op : (scale_c * beta) * C + ((scale_a * scale_b * alpha) * acc + bias)
+                    {{scale_c, beta},
+                     {scale_c_ptr, beta_ptr}
+                    },                // leaf args : (scale_c * beta)
+                    {},               // leaf args : C
+                    {                 // ternary op : (scale_a * scale_b * alpha) * acc + bias
+                      {{scale_a, scale_b, alpha}, 
+                       {scale_a_ptr, scale_b_ptr, alpha_ptr}
+                      },                // leaf args : (scale_a * scale_b * alpha)
+                      {},               // leaf args : acc
+                      {bias_ptr, ElementBias(0), dBias
+                      },                // leaf args : bias
+                      {}              // ternary args : multiply_add
+                    },                // end ternary op
+                    {}              // ternary args : multiply_add
+                  },                // end ternary op
+                  {aux_ptr, dAux} // unary args : store
+                },                // end unary op
+                activation     // unary args : activation
+              },               // end unary op
+              {amax_D_ptr_} // unary args : reduce
+            },              // end unary op
+            {{scale_d},{scale_d_ptr}}, // leaf args : scale_d
+            {} // binary args : multiplies or first
+          };   // end binary op
+      }
     }
   };
 
   // Ctor inheritance
   using Impl::Impl;
 };
 
@@ -1044,14 +1160,15 @@
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class GmemLayoutTagAux,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementAux,
   class ElementSource,
   class ElementScalar,
@@ -1059,15 +1176,15 @@
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile,
   class SmemLayoutAtom,
   class CopyOpS2R
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombDeEltAct<
       GmemLayoutTagAux, ActivationFn, ElementOutput, ElementCompute,
       ElementAux, ElementSource, ElementScalar, AlignmentAux, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile,
     SmemLayoutAtom,
@@ -1142,26 +1259,27 @@
   class ElementScalar = ElementCompute,
   int AlignmentAux = 128 / sizeof_bits_v<ElementAux>,
   int AlignmentBias = 128 / sizeof_bits_v<ElementBias>,
   FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
 >
 using Sm90LinCombDeEltActDePerRowBias =
   Sm90EVT<Sm90Compute<cutlass::epilogue::thread::Identity, ElementOutput, ElementCompute, RoundStyle>, // Identity for final conversion
-    Sm90EVT<Sm90ColReduction<plus, plus, 0, CtaTileShapeMNK,
+    Sm90EVT<Sm90ColReduction<plus, plus, plus, 0, CtaTileShapeMNK,
                              ElementBias, ElementCompute, RoundStyle, Stride<_1,_0,int>, AlignmentBias>,
       Sm90LinCombDeEltAct<CtaTileShapeMNK, EpilogueTile, Stages, StrideAux, SmemLayoutAtom, CopyOpS2R, ActivationFn,
                           ElementCompute, ElementCompute, ElementAux, ElementSource, ElementScalar, AlignmentAux, RoundStyle>
     >
   >;
 
 template <
   int StagesC,
   int StagesD,
   int FragmentSize,
   bool ReuseSmemC,
+  bool DelayTmaStore,
   class GmemLayoutTagAux,
   template <class> class ActivationFn,
   class ElementOutput,
   class ElementCompute,
   class ElementAux,
   class ElementBias,
   class ElementSource,
@@ -1171,15 +1289,15 @@
   FloatRoundStyle RoundStyle,
   class CtaTileShapeMNK,
   class EpilogueTile,
   class SmemLayoutAtom,
   class CopyOpS2R
 >
 struct FusionCallbacks<
-    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC>,
+    epilogue::Sm90TmaWarpSpecialized<StagesC, StagesD, FragmentSize, ReuseSmemC, DelayTmaStore>,
     fusion::LinCombDeEltActDePerRowBias<
       GmemLayoutTagAux, ActivationFn, ElementOutput, ElementCompute,
       ElementAux, ElementBias, ElementSource, ElementScalar, AlignmentAux, AlignmentBias, RoundStyle
     >,
     CtaTileShapeMNK,
     EpilogueTile,
     SmemLayoutAtom,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_compute_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_compute_tma_warpspecialized.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -107,27 +107,28 @@
 
   using Arguments = typename ComputeArguments<ComputeFn<ElementCompute>>::type;
 
   using Params = Arguments;
 
   template <class ProblemShape>
   static constexpr Params
-  to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
+  to_underlying_arguments(ProblemShape const&, Arguments const& args, void*) {
     return args;
   }
 
   template <class ProblemShape>
   static size_t
-  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+  get_workspace_size(ProblemShape const&, Arguments const&) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream, 
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
     return false;
   }
@@ -173,15 +174,15 @@
         },
         [&] (auto&&... cvt_frg_inputs) {
           using ComputeOutput = ComputeFn<Array<ElementCompute, FragmentSize>>;
           using ConvertOutput = NumericArrayConverter<ElementOutput, ElementCompute, FragmentSize, RoundStyle>;
           ComputeOutput compute_output{};
           ConvertOutput convert_output{};
 
-          if constexpr (is_same_v<Arguments, EmptyArguments>) {
+          if constexpr (cute::is_same_v<Arguments, EmptyArguments>) {
             return convert_output(compute_output(cvt_frg_inputs...));
           }
           else {
             return convert_output(compute_output(cvt_frg_inputs..., params));
           }
         }
       );
@@ -207,36 +208,34 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // beta * C + Z
 template <
   class ElementOutput,
   class ElementCompute,
   FloatRoundStyle RoundStyle,
-  class ElementScalar,
-  class StrideScalar,
-  int ScalarCount,
-  template <class> class ScalarReduceFn,
-  class ElementSource,
-  class InputAddOp // Z
+  class InputScaleOp,  // beta
+  class ElementSource, // C
+  class InputAddOp     // Z
 >
 struct Sm90TreeVisitor<
-  Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>,
-  Sm90ScalarBroadcast<ElementScalar, StrideScalar, ScalarCount, ScalarReduceFn>,
+  Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle,
+              cute::void_t<decltype(declval<InputScaleOp>().is_zero())>>,
+  InputScaleOp,
   Sm90SrcFetch<ElementSource>,
   InputAddOp
 > : Sm90VisitorImpl<
-      Sm90ScalarBroadcast<ElementScalar, StrideScalar, ScalarCount, ScalarReduceFn>,
+      InputScaleOp,
       Sm90SrcFetch<ElementSource>,
       InputAddOp,
       Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>
     >
 {
   using Impl =
     Sm90VisitorImpl<
-      Sm90ScalarBroadcast<ElementScalar, StrideScalar, ScalarCount, ScalarReduceFn>,
+      InputScaleOp,
       Sm90SrcFetch<ElementSource>,
       InputAddOp,
       Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>
     >;
   using Params = typename Impl::Params;
   using SharedStorage = typename Impl::SharedStorage;
 
@@ -247,26 +246,24 @@
   Sm90TreeVisitor(
       Params const& params,
       SharedStorage const& shared_storage)
     : Impl(params, shared_storage) {}
 
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
-    auto const& bcast_op = get<0>(Impl::ops);
     auto const& added_op = get<2>(Impl::ops);
-    return not (bcast_op.params_ptr->dScalar == Stride<_0,_0,_0>{} && not is_C_load_needed()) ||
-           added_op.is_producer_load_needed();
+    return is_C_load_needed() || added_op.is_producer_load_needed();
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
-    auto const& bcast_op = get<0>(Impl::ops);
+    auto const& scale_op = get<0>(Impl::ops);
     auto const& src_op = get<1>(Impl::ops);
     auto const& added_op = get<2>(Impl::ops);
-    return (bcast_op.scalar != 0 && src_op.is_C_load_needed()) || added_op.is_C_load_needed();
+    return (not scale_op.is_zero() && src_op.is_C_load_needed()) || added_op.is_C_load_needed();
   }
 
   template <class CallbacksImpl>
   struct ConsumerStoreCallbacks : CallbacksImpl {
     CUTLASS_DEVICE
     ConsumerStoreCallbacks(bool is_C_load_needed, CallbacksImpl&& impl)
       : is_C_load_needed(is_C_load_needed), CallbacksImpl(cute::forward<CallbacksImpl>(impl)) { }
@@ -343,15 +340,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_HOST_DEVICE
   Sm90ReLUAuxStore() { }
 
   CUTLASS_HOST_DEVICE
@@ -375,16 +373,16 @@
   int Alignment,
   bool EnableNullptr,
   // Input node
   class InputOp
 >
 struct Sm90TreeVisitor<
   Sm90Compute<Activation, ElementOutput, ElementCompute, RoundStyle,
-              enable_if_t<is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::ReLu<ElementCompute>> ||
-                          is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::Clamp<ElementCompute>>  >>,
+              cute::enable_if_t<cute::is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::ReLu<ElementCompute>> ||
+                                cute::is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::Clamp<ElementCompute>>  >>,
   Sm90TreeVisitor<
     Sm90AuxStore<
       Stages,
       EpilogueTile,
       cutlass::uint1b_t,
       RoundStyle,
       StrideMNL,
@@ -470,15 +468,15 @@
       ConvertOutput convert_output{};
 
       Array frg_compute = convert_input(frg_input);
       bool frg_aux[FragmentSize];
       CUTLASS_PRAGMA_UNROLL
       for (int i = 0; i < FragmentSize; ++i) {
         ElementCompute pre_relu = frg_compute[i];
-        if constexpr (is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::Clamp<ElementCompute>>) {
+        if constexpr (cute::is_same_v<Activation<ElementCompute>, cutlass::epilogue::thread::Clamp<ElementCompute>>) {
           frg_compute[i] = relu(frg_compute[i], params_compute);
         }
         else {
           frg_compute[i] = relu(frg_compute[i]);
         }
         frg_aux[i] = frg_compute[i] == pre_relu;
       }
@@ -602,15 +600,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_HOST_DEVICE
   Sm90AuxLoad() { }
 
   CUTLASS_HOST_DEVICE
@@ -631,55 +630,66 @@
 
   template <class... Args>
   CUTLASS_DEVICE auto
   get_producer_load_callbacks(ProducerLoadArgs<Args...> const& args) {
     return EmptyProducerLoadCallbacks{};
   }
 
-  template <class RTensor, class GTensor, class ResidueMN>
+  template <class RTensor, class GTensor, class CTensor, class ResidueMN>
   struct ConsumerStoreCallbacks : EmptyConsumerStoreCallbacks {
     CUTLASS_DEVICE
-    ConsumerStoreCallbacks(RTensor&& tC_rAux_, GTensor&& tC_gAux_, ResidueMN residue_mn_, Params const& params_)
+    ConsumerStoreCallbacks(RTensor&& tC_rAux_, GTensor&& tC_gAux_, CTensor tC_cAux_, ResidueMN residue_mn_, Params const& params_)
       : tC_rAux(cute::forward<RTensor>(tC_rAux_)),
         tC_gAux(cute::forward<GTensor>(tC_gAux_)),
+        tC_cAux(tC_cAux_),
         residue_mn(residue_mn_),
         params(params_) {}
 
     RTensor tC_rAux;                                                                   // (CPY,CPY_M,CPY_N,{EPI_M,EPI_N})
     GTensor tC_gAux;                                                                   // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
+    CTensor tC_cAux;                                                                   // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
     ResidueMN residue_mn;
     Params const& params;
 
     CUTLASS_DEVICE void
     begin() {
       if constexpr (decltype(cute::rank(tC_rAux))::value == 5) {
         if constexpr (EnableNullptr) {
           if (params.ptr_aux == nullptr) {
             return;
           }
         }
 
-        if (elem_less(repeat_like(residue_mn, _0{}), residue_mn)) { // (partially) in-bounds CTA tile
-          copy_aligned(tC_gAux, tC_rAux);
+        constexpr int V = cute::min(Alignment, decltype(max_common_vector(tC_rAux, tC_gAux))::value);
+        if constexpr (V > 0) {
+          using VecType = uint_bit_t<V>;
+          Tensor tC_gAux_vec = recast<VecType>(tC_gAux);
+          Tensor tC_rAux_vec = recast<VecType>(tC_rAux);
+          Tensor tC_cAux_vec = tC_cAux.compose(make_layout(Int<size(tC_rAux_vec)>{}, Int<V>{})); // only works if vector is logically sequential
+          auto predicate_fn = [&] (auto&&... coords) { return elem_less(tC_cAux_vec(coords...), residue_mn); };
+          copy_if(FunctionPredTensor(predicate_fn), tC_gAux_vec, tC_rAux_vec);
+        }
+        else {
+          auto predicate_fn = [&] (auto&&... coords) { return elem_less(tC_cAux(coords...), residue_mn); };
+          copy_if(FunctionPredTensor(predicate_fn), tC_gAux, tC_rAux);
         }
       }
     }
 
     CUTLASS_DEVICE void
     previsit(int epi_m, int epi_n, int load_iteration, bool is_producer_load_needed) {
       if constexpr (decltype(cute::rank(tC_rAux))::value == 3) {
         if constexpr (EnableNullptr) {
           if (params.ptr_aux == nullptr) {
             return;
           }
         }
 
-        if (elem_less(repeat_like(residue_mn, _0{}), residue_mn)) {
-          copy_aligned(tC_gAux(_,_,_,epi_m,epi_n), tC_rAux);
-        }
+        auto predicate_fn = [&] (auto&&... coords) { return elem_less(tC_cAux(_,_,_,epi_m,epi_n)(coords...), residue_mn); };
+        copy_if(FunctionPredTensor(predicate_fn), tC_gAux(_,_,_,epi_m,epi_n), tC_rAux);
       }
     }
 
     template <typename ElementAccumulator, int FragmentSize>
     CUTLASS_DEVICE auto
     visit(Array<ElementAccumulator, FragmentSize> const& frg_acc, int epi_v, int epi_m, int epi_n) {
       using ElementRegister = typename remove_cvref_t<RTensor>::value_type;
@@ -720,16 +730,16 @@
 
     if constexpr (EnableNullptr) {
       if (params.ptr_aux == nullptr) {
         fill(tC_rAux, params.null_default);
       }
     }
 
-    return ConsumerStoreCallbacks<decltype(tC_rAux), decltype(tC_gAux), decltype(args.residue_mn)>(
-        cute::move(tC_rAux), cute::move(tC_gAux), args.residue_mn, params);
+    return ConsumerStoreCallbacks<decltype(tC_rAux), decltype(tC_gAux), decltype(args.tCcD), decltype(args.residue_mn)>(
+        cute::move(tC_rAux), cute::move(tC_gAux), args.tCcD, args.residue_mn, params);
   }
 };
 
 // dReLU specialization
 template<
   class ElementOutput,
   class ElementCompute,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_load_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_load_tma_warpspecialized.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -94,14 +94,19 @@
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
     return not is_void_v<Element>;
   }
 
+  CUTLASS_DEVICE bool
+  is_zero() const {
+    return is_void_v<Element>;
+  }
+
   using Sm90VisitorImpl<>::Sm90VisitorImpl;
 
   template<class SrcTensor>
   struct ConsumerStoreCallbacks : EmptyConsumerStoreCallbacks {
     CUTLASS_DEVICE
     ConsumerStoreCallbacks(SrcTensor const& tCrC)
       : tCrC(tCrC) {}
@@ -154,45 +159,50 @@
   using SmemLayoutTma = decltype(tile_to_shape(
       SmemLayoutAtom{}, SmemShapeTma{},
       cute::conditional_t<is_m_major, Step<_2,_1>, Step<_1,_2>>{} ));
   using SmemLayout = decltype(tile_to_shape(
       SmemLayoutTma{},
       make_shape(size<0>(shape(EpilogueTile{})), size<1>(shape(EpilogueTile{})), Int<Stages>{}),
       cute::conditional_t<is_m_major, Step<_2,_1,_3>, Step<_1,_2,_3>>{} ));
+  using CopyOpG2S =
+      SM90_TMA_LOAD
+    ;
 
   struct SharedStorage {
     alignas(cutlass::detail::alignment_for_swizzle(SmemLayout{}))
     array_aligned<Element, size(SmemLayout{})> smem_aux;
   };
 
   struct Arguments {
     Element const* ptr_aux = nullptr;
     Element null_default = Element(0);
     StrideMNL dAux = {};
   };
 
   struct Params {
     using TMA_Aux = decltype(make_tma_copy(
-        SM90_TMA_LOAD{},
-        make_tensor(static_cast<Element const*>(nullptr), repeat_like(StrideMNL{}, int32_t(0)), StrideMNL{}),
-        SmemLayoutTma{}));
+        CopyOpG2S{},
+        make_tensor(make_gmem_ptr(static_cast<Element const*>(nullptr)), repeat_like(StrideMNL{}, int32_t(0)), append<3>(StrideMNL{}, _0{})),
+        take<0,2>(SmemLayoutTma{})));
     TMA_Aux tma_load_aux;
     Element null_default = Element(0);
     bool use_default = false;
   };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     // Optionally append 1s until problem shape is rank-4 in case its is only rank-3 (MNK)
     auto problem_shape_mnkl = append<4>(problem_shape, 1);
     auto [M, N, K, L] = problem_shape_mnkl;
-
-    Tensor tensor_aux = make_tensor(args.ptr_aux, make_layout(make_shape(M,N,L), args.dAux));
-    typename Params::TMA_Aux tma_load_aux = make_tma_copy(SM90_TMA_LOAD{}, tensor_aux, SmemLayoutTma{});
+    auto M_AUX =
+        size(M)
+      ;
+    Tensor tensor_aux = make_tensor(make_gmem_ptr(args.ptr_aux), make_layout(make_shape(M_AUX,N,L), append<3>(args.dAux, _0{})));
+    typename Params::TMA_Aux tma_load_aux = make_tma_copy(CopyOpG2S{}, tensor_aux, take<0,2>(SmemLayoutTma{}));
 
     bool use_default = false;
     if constexpr (EnableNullptr) {
       use_default = args.ptr_aux == nullptr;
     }
 
     return Params{tma_load_aux, args.null_default, use_default};
@@ -202,15 +212,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_HOST_DEVICE
   Sm90AuxLoad() { }
 
   CUTLASS_HOST_DEVICE
@@ -227,14 +238,19 @@
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
     return false;
   }
 
+  CUTLASS_DEVICE bool
+  is_zero() const {
+    return (params_ptr->use_default && params_ptr->null_default == Element(0));
+  }
+
   template <class GTensor, class STensor>
   struct ProducerLoadCallbacks : EmptyProducerLoadCallbacks {
     CUTLASS_DEVICE
     ProducerLoadCallbacks(GTensor&& bGS_gAux, STensor&& bGS_sAux, Params const* params_ptr)
       : bGS_gAux(cute::forward<GTensor>(bGS_gAux)),
         bGS_sAux(cute::forward<STensor>(bGS_sAux)),
         params_ptr(params_ptr) {}
@@ -249,15 +265,15 @@
         if (params_ptr->use_default) {
           return;
         }
       }
 
       if (issue_tma_load) {
         // Increment the expected transaction bytes of the current stage's mbarrier by the subtile's byte-size
-        constexpr uint32_t copy_bytes = size(take<0,2>(SmemLayout{})) * sizeof_bytes_v<Element>;
+        constexpr uint32_t copy_bytes = size(take<0,2>(SmemLayout{})) * sizeof_bits_v<Element> / 8;
         cutlass::arch::ClusterTransactionBarrier::expect_transaction(full_mbarrier_ptr, copy_bytes);
         // Issue the TMA load
         constexpr uint16_t mcast_mask = 0;
         int load_pipe_index = load_iteration % Stages;
         copy(params_ptr->tma_load_aux.with(*full_mbarrier_ptr, mcast_mask),
           bGS_gAux(_,_,_,epi_m,epi_n), bGS_sAux(_,_,_,load_pipe_index));
       }
@@ -266,16 +282,20 @@
 
   template <class... Args>
   CUTLASS_DEVICE auto
   get_producer_load_callbacks(ProducerLoadArgs<Args...> const& args) {
 
     auto [M, N, K, L] = args.problem_shape_mnkl;
     auto [m, n, k, l] = args.tile_coord_mnkl;
-    Tensor mAux = params_ptr->tma_load_aux.get_tma_tensor(make_shape(M,N,L));                                // (M,N,L)
-    Tensor gAux = local_tile(mAux, take<0,2>(args.tile_shape_mnk), make_coord(m,n,l));                 // (CTA_M,CTA_N)
+    auto coord_shape =
+        make_coord(m, n, l)
+      ;
+    Tensor mAux_mn = params_ptr->tma_load_aux.get_tma_tensor(make_shape(M,N,L));                             // (M,N,L)
+    Tensor mAux = coalesce(mAux_mn, take<0,2>(args.tile_shape_mnk));
+    Tensor gAux = local_tile(mAux, take<0,2>(args.tile_shape_mnk), coord_shape);                       // (CTA_M,CTA_N)
 
     Tensor gAux_epi = flat_divide(gAux, args.epi_tile);                          // (EPI_TILE_M,EPI_TILE_N,EPI_M,EPI_N)
     Tensor sAux_epi = make_tensor(make_smem_ptr(smem_aux), SmemLayout{});        // (EPI_TILE_M,EPI_TILE_N,PIPE)
 
     ThrCopy thrblk_g2s = params_ptr->tma_load_aux.get_slice(_0{});
     Tensor bGS_gAux = thrblk_g2s.partition_S(gAux_epi);                                // (TMA,TMA_M,TMA_N,EPI_M,EPI_N)
     Tensor bGS_sAux = thrblk_g2s.partition_D(sAux_epi);                                // (TMA,TMA_M,TMA_N,PIPE)
@@ -327,17 +347,19 @@
     bool ReferenceSrc, // do register tensors reference the src or dst layout of the tiled copy
     class... Args
   >
   CUTLASS_DEVICE auto
   get_consumer_store_callbacks(ConsumerStoreArgs<Args...> const& args) {
 
     auto [M, N, K, L] = args.problem_shape_mnkl;
-    Tensor mAux = params_ptr->tma_load_aux.get_tma_tensor(make_shape(M,N,L));                                // (M,N,L)
-    Tensor tC_gAux = sm90_partition_for_epilogue<ReferenceSrc>(                        // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
-      mAux, args.tile_shape_mnk, args.tile_coord_mnkl, args.epi_tile, args.tiled_copy, args.thread_idx);
+
+    Tensor mAux_mn = params_ptr->tma_load_aux.get_tma_tensor(make_shape(M,N,L));                             // (M,N,L)
+    Tensor mAux = coalesce(mAux_mn, take<0,2>(args.tile_shape_mnk));
+    Tensor tC_gAux = sm90_partition_for_epilogue<ReferenceSrc                          // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
+      >(mAux, args.tile_shape_mnk, args.tile_coord_mnkl, args.epi_tile, args.tiled_copy, args.thread_idx);
     Tensor tC_rAux = make_tensor<Element>(take<0,3>(shape(tC_gAux)));                  // (CPY,CPY_M,CPY_N)
 
     auto tiled_s2r = conditional_return<ReferenceSrc>(
       make_tiled_copy_S(Copy_Atom<CopyOpS2R,Element>{}, args.tiled_copy),
       make_tiled_copy_D(Copy_Atom<CopyOpS2R,Element>{}, args.tiled_copy)
     );
     Tensor sAux_epi = cute::as_position_independent_swizzle_tensor(
@@ -389,50 +411,55 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter *cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
     return false;
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
     return false;
   }
 
+  // This must be called after update_scalar is called
+  CUTLASS_DEVICE bool
+  is_zero() const {
+    return scalar == Element(0);
+  }
+
   CUTLASS_HOST_DEVICE
   Sm90ScalarBroadcast() { }
 
   CUTLASS_HOST_DEVICE
   Sm90ScalarBroadcast(Params const& params, SharedStorage const& shared_storage)
       : params_ptr(&params) {
     // Get the scalar for non-batched broadcast
-    if constexpr (cute::is_same_v<StrideMNL, Stride<_0,_0,_0>>) {
+    if (get<2>(params_ptr->dScalar) == 0) {
       update_scalar();
     }
   }
 
   Element scalar;
   Params const* params_ptr;
 
   template <class... Args>
   CUTLASS_DEVICE auto
   get_producer_load_callbacks(ProducerLoadArgs<Args...> const& args) {
     // Get the scalar for batched broadcast
-    if constexpr (
-      cute::is_same_v<StrideMNL, Stride<_0,_0,_1>> ||
-      cute::is_same_v<StrideMNL, Stride<_0,_0,int>>) {
+    if (get<2>(params_ptr->dScalar) != 0) {
       auto [m_coord, n_coord, k_coord, l_coord] = args.tile_coord_mnkl;
       update_scalar(l_coord);
     }
 
     return EmptyProducerLoadCallbacks{};
   }
 
@@ -458,17 +485,15 @@
     bool ReferenceSrc, // do register tensors reference the src or dst layout of the tiled copy
     class... Args
   >
   CUTLASS_DEVICE auto
   get_consumer_store_callbacks(ConsumerStoreArgs<Args...> const& args) {
 
     // Get the scalar for batched broadcast
-    if constexpr (
-      cute::is_same_v<StrideMNL, Stride<_0,_0,_1>> ||
-      cute::is_same_v<StrideMNL, Stride<_0,_0,int>>) {
+    if (get<2>(params_ptr->dScalar) != 0) {
       auto [m_coord, n_coord, k_coord, l_coord] = args.tile_coord_mnkl;
       update_scalar(l_coord);
     }
 
     return ConsumerStoreCallbacks(scalar);
   }
 
@@ -492,18 +517,36 @@
         scalar = reduction_fn(scalar, params_ptr->scalar_ptrs[i][l_offset]);
       } else {
         // batch stride is ignored for nullptr fallback
         scalar = reduction_fn(scalar, params_ptr->scalars[i]);
       }
     }
   }
+
+  template<class... Xs>
+  CUTLASS_DEVICE void
+  update_scalar(cute::tuple<Xs...>) {
+    // Only support multiple L-modes with fully-broadcast scalar
+    static_assert(cute::is_same_v<StrideMNL, Stride<_0,_0, _0>>);
+    scalar = params_ptr->scalars[0];
+  }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
+namespace detail {
+
+template <int StagesC, class CtaTileShapeMNK, class EpilogueTile>
+constexpr int
+compute_row_broadcast_stages() {
+  return ceil_div(StagesC, size<1>(zipped_divide(make_layout(take<0,2>(CtaTileShapeMNK{})), EpilogueTile{}))) + 1;
+}
+
+}
+
 // Row vector broadcast
 template<
   // Row bcast reuses the mbarriers from the epilogue subtile load pipeline, so this must be at least
   // ceil_div(StagesC, epi tiles per CTA tile) + 1 to ensure no data races
   int Stages,
   class CtaTileShapeMNK,
   class Element,
@@ -540,15 +583,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_HOST_DEVICE
   Sm90RowBroadcast() { }
 
   CUTLASS_HOST_DEVICE
@@ -565,14 +609,19 @@
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
     return false;
   }
 
+  CUTLASS_DEVICE bool
+  is_zero() const {
+    return (params.ptr_row == nullptr && params.null_default == Element(0));
+  }
+
   template <int EpiTiles, class GTensor, class STensor>
   struct ProducerLoadCallbacks : EmptyProducerLoadCallbacks {
     CUTLASS_DEVICE
     ProducerLoadCallbacks(GTensor&& gRow, STensor&& sRow, Params const& params)
       : gRow(cute::forward<GTensor>(gRow)),
         sRow(cute::forward<STensor>(sRow)),
         params(params) {}
@@ -587,15 +636,15 @@
         if (params.ptr_row == nullptr) {
           return;
         }
       }
 
       if (issue_tma_load) {
         // Increment the expect-tx count of the first subtile's mbarrier by the row vector's byte-size
-        constexpr uint32_t copy_bytes = size<1>(CtaTileShapeMNK{}) * sizeof_bytes_v<Element>;
+        constexpr uint32_t copy_bytes = size<1>(CtaTileShapeMNK{}) * sizeof_bits_v<Element> / 8;
         cutlass::arch::ClusterTransactionBarrier::expect_transaction(full_mbarrier_ptr, copy_bytes);
         // Issue the TMA bulk copy
         auto bulk_copy = Copy_Atom<SM90_BULK_COPY_AUTO, Element>{}.with(*full_mbarrier_ptr);
         // Filter so we don't issue redundant copies over stride-0 modes
         int bcast_pipe_index = (load_iteration / EpiTiles) % Stages;
         copy(bulk_copy, filter(gRow), filter(sRow(_,_,bcast_pipe_index)));
       }
@@ -610,15 +659,15 @@
     auto [m, n, k, l] = args.tile_coord_mnkl;
     Tensor mRow = make_tensor(make_gmem_ptr(params.ptr_row), make_shape(M,N,L), params.dRow);
     Tensor gRow = local_tile(mRow, take<0,2>(args.tile_shape_mnk), make_coord(m,n,l));            // (CTA_M,CTA_N)
     Tensor sRow = make_tensor(make_smem_ptr(smem_row),                                            // (CTA_M,CTA_N,PIPE)
                     make_shape(size<0>(CtaTileShapeMNK{}), size<1>(CtaTileShapeMNK{}), Stages),
                     make_stride(_0{},_1{},size<1>(CtaTileShapeMNK{})));
 
-    constexpr int EpiTiles = decltype(size(shape_div(take<0,2>(args.tile_shape_mnk), args.epi_tile)))::value;
+    constexpr int EpiTiles = decltype(size<1>(zipped_divide(make_layout(take<0,2>(args.tile_shape_mnk)), args.epi_tile)))::value;
     return ProducerLoadCallbacks<EpiTiles, decltype(gRow), decltype(sRow)>(
       cute::move(gRow), cute::move(sRow), params);
   }
 
   template <int EpiTiles, class RTensor, class STensor>
   struct ConsumerStoreCallbacks : EmptyConsumerStoreCallbacks {
     CUTLASS_DEVICE
@@ -672,15 +721,15 @@
     Tensor sRow = make_tensor(make_smem_ptr(smem_row),                                            // (CTA_M,CTA_N,PIPE)
                     make_shape(size<0>(CtaTileShapeMNK{}), size<1>(CtaTileShapeMNK{}), Stages),
                     make_stride(_0{},_1{},size<1>(CtaTileShapeMNK{})));
     Tensor tCsRow = sm90_partition_for_epilogue<ReferenceSrc>(                    // (CPY,CPY_M,CPY_N,EPI_M,EPI_N,PIPE)
                       sRow, args.epi_tile, args.tiled_copy, args.thread_idx);
     Tensor tCrRow = make_tensor_like(take<0,3>(tCsRow));                                           // (CPY,CPY_M,CPY_N)
 
-    constexpr int EpiTiles = decltype(size(shape_div(take<0,2>(args.tile_shape_mnk), args.epi_tile)))::value;
+    constexpr int EpiTiles = decltype(size<1>(zipped_divide(make_layout(take<0,2>(args.tile_shape_mnk)), args.epi_tile)))::value;
     return ConsumerStoreCallbacks<EpiTiles, decltype(tCrRow), decltype(tCsRow)>(
       cute::move(tCrRow), cute::move(tCsRow), params);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -721,28 +770,34 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
     return false;
   }
 
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
     return false;
   }
 
+  CUTLASS_DEVICE bool
+  is_zero() const {
+    return (params.ptr_col == nullptr && params.null_default == Element(0));
+  }
+
   CUTLASS_HOST_DEVICE
   Sm90ColBroadcast() { }
 
   CUTLASS_HOST_DEVICE
   Sm90ColBroadcast(Params const& params, SharedStorage const& shared_storage)
       : params(params) { }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_store_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_store_tma_warpspecialized.hpp`

 * *Files 15% similar despite different names*

```diff
@@ -128,15 +128,16 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_HOST_DEVICE
   Sm90AuxStore() { }
 
   CUTLASS_HOST_DEVICE
@@ -203,15 +204,15 @@
       Tensor tC_rAux_frg = recast<Array<Element, FragmentSize>>(coalesce(tC_rAux));                          // (EPI_V)
       tC_rAux_frg(epi_v) = convert_input(frg_input);
 
       return frg_input;
     }
 
     CUTLASS_DEVICE void
-    postvisit(int epi_m, int epi_n, int store_iteration, bool issue_smem_store) {
+    postreduce(int epi_m, int epi_n, int store_iteration, bool issue_smem_store) {
       if constexpr (EnableNullptr) {
         if (params_ptr->is_nullptr) {
           return;
         }
       }
 
       using RLayoutR2S = decltype(cute::layout(TiledR2S{}.get_slice(0).retile_S(RTensor{})));
@@ -220,15 +221,15 @@
       if (issue_smem_store) {
         int store_pipe_index = store_iteration % Stages;
         copy(tiled_r2s, tRS_rAux, tRS_sAux(_,_,_,store_pipe_index));
       }
     }
 
     CUTLASS_DEVICE void
-    step(int epi_m, int epi_n, int store_iteration, bool issue_tma_store) {
+    tma_store(int epi_m, int epi_n, int store_iteration, bool issue_tma_store) {
       if constexpr (EnableNullptr) {
         if (params_ptr->is_nullptr) {
           return;
         }
       }
 
       if (issue_tma_store) {
@@ -325,20 +326,21 @@
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     return 0;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     if constexpr (IsAtomic) {
       auto [M, N, K, L] = problem_shape;
       Layout mScalar_layout = make_layout(make_shape(M,N,L), args.dScalar);
       if (args.ptr_scalar != nullptr) {
-        return fill_workspace(args.ptr_scalar, ElementOutput(args.reduction_identity), cosize(mScalar_layout), stream);
+        return fill_workspace(args.ptr_scalar, ElementOutput(args.reduction_identity), cosize(mScalar_layout), stream, cuda_adapter);
       }
     }
 
     return cutlass::Status::kSuccess;
   }
 
   CUTLASS_DEVICE bool
@@ -448,69 +450,124 @@
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Row vector reduction
 template <
   template <class> class RegReduceFn,
+  template <class> class ShuffleReduceFn,
   template <class> class GmemReduceFn,
   int Stages,
   class CtaTileShapeMNK,
   class ElementOutput,
   class ElementCompute,
   FloatRoundStyle RoundStyle,
   class StrideMNL = Stride<_0,_1,_0>,
   int Alignment = 128 / sizeof_bits_v<ElementOutput>,
-  bool EnableNullptr = true // Noop on nullptr params
+  bool EnableNullptr = true, // Noop on nullptr params
+  // If this is false, ptr_row is assumed to point to a compact n-major (ceil_div(M,CTA_M), round_nearest(N,CTA_N), L)
+  // tensor of ElementCompute. It is the user's responsibility to reduce this to a (N, L) tensor of ElementOutput
+  bool FinalReduction = true,
+  // False means skip OOB predication if OOB inputs are known to be the reduction identity
+  bool VisitCheckOOB = true
 >
 struct Sm90RowReduction {
 private:
   static_assert(Stages == 0, "Smem usage not supported yet");
   static_assert(Alignment * sizeof_bits_v<ElementOutput> % 128 == 0, "sub-16B alignment not supported yet");
   static_assert(
     (cute::is_same_v<StrideMNL, Stride<_0,_1, _0>>) || // row vector reduction, e.g. per-col sum over all batches
     (cute::is_same_v<StrideMNL, Stride<_0,_1,int>>));  // batched row vector reduction, e.g. per-col sum per batch
   static constexpr bool IsAtomic = is_atomic<GmemReduceFn<ElementCompute>>::value;
-  static_assert(IsAtomic, "non-atomic row reduction not supported yet");
+  static_assert(not (IsAtomic && not FinalReduction), "atomic reduction must be final");
 
 public:
   struct SharedStorage { };
 
   struct Arguments {
-    ElementOutput* ptr_row = nullptr;
+    void* ptr_row = nullptr; // ElementOutput* if FinalReduction, else ElementCompute*
     ElementCompute reduction_identity = 0;
     StrideMNL dRow = {};
   };
 
-  using Params = Arguments;
+  struct Params {
+    void* ptr_row = nullptr;
+    ElementCompute reduction_identity = 0;
+    StrideMNL dRow = {};
+    ElementCompute* reduction_buffer = nullptr;
+    int* tile_counters = nullptr;
+  };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
-    return args;
+    ElementCompute* reduction_buffer;
+    int* tile_counters = nullptr;
+    if constexpr (IsAtomic) {
+      reduction_buffer = nullptr;
+    }
+    else if constexpr (not FinalReduction) {
+      reduction_buffer = reinterpret_cast<ElementCompute*>(args.ptr_row);
+    }
+    else {
+      auto [M, N, K, L] = problem_shape;
+      auto [tile_M, tile_N, tile_K] = CtaTileShapeMNK{};
+      size_t tile_counters_offset = product(ceil_div(make_shape(size<>(M), size<>(N), L), make_shape(tile_M, tile_N))) * tile_N * sizeof(ElementCompute);
+      tile_counters_offset = round_nearest(tile_counters_offset, sizeof(int));
+
+      reduction_buffer = reinterpret_cast<ElementCompute*>(workspace);
+      tile_counters = reinterpret_cast<int*>(reinterpret_cast<uint8_t*>(workspace) + tile_counters_offset);
+    }
+
+    return {
+      args.ptr_row,
+      args.reduction_identity,
+      args.dRow,
+      reduction_buffer,
+      tile_counters
+    };
   }
 
   template <class ProblemShape>
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
-    return 0;
+    if constexpr (IsAtomic || not FinalReduction) {
+      return 0;
+    }
+
+    size_t workspace_size = 0;
+    auto [M, N, K, L] = problem_shape;
+    auto [tile_M, tile_N, tile_K] = CtaTileShapeMNK{};
+    // Increment by size of reduction buffer
+    workspace_size += product(ceil_div(make_shape(size<>(M),size<>(N),L), make_shape(tile_M, tile_N))) * tile_N * sizeof(ElementCompute);
+    // Align and increment by size of tile counters
+    workspace_size = round_nearest(workspace_size, sizeof(int));
+    workspace_size += cute::ceil_div(size<>(N), tile_N) * sizeof(int);
+    return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     if constexpr (IsAtomic) {
       auto [M, N, K, L] = problem_shape;
       Layout mRow_layout = make_layout(make_shape(M,N,L), args.dRow);
       if (args.ptr_row != nullptr) {
-        return fill_workspace(args.ptr_row, ElementOutput(args.reduction_identity), cosize(mRow_layout), stream);
+        return fill_workspace(args.ptr_row, ElementOutput(args.reduction_identity), cosize(mRow_layout), stream, cuda_adapter);
       }
+      return Status::kSuccess;
     }
+    auto [M, N, K, L] = problem_shape;
+    auto [tile_M, tile_N, tile_K] = CtaTileShapeMNK{};
+    size_t tile_counters_offset = product(ceil_div(make_shape(size<>(M),size<>(N),L), make_shape(tile_M, tile_N))) * tile_N * sizeof(ElementCompute);
 
-    return cutlass::Status::kSuccess;
+    int* tile_counters = reinterpret_cast<int*>(reinterpret_cast<uint8_t*>(workspace) + tile_counters_offset);
+    size_t tile_counters_size = cute::ceil_div(size<>(N), tile_N) * sizeof(int);
+    return zero_workspace(tile_counters, tile_counters_size, stream);
   }
 
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
     return false;
   }
 
@@ -530,146 +587,358 @@
 
   template <class... Args>
   CUTLASS_DEVICE auto
   get_producer_load_callbacks(ProducerLoadArgs<Args...> const& args) {
     return EmptyProducerLoadCallbacks{};
   }
 
-  template<class RTensor, class GTensor, class CTensor, class ResidueMN>
+  template<class ArgsTuple>
   struct ConsumerStoreCallbacks : EmptyConsumerStoreCallbacks {
     CUTLASS_DEVICE
-    ConsumerStoreCallbacks(
-        RTensor&& tCrRow,
-        GTensor&& tCgRow,
-        CTensor   tCcRow,
-        ResidueMN residue_mn,
-        Params const& params)
-      : tCrRow(cute::forward<RTensor>(tCrRow)),
-        tCgRow(cute::forward<GTensor>(tCgRow)),
-        tCcRow(tCcRow),
-        residue_mn(residue_mn),
+    ConsumerStoreCallbacks(ArgsTuple&& args_tuple, Params const& params)
+      : args_tuple(cute::forward<ArgsTuple>(args_tuple)),
         params(params) {}
 
-    // gmem store after every column of subtiles, assuming M-major loop
-    // needed to reduce reg pressure, otherwise each thread stores up to a full row in RF
-    // since row-elements aren't evenly distributed amongst threads
-    RTensor tCrRow;                                                                    // (CPY,CPY_M,CPY_N,EPI_M)
-    GTensor tCgRow;                                                                    // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
-    CTensor tCcRow;                                                                    // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
-    ResidueMN residue_mn;
+    ArgsTuple args_tuple;
     Params const& params;
+    bool do_final_reduction = false;
+
 
     template <typename ElementAccumulator, typename ElementInput, int FragmentSize>
     CUTLASS_DEVICE auto
     visit(Array<ElementAccumulator, FragmentSize> const& frg_acc, int epi_v, int epi_m, int epi_n,
           Array<ElementInput, FragmentSize> const& frg_input) {
-
       if constexpr (EnableNullptr) {
         if (params.ptr_row == nullptr) {
           return frg_input;
         }
       }
 
+      auto& [ref_src, tCrRow, tCcRow, gRow_l, cRow, gBuf_ml, sBuf_layout,
+        lane_layout_MN, lane_mn, warp_layout_MN, warp_mn,
+        tile_coord_mnkl, residue_mn, epi_tile, tiled_copy, thread_idx] = args_tuple;
+      Tensor tCrRow_mn = tCrRow(_,_,_,epi_m,epi_n);
+      Tensor tCcRow_mn = tCcRow(_,_,_,epi_m,epi_n);
+
       using ConvertInput = NumericArrayConverter<ElementCompute, ElementInput, FragmentSize, RoundStyle>;
       using ReduceInput = RegReduceFn<ElementCompute>;
       ConvertInput convert_input{};
       ReduceInput reduce_input{};
 
       Array frg_I = convert_input(frg_input);
-      Tensor tCrRow_mn = tCrRow(_,_,_,epi_m);
-      Tensor tCcRow_mn = tCcRow(_,_,_,epi_m,epi_n);
-
       CUTLASS_PRAGMA_UNROLL
       for (int i = 0; i < FragmentSize; ++i) {
-        if (elem_less(tCcRow_mn(epi_v * FragmentSize + i), residue_mn)) {
+        if constexpr (VisitCheckOOB) {
+          if (elem_less(tCcRow_mn(epi_v * FragmentSize + i), residue_mn)) {
+            ElementCompute& tCrRow_vmn = tCrRow_mn(epi_v * FragmentSize + i);
+            tCrRow_vmn = reduce_input(tCrRow_vmn, frg_I[i]);
+          }
+        }
+        else {
           ElementCompute& tCrRow_vmn = tCrRow_mn(epi_v * FragmentSize + i);
           tCrRow_vmn = reduce_input(tCrRow_vmn, frg_I[i]);
         }
       }
 
       return frg_input;
     }
 
+    template <class STensor, class SyncFn>
     CUTLASS_DEVICE void
-    step(int epi_m, int epi_n, int store_iteration, bool issue_tma_store) {
+    reduce(STensor&& smem_buffer, SyncFn const& sync_fn, int epi_m, int epi_n, bool is_last_iteration) {
+      if (not is_last_iteration) {
+        return;
+      }
+
+      auto& [ref_src, tCrRow, tCcRow, gRow_l, cRow, gBuf_ml, sBuf_layout,
+        lane_layout_MN, lane_mn, warp_layout_MN, warp_mn,
+        tile_coord_mnkl, residue_mn, epi_tile, tiled_copy, thread_idx] = args_tuple;
+      auto [m, n, k, l] = tile_coord_mnkl;
+      constexpr bool ReferenceSrc = decltype(ref_src)::value;
       if constexpr (EnableNullptr) {
         if (params.ptr_row == nullptr) {
           return;
         }
       }
 
-      if (epi_m == size<3>(tCrRow)-1) { // assumes M-major subtile loop
-        using ConvertI = NumericConverter<ElementOutput, ElementCompute, RoundStyle>;
-        using ReduceInput = GmemReduceFn<ElementOutput>;
+      // fully OOB CTA in partially OOB cluster
+      if (not elem_less(cRow(_0{},_0{}), residue_mn)) {
+        return;
+      }
 
-        ConvertI convert_I{};
-        ReduceInput reduce_input{};
+      //
+      // 1. Warp shuffle reduction
+      //
+      using FragmentShuffle = Array<ElementCompute, sizeof(uint64_t) / sizeof(ElementCompute)>;
+      using ReduceShuffle = ShuffleReduceFn<FragmentShuffle>;
+      ReduceShuffle reduce_shuffle{};
+      Tensor tCrRow_frg = recast<FragmentShuffle>(filter(tCrRow));
+      CUTLASS_PRAGMA_UNROLL
+      for (int reduction_rows = size<0>(lane_layout_MN) / 2; reduction_rows > 0; reduction_rows /= 2) {
+        CUTLASS_PRAGMA_UNROLL
+        for (int frg_idx = 0; frg_idx < size(tCrRow_frg); ++frg_idx) {
+          uint64_t frg_shfl = reinterpret_cast<uint64_t&>(tCrRow_frg(frg_idx));
+          frg_shfl = __shfl_down_sync(0xFFFFFFFF, frg_shfl, lane_layout_MN(reduction_rows, _0{}));
+          tCrRow_frg(frg_idx) = reduce_shuffle(tCrRow_frg(frg_idx), reinterpret_cast<FragmentShuffle&>(frg_shfl));
+        }
+      }
+      bool is_reduced_lane = get<0>(lane_mn) == 0;
 
+      //
+      // 2. Atomic reduction
+      //
+      if constexpr (IsAtomic) {
         // Filter so we don't issue redunant copies over stride-0 modes
-        Tensor tCrRow_flt = filter_zeros(tCrRow(_,_,_,epi_m));
-        Tensor tCgRow_flt = filter_zeros(tCgRow(_,_,_,epi_m,epi_n));
-        Tensor tCcRow_mn  = tCcRow(_,_,_,epi_m,epi_n);
-        Tensor tCcRow_flt = make_tensor(tCcRow_mn.data(), make_layout(tCgRow_flt.shape(), tCcRow_mn.stride()));
+        Tensor tCrRow_flt = filter_zeros(tCrRow);
+        Tensor tCcRow_flt = make_tensor(tCcRow.data(), make_layout(tCrRow_flt.shape(), tCcRow.stride()));
+
+        Tensor tCgRow = sm90_partition_for_epilogue<ReferenceSrc>(gRow_l(_,_,l), epi_tile, tiled_copy, thread_idx);
+        Tensor tCgRow_flt = filter_zeros(tCgRow);
+        // NOTE: atomic reduction is performed in the output type
+        using ConvertOutput = NumericConverter<ElementOutput, ElementCompute, RoundStyle>;
+        using ReduceOutput = GmemReduceFn<ElementOutput>;
+        ConvertOutput convert_output{};
+        ReduceOutput reduce_output{};
+
+        if (is_reduced_lane) {
+          CUTLASS_PRAGMA_UNROLL
+          for (int i = 0; i < size(tCrRow_flt); ++i) {
+            if (elem_less(tCcRow_flt(i), residue_mn)) {
+              reduce_output(&tCgRow_flt(i), convert_output(tCrRow_flt(i)));
+            }
+          }
+        }
+        sync_fn();
+      }
+
+      //
+      // 2. One warp in M, skip threadblock smem reduction
+      //
+      else if constexpr (decltype(size<0>(warp_layout_MN))::value <= 1) {
+        // Dump warp reduction to gmem workspace
+        using ElementGmem = cute::conditional_t<FinalReduction, ElementCompute volatile, ElementCompute>;
+        Tensor tCgBuf = sm90_partition_for_epilogue<ReferenceSrc>(gBuf_ml(_,_,m,l), epi_tile, tiled_copy, thread_idx);
+        if (is_reduced_lane) {
+          // Filter so we don't issue redundant copies over stride-0 modes
+          // (only works if 0-strides are in same location, which is by construction)
+          copy_aligned(filter(tCrRow), recast<ElementGmem>(filter(tCgBuf)));
+        }
+        sync_fn();
+      }
+
+      //
+      // 2. Multiple warps in M, do threadblock smem reduction
+      //
+      else {
+        Tensor sBuf = make_tensor(make_smem_ptr<ElementCompute>(raw_pointer_cast(smem_buffer.data())), sBuf_layout);
+        static_assert(decltype(cosize(sBuf.layout()))::value * sizeof(ElementCompute) <=
+                      decltype(cosize(smem_buffer.layout()))::value * sizeof(typename remove_cvref_t<STensor>::value_type),
+                      "smem reduction buffer not large enough, use a larger epilogue tile");
+
+        // Dump warp reduction to smem workspace
+        Tensor tCsBuf = sm90_partition_for_epilogue<ReferenceSrc>(sBuf(_,_,get<0>(warp_mn)), epi_tile, tiled_copy, thread_idx);
+        if (is_reduced_lane) {
+          // Filter so we don't issue redunant copies over stride-0 modes
+          // (only works if 0-strides are in same location, which is by construction)
+          copy_aligned(filter(tCrRow), filter(tCsBuf));
+        }
+        sync_fn();
+
+        constexpr int SmemFragSize = cute::max(size_t{1}, sizeof(uint32_t) / sizeof(ElementCompute));
+        using FragmentSmem = Array<ElementCompute, SmemFragSize>;
+        using VectorSmem = uint_bit_t<sizeof_bits_v<FragmentSmem>>;
+        using ReduceSmem = GmemReduceFn<FragmentSmem>;
+        ReduceSmem reduce_smem{};
 
+        Tensor sBuf_frg = recast<FragmentSmem>(filter_zeros(sBuf));
+        Tensor sBuf_vec = recast<VectorSmem>(filter_zeros(sBuf));
+        constexpr int FragsPerRow = decltype(size<1>(sBuf_frg))::value;
 
-        auto [residue_m, residue_n] = residue_mn;
+        // Do the threadblock smem reduction
         CUTLASS_PRAGMA_UNROLL
-        for (int i = 0; i < size(tCrRow_flt); ++i) {
-          // partially OOB in M must still issue gmem reduction, so only consider residue_n
-          // in case last epi tile in column is fully OOB in M and CTA tile is partially OOB in M
-          if (residue_n > get<1>(tCcRow_flt(i)) &&
-              // fully OOB in M does not need to issue gmem reduction, skip
-              residue_m > 0) {
-            reduce_input(&tCgRow_flt(i), convert_I(tCrRow_flt(i)));
+        for (int reduction_rows = size<0>(warp_layout_MN) / 2; reduction_rows > 1; reduction_rows /= 2) {
+          int FragsPerReduction = reduction_rows * FragsPerRow;
+          CUTLASS_PRAGMA_NO_UNROLL
+          for (int frg_idx = thread_idx; frg_idx < FragsPerReduction; frg_idx += size(tiled_copy)) {
+            FragmentSmem frg_smem = reduce_smem(sBuf_frg(frg_idx), sBuf_frg(frg_idx + FragsPerReduction));
+            sBuf_vec(frg_idx) = reinterpret_cast<VectorSmem&>(frg_smem);
           }
+          sync_fn();
+        }
+
+        // Do final smem reduction and dump to gmem workspace
+        using VectorGmem = cute::conditional_t<FinalReduction, VectorSmem volatile, VectorSmem>;
+        Tensor gBuf_vec = recast<VectorGmem>(filter(gBuf_ml(_,_,m,l)));
+        CUTLASS_PRAGMA_NO_UNROLL
+        for (int frg_idx = thread_idx; frg_idx < FragsPerRow; frg_idx += size(tiled_copy)) {
+          FragmentSmem frg_smem = reduce_smem(sBuf_frg(frg_idx), sBuf_frg(frg_idx + FragsPerRow));
+          gBuf_vec(frg_idx) = reinterpret_cast<VectorSmem&>(frg_smem);
         }
+        sync_fn();
+      }
 
-        // Reset the registers to the reduction identity
-        fill(tCrRow, params.reduction_identity);
+      //
+      // 3. Increment atomic counters to signal final gmem reduction
+      //
+      if constexpr (not IsAtomic && FinalReduction) {
+        // Ensure gmem writes are visible to other threads before incrementing counter
+        __threadfence();
+        sync_fn();
+        // Collective thread 0 increments atomic tile counter and copies value to smem
+        int* prev_tile_count = reinterpret_cast<int*>(raw_pointer_cast(smem_buffer.data()));
+        if (thread_idx == 0) {
+          *prev_tile_count = atomicAdd(&params.tile_counters[n], 1);
+        }
+        sync_fn();
+        // Broadcast tile count to other threads in CTA and determine final reduction status
+        do_final_reduction = *prev_tile_count == size<2>(gBuf_ml) * size<3>(gBuf_ml) - 1;
+        sync_fn();
       }
     }
 
+    CUTLASS_DEVICE void
+    end() {
+      //
+      // 4. Do final gmem reduction if necessary
+      //
+      if constexpr (not IsAtomic && FinalReduction) {
+        if (not do_final_reduction) {
+          return;
+        }
+
+        auto& [ref_src, tCrRow, tCcRow, gRow_l, cRow, gBuf_ml, sBuf_layout,
+          lane_layout_MN, lane_mn, warp_layout_MN, warp_mn,
+          tile_coord_mnkl, residue_mn, epi_tile, tiled_copy, thread_idx] = args_tuple;
+
+        using ReduceOutput = GmemReduceFn<ElementCompute>;
+        using ConvertOutput = NumericConverter<ElementOutput, ElementCompute, RoundStyle>;
+        ReduceOutput reduce_output{};
+        ConvertOutput convert_output{};
+
+        // Reduction over batches
+        if (size<2>(stride(gRow_l)) == 0) {
+          CUTLASS_PRAGMA_NO_UNROLL
+          for (int n = thread_idx; n < size<1>(gBuf_ml); n += size(tiled_copy)) {
+            Tensor tRgBuf_ml = gBuf_ml(_0{},n,_,_);
+            ElementCompute output = tRgBuf_ml(_0{});
+            CUTLASS_PRAGMA_NO_UNROLL
+            for (int ml = 1; ml < size(tRgBuf_ml); ++ml) {
+              output = reduce_output(output, tRgBuf_ml(ml));
+            }
+            if (elem_less(cRow(_0{},n), residue_mn)) {
+              gRow_l(_0{},n,_0{}) = convert_output(output);
+            }
+          }
+        }
+        // No reduction over batches
+        else {
+          CUTLASS_PRAGMA_NO_UNROLL
+          for (int n = thread_idx; n < size<1>(gBuf_ml); n += size(tiled_copy)) {
+            bool do_store = elem_less(cRow(_0{},n), residue_mn);
+            CUTLASS_PRAGMA_NO_UNROLL
+            for (int l = 0; l < size<3>(gBuf_ml); ++l) {
+              Tensor tRgBuf_m = gBuf_ml(_0{},n,_,l);
+              ElementCompute output = tRgBuf_m(_0{});
+              CUTLASS_PRAGMA_NO_UNROLL
+              for (int m = 1; m < size(tRgBuf_m); ++m) {
+                output = reduce_output(output, tRgBuf_m(m));
+              }
+              if (do_store) {
+                gRow_l(_0{},n,l) = convert_output(output);
+              }
+            }
+          }
+        }
+
+      }
+    }
   };
 
   template <
     bool ReferenceSrc, // do register tensors reference the src or dst layout of the tiled copy
     class... Args
   >
   CUTLASS_DEVICE auto
   get_consumer_store_callbacks(ConsumerStoreArgs<Args...> const& args) {
+    Layout ref_layout_MN = [&] () {
+      if constexpr (ReferenceSrc) { return get<0>(args.tiled_copy.get_layoutS_MN()); }
+      else                        { return get<0>(args.tiled_copy.get_layoutD_MN()); }
+    }();                                                                                         // tile_mn -> tv_idx
 
+    // Get the MN layout + coord of lanes to determine shuffle reduction iterations
+    using _W = Int<decltype(args.tiled_copy)::TiledNumThr::value / NumThreadsPerWarp>;
+    Layout tv2lane = Layout<Shape<Int<NumThreadsPerWarp>,_W,_1>,Stride<_1,_0,_0>>{};            //   tv_idx -> lane_idx
+    Layout ref2lane = composition(tv2lane, ref_layout_MN);                                      //  tile_mn -> lane_idx
+    Layout lane_layout_MN = make_layout(filter(get<0>(ref2lane)), filter(get<1>(ref2lane)));    //  lane_mn -> lane_idx
+    Layout inv_lane_layout_MN = right_inverse(lane_layout_MN);                                  // lane_idx -> lane_mn
+    int lane_idx = canonical_lane_idx();
+    auto lane_mn = idx2crd(inv_lane_layout_MN(lane_idx), shape(lane_layout_MN));
+
+    // Get the MN layout + coord of warps to determine smem reduction iterations
+    Layout tv2warp = Layout<Shape<Int<NumThreadsPerWarp>,_W,_1>,Stride<_0,_1,_0>>{};            //   tv_idx -> warp_idx
+    Layout ref2warp = composition(tv2warp, ref_layout_MN);                                      //  tile_mn -> warp_idx
+    Layout warp_layout_MN = make_layout(filter(get<0>(ref2warp)), filter(get<1>(ref2warp)));    //  warp_mn -> warp_idx
+    Layout inv_warp_layout_MN = right_inverse(warp_layout_MN);                                  // warp_idx -> warp_mn
+
+    int warp_idx = args.thread_idx / NumThreadsPerWarp;
+    auto warp_mn = idx2crd(inv_warp_layout_MN(warp_idx), shape(warp_layout_MN));
+
+    // Partition output gmem and register tensors
+    auto [tile_M, tile_N, tile_K] = args.tile_shape_mnk;
     auto [M, N, K, L] = args.problem_shape_mnkl;
-    Tensor mRow = make_tensor(make_gmem_ptr(params.ptr_row), make_shape(M,N,L), params.dRow);
+    auto [m, n, k, l] = args.tile_coord_mnkl;
+
+    Tensor mRow = make_tensor(make_gmem_ptr<ElementOutput>(params.ptr_row), make_shape(M,N,L), params.dRow); // (M,N,L)
+    Tensor gRow_l = local_tile(mRow, take<0,2>(args.tile_shape_mnk), make_coord(m,n,_));             // (CTA_M,CTA_N,L)
     Tensor tCgRow = sm90_partition_for_epilogue<ReferenceSrc>(                         // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
-      mRow, args.tile_shape_mnk, args.tile_coord_mnkl, args.epi_tile, args.tiled_copy, args.thread_idx);
-    Tensor tCrRow = make_tensor_like<ElementCompute>(tCgRow(_,_,_,_,_0{}));            // (CPY,CPY_M,CPY_N,EPI_M)
+      gRow_l(_,_,l), args.epi_tile, args.tiled_copy, args.thread_idx);
+    Tensor tCrRow = make_tensor_like<ElementCompute>(tCgRow);                          // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
+
     fill(tCrRow, params.reduction_identity);
 
-    return ConsumerStoreCallbacks<decltype(tCrRow),decltype(tCgRow),decltype(args.tCcD),decltype(args.residue_mn)>(
-      cute::move(tCrRow), cute::move(tCgRow), args.tCcD, args.residue_mn, params);
+    // Partition gmem+smem reduction buffer tensors
+    Layout gBuf_layout = make_layout(take<0,2>(args.tile_shape_mnk), make_stride(_0{}, _1{}));
+    auto block_shape = ceil_div(make_shape(M,N,L), shape(gBuf_layout)); // (M_CNT, N_CNT, L_CNT)
+
+    // Let the M_CNT (the num of partial reduction results) become the outer mode
+    Layout block_layout = make_layout(block_shape, make_stride(get<1>(block_shape), _1{}, get<0>(block_shape) * get<1>(block_shape)));
+    Layout mBuf_layout = blocked_product(gBuf_layout, block_layout);
+    Tensor mBuf = make_tensor(make_gmem_ptr(params.reduction_buffer), mBuf_layout);                // (ceil_M,ceil_N,L)
+    Tensor gBuf_ml = local_tile(mBuf, take<0,2>(args.tile_shape_mnk), make_coord(_,n,_));     // (CTA_M,CTA_N,REST_M,L)
+    Layout sBuf_layout = blocked_product(gBuf_layout,                                          // (CTA_M,CTA_N,WARPS_M)
+      make_layout(make_shape(_1{},_1{},size<0>(warp_layout_MN))));
+
+    auto args_tuple = make_tuple(
+        bool_constant<ReferenceSrc>{}, cute::move(tCrRow), args.tCcD, gRow_l, args.cD, gBuf_ml, sBuf_layout,
+        lane_layout_MN, lane_mn, warp_layout_MN, warp_mn,
+        args.tile_coord_mnkl, args.residue_mn, args.epi_tile, args.tiled_copy, args.thread_idx);
+    return ConsumerStoreCallbacks<decltype(args_tuple)>(cute::move(args_tuple), params);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Col vector reduction
 template <
   template <class> class RegReduceFn,
+  template <class> class ShuffleReduceFn,
   template <class> class GmemReduceFn,
   int Stages,
   class CtaTileShapeMNK,
   class ElementOutput,
   class ElementCompute,
   FloatRoundStyle RoundStyle,
   class StrideMNL = Stride<_1,_0,_0>,
   int Alignment = 128 / sizeof_bits_v<ElementOutput>,
   bool EnableNullptr = true, // Noop on nullptr params
   // If this is false, ptr_col is assumed to point to a compact m-major (round_nearest(M,CTA_M), ceil_div(N,CTA_N), L)
   // tensor of ElementCompute. It is the user's responsibility to reduce this to a (M, L) tensor of ElementOutput
-  bool FinalReduction = true
+  bool FinalReduction = true,
+  // False means skip OOB predication if OOB inputs are known to be the reduction identity
+  bool VisitCheckOOB = true
 >
 struct Sm90ColReduction {
 private:
   static_assert(Stages == 0, "Smem usage not supported yet");
   static_assert(Alignment * sizeof_bits_v<ElementOutput> % 128 == 0, "sub-16B alignment not supported yet");
   static_assert(
     (cute::is_same_v<StrideMNL, Stride<_1,_0, _0>>) || // col vector reduction, e.g. per-row sum over all batches
@@ -694,22 +963,20 @@
     int* tile_counters = nullptr;
   };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     ElementCompute* reduction_buffer;
-    int* tile_counters;
+    int* tile_counters = nullptr;
     if constexpr (IsAtomic) {
       reduction_buffer = nullptr;
-      tile_counters = nullptr;
     }
     else if constexpr (not FinalReduction) {
       reduction_buffer = reinterpret_cast<ElementCompute*>(args.ptr_col);
-      tile_counters = nullptr;
     }
     else {
       auto [M, N, K, L] = problem_shape;
       auto [tile_M, tile_N, tile_K] = CtaTileShapeMNK{};
       size_t tile_counters_offset = product(ceil_div(make_shape(M,N,L), make_shape(tile_M, tile_N))) * tile_M * sizeof(ElementCompute);
       tile_counters_offset = round_nearest(tile_counters_offset, sizeof(int));
 
@@ -744,20 +1011,21 @@
     workspace_size += cute::ceil_div(M, tile_M) * sizeof(int);
 
     return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     if constexpr (IsAtomic) {
       auto [M, N, K, L] = problem_shape;
       Layout mCol_layout = make_layout(make_shape(M,N,L), args.dCol);
       if (args.ptr_col != nullptr) {
-        return fill_workspace(args.ptr_col, ElementOutput(args.reduction_identity), cosize(mCol_layout), stream);
+        return fill_workspace(args.ptr_col, ElementOutput(args.reduction_identity), cosize(mCol_layout), stream, cuda_adapter);
       }
       return Status::kSuccess;
     }
 
     auto [M, N, K, L] = problem_shape;
     auto [tile_M, tile_N, tile_K] = CtaTileShapeMNK{};
     size_t tile_counters_offset = product(ceil_div(make_shape(M,N,L), make_shape(tile_M, tile_N))) * tile_M * sizeof(ElementCompute);
@@ -824,17 +1092,25 @@
       using ReduceInput = RegReduceFn<ElementCompute>;
       ConvertInput convert_input{};
       ReduceInput reduce_input{};
 
       Array frg_I = convert_input(frg_input);
       CUTLASS_PRAGMA_UNROLL
       for (int i = 0; i < FragmentSize; ++i) {
-        if (elem_less(tCcCol_mn(epi_v * FragmentSize + i), residue_mn)) {
-          ElementCompute& tCrCol_vmn = tCrCol_mn(epi_v * FragmentSize + i);
-          tCrCol_vmn = reduce_input(tCrCol_vmn, frg_I[i]);
+        if constexpr (VisitCheckOOB) {
+          if (elem_less(tCcCol_mn(epi_v * FragmentSize + i), residue_mn)) {
+            ElementCompute& tCrCol_vmn = tCrCol_mn(epi_v * FragmentSize + i);
+            tCrCol_vmn = reduce_input(tCrCol_vmn, frg_I[i]);
+          }
+        }
+        else {
+          if (elem_less(tCcCol_mn(epi_v * FragmentSize + i), residue_mn)) {
+            ElementCompute& tCrCol_vmn = tCrCol_mn(epi_v * FragmentSize + i);
+            tCrCol_vmn = reduce_input(tCrCol_vmn, frg_I[i]);
+          }
         }
       }
 
       return frg_input;
     }
 
     template <class STensor, class SyncFn>
@@ -862,15 +1138,15 @@
         return;
       }
 
       //
       // 1. Warp shuffle reduction
       //
       using FragmentShuffle = Array<ElementCompute, sizeof(uint64_t) / sizeof(ElementCompute)>;
-      using ReduceShuffle = RegReduceFn<FragmentShuffle>;
+      using ReduceShuffle = ShuffleReduceFn<FragmentShuffle>;
       ReduceShuffle reduce_shuffle{};
       Tensor tCrCol_frg = recast<FragmentShuffle>(filter(tCrCol));
       CUTLASS_PRAGMA_UNROLL
       for (int reduction_cols = size<1>(lane_layout_MN) / 2; reduction_cols > 0; reduction_cols /= 2) {
         CUTLASS_PRAGMA_UNROLL
         for (int frg_idx = 0; frg_idx < size(tCrCol_frg); ++frg_idx) {
           uint64_t frg_shfl = reinterpret_cast<uint64_t&>(tCrCol_frg(frg_idx));
@@ -909,15 +1185,15 @@
       }
 
       //
       // 2. One warp in N, skip threadblock smem reduction
       //
       else if constexpr (decltype(size<1>(warp_layout_MN))::value <= 1) {
         // Dump warp reduction to gmem workspace
-        using ElementGmem = conditional_t<FinalReduction, ElementCompute volatile, ElementCompute>;
+        using ElementGmem = cute::conditional_t<FinalReduction, ElementCompute volatile, ElementCompute>;
         Tensor tCgBuf = sm90_partition_for_epilogue<ReferenceSrc>(gBuf_nl(_,_,n,l), epi_tile, tiled_copy, thread_idx);
         if (is_reduced_lane) {
           // Filter so we don't issue redundant copies over stride-0 modes
           // (only works if 0-strides are in same location, which is by construction)
           copy_aligned(filter(tCrCol), recast<ElementGmem>(filter(tCgBuf)));
         }
         sync_fn();
@@ -937,15 +1213,15 @@
         if (is_reduced_lane) {
           // Filter so we don't issue redunant copies over stride-0 modes
           // (only works if 0-strides are in same location, which is by construction)
           copy_aligned(filter(tCrCol), filter(tCsBuf));
         }
         sync_fn();
 
-        constexpr int SmemFragSize = cute::max(1, sizeof(uint32_t) / sizeof(ElementCompute));
+        constexpr int SmemFragSize = cute::max(size_t{1}, sizeof(uint32_t) / sizeof(ElementCompute));
         using FragmentSmem = Array<ElementCompute, SmemFragSize>;
         using VectorSmem = uint_bit_t<sizeof_bits_v<FragmentSmem>>;
         using ReduceSmem = GmemReduceFn<FragmentSmem>;
         ReduceSmem reduce_smem{};
 
         Tensor sBuf_frg = recast<FragmentSmem>(filter_zeros(sBuf));
         Tensor sBuf_vec = recast<VectorSmem>(filter_zeros(sBuf));
@@ -960,15 +1236,15 @@
             FragmentSmem frg_smem = reduce_smem(sBuf_frg(frg_idx), sBuf_frg(frg_idx + FragsPerReduction));
             sBuf_vec(frg_idx) = reinterpret_cast<VectorSmem&>(frg_smem);
           }
           sync_fn();
         }
 
         // Do final smem reduction and dump to gmem workspace
-        using VectorGmem = conditional_t<FinalReduction, VectorSmem volatile, VectorSmem>;
+        using VectorGmem = cute::conditional_t<FinalReduction, VectorSmem volatile, VectorSmem>;
         Tensor gBuf_vec = recast<VectorGmem>(filter(gBuf_nl(_,_,n,l)));
         CUTLASS_PRAGMA_NO_UNROLL
         for (int frg_idx = thread_idx; frg_idx < FragsPerCol; frg_idx += size(tiled_copy)) {
           FragmentSmem frg_smem = reduce_smem(sBuf_frg(frg_idx), sBuf_frg(frg_idx + FragsPerCol));
           gBuf_vec(frg_idx) = reinterpret_cast<VectorSmem&>(frg_smem);
         }
         sync_fn();
@@ -1046,26 +1322,14 @@
             }
           }
         }
 
       }
     }
 
-    CUTLASS_DEVICE bool
-    is_reduction_buffer_needed(int epi_m, int epi_n, bool is_last_iteration) const {
-      auto const& [ref_src, tCrCol, tCcCol, gCol_l, cCol, gBuf_nl, sBuf_layout,
-                    lane_layout_MN, lane_mn, warp_layout_MN, warp_mn,
-                    tile_coord_mnkl, residue_mn, epi_tile, tiled_copy, thread_idx] = args_tuple;
-
-      return (not IsAtomic &&                                  // atomic reduction doesn't use smem
-              is_last_iteration &&                             // smem reduction happens after epilogue loop
-              (decltype(size<1>(warp_layout_MN))::value > 1 || // smem reduction happens when multiple warps are in N
-               FinalReduction));                               // smem is used to broadcast tile counters for final reduction
-    }
-
   };
 
   template <
     bool ReferenceSrc, // do register tensors reference the src or dst layout of the tiled copy
     class... Args
   >
   CUTLASS_DEVICE auto
@@ -1092,14 +1356,15 @@
     int warp_idx = args.thread_idx / NumThreadsPerWarp;
     auto warp_mn = idx2crd(inv_warp_layout_MN(warp_idx), shape(warp_layout_MN));
 
     // Partition output gmem and register tensors
     auto [tile_M, tile_N, tile_K] = args.tile_shape_mnk;
     auto [M, N, K, L] = args.problem_shape_mnkl;
     auto [m, n, k, l] = args.tile_coord_mnkl;
+
     Tensor mCol = make_tensor(make_gmem_ptr<ElementOutput>(params.ptr_col), make_shape(M,N,L), params.dCol); // (M,N,L)
     Tensor gCol_l = local_tile(mCol, take<0,2>(args.tile_shape_mnk), make_coord(m,n,_));             // (CTA_M,CTA_N,L)
     Tensor tCgCol = sm90_partition_for_epilogue<ReferenceSrc>(                         // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
                       gCol_l(_,_,l), args.epi_tile, args.tiled_copy, args.thread_idx);
     Tensor tCrCol = make_tensor_like<ElementCompute>(tCgCol);                          // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
     fill(tCrCol, params.reduction_identity);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/fusion/sm90_visitor_tma_warpspecialized.hpp`

 * *Files 12% similar despite different names*

```diff
@@ -95,15 +95,18 @@
     Tensor<Engine, LayoutMNL> mT,  // (M,N,L)
     TileShapeMNK tile_shape_mnk,   // (CTA_M,CTA_N,CTA_K)
     TileCoordMNKL tile_coord_mnkl, // (m,n,k,l)
     EpilogueTile epi_tile,         // (EPI_TILE_M,EPI_TILE_N)
     TiledCopy tiled_copy,
     int thread_idx) {
   auto [m, n, k, l] = tile_coord_mnkl;
-  Tensor cT = local_tile(mT, take<0,2>(tile_shape_mnk), make_coord(m,n,l));                            // (CTA_M,CTA_N)
+  auto coord_shape =
+      make_coord(m, n, l)
+    ;
+  Tensor cT = local_tile(mT, take<0,2>(tile_shape_mnk), coord_shape);                                  // (CTA_M,CTA_N)
   Tensor tCcT =
     sm90_partition_for_epilogue<ReferenceSrc>(cT, epi_tile, tiled_copy, thread_idx);   // (CPY,CPY_M,CPY_N,EPI_M,EPI_N)
 
   return tCcT;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -130,15 +133,15 @@
   CUTLASS_DEVICE
   ProducerLoadArgs(
       ProblemShapeMNKL problem_shape_mnkl,
       TileShapeMNK tile_shape_mnk,
       TileCoordMNKL tile_coord_mnkl,
       ResidueMN residue_mn,
       EpilogueTile epi_tile,
-      int thread_idx) 
+      int thread_idx)
   : problem_shape_mnkl(problem_shape_mnkl),
     tile_shape_mnk(tile_shape_mnk),
     tile_coord_mnkl(tile_coord_mnkl),
     residue_mn(residue_mn),
     epi_tile(epi_tile),
     thread_idx(thread_idx) {}
 };
@@ -173,15 +176,15 @@
       TileCoordMNKL tile_coord_mnkl,
       ResidueMN residue_mn,
       EpilogueTile epi_tile,
       TiledCopy tiled_copy,
       int thread_idx,
       CoordTensor cD,
       ThrCoordTensor tCcD,
-      ThrSrcTensor const& tCrC) 
+      ThrSrcTensor const& tCrC)
   : problem_shape_mnkl(problem_shape_mnkl),
     tile_shape_mnk(tile_shape_mnk),
     tile_coord_mnkl(tile_coord_mnkl),
     residue_mn(residue_mn),
     epi_tile(epi_tile),
     tiled_copy(tiled_copy),
     thread_idx(thread_idx),
@@ -198,18 +201,24 @@
   using Arguments = tuple<typename Ops::Arguments...>;
   // Device side fusion params (Kernel-entry API)
   using Params = tuple<typename Ops::Params...>;
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
+    uint8_t* op_workspace = reinterpret_cast<uint8_t*>(workspace);
     return transform_apply(tuple<Ops...>{}, args,
       [&] (auto&& op, auto const& op_args) {
         using Op = cute::remove_cvref_t<decltype(op)>;
-        return Op::to_underlying_arguments(problem_shape, op_args, workspace);
+        auto ret = Op::to_underlying_arguments(problem_shape, op_args, op_workspace);
+        if (op_workspace != nullptr) {
+          size_t op_workspace_size = Op::get_workspace_size(problem_shape, op_args);
+          op_workspace += round_nearest(op_workspace_size, MinWorkspaceAlignment);
+        }
+        return ret;
       },
       [] (auto&&... op_params) { return cute::make_tuple(op_params...); }
     );
   }
 
   template <class ProblemShape>
   static size_t
@@ -224,34 +233,35 @@
         return (0 + ... + op_workspace_size);
       }
     );
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* op_workspace = reinterpret_cast<uint8_t*>(workspace);
     return transform_apply(tuple<Ops...>{}, args,
       // Initialize each operation's workspace, stopping at the first error
       [&] (auto&& op, auto const& op_args) {
         if (status != Status::kSuccess) {
           return status;
         }
 
         using Op = cute::remove_cvref_t<decltype(op)>;
-        status = Op::initialize_workspace(problem_shape, op_args, op_workspace, stream);
+        status = Op::initialize_workspace(problem_shape, op_args, op_workspace, stream, cuda_adapter);
         if (op_workspace != nullptr) {
           size_t op_workspace_size = Op::get_workspace_size(problem_shape, op_args);
           op_workspace += round_nearest(op_workspace_size, MinWorkspaceAlignment);
         }
         return status;
       },
       // Return the final status
-      [&] (auto const&...) { return status; }
+      [&] (auto const&...ops) { return status; }
     );
   }
 
   CUTLASS_HOST_DEVICE
   Sm90VisitorImplBase() {}
 
   CUTLASS_HOST_DEVICE
@@ -292,29 +302,29 @@
   // Is a specialized warp for producer TMA loads needed
   // e.g. Aux tensor loads, broadcasts using TMA bulk copy
   // This condition cannot change between work tiles because it is used
   // to determine whether the load warp should exit early or not
   // e.g. for batched beta this must always be true regardless of current batch idx
   CUTLASS_DEVICE bool
   is_producer_load_needed() const {
-    return apply(ops,
+    return cute::apply(ops,
       [] (auto const&... op) {
         return (false || ... || op.is_producer_load_needed());
       }
     );
   }
 
   // Is a producer TMA load specifically for C needed
   // If this is true then is_producer_load_needed must also be true
   // This condition can change between work tiles because it is only used
   // to determine whether the TMA and smem loads for C of a given tile should happen
   // e.g. for batched beta this can be false depending on current batch idx
   CUTLASS_DEVICE bool
   is_C_load_needed() const {
-    return apply(ops,
+    return cute::apply(ops,
       [] (auto const&... op) {
         return (false || ... || op.is_C_load_needed());
       }
     );
   }
 
   //
@@ -413,57 +423,49 @@
     // Perform the fused elementwise computation
     template <typename ElementAccumulator, typename... ElementInputs, int FragmentSize>
     CUTLASS_DEVICE auto // returns an Array
     visit(Array<ElementAccumulator, FragmentSize> const& frg_acc, int epi_v, int epi_m, int epi_n,
           Array<ElementInputs, FragmentSize> const&... frg_inputs) // depends on the N-naryness of the op
       = delete; // Must be implemented for each operation
 
-    // After visit call, before smem async fence. Smem stores usually performed here.
-    // Upon exit, all smem stores for TMA must have been issued
+    // After visit call. Smem reductions usually performed here
+    // reduction_buffer is an arbitrary smem tensor that can be used for workspace
+    // It is each nodes reponsibility to assert that this buffer is sufficiently sized
+    // and to ensure that this buffer is no longer needed upon callback exit
+    // i.e. results are synchronized and no longer in the reduction buffer
+    template <class STensor, class SyncFn>
     CUTLASS_DEVICE void
-    postvisit(int epi_m, int epi_n, int store_iteration, bool issue_smem_store) {
+    reduce(STensor&& reduction_buffer, SyncFn const& sync_fn, int epi_m, int epi_n, bool is_last_iteration) {
       for_each(callbacks_tuple,
         [&] (auto& callbacks) {
-          callbacks.postvisit(epi_m, epi_n, store_iteration, issue_smem_store);
+          callbacks.reduce(reduction_buffer, sync_fn, epi_m, epi_n, is_last_iteration);
         }
       );
     }
 
-    // After async fence, before TMA store commit. Aux stores usually performed here
-    // Upon exit, all TMA stores for this subtile must have been issued
+    // After reduce call, before smem async fence. Smem stores usually performed here.
+    // Upon exit, all smem stores for TMA must have been issued
     CUTLASS_DEVICE void
-    step(int epi_m, int epi_n, int store_iteration, bool issue_tma_store) {
+    postreduce(int epi_m, int epi_n, int store_iteration, bool issue_smem_store) {
       for_each(callbacks_tuple,
         [&] (auto& callbacks) {
-          callbacks.step(epi_m, epi_n, store_iteration, issue_tma_store);
+          callbacks.postreduce(epi_m, epi_n, store_iteration, issue_smem_store);
         }
       );
     }
 
-    // After TMA store commit. Smem reductions usually performed here
-    // reduction_buffer is an arbitrary smem tensor that can be used for workspace
-    // It is each nodes reponsibility to assert that this buffer is sufficiently sized
-    // and to ensure that this buffer is no longer needed upon callback exit
-    // i.e. results are synchronized and no longer in the reduction buffer
-    template <class STensor, class SyncFn>
+    // After smem async fence, before TMA store commit. Aux stores usually performed here
+    // Upon exit, all TMA stores for this subtile must have been issued
+    // Because of the TMA store delay optimization, this entry point must ONLY be used for TMA stores
+    // other gmem stores can be placed in the reduce or postreduce entry points
     CUTLASS_DEVICE void
-    reduce(STensor&& reduction_buffer, SyncFn const& sync_fn, int epi_m, int epi_n, bool is_last_iteration) {
+    tma_store(int epi_m, int epi_n, int store_iteration, bool issue_tma_store) {
       for_each(callbacks_tuple,
         [&] (auto& callbacks) {
-          callbacks.reduce(reduction_buffer, sync_fn, epi_m, epi_n, is_last_iteration);
-        }
-      );
-    }
-
-    // Collective can query this to determine whether a buffer needs to be freed for reduction
-    CUTLASS_DEVICE bool
-    is_reduction_buffer_needed(int epi_m, int epi_n, bool is_last_iteration) const {
-      return apply(callbacks_tuple,
-        [&] (auto const&... callbacks) {
-          return (false || ... || callbacks.is_reduction_buffer_needed(epi_m, epi_n, is_last_iteration));
+          callbacks.tma_store(epi_m, epi_n, store_iteration, issue_tma_store);
         }
       );
     }
 
     // Exit of subtile store loop. Gmem reductions usually performed here.
     CUTLASS_DEVICE void
     end() {
@@ -588,18 +590,17 @@
 
     template <typename ElementAccumulator, int FragmentSize>
     CUTLASS_DEVICE auto
     visit(Array<ElementAccumulator, FragmentSize> const& frg_acc, int epi_v, int epi_m, int epi_n) {
       Array frg_input = get<0>(callbacks_tuple).visit(frg_acc, epi_v, epi_m, epi_n);
 
       constexpr int Rm2 = sizeof...(AuxOutTrees);
-      cute::detail::for_sequence(make_seq<Rm2>{}, // restrict the sequence to aux out trees
-        [&] (auto&& _I) {
-          constexpr int i = remove_cvref_t<decltype(_I)>::value;
-          get<i+1>(callbacks_tuple).visit(frg_input, epi_v, epi_m, epi_n);
+      cute::for_each(make_seq<Rm2>{}, // restrict the sequence to aux out trees
+        [&] (auto I) {
+          get<I+1>(callbacks_tuple).visit(frg_input, epi_v, epi_m, epi_n);
         }
       );
 
       return get<Rm2+1>(callbacks_tuple).visit(frg_input, epi_v, epi_m, epi_n);
     }
   };
 
@@ -660,15 +661,15 @@
             },
             // Get inputs in the sequence given by the children indices of the current op
             edge_seq
           );
           return frg_compute; // unused
         },
         // Visit the last op
-        [&] (auto const&...) {
+        [&] (auto const&...ops) {
           return cute::detail::apply(frg_compute_tuple,
             // Compute the last op with children inputs
             [&] (auto const&... frg_inputs) {
               return get<Rm1>(callbacks_tuple).visit(frg_acc, epi_v, epi_m, epi_n, frg_inputs...);
             },
             // Get inputs in the sequence given by the children indices of the last op
             get<Rm1>(EdgeTuple{})
@@ -730,20 +731,21 @@
     workspace_size = round_nearest(workspace_size, MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
 
-    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream);
+    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op0::get_workspace_size(problem_shape, args.op_0);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
@@ -778,17 +780,20 @@
     typename Op0::Params op_0;
     typename Op1::Params op_1;
   };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
+    size_t op_0_workspace_size = Op0::get_workspace_size(problem_shape, args.op_0);
+    uint8_t* op_0_workspace = reinterpret_cast<uint8_t*>(workspace);
+    uint8_t* op_1_workspace = op_0_workspace + op_0_workspace_size;
     return Params{
-      Op0::to_underlying_arguments(problem_shape, args.op_0, workspace),
-      Op1::to_underlying_arguments(problem_shape, args.op_1, workspace)
+      Op0::to_underlying_arguments(problem_shape, args.op_0, op_0_workspace),
+      Op1::to_underlying_arguments(problem_shape, args.op_1, op_1_workspace)
     };
   }
 
   template <class ProblemShape>
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     size_t workspace_size = 0;
@@ -799,27 +804,28 @@
     workspace_size = round_nearest(workspace_size, MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
 
-    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream);
+    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op0::get_workspace_size(problem_shape, args.op_0);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream);
+    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op1::get_workspace_size(problem_shape, args.op_1);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
@@ -858,18 +864,23 @@
     typename Op1::Params op_1;
     typename Op2::Params op_2;
   };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
+    size_t op_0_workspace_size = Op0::get_workspace_size(problem_shape, args.op_0);
+    size_t op_1_workspace_size = Op1::get_workspace_size(problem_shape, args.op_1);
+    uint8_t* op_0_workspace = reinterpret_cast<uint8_t*>(workspace);
+    uint8_t* op_1_workspace = op_0_workspace + op_0_workspace_size;
+    uint8_t* op_2_workspace = op_1_workspace + op_1_workspace_size;
     return Params{
-      Op0::to_underlying_arguments(problem_shape, args.op_0, workspace),
-      Op1::to_underlying_arguments(problem_shape, args.op_1, workspace),
-      Op2::to_underlying_arguments(problem_shape, args.op_2, workspace)
+      Op0::to_underlying_arguments(problem_shape, args.op_0, op_0_workspace),
+      Op1::to_underlying_arguments(problem_shape, args.op_1, op_1_workspace),
+      Op2::to_underlying_arguments(problem_shape, args.op_2, op_2_workspace)
     };
   }
 
   template <class ProblemShape>
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     size_t workspace_size = 0;
@@ -883,34 +894,35 @@
     workspace_size = round_nearest(workspace_size, MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
 
-    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream);
+    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op0::get_workspace_size(problem_shape, args.op_0);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream);
+    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op1::get_workspace_size(problem_shape, args.op_1);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op2::initialize_workspace(problem_shape, args.op_2, workspace_ptr + workspace_offset, stream);
+    status = Op2::initialize_workspace(problem_shape, args.op_2, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op2::get_workspace_size(problem_shape, args.op_2);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
@@ -953,19 +965,26 @@
     typename Op2::Params op_2;
     typename Op3::Params op_3;
   };
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
+    size_t op_0_workspace_size = Op0::get_workspace_size(problem_shape, args.op_0);
+    size_t op_1_workspace_size = Op1::get_workspace_size(problem_shape, args.op_1);
+    size_t op_2_workspace_size = Op2::get_workspace_size(problem_shape, args.op_2);
+    uint8_t* op_0_workspace = reinterpret_cast<uint8_t*>(workspace);
+    uint8_t* op_1_workspace = op_0_workspace + op_0_workspace_size;
+    uint8_t* op_2_workspace = op_1_workspace + op_1_workspace_size;
+    uint8_t* op_3_workspace = op_2_workspace + op_2_workspace_size;
     return Params{
-      Op0::to_underlying_arguments(problem_shape, args.op_0, workspace),
-      Op1::to_underlying_arguments(problem_shape, args.op_1, workspace),
-      Op2::to_underlying_arguments(problem_shape, args.op_2, workspace),
-      Op3::to_underlying_arguments(problem_shape, args.op_3, workspace)
+      Op0::to_underlying_arguments(problem_shape, args.op_0, op_0_workspace),
+      Op1::to_underlying_arguments(problem_shape, args.op_1, op_1_workspace),
+      Op2::to_underlying_arguments(problem_shape, args.op_2, op_2_workspace),
+      Op3::to_underlying_arguments(problem_shape, args.op_3, op_3_workspace)
     };
   }
 
   template <class ProblemShape>
   static size_t
   get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
     size_t workspace_size = 0;
@@ -982,41 +1001,42 @@
     workspace_size = round_nearest(workspace_size, MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   template <class ProblemShape>
   static cutlass::Status
-  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream) {
+  initialize_workspace(ProblemShape const& problem_shape, Arguments const& args, void* workspace, cudaStream_t stream,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
 
-    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream);
+    status = Op0::initialize_workspace(problem_shape, args.op_0, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op0::get_workspace_size(problem_shape, args.op_0);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream);
+    status = Op1::initialize_workspace(problem_shape, args.op_1, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op1::get_workspace_size(problem_shape, args.op_1);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op2::initialize_workspace(problem_shape, args.op_2, workspace_ptr + workspace_offset, stream);
+    status = Op2::initialize_workspace(problem_shape, args.op_2, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op2::get_workspace_size(problem_shape, args.op_2);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = Op3::initialize_workspace(problem_shape, args.op_3, workspace_ptr + workspace_offset, stream);
+    status = Op3::initialize_workspace(problem_shape, args.op_3, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += Op3::get_workspace_size(problem_shape, args.op_3);
     workspace_offset = round_nearest(workspace_offset, MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/activation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h`

 * *Files 2% similar despite different names*

```diff
@@ -62,81 +62,82 @@
     return value;
   }
 };
 
 template <typename T, int N>
 struct Identity<Array<T, N> > {
   CUTLASS_HOST_DEVICE
-  Array<T, N> operator()(Array<T, N> const &value) const {
+  Array<T, N> operator()(Array<T, N> value) const {
     return value;
   }
 };
 
 /// Scale operator
 template <typename T>
 struct Scale {
   struct Arguments {
+    using scale_type = T;
     T scale = T(1);
   };
 
   CUTLASS_HOST_DEVICE
-  T operator()(T const& value, T const& scale) const {
+  T operator()(T value, T scale) const {
     multiplies<T> mul;
     return mul(scale, value);
   }
 
   CUTLASS_HOST_DEVICE
-  T operator()(T const& value, Arguments const& args = Arguments()) const {
+  T operator()(T value, Arguments args = Arguments()) const {
     return this->operator()(value, args.scale);
   }
 };
 
 template <typename T, int N>
 struct Scale<Array<T, N>> {
   using Arguments = typename Scale<T>::Arguments;
 
   CUTLASS_HOST_DEVICE
-  Array<T, N> operator()(Array<T, N> const& values, T const& scale) const {
+  Array<T, N> operator()(Array<T, N> values, T scale) const {
     multiplies<Array<T, N>> mul;
     return mul(scale, values);
   }
 
   CUTLASS_HOST_DEVICE
-  Array<T, N> operator()(Array<T, N> const& values, Arguments const& args = Arguments()) const {
+  Array<T, N> operator()(Array<T, N> values, Arguments args = Arguments()) const {
     return this->operator()(values, args.scale);
   }
 };
 
 /// Specialization to compose other activations with a defined unary operator
 /// e.g. Scale<Identity<T>>
 template <template <class> class Activation, typename T>
 struct Scale<Activation<T>> {
   using Arguments = typename Scale<T>::Arguments;
 
   CUTLASS_HOST_DEVICE
-  T operator()(T const &value, decltype(Arguments{}.scale) const& scale) const {
+  T operator()(T value, typename Arguments::scale_type scale) const {
     multiplies<T> mul;
     Activation<T> act;
     return mul(scale, act(value));
   }
 
   CUTLASS_HOST_DEVICE
-  T operator()(T const& value, Arguments const& args = Arguments()) const {
+  T operator()(T value, Arguments args = Arguments()) const {
     return this->operator()(value, args.scale);
   }
 };
 
 /// ReLu operator - propagates NaNs
 /// Always put threshold in the right hand side of max to propagate NaN.
 template <typename T>
 struct ReLu {
   static const bool kIsHeavy = false;
 
   CUTLASS_HOST_DEVICE
-  T operator()(T const & threshold, T value) const {
+  T operator()(T threshold, T value) const {
     maximum<T> mx;
 
     return mx(value, threshold);
   }
 
   CUTLASS_HOST_DEVICE
   T operator()(T value) const {
@@ -167,15 +168,15 @@
   }
 };
 
 // Generic clamp
 template <typename T>
 struct Clamp {
   struct Arguments {
-    T lower_bound = CUTLASS_STL_NAMESPACE::numeric_limits<T>::min();
+    T lower_bound = CUTLASS_STL_NAMESPACE::numeric_limits<T>::lowest();
     T upper_bound = CUTLASS_STL_NAMESPACE::numeric_limits<T>::max();
   };
 
   CUTLASS_HOST_DEVICE
   T operator()(T const& value, T const& lower_bound, T const& upper_bound) const {
     maximum<T> mx;
     minimum<T> mn;
@@ -662,14 +663,40 @@
       y[i] = relu_op(d_t[i], d_relu[i]);
     }
 
     return y;
   }
 };
 
+/// Computes backwards pass for ReLU operator assuming d_t is the layer gradient and
+/// z is computed from the forward pass.
+template <typename T>
+struct dReLU_Z {
+  CUTLASS_HOST_DEVICE
+  T operator()(T d_t, T z) const {
+    return z < 0 ? T(0) : d_t;
+  }
+};
+
+template <typename T, int N>
+struct dReLU_Z<Array<T, N>> {
+  CUTLASS_HOST_DEVICE
+  Array<T, N> operator()(Array<T, N> const& d_t, Array<T, N> const& z) const {
+    Array<T, N> y;
+    dReLU_Z<T> relu_op;
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < N; ++i) {
+      y[i] = relu_op(d_t[i], z[i]);
+    }
+
+    return y;
+  }
+};
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace thread
 } // namespace epilogue
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/detail.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/detail.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h`

 * *Files 15% similar despite different names*

```diff
@@ -25,260 +25,204 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
-/*! \file
-  \brief Functor performing linear combination operations used by epilogues.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
 #include "cutlass/functional.h"
 #include "cutlass/numeric_conversion.h"
-#include "cutlass/platform/platform.h"
-
 #include "cutlass/epilogue/thread/activation.h"
 #include "cutlass/epilogue/thread/scale_type.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace thread {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-// If kIsHeavy is a member, use it.  Otherwise, assume that it's false.
-namespace { // (anonymous)
-template<class Op, class Enable = void>
-struct kIsHeavy_member_or_false {
-  static constexpr bool value = false;
-};
-template<class Op>
-struct kIsHeavy_member_or_false<Op, typename cutlass::platform::enable_if<Op::kIsHeavy>::type> {
-  static constexpr bool value = Op::kIsHeavy;
-};
-} // namespace (anonymous)
-
-/// This base class is meant to define the concept required of the
-/// EpilogueWithBroadcast::OutputOp
+/// Applies a linear combination operator to an array of elements.
+///
+/// D = alpha * accumulator + beta * source + uniform
+///
 template <
-  typename ElementC_,
-  typename ElementAccumulator_,
-  typename ElementCompute_,
-  typename ElementZ_,
-  typename ElementT_,
-  int ElementsPerAccess,
-  typename ElementwiseOp_ = Identity<ElementCompute_>,
-  typename BinaryOp_ = plus<ElementCompute_>,
-  bool StoreT_ = true,
-  typename ElementVector_ = ElementC_
+  typename ElementOutput_,                             ///< Data type used to load and store tensors
+  int Count,                                           ///< Number of elements computed per operation
+  typename ElementAccumulator_ = ElementOutput_,       ///< Accumulator data type
+  typename ElementCompute_ = ElementOutput_,           ///< Data type used to compute linear combination
+  ScaleType::Kind Scale = ScaleType::Default,          ///< Control Alpha and Beta scaling
+  FloatRoundStyle Round = FloatRoundStyle::round_to_nearest
 >
-class LinearCombinationBiasElementwise {
+class LinearCombinationLeakyRelu {
 public:
 
-  using ElementOutput = ElementC_;
-  using ElementC = ElementC_;
+  using ElementOutput = ElementOutput_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
-  using ElementZ = ElementZ_;
-  using ElementT = ElementT_;
-  using ElementVector = ElementVector_;
-  static int const kElementsPerAccess = ElementsPerAccess;
-  static int const kCount = kElementsPerAccess;
-
-  using ElementwiseOp = ElementwiseOp_;
-  using BinaryOp = BinaryOp_;
-
-  // Indicates that this epilogue applies only one binary operation
-  static bool const kIsSingleSource = true;
-
-  using FragmentAccumulator = Array<ElementAccumulator, kElementsPerAccess>;
-  using FragmentCompute = Array<ElementCompute, kElementsPerAccess>;
-  using FragmentC = Array<ElementC, kElementsPerAccess>;
-  using FragmentZ = Array<ElementZ, kElementsPerAccess>;
-  using FragmentT = Array<ElementT, kElementsPerAccess>;
-
-  // Definitions needed for collective epilogue
-  using FragmentSource = FragmentC;
-  using FragmentOutput = FragmentZ;
-  using ElementBias = ElementVector;
-  using FragmentBias = Array<ElementBias, kElementsPerAccess>;
-  using ActivationFunctor = ElementwiseOp;
-  static const ScaleType::Kind kScale = ScaleType::Default;
 
-  static bool const kIsHeavy = kIsHeavy_member_or_false<ElementwiseOp>::value;
+  static int const kCount = Count;
+  static const ScaleType::Kind kScale = Scale;
 
-  /// If true, the 'Z' tensor is stored
-  static bool const kStoreZ = true;
+  using FragmentOutput = Array<ElementOutput, kCount>;
+  using FragmentAccumulator = Array<ElementAccumulator, kCount>;
+  using ComputeFragment = Array<ElementCompute, kCount>;
+  using FragmentSource = Array<ElementOutput, kCount>;
 
-  /// If true, the 'T' tensor is stored
-  static bool const kStoreT = StoreT_;
+  static FloatRoundStyle const kRound = Round;
 
   /// Host-constructable parameters structure
   struct Params {
 
     ElementCompute alpha;                  ///< scales accumulators
-    ElementCompute beta;                   ///< scales source tensor
-    ElementCompute const *alpha_ptr;       ///< pointer to accumulator scalar - if not null, loads it from memory
-    ElementCompute const *beta_ptr;        ///< pointer to source scalar - if not null, loads it from memory
-
+    ElementCompute beta_bias;              ///< scales bias tensor
+    ElementCompute leaky_alpha;            ///< leaky_alpha
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
     Params(): 
       alpha(ElementCompute(1)), 
-      beta(ElementCompute(0)), 
-      alpha_ptr(nullptr), 
-      beta_ptr(nullptr) { }
+      beta_bias(ElementCompute(0)),
+      leaky_alpha(ElementCompute(1)) 
+       { }
 
     CUTLASS_HOST_DEVICE
     Params(
       ElementCompute alpha,
-      ElementCompute beta
-    ): alpha(alpha), beta(beta), alpha_ptr(nullptr), beta_ptr(nullptr) {
-
-    }
-
-    CUTLASS_HOST_DEVICE
-    Params(
-      ElementCompute alpha
-    ): alpha(alpha), beta(0), alpha_ptr(nullptr), beta_ptr(nullptr) {
+      ElementCompute beta_bias,
+      ElementCompute leaky_alpha = ElementCompute(1)
+    ): alpha(alpha), beta_bias(beta_bias), leaky_alpha(leaky_alpha) {
 
     }
 
-    CUTLASS_HOST_DEVICE
-    Params(
-      ElementCompute const *alpha_ptr,
-      ElementCompute const *beta_ptr
-    ): alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) {
-
-    }
-
-    CUTLASS_HOST_DEVICE
-    Params(
-      ElementCompute const *alpha_ptr
-    ): alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(nullptr) {
-
-    }
   };
 
 private:
 
   //
   // Data members
   //
 
   ElementCompute alpha_;
-  ElementCompute beta_;
-  bool skip_elementwise_;
+  ElementCompute beta_bias_;
+  ElementCompute leaky_alpha_recip_;
 
 public:
 
-  //
-  // Methods
-  //
-
-  /// Constructor from Params
+  /// Constructs the function object, possibly loading from pointers in host memory
   CUTLASS_HOST_DEVICE
-  LinearCombinationBiasElementwise(Params const &params) {
-
-    alpha_ = (params.alpha_ptr ? *params.alpha_ptr : params.alpha);
-    beta_ = (params.beta_ptr ? *params.beta_ptr : params.beta);
-    skip_elementwise_ = false;
+  LinearCombinationLeakyRelu(Params const &params) {
+    alpha_ = (params.alpha);
+    beta_bias_ = (params.beta_bias);
+    leaky_alpha_recip_ = (ElementCompute(params.leaky_alpha));    
   }
 
   /// Returns true if source is needed
   CUTLASS_HOST_DEVICE
   bool is_source_needed() const {
-    return beta_ != ElementCompute(0);
+    if (Scale == ScaleType::NoBetaScaling) return true;
+
+    if (Scale == ScaleType::OnlyAlphaScaling) return false;
+
+    if (Scale == ScaleType::Nothing) return false;
+
+    return beta_bias_ != ElementCompute(0);
   }
 
   /// Functionally required for serial reduction in the epilogue
   CUTLASS_HOST_DEVICE
-  void set_k_partition(int k_partition, int k_partition_count) {
+  void set_k_partition(int k_partition) {
     if (k_partition) {
-      beta_ = ElementCompute(1);
-    }
-
-    if (k_partition != k_partition_count - 1) {
-      skip_elementwise_ = true;
+      beta_bias_ = ElementCompute(1);
     }
   }
-
-  /// Applies the operation when is_source_needed() is true
   CUTLASS_HOST_DEVICE
-  void operator()(
-    FragmentZ &frag_Z,
-    FragmentT &frag_T,
-    FragmentAccumulator const &AB,
-    FragmentC const &frag_C,
-    FragmentCompute const &V) const {
-
-    ElementwiseOp elementwise_op;
-    BinaryOp binary_op;
-
-    FragmentCompute tmp_Accum = NumericArrayConverter<ElementCompute, ElementAccumulator, kElementsPerAccess>()(AB);
-    FragmentCompute tmp_C = NumericArrayConverter<ElementCompute, ElementC, kElementsPerAccess>()(frag_C);
-    FragmentCompute result_Z;
-    FragmentCompute result_T;
-
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kElementsPerAccess; ++i) {
-      ElementCompute z = binary_op(alpha_ * tmp_Accum[i] + beta_ * tmp_C[i], V[i]);
-      result_T[i] = z;
-      result_Z[i] = skip_elementwise_ ? z : elementwise_op(z);
+  void set_k_partition(int k_partition, int k_partition_count) {
+    if (k_partition) {
+      beta_bias_ = ElementCompute(1);
     }
+  }
+  
+  /// Computes linear scaling: D = alpha * accumulator + beta * source
+  CUTLASS_HOST_DEVICE
+  FragmentOutput operator()(
+    FragmentAccumulator const &accumulator, 
+    FragmentOutput const &source) const {
+
+    // Convert source to interal compute numeric type
+    NumericArrayConverter<ElementCompute, ElementOutput, kCount, Round> source_converter;
+    NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
+
+    ComputeFragment converted_source = source_converter(source);
+    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
+
+    // Perform binary operations
+    ComputeFragment intermediate;
 
-    NumericArrayConverter<ElementZ, ElementCompute, kElementsPerAccess> convert_z;
-    frag_Z = convert_z(result_Z);
+    multiplies<ComputeFragment> mul_add_source;
+    multiply_add<ComputeFragment> mul_add_accumulator;
 
-    if constexpr (kStoreT) {
-      NumericArrayConverter<ElementT, ElementCompute, kElementsPerAccess> convert_t;
-      frag_T = convert_t(result_T);
+    LeakyReLU<ComputeFragment> leakyrelu;
+
+    if (Scale == ScaleType::NoBetaScaling) {
+      intermediate = converted_source;
+      intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
+    }  else if (Scale == ScaleType::Nothing) {
+      intermediate = converted_accumulator;
+    } else {
+      intermediate = mul_add_source(beta_bias_, converted_source);                        // X =  beta * C + uniform
+      intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
     }
+    // Compute threshold optionally
+    intermediate = leakyrelu(intermediate, leaky_alpha_recip_);
+
+    // Convert to destination numeric type
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
+
+    return destination_converter(intermediate);
   }
 
-  /// Applies the operation when is_source_needed() is false
+  /// Computes linear scaling: D = alpha * accumulator
   CUTLASS_HOST_DEVICE
-  void operator()(
-    FragmentZ &frag_Z,
-    FragmentT &frag_T,
-    FragmentAccumulator const &AB,
-    FragmentCompute const &V) const {
-
-    ElementwiseOp elementwise_op;
-    BinaryOp binary_op;
-
-    FragmentCompute tmp_Accum = NumericArrayConverter<ElementCompute, ElementAccumulator, kElementsPerAccess>()(AB);
-    FragmentCompute result_Z;
-    FragmentCompute result_T;
-
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kElementsPerAccess; ++i) {
-      ElementCompute z = binary_op(alpha_ * tmp_Accum[i], V[i]);
-      result_T[i] = z;
-      result_Z[i] = skip_elementwise_ ? z : elementwise_op(z);
-    }
+  FragmentOutput operator()(
+    FragmentAccumulator const &accumulator) const {
 
-    NumericArrayConverter<ElementZ, ElementCompute, kElementsPerAccess> convert_z;
-    frag_Z = convert_z(result_Z);
+    // Convert source to interal compute numeric type
+    NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
+    
+    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
+    
+    // Perform binary operations
+    ComputeFragment intermediate;
+
+    multiplies<ComputeFragment> mul_accumulator;
+    LeakyReLU<ComputeFragment> leakyrelu;
+    //printf("in doing with bias");
+    if (Scale == ScaleType::Nothing) {
+      intermediate = converted_accumulator;
+    } else {
+      intermediate = mul_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum
+    }
+    
+    // Compute threshold optionally
+    intermediate = leakyrelu(intermediate, leaky_alpha_recip_);
+    
+    
+    // Convert to destination numeric type
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    if constexpr (kStoreT) {
-      NumericArrayConverter<ElementT, ElementCompute, kElementsPerAccess> convert_t;
-      frag_T = convert_t(result_T);
-    }
+    return destination_converter(intermediate);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace thread
 } // namespace epilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h`

 * *Files 2% similar despite different names*

```diff
@@ -428,25 +428,20 @@
     } else if (Scale == ScaleType::Nothing) {
       intermediate = converted_accumulator;
     } else {
       intermediate = mul_add_source(beta_, converted_source);                             // X =  beta * C + uniform
       intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
     }
 
-    // Convert floats back to INT
-    FragmentAccumulator scaled_accumulator;
+    //
+    // Convert float => ElementOutput_ with clamping
+    //
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    NumericArrayConverter<int, ElementCompute, kCount, Round> compute_converter;
-
-    scaled_accumulator = compute_converter(intermediate);
-
-    // Convert to destination numeric type
-    NumericArrayConverter<ElementOutput, int, kCount, Round> destination_converter;
-
-    return destination_converter(scaled_accumulator);
+    return destination_converter(intermediate);
   }
 
   /// Computes linear scaling: D = alpha * accumulator
   CUTLASS_HOST_DEVICE
   FragmentOutput operator()(FragmentAccumulator const &accumulator) const {
 
     // Convert source to interal compute numeric type
@@ -462,25 +457,20 @@
     // Float min-max
     if (Scale == ScaleType::Nothing) {
       intermediate = converted_accumulator;
     } else {
       intermediate = mul_add_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum
     }
 
-    // Convert floats back to INT
-    FragmentAccumulator scaled_accumulator;
-
-    NumericArrayConverter<int, ElementCompute, kCount, Round> compute_converter;
-
-    scaled_accumulator = compute_converter(intermediate);
-
-    // Convert to destination numeric type
-    NumericArrayConverter<ElementOutput, int, kCount, Round> destination_converter;
+    //
+    // Convert float => ElementOutput_ with clamping
+    //
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    return destination_converter(scaled_accumulator);
+    return destination_converter(intermediate);
   }
 };
 
 #endif // Conditional guards to enable partial specialization for packed integers
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h`

 * *Files 11% similar despite different names*

```diff
@@ -24,205 +24,210 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*! \file
+  \brief Functor performing linear combination operations on planar-complex arrays
+*/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
-#include "cutlass/array.h"
+#include "cutlass/complex.h"
+#include "cutlass/array_planar_complex.h"
 #include "cutlass/functional.h"
 #include "cutlass/numeric_conversion.h"
-#include "cutlass/epilogue/thread/activation.h"
 #include "cutlass/epilogue/thread/scale_type.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace thread {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Applies a linear combination operator to an array of elements.
+/// Applies a linear combination operator to arrays of planar-complex elements.
 ///
 /// D = alpha * accumulator + beta * source + uniform
 ///
+/// Note, as with most CUTLASS components for planar complex, the template arguments describe
+/// the underlying real data type.
 template <
   typename ElementOutput_,                             ///< Data type used to load and store tensors
   int Count,                                           ///< Number of elements computed per operation
+                                                       ///< Usually it is 128/sizeof_bits<ElementOutput_>,
+                                                       ///< but we use 64 or 32 sometimes when there are not enough data to store
   typename ElementAccumulator_ = ElementOutput_,       ///< Accumulator data type
   typename ElementCompute_ = ElementOutput_,           ///< Data type used to compute linear combination
-  ScaleType::Kind Scale = ScaleType::Default,          ///< Control Alpha and Beta scaling
-  FloatRoundStyle Round = FloatRoundStyle::round_to_nearest
+  FloatRoundStyle Round = FloatRoundStyle::round_to_nearest,
+  ScaleType::Kind Scale = ScaleType::Default           ///< Control Alpha and Beta scaling
 >
-class LinearCombinationLeakyRelu {
+class LinearCombinationPlanarComplex {
 public:
 
   using ElementOutput = ElementOutput_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
+  using ElementScalar = complex<ElementCompute>;
 
   static int const kCount = Count;
   static const ScaleType::Kind kScale = Scale;
 
-  using FragmentOutput = Array<ElementOutput, kCount>;
-  using FragmentAccumulator = Array<ElementAccumulator, kCount>;
-  using ComputeFragment = Array<ElementCompute, kCount>;
-  using FragmentSource = Array<ElementOutput, kCount>;
+  using FragmentOutput = ArrayPlanarComplex<ElementOutput, kCount>;
+  using FragmentAccumulator = ArrayPlanarComplex<ElementAccumulator, kCount>;
+  using ComputeFragment = ArrayPlanarComplex<ElementCompute, kCount>;
 
   static FloatRoundStyle const kRound = Round;
 
   /// Host-constructable parameters structure
   struct Params {
 
-    ElementCompute alpha;                  ///< scales accumulators
-    ElementCompute beta_bias;              ///< scales bias tensor
-    ElementCompute leaky_alpha;            ///< leaky_alpha
+    ElementScalar alpha{ElementCompute(1)};         ///< scales accumulators
+    ElementScalar beta{ElementCompute(0)};          ///< scales source tensor
+    ElementScalar const* alpha_ptr{nullptr};        ///< pointer to accumulator scalar - if not null, loads it from memory
+    ElementScalar const* beta_ptr{nullptr};         ///< pointer to source scalar - if not null, loads it from memory
+
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params(): 
-      alpha(ElementCompute(1)), 
-      beta_bias(ElementCompute(0)),
-      leaky_alpha(ElementCompute(1)) 
-       { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
-      ElementCompute alpha,
-      ElementCompute beta_bias,
-      ElementCompute leaky_alpha = ElementCompute(1)
-    ): alpha(alpha), beta_bias(beta_bias), leaky_alpha(leaky_alpha) {
-
-    }
+      ElementScalar alpha,
+      ElementScalar beta
+    ): alpha(alpha), beta(beta)
+    {}
 
+    CUTLASS_HOST_DEVICE
+    Params(
+      ElementScalar const *alpha_ptr,
+      ElementScalar const *beta_ptr
+    ): alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) 
+    {}
   };
 
 private:
 
   //
   // Data members
   //
 
-  ElementCompute alpha_;
-  ElementCompute beta_bias_;
-  ElementCompute leaky_alpha_recip_;
+  ElementScalar alpha_;
+  ElementScalar beta_;
 
 public:
 
   /// Constructs the function object, possibly loading from pointers in host memory
   CUTLASS_HOST_DEVICE
-  LinearCombinationLeakyRelu(Params const &params) {
-    alpha_ = (params.alpha);
-    beta_bias_ = (params.beta_bias);
-    leaky_alpha_recip_ = (ElementCompute(params.leaky_alpha));    
+  LinearCombinationPlanarComplex(Params const &params) {
+    alpha_ = (params.alpha_ptr ? *params.alpha_ptr : params.alpha);
+    beta_ = (params.beta_ptr ? *params.beta_ptr : params.beta);
   }
 
   /// Returns true if source is needed
   CUTLASS_HOST_DEVICE
   bool is_source_needed() const {
-    if (Scale == ScaleType::NoBetaScaling) return true;
-
     if (Scale == ScaleType::OnlyAlphaScaling) return false;
 
-    if (Scale == ScaleType::Nothing) return false;
-
-    return beta_bias_ != ElementCompute(0);
+    return beta_.real() != ElementCompute(0) || beta_.imag() != ElementCompute(0);
   }
 
   /// Functionally required for serial reduction in the epilogue
   CUTLASS_HOST_DEVICE
-  void set_k_partition(int k_partition) {
-    if (k_partition) {
-      beta_bias_ = ElementCompute(1);
-    }
-  }
-  CUTLASS_HOST_DEVICE
   void set_k_partition(int k_partition, int k_partition_count) {
     if (k_partition) {
-      beta_bias_ = ElementCompute(1);
+      beta_ = ElementCompute(1);
     }
   }
-  
+
   /// Computes linear scaling: D = alpha * accumulator + beta * source
   CUTLASS_HOST_DEVICE
   FragmentOutput operator()(
     FragmentAccumulator const &accumulator, 
     FragmentOutput const &source) const {
 
     // Convert source to interal compute numeric type
     NumericArrayConverter<ElementCompute, ElementOutput, kCount, Round> source_converter;
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
 
-    ComputeFragment converted_source = source_converter(source);
-    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
-
-    // Perform binary operations
-    ComputeFragment intermediate;
+    ComputeFragment converted_source{
+      source_converter(source.real), 
+      source_converter(source.imag)};
+
+    ComputeFragment converted_accumulator{
+      accumulator_converter(accumulator.real), 
+      accumulator_converter(accumulator.imag)};
 
-    multiplies<ComputeFragment> mul_add_source;
-    multiply_add<ComputeFragment> mul_add_accumulator;
+    multiplies<Array<ElementCompute, kCount> > mul_op;
+    multiply_add<Array<ElementCompute, kCount> > mul_add_op;
 
-    LeakyReLU<ComputeFragment> leakyrelu;
+    // Perform binary operations
+  
+    // complex multiply: I = beta * C
+    ComputeFragment intermediate {
+      mul_op(beta_.real(), converted_source.real),
+      mul_op(beta_.real(), converted_source.imag)
+    };
+
+    intermediate.real = mul_add_op(-beta_.imag(), converted_source.imag, intermediate.real);
+    intermediate.imag = mul_add_op( beta_.imag(), converted_source.real, intermediate.imag);
+
+    // complex multiply-add: I = alpha * AB + I
+    intermediate.real = mul_add_op(alpha_.real(), converted_accumulator.real, intermediate.real);
+    intermediate.imag = mul_add_op(alpha_.real(), converted_accumulator.imag, intermediate.imag);
 
-    if (Scale == ScaleType::NoBetaScaling) {
-      intermediate = converted_source;
-      intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
-    }  else if (Scale == ScaleType::Nothing) {
-      intermediate = converted_accumulator;
-    } else {
-      intermediate = mul_add_source(beta_bias_, converted_source);                        // X =  beta * C + uniform
-      intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
-    }
-    // Compute threshold optionally
-    intermediate = leakyrelu(intermediate, leaky_alpha_recip_);
+    intermediate.real = mul_add_op(-alpha_.imag(), converted_accumulator.imag, intermediate.real);
+    intermediate.imag = mul_add_op( alpha_.imag(), converted_accumulator.real, intermediate.imag);
 
     // Convert to destination numeric type
     NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    return destination_converter(intermediate);
+    return FragmentOutput{
+      destination_converter(intermediate.real), 
+      destination_converter(intermediate.imag)};
   }
 
-  /// Computes linear scaling: D = alpha * accumulator
+  /// Computes linear scaling: D = alpha * accumulator + beta * source
   CUTLASS_HOST_DEVICE
   FragmentOutput operator()(
     FragmentAccumulator const &accumulator) const {
 
     // Convert source to interal compute numeric type
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
-    
-    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
-    
+
+    ComputeFragment converted_accumulator{
+      accumulator_converter(accumulator.real), 
+      accumulator_converter(accumulator.imag)};
+
     // Perform binary operations
-    ComputeFragment intermediate;
+    multiplies<Array<ElementCompute, kCount> > mul_op;
+    multiply_add<Array<ElementCompute, kCount> > mul_add_op;
+
+    // complex multiply-add: I = alpha * AB + I
+    ComputeFragment intermediate {
+      mul_op(alpha_.real(), converted_accumulator.real),
+      mul_op(alpha_.real(), converted_accumulator.imag)
+    };
+
+    intermediate.real = mul_add_op(-alpha_.imag(), converted_accumulator.imag, intermediate.real);
+    intermediate.imag = mul_add_op( alpha_.imag(), converted_accumulator.real, intermediate.imag);
 
-    multiplies<ComputeFragment> mul_accumulator;
-    LeakyReLU<ComputeFragment> leakyrelu;
-    //printf("in doing with bias");
-    if (Scale == ScaleType::Nothing) {
-      intermediate = converted_accumulator;
-    } else {
-      intermediate = mul_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum
-    }
-    
-    // Compute threshold optionally
-    intermediate = leakyrelu(intermediate, leaky_alpha_recip_);
-    
-    
     // Convert to destination numeric type
     NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    return destination_converter(intermediate);
+    return FragmentOutput{
+      destination_converter(intermediate.real), 
+      destination_converter(intermediate.imag)};
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace thread
 } // namespace epilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_tensor_broadcast.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_tensor_broadcast.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h`

 * *Files 2% similar despite different names*

```diff
@@ -60,19 +60,20 @@
 
 #include "cutlass/epilogue/warp/fragment_iterator_simt.h"
 #include "cutlass/epilogue/warp/tile_iterator_simt.h"
 #include "cutlass/epilogue/threadblock/default_thread_map_simt.h"
 #include "cutlass/transform/pitch_linear_thread_map.h"
 
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
+#include "cutlass/epilogue/threadblock/predicated_tile_iterator_conv.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h" 
 #include "cutlass/epilogue/threadblock/shared_load_iterator.h"
-#include "cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h"
+#include "cutlass/epilogue/threadblock/shared_load_iterator_pitch_linear.h"
 #include "cutlass/epilogue/threadblock/epilogue.h"
 #include "cutlass/epilogue/threadblock/epilogue_depthwise.h"
 
 #include "cutlass/layout/permute.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -85,48 +86,68 @@
 /// Defines sensible defaults for epilogues for SimtOps.
 template <
   typename Shape_,
   typename WarpMmaSimt_,
   typename OutputOp_,
   int ElementsPerAccess,
   bool ScatterD = false,
-  typename PermuteDLayout = layout::NoPermute
+  typename PermuteDLayout = layout::NoPermute,
+  conv::StrideSupport StrideSupport = conv::StrideSupport::kUnity,
+  int Rank = 4
 >
 struct DefaultEpilogueSimt {
 
   using Shape = Shape_;
   using WarpMmaSimt = WarpMmaSimt_;
   using OutputOp = OutputOp_;
   static int const kElementsPerAccess = ElementsPerAccess;
   static const int kPartitionsK = Shape::kK / WarpMmaSimt::Shape::kK;
 
   using ElementOutput = typename OutputOp::ElementOutput;
   using LayoutC = typename WarpMmaSimt::LayoutC;
   using ElementAccumulator = typename WarpMmaSimt::ElementC;
+  static conv::StrideSupport const kStrideSupport = StrideSupport;
+  static int const kRank = Rank;
 
   //
   // Thread map
   //
 
   using OutputTileThreadMap = typename cutlass::epilogue::threadblock::DefaultThreadMapSimt<
     Shape,
     typename WarpMmaSimt::Shape,
     typename WarpMmaSimt::Policy,
     kPartitionsK,
     ElementOutput,
     kElementsPerAccess
   >::Type;
 
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
+  static bool const UseCUDAStore = platform::is_same<ElementOutput, double>::value;
+
+  using PackedOutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     OutputTileThreadMap,
     ElementOutput,
     ScatterD,
-    PermuteDLayout
+    PermuteDLayout,
+    UseCUDAStore
   >;
 
+  using StridedOutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIteratorConv<
+    OutputTileThreadMap,
+    ElementOutput,
+    ScatterD,
+    PermuteDLayout,
+    UseCUDAStore,
+    kRank
+  >;
+
+  using OutputTileIterator = typename platform::conditional<StrideSupport == cutlass::conv::StrideSupport::kUnity,
+                                                            PackedOutputTileIterator,
+                                                            StridedOutputTileIterator>::type;
+
   using AccumulatorFragmentIterator = cutlass::epilogue::warp::FragmentIteratorSimt<
     typename WarpMmaSimt::Shape,
     typename WarpMmaSimt::ThreadMma,
     layout::RowMajor,
     typename WarpMmaSimt::Policy
   >;
 
@@ -385,15 +406,15 @@
     ThreadBlockOutputShape,
     typename WarpMmaSimt::ThreadMma,
     ElementAccumulator,
     layout::RowMajor,
     typename WarpMmaSimt::Policy
   >;
 
-  using SharedLoadIterator = cutlass::epilogue::threadblock::SharedLoadIteratorPitchLiner<
+  using SharedLoadIterator = cutlass::epilogue::threadblock::SharedLoadIteratorPitchLinear<
     OutputTileThreadMap,
     ElementAccumulator
   >;
 
   /// Hard-coded padding elements added 
   using Padding = typename WarpTileIterator::Padding;
   //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h`

 * *Files 2% similar despite different names*

```diff
@@ -62,14 +62,15 @@
 
 #include "cutlass/epilogue/warp/fragment_iterator_tensor_op.h"
 #include "cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h"
 #include "cutlass/epilogue/warp/tile_iterator_tensor_op.h"
 #include "cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h"
 #include "cutlass/epilogue/threadblock/default_thread_map_tensor_op.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
+#include "cutlass/epilogue/threadblock/predicated_tile_iterator_conv.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h"
 #include "cutlass/epilogue/threadblock/shared_load_iterator.h"
 #include "cutlass/epilogue/threadblock/shared_load_iterator_mixed.h"
 
 #include "cutlass/epilogue/threadblock/epilogue.h"
 #include "cutlass/epilogue/threadblock/interleaved_epilogue.h"
@@ -283,15 +284,15 @@
 
   static_assert(platform::is_same<ElementOutput, cutlass::int4b_t>::value ||
                 platform::is_same<ElementOutput, cutlass::uint4b_t>::value ||
                 platform::is_same<ElementOutput, int8_t>::value ||
                 platform::is_same<ElementOutput, uint8_t>::value,
                 "ElementOutput needs to be 4 or 8 bit (unsigned) int.");
 
-   static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8),
+   static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8 || ElementsPerAccess == 4),
                 "ElementsPerAccess needs to be 16 or 8.");
   
   using WarpTileIteratorMixed = cutlass::epilogue::warp::TileIteratorTensorOpMixed<
     WarpShape,
     InstructionShape,
     int32_t,
     32,
@@ -304,15 +305,15 @@
     WarpShape,
     InstructionShape,
     int32_t,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     int32_t,
     32,
@@ -323,15 +324,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     int32_t
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 /// Partial specialization for float_e4m3_t <= float x 16/8 epilogues avoids shared memory bank conflicts.
@@ -350,15 +351,15 @@
   ThreadblockShape, 
   WarpShape, 
   InstructionShape, 
   ThreadMap> {
 
   using ElementOutput = cutlass::float_e4m3_t;
 
-  static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8),
+  static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8 || ElementsPerAccess == 4),
               "ElementsPerAccess needs to be 16 or 8.");
   
   using WarpTileIteratorMixed = cutlass::epilogue::warp::TileIteratorTensorOpMixed<
     WarpShape,
     InstructionShape,
     float,
     32,
@@ -371,15 +372,15 @@
     WarpShape,
     InstructionShape,
     float,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     float,
     32,
@@ -390,15 +391,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     float
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 /// Partial specialization for float_e5m2_t <= float x 16/8 epilogues avoids shared memory bank conflicts.
@@ -417,15 +418,15 @@
   ThreadblockShape, 
   WarpShape, 
   InstructionShape, 
   ThreadMap> {
 
   using ElementOutput = cutlass::float_e5m2_t;
 
-  static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8),
+  static_assert((ElementsPerAccess == 16 || ElementsPerAccess == 8 || ElementsPerAccess == 4),
               "ElementsPerAccess needs to be 16 or 8.");
   
   using WarpTileIteratorMixed = cutlass::epilogue::warp::TileIteratorTensorOpMixed<
     WarpShape,
     InstructionShape,
     float,
     32,
@@ -438,15 +439,15 @@
     WarpShape,
     InstructionShape,
     float,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     float,
     32,
@@ -457,15 +458,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     float
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8) || (ElementsPerAccess == 4),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 } // namespace detail
@@ -476,27 +477,31 @@
 template <
   typename Shape_,
   typename WarpMmaTensorOp_,
   int PartitionsK,
   typename OutputOp_,
   int ElementsPerAccess,
   bool ScatterD = false,
-  typename PermuteDLayout = layout::NoPermute
+  typename PermuteDLayout = layout::NoPermute,
+  conv::StrideSupport StrideSupport = conv::StrideSupport::kUnity,
+  int Rank = 4
 >
 struct DefaultEpilogueTensorOp {
 
   using Shape = Shape_;
   using WarpMmaTensorOp = WarpMmaTensorOp_;
   static int const kPartitionsK = PartitionsK;
   using OutputOp = OutputOp_;
   static int const kElementsPerAccess = ElementsPerAccess;
 
   using ElementOutput = typename OutputOp::ElementOutput;
   using LayoutC = typename WarpMmaTensorOp::LayoutC;
   using ElementAccumulator = typename WarpMmaTensorOp::ElementC;
+  static conv::StrideSupport const kStrideSupport = StrideSupport;
+  static int const kRank = Rank;
 
   //
   // Thread map
   //
 
   using OutputTileThreadMap = typename cutlass::epilogue::threadblock::DefaultThreadMapTensorOp<
     Shape,
@@ -504,22 +509,35 @@
     kPartitionsK,
     ElementOutput,
     kElementsPerAccess
   >::Type;
 
   static bool const UseCUDAStore = platform::is_same<ElementOutput, double>::value;
 
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
+  using PackedOutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     OutputTileThreadMap,
     ElementOutput,
     ScatterD,
     PermuteDLayout,
     UseCUDAStore
   >;
 
+  using StridedOutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIteratorConv<
+    OutputTileThreadMap,
+    ElementOutput,
+    ScatterD,
+    PermuteDLayout,
+    UseCUDAStore,
+    kRank
+  >;
+
+  using OutputTileIterator = typename platform::conditional<StrideSupport == cutlass::conv::StrideSupport::kUnity,
+                                                            PackedOutputTileIterator,
+                                                            StridedOutputTileIterator>::type;
+
   using AccumulatorFragmentIterator = typename platform::conditional<is_complex<ElementOutput>::value,
                                     cutlass::epilogue::warp::FragmentIteratorComplexTensorOp<
                                         typename WarpMmaTensorOp::Shape,
                                         typename WarpMmaTensorOp::Policy::Operator::Shape,
                                         typename WarpMmaTensorOp::Policy::Operator::ElementC,
                                         typename WarpMmaTensorOp::Policy::Operator::FragmentC,
                                         LayoutC>,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h`

 * *Files 1% similar despite different names*

```diff
@@ -115,15 +115,15 @@
 
   using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIteratorBlas3<
     OutputTileThreadMap,
     ElementOutput,
     kBlasMode
   >;
 
-  using AccumulatorFragmentIterator = typename std::conditional<is_complex<ElementOutput>::value,
+  using AccumulatorFragmentIterator = typename platform::conditional<is_complex<ElementOutput>::value,
                                     cutlass::epilogue::warp::FragmentIteratorComplexTensorOp<
                                         typename WarpMmaTensorOp::Shape,
                                         typename WarpMmaTensorOp::Policy::Operator::Shape,
                                         typename WarpMmaTensorOp::Policy::Operator::ElementC,
                                         typename WarpMmaTensorOp::Policy::Operator::FragmentC,
                                         LayoutC>,
                                     cutlass::epilogue::warp::FragmentIteratorTensorOp<
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h`

 * *Files 14% similar despite different names*

```diff
@@ -25,14 +25,15 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
+
   \brief Epilogue for threadblock scoped GEMMs using Tensor Ops.
 
   The epilogue rearranges the result of a matrix product through shared memory to match canonical
   tensor layouts in global memory. Epilogues support conversion and reduction operations.
 
 */
 
@@ -43,16 +44,15 @@
 #include "cutlass/array.h"
 
 #include "cutlass/gemm/gemm.h"
 
 #include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
 #include "cutlass/epilogue/threadblock/epilogue.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_broadcast.h"
-#include "cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_reduction.h"
 
 #include "cutlass/layout/permute.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
@@ -62,180 +62,112 @@
 
 /// Defines sensible defaults for epilogues for TensorOps.
 template <
   typename Shape,
   typename WarpMmaTensorOp,
   int PartitionsK,
   typename ElementOutput,
-  typename ElementTensor,
-  typename ElementVector,
   typename OutputOp,
+  typename ReductionOp,
   int ElementsPerAccess,
   bool ScatterD = false,
   typename PermuteDLayout = layout::NoPermute
 >
-struct DefaultEpilogueWithBroadcastTensorOp {
+struct DefaultEpilogueWithReductionTensorOp {
 
   /// Use defaults related to the existing epilogue
   using Base = DefaultEpilogueTensorOp<
     Shape,
     WarpMmaTensorOp,
     PartitionsK,
     OutputOp,
     ElementsPerAccess
   >;
 
-  //
-  // Stores the result z = (y = GEMM(A, B, C), broadcast)
-  //
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
-    ElementOutput,
-    ScatterD,
-    PermuteDLayout
-  >;
-
-  //
-  // Additional tensor tile iterator - stores t = Elementwise(z)
-  //
+  /// Additional tensor tile iterator
   using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     typename Base::OutputTileThreadMap,
-    ElementTensor
+    typename OutputOp::ElementTensor
   >;
 
-  /// Define the epilogue
-  using Epilogue = EpilogueWithBroadcast<
-    Shape,
-    WarpMmaTensorOp,
-    PartitionsK,
-    OutputTileIterator,
-    TensorTileIterator,
-    ElementVector,
-    typename Base::AccumulatorFragmentIterator,
-    typename Base::WarpTileIterator,
-    typename Base::SharedLoadIterator,
-    OutputOp,
-    typename Base::Padding,
-    Base::kFragmentsPerIteration
-  >;
-};
-
-////////////////////////////////////////////////////////////////////////////////
-
-/// Defines sensible defaults for streamk epilogues for TensorOps.
-template <
-  typename Shape,
-  typename WarpMmaTensorOp,
-  int PartitionsK,
-  typename ElementOutput,
-  typename ElementTensor,
-  typename ElementVector,
-  typename OutputOp,
-  int ElementsPerAccess,
-  bool ScatterD = false,
-  typename PermuteDLayout = layout::NoPermute
->
-struct DefaultStreamkEpilogueWithBroadcastTensorOp {
-
-  /// Use defaults related to the existing epilogue
-  using Base = DefaultEpilogueTensorOp<
-    Shape,
-    WarpMmaTensorOp,
-    PartitionsK,
-    OutputOp,
-    ElementsPerAccess
-  >;
-
-  //
-  // Stores the result z = (y = GEMM(A, B, C), broadcast)
-  //
   using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     typename Base::OutputTileThreadMap,
     ElementOutput,
     ScatterD,
     PermuteDLayout
   >;
 
-  //
-  // Additional tensor tile iterator - stores t = Elementwise(z)
-  //
-  using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
-    ElementTensor
-  >;
-
   /// Define the epilogue
-  using Epilogue = EpilogueStreamkWithBroadcast<
+  using Epilogue = EpilogueWithReduction<
     Shape,
     WarpMmaTensorOp,
     PartitionsK,
     OutputTileIterator,
     TensorTileIterator,
-    ElementVector,
+    typename WarpMmaTensorOp::ElementC,
     typename Base::AccumulatorFragmentIterator,
     typename Base::WarpTileIterator,
     typename Base::SharedLoadIterator,
-    OutputOp,
-    typename Base::Padding,
-    Base::kFragmentsPerIteration
+    typename Base::OutputOp,
+    ReductionOp,
+    typename Base::Padding
   >;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Defines sensible defaults for epilogues for VoltaTensorOps.
+/// Defines sensible defaults for epilogues for TensorOps.
 template <
   typename Shape,
   typename WarpMmaTensorOp,
   int PartitionsK,
   typename ElementOutput,
-  typename ElementTensor,
-  typename ElementVector,
   typename OutputOp,
-  int ElementsPerAccess
+  typename ReductionOp,
+  int ElementsPerAccess,
+  bool ScatterD = false,
+  typename PermuteDLayout = layout::NoPermute
 >
-struct DefaultEpilogueWithBroadcastVoltaTensorOp {
+struct DefaultEpilogueWithReductionVoltaTensorOp {
 
   /// Use defaults related to the existing epilogue
   using Base = DefaultEpilogueVoltaTensorOp<
     Shape,
     WarpMmaTensorOp,
     PartitionsK,
     OutputOp,
     ElementsPerAccess
   >;
 
-  //
-  // Stores the result z = (y = GEMM(A, B, C), broadcast)
-  //
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
+  /// Additional tensor tile iterator
+  using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     typename Base::OutputTileThreadMap,
-    ElementOutput
+    typename OutputOp::ElementTensor
   >;
 
-  //
-  // Additional tensor tile iterator - stores t = Elementwise(z)
-  //
-  using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
+  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
     typename Base::OutputTileThreadMap,
-    ElementTensor
+    ElementOutput,
+    ScatterD,
+    PermuteDLayout
   >;
 
   /// Define the epilogue
-  using Epilogue = EpilogueWithBroadcast<
+  using Epilogue = EpilogueWithReduction<
     Shape,
     WarpMmaTensorOp,
     PartitionsK,
     OutputTileIterator,
     TensorTileIterator,
-    ElementVector,
+    typename WarpMmaTensorOp::ElementC,
     typename Base::AccumulatorFragmentIterator,
     typename Base::WarpTileIterator,
     typename Base::SharedLoadIterator,
-    OutputOp,
+    typename Base::OutputOp,
+    ReductionOp,
     typename Base::Padding
   >;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h`

 * *Files 21% similar despite different names*

```diff
@@ -25,153 +25,141 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-
-  \brief Epilogue for threadblock scoped GEMMs using Tensor Ops.
+  \brief Epilogue for threadblock scoped GEMMs using WMMA.
 
   The epilogue rearranges the result of a matrix product through shared memory to match canonical
   tensor layouts in global memory. Epilogues support conversion and reduction operations.
 
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
 
 #include "cutlass/gemm/gemm.h"
 
-#include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
-#include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
+#include "cutlass/epilogue/thread/linear_combination.h"
+#include "cutlass/epilogue/thread/linear_combination_clamp.h"
+#include "cutlass/epilogue/thread/linear_combination_relu.h"
+#include "cutlass/epilogue/thread/linear_combination_gelu.h"
+#include "cutlass/epilogue/thread/linear_combination_sigmoid.h"
+#include "cutlass/epilogue/thread/linear_combination_planar_complex.h"
+
+#include "cutlass/epilogue/thread/conversion_op.h"
+#include "cutlass/epilogue/thread/reduction_op.h"
+
+#include "cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h"
+
+#include "cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h"
+#include "cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h"
+#include "cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h"
+#include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
+#include "cutlass/epilogue/threadblock/shared_load_iterator.h"
+
 #include "cutlass/epilogue/threadblock/epilogue.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_reduction.h"
 
 #include "cutlass/layout/permute.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Defines sensible defaults for epilogues for TensorOps.
+/// Defines sensible defaults for epilogues for WMMA TensorOps.
 template <
-  typename Shape,
-  typename WarpMmaTensorOp,
+  typename Shape_,
+  typename WarpMmaTensorOp_,
   int PartitionsK,
-  typename ElementOutput,
-  typename OutputOp,
-  typename ReductionOp,
+  typename OutputOp_,
   int ElementsPerAccess,
   bool ScatterD = false,
   typename PermuteDLayout = layout::NoPermute
 >
-struct DefaultEpilogueWithReductionTensorOp {
+struct DefaultEpilogueWmmaTensorOp {
 
-  /// Use defaults related to the existing epilogue
-  using Base = DefaultEpilogueTensorOp<
-    Shape,
-    WarpMmaTensorOp,
-    PartitionsK,
-    OutputOp,
-    ElementsPerAccess
-  >;
+  using Shape = Shape_;
+  using WarpMmaTensorOp = WarpMmaTensorOp_;
+  static int const kPartitionsK = PartitionsK;
+  using OutputOp = OutputOp_;
+  static int const kElementsPerAccess = ElementsPerAccess;
+
+  using ElementOutput = typename OutputOp::ElementOutput;
+  using LayoutC = typename WarpMmaTensorOp::LayoutC;
+  using ElementAccumulator = typename WarpMmaTensorOp::ElementC;
+
+  //
+  // Thread map
+  //
 
-  /// Additional tensor tile iterator
-  using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
-    typename OutputOp::ElementTensor
-  >;
+  using OutputTileThreadMap = typename cutlass::epilogue::threadblock::DefaultThreadMapWmmaTensorOp<
+    Shape,
+    typename WarpMmaTensorOp::Shape,
+    typename WarpMmaTensorOp::Policy::Operator::Shape,
+    kPartitionsK,
+    ElementOutput,
+    kElementsPerAccess
+  >::Type;
 
   using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
+    OutputTileThreadMap,
     ElementOutput,
     ScatterD,
     PermuteDLayout
   >;
 
-  /// Define the epilogue
-  using Epilogue = EpilogueWithReduction<
-    Shape,
-    WarpMmaTensorOp,
-    PartitionsK,
-    OutputTileIterator,
-    TensorTileIterator,
-    typename WarpMmaTensorOp::ElementC,
-    typename Base::AccumulatorFragmentIterator,
-    typename Base::WarpTileIterator,
-    typename Base::SharedLoadIterator,
-    typename Base::OutputOp,
-    ReductionOp,
-    typename Base::Padding
+  using AccumulatorFragmentIterator = cutlass::epilogue::warp::FragmentIteratorWmmaTensorOp<
+    typename WarpMmaTensorOp::Shape,
+    typename WarpMmaTensorOp::Policy::Operator::Shape,
+    typename WarpMmaTensorOp::Policy::Operator::ElementC,
+    typename WarpMmaTensorOp::Policy::Operator::FragmentC,
+    LayoutC
   >;
-};
-
-////////////////////////////////////////////////////////////////////////////////
-
-/// Defines sensible defaults for epilogues for TensorOps.
-template <
-  typename Shape,
-  typename WarpMmaTensorOp,
-  int PartitionsK,
-  typename ElementOutput,
-  typename OutputOp,
-  typename ReductionOp,
-  int ElementsPerAccess,
-  bool ScatterD = false,
-  typename PermuteDLayout = layout::NoPermute
->
-struct DefaultEpilogueWithReductionVoltaTensorOp {
 
-  /// Use defaults related to the existing epilogue
-  using Base = DefaultEpilogueVoltaTensorOp<
-    Shape,
-    WarpMmaTensorOp,
-    PartitionsK,
-    OutputOp,
-    ElementsPerAccess
+  using WarpTileIterator = cutlass::epilogue::warp::TileIteratorWmmaTensorOp<
+    typename WarpMmaTensorOp::Shape,
+    typename WarpMmaTensorOp::Policy::Operator::Shape,
+    typename WarpMmaTensorOp::Policy::Operator::FragmentC,
+    LayoutC
   >;
 
-  /// Additional tensor tile iterator
-  using TensorTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
-    typename OutputOp::ElementTensor
+  using SharedLoadIterator = cutlass::epilogue::threadblock::SharedLoadIterator<
+    typename OutputTileThreadMap::CompactedThreadMap,
+    ElementAccumulator
   >;
 
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    typename Base::OutputTileThreadMap,
-    ElementOutput,
-    ScatterD,
-    PermuteDLayout
-  >;
+  /// Hard-coded padding elements added 
+  using Padding = typename WarpTileIterator::Padding;
 
-  /// Define the epilogue
-  using Epilogue = EpilogueWithReduction<
+  //
+  // Define the epilogue
+  //
+  using Epilogue = cutlass::epilogue::threadblock::Epilogue<
     Shape,
     WarpMmaTensorOp,
-    PartitionsK,
+    kPartitionsK,
     OutputTileIterator,
-    TensorTileIterator,
-    typename WarpMmaTensorOp::ElementC,
-    typename Base::AccumulatorFragmentIterator,
-    typename Base::WarpTileIterator,
-    typename Base::SharedLoadIterator,
-    typename Base::OutputOp,
-    ReductionOp,
-    typename Base::Padding
+    AccumulatorFragmentIterator,
+    WarpTileIterator,
+    SharedLoadIterator,
+    OutputOp,
+    Padding
   >;
 };
 
+
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
 } // namespace epilogue
 } // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h`

 * *Files 23% similar despite different names*

```diff
@@ -24,142 +24,114 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-  \brief Epilogue for threadblock scoped GEMMs using WMMA.
-
-  The epilogue rearranges the result of a matrix product through shared memory to match canonical
-  tensor layouts in global memory. Epilogues support conversion and reduction operations.
 
+/*! \file
+    \brief 
+      Default kernel-level GEMM definitions combine threadblock-scoped matrix multiply-add with
+      the appropriate threadblock-scoped epilogue.
+  
+      Note, CUTLASS epilogues universally target row-major outputs. Column-major outputs are
+      accommodated by exchanging A and B operands and assuming transposed layouts. Partial
+      specializations here choose 'device::GemmTransposed' to implement this functionality.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/numeric_types.h"
-#include "cutlass/array.h"
 
-#include "cutlass/gemm/gemm.h"
-
-#include "cutlass/epilogue/thread/linear_combination.h"
-#include "cutlass/epilogue/thread/linear_combination_clamp.h"
-#include "cutlass/epilogue/thread/linear_combination_relu.h"
-#include "cutlass/epilogue/thread/linear_combination_gelu.h"
-#include "cutlass/epilogue/thread/linear_combination_sigmoid.h"
-#include "cutlass/epilogue/thread/linear_combination_planar_complex.h"
-
-#include "cutlass/epilogue/thread/conversion_op.h"
-#include "cutlass/epilogue/thread/reduction_op.h"
-
-#include "cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h"
-
-#include "cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h"
-#include "cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h"
-#include "cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h"
-#include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
-#include "cutlass/epilogue/threadblock/shared_load_iterator.h"
+#include "cutlass/layout/matrix.h"
+#include "cutlass/numeric_types.h"
+#include "cutlass/arch/wmma.h"
 
 #include "cutlass/epilogue/threadblock/epilogue.h"
+#include "cutlass/epilogue/thread/linear_combination.h"
 
-#include "cutlass/layout/permute.h"
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h"
+#include "cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h"
+#include "cutlass/gemm/threadblock/threadblock_swizzle.h"
 
-////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
+#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
 
 namespace cutlass {
-namespace epilogue {
-namespace threadblock {
+namespace gemm {
+namespace kernel {
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Defines sensible defaults for epilogues for WMMA TensorOps.
 template <
-  typename Shape_,
-  typename WarpMmaTensorOp_,
-  int PartitionsK,
-  typename OutputOp_,
-  int ElementsPerAccess,
-  bool ScatterD = false,
-  typename PermuteDLayout = layout::NoPermute
->
-struct DefaultEpilogueWmmaTensorOp {
-
-  using Shape = Shape_;
-  using WarpMmaTensorOp = WarpMmaTensorOp_;
-  static int const kPartitionsK = PartitionsK;
-  using OutputOp = OutputOp_;
-  static int const kElementsPerAccess = ElementsPerAccess;
-
-  using ElementOutput = typename OutputOp::ElementOutput;
-  using LayoutC = typename WarpMmaTensorOp::LayoutC;
-  using ElementAccumulator = typename WarpMmaTensorOp::ElementC;
-
-  //
-  // Thread map
-  //
-
-  using OutputTileThreadMap = typename cutlass::epilogue::threadblock::DefaultThreadMapWmmaTensorOp<
-    Shape,
-    typename WarpMmaTensorOp::Shape,
-    typename WarpMmaTensorOp::Policy::Operator::Shape,
-    kPartitionsK,
-    ElementOutput,
-    kElementsPerAccess
-  >::Type;
-
-  using OutputTileIterator = cutlass::epilogue::threadblock::PredicatedTileIterator<
-    OutputTileThreadMap,
-    ElementOutput,
-    ScatterD,
-    PermuteDLayout
-  >;
-
-  using AccumulatorFragmentIterator = cutlass::epilogue::warp::FragmentIteratorWmmaTensorOp<
-    typename WarpMmaTensorOp::Shape,
-    typename WarpMmaTensorOp::Policy::Operator::Shape,
-    typename WarpMmaTensorOp::Policy::Operator::ElementC,
-    typename WarpMmaTensorOp::Policy::Operator::FragmentC,
-    LayoutC
-  >;
-
-  using WarpTileIterator = cutlass::epilogue::warp::TileIteratorWmmaTensorOp<
-    typename WarpMmaTensorOp::Shape,
-    typename WarpMmaTensorOp::Policy::Operator::Shape,
-    typename WarpMmaTensorOp::Policy::Operator::FragmentC,
-    LayoutC
-  >;
-
-  using SharedLoadIterator = cutlass::epilogue::threadblock::SharedLoadIterator<
-    typename OutputTileThreadMap::CompactedThreadMap,
-    ElementAccumulator
-  >;
-
-  /// Hard-coded padding elements added 
-  using Padding = typename WarpTileIterator::Padding;
-
-  //
-  // Define the epilogue
-  //
-  using Epilogue = cutlass::epilogue::threadblock::Epilogue<
-    Shape,
-    WarpMmaTensorOp,
-    kPartitionsK,
-    OutputTileIterator,
-    AccumulatorFragmentIterator,
-    WarpTileIterator,
-    SharedLoadIterator,
-    OutputOp,
-    Padding
-  >;
-};
+    /// Element type for A matrix operand
+    typename ElementA,
+    /// Layout type for A matrix operand
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB,
+    /// Layout type for B matrix operand
+    typename LayoutB,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB,
+    /// Element type for Scale/Bias vectors
+    typename ElementScaleBias,
+    /// Layout type for Scale/Bias vectors
+    typename LayoutScaleBias,
+    /// Element type for C and D matrix operands
+    typename ElementC,
+    /// Layout type for C and D matrix operands
+    typename LayoutC,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Operator class tag
+    typename OperatorClass,
+    /// Tag indicating architecture to tune for
+    typename ArchTag,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// Operation performed by GEMM
+    typename Operator,
+    /// Use zfill or predicate for out-of-bound cp.async
+    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone>
+struct DefaultGemmLayernormMainloopFusion {
+
+  /// Define the threadblock-scoped matrix multiply-accumulate
+  using Mma = typename cutlass::gemm::threadblock::DefaultMmaLayernormMainloopFusion<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+      ElementScaleBias, LayoutScaleBias, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm80,
+      ThreadblockShape, WarpShape, InstructionShape, Stages,
+      Operator, false, SharedMemoryClear>::ThreadblockMma;
+
+  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+
+  /// Define the epilogue
+  using Epilogue =
+      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
+          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
+          EpilogueOutputOp::kCount>::Epilogue;
 
+  /// Define the kernel-level GEMM operator.
+  using GemmKernel = kernel::GemmLayernormMainloopFusion<Mma, Epilogue, ThreadblockSwizzle>;
+};
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace threadblock
-} // namespace epilogue
-} // namespace cutlass
+}  // namespace kernel
+}  // namespace gemm
+}  // namespace cutlass
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_2x.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_2x.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -88,19 +88,19 @@
         }
       );
     }
 
     /// Called after accumulators have been exchanged for each accumulator vector
     template <typename ElementAccumulator, typename... ElementInputs, int FragmentSize>
     CUTLASS_DEVICE auto // returns an Array
-    visit(int iter_idx, int row_idx, int column_idx, int frg_idx, 
+    visit(int iter_idx, int row_idx, int column_idx, int frg_idx,
           Array<ElementAccumulator, FragmentSize> const& frg_acc,
           Array<ElementInputs, FragmentSize> const&... frg_inputs) // depends on the N-naryness of the op
       = delete; // Must be implemented for each operation
-    
+
     /// Called at the start of a row
     CUTLASS_DEVICE void
     end_row(int row_idx) {
       for_each(callbacks_tuple,
         [&] (auto& callbacks) {
           callbacks.end_row(row_idx);
         }
@@ -175,20 +175,20 @@
   using VisitorImpl2x<ChildOps..., NodeOp>::VisitorImpl2x;
 
   template<class CallbacksImpl>
   struct Callbacks : CallbacksImpl {
     CUTLASS_DEVICE
     Callbacks(CallbacksImpl&& impl)
       : CallbacksImpl(cute::forward<CallbacksImpl>(impl)) {}
-    
+
     using CallbacksImpl::callbacks_tuple;
 
     template <typename ElementAccumulator, int FragmentSize>
     CUTLASS_DEVICE auto
-    visit(int iter_idx, int row_idx, int column_idx, int frg_idx, 
+    visit(int iter_idx, int row_idx, int column_idx, int frg_idx,
           Array<ElementAccumulator, FragmentSize> const& frg_acc) {
       constexpr int Rm1 = sizeof...(ChildOps);
       return cute::detail::tapply(callbacks_tuple,
         [&] (auto& child_callbacks) {
           return child_callbacks.visit(iter_idx, row_idx, column_idx, frg_idx, frg_acc);
         },
         [&] (auto&&... frg_inputs) {
@@ -238,24 +238,24 @@
   using VisitorImpl2x<Ops...>::VisitorImpl2x;
 
   template<class CallbacksImpl>
   struct Callbacks : CallbacksImpl {
     CUTLASS_DEVICE
     Callbacks(CallbacksImpl&& impl)
       : CallbacksImpl(cute::forward<CallbacksImpl>(impl)) {}
-    
+
     using CallbacksImpl::callbacks_tuple;
 
     template <typename ElementAccumulator, int FragmentSize>
     CUTLASS_DEVICE auto
-    visit(int iter_idx, int row_idx, int column_idx, int frg_idx, 
+    visit(int iter_idx, int row_idx, int column_idx, int frg_idx,
           Array<ElementAccumulator, FragmentSize> const& frg_acc) {
       constexpr int Rm1 = sizeof...(Ops) - 1;
       auto frg_compute_tuple = cute::repeat<Rm1>(Array<ElementCompute, FragmentSize>{});
-      
+
       return cute::detail::tapply(EdgeTuple{}, callbacks_tuple, frg_compute_tuple,
         // Visit the first R-1 ops in topological order
         [&] (auto&& edge_seq, auto& callbacks, auto& frg_compute) {
           frg_compute = cute::detail::apply(frg_compute_tuple,
           // Compute the current op with children inputs
           [&] (auto const&... frg_inputs) {
             auto frg_output = callbacks.visit(iter_idx, row_idx, column_idx, frg_idx, frg_acc, frg_inputs...);
@@ -267,15 +267,15 @@
           },
           // Get inputs in the sequence given by the children indices of the current op
           edge_seq
         );
         return frg_compute;
       },
       // Visit the last op
-      [&] (auto const&...) {
+      [&] (auto const&...ops) {
         return cute::detail::apply(frg_compute_tuple,
           // Compute the last op with children inputs
           [&] (auto const&... frg_inputs) {
             return get<Rm1>(callbacks_tuple).visit(iter_idx, row_idx, column_idx, frg_idx, frg_acc, frg_inputs...);
           },
           // Get inputs in the sequence given by the children indices of the last op
           get<Rm1>(EdgeTuple{})
@@ -339,15 +339,15 @@
 >
 struct OutputTileThreadLayout: DefaultThreadMapTensorOp<
   ThreadblockShape_,
   WarpShape_,
   ThreadblockShape_::kK/WarpShape_::kK,
   Element_,
   ElementsPerAccess>::Type {
-  
+
   using Base = typename DefaultThreadMapTensorOp<
     ThreadblockShape_,
     WarpShape_,
     ThreadblockShape_::kK/WarpShape_::kK,
     Element_,
     ElementsPerAccess>::Type;
   using Base::Base;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_compute.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_compute.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_load.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_load.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -109,14 +109,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   CUTLASS_HOST_DEVICE
   VisitorScalarBroadcast() { }
 
   CUTLASS_HOST_DEVICE
   VisitorScalarBroadcast(Params const& params, SharedStorage const& shared_storage)
       : params_ptr(&params) {
     // Get the scalar for non-batched broadcast
@@ -212,14 +218,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   // Software pipeline stages
   static const int Stages = ThreadMap::Stages;
 
   struct SharedStorage {};
 
   // Global load type
   static int constexpr vec_bits = ThreadMap::kElementsPerAccess * sizeof_bits<Element>::value;
@@ -337,14 +349,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   struct SharedStorage {};
 
   // Global load type
   static int constexpr vec_bits = ThreadMap::kElementsPerAccess * sizeof_bits<Element>::value;
   using VecType = uint_bit_t<cute::min(128, vec_bits)>;
   static int constexpr VecLength = sizeof(VecType) / sizeof(Element);
 
@@ -460,14 +478,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   struct SharedStorage { };
 
   CUTLASS_HOST_DEVICE
   VisitorColBroadcast() { }
 
   CUTLASS_HOST_DEVICE
   VisitorColBroadcast(Params const& params, SharedStorage const& shared_storage)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_store.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_store.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -70,14 +70,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   struct SharedStorage {};
 
   static int constexpr vec_bits = ThreadMap::kElementsPerAccess * sizeof_bits<Element>::value;
   using VecType = uint_bit_t<cute::min(128, vec_bits)>;
   static int constexpr VecLength = sizeof(VecType) / sizeof(Element);
 
   CUTLASS_HOST_DEVICE
@@ -254,14 +260,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   struct SharedStorage { };
 
   CUTLASS_HOST_DEVICE
   VisitorColReduction() { }
 
   CUTLASS_HOST_DEVICE
   VisitorColReduction(Params const& params, SharedStorage const& shared_storage)
@@ -394,14 +406,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   using SharedStorageShape = decltype(select<0,1,2,3,5,8,10>(typename ThreadMap::ThreadMapShape{}));
 
   struct SharedStorage {
     AlignedArray<ElementCompute, size(SharedStorageShape{}), 16> reduction;
   };
 
   static int constexpr vec_bits = ThreadMap::kElementsPerAccess * sizeof_bits<ElementOutput>::value;
@@ -668,14 +686,20 @@
 
   template <class ProblemShape>
   static constexpr Params
   to_underlying_arguments(ProblemShape const& problem_shape, Arguments const& args, void* workspace) {
     return args;
   }
 
+  template <class ProblemShape>
+  static size_t
+  get_workspace_size(ProblemShape const& problem_shape, Arguments const& args) {
+    return 0;
+  }
+
   struct SharedStorage { };
 
   CUTLASS_HOST_DEVICE
   VisitorScalarReduction(){ };
 
   CUTLASS_HOST_DEVICE
   VisitorScalarReduction(Params const& params, SharedStorage const& shared_storage)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitors.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitors.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/pitch_linear.h`

 * *Files 27% similar despite different names*

```diff
@@ -24,100 +24,126 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*! \file
+    \brief Defines layout functions used by TensorRef and derived classes for pitch-linear memory.
+*/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-
-#include "cutlass/conv/convolution.h"
-#include "cutlass/conv/conv2d_problem_size.h"
-#include "cutlass/conv/conv3d_problem_size.h"
-#include "cutlass/layout/tensor.h"
-#include "cutlass/layout/matrix.h"
-#include "cutlass/tensor_ref.h"
+#include "cutlass/coord.h"
+#include "cutlass/pitch_linear_coord.h"
 
 namespace cutlass {
-namespace epilogue {
-namespace threadblock {
+namespace layout {
+
+template <int Contiguous, int Strided>
+  using PitchLinearShape = cutlass::PitchLinearShape < Contiguous, Strided >;
+  using PitchLinearCoord = PitchLinearCoord;
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Mapping function for pitch-linear memory
+class PitchLinear {
+public:
+  /// Logical rank of tensor
+  static int const kRank = 2;
+
+  /// Rank of stride vector
+  static int const kStrideRank = 1;
+
+  /// Index type used for coordinates
+  using Index = int32_t;
 
-template<
-  typename TensorLayout_,                             ///! The original output tensor layout
-  typename OutputIteratorLayout_,                     ///! Layout used by epilogue output iterator
-  typename TensorRef_,                                ///! Input tensor to epilogue output iterator
-  conv::Operator ConvOperator,                        ///! Convolutional operator (Fprop, Dgrad, Wgrad)
-  typename ConvProblemSize_                          ///! Convolutional operator on 2D or 3D problem
->
-struct ConvOutputIteratorParameter {
+  /// Long index type used for offsets
+  using LongIndex = int64_t;
 
-  using TensorLayout = TensorLayout_;
-  using OutputIteratorLayout = OutputIteratorLayout_;
-  using OutputTensorCoord = typename OutputIteratorLayout::TensorCoord;
-  using TensorRef = TensorRef_;
-  static conv::Operator const kConvolutionalOperator = ConvOperator;
-  using ConvProblemSize = ConvProblemSize_;
+  /// Logical coordinate
+  using TensorCoord = PitchLinearCoord;
 
-  /// Wgrad stride idx for implicit gemm algorithm 
-  // Conv2d row-major matrix (KxRSC) 
-  // Conv3d row-major matrix (KxTRSC)
-  static int const kWgradStrideIdx = 
-    platform::is_same<TensorLayout, layout::TensorNHWC>::value ? 2 : 3;
+  /// Stride vector
+  using Stride = Coord<kStrideRank, LongIndex>;
 
-  /// This chooses the appropriate stride element of the C tensor.
-  static int const kTensorStrideIdx = 
-    (kConvolutionalOperator == conv::Operator::kWgrad ? kWgradStrideIdx : 0);
+private:
+  //
+  // Data members
+  //
 
+  /// Stride data member
+  Stride stride_;
 
+public:
+  //
+  // Methods
+  //
+  
+  /// Constructor
   CUTLASS_HOST_DEVICE
-  static OutputIteratorLayout layout(const TensorRef & ref) {
-    return ref.stride(kTensorStrideIdx);
-  }
+  PitchLinear(LongIndex ldm = 0): stride_(ldm) { }
+
+  /// Constructor
+  CUTLASS_HOST_DEVICE
+  PitchLinear(Stride _stride): stride_(_stride) { }
 
+  /// Helper returns a layout to a tightly packed tensor
   CUTLASS_HOST_DEVICE
-  static OutputTensorCoord extent(ConvProblemSize problem_size) {
-    return conv::implicit_gemm_problem_size(kConvolutionalOperator, problem_size).mn();
+  static PitchLinear packed(TensorCoord const &extent) {
+    return PitchLinear(extent.contiguous());
   }
 
-};
+  /// Returns the offset of a coordinate in linear memory. 
+  /// Assumes coordinate has convention (contiguous, strided)
+  CUTLASS_HOST_DEVICE
+  LongIndex operator()(TensorCoord const &coord) const {
+    return LongIndex(coord.contiguous()) + LongIndex(coord.strided()) * LongIndex(stride_[0]);
+  }
 
+  /// Returns the logical coordinate given an offset.
+  CUTLASS_HOST_DEVICE
+  TensorCoord inverse(LongIndex index) const {
+    return make_Coord(
+      TensorCoord::Index(index % stride_[0]),
+      TensorCoord::Index(index / stride_[0])
+    );
+  }
 
+  /// Returns the stride of the layout
+  CUTLASS_HOST_DEVICE
+  Stride stride() const {
+    return stride_;
+  }
 
-template <
-  int InterleavedK,
-  typename TensorRef_,
-  conv::Operator ConvOperator,
-  typename ConvProblemSize_
->
-struct ConvOutputIteratorParameter<
-  layout::TensorNCxHWx<InterleavedK>, 
-  layout::TensorNCxHWx<InterleavedK>,
-  TensorRef_,
-  ConvOperator,
-  ConvProblemSize_>
-{ 
-
-  using TensorLayout = typename layout::TensorNCxHWx<InterleavedK>;
-  using OutputIteratorLayout = typename layout::TensorNCxHWx<InterleavedK>;
-  using OutputTensorCoord = typename OutputIteratorLayout::TensorCoord;
-  using TensorRef = TensorRef_;
-  static conv::Operator const kConvolutionalOperator = ConvOperator;
-  using ConvProblemSize = ConvProblemSize_;
+  /// Returns the stride of the layout
+  CUTLASS_HOST_DEVICE
+  Stride & stride() {
+    return stride_;
+  }
 
+  /// Returns the stride of the layout
   CUTLASS_HOST_DEVICE
-  static OutputIteratorLayout layout(const TensorRef & ref) {
-    return ref.stride();
+  LongIndex stride(int rank) const {
+    return stride_[rank];
   }
 
+  /// Returns the stride of the layout
   CUTLASS_HOST_DEVICE
-  static OutputTensorCoord extent(ConvProblemSize problem_size) {
-    return problem_size.output_extent();
+  LongIndex & stride(int rank) {
+    return stride_[rank];
   }
 
+  /// Compute the number of contiguous elements needed to store a tensor with the given size
+  CUTLASS_HOST_DEVICE
+  LongIndex capacity(TensorCoord const &extent) const {
+    return extent.strided() * stride_[0];
+  }
 };
 
-} // namespace threadblock
-} // namespace epilogue
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace layout
 } // namespace cutlass
+
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h`

 * *Files 2% similar despite different names*

```diff
@@ -47,14 +47,16 @@
 #include "cutlass/matrix_shape.h"
 #include "cutlass/tensor_ref.h"
 #include "cutlass/transform/pitch_linear_thread_map.h"
 #include "cutlass/epilogue/threadblock/output_tile_thread_map.h"
 #include "cutlass/arch/arch.h"
 #include "cutlass/arch/memory.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator_params.h"
+#include "cutlass/conv/conv2d_problem_size.h"
+#include "cutlass/conv/conv3d_problem_size.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 
 ////////////////////////////////////////////////////////////////////////////////
 
@@ -98,18 +100,18 @@
   static_assert( ThreadMap::Iterations::kRow > 0,"ThreadMap::Iterations::kRow must be > 0");
   static_assert( ThreadMap::Iterations::kGroup > 0,"ThreadMap::Iterations::kGroup must be > 0");
   static_assert( ThreadMap::Iterations::kCluster > 0,"ThreadMap::Iterations::kCluster must be > 0");
   static_assert( ThreadMap::Iterations::kColumn > 0,"ThreadMap::Iterations::kColumn must be > 0");
 
   /// Fragment object
   using Fragment = Array<
-    Element, 
-    ThreadMap::Iterations::kColumn * 
-    ThreadMap::Iterations::kRow * 
-    ThreadMap::Iterations::kGroup * 
+    Element,
+    ThreadMap::Iterations::kColumn *
+    ThreadMap::Iterations::kRow *
+    ThreadMap::Iterations::kGroup *
     ThreadMap::Iterations::kCluster * ThreadMap::kElementsPerAccess>;
 
   /// Memory access size
   using AccessType = AlignedArray<Element, ThreadMap::kElementsPerAccess>;
 
   //
   // Parameters struct
@@ -119,22 +121,36 @@
   struct Params : PredicatedTileIteratorParams {
     using Base = PredicatedTileIteratorParams;
 
     CUTLASS_HOST_DEVICE
     Params() { }
 
     CUTLASS_HOST_DEVICE
-    Params(Layout const &layout): 
+    Params(Layout const &layout):
       PredicatedTileIteratorParams(
         layout.stride(0) * int(sizeof(AccessType)) / kElementsPerAccess,
         make_OutputTileThreadMapDesc<ThreadMap>()
       ) 
     { }
 
     CUTLASS_HOST_DEVICE
+    Params(Layout const &layout,
+           // Not needed.  Added to be compatible with strided conv epilogue.
+           conv::Conv2dProblemSize const &problem_size):
+      Params(layout)
+    { }
+
+    CUTLASS_HOST_DEVICE
+    Params(Layout const &layout,
+           // Not needed.  Added to be compatible with strided conv epilogue.
+           conv::Conv3dProblemSize const &problem_size):
+      Params(layout)
+    { }
+
+    CUTLASS_HOST_DEVICE
     Params(Base const &base) : 
       Base(base) { }
   };
 
   /// Mask object
   struct Mask {
 
@@ -198,15 +214,15 @@
   /// A thread's starting column
   Index thread_start_column_;
 
   /// Internal state counter
   int state_[3];
 
   /// Scatter indices
-  int const *indices_; 
+  int const *indices_;
 
   /// PermuteDLayout
   PermuteDLayout permute_layout_;
 
   //
   // Static asserts about internal strides
   //
@@ -249,30 +265,30 @@
     thread_start_row_ = thread_offset.row();
     thread_start_column_ = thread_offset.column();
 
     // Initialize predicates
     CUTLASS_PRAGMA_UNROLL
     for (int c = 0; c < ThreadMap::Iterations::kColumn; ++c) {
 
-      mask_.predicates[c] = ((thread_offset.column() 
+      mask_.predicates[c] = ((thread_offset.column()
         + ThreadMap::Delta::kColumn * c) < extent.column());
     }
 
     // Null pointer performs no accesses
     if (!pointer) {
       mask_.clear();
     }
 
     if (ScatterD && !indices) {
       mask_.clear();
     }
 
     // Initialize byte_pointer_
-    byte_pointer_ = reinterpret_cast<uint8_t *>(pointer) + 
-      LongIndex(thread_offset.row()) * LongIndex(params_.stride) + 
+    byte_pointer_ = reinterpret_cast<uint8_t *>(pointer) +
+      LongIndex(thread_offset.row()) * LongIndex(params_.stride) +
       LongIndex(thread_offset.column()) * sizeof(AccessType) / kElementsPerAccess;
 
     if (ScatterD) {
       byte_pointer_ = reinterpret_cast<uint8_t *>(pointer) +
         LongIndex(thread_offset.column()) * sizeof(AccessType) / kElementsPerAccess;
     }
 
@@ -302,15 +318,15 @@
 
       CUTLASS_PRAGMA_UNROLL
       for (int group = 0; group < ThreadMap::Iterations::kGroup; ++group) {
 
         CUTLASS_PRAGMA_UNROLL
         for (int row = 0; row < ThreadMap::Iterations::kRow; ++row) {
 
-          int frag_row_idx = 
+          int frag_row_idx =
             (row + ThreadMap::Iterations::kRow * (group + ThreadMap::Iterations::kGroup * cluster));
 
           int row_offset = row * ThreadMap::Delta::kRow 
             + group * ThreadMap::Delta::kGroup 
             + cluster * ThreadMap::Delta::kCluster;
 
           bool row_guard = ((row_offset + thread_start_row_) < extent_row_);
@@ -326,15 +342,15 @@
 
           CUTLASS_PRAGMA_UNROLL
           for (int column = 0; column < ThreadMap::Iterations::kColumn; ++column) {
 
             bool guard = row_guard && mask_.predicates[column];
 
             cutlass::arch::global_load<
-              AccessType, 
+              AccessType,
               sizeof(AccessType)
             >(
                 frag_ptr[frag_row_idx * ThreadMap::Iterations::kColumn +
                          column],
                 (void *)&memory_pointer[column * ThreadMap::Delta::kColumn /
                                         kElementsPerAccess],
                 guard);
@@ -376,19 +392,19 @@
 
       CUTLASS_PRAGMA_UNROLL
       for (int group = 0; group < ThreadMap::Iterations::kGroup; ++group) {
 
         CUTLASS_PRAGMA_UNROLL
         for (int row = 0; row < ThreadMap::Iterations::kRow; ++row) {
 
-          int frag_row_idx = 
+          int frag_row_idx =
             (row + ThreadMap::Iterations::kRow * (group + ThreadMap::Iterations::kGroup * cluster));
 
-          int row_offset = row * ThreadMap::Delta::kRow 
-            + group * ThreadMap::Delta::kGroup 
+          int row_offset = row * ThreadMap::Delta::kRow
+            + group * ThreadMap::Delta::kGroup
             + cluster * ThreadMap::Delta::kCluster;
 
           bool row_guard = ((row_offset + thread_start_row_) < extent_row_);
 
           AccessType *memory_pointer = reinterpret_cast<AccessType *>(byte_pointer + byte_offset);
 
           if (ScatterD && row_guard) {
@@ -422,15 +438,15 @@
               }
             } else {
               cutlass::arch::global_store<AccessType, sizeof(AccessType)>(
                   frag_ptr[frag_row_idx * ThreadMap::Iterations::kColumn + column],
                   (void *)&memory_pointer[0],
                   guard);
             }
-            
+
             if (!PermuteD) {
               memory_pointer += (ThreadMap::Delta::kColumn / kElementsPerAccess);
             }
           }
 
           if (row + 1 < ThreadMap::Iterations::kRow) {
             if (!ScatterD && !PermuteD) {
@@ -645,29 +661,29 @@
     }
 
     if (!ScatterD && !PermuteD) {
       store_byte_pointer_ += params_.advance_row;
     }
 
     thread_start_row_ += ThreadMap::Shape::kRow;
-    
+
     if (state_[0] == ThreadMap::Count::kRow) {
 
       state_[0] = 0;
       ++state_[1];
 
       if (!ScatterD) {
         byte_pointer_ += params_.advance_group;
       }
 
       if (!ScatterD && !PermuteD) {
         store_byte_pointer_ += params_.advance_group;
       }
 
-      thread_start_row_ += (ThreadMap::Shape::kGroup - 1) * 
+      thread_start_row_ += (ThreadMap::Shape::kGroup - 1) *
         ThreadMap::Shape::kRow * ThreadMap::Count::kRow;
 
       if (state_[1] == ThreadMap::Count::kGroup) {
 
         state_[1] = 0;
         ++state_[2];
 
@@ -675,15 +691,15 @@
           byte_pointer_ += params_.advance_cluster;
         }
 
         if (!ScatterD && !PermuteD) {
           store_byte_pointer_ += params_.advance_cluster;
         }
 
-        thread_start_row_ += ThreadMap::Count::kGroup * 
+        thread_start_row_ += ThreadMap::Count::kGroup *
           ThreadMap::Shape::kGroup * ThreadMap::Count::kRow * ThreadMap::Shape::kRow;
 
         if (state_[2] == ThreadMap::Count::kCluster) {
           state_[2] = 0;
 
           if (!ScatterD) {
             byte_pointer_ += params_.advance_tile;
@@ -1117,14 +1133,22 @@
     }
 
     CUTLASS_HOST_DEVICE
     Params(Layout const &layout) {
 
       initialize(layout.stride());
     }
+
+    CUTLASS_HOST_DEVICE
+    Params(Layout const &layout,
+           // Not needed.  Added to be compatible with strided conv epilogue.
+           conv::Conv2dProblemSize const &problem_size):
+      Params(layout)
+    { }
+
   };
 
   /// Mask object
   struct Mask {
     static int const kCount =
         (ThreadMap::Iterations::kRow < 8) ? 8 : ThreadMap::Iterations::kRow;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h`

 * *Files 4% similar despite different names*

```diff
@@ -28,24 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
   \brief 
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 
 #include "cutlass/layout/pitch_linear.h"
 #include "cutlass/layout/matrix.h"
 
@@ -253,16 +243,14 @@
 
   CUTLASS_HOST_DEVICE
   PredicatedTileIteratorParams(LongIndex stride, OutputTileThreadMapDesc thread_map) {
     initialize(stride, thread_map);
   }
 };
 
-
-
 ///////////////////////////////////////////////////////////////////////////////
 
 //
 // Parameters struct for PredicatedTileIteratorDirect2dConv
 //
 
 struct PredicatedTileIteratorDirect2dConvParams{
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_linear.h`

 * *Files 1% similar despite different names*

```diff
@@ -62,15 +62,15 @@
 /// Tile iterator used to load output tile from shared memory in epilogue.
 ///
 /// Satisfies: ReadableTileIterator
 ///
 template <typename ThreadMap_,  ///< Thread map (conept: PitchLinearThreadMap)
           typename Element_,    ///< Element data type
           int MaxAlignment = ThreadMap_::kElementsPerAccess *sizeof_bits<Element_>::value / 8>
-class SharedLoadIteratorPitchLiner {
+class SharedLoadIteratorPitchLinear {
  public:
   using ThreadMap = ThreadMap_;
   using Element = Element_;
 
   using Layout = layout::RowMajor;
   using TensorRef = TensorRef<Element, Layout>;
   using ConstTensorRef = typename TensorRef::ConstTensorRef;
@@ -119,15 +119,15 @@
  public:
   //
   // Methods
   //
 
   /// Constructor
   CUTLASS_DEVICE
-  SharedLoadIteratorPitchLiner(TensorRef ref, int thread_idx)
+  SharedLoadIteratorPitchLinear(TensorRef ref, int thread_idx)
       : byte_pointer_(reinterpret_cast<uint8_t *>(ref.data())),
         stride_((ref.stride(0) * sizeof_bits<Element>::value) / 8),
         base_smem_address_(0) {
     TensorCoord thread_offset = ThreadMap::initial_offset(thread_idx);
 
     // Initialize pointer
     // thread_offset.row() is contiguous dim
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h`

 * *Files 16% similar despite different names*

```diff
@@ -104,15 +104,18 @@
   struct Detail {
     static int const kLanesInQuad = 4;
 
     /// Number of pointers needed to write accumulators
     static int const kPointerCount = 
       (OutputElementCount * sizeof_bits<Element>::value) / (const_min(128, OutputElementCount * sizeof_bits<Element>::value));
 
-    static_assert(kPointerCount <= 4, "Can only accommodate four pointers at present.");
+    // Currently support max 4 ptr
+    static constexpr int kMaxPointerCount{4};
+
+    static_assert(kPointerCount <= kMaxPointerCount, "Can only accommodate four pointers at present.");
     static_assert(sizeof(Element) == 4, "This can only be used with 32b accumulator data types (f32, s32).");
   };
 
   /// Padding quantity
   using Padding = MatrixShape<
     0,
     Detail::kLanesInQuad * Policy::kElementsPerAccess>;
@@ -123,32 +126,26 @@
   using AccessType = AlignedArray<Element, Policy::kElementsPerAccess>;
 
   //
   // Data members
   //
 
   /// Internal pointer to memory
-  AccessType *pointers_[Detail::kPointerCount];
+  AccessType *pointers_[Detail::kPointerCount] = {nullptr};
 
   /// Stride in units of AccessType
-  int stride_;
+  int stride_{0};
 
   /// Logical column in which warp tile is aligned
-  int warp_column_;
+  int warp_column_{0};
 
 public:
 
   /// Default constructor
-  CUTLASS_HOST_DEVICE
-  TileIteratorTensorOpMixed() {
-    CUTLASS_PRAGMA_UNROLL
-    for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
-      pointers_[i] = nullptr;
-    }
-  }
+  TileIteratorTensorOpMixed() = default;
 
   /// Constructor from TensorRef
   CUTLASS_HOST_DEVICE
   TileIteratorTensorOpMixed(
     TensorRef const &ref,
     unsigned lane_id
   ):
@@ -161,26 +158,15 @@
     CUTLASS_PRAGMA_UNROLL
     for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
       AccessType *ptr = reinterpret_cast<AccessType *>(ref.data()) + quad_id * stride_;
       int column_idx = (lane_in_quad % 2) + (((lane_in_quad / 2) + i) % Detail::kPointerCount) * 2;
 
       ptr += column_idx;
 
-      if (i == 0) {
-        pointers_[0 % Detail::kPointerCount] = ptr;
-      }
-      else if (i == 1) {
-        pointers_[1 % Detail::kPointerCount] = ptr;
-      }
-      else if (i == 2) {
-        pointers_[2 % Detail::kPointerCount] = ptr;
-      }
-      else if (i == 3) {
-        pointers_[3 % Detail::kPointerCount] = ptr;
-      }
+      pointers_[i % Detail::kPointerCount] = ptr;
     }
   }
 
   /// Adds a pointer offset
   CUTLASS_HOST_DEVICE
   TileIteratorTensorOpMixed & add_pointer_offset(Index pointer_offset) {
 
@@ -375,32 +361,26 @@
   using AccessType = AlignedArray<Element, 2>;
 
   //
   // Data members
   //
 
   /// Internal pointer to memory
-  AccessType *pointers_[Detail::kPointerCount];
+  AccessType *pointers_[Detail::kPointerCount] = {nullptr};
 
   /// Stride in units of AccessType
-  int stride_;
+  int stride_{0};
 
   /// Uniform offset in bytes added to warp tile iterator
-  int uniform_offset_[Detail::kOffsetCount];
+  int uniform_offset_[Detail::kOffsetCount] = {0};
 
 public:
 
   /// Default constructor
-  CUTLASS_HOST_DEVICE
-  TileIteratorTensorOpMixed() {
-    CUTLASS_PRAGMA_UNROLL
-    for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
-      pointers_[i] = nullptr;
-    }
-  }
+  TileIteratorTensorOpMixed() = default;
 
   /// Constructor from TensorRef
   CUTLASS_HOST_DEVICE
   TileIteratorTensorOpMixed(
     TensorRef const &ref,
     unsigned lane_id
   ):
@@ -579,29 +559,23 @@
   using AccessType = AlignedArray<Element, 2>;
 
   //
   // Data members
   //
 
   /// Internal pointer to memory
-  AccessType *pointers_[Detail::kPointerCount];
+  AccessType *pointers_[Detail::kPointerCount] = {nullptr};
 
   /// Stride in units of AccessType
-  int stride_;
+  int stride_{0};
 
 public:
 
   /// Default constructor
-  CUTLASS_HOST_DEVICE
-  TileIteratorTensorOpMixed() {
-    CUTLASS_PRAGMA_UNROLL
-    for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
-      pointers_[i] = nullptr;
-    }
-  }
+  TileIteratorTensorOpMixed() = default;
 
   /// Constructor from TensorRef
   CUTLASS_HOST_DEVICE
   TileIteratorTensorOpMixed(
     TensorRef const &ref,
     unsigned lane_id
   ):
@@ -712,14 +686,394 @@
   /// Set smem base address
   CUTLASS_HOST_DEVICE
   void set_smem_base_address(Index address) {
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Partial specialization for float x 16 => float_e4m3_t/float_e5m2_t x 16
+template <
+  typename WarpShape_,            ///< shape of warp-level GEMM (concept: GemmShape)
+  typename OperatorShape_         ///< matrix multiply operation shape (concept: gemm::GemmShape),
+>
+class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, float, 32, 8, 16, 8> {
+public:
+
+  using WarpShape = WarpShape_;
+  using OperatorShape = OperatorShape_;
+  using Element = float;
+  using Layout = layout::RowMajor;
+  static int const kOutputElementCount = 16;
+
+  using TensorRef = TensorRef<Element, Layout>;         ///< Tensor Reference object
+  using TensorCoord = MatrixCoord;                      ///< Logical coordinate in referenced tensor
+  using Index = typename TensorRef::Index;
+  using LongIndex = typename TensorRef::LongIndex;
+
+  using Policy = TensorOpPolicy<WarpShape, OperatorShape, Layout>;
+
+  /// Shape of the tile in memory
+  using Shape = MatrixShape<
+    Policy::kRowsPerIteration,
+    WarpShape::kN
+  >;
+
+  /// This is the fragment size produced by one access of the iterator.
+  using Fragment = Array<
+    Element,
+    Policy::OperatorCount::kColumn * Policy::kElementsPerAccess>;
+
+  /// This is the complete warp-level accumulator tile.
+  //using AccumulatorTile = typename Operator::FragmentC;
+
+  /// Number of times this iterator can be incremented
+  static int const kIterations = Policy::kIterations;
+
+  // Internal constants
+  struct Detail {
+    static int const kLanesInQuad = 4;
+
+    /// Number of pointers needed to write accumulators
+    static int const kPointerCount = 2;
+
+    /// Offsets added
+    static int const kOffsetCount = 4;
+
+    static_assert(sizeof(Element) == 4, "This can only be used with 32b accumulator data types (f32, s32).");
+  };
+
+  /// Padding quantity
+  using Padding = MatrixShape<0, Detail::kLanesInQuad * 2>;
+
+private:
+
+  /// Storage type for accessing memory
+  using AccessType = AlignedArray<Element, 2>;
+
+  //
+  // Data members
+  //
+
+  /// Internal pointer to memory
+  AccessType *pointers_[Detail::kPointerCount] = {nullptr};
+
+  /// Stride in units of AccessType
+  int stride_{0};
+
+  /// Uniform offset in bytes added to warp tile iterator
+  int uniform_offset_[Detail::kOffsetCount] = {0};
+
+public:
+
+  /// Default constructor
+  TileIteratorTensorOpMixed() = default;
+
+  /// Constructor from TensorRef
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed(
+    TensorRef const &ref,
+    unsigned lane_id
+  ):
+    stride_(ref.stride()[0] / AccessType::kElements) {
+
+    int quad_id = (lane_id / Detail::kLanesInQuad);
+    int lane_in_quad = (lane_id % Detail::kLanesInQuad);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < Detail::kPointerCount; ++i) {
+      AccessType *ptr = reinterpret_cast<AccessType *>(ref.data()) + quad_id * stride_;
+      int column_idx = lane_in_quad ^ (i * 2);
+
+      ptr += column_idx;
+
+      if (i == 0) {
+        pointers_[0] = ptr;
+      }
+      else if (i == 1) {
+        pointers_[1] = ptr;
+      }
+    }
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < Detail::kOffsetCount; ++i) {
+      uniform_offset_[i] = (i ^ 0) * 4 * sizeof(AccessType);
+    }
+  }
+
+  /// Adds a pointer offset
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & add_pointer_offset(Index pointer_offset) {
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
+      pointers_[i] += pointer_offset / AccessType::kElements;
+    }
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & add_tile_offset(TensorCoord const &tile_offset) {
+
+    int ptr_offset = tile_offset.row() * Shape::kRow * stride_ +
+      tile_offset.column() * Shape::kColumn / AccessType::kElements;
+
+    pointers_[0] += ptr_offset;
+    pointers_[1] += ptr_offset;
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < Detail::kOffsetCount; ++i) {
+      uniform_offset_[i] = (i ^ tile_offset.column()) * 4 * sizeof(AccessType);
+    }
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & operator+=(TensorCoord const &tile_offset) {
+    return add_tile_offset(tile_offset);
+  }
+
+  /// Store
+  CUTLASS_DEVICE
+  void store_with_pointer_offset(Fragment const &frag, Index pointer_offset) {
+
+    AccessType const *frag_ptr = reinterpret_cast<AccessType const *>(&frag);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int n = 0; n < Policy::OperatorCount::kColumn; ++n) {
+
+      int ptr_idx = (n / 4);
+      int offset_idx = (n % 4);
+
+      AccessType *ptr;
+      if (ptr_idx == 0) {
+        ptr = pointers_[0];
+      }
+      else if (ptr_idx == 1) {
+        ptr = pointers_[1];
+      }
+
+      int offset = (n / 4) * 16 + pointer_offset / AccessType::kElements;
+
+#if 0
+      //
+      // Using inline PTX to avoid generic memory
+      //
+      AccessType *smem_ptr = pointers_[ptr_idx];
+      smem_ptr[offset] = frag_ptr[n];
+#else
+      uint32_t smem_addr = arch::cutlass_get_smem_pointer(ptr);
+      uint32_t const *data = reinterpret_cast<uint32_t const *>(frag_ptr + n);
+      uint32_t offset_in_bytes = offset * sizeof(AccessType) + uniform_offset_[offset_idx];
+
+      asm volatile(
+        "{ .reg .u32 smem_ptr; add.u32 smem_ptr, %0, %1; st.shared.v2.u32 [smem_ptr], {%2, %3}; }\n"
+        : : "r"(smem_addr), "r"(offset_in_bytes), "r"(data[0]), "r"(data[1])
+      );
+#endif
+    }
+  }
+
+  /// Store
+  CUTLASS_HOST_DEVICE
+  void store(Fragment const &frag) {
+    store_with_pointer_offset(frag, 0);
+  }
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Partial specialization for float x 8 => float_e4m3_t/float_e5m2_t x 8
+template <
+  typename WarpShape_,            ///< shape of warp-level GEMM (concept: GemmShape)
+  typename OperatorShape_         ///< matrix multiply operation shape (concept: gemm::GemmShape)
+>
+class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, float, 32, 8, 8, 8> {
+public:
+
+  using WarpShape = WarpShape_;
+  using OperatorShape = OperatorShape_;
+  using Element = float;
+  using Layout = layout::RowMajor;
+  static int const kOutputElementCount = 8;
+
+  using TensorRef = TensorRef<Element, Layout>;         ///< Tensor Reference object
+  using TensorCoord = MatrixCoord;                      ///< Logical coordinate in referenced tensor
+  using Index = typename TensorRef::Index;
+  using LongIndex = typename TensorRef::LongIndex;
+
+  using Policy = TensorOpPolicy<WarpShape, OperatorShape, Layout>;
+
+  /// Shape of the tile in memory
+  using Shape = MatrixShape<
+    Policy::kRowsPerIteration,
+    WarpShape::kN
+  >;
+
+  /// This is the fragment size produced by one access of the iterator.
+  using Fragment = Array<
+    Element,
+    Policy::OperatorCount::kColumn * Policy::kElementsPerAccess>;
+
+  /// This is the complete warp-level accumulator tile.
+  //using AccumulatorTile = typename Operator::FragmentC;
+
+  /// Number of times this iterator can be incremented
+  static int const kIterations = Policy::kIterations;
+
+  // Internal constants
+  struct Detail {
+    static int const kLanesInQuad = 4;
+
+    /// Number of pointers needed to write accumulators
+    static int const kPointerCount = 2;
+
+    static_assert(sizeof(Element) == 4, "This can only be used with 32b accumulator data types (f32, s32).");
+  };
+
+  /// Padding quantity
+  using Padding = MatrixShape<0, Detail::kLanesInQuad * 2>;
+
+private:
+
+  /// Storage type for accessing memory
+  using AccessType = AlignedArray<Element, 2>;
+
+  //
+  // Data members
+  //
+
+  /// Internal pointer to memory
+  AccessType *pointers_[Detail::kPointerCount] = {nullptr};
+
+  /// Stride in units of AccessType
+  int stride_{0};
+
+public:
+
+  /// Default constructor
+  TileIteratorTensorOpMixed() = default;
+
+  /// Constructor from TensorRef
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed(
+    TensorRef const &ref,
+    unsigned lane_id
+  ):
+    stride_(ref.stride()[0] / AccessType::kElements) {
+
+    int quad_id = (lane_id / Detail::kLanesInQuad);
+    int lane_in_quad = (lane_id % Detail::kLanesInQuad);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < Detail::kPointerCount; ++i) {
+      AccessType *ptr = reinterpret_cast<AccessType *>(ref.data()) + quad_id * stride_;
+      int column_idx = lane_in_quad ^ (i * 2);
+
+      ptr += column_idx;
+
+      if (i == 0) {
+        pointers_[0] = ptr;
+      }
+      else if (i == 1) {
+        pointers_[1] = ptr;
+      }
+    }
+  }
+
+  /// Adds a pointer offset
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & add_pointer_offset(Index pointer_offset) {
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int64_t i = 0; i < Detail::kPointerCount; ++i) {
+      pointers_[i] += pointer_offset / AccessType::kElements;
+    }
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & add_tile_offset(TensorCoord const &tile_offset) {
+
+    int ptr_offset = tile_offset.row() * Shape::kRow * stride_ +
+      tile_offset.column() * Shape::kColumn / AccessType::kElements;
+
+    pointers_[0] += ptr_offset;
+    pointers_[1] += ptr_offset;
+
+    if (tile_offset.column() % 2) {
+      auto tmp = pointers_[0];
+      pointers_[0] = pointers_[1];
+      pointers_[1] = tmp;
+    }
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_HOST_DEVICE
+  TileIteratorTensorOpMixed & operator+=(TensorCoord const &tile_offset) {
+    return add_tile_offset(tile_offset);
+  }
+
+  /// Store
+  CUTLASS_DEVICE
+  void store_with_pointer_offset(Fragment const &frag, Index pointer_offset) {
+
+    AccessType const *frag_ptr = reinterpret_cast<AccessType const *>(&frag);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int n = 0; n < Policy::OperatorCount::kColumn; ++n) {
+
+      int ptr_idx = (n / 4);
+
+      AccessType *ptr;
+      if (ptr_idx == 0) {
+        ptr = pointers_[0];
+      }
+      else if (ptr_idx == 1) {
+        ptr = pointers_[1];
+      }
+
+      int offset = (n / 4) * 16 + pointer_offset / AccessType::kElements + (n % 4) * 4;
+
+#if 0
+      //
+      // Using inline PTX to avoid generic memory
+      //
+      AccessType *smem_ptr = pointers_[ptr_idx];
+      smem_ptr[offset] = frag_ptr[n];
+#else
+      uint32_t smem_addr = arch::cutlass_get_smem_pointer(ptr);
+      uint32_t const *data = reinterpret_cast<uint32_t const *>(frag_ptr + n);
+      uint32_t offset_in_bytes = offset * sizeof(AccessType);
+
+      asm volatile(
+        "{ .reg .u32 smem_ptr; add.u32 smem_ptr, %0, %1; st.shared.v2.u32 [smem_ptr], {%2, %3}; }\n"
+        : : "r"(smem_addr), "r"(offset_in_bytes), "r"(data[0]), "r"(data[1])
+      );
+#endif
+    }
+  }
+
+  /// Store
+  CUTLASS_HOST_DEVICE
+  void store(Fragment const &frag) {
+    store_with_pointer_offset(frag, 0);
+  }
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
 } // namespace warp
 } // namespace epilogue
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #undef CUTLASS_EPILOGUE_WARP_TILE_ITERATOR_TENSOR_OP_MIXED_OPTIMIZATION_ENABLED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/fast_math.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/fast_math.h`

 * *Files 2% similar despite different names*

```diff
@@ -24,23 +24,14 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/cstdint>
 #else
 #include <cstdint>
@@ -149,21 +140,23 @@
  * Rounding
  ******************************************************************************/
 
 /**
  * Round dividend up to the nearest multiple of divisor
  */
 template <typename dividend_t, typename divisor_t>
-CUTLASS_HOST_DEVICE dividend_t round_nearest(dividend_t dividend, divisor_t divisor) {
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
+dividend_t round_nearest(dividend_t dividend, divisor_t divisor) {
   return ((dividend + divisor - 1) / divisor) * divisor;
 }
 
 template <typename value_t>
 CUTLASS_HOST_DEVICE
-constexpr
+CUTLASS_CONSTEXPR_IF_CXX17
 value_t abs_for_integer(value_t a) {
   return ((a > 0) ? a : -a);
 }
 /**
  * Greatest common divisor
  */
 template <typename value_t>
@@ -181,39 +174,38 @@
 /**
  * Least common multiple
  */
 template <typename value_t>
 CUTLASS_HOST_DEVICE
 CUTLASS_CONSTEXPR_IF_CXX17
 value_t lcm(value_t a, value_t b) {
-  value_t temp = gcd(a, b);
-
-  return temp ? (cutlass::abs_for_integer(a) / temp * cutlass::abs_for_integer(b)) : value_t();
+  value_t temp = cutlass::gcd(a, b);
+  return (temp != 0) ? value_t(cutlass::abs_for_integer(a) / temp * cutlass::abs_for_integer(b)) : value_t{};
 }
 
 /**
  * Greatest common divisor
  */
 template <typename value_t>
 CUTLASS_HOST_DEVICE
-constexpr
+CUTLASS_CONSTEXPR_IF_CXX17
 value_t gcd_cxx11(value_t a, value_t b) {
-  return (a == 0 || b == 0) ? cutlass::abs_for_integer(a | b) : gcd_cxx11(b, a % b);
+  return (a == 0 || b == 0) ? cutlass::abs_for_integer(a | b) : cutlass::gcd_cxx11(b, a % b);
 }
 
 /**
  * Least common multiple
  */
 template <typename value_t>
 CUTLASS_HOST_DEVICE
-constexpr
+CUTLASS_CONSTEXPR_IF_CXX17
 value_t lcm_cxx11(value_t a, value_t b) {
-  return gcd_cxx11(a, b) ? (cutlass::abs_for_integer(a) / gcd_cxx11(a, b) *
-                            cutlass::abs_for_integer(b))
-                         : value_t();
+  return cutlass::gcd_cxx11(a, b) ? (cutlass::abs_for_integer(a) / cutlass::gcd_cxx11(a, b) *
+                                    cutlass::abs_for_integer(b))
+                                  : value_t{};
 }
 
 /// Returns the smallest value in the half-open range [a, a+b) that is a multiple of b
 CUTLASS_HOST_DEVICE
 CUTLASS_CONSTEXPR_IF_CXX17
 int round_up(int a, int b) {
   return ((a + b - 1) / b) * b;
@@ -230,34 +222,39 @@
 
 /**
  * log2 computation, what's the
  * difference between the below codes and
  * log2_up/down codes?
  */
 template <typename value_t>
-CUTLASS_HOST_DEVICE value_t clz(value_t x) {
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
+value_t clz(value_t x) {
   for (int i = 31; i >= 0; --i) {
     if ((1 << i) & x)
       return value_t(31 - i);
   }
-  return 32;
+  return value_t(32);
 }
 
 template <typename value_t>
-CUTLASS_HOST_DEVICE value_t find_log2(value_t x) {
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
+value_t find_log2(value_t x) {
   int a = int(31 - clz(x));
   a += (x & (x - 1)) != 0;  // Round up, add 1 if not a power of 2.
   return a;
 }
 
 
 /**
  * Find divisor, using find_log2
  */
-CUTLASS_HOST_DEVICE 
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
 void find_divisor(unsigned int& mul, unsigned int& shr, unsigned int denom) {
   if (denom == 1) {
     mul = 0;
     shr = 0;
   } else {
     unsigned int p = 31 + find_log2(denom);
     unsigned m = unsigned(((1ull << p) + unsigned(denom) - 1) / unsigned(denom));
@@ -266,15 +263,16 @@
     shr = p - 32;
   }
 }
 
 /**
  * Find quotient and remainder using device-side intrinsics
  */
-CUTLASS_HOST_DEVICE 
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
 void fast_divmod(int& quo, int& rem, int src, int div, unsigned int mul, unsigned int shr) {
 
   #if defined(__CUDA_ARCH__)
   // Use IMUL.HI if div != 1, else simply copy the source.
   quo = (div != 1) ? __umulhi(src, mul) >> shr : src;
   #else
   quo = int((div != 1) ? int(((int64_t)src * mul) >> 32) >> shr : src);
@@ -282,14 +280,15 @@
 
   // The remainder.
   rem = src - (quo * div);
 }
 
 // For long int input
 CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
 void fast_divmod(int& quo, int64_t& rem, int64_t src, int div, unsigned int mul, unsigned int shr) {
 
   #if defined(__CUDA_ARCH__)
   // Use IMUL.HI if div != 1, else simply copy the source.
   quo = (div != 1) ? __umulhi(src, mul) >> shr : src;
   #else
   quo = int((div != 1) ? ((src * mul) >> 32) >> shr : src);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/float8.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/float8.h`

 * *Files 2% similar despite different names*

```diff
@@ -29,36 +29,31 @@
  *
  **************************************************************************************************/
 /*!
     \file
     \brief Defines a class for using IEEE half-precision floating-point types in host or
       device code.
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 
 #pragma once
 
 // FP8 types are available starting CUDA 11.8+
 #if (__CUDACC_VER_MAJOR__ >= 12) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 8))
 #define CUDA_FP8_ENABLED 1
 #endif
 
 #if defined(__CUDA_ARCH__)
 #  if (__CUDA_ARCH__ >= 900)
 #    if (__CUDACC_VER_MAJOR__ >= 12) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 8))
 #      define CUDA_PTX_FP8_CVT_ENABLED 1
 #    endif // (__CUDACC_VER_MAJOR__ >= 12) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 8))
+#  elif (__CUDA_ARCH__ == 890)
+#    if (__CUDACC_VER_MAJOR__ > 12) || ((__CUDACC_VER_MAJOR__ == 12) && (__CUDACC_VER_MINOR__ >= 1))
+#      define CUDA_PTX_FP8_CVT_ENABLED 1
+#    endif // (__CUDACC_VER_MAJOR__ > 12) || ((__CUDACC_VER_MAJOR__ == 12) && (__CUDACC_VER_MINOR__ >= 1))
 #  endif // (__CUDA_ARCH__ >= 900)
 #endif // defined(__CUDA_ARCH__)
 
 #ifdef __GNUC__
 // Ignore checks on reinterpret-casts that are being used for bitcasts.
 #pragma GCC diagnostic ignored "-Wstrict-aliasing"
 #endif
@@ -127,15 +122,15 @@
     static constexpr int FP16_MAX_EXPONENT  = 15;
     static constexpr int FP16_MIN_EXPONENT  = -14;
     static constexpr int FP16_EXPONENT_BIAS = 15;
 
     static constexpr int FP8_NUM_BITS = 8;
     static constexpr int FP8_NUM_EXPONENT_BITS = IS_E4M3 ? 4 : 5;
     static constexpr int FP8_NUM_MANTISSA_BITS = IS_E4M3 ? 3 : 2;
-    static constexpr uint8_t  FP8_NAN = 0x7f; // Also F8_INF 
+    static constexpr uint8_t  FP8_NAN = 0x7f; // Also F8_INF
     static constexpr uint8_t  FP8_INFINITY_MASK = IS_E4M3 ? 0x78 : 0x7c;
     static constexpr int FP8_MAX_EXPONENT  = IS_E4M3 ?  7 :  15;
     static constexpr int FP8_MIN_EXPONENT  = IS_E4M3 ? -6 : -14;
     static constexpr int FP8_EXPONENT_BIAS = IS_E4M3 ?  7 :  15;
 
     static constexpr uint8_t  FP8_EXPONENT_MASK = (1 << FP8_NUM_EXPONENT_BITS) - 1;
     static constexpr uint8_t  FP8_MANTISSA_MASK = (1 << FP8_NUM_MANTISSA_BITS) - 1;
@@ -1035,14 +1030,42 @@
 
 /// float_e5m2_t <= float_e4m3_t
 CUTLASS_HOST_DEVICE
 float_e5m2_t::float_e5m2_t(float_e4m3_t x) {
     storage = from_float(float_e4m3_t::to_float(x)).storage;
 }
 
+///////////////////////////////////////////////////////////////
+///
+/// Umbrella floating-point 8-bit data type : type_erased_dynamic_float8_t
+/// This umbrella datatype can be enabled when a user provides a specific
+/// datatype in runtime argument list.
+///
+/// Currently supported runtime datatypes compatible with type_erased_dynamic_float8_t:
+///   QMMAFormat::E5M2
+///   QMMAFormat::E4M3
+///
+///////////////////////////////////////////////////////////////
+
+union type_erased_dynamic_float8_t {
+  uint8_t data;
+  cutlass::float_e5m2_t e5m2;
+  cutlass::float_e4m3_t e4m3;
+  CUTLASS_HOST_DEVICE
+  explicit operator cutlass::float_e5m2_t() const {
+    return e5m2;
+  }
+
+  CUTLASS_HOST_DEVICE
+  explicit operator cutlass::float_e4m3_t() const {
+    return e4m3;
+  }
+
+};
+
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 //
 // Standard Library operations and definitions
@@ -1069,32 +1092,39 @@
   static std::float_round_style const round_style = std::round_to_nearest;
   static bool const is_iec559 = false;
   static bool const is_bounded = true;
   static bool const is_modulo = false;
   static int const digits = F8Type::FP8_NUM_MANTISSA_BITS;
 
   /// Least positive value
+  CUTLASS_HOST_DEVICE
   static F8Type min() { return F8Type::bitcast(0x01); }
 
   /// Maximum finite value
+  CUTLASS_HOST_DEVICE
   static F8Type max() { return F8Type::bitcast(F8Type::FP8_MAX_FLT); }
 
   /// Returns maximum rounding error
+  CUTLASS_HOST_DEVICE
   static F8Type round_error() { return F8Type(0.5f); }
 
   /// Returns positive infinity value
+  CUTLASS_HOST_DEVICE
   static F8Type infinity() { return F8Type::bitcast(F8Type::FP8_INFINITY_MASK); }
 
   /// Returns quiet NaN value
+  CUTLASS_HOST_DEVICE
   static F8Type quiet_NaN() { return F8Type::bitcast(F8Type::FP8_NAN); }
 
   /// Returns signaling NaN value
+  CUTLASS_HOST_DEVICE
   static F8Type signaling_NaN() { return F8Type::bitcast(F8Type::FP8_NAN); }
 
   /// Returns smallest positive subnormal value
+  CUTLASS_HOST_DEVICE
   static F8Type denorm_min() { return F8Type::bitcast(0x01); }
 };
 
 /// Numeric limits for float_e4m3_t
 template <>
 struct numeric_limits<cutlass::float_e4m3_t> :
     public float8_base_numeric_limits<cutlass::float_e4m3_t> {
@@ -1146,32 +1176,39 @@
 #endif
   static bool const is_iec559 = false;
   static bool const is_bounded = true;
   static bool const is_modulo = false;
   static int const digits = F8Type::FP8_NUM_MANTISSA_BITS;
 
   /// Least positive value
+  CUTLASS_HOST_DEVICE
   static F8Type min() { return F8Type::bitcast(0x01); }
 
   /// Maximum finite value
+  CUTLASS_HOST_DEVICE
   static F8Type max() { return F8Type::bitcast(F8Type::FP8_MAX_FLT); }
 
   /// Returns maximum rounding error
+  CUTLASS_HOST_DEVICE
   static F8Type round_error() { return F8Type(0.5f); }
 
   /// Returns positive infinity value
+  CUTLASS_HOST_DEVICE
   static F8Type infinity() { return F8Type::bitcast(F8Type::FP8_INFINITY_MASK); }
 
   /// Returns quiet NaN value
+  CUTLASS_HOST_DEVICE
   static F8Type quiet_NaN() { return F8Type::bitcast(F8Type::FP8_NAN); }
 
   /// Returns signaling NaN value
+  CUTLASS_HOST_DEVICE
   static F8Type signaling_NaN() { return F8Type::bitcast(F8Type::FP8_NAN); }
 
   /// Returns smallest positive subnormal value
+  CUTLASS_HOST_DEVICE
   static F8Type denorm_min() { return F8Type::bitcast(0x01); }
 };
 
 /// std::numeric_limits
 template <class T>
 struct numeric_limits;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/floating_point_nvrtc.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/functional.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/functional.h`

 * *Files 2% similar despite different names*

```diff
@@ -29,29 +29,20 @@
  *
  **************************************************************************************************/
 /*! \file
     \brief Define basic numeric operators
 
     This is inspired by the Standard Library's <functional> header.
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/half.h"
-#include "cutlass/tfloat32.h"
-#include "cutlass/bfloat16.h"
+#include "cutlass/numeric_types.h"
+
+#include <cuda_runtime.h>
 
 #if defined(CUTLASS_ARCH_WMMA_ENABLED)
 #include <mma.h>
 #endif // defined(CUTLASS_ARCH_WMMA_ENABLED)
 
 #ifdef _MSC_VER
 // Provides support for alternate operators such as 'and', 'or', ...
@@ -102,15 +93,15 @@
     return lhs;
   }
 };
 
 template <typename T>
 struct scale {
   T const scaling_factor_;
-  
+
   CUTLASS_HOST_DEVICE
   scale(float scaling_factor) : scaling_factor_(scaling_factor) {
   }
 
   T operator()(T const &rhs) const {
     T result = rhs * scaling_factor_;
     return result;
@@ -214,37 +205,66 @@
     multiplies<Output> mul_op;
 
     Output y = Output(lhs) - Output(rhs);
     return mul_op(y, y);
   }
 };
 
+// Computes the reciprocal square root
+template <typename T>
+struct inverse_square_root;
+
+template <>
+struct inverse_square_root<float> {
+  CUTLASS_HOST_DEVICE
+  float operator()(float const &lhs) const {
+#if defined(__CUDA_ARCH__)
+    return rsqrtf(lhs);
+#else
+    return 1.f / std::sqrt(lhs);
+#endif
+  }
+};
+
+template <>
+struct inverse_square_root<half_t> {
+  CUTLASS_HOST_DEVICE
+  half_t operator()(half_t const &lhs) const {
+#if defined(__CUDA_ARCH__)
+    auto result = hrsqrt(reinterpret_cast<__half const &>(lhs));
+    return reinterpret_cast<half_t const &>(result);
+#else
+    return half_t(1.f / std::sqrt(half_t::convert(lhs)));
+#endif
+  }
+};
+
 /// Divides
 template <typename T>
 struct divides {
   CUTLASS_HOST_DEVICE
   T operator()(T lhs, T const &rhs) const {
     lhs /= rhs;
     return lhs;
   }
 };
 
-/// reciprocal_approximate 
+/// reciprocal_approximate
 template <typename T>
 struct reciprocal_approximate {
   CUTLASS_HOST_DEVICE
   T operator()(T lhs) const {
-    return divide(T(1), lhs);
+    return divides<T>{}(T(1), lhs);
   }
 };
 
 template <>
 struct reciprocal_approximate <float> {
   CUTLASS_HOST_DEVICE
-  float operator()(float lhs) const { 
+  float operator()(float lhs) const {
     float ret;
       ret = 1.0f / lhs;
     return ret;
   }
 };
 
 /// Negate
@@ -252,42 +272,42 @@
 struct negate {
   CUTLASS_HOST_DEVICE
   T operator()(T lhs) const {
     return -lhs;
   }
 };
 
-/// Greater equal 
+/// Greater equal
 template <typename T>
 struct greater_equal {
   CUTLASS_HOST_DEVICE
   bool operator()(T const &lhs, T const &rhs) const {
     return (lhs >= rhs);
   }
 };
 
-/// Greater  
+/// Greater
 template <typename T>
 struct greater {
   CUTLASS_HOST_DEVICE
   bool operator()(T const &lhs, T const &rhs) const {
     return (lhs > rhs);
   }
 };
 
-/// Less equal 
+/// Less equal
 template <typename T>
 struct less_equal {
   CUTLASS_HOST_DEVICE
   bool operator()(T const &lhs, T const &rhs) const {
     return (lhs <= rhs);
   }
 };
 
-/// Less  
+/// Less
 template <typename T>
 struct less {
   CUTLASS_HOST_DEVICE
   bool operator()(T const &lhs, T const &rhs) const {
     return (lhs < rhs);
   }
 };
@@ -417,14 +437,23 @@
 struct multiply_add {
   CUTLASS_HOST_DEVICE
   C operator()(A const &a, B const &b, C const &c) const {
     return C(a) * C(b) + c;
   }
 };
 
+template <typename T>
+struct square_and_plus {
+  CUTLASS_HOST_DEVICE
+  T operator()(T lhs, T const &rhs) const {
+    multiply_add<T> multiply_add_op;
+    return multiply_add_op(rhs, rhs, lhs);
+  }
+};
+
 // Fused multiply-add that takes exactly one template parameter.
 // This is useful for working around a known Clang issue,
 // where a template template parameter with one template parameter
 // does not match classes that take multiple template parameters
 // but have defaults for all but the first.
 template <typename A>
 struct homogeneous_multiply_add : public multiply_add<A, A, A>
@@ -469,31 +498,35 @@
 
 template <typename T>
 struct first {
   CUTLASS_HOST_DEVICE
   T operator()(T const & first, T const &...) const {
     return first;
   }
+  CUTLASS_HOST_DEVICE
+  T operator()(T const & first) const {
+    return first;
+  }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename T>
 struct logical_and {
   CUTLASS_HOST_DEVICE
   T operator()(T const &a, T const &b) const {
-    return ((a && b) ? T(1) : T());
+    return ((static_cast<bool>(a) && static_cast<bool>(b)) ? T(1) : T());
   }
 };
 
 template <typename T>
 struct logical_or {
   CUTLASS_HOST_DEVICE
   T operator()(T const &a, T const &b) const {
-    return ((a || b) ? T(1) : T());
+    return ((static_cast<bool>(a) || static_cast<bool>(b)) ? T(1) : T());
   }
 };
 
 template <typename T>
 struct logical_not {
   CUTLASS_HOST_DEVICE
   T operator()(T const &a) const {
@@ -531,16 +564,14 @@
 struct bit_xor {
   CUTLASS_HOST_DEVICE
   T operator()(T const &a, T const &b) const {
     return a ^ b;
   }
 };
 
-
-
 //////////////////////////////////////////////////////////////////////////////////////////////////
 /// Atomic reductions
 
 template <typename T>
 struct atomic_add
 {
   CUTLASS_DEVICE
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -35,18 +35,28 @@
 
 namespace cutlass::gemm::collective {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Used to specify stage counts or dispatch to automatic computation of stage count
 template<int num_stages>
-struct StageCount { static constexpr int value = num_stages; };
+struct StageCount {
+  static constexpr int value = num_stages;
+
+  StageCount() = default;
+  explicit StageCount(cute::Int<num_stages>) {}
+};
 
 template<int carveout_bytes>
-struct StageCountAutoCarveout { static constexpr int bytes = carveout_bytes; };
+struct StageCountAutoCarveout {
+  static constexpr int bytes = carveout_bytes;
+
+  StageCountAutoCarveout() = default;
+  explicit StageCountAutoCarveout(cute::Int<carveout_bytes>) {}
+};
 
 using StageCountAuto = StageCountAutoCarveout<0>;
 
 // Used to automatically let the builder pick the kernel schedule.
 // Can be overridden with kernel schedule tags in cutlass/gemm/dispatch_policy.hpp
 struct KernelScheduleAuto {};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/fp8_accumulation.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/fp8_accumulation.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -96,14 +96,17 @@
   using SmemLayoutAtomA = SmemLayoutAtomA_;
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
+  // Follow the change in TestSmall: TileShape switch to CtaShape 
+  // For sm80 arch, CtaShape should euqal to TileShape
+  using CtaShape_MNK = TileShape;
 
   static_assert(cute::rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   static_assert(cute::rank(SmemLayoutAtomB{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
@@ -328,14 +331,16 @@
         cute::transform(tCrB(_,_,k_block), TransformB{});
         // Thread-level register gemm for k_block
         cute::gemm(tiled_mma, accum, tCrA(_,_,k_block), tCrB(_,_,k_block), src_accum);
       });
 
     }
 
+    cp_async_wait<0>();
+    __syncthreads();
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   int Stages,
@@ -373,29 +378,31 @@
    >
 {
   //
   // Type Aliases
   //
   using DispatchPolicy = MainloopSm80CpAsync<Stages>;
   using TileShape = TileShape_;
+  // Follow the change in TestSmall: TileShape switch to CtaShape 
+  // In legacy arch, it should be same
+  using CtaShape_MNK = TileShape;
   using ElementA = ElementA_;
   using StrideA = StrideA_;
   using ElementB = ElementB_;
   using StrideB = StrideB_;
   using TiledMma = TiledMma_;
   using ElementAccumulator = typename TiledMma::ValTypeC;  using GmemTiledCopyA = GmemTiledCopyA_;
   using GmemTiledCopyB = GmemTiledCopyB_;
   using SmemLayoutAtomA = SmemLayoutAtomA_;
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
-
   static_assert(cute::rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   static_assert(cute::rank(SmemLayoutAtomB{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
@@ -676,14 +683,16 @@
         cute::transform(tCrB(_,_,k_block), TransformB{});
         // Thread-level register gemm for k_block
         cute::gemm(tiled_mma, accum, tCrA(_,_,k_block), tCrB(_,_,k_block), src_accum);
       });
 
     }
 
+    cp_async_wait<0>();
+    __syncthreads();
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass::gemm::collective
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -27,25 +27,26 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/numeric_types.h"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/trace.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -109,32 +110,32 @@
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
 
   using MainloopPipeline = cutlass::PipelineTmaAsync<DispatchPolicy::Stages>;
   using PipelineState = cutlass::PipelineState<DispatchPolicy::Stages>;
 
   using PipelineParams = typename MainloopPipeline::Params;
-
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   static_assert(rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   static_assert(rank(SmemLayoutAtomB{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       SmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       SmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(DispatchPolicy::Stages >= 2, "Specialization requires Stages set to value 2 or more.");
   static_assert(cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeA>::value &&
                 cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeB>::value,
                 "MMA atom must source both A and B operand from smem_desc for this mainloop.");
   static_assert(cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
@@ -308,17 +309,16 @@
     }
     return implementable;
   }
 
   static constexpr int K_PIPE_MAX = DispatchPolicy::Stages;
   static constexpr int K_PIPE_MMAS = 1;
   static constexpr uint32_t TmaTransactionBytes =
-        (size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value)) / 8+
-        (size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value)) / 8;
-
+        cutlass::bits_to_bytes(size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value))+
+        cutlass::bits_to_bytes(size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value));
 
   // Set up the data needed by this collective for load and mma.
   // Returns a tuple of tensors. The collective and the kernel layer have the contract that the
   // returned tuple must contain at least two elements, with the first two elements being:
   // gA_mkl - The tma tensor, A after a local tile so it has shape  (BLK_M,BLK_K,m,k,l)
   // gB_nkl - The tma tensor, B after a local tile so it has shape  (BLK_N,BLK_K,n,k,l)
   // The rest of the tensors can be specified as needed by this collective.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_rs_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_rs_warpspecialized.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -27,26 +27,27 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/numeric_types.h"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
+#include "cutlass/trace.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -102,14 +103,15 @@
   using GmemTiledCopyA = GmemTiledCopyA_;
   using GmemTiledCopyB = GmemTiledCopyB_;
   using SmemLayoutAtomA = SmemLayoutAtomA_;
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   // Swap and transpose A/B for A k-major layout and B mn-major layout since WGMMA is k-major only (e.g. tf32, Fp32, Int8, Fp8 WGMMA)
   static constexpr bool IsLayoutAkBmn =
     cute::is_same_v<gemm::detail::StrideToLayoutTagA_t<StrideA>, layout::RowMajor> &&
     cute::is_same_v<gemm::detail::StrideToLayoutTagB_t<StrideB>, layout::RowMajor>;
 
   static constexpr bool IsInputSizeTwoBytes = sizeof(ElementA) == 2 && sizeof(ElementB) == 2;
   static constexpr bool SwapAB =  !IsInputSizeTwoBytes && IsLayoutAkBmn;
@@ -174,15 +176,15 @@
   using GmmaSmemLayoutB = decltype(tile_to_shape(
       GmmaSmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{})));
 
   static_assert(!SwapAB || !TransposeB, "Cannot SwapAB and TransposeB at the same time.");
   static_assert(TransposeB xor (cute::is_same_v<SmemLayoutB, GmmaSmemLayoutB>),
     "Should be same layout if not TransposeB.");
-  static_assert(!TransposeB || ((size<1>(SmemLayoutB{}) * sizeof_bits<InternalElementB>::value) / 8) == 128,
+  static_assert(!TransposeB || (cutlass::bits_to_bytes(size<1>(SmemLayoutB{}) * sizeof_bits<InternalElementB>::value)) == 128,
     "SmemLayoutB K must be 128bytes to be transposed.");
   static_assert(!transform::collective::detail::use_universal_transposition<InternalSmemLayoutAtomB, InternalElementB>(),
     "Warp specialized ARF kernels have not supported universal B transposition yet.");
 
   struct SharedStorage
   {
     struct TensorStorage : cute::aligned_struct<256> {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss_warpspecialized.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -104,14 +104,15 @@
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   using MainloopPipeline = cutlass::PipelineAsync<DispatchPolicy::Stages>;
   using PipelineState    = typename MainloopPipeline::PipelineState;
   using PipelineParams   = typename MainloopPipeline::Params;
 
   static_assert(cute::rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -27,29 +27,30 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/detail/dependent_false.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
 #include "cutlass/detail/layout.hpp"
+#include "cutlass/numeric_types.h"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
+#include "cutlass/trace.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -104,14 +105,15 @@
   using GmemTiledCopyA = GmemTiledCopyA_;
   using GmemTiledCopyB = GmemTiledCopyB_;
   using SmemLayoutAtomA = SmemLayoutAtomA_;
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   // Swap and transpose A/B for A k-major layout and B mn-major layout since WGMMA is k-major only (e.g. tf32, Fp32, Int8, Fp8 WGMMA)
   static constexpr bool IsLayoutAkBmn =
     cute::is_same_v<gemm::detail::StrideToLayoutTagA_t<StrideA>, layout::RowMajor> &&
     cute::is_same_v<gemm::detail::StrideToLayoutTagB_t<StrideB>, layout::RowMajor>;
 
   static constexpr bool IsInputSizeTwoBytes = sizeof(ElementA) == 2 && sizeof(ElementB) == 2;
   static constexpr bool SwapAB =  !IsInputSizeTwoBytes && IsLayoutAkBmn;
@@ -147,19 +149,19 @@
   static_assert((size<1>(TileShape{}) % size<0>(InternalSmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(InternalSmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       InternalSmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       InternalSmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   // If A mn-layout and B mn-layout, transposing B matrix since WGMMA is k-major only (e.g. tf32, fp32, fp8, int8).
   static constexpr bool IsLayoutAmnBmn =
     cute::is_same_v<gemm::detail::StrideToLayoutTagA_t<StrideA>, layout::ColumnMajor> &&
     cute::is_same_v<gemm::detail::StrideToLayoutTagB_t<StrideB>, layout::RowMajor>;
   static constexpr bool TransposeB = !IsInputSizeTwoBytes && IsLayoutAmnBmn;
   using TransposeOperandB = decltype(cutlass::transform::collective::detail::make_transpose_operand_b(
@@ -178,20 +180,20 @@
   using GmmaSmemLayoutAtomB = decltype(transform::collective::detail::gmma_smem_transpose_or_passthrough<
       TransposeB, InternalSmemLayoutAtomB, InternalElementB>());
 
   // SmemLayoutB for GMMA is different from SmemLayoutB for TMA if TransposeB
   using GmmaSmemLayoutB = decltype(tile_to_shape(
       GmmaSmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(!SwapAB || !TransposeB, "Cannot SwapAB and TransposeB at the same time.");
   static_assert(TransposeB xor (cute::is_same_v<SmemLayoutB, GmmaSmemLayoutB>),
     "Should be same layout if not TransposeB.");
-  static_assert(!TransposeB || (((size<1>(SmemLayoutB{}) * sizeof_bits<InternalElementB>::value)) / 8) == 128,
+  static_assert(!TransposeB || (cutlass::bits_to_bytes((size<1>(SmemLayoutB{}) * sizeof_bits<InternalElementB>::value))) == 128,
     "SmemLayoutB K must be 128bytes to be transposed.");
 
   static constexpr bool uses_universal_transposition() {
     if constexpr (TransposeB) {
       return transform::collective::detail::use_universal_transposition<InternalSmemLayoutAtomB, InternalElementB>();
     }
     else {
@@ -325,16 +327,16 @@
       CUTLASS_TRACE_HOST("  CAN IMPLEMENT: Problem Size doesn't meet the minimum alignment requirements for TMA.\n");
     }
     return implementable;
   }
 
   static constexpr int K_PIPE_MAX = DispatchPolicy::Stages;
   static constexpr uint32_t TmaTransactionBytes =
-        (size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<InternalElementA>::value)) / 8 +
-        (size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<InternalElementB>::value)) / 8 ;
+        cutlass::bits_to_bytes(size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<InternalElementA>::value)) +
+        cutlass::bits_to_bytes(size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<InternalElementB>::value)) ;
 
   /// Issue Tma Descriptor Prefetch -- ideally from a single thread for best performance
   CUTLASS_DEVICE
   static void prefetch_tma_descriptors(Params const& mainloop_params) {
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_a.get_tma_descriptor());
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_b.get_tma_descriptor());
   }
@@ -543,14 +545,15 @@
     CUTE_STATIC_ASSERT_V(size<2>(tCsA_copy_view) == size<2>(tCrA_copy_view));                                  // CPY_K
     CUTE_STATIC_ASSERT_V(size<1>(tCrA) == size<1>(accum));                                                     // MMA_M
     CUTE_STATIC_ASSERT_V(size<1>(tCsB) == size<2>(accum));                                                         // N
     CUTE_STATIC_ASSERT_V(size<2>(tCsA) == size<2>(tCsB));                                                          // K
     CUTE_STATIC_ASSERT_V(size<3>(tCsA) == size<3>(tCsB));                                                       // PIPE
     CUTE_STATIC_ASSERT_V(Int<DispatchPolicy::Stages>{} == size<2>(sA));                                         // PIPE
     CUTE_STATIC_ASSERT_V(Int<DispatchPolicy::Stages>{} == size<2>(sB));                                         // PIPE
+    CUTE_STATIC_ASSERT_V(size<2>(tCrA) > _2{}, "RS loops require more than 2 MMA k-iterations for correctness.");
 
     //
     // PIPELINED MAIN LOOP
     //
 
     // We release buffers to producer warps(dma load) with some mmas in flight
     PipelineState smem_pipe_release = smem_pipe_read;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized_mixed_input.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_rs_warpspecialized_mixed_input.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -28,31 +28,34 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_conversion.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/detail/dependent_false.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/numeric_types.h"
 #include "cutlass/detail/layout.hpp"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
+#include "cutlass/trace.h"
+#include "cutlass/detail/collective.hpp"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/atom/copy_traits_sm90_tma.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
 #include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/transform/collective/sm90_wgmma_transpose.hpp"
 #include "cutlass/trace.h"
-
 #include "cutlass/detail/collective.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
@@ -152,14 +155,15 @@
                 (cutlass::gemm::detail::is_k_major<StrideA>() && 
                  cutlass::gemm::detail::is_k_major<StrideB>()), 
                 "The unscaled element must be 2 bytes OR both inputs must be K-major");
 
   static_assert(cutlass::gemm::detail::is_mn_major<NonVoidStrideScale>(), 
     "Scale must be MN major [Col Major if A is scaled, Row Major if B is scaled].");
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
 
   using TiledMma = TiledMma_;
   using ElementAccumulator = typename TiledMma::ValTypeC;
 
   using GmemTiledCopyA = GmemTiledCopyA_;
   using GmemTiledCopyB = GmemTiledCopyB_;
   using GmemTiledCopyScale = cute::SM90_TMA_LOAD;
@@ -168,21 +172,14 @@
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   // Scale layout atom set after swapping.
 
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using SmemCopyAtomScale = Copy_Atom<cute::DefaultCopy, NonVoidElementScale>;
 
-  // Swap and transpose A/B for A k-major layout and B mn-major layout since WGMMA is k-major only (e.g. tf32, Fp32, Int8, Fp8 WGMMA)
-  static constexpr bool IsLayoutAkBmn =
-    cute::is_same_v<gemm::detail::StrideToLayoutTagA_t<StrideA>, layout::RowMajor> &&
-    cute::is_same_v<gemm::detail::StrideToLayoutTagB_t<StrideB>, layout::RowMajor>;
-
-  static constexpr bool IsInputSizeTwoBytes = sizeof(ElementA) == 2 && sizeof(ElementB) == 2;
-
   // We must ensure the type to be scaled goes to RF
   static constexpr bool SwapAB = !IsATransformed;
   using InternalSmemLayoutAtomA = cute::conditional_t<!SwapAB, SmemLayoutAtomA, SmemLayoutAtomB>;
   using InternalSmemLayoutAtomB = cute::conditional_t<!SwapAB, SmemLayoutAtomB, SmemLayoutAtomA>;
   using InternalSmemCopyAtomA   = cute::conditional_t<!SwapAB, SmemCopyAtomA, SmemCopyAtomB>;
   using InternalSmemCopyAtomB   = cute::conditional_t<!SwapAB, SmemCopyAtomB, SmemCopyAtomA>;
   // TMA converts f32 input to tf32 when copying from GMEM to SMEM
@@ -229,65 +226,40 @@
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomScale{})) == 0, "SmemLayoutAtomScale must equal the tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomScale{})) == 0, "SmemLayoutAtomScale must evenly divide tile k shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       InternalSmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       InternalSmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
     
   // It is assumed that the scales and zero-points share the same smem layout
   using SmemLayoutScale = decltype(tile_to_shape(
     SmemLayoutAtomScale{}, 
     make_shape(shape<0>(ScaleTileShape{}), shape<1>(ScaleTileShape{}), Int<Stages>{}),
-    conditional_t< ::cutlass::gemm::detail::is_major<0,NonVoidStrideScale>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
-
-  // If A mn-layout and B mn-layout, transposing B matrix since WGMMA is k-major only (e.g. tf32, fp32, fp8, int8).
-  static constexpr bool IsLayoutAmnBmn =
-    cute::is_same_v<gemm::detail::StrideToLayoutTagA_t<StrideA>, layout::ColumnMajor> &&
-    cute::is_same_v<gemm::detail::StrideToLayoutTagB_t<StrideB>, layout::RowMajor>;
-  static constexpr bool TransposeB = !IsInputSizeTwoBytes && IsLayoutAmnBmn;
-  using TransposeOperandB = decltype(cutlass::transform::collective::detail::make_transpose_operand_b(
-                                      0, 0, TiledMma{}, SmemLayoutB{}, InternalSmemLayoutAtomB{},
-                                      InternalElementB{}, cute::bool_constant<TransposeB>{})); 
+    cute::conditional_t< ::cutlass::gemm::detail::is_major<0,NonVoidStrideScale>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(DispatchPolicy::Stages >= 2, "Specialization requires Stages set to value 2 or more.");
   static_assert(not cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeA>::value &&
                     cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeB>::value,
                 "MMA atom must source A from rmem and B operand from smem_desc for this mainloop.");
   static_assert(cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
   static_assert(cute::is_same_v<GmemTiledCopyB, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyB, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
 
-  using GmmaSmemLayoutAtomB = decltype(transform::collective::detail::gmma_smem_transpose_or_passthrough<
-      TransposeB, InternalSmemLayoutAtomB, InternalElementB>());
-
-  // SmemLayoutB for GMMA is different from SmemLayoutB for TMA if TransposeB
-  using GmmaSmemLayoutB = decltype(tile_to_shape(
-      GmmaSmemLayoutAtomB{},
-      make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,InternalStrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
-
-  // These two restrictions are related, so we place the assertions together.
   // To relax them, we need to handle loading more than 1 row of scales for every main loop iteration.
   // We must also handle updating the pipeline transaction bytes on the fly.
   // NOTE: Deleting this assertion without required changes will cause the code to hang.
   static_assert(size<1>(SmemLayoutAtomScale{}) == 1, "size<1>(SmemLayoutAtomScale) must be 1.");
 
-  static_assert(!SwapAB || !TransposeB, "Cannot SwapAB and TransposeB at the same time.");
-  static_assert(TransposeB xor (cute::is_same_v<SmemLayoutB, GmmaSmemLayoutB>),
-    "Should be same layout if not TransposeB.");
-  static_assert(!TransposeB || size<1>(SmemLayoutB{}) * cute::sizeof_bits_v<InternalElementB> / 8 == 128,
-    "SmemLayoutB K must be 128bytes to be transposed.");
-
 private:
   static constexpr ConversionMode 
   get_conversion_mode() {
     if constexpr (cute::is_void_v<ElementScale>) {
       return ConversionMode::DirectConvert;
     } 
     else if constexpr (cute::is_void_v<ElementZero>) {
@@ -328,31 +300,31 @@
       static_assert(cutlass::detail::dependent_false<KernelSchedule>, "Type not handled in scale smem allocation.");
     }
   }
 
   // These methods use some the public members of the class. For that reason, we define them after the public section.
   static constexpr uint32_t
   compute_tma_transaction_bytes() {
-    constexpr uint32_t a_bytes = (size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(cute::sizeof_bits_v<InternalElementA>) / 8);
-    constexpr uint32_t b_bytes = (size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(cute::sizeof_bits_v<InternalElementB>) / 8);
+    constexpr uint32_t a_bytes = cutlass::bits_to_bytes(size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(cute::sizeof_bits_v<InternalElementA>));
+    constexpr uint32_t b_bytes = cutlass::bits_to_bytes(size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(cute::sizeof_bits_v<InternalElementB>));
 
     constexpr uint32_t baseline_bytes = a_bytes + b_bytes;
 
     if constexpr (KernelConversionMode == ConversionMode::DirectConvert) {
       return baseline_bytes;
     }
     else if constexpr (ModeHasScales) {
-      constexpr uint32_t scale_tx_bytes = (size<0>(SmemLayoutScale{}) * size<1>(SmemLayoutScale{}) * static_cast<uint32_t>(cute::sizeof_bits_v<ElementScale>) / 8);
+      constexpr uint32_t scale_tx_bytes = cutlass::bits_to_bytes(size<0>(SmemLayoutScale{}) * size<1>(SmemLayoutScale{}) * static_cast<uint32_t>(cute::sizeof_bits_v<ElementScale>));
       static_assert(scale_tx_bytes % 128 == 0, "Each scale stage must be 128B aligned."); // required by TMA
       if constexpr (KernelConversionMode == ConversionMode::ConvertAndScale) {
         return baseline_bytes + scale_tx_bytes;
       }
       else if constexpr (KernelConversionMode == ConversionMode::ConvertAndScaleWithZero) {
         // Scale and zero share smem layout
-        constexpr uint32_t zero_tx_bytes =  (size<0>(SmemLayoutScale{}) * size<1>(SmemLayoutScale{}) * static_cast<uint32_t>(cute::sizeof_bits_v<ElementZero>) / 8);
+        constexpr uint32_t zero_tx_bytes = cutlass::bits_to_bytes(size<0>(SmemLayoutScale{}) * size<1>(SmemLayoutScale{}) * static_cast<uint32_t>(cute::sizeof_bits_v<ElementZero>));
         static_assert(zero_tx_bytes % 128 == 0, "Each zero stage must be 128B aligned."); // required by TMA
         return baseline_bytes + scale_tx_bytes + zero_tx_bytes;
       }
       else {
         static_assert(cutlass::detail::dependent_false<KernelSchedule>, "Type not handled in tma transaction bytes computation.");
       }
     }
@@ -847,35 +819,29 @@
     // Obtain warp index
     int warp_idx = canonical_warp_idx_sync();
     [[maybe_unused]] int warp_group_thread_idx = thread_idx % 128;
     
     Tensor sA_ = make_tensor(make_smem_ptr(shared_tensors.smem_A.begin()), SmemLayoutA{});        // (BLK_M,BLK_K,PIPE)
     Tensor sA = as_position_independent_swizzle_tensor(sA_);                                      // (BLK_M,BLK_K,PIPE)
     
-    Tensor sB_ = make_tensor(make_smem_ptr(shared_tensors.smem_B.begin()), SmemLayoutB{});        // (BLK_N,BLK_K,PIPE)
-    Tensor sB  = as_position_independent_swizzle_tensor(sB_);                                     // (BLK_M,BLK_K,PIPE)
-
-    // If TransposeB, GMMA will read from transposed B layout SMEM
-    Tensor gmma_sB_position_dependent = make_tensor(make_smem_ptr(shared_tensors.smem_B.begin()), 
-                                          GmmaSmemLayoutB{});                                     // (BLK_N,BLK_K,PIPE)
-    Tensor gmma_sB = as_position_independent_swizzle_tensor(gmma_sB_position_dependent);          // (BLK_N,BLK_K,PIPE)
+    Tensor sB = make_tensor(make_smem_ptr(shared_tensors.smem_B.begin()), SmemLayoutB{});         // (BLK_N,BLK_K,PIPE)
 
     //
     // Define C accumulators and A/B partitioning
     //
 
     TiledMma tiled_mma;
     auto thread_mma = tiled_mma.get_thread_slice(thread_idx);
     Tensor tCsA = thread_mma.partition_A(sA);
 
     // Allocate fragments and descriptors
     Tensor tCrA_mma = thread_mma.partition_fragment_A(sA(_,_,Int<0>{}));                      // (MMA,MMA_M,MMA_K,PIPE)
     Tensor tCrA_load = make_fragment_like<RealInternalElementA>(tCrA_mma);
     
-    Tensor tCsB = thread_mma.partition_B(gmma_sB_position_dependent);                         // (MMA,MMA_N,MMA_K,PIPE)
+    Tensor tCsB = thread_mma.partition_B(sB);                                                 // (MMA,MMA_N,MMA_K,PIPE)
     Tensor tCrB = thread_mma.make_fragment_B(tCsB);                                           // (MMA,MMA_N,MMA_K,PIPE)
 
     //
     // Copy Atom A retiling
     //
     auto smem_tiled_copy_A = make_tiled_copy_A(InternalSmemCopyAtomA{}, tiled_mma);
     auto smem_thr_copy_A   = smem_tiled_copy_A.get_thread_slice(warp_group_thread_idx);
@@ -907,20 +873,17 @@
     //
 
     // We release buffers to producer warps(dma load) with some mmas in flight
     PipelineState smem_pipe_release = smem_pipe_read;
 
     tiled_mma.accumulate_ = GMMA::ScaleOut::Zero;
 
-    TransposeOperandB transpose = cutlass::transform::collective::detail::make_transpose_operand_b(
-                                    warp_idx, warp_group_thread_idx, tiled_mma, SmemLayoutB{}, 
-                                    InternalSmemLayoutAtomB{}, InternalElementB{}, 
-                                    cute::bool_constant<TransposeB>{});
-
     warpgroup_fence_operand(accum);
+
+    constexpr int K_BLOCK_MAX = size<2>(tCrA_load);
     
     ConsumerToken barrier_token = {BarrierStatus::WaitAgain};
     // first k tile
     {
       barrier_token = pipeline.consumer_try_wait(smem_pipe_read);
       pipeline.consumer_wait(smem_pipe_read, barrier_token);
 
@@ -930,49 +893,39 @@
       barrier_token = pipeline.consumer_try_wait(smem_pipe_read);
 
       // copy smem->rmem for A operand
       copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
         partitioned_extra_info, copy_partitions_extra_info, 0, read_stage);
 
       transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, 0);
-      // transpose B operand in SMEM
-      transpose(sB, gmma_sB, read_stage, 0);
       
       // Unroll the K mode manually to set scale D to 1
       CUTLASS_PRAGMA_UNROLL
-      for (int k_block = 0; k_block < size<2>(tCrA_load) - 1; ++k_block) {
-        copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
-          partitioned_extra_info, copy_partitions_extra_info, k_block + 1, read_stage);
-        transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, k_block + 1);
-        transpose.synchronize(k_block);
-        transpose(sB, gmma_sB, read_stage, k_block + 1);
+      for (int k_block = 0; k_block < K_BLOCK_MAX; ++k_block) {
+        if (k_block < K_BLOCK_MAX - 1) {
+          copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
+            partitioned_extra_info, copy_partitions_extra_info, k_block + 1, read_stage);
+          transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, k_block + 1);
+        }
         warpgroup_arrive();
         // (V,M) x (V,N) => (V,M,N)
         cute::gemm(tiled_mma, tCrA_mma(_,_,k_block), tCrB(_,_,k_block,read_stage), accum);
         tiled_mma.accumulate_ = GMMA::ScaleOut::One;
         warpgroup_commit_batch();
-      }
+      }     
 
-      warpgroup_wait<2>();
-      
       --k_tile_count;
       if (k_tile_count > 0) {
+        // Wait for K_BLOCK_MAX - 1 to be in flight to ensure that it is safe to overwrite the A registers for the first mma.
+        warpgroup_wait<K_BLOCK_MAX - 1>(); 
         pipeline.consumer_wait(smem_pipe_read, barrier_token);
         copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
           partitioned_extra_info, copy_partitions_extra_info, 0, smem_pipe_read.index());
         transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, 0);
-        transpose(sB, gmma_sB, smem_pipe_read.index(), 0);
       }
-      warpgroup_arrive();
-      // (V,M) x (V,N) => (V,M,N)
-      const int final_k = size<2>(tCrA_load) - 1;
-      cute::gemm(tiled_mma, tCrA_mma(_,_, final_k), tCrB(_,_,final_k,read_stage), accum);
-      tiled_mma.accumulate_ = GMMA::ScaleOut::One;
-      warpgroup_commit_batch();
-      warpgroup_wait<2>();
     }
 
     if (k_tile_count == 0) {
       return;
     }
 
     warpgroup_fence_operand(accum);
@@ -986,45 +939,43 @@
 
       int read_stage = smem_pipe_read.index();
       ++smem_pipe_read;
 
       warpgroup_fence_operand(accum);
       // Unroll the K mode manually to set scale D to 1
       CUTLASS_PRAGMA_UNROLL
-      for (int k_block = 0; k_block < size<2>(tCrA_load); ++k_block) {
+      for (int k_block = 0; k_block < K_BLOCK_MAX; ++k_block) {
+        
+        warpgroup_arrive();
+        // (V,M) x (V,N) => (V,M,N)
+        cute::gemm(tiled_mma, tCrA_mma(_,_,k_block), tCrB(_,_,k_block,read_stage), accum);
+        tiled_mma.accumulate_ = GMMA::ScaleOut::One;
+        warpgroup_commit_batch();
+
+        warpgroup_wait<K_BLOCK_MAX - 1>();
+        if (k_block == K_BLOCK_MAX - 1) {
+          // We have K_BLOCK_MAX - 1 GMMA instructions pending for this stage, so we can release prior barrier
+          pipeline.consumer_release(smem_pipe_release);             // UNLOCK smem_pipe_release, done _computing_ on it
+          ++smem_pipe_release;
+        }
+
         if (k_block == 0) {
           barrier_token = pipeline.consumer_try_wait(smem_pipe_read);
         }
-        if (k_block == size<2>(tCrA_load) - 1) {
+
+        if (k_block == K_BLOCK_MAX - 1) { 
           pipeline.consumer_wait(smem_pipe_read, barrier_token);
           copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
             partitioned_extra_info, copy_partitions_extra_info, 0, smem_pipe_read.index());
           transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, 0);
-          // transpose B operand in SMEM
-          transpose(sB, gmma_sB, smem_pipe_read.index(), 0);
         } 
         else {
           copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
             partitioned_extra_info, copy_partitions_extra_info, k_block + 1, read_stage);
           transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, k_block + 1);
-          // transpose B operand in SMEM
-          transpose.synchronize(k_block);                                      // make transpose of k_block available
-          transpose(sB, gmma_sB, read_stage, k_block + 1);
-        }
-        
-        warpgroup_arrive();
-        // (V,M) x (V,N) => (V,M,N)
-        cute::gemm(tiled_mma, tCrA_mma(_,_,k_block), tCrB(_,_,k_block,read_stage), accum);
-        tiled_mma.accumulate_ = GMMA::ScaleOut::One;
-        warpgroup_commit_batch();
-        warpgroup_wait<2>();
-        if (k_block == 1) {
-          // release prior barrier
-          pipeline.consumer_release(smem_pipe_release);             // UNLOCK smem_pipe_release, done _computing_ on it
-          ++smem_pipe_release;
         }
       }
       warpgroup_fence_operand(accum);
 
     }
 
     warpgroup_fence_operand(accum);
@@ -1036,40 +987,34 @@
 
       int read_stage = smem_pipe_read.index();
 
       warpgroup_fence_operand(accum);
       
       // Unroll the K mode manually to set scale D to 1
       CUTLASS_PRAGMA_UNROLL
-      for (int k_block = 0; k_block < size<2>(tCrA_load) - 1; ++k_block) {
-        
-        copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
-          partitioned_extra_info, copy_partitions_extra_info, k_block + 1, read_stage);
-        transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, k_block + 1);
-        transpose.synchronize(k_block);                                           // make k_block transpose available
-        transpose(sB, gmma_sB, read_stage, k_block + 1);
+      for (int k_block = 0; k_block < K_BLOCK_MAX; ++k_block) {
+
         warpgroup_arrive();
         // (V,M) x (V,N) => (V,M,N)
         cute::gemm(tiled_mma, tCrA_mma(_,_,k_block), tCrB(_,_,k_block,read_stage), accum);
         tiled_mma.accumulate_ = GMMA::ScaleOut::One;
         warpgroup_commit_batch();
-        warpgroup_wait<2>();
-        if (k_block == 1) {
+        warpgroup_wait<K_BLOCK_MAX - 1>();
+        if (k_block == K_BLOCK_MAX - 1) {
           // release prior barrier
           pipeline.consumer_release(smem_pipe_release);             // UNLOCK smem_pipe_release, done _computing_ on it
           ++smem_pipe_release;
         }
+
+        if (k_block < K_BLOCK_MAX - 1) {
+          copy_A_and_extra_info(smem_tiled_copy_A, tCsA, tCrA_copy_view, 
+            partitioned_extra_info, copy_partitions_extra_info, k_block + 1, read_stage);
+          transform_A_kblock(tCrA_load, A_CPY_VEC{}, tCrA_mma, partitioned_extra_info, k_block + 1);
+        }
       }
-      
-      warpgroup_arrive();
-      // (V,M) x (V,N) => (V,M,N)
-      const int final_k = size<2>(tCrA_load) - 1;
-      cute::gemm(tiled_mma, tCrA_mma(_,_,final_k), tCrB(_,_,final_k,read_stage), accum);
-      tiled_mma.accumulate_ = GMMA::ScaleOut::One;
-      warpgroup_commit_batch();
     }
 
     warpgroup_fence_operand(accum);
   }
   
   /// Perform a Consumer Epilogue to release all buffers
   CUTLASS_DEVICE void
@@ -1144,23 +1089,23 @@
     if constexpr (KernelConversionMode == ConversionMode::DirectConvert) {
       // noting to do
       return cute::tuple{};
     }
     else if constexpr (ModeHasScales) {
       Tensor sS = make_tensor(make_smem_ptr(shared_tensors.smem_scale.begin()), SmemLayoutScale{});    // (BLK_M,BLK_SCALE_K,PIPE)
       Tensor tCsS = thread_mma.partition_A(sS);
-      Tensor tCrS = make_fragment_like<ElementScale>(thread_mma.partition_fragment_A(sS(_,_,Int<0>{}))); 
+      Tensor tCrS = make_tensor<ElementScale>(thread_mma.partition_fragment_A(sS(_,_,Int<0>{})).shape()); 
 
       if constexpr (KernelConversionMode == ConversionMode::ConvertAndScale) {
         return cute::make_tuple(tCsS, tCrS);
       }
       else if constexpr (KernelConversionMode == ConversionMode::ConvertAndScaleWithZero) {
         Tensor sZ = make_tensor(make_smem_ptr(shared_tensors.smem_zero.begin()), SmemLayoutScale{});    // (BLK_M,BLK_SCALE_K,PIPE)
         Tensor tCsZ = thread_mma.partition_A(sZ);
-        Tensor tCrZ = make_fragment_like<ElementZero>(thread_mma.partition_fragment_A(sZ(_,_,Int<0>{}))); 
+        Tensor tCrZ = make_tensor<ElementZero>(thread_mma.partition_fragment_A(sZ(_,_,Int<0>{})).shape()); 
         return cute::make_tuple(tCsS, tCrS, tCsZ, tCrZ);
       }
       else {
         static_assert(cutlass::detail::dependent_false<KernelSchedule>, "Conversion mode not handled in A -> RF path.");
       }
     } 
     else {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -27,25 +27,26 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/numeric_types.h"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/trace.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -102,14 +103,15 @@
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   using MainloopPipeline = cutlass::PipelineTmaAsync<DispatchPolicy::Stages>;
 
   using PipelineParams = typename MainloopPipeline::Params;
   using PipelineState  = typename cutlass::PipelineState<DispatchPolicy::Stages>;
 
   static constexpr int ThreadCount = CUTE_STATIC_V(size(TiledMma{}));
 
@@ -121,19 +123,19 @@
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       SmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       SmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(DispatchPolicy::Stages >= 2, "Specialization requires Stages set to value 1 or more.");
   static_assert(cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeA>::value &&
                 cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeB>::value,
                 "MMA atom must source both A and B operand from smem_desc for this mainloop.");
   static_assert(cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
@@ -316,17 +318,16 @@
     static_assert(0 <= K_PIPE_MMAS && K_PIPE_MMAS <  K_PIPE_MAX);
     static_assert(0 <  K_PIPE_TMAS && K_PIPE_TMAS <= K_PIPE_MAX);
 
     static_assert(K_PIPE_MMAS < K_PIPE_MAX - 1);
 
     // Set the bytes transferred in this TMA transaction (may involve multiple issues)
     constexpr uint32_t TmaTransactionBytes = static_cast<uint32_t>(
-        (size<0>(sA) * size<1>(sA) * sizeof_bits<InternalElementA>::value) / 8 +
-        (size<0>(sB) * size<1>(sB) * sizeof_bits<InternalElementB>::value) / 8);
-
+        cutlass::bits_to_bytes(size<0>(sA) * size<1>(sA) * sizeof_bits<InternalElementA>::value) +
+        cutlass::bits_to_bytes(size<0>(sB) * size<1>(sB) * sizeof_bits<InternalElementB>::value));
 
     // Obtain warp index
     int warp_idx = canonical_warp_idx_sync();
     int warp_group_thread_idx = thread_idx % NumThreadsPerWarpGroup;
 
     PipelineParams params;
     params.transaction_bytes = TmaTransactionBytes;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -27,25 +27,26 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/numeric_types.h"
+#include "cutlass/pipeline/pipeline.hpp"
+#include "cutlass/trace.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/pipeline/pipeline.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -103,14 +104,15 @@
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   using MainloopPipeline = cutlass::PipelineTmaAsync<DispatchPolicy::Stages>;
   using PipelineState = cutlass::PipelineState<DispatchPolicy::Stages>;
 
   using PipelineParams = typename MainloopPipeline::Params;
 
   static_assert(cute::rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
@@ -120,19 +122,19 @@
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       SmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       SmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(DispatchPolicy::Stages >= 2, "Specialization requires Stages set to value 2 or more.");
   static_assert(cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeA>::value &&
                 cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeB>::value,
                 "MMA atom must source both A and B operand from smem_desc for this mainloop.");
   static_assert(cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
@@ -244,16 +246,16 @@
     }
     return implementable;
   }
 
   static constexpr int K_PIPE_MAX = DispatchPolicy::Stages;
   static constexpr int K_PIPE_MMAS = 1;
   static constexpr uint32_t TmaTransactionBytes =
-        (size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value)) / 8+
-        (size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value)) / 8;
+        cutlass::bits_to_bytes(size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value))+
+        cutlass::bits_to_bytes(size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value));
 
   /// Issue Tma Descriptor Prefetch -- ideally from a single thread for best performance
   CUTLASS_DEVICE
   static void prefetch_tma_descriptors(Params const& mainloop_params) {
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_a.get_tma_descriptor());
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_b.get_tma_descriptor());
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized_fp8.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized_fp8.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -28,25 +28,26 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cute/arch/cluster_sm90.hpp"
-#include "cute/arch/copy_sm90.hpp"
 #include "cutlass/gemm/dispatch_policy.hpp"
+#include "cutlass/gemm/collective/fp8_accumulation.hpp"
+#include "cutlass/trace.h"
+#include "cutlass/numeric_types.h"
 
+#include "cute/arch/cluster_sm90.hpp"
+#include "cute/arch/copy_sm90.hpp"
 #include "cute/algorithm/functional.hpp"
 #include "cute/atom/mma_atom.hpp"
 #include "cute/algorithm/gemm.hpp"
 #include "cute/tensor_predicate.hpp"
 #include "cute/numeric/arithmetic_tuple.hpp"
-#include "cutlass/gemm/collective/fp8_accumulation.hpp"
-#include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::gemm::collective {
 using namespace cute;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -104,14 +105,15 @@
   using SmemLayoutAtomB = SmemLayoutAtomB_;
   using SmemCopyAtomA = SmemCopyAtomA_;
   using SmemCopyAtomB = SmemCopyAtomB_;
   using TransformA = TransformA_;
   using TransformB = TransformB_;
   using ArchTag = typename DispatchPolicy::ArchTag;
 
+  using CtaShape_MNK = decltype(shape_div(TileShape{}, ClusterShape{}));
   using MainloopPipeline = cutlass::PipelineTmaAsync<DispatchPolicy::Stages>;
   using PipelineState = cutlass::PipelineState<DispatchPolicy::Stages>;
 
   using PipelineParams = typename MainloopPipeline::Params;
 
   static_assert(cute::rank(SmemLayoutAtomA{}) == 2, "SmemLayoutAtom must be rank 2 (M/N, K)");
   static_assert((size<0>(TileShape{}) % size<0>(SmemLayoutAtomA{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
@@ -121,19 +123,19 @@
   static_assert((size<1>(TileShape{}) % size<0>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
   static_assert((size<2>(TileShape{}) % size<1>(SmemLayoutAtomB{})) == 0, "SmemLayoutAtom must evenly divide tile shape.");
 
   // Tile along modes in a way that maximizes the TMA box size.
   using SmemLayoutA = decltype(tile_to_shape(
       SmemLayoutAtomA{},
       make_shape(shape<0>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideA>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
   using SmemLayoutB = decltype(tile_to_shape(
       SmemLayoutAtomB{},
       make_shape(shape<1>(TileShape{}), shape<2>(TileShape{}), Int<DispatchPolicy::Stages>{}),
-      conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
+      cute::conditional_t< ::cutlass::gemm::detail::is_major<0,StrideB>(), Step<_2,_1,_3>, Step<_1,_2,_3>>{}));
 
   static_assert(DispatchPolicy::Stages >= 2, "Specialization requires Stages set to value 1 or more.");
   static_assert(cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeA>::value &&
                 cute::is_base_of<cute::GMMA::DescriptorIterator, typename TiledMma::FrgTypeB>::value,
                 "MMA atom must source both A and B operand from smem_desc for this mainloop.");
   static_assert(cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD> || cute::is_same_v<GmemTiledCopyA, SM90_TMA_LOAD_MULTICAST>,
       "GmemTiledCopy - invalid SM90 TMA copy atom specified.");
@@ -242,16 +244,16 @@
     }
     return implementable;
   }
 
   static constexpr int K_PIPE_MAX = DispatchPolicy::Stages;
   static constexpr int K_PIPE_MMAS = 1;
   static constexpr uint32_t TmaTransactionBytes =
-        (size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value)) / 8+
-        (size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value)) / 8;
+        cutlass::bits_to_bytes(size<0>(SmemLayoutA{}) * size<1>(SmemLayoutA{}) * static_cast<uint32_t>(sizeof_bits<ElementA>::value))+
+        cutlass::bits_to_bytes(size<0>(SmemLayoutB{}) * size<1>(SmemLayoutB{}) * static_cast<uint32_t>(sizeof_bits<ElementB>::value));
 
   /// Issue Tma Descriptor Prefetch -- ideally from a single thread for best performance
   CUTLASS_DEVICE
   static void prefetch_tma_descriptors(Params const& mainloop_params)
   {
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_a.get_tma_descriptor());
     cute::prefetch_tma_descriptor(mainloop_params.tma_load_b.get_tma_descriptor());
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h`

 * *Files 6% similar despite different names*

```diff
@@ -759,14 +759,102 @@
   using EpilogueOutputOp = epilogue::thread::LinearCombinationClamp<
       ElementC, 128 / sizeof_bits<ElementC>::value, int32_t, float>;
 
   using Operator = arch::OpMultiplyAdd;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
+
+/// Base configuration for all {fe4m3, fe5m2} x {fe4m3, fe5m2} combinations on SM89
+template <
+  typename ElementA,
+  typename ElementB,
+  typename ElementC,
+  typename ElementAccumulator>
+struct DefaultGemmConfigurationSm89F8 {
+  static_assert((platform::is_same<ElementA, cutlass::float_e4m3_t>::value ||
+                 platform::is_same<ElementA, cutlass::float_e5m2_t>::value),
+                "ElementA must be of type float_e4m3_t or float_e5m2_t");
+  static_assert((platform::is_same<ElementB, cutlass::float_e4m3_t>::value ||
+                 platform::is_same<ElementB, cutlass::float_e5m2_t>::value),
+                "ElementB must be of type float_e4m3_t or float_e5m2_t");
+
+  static int const kAlignmentA = 128 / sizeof_bits<ElementA>::value;
+  static int const kAlignmentB = 128 / sizeof_bits<ElementB>::value;
+
+  using ThreadblockShape = GemmShape<128, 256, 64>;
+  using WarpShape = GemmShape<64, 64, 64>;
+  using InstructionShape = GemmShape<16, 8, 32>;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = epilogue::thread::LinearCombination<
+      ElementC, 128 / sizeof_bits<ElementC>::value, ElementAccumulator,
+      ElementAccumulator>;
+
+  using Operator = arch::OpMultiplyAdd;
+};
+
+/// Partial specialization for SM89 fe4m3 x fe4m3
+template <typename ElementC, typename ElementAccumulator>
+struct DefaultGemmConfiguration<
+  arch::OpClassTensorOp,
+  arch::Sm89,
+  cutlass::float_e4m3_t,
+  cutlass::float_e4m3_t,
+  ElementC,
+  ElementAccumulator> : DefaultGemmConfigurationSm89F8<
+                            cutlass::float_e4m3_t,
+                            cutlass::float_e4m3_t,
+                            ElementC,
+                            ElementAccumulator> {};
+
+/// Partial specialization for SM89 fe4m3 x fe5m2
+template <typename ElementC, typename ElementAccumulator>
+struct DefaultGemmConfiguration<
+  arch::OpClassTensorOp,
+  arch::Sm89,
+  cutlass::float_e4m3_t,
+  cutlass::float_e5m2_t,
+  ElementC,
+  ElementAccumulator> : DefaultGemmConfigurationSm89F8<
+                            cutlass::float_e4m3_t,
+                            cutlass::float_e5m2_t,
+                            ElementC,
+                            ElementAccumulator> {};
+
+/// Partial specialization for SM89 fe5m2 x fe4m3
+template <typename ElementC, typename ElementAccumulator>
+struct DefaultGemmConfiguration<
+  arch::OpClassTensorOp,
+  arch::Sm89,
+  cutlass::float_e5m2_t,
+  cutlass::float_e4m3_t,
+  ElementC,
+  ElementAccumulator> : DefaultGemmConfigurationSm89F8<
+                            cutlass::float_e5m2_t,
+                            cutlass::float_e4m3_t,
+                            ElementC,
+                            ElementAccumulator> {};
+
+/// Partial specialization for SM89 fe5m2 x fe5m2
+template <typename ElementC, typename ElementAccumulator>
+struct DefaultGemmConfiguration<
+  arch::OpClassTensorOp,
+  arch::Sm89,
+  cutlass::float_e5m2_t,
+  cutlass::float_e5m2_t,
+  ElementC,
+  ElementAccumulator> : DefaultGemmConfigurationSm89F8<
+                            cutlass::float_e5m2_t,
+                            cutlass::float_e5m2_t,
+                            ElementC,
+                            ElementAccumulator> {};
+
+////////////////////////////////////////////////////////////////////////////////
+
 template <typename ElementC,
           typename ElementAccumulator>
 struct DefaultGemmConfiguration<arch::OpClassTensorOp, arch::Sm90, double,
                                 double, ElementC, ElementAccumulator> {
 
   static int const kAlignmentA = 1;
   static int const kAlignmentB = 1;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -362,15 +362,15 @@
 
     }
   };
 
 private:
 
   /// Kernel parameters object
-  typename GemmKernel::Params params_;
+  typename GemmKernel::Params params_{};
 
 public:
 
   /// Constructs the GEMM.
   EllGemm() { }
 
   /// Determines whether the GEMM can execute the given problem.
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma.h`

 * *Files 6% similar despite different names*

```diff
@@ -24,38 +24,37 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*!
-  \file
-  \brief Device-level grouped GEMM.
+/*! \file
+    \brief Templates exposing architecture support for warp-level multiply-add operations
 */
 
 #pragma once
 
-#include "cutlass/gemm/device/base_grouped.h"
+#include "cutlass/cutlass.h"
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
-namespace device {
+namespace warp {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// GEMM Grouped
-template <typename GemmKernel_>
-class GemmGrouped : public BaseGrouped<GemmKernel_> {
-public:
-  using GemmKernel = GemmKernel_;
+/// Query the number of threads per warp
+template <typename OperatorClass>
+struct WarpSize {
+  static int const value = 32;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace device
+} // namespace warp
 } // namespace gemm
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -30,14 +30,15 @@
  **************************************************************************************************/
 /*! \file
     \brief
 */
 
 #pragma once
 
+#include "cutlass/arch/mma.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/arch/arch.h"
 #include "cutlass/device_kernel.h"
 
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h`

 * *Files 2% similar despite different names*

```diff
@@ -92,30 +92,30 @@
 public:
   using GemmKernel = GemmKernel_;
   using TileShape = typename GemmKernel::TileShape;
   using ElementA = typename GemmKernel::ElementA;
   using ElementB = typename GemmKernel::ElementB;
   using ElementC = typename GemmKernel::ElementC;
   using ElementD = typename GemmKernel::ElementD;
-  using ElementAccumulator = typename GemmKernel::TiledMma::ValTypeC;
+  using ElementAccumulator = typename GemmKernel::ElementAccumulator;
   using DispatchPolicy = typename GemmKernel::DispatchPolicy;
   using CollectiveMainloop = typename GemmKernel::CollectiveMainloop;
   using CollectiveEpilogue = typename GemmKernel::CollectiveEpilogue;
 
   // Map back to 2.x type as best as possible
   using LayoutA = gemm::detail::StrideToLayoutTagA_t<typename GemmKernel::StrideA>;
   using LayoutB = gemm::detail::StrideToLayoutTagB_t<typename GemmKernel::StrideB>;
   using LayoutC = gemm::detail::StrideToLayoutTagC_t<typename GemmKernel::StrideC>;
   using LayoutD = gemm::detail::StrideToLayoutTagC_t<typename GemmKernel::StrideD>;
 
   static bool const kEnableCudaHostAdapter = CUTLASS_ENABLE_CUDA_HOST_ADAPTER;
 
   static ComplexTransform const kTransformA = cute::is_same_v<typename GemmKernel::CollectiveMainloop::TransformA, cute::conjugate> ?
                                               ComplexTransform::kConjugate : ComplexTransform::kNone;
-  static ComplexTransform const kTransformB = cute::is_same_v<typename GemmKernel::CollectiveMainloop::TransformB, cute::conjugate> ? 
+  static ComplexTransform const kTransformB = cute::is_same_v<typename GemmKernel::CollectiveMainloop::TransformB, cute::conjugate> ?
                                               ComplexTransform::kConjugate : ComplexTransform::kNone;
 
   // Legacy: Assume MultiplyAdd only since we do not use this tag type in 3.0
   using MathOperator = cutlass::arch::OpMultiplyAdd;
 
   using OperatorClass = cutlass::detail::get_operator_class_t<typename CollectiveMainloop::TiledMma>;
 
@@ -157,17 +157,17 @@
       CUTE_STATIC_V(cute::tile_size<1>(typename CollectiveMainloop::TiledMma{})) / WarpsInMmaN,
       CUTE_STATIC_V(cute::tile_size<2>(typename CollectiveMainloop::TiledMma{}))>;
 
   static int constexpr kStages = CollectiveMainloop::DispatchPolicy::Stages;
 
   // Inspect TiledCopy for A and B to compute the alignment size
   static int constexpr kAlignmentA = cutlass::detail::get_alignment_count_from_gmem_tiled_copy<
-      typename CollectiveMainloop::GmemTiledCopyA, ElementA>();
+      typename CollectiveMainloop::GmemTiledCopyA, ElementA, typename CollectiveMainloop::TiledMma::ValTypeA>();
   static int constexpr kAlignmentB = cutlass::detail::get_alignment_count_from_gmem_tiled_copy<
-      typename CollectiveMainloop::GmemTiledCopyB, ElementB>();
+      typename CollectiveMainloop::GmemTiledCopyB, ElementB, typename CollectiveMainloop::TiledMma::ValTypeB>();
   static int constexpr kAlignmentC = cutlass::detail::get_alignment_count_from_gmem_tiled_copy<
       typename CollectiveEpilogue::GmemTiledCopyC, ElementC>();
   static int constexpr kAlignmentD = cutlass::detail::get_alignment_count_from_gmem_tiled_copy<
       typename CollectiveEpilogue::GmemTiledCopyD, ElementD>();
 
   using EpilogueOutputOp = typename CollectiveEpilogue::ThreadEpilogueOp;
 
@@ -274,28 +274,26 @@
 
   /// Initializes GEMM state from arguments.
   Status
   initialize(
     Arguments const& args,
     void* workspace = nullptr,
     cudaStream_t stream = nullptr,
-    CudaHostAdapter *cuda_adapter = nullptr) {
+    CudaHostAdapter* cuda_adapter = nullptr) {
 
     CUTLASS_TRACE_HOST("GemmUniversal::initialize() - workspace "
       << workspace << ", stream: " << (stream ? "non-null" : "null"));
 
     // Initialize the workspace
-    Status status = GemmKernel::initialize_workspace(args, workspace, stream);
+    Status status = GemmKernel::initialize_workspace(args, workspace, stream, cuda_adapter);
     if (status != Status::kSuccess) {
       return status;
     }
-
     // Initialize the Params structure
     params_ = GemmKernel::to_underlying_arguments(args, workspace);
-
     // Don't set the function attributes - require the CudaHostAdapter to set it.
     if constexpr (kEnableCudaHostAdapter) {
       CUTLASS_ASSERT(cuda_adapter);
       return Status::kSuccess;
     }
     else {
       //
@@ -314,15 +312,14 @@
         if (cudaSuccess != result) {
           result = cudaGetLastError(); // to clear the error bit
           CUTLASS_TRACE_HOST("  cudaFuncSetAttribute() returned error: " << cudaGetErrorString(result));
           return Status::kErrorInternal;
         }
       }
     }
-
     return Status::kSuccess;
   }
 
   /// Update API is preserved in 3.0, but does not guarantee a lightweight update of params.
   Status
   update(Arguments const& args, void* workspace = nullptr) {
     CUTLASS_TRACE_HOST("GemmUniversal()::update() - workspace: " << workspace);
@@ -338,54 +335,55 @@
 
   /// Primary run() entry point API that is static allowing users to create and manage their own params.
   /// Supplied params struct must be construct by calling GemmKernel::to_underling_arguments()
   static Status
   run(Params& params,
       cudaStream_t stream = nullptr,
       CudaHostAdapter *cuda_adapter = nullptr) {
-
     CUTLASS_TRACE_HOST("GemmUniversal::run()");
     dim3 const block = GemmKernel::get_block_shape();
     dim3 const grid = get_grid_shape(params);
 
     // configure smem size and carveout
     int smem_size = GemmKernel::SharedStorageSize;
 
-    Status launch_result;
+    Status launch_result{ Status::kSuccess };
     // Use extended launch API only for mainloops that use it
-    if constexpr(GemmKernel::ArchTag::kMinComputeCapability >= 90) {
+    if constexpr (GemmKernel::ArchTag::kMinComputeCapability >= 90) {
       dim3 cluster(cute::size<0>(typename GemmKernel::DispatchPolicy::ClusterShape{}),
                    cute::size<1>(typename GemmKernel::DispatchPolicy::ClusterShape{}),
                    cute::size<2>(typename GemmKernel::DispatchPolicy::ClusterShape{}));
-
       void* kernel_params[] = {&params};
 
       if constexpr (kEnableCudaHostAdapter) {
         //
         // Use the cuda host adapter
         //
         CUTLASS_ASSERT(cuda_adapter);
         if (cuda_adapter) {
 
-          launch_result = cuda_adapter->launch(
-            grid, cluster, block, smem_size, stream, kernel_params, 0
-          );
+          launch_result = cuda_adapter->launch(grid,
+                                               cluster,
+                                               block,
+                                               smem_size,
+                                               stream,
+                                               kernel_params,
+                                               0);
         }
         else {
           return Status::kErrorInternal;
         }
       }
       else {
-
         CUTLASS_ASSERT(cuda_adapter == nullptr);
         void const* kernel = (void const*) device_kernel<GemmKernel>;
-
-        launch_result = ClusterLauncher::launch(
-          grid, cluster, block, smem_size, stream, kernel, kernel_params);
-
+        if constexpr (GemmKernel::ArchTag::kMinComputeCapability == 90) {
+          launch_result = ClusterLauncher::launch(
+            grid, cluster, block, smem_size, stream, kernel, kernel_params);
+        }
       }
     }
     else {
       launch_result = Status::kSuccess;
       if constexpr (kEnableCudaHostAdapter) {
         CUTLASS_ASSERT(cuda_adapter);
         if (cuda_adapter) {
@@ -424,15 +422,14 @@
   Status
   run(
     Arguments const& args,
     void* workspace = nullptr,
     cudaStream_t stream = nullptr,
     CudaHostAdapter *cuda_adapter = nullptr
   ) {
-
     Status status = initialize(args, workspace, stream, cuda_adapter);
 
     if (Status::kSuccess == status) {
       status = run(params_, stream, cuda_adapter);
     }
     return status;
   }
@@ -552,23 +549,23 @@
     }
     else {
       return args;
     }
   }
 
   /// Determines whether the GEMM can execute the given problem.
-  static Status can_implement(Arguments const &args) {
+  static Status can_implement(Arguments const &args, CudaHostAdapter *cuda_adapter = nullptr) {
 
-    return UnderlyingOperator::can_implement(to_underlying_arguments(args));
+    return UnderlyingOperator::can_implement(to_underlying_arguments(args), cuda_adapter);
   }
 
   /// Gets the workspace size
-  static size_t get_workspace_size(Arguments const &args) {
+  static size_t get_workspace_size(Arguments const &args, CudaHostAdapter *cuda_adapter = nullptr) {
 
-    return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args));
+    return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args), cuda_adapter);
   }
 
   /// Computes the grid shape
   static dim3 get_grid_shape(Arguments const &args) {
     return UnderlyingOperator::get_grid_shape(to_underlying_arguments(args));
   }
 
@@ -600,15 +597,15 @@
     CudaHostAdapter *cuda_adapter = nullptr) {
 
     return underlying_operator_.run(stream, cuda_adapter);
   }
 
   /// Runs the kernel using initialized state.
   Status operator()(
-    cudaStream_t stream = nullptr, 
+    cudaStream_t stream = nullptr,
     CudaHostAdapter *cuda_adapter = nullptr) {
 
     return run(stream);
   }
 
   /// Runs the kernel using initialized state.
   Status operator()(
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_streamk_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_streamk_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/gemv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/rank_k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/symm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/device/trmm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/device/trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp`

 * *Files 6% similar despite different names*

```diff
@@ -33,19 +33,45 @@
 #include "cutlass/arch/arch.h"
 #include "cutlass/gemm/gemm.h"
 
 #include "cute/layout.hpp"
 #include "cute/numeric/integral_constant.hpp"
 //////////////////////////////////////////////////////////////////////////////
 
+namespace cutlass::detail {
+
+template <class T, template <int...> class U>
+struct is_kernel_tag_of : cute::false_type {};
+
+template <template <int...> class U, int... Args>
+struct is_kernel_tag_of<U<Args...>, U> : cute::true_type {};
+
+template <class T, template <int...> class U>
+constexpr bool is_kernel_tag_of_v = is_kernel_tag_of<T, U>::value;
+
+}
+
+//////////////////////////////////////////////////////////////////////////////
+
 namespace cutlass::gemm {
 using namespace cute;
 
 //////////////////////////////////////////////////////////////////////////////
 
+namespace detail {
+
+enum class KernelInputTransformType {
+    FastF32,
+    InterleavedComplexTF32
+};
+
+} // namespace detail
+
+//////////////////////////////////////////////////////////////////////////////
+
 //
 // Kernel schedule policies (the base class tags, one for each kernel layer file)
 //
 struct KernelMultistage { };
 struct KernelCpAsyncWarpSpecialized { };
 struct KernelCpAsyncWarpSpecializedPingpong { };
 struct KernelCpAsyncWarpSpecializedCooperative { };
@@ -54,15 +80,15 @@
 struct KernelTmaWarpSpecializedPingpong { };
 struct KernelTmaWarpSpecializedCooperative { };
 struct KernelPtrArrayTmaWarpSpecializedCooperative { };
 
 //////////////////////////////////////////////////////////////////////////////
 
 //
-// Builder dispatch policies (not a part of the main CUTLASS layers, simply used to opt into 
+// Builder dispatch policies (not a part of the main CUTLASS layers, simply used to opt into
 // specific collective builder dispatches)
 //
 
 // FP8 related policies (including Fast Accumulation)
 struct KernelTmaWarpSpecializedFP8FastAccum : KernelTmaWarpSpecialized { };
 struct KernelTmaWarpSpecializedPingpongFP8FastAccum : KernelTmaWarpSpecializedPingpong { };
 struct KernelTmaWarpSpecializedCooperativeFP8FastAccum: KernelTmaWarpSpecializedCooperative { };
@@ -215,15 +241,15 @@
 // For FP8 kernels
 template<
   int Stages_,
   class ClusterShape_ = Shape<_1,_1,_1>,
   class KernelSchedule = KernelTmaWarpSpecialized
 >
 struct MainloopSm90TmaGmmaWarpSpecializedFP8
-  : MainloopSm90TmaGmmaWarpSpecialized<Stages_, ClusterShape_, KernelSchedule> { 
+  : MainloopSm90TmaGmmaWarpSpecialized<Stages_, ClusterShape_, KernelSchedule> {
   static_assert(
     cute::is_same_v<KernelSchedule, KernelTmaWarpSpecialized> ||
     cute::is_same_v<KernelSchedule, KernelTmaWarpSpecializedPingpong> ||
     cute::is_same_v<KernelSchedule, KernelTmaWarpSpecializedCooperative>,
     "KernelSchedule must be one of the warp specialized policies");
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/gemm_enumerated_types.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_swizzling4_sm80.cu`

 * *Files 22% similar despite different names*

```diff
@@ -25,66 +25,75 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Defines common types used for all GEMM-like operators.
+    \brief Tests for device-wide Implicit GEMM interface with swizzling functor > 1
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
-#pragma once
-
+#include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
-#include "cutlass/coord.h"
-#include "cutlass/gemm_coord.h"
-#include "cutlass/layout/matrix.h"
-
-namespace cutlass {
-namespace gemm {
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// GEMM operand enumeration: D = A * B + C
-enum class Operand {
-  kA, /// A multiplicand
-  kB, /// B multiplicand
-  kC, /// Source accumulator
-  kD  /// Destination accumulator
-};
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-enum class GemmUniversalMode {
-  kGemm,
-  kGemmSplitKParallel,
-  kBatched,
-  kArray,
-  kGrouped,
-  kInvalid
-};
-
-////////////////////////////////////////////////////////////////////////////////
-
-/// Some options for clearing shared memory
-enum class SharedMemoryClearOption {
-  kNone,            ///< SMEM is in don't-care state
-  kZfill,           ///< Kernels fill out of bounds accesses with zeros
-  kClearLastStage   ///< Last SMEM stage is explicitly cleared. Mainloop uses 'kNone'
-};
 
-/////////////////////////////////////////////////////////////////////////
+#include "cutlass/conv/kernel/default_conv2d_dgrad.h"
+#include "cutlass/conv/device/implicit_gemm_convolution.h"
+
+#include "conv2d_testbed.h"
 
-} // namespace gemm
-} // namespace cutlass
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+TEST(SM80_Device_Conv2d_Strided_Dgrad_Optimized_ImplicitGemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_swizzle4,
+  128x64_32x3_64x32x32) {
+
+  /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
+  using ElementA           = cutlass::half_t;
+  using ElementB           = cutlass::half_t;
+  using ElementC           = cutlass::half_t;
+  using ElementAccumulator = float;
+  using ElementCompute     = float;
+
+  /// Device-level Conv2d instance
+  using Conv2dDgradKernel = typename cutlass::conv::kernel::DefaultConv2dDgrad<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementC, cutlass::layout::TensorNHWC,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<64, 32, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      2,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::conv::threadblock::StridedDgradIdentityThreadblockSwizzle<4>,
+    3,
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::conv::IteratorAlgorithm::kOptimized,
+    cutlass::conv::StrideSupport::kStrided,
+    8,
+    2
+  >::Kernel;
+
+  using Conv2dDgrad = cutlass::conv::device::ImplicitGemmConvolution<Conv2dDgradKernel>;
+
+
+  test::conv::device::Conv2dProblemVector problem_size_list;
+
+
+  // run specific problem size in the unit test first
+  problem_size_list.push_back(cutlass::conv::Conv2dProblemSize(
+    {1, 23, 56, 98},      // input size (NHWC)
+    {128, 3, 3, 98},      // filter size (KRSC)
+    {4, 0, 5, 0},         // padding (pad_h, _, pad_w, _)
+    {3, 3},               // stride (stride_h, stride_w)
+    {1, 1}                // dilation (dilation_h, dilation_w)
+  ));
+
+  /// Run all unit test sizes with device-level Conv2d instance
+  EXPECT_TRUE(test::conv::device::TestAllConv2d<Conv2dDgrad>(problem_size_list));
+}
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
+#endif  // CUTLASS_ARCH_MMA_SM80_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/group_array_problem_shape.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/group_array_problem_shape.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -214,14 +214,92 @@
 
   /// Define the kernel-level GEMM operator.
   using GemmKernel = kernel::Gemm<Mma, Epilogue, ThreadblockSwizzle, SplitKSerial>;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
+/// Partial specialization for Ada Architecture
+template <
+    /// Element type for A matrix operand
+    typename ElementA,
+    /// Layout type for A matrix operand
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB,
+    /// Layout type for B matrix operand
+    typename LayoutB,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentB,
+    /// Element type for C and D matrix operands
+    typename ElementC,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// If true, kernel is configured to support serial reduction in the
+    /// epilogue
+    bool SplitKSerial,
+    /// Operation performed by GEMM
+    typename Operator,
+    /// Use zfill or predicate for out-of-bound cp.async
+    SharedMemoryClearOption SharedMemoryClear,
+    /// Gather operand A by using an index array
+    bool GatherA,
+    /// Gather operand B by using an index array
+    bool GatherB,
+    /// Scatter result D by using an index array
+    bool ScatterD,
+    /// Permute result D
+    typename PermuteDLayout,
+    /// Permute operand A
+    typename PermuteALayout,
+    /// Permute operand B
+    typename PermuteBLayout
+>
+struct DefaultGemm<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB, ElementC,
+                   layout::RowMajor, ElementAccumulator, arch::OpClassTensorOp,
+                   arch::Sm89, ThreadblockShape, WarpShape, InstructionShape,
+                   EpilogueOutputOp, ThreadblockSwizzle, Stages, SplitKSerial,
+                   Operator, SharedMemoryClear, GatherA, GatherB, ScatterD, 
+                   PermuteDLayout, PermuteALayout, PermuteBLayout> {
+  /// Define the threadblock-scoped matrix multiply-accumulate
+  using Mma = typename cutlass::gemm::threadblock::DefaultMma<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm89,
+      ThreadblockShape, WarpShape, InstructionShape, Stages,
+      Operator, false, SharedMemoryClear, GatherA, GatherB,
+      PermuteALayout, PermuteBLayout>::ThreadblockMma;
+
+  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+
+  /// Define the epilogue
+  using Epilogue =
+      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
+          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
+          EpilogueOutputOp::kCount, ScatterD, PermuteDLayout>::Epilogue;
+
+  /// Define the kernel-level GEMM operator.
+  using GemmKernel = kernel::Gemm<Mma, Epilogue, ThreadblockSwizzle, SplitKSerial>;
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
 /// Partial specialization for Ampere Architecture
 template <
     /// Element type for A matrix operand
     typename ElementA,
     /// Layout type for A matrix operand
     typename LayoutA,
     /// Access granularity of A matrix in units of elements
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h`

 * *Files 8% similar despite different names*

```diff
@@ -47,52 +47,56 @@
 #include "cutlass/numeric_types.h"
 #include "cutlass/arch/wmma.h"
 
 #include "cutlass/epilogue/threadblock/epilogue.h"
 #include "cutlass/epilogue/thread/linear_combination.h"
 
 #include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h"
-#include "cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h"
+#include "cutlass/gemm/kernel/gemm_with_k_reduction.h"
+#include "cutlass/gemm/threadblock/default_mma_with_reduction.h"
+#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
 
 #include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
+#include "cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <
     /// Element type for A matrix operand
     typename ElementA,
     /// Layout type for A matrix operand
     typename LayoutA,
+    /// Complex elementwise transformation on A operand
+    ComplexTransform TransformA,
     /// Access granularity of A matrix in units of elements
     int kAlignmentA,
     /// Element type for B matrix operand
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
+    /// Complex elementwise transformation on B operand
+    ComplexTransform TransformB,
     /// Access granularity of B matrix in units of elements
     int kAlignmentB,
-    /// Element type for Scale/Bias vectors
-    typename ElementScaleBias,
-    /// Layout type for Scale/Bias vectors
-    typename LayoutScaleBias,
     /// Element type for C and D matrix operands
     typename ElementC,
     /// Layout type for C and D matrix operands
     typename LayoutC,
     /// Element type for internal accumulation
     typename ElementAccumulator,
     /// Operator class tag
     typename OperatorClass,
+    /// Reduce A or B along the K dimension
+    bool ReduceKForA_,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Warp-level tile size (concept: GemmShape)
@@ -102,34 +106,43 @@
     /// Threadblock-level swizzling operator
     typename ThreadblockSwizzle,
     /// Number of stages used in the pipelined mainloop
     int Stages,
     /// Operation performed by GEMM
     typename Operator,
     /// Use zfill or predicate for out-of-bound cp.async
-    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone>
-struct DefaultGemmLayernormMainloopFusion {
+    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone,
+    ///
+    typename Enable = void>
+struct DefaultGemmWithKReduction {
+
+  static const bool kReduceKForA = (platform::is_same<LayoutC, cutlass::layout::RowMajor>::value) ? ReduceKForA_ : !ReduceKForA_;
 
   /// Define the threadblock-scoped matrix multiply-accumulate
-  using Mma = typename cutlass::gemm::threadblock::DefaultMmaLayernormMainloopFusion<
+  using Mma = typename cutlass::gemm::threadblock::DefaultMmaWithReduction<
       ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
-      ElementScaleBias, LayoutScaleBias, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm80,
+      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, kReduceKForA, arch::Sm80,
       ThreadblockShape, WarpShape, InstructionShape, Stages,
       Operator, false, SharedMemoryClear>::ThreadblockMma;
 
   static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
 
   /// Define the epilogue
   using Epilogue =
       typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
           ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
           EpilogueOutputOp::kCount>::Epilogue;
 
+  /// Define the epilogue of the reduction vector
+  using EpilogueGemmKReduction =
+      typename cutlass::epilogue::threadblock::EpilogueGemmKReduction<
+          ElementAccumulator, ElementC, ThreadblockShape, typename Mma::Operator, kReduceKForA>;
+
   /// Define the kernel-level GEMM operator.
-  using GemmKernel = kernel::GemmLayernormMainloopFusion<Mma, Epilogue, ThreadblockSwizzle>;
+  using GemmKernel = kernel::GemmWithKReduction<Mma, Epilogue, EpilogueGemmKReduction, ThreadblockSwizzle>;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace kernel
 }  // namespace gemm
 }  // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_visitor.h`

 * *Files 12% similar despite different names*

```diff
@@ -25,21 +25,15 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief 
-      Default kernel-level GEMM definitions combine threadblock-scoped matrix multiply-add with
-      the appropriate threadblock-scoped epilogue.
-  
-      Note, CUTLASS epilogues universally target row-major outputs. Column-major outputs are
-      accommodated by exchanging A and B operands and assuming transposed layouts. Partial
-      specializations here choose 'device::GemmTransposed' to implement this functionality.
+    \brief Default sparse GEMM with visitor.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 
 #include "cutlass/layout/matrix.h"
@@ -47,27 +41,29 @@
 #include "cutlass/arch/wmma.h"
 
 #include "cutlass/epilogue/threadblock/epilogue.h"
 #include "cutlass/epilogue/thread/linear_combination.h"
 
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/kernel/gemm.h"
-#include "cutlass/gemm/kernel/sparse_gemm.h"
+#include "cutlass/gemm/kernel/default_gemm_sparse.h"
+#include "cutlass/gemm/kernel/sparse_gemm_with_visitor.h"
 #include "cutlass/gemm/kernel/gemm_pipelined.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sm75.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sm70.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h"
 #include "cutlass/gemm/threadblock/default_sparse_mma.h"
 #include "cutlass/gemm/threadblock/default_mma_core_simt.h"
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
 
 #include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_simt.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
 
 #if defined(CUTLASS_ARCH_WMMA_ENABLED)
 #include "cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h"
 #endif //CUTLASS_ARCH_WMMA_ENABLED
 
 
@@ -77,53 +73,52 @@
 namespace gemm {
 namespace kernel {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <
     /// Element type for A matrix operand
-    typename ElementA_,
+    typename ElementA,
     /// Layout type for A matrix operand
-    typename LayoutA_,
+    typename LayoutA,
     /// Access granularity of A matrix in units of elements
     int kAlignmentA,
     /// Element type for B matrix operand
-    typename ElementB_,
+    typename ElementB,
     /// Layout type for B matrix operand
-    typename LayoutB_,
+    typename LayoutB,
     /// Access granularity of B matrix in units of elements
     int kAlignmentB,
     /// Element type for C and D matrix operands
-    typename ElementC_,
+    typename ElementC,
     /// Layout type for C and D matrix operands
-    typename LayoutC_,
+    typename LayoutC,
     /// Element type for internal accumulation
     typename ElementAccumulator,
     /// Operator class tag
     typename OperatorClass,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Warp-level tile size (concept: GemmShape)
     typename InstructionShape,
     /// Epilogue output operator
-    typename EpilogueOutputOp,
+    typename FusionCallbacks,
     /// Threadblock-level swizzling operator
     typename ThreadblockSwizzle,
     /// Number of stages used in the pipelined mainloop
     int Stages,
-    /// If true, kernel is configured to support serial reduction in the
-    /// epilogue
-    bool SplitKSerial,
     /// Operation performed by GEMM
-    typename Operator>
-struct DefaultSparseGemm;
+    typename Operator,
+    /// Number of stages used in the pipelined epilogue
+    int EpilogueStages = 1>
+struct DefaultSparseGemmWithVisitor;
 
 ////////////////////////////////////////////////////////////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Ampere Architecture
 template <
     /// Element type for A matrix operand
@@ -136,56 +131,67 @@
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
     /// Access granularity of A matrix in units of elements
     int kAlignmentB,
     /// Element type for C and D matrix operands
     typename ElementC,
+    /// Layout type for C and D matrix operands
+    typename LayoutC,
     /// Element type for internal accumulation
     typename ElementAccumulator,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Warp-level tile size (concept: GemmShape)
     typename InstructionShape,
     /// Epilogue output operator
-    typename EpilogueOutputOp,
+    typename FusionCallbacks,
     /// Threadblock-level swizzling operator
     typename ThreadblockSwizzle,
     /// Number of stages used in the pipelined mainloop
     int Stages,
-    /// If true, kernel is configured to support serial reduction in the
-    /// epilogue
-    bool SplitKSerial,
     /// Operation performed by GEMM
-    typename Operator>
-struct DefaultSparseGemm<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB, ElementC,
-                   layout::RowMajor, ElementAccumulator, arch::OpClassTensorOp,
+    typename Operator,
+    /// Number of stages used in the pipelined epilogue
+    int EpilogueStages>
+struct DefaultSparseGemmWithVisitor<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+                   ElementC, LayoutC, ElementAccumulator, arch::OpClassTensorOp,
                    arch::Sm80, ThreadblockShape, WarpShape, InstructionShape,
-                   EpilogueOutputOp, ThreadblockSwizzle, Stages, SplitKSerial,
-                   Operator> {
+                   FusionCallbacks, ThreadblockSwizzle, Stages, Operator,
+                   EpilogueStages> {
   /// Define the threadblock-scoped matrix multiply-accumulate
   using Mma = typename cutlass::gemm::threadblock::DefaultSparseMma<
       ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
       ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm80,
       ThreadblockShape, WarpShape, InstructionShape, Stages,
       Operator>::ThreadblockMma;
 
-  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+  static constexpr int kAlignmentC = 128 / sizeof_bits<ElementC>::value;;
+  using ElementEpilogue = ElementAccumulator;
 
-  /// Define the epilogue
-  using Epilogue =
+  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
+  using EpilogueOutputOp =
+      typename epilogue::thread::LinearCombination<
+          ElementC, kAlignmentC,
+          ElementAccumulator, ElementEpilogue>;
+  using BaseEpilogue =
       typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
-          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
-          EpilogueOutputOp::kCount>::Epilogue;
+          ThreadblockShape, typename Mma::Operator, kPartitionsK,
+          EpilogueOutputOp, EpilogueOutputOp::kCount>::Epilogue;
+
+  // Define epilogue
+  using Epilogue = cutlass::epilogue::threadblock::EpilogueWithVisitorCallbacks<
+      BaseEpilogue,
+      FusionCallbacks,
+      EpilogueStages>;
 
   /// Define the kernel-level GEMM operator.
-  using GemmKernel = kernel::SparseGemm<Mma, Epilogue, ThreadblockSwizzle, SplitKSerial>;
+  using GemmKernel = kernel::SparseGemmWithEpilogueVisitor<Mma, Epilogue, ThreadblockSwizzle>;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace kernel
 }  // namespace gemm
 }  // namespace cutlass
-
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h`

 * *Files 16% similar despite different names*

```diff
@@ -24,174 +24,220 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Default sparse GEMM with visitor.
+  \brief 
+    Defines a GEMM with Reduction based on an existing UniversalGemm kernel.
+
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 
-#include "cutlass/layout/matrix.h"
-#include "cutlass/numeric_types.h"
-#include "cutlass/arch/wmma.h"
-
-#include "cutlass/epilogue/threadblock/epilogue.h"
-#include "cutlass/epilogue/thread/linear_combination.h"
-
-#include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/kernel/gemm.h"
-#include "cutlass/gemm/kernel/default_gemm_sparse.h"
-#include "cutlass/gemm/kernel/sparse_gemm_with_visitor.h"
-#include "cutlass/gemm/kernel/gemm_pipelined.h"
-#include "cutlass/gemm/threadblock/default_mma_core_sm75.h"
-#include "cutlass/gemm/threadblock/default_mma_core_sm70.h"
-#include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
-#include "cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h"
-#include "cutlass/gemm/threadblock/default_sparse_mma.h"
-#include "cutlass/gemm/threadblock/default_mma_core_simt.h"
-#include "cutlass/gemm/threadblock/threadblock_swizzle.h"
-
-#include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
-#include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
-#include "cutlass/epilogue/threadblock/default_epilogue_simt.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h"
-#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
-
-#if defined(CUTLASS_ARCH_WMMA_ENABLED)
-#include "cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h"
-#endif //CUTLASS_ARCH_WMMA_ENABLED
+#include "cutlass/gemm/kernel/gemm_with_fused_epilogue.h"
+#include "cutlass/gemm/kernel/default_gemm_universal.h"
 
+#include "cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_broadcast.h"
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-    /// Element type for A matrix operand
-    typename ElementA,
-    /// Layout type for A matrix operand
-    typename LayoutA,
-    /// Access granularity of A matrix in units of elements
-    int kAlignmentA,
-    /// Element type for B matrix operand
-    typename ElementB,
-    /// Layout type for B matrix operand
-    typename LayoutB,
-    /// Access granularity of B matrix in units of elements
-    int kAlignmentB,
-    /// Element type for C and D matrix operands
-    typename ElementC,
-    /// Layout type for C and D matrix operands
-    typename LayoutC,
-    /// Element type for internal accumulation
-    typename ElementAccumulator,
-    /// Operator class tag
-    typename OperatorClass,
-    /// Tag indicating architecture to tune for
-    typename ArchTag,
-    /// Threadblock-level tile size (concept: GemmShape)
-    typename ThreadblockShape,
-    /// Warp-level tile size (concept: GemmShape)
-    typename WarpShape,
-    /// Warp-level tile size (concept: GemmShape)
-    typename InstructionShape,
-    /// Epilogue output operator
-    typename FusionCallbacks,
-    /// Threadblock-level swizzling operator
-    typename ThreadblockSwizzle,
-    /// Number of stages used in the pipelined mainloop
-    int Stages,
-    /// Operation performed by GEMM
-    typename Operator,
-    /// Number of stages used in the pipelined epilogue
-    int EpilogueStages = 1>
-struct DefaultSparseGemmWithVisitor;
+  /// Element type for A matrix operand
+  typename ElementA_,
+  /// Layout type for A matrix operand
+  typename LayoutA_,
+  /// Complex elementwise transformation on A operand
+  ComplexTransform TransformA,
+  /// Access granularity of A matrix in units of elements
+  int kAlignmentA,
+  /// Element type for B matrix operand
+  typename ElementB_,
+  /// Layout type for B matrix operand
+  typename LayoutB_,
+  /// Complex elementwise transformation on B operand
+  ComplexTransform TransformB,
+  /// Access granularity of B matrix in units of elements
+  int kAlignmentB,
+  /// Element type for C and D matrix operands
+  typename ElementC_,
+  /// Layout type for C and D matrix operands
+  typename LayoutC_,
+  /// Element type for internal accumulation
+  typename ElementAccumulator,
+  /// Operator class tag
+  typename OperatorClass,
+  /// Tag indicating architecture to tune for
+  typename ArchTag,
+  /// Threadblock-level tile size (concept: GemmShape)
+  typename ThreadblockShape,
+  /// Warp-level tile size (concept: GemmShape)
+  typename WarpShape,
+  /// Warp-level tile size (concept: GemmShape)
+  typename InstructionShape,
+  /// Epilogue output operator      - must satisfy concept of 'EpilogueWithBroadcastOp' 
+  typename EpilogueOutputOp,
+  /// Threadblock-level swizzling operator
+  typename ThreadblockSwizzle,
+  /// Number of stages used in the pipelined mainloop
+  int Stages,
+  /// Operation performed by GEMM
+  typename Operator,
+  ///
+  typename Enable = void
+>
+struct DefaultGemmWithBroadcast {
+
+  using GemmBase = typename DefaultGemmUniversal<
+    ElementA_, LayoutA_, TransformA, kAlignmentA,
+    ElementB_, LayoutB_, TransformB, kAlignmentB,
+    ElementC_, LayoutC_, ElementAccumulator,
+    OperatorClass,
+    ArchTag,
+    ThreadblockShape,
+    WarpShape,
+    InstructionShape,
+    EpilogueOutputOp,
+    ThreadblockSwizzle,
+    Stages,
+    Operator
+  >::GemmKernel;
+
+  // Define epilogue
+  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastTensorOp<
+    typename GemmBase::Epilogue::Shape,
+    typename GemmBase::Epilogue::WarpMmaOperator,
+    GemmBase::Epilogue::kPartitionsK,
+    ElementC_,
+    typename EpilogueOutputOp::ElementT,
+    typename EpilogueOutputOp::ElementVector,
+    EpilogueOutputOp,
+    GemmBase::Epilogue::kElementsPerAccess
+  >::Epilogue;
+
+  // Compose the GEMM kernel
+  using GemmKernel = GemmWithFusedEpilogue<
+    typename GemmBase::Mma,
+    Epilogue,
+    ThreadblockSwizzle
+  >;
+};
+
 
-////////////////////////////////////////////////////////////////////////////////
-///////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Ampere Architecture
+/// Partial specialization: ArchTag = cutlass::arch::Sm70
+///
+///
 template <
-    /// Element type for A matrix operand
-    typename ElementA,
-    /// Layout type for A matrix operand
-    typename LayoutA,
-    /// Access granularity of A matrix in units of elements
-    int kAlignmentA,
-    /// Element type for B matrix operand
-    typename ElementB,
-    /// Layout type for B matrix operand
-    typename LayoutB,
-    /// Access granularity of A matrix in units of elements
-    int kAlignmentB,
-    /// Element type for C and D matrix operands
-    typename ElementC,
-    /// Layout type for C and D matrix operands
-    typename LayoutC,
-    /// Element type for internal accumulation
-    typename ElementAccumulator,
-    /// Threadblock-level tile size (concept: GemmShape)
-    typename ThreadblockShape,
-    /// Warp-level tile size (concept: GemmShape)
-    typename WarpShape,
-    /// Warp-level tile size (concept: GemmShape)
-    typename InstructionShape,
-    /// Epilogue output operator
-    typename FusionCallbacks,
-    /// Threadblock-level swizzling operator
-    typename ThreadblockSwizzle,
-    /// Number of stages used in the pipelined mainloop
-    int Stages,
-    /// Operation performed by GEMM
-    typename Operator,
-    /// Number of stages used in the pipelined epilogue
-    int EpilogueStages>
-struct DefaultSparseGemmWithVisitor<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
-                   ElementC, LayoutC, ElementAccumulator, arch::OpClassTensorOp,
-                   arch::Sm80, ThreadblockShape, WarpShape, InstructionShape,
-                   FusionCallbacks, ThreadblockSwizzle, Stages, Operator,
-                   EpilogueStages> {
-  /// Define the threadblock-scoped matrix multiply-accumulate
-  using Mma = typename cutlass::gemm::threadblock::DefaultSparseMma<
-      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
-      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, arch::Sm80,
-      ThreadblockShape, WarpShape, InstructionShape, Stages,
-      Operator>::ThreadblockMma;
-
-  static constexpr int kAlignmentC = 128 / sizeof_bits<ElementC>::value;;
-  using ElementEpilogue = ElementAccumulator;
-
-  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
-  using EpilogueOutputOp =
-      typename epilogue::thread::LinearCombination<
-          ElementC, kAlignmentC,
-          ElementAccumulator, ElementEpilogue>;
-  using BaseEpilogue =
-      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
-          ThreadblockShape, typename Mma::Operator, kPartitionsK,
-          EpilogueOutputOp, EpilogueOutputOp::kCount>::Epilogue;
+  /// Element type for A matrix operand
+  typename ElementA_,
+  /// Layout type for A matrix operand
+  typename LayoutA_,
+  /// Complex elementwise transformation on A operand
+  ComplexTransform TransformA,
+  /// Access granularity of A matrix in units of elements
+  int kAlignmentA,
+  /// Element type for B matrix operand
+  typename ElementB_,
+  /// Layout type for B matrix operand
+  typename LayoutB_,
+  /// Complex elementwise transformation on B operand
+  ComplexTransform TransformB,
+  /// Access granularity of B matrix in units of elements
+  int kAlignmentB,
+  /// Element type for C and D matrix operands
+  typename ElementC_,
+  /// Layout type for C and D matrix operands
+  typename LayoutC_,
+  /// Element type for internal accumulation
+  typename ElementAccumulator,
+  /// Operator class tag
+  typename OperatorClass,
+  /// Threadblock-level tile size (concept: GemmShape)
+  typename ThreadblockShape,
+  /// Warp-level tile size (concept: GemmShape)
+  typename WarpShape,
+  /// Warp-level tile size (concept: GemmShape)
+  typename InstructionShape,
+  /// Epilogue output operator      - must satisfy concept of 'EpilogueWithBroadcastOp' 
+  typename EpilogueOutputOp,
+  /// Threadblock-level swizzling operator
+  typename ThreadblockSwizzle,
+  /// Number of stages used in the pipelined mainloop
+  int Stages,
+  /// Operation performed by GEMM
+  typename Operator,
+  ///
+  typename Enable
+>
+struct DefaultGemmWithBroadcast<
+  ElementA_, LayoutA_, TransformA, kAlignmentA, 
+  ElementB_, LayoutB_, TransformB, kAlignmentB,
+  ElementC_, LayoutC_,
+  ElementAccumulator,
+  OperatorClass,
+  cutlass::arch::Sm70,
+  ThreadblockShape,
+  WarpShape,
+  InstructionShape,
+  EpilogueOutputOp,
+  ThreadblockSwizzle,
+  Stages,
+  Operator,
+  Enable
+  > {
+
+  using GemmBase = typename DefaultGemmUniversal<
+    ElementA_, LayoutA_, TransformA, kAlignmentA,
+    ElementB_, LayoutB_, TransformB, kAlignmentB,
+    ElementC_, LayoutC_, ElementAccumulator,
+    OperatorClass,
+    cutlass::arch::Sm70,
+    ThreadblockShape,
+    WarpShape,
+    InstructionShape,
+    EpilogueOutputOp,
+    ThreadblockSwizzle,
+    Stages,
+    Operator
+  >::GemmKernel;
 
   // Define epilogue
-  using Epilogue = cutlass::epilogue::threadblock::EpilogueWithVisitorCallbacks<
-      BaseEpilogue,
-      FusionCallbacks,
-      EpilogueStages>;
-
-  /// Define the kernel-level GEMM operator.
-  using GemmKernel = kernel::SparseGemmWithEpilogueVisitor<Mma, Epilogue, ThreadblockSwizzle>;
+  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastVoltaTensorOp<
+    typename GemmBase::Epilogue::Shape,
+    typename GemmBase::Epilogue::WarpMmaOperator,
+    GemmBase::Epilogue::kPartitionsK,
+    ElementC_,
+    typename EpilogueOutputOp::ElementT,
+    typename EpilogueOutputOp::ElementVector,
+    EpilogueOutputOp,
+    GemmBase::Epilogue::kElementsPerAccess
+  >::Epilogue;
+
+  // Compose the GEMM kernel
+  using GemmKernel = GemmWithFusedEpilogue<
+    typename GemmBase::Mma,
+    Epilogue,
+    ThreadblockSwizzle
+  >;
 };
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace kernel
 }  // namespace gemm
 }  // namespace cutlass
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_streamk_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_streamk_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h`

 * *Files 6% similar despite different names*

```diff
@@ -38,16 +38,16 @@
 #pragma once
 
 #include "cutlass/cutlass.h"
 
 #include "cutlass/gemm/kernel/gemm_with_fused_epilogue.h"
 #include "cutlass/gemm/kernel/default_gemm_universal.h"
 
-#include "cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_broadcast.h"
+#include "cutlass/epilogue/threadblock/default_epilogue_with_reduction.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_reduction.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
@@ -82,63 +82,64 @@
   typename ArchTag,
   /// Threadblock-level tile size (concept: GemmShape)
   typename ThreadblockShape,
   /// Warp-level tile size (concept: GemmShape)
   typename WarpShape,
   /// Warp-level tile size (concept: GemmShape)
   typename InstructionShape,
-  /// Epilogue output operator      - must satisfy concept of 'EpilogueWithBroadcastOp' 
+  /// Epilogue output operator
   typename EpilogueOutputOp,
+  /// Epilogue reduction operator
+  typename EpilogueReductionOp,
   /// Threadblock-level swizzling operator
   typename ThreadblockSwizzle,
   /// Number of stages used in the pipelined mainloop
   int Stages,
   /// Operation performed by GEMM
   typename Operator,
   ///
   typename Enable = void
 >
-struct DefaultGemmWithBroadcast {
+struct DefaultGemmWithReduction {
 
   using GemmBase = typename DefaultGemmUniversal<
     ElementA_, LayoutA_, TransformA, kAlignmentA,
     ElementB_, LayoutB_, TransformB, kAlignmentB,
     ElementC_, LayoutC_, ElementAccumulator,
     OperatorClass,
     ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
     EpilogueOutputOp,
     ThreadblockSwizzle,
     Stages,
-    Operator
+    Operator,
+    SharedMemoryClearOption::kClearLastStage
   >::GemmKernel;
 
   // Define epilogue
-  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastTensorOp<
+  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithReductionTensorOp<
     typename GemmBase::Epilogue::Shape,
     typename GemmBase::Epilogue::WarpMmaOperator,
     GemmBase::Epilogue::kPartitionsK,
     ElementC_,
-    typename EpilogueOutputOp::ElementT,
-    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
+    EpilogueReductionOp,
     GemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Compose the GEMM kernel
   using GemmKernel = GemmWithFusedEpilogue<
     typename GemmBase::Mma,
     Epilogue,
     ThreadblockSwizzle
   >;
 };
 
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization: ArchTag = cutlass::arch::Sm70
 ///
 ///
 template <
   /// Element type for A matrix operand
@@ -167,41 +168,44 @@
   typename OperatorClass,
   /// Threadblock-level tile size (concept: GemmShape)
   typename ThreadblockShape,
   /// Warp-level tile size (concept: GemmShape)
   typename WarpShape,
   /// Warp-level tile size (concept: GemmShape)
   typename InstructionShape,
-  /// Epilogue output operator      - must satisfy concept of 'EpilogueWithBroadcastOp' 
+  /// Epilogue output operator
   typename EpilogueOutputOp,
+  /// Epilogue reduction operator
+  typename EpilogueReductionOp,
   /// Threadblock-level swizzling operator
   typename ThreadblockSwizzle,
   /// Number of stages used in the pipelined mainloop
   int Stages,
   /// Operation performed by GEMM
   typename Operator,
   ///
   typename Enable
 >
-struct DefaultGemmWithBroadcast<
+struct DefaultGemmWithReduction<
   ElementA_, LayoutA_, TransformA, kAlignmentA, 
   ElementB_, LayoutB_, TransformB, kAlignmentB,
   ElementC_, LayoutC_,
   ElementAccumulator,
   OperatorClass,
   cutlass::arch::Sm70,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
+  EpilogueReductionOp,
   ThreadblockSwizzle,
   Stages,
   Operator,
   Enable
-  > {
+  >  {
 
   using GemmBase = typename DefaultGemmUniversal<
     ElementA_, LayoutA_, TransformA, kAlignmentA,
     ElementB_, LayoutB_, TransformB, kAlignmentB,
     ElementC_, LayoutC_, ElementAccumulator,
     OperatorClass,
     cutlass::arch::Sm70,
@@ -211,22 +215,21 @@
     EpilogueOutputOp,
     ThreadblockSwizzle,
     Stages,
     Operator
   >::GemmKernel;
 
   // Define epilogue
-  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastVoltaTensorOp<
+  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithReductionVoltaTensorOp<
     typename GemmBase::Epilogue::Shape,
     typename GemmBase::Epilogue::WarpMmaOperator,
     GemmBase::Epilogue::kPartitionsK,
     ElementC_,
-    typename EpilogueOutputOp::ElementT,
-    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
+    EpilogueReductionOp,
     GemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Compose the GEMM kernel
   using GemmKernel = GemmWithFusedEpilogue<
     typename GemmBase::Mma,
     Epilogue,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h`

 * *Files 13% similar despite different names*

```diff
@@ -24,127 +24,137 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
-    \brief 
-      Default kernel-level GEMM definitions combine threadblock-scoped matrix multiply-add with
-      the appropriate threadblock-scoped epilogue.
-  
-      Note, CUTLASS epilogues universally target row-major outputs. Column-major outputs are
-      accommodated by exchanging A and B operands and assuming transposed layouts. Partial
-      specializations here choose 'device::GemmTransposed' to implement this functionality.
+    \brief Template for a pipelined softmax-GEMM kernel.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-
-#include "cutlass/layout/matrix.h"
 #include "cutlass/numeric_types.h"
-#include "cutlass/arch/wmma.h"
-
-#include "cutlass/epilogue/threadblock/epilogue.h"
-#include "cutlass/epilogue/thread/linear_combination.h"
+#include "cutlass/arch/arch.h"
 
-#include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/kernel/gemm_with_k_reduction.h"
-#include "cutlass/gemm/threadblock/default_mma_with_reduction.h"
-#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
-#include "cutlass/gemm/threadblock/threadblock_swizzle.h"
-
-#include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
-#include "cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h"
+#include "cutlass/layout/matrix.h"
+#include "cutlass/gemm/threadblock/default_mma_core.h"
+#include "cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h"
+#include "cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h"
+#include "cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h"
+#include "cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h"
+#include "cutlass/gemm/warp/scale_bias_tile_iterator.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
 
+////////////////////////////////////////////////////////////////////////////////
+
 namespace cutlass {
 namespace gemm {
-namespace kernel {
+namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <
     /// Element type for A matrix operand
     typename ElementA,
     /// Layout type for A matrix operand
     typename LayoutA,
-    /// Complex elementwise transformation on A operand
-    ComplexTransform TransformA,
     /// Access granularity of A matrix in units of elements
     int kAlignmentA,
     /// Element type for B matrix operand
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
-    /// Complex elementwise transformation on B operand
-    ComplexTransform TransformB,
     /// Access granularity of B matrix in units of elements
     int kAlignmentB,
-    /// Element type for C and D matrix operands
-    typename ElementC,
-    /// Layout type for C and D matrix operands
-    typename LayoutC,
+    /// Element type for Scale/Bias vectors
+    typename ElementScaleBias,
+    /// Layout type for Scale/Bias vectors
+    typename LayoutScaleBias,
     /// Element type for internal accumulation
     typename ElementAccumulator,
+    /// Layout type for C and D matrix operands
+    typename LayoutC,
     /// Operator class tag
     typename OperatorClass,
-    /// Reduce A or B along the K dimension
-    bool ReduceKForA_,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
-    /// Warp-level tile size (concept: GemmShape)
+    /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape,
-    /// Epilogue output operator
-    typename EpilogueOutputOp,
-    /// Threadblock-level swizzling operator
-    typename ThreadblockSwizzle,
     /// Number of stages used in the pipelined mainloop
     int Stages,
-    /// Operation performed by GEMM
+    /// Whether problem has been transformed. This determines to which operand
+    /// the softmax is applied.
+    bool InternalTranspose,
+    /// Operation perfomed by GEMM
     typename Operator,
-    /// Use zfill or predicate for out-of-bound cp.async
-    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone,
-    ///
-    typename Enable = void>
-struct DefaultGemmWithKReduction {
-
-  static const bool kReduceKForA = (platform::is_same<LayoutC, cutlass::layout::RowMajor>::value) ? ReduceKForA_ : !ReduceKForA_;
-
-  /// Define the threadblock-scoped matrix multiply-accumulate
-  using Mma = typename cutlass::gemm::threadblock::DefaultMmaWithReduction<
-      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
-      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, kReduceKForA, arch::Sm80,
-      ThreadblockShape, WarpShape, InstructionShape, Stages,
-      Operator, false, SharedMemoryClear>::ThreadblockMma;
-
-  static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
-
-  /// Define the epilogue
-  using Epilogue =
-      typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
-          ThreadblockShape, typename Mma::Operator, kPartitionsK, EpilogueOutputOp,
-          EpilogueOutputOp::kCount>::Epilogue;
-
-  /// Define the epilogue of the reduction vector
-  using EpilogueGemmKReduction =
-      typename cutlass::epilogue::threadblock::EpilogueGemmKReduction<
-          ElementAccumulator, ElementC, ThreadblockShape, typename Mma::Operator, kReduceKForA>;
-
-  /// Define the kernel-level GEMM operator.
-  using GemmKernel = kernel::GemmWithKReduction<Mma, Epilogue, EpilogueGemmKReduction, ThreadblockSwizzle>;
+    /// Store the accumulators in row major or column major.  Row major is used
+    /// when output layout is interleaved.
+    bool AccumulatorsInRowMajor = false,
+    /// Use zfill or predicate for SM80 out-of-bound cp.async 
+    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone
+    >
+struct DefaultMmaSoftmaxMainloopFusion {
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpA =
+      ((sizeof_bits<ElementA>::value * kAlignmentA) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpB =
+      ((sizeof_bits<ElementB>::value * kAlignmentB) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpGammaBeta = CacheOpA;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
+      Stages, Operator, false, CacheOpA, CacheOpB>;
+
+  // Define iterators over tiles from the A operand
+  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
+  using AccessTypeA = cutlass::Array<ElementA, kAlignmentA>;
+  using IteratorA =
+      cutlass::transform::threadblock::PredicatedTileAccessIterator<
+          cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+          ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
+
+  // Define iterators over tiles from the B operand
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using AccessTypeB = cutlass::Array<ElementB, kAlignmentB>;
+  using IteratorB =
+      cutlass::transform::threadblock::PredicatedTileAccessIterator<
+          cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+          ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
+
+  /// Define iterators over tiles from scale/bias vectors
+  using IteratorNormSum =
+      cutlass::transform::threadblock::PredicatedScaleBiasVectorIterator<
+          cutlass::MatrixShape<1, WarpShape::kN>,
+          ElementScaleBias,
+          LayoutScaleBias>;
+
+  // Define the threadblock-scoped multistage matrix multiply
+  using ThreadblockMma = cutlass::gemm::threadblock::MmaSoftmaxMainloopFusionMultistage<
+      typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
+      MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
+      MmaCore::kCacheOpB, IteratorNormSum,
+      ElementAccumulator, layout::RowMajor,
+      typename MmaCore::MmaPolicy, Stages, InternalTranspose, SharedMemoryClear>;
 };
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-}  // namespace kernel
-}  // namespace gemm
-}  // namespace cutlass
+} // namespace threadblock
+} // namespace gemm
+} // namespace cutlass 
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h`

 * *Files 18% similar despite different names*

```diff
@@ -27,220 +27,195 @@
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
   \brief 
-    Defines a GEMM with Reduction based on an existing UniversalGemm kernel.
+    Defines a GEMM with Broadcast based on an existing UniversalGemm kernel.
 
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 
-#include "cutlass/gemm/kernel/gemm_with_fused_epilogue.h"
-#include "cutlass/gemm/kernel/default_gemm_universal.h"
+#include "cutlass/conv/kernel/default_conv2d_fprop.h"
+#include "cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h"
 
-#include "cutlass/epilogue/threadblock/default_epilogue_with_reduction.h"
-#include "cutlass/epilogue/threadblock/epilogue_with_reduction.h"
+#include "cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h"
+#include "cutlass/epilogue/threadblock/epilogue_with_broadcast.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
-namespace gemm {
+namespace conv {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-  /// Element type for A matrix operand
-  typename ElementA_,
-  /// Layout type for A matrix operand
-  typename LayoutA_,
-  /// Complex elementwise transformation on A operand
-  ComplexTransform TransformA,
-  /// Access granularity of A matrix in units of elements
-  int kAlignmentA,
-  /// Element type for B matrix operand
-  typename ElementB_,
-  /// Layout type for B matrix operand
-  typename LayoutB_,
-  /// Complex elementwise transformation on B operand
-  ComplexTransform TransformB,
-  /// Access granularity of B matrix in units of elements
-  int kAlignmentB,
-  /// Element type for C and D matrix operands
-  typename ElementC_,
-  /// Layout type for C and D matrix operands
-  typename LayoutC_,
-  /// Element type for internal accumulation
+  typename ElementA,
+  typename LayoutA,
+  typename ElementB,
+  typename LayoutB,
+  typename ElementC,
+  typename LayoutC,
   typename ElementAccumulator,
-  /// Operator class tag
   typename OperatorClass,
-  /// Tag indicating architecture to tune for
   typename ArchTag,
-  /// Threadblock-level tile size (concept: GemmShape)
   typename ThreadblockShape,
-  /// Warp-level tile size (concept: GemmShape)
   typename WarpShape,
-  /// Warp-level tile size (concept: GemmShape)
   typename InstructionShape,
-  /// Epilogue output operator
   typename EpilogueOutputOp,
-  /// Epilogue reduction operator
-  typename EpilogueReductionOp,
-  /// Threadblock-level swizzling operator
   typename ThreadblockSwizzle,
-  /// Number of stages used in the pipelined mainloop
   int Stages,
-  /// Operation performed by GEMM
-  typename Operator,
-  ///
-  typename Enable = void
+  typename MathOperatorTag,
+  conv::IteratorAlgorithm IteratorAlgorithm = IteratorAlgorithm::kOptimized,
+  conv::StrideSupport StrideSupport = StrideSupport::kUnity,
+  /// Access granularity of A matrix in units of elements
+  int AlignmentA = 128 / cutlass::sizeof_bits<ElementA>::value,
+  /// Access granularity of B matrix in units of elements
+  int AlignmentB = 128 / cutlass::sizeof_bits<ElementB>::value
 >
-struct DefaultGemmWithReduction {
+struct DefaultConv2dFpropWithBroadcast {
 
-  using GemmBase = typename DefaultGemmUniversal<
-    ElementA_, LayoutA_, TransformA, kAlignmentA,
-    ElementB_, LayoutB_, TransformB, kAlignmentB,
-    ElementC_, LayoutC_, ElementAccumulator,
+  using ImplicitGemmBase = typename DefaultConv2dFprop<
+    ElementA, LayoutA,
+    ElementB, LayoutB,
+    ElementC, LayoutC,
+    ElementAccumulator,
     OperatorClass,
     ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
     EpilogueOutputOp,
     ThreadblockSwizzle,
     Stages,
-    Operator,
-    SharedMemoryClearOption::kClearLastStage
-  >::GemmKernel;
+    MathOperatorTag,
+    IteratorAlgorithm,
+    StrideSupport,
+    AlignmentA,
+    AlignmentB
+  >::Kernel;
 
   // Define epilogue
-  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithReductionTensorOp<
-    typename GemmBase::Epilogue::Shape,
-    typename GemmBase::Epilogue::WarpMmaOperator,
-    GemmBase::Epilogue::kPartitionsK,
-    ElementC_,
+  using Epilogue = typename cutlass::conv::kernel::detail::DefaultConvEpilogueWithBroadcastTensorOp<
+    ArchTag,
+    typename ImplicitGemmBase::Epilogue::Shape,
+    typename ImplicitGemmBase::Epilogue::WarpMmaOperator,
+    ImplicitGemmBase::Epilogue::kPartitionsK,
+    ElementC,
+    typename EpilogueOutputOp::ElementT,
+    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
-    EpilogueReductionOp,
-    GemmBase::Epilogue::kElementsPerAccess
+    ImplicitGemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
-  // Compose the GEMM kernel
-  using GemmKernel = GemmWithFusedEpilogue<
-    typename GemmBase::Mma,
+  // Define the kernel
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolutionWithFusedEpilogue<
+    typename ImplicitGemmBase::Mma,
     Epilogue,
-    ThreadblockSwizzle
+    ThreadblockSwizzle,
+    conv::Operator::kFprop
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+//                            OpClassSimt convolutions
+/////////////////////////////////////////////////////////////////////////////////////////////////
+/// Defines a kernel for Conv2dFprop specialization for Analytic IteratorAlgorithm,
+/// multi-stage pipeline, and FFMA-based mainloop for SM80
 
-/// Partial specialization: ArchTag = cutlass::arch::Sm70
-///
-///
 template <
-  /// Element type for A matrix operand
-  typename ElementA_,
-  /// Layout type for A matrix operand
-  typename LayoutA_,
-  /// Complex elementwise transformation on A operand
-  ComplexTransform TransformA,
-  /// Access granularity of A matrix in units of elements
-  int kAlignmentA,
-  /// Element type for B matrix operand
-  typename ElementB_,
-  /// Layout type for B matrix operand
-  typename LayoutB_,
-  /// Complex elementwise transformation on B operand
-  ComplexTransform TransformB,
-  /// Access granularity of B matrix in units of elements
-  int kAlignmentB,
-  /// Element type for C and D matrix operands
-  typename ElementC_,
-  /// Layout type for C and D matrix operands
-  typename LayoutC_,
-  /// Element type for internal accumulation
+  typename ElementA,
+  typename LayoutA,
+  typename ElementB,
+  typename LayoutB,
+  typename ElementC,
+  typename LayoutC,
   typename ElementAccumulator,
-  /// Operator class tag
-  typename OperatorClass,
-  /// Threadblock-level tile size (concept: GemmShape)
+  typename ArchTag,
   typename ThreadblockShape,
-  /// Warp-level tile size (concept: GemmShape)
   typename WarpShape,
-  /// Warp-level tile size (concept: GemmShape)
   typename InstructionShape,
-  /// Epilogue output operator
   typename EpilogueOutputOp,
-  /// Epilogue reduction operator
-  typename EpilogueReductionOp,
-  /// Threadblock-level swizzling operator
   typename ThreadblockSwizzle,
-  /// Number of stages used in the pipelined mainloop
   int Stages,
-  /// Operation performed by GEMM
-  typename Operator,
-  ///
-  typename Enable
+  typename MathOperatorTag,
+  conv::IteratorAlgorithm IteratorAlgorithm,
+  conv::StrideSupport StrideSupport,
+  int AlignmentA,
+  int AlignmentB
 >
-struct DefaultGemmWithReduction<
-  ElementA_, LayoutA_, TransformA, kAlignmentA, 
-  ElementB_, LayoutB_, TransformB, kAlignmentB,
-  ElementC_, LayoutC_,
+struct DefaultConv2dFpropWithBroadcast <
+  ElementA,
+  LayoutA,
+  ElementB,
+  LayoutB,
+  ElementC,
+  LayoutC,
   ElementAccumulator,
-  OperatorClass,
-  cutlass::arch::Sm70,
+  arch::OpClassSimt,
+  ArchTag,
   ThreadblockShape,
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
-  EpilogueReductionOp,
   ThreadblockSwizzle,
   Stages,
-  Operator,
-  Enable
-  >  {
-
-  using GemmBase = typename DefaultGemmUniversal<
-    ElementA_, LayoutA_, TransformA, kAlignmentA,
-    ElementB_, LayoutB_, TransformB, kAlignmentB,
-    ElementC_, LayoutC_, ElementAccumulator,
-    OperatorClass,
-    cutlass::arch::Sm70,
+  MathOperatorTag,
+  IteratorAlgorithm,
+  StrideSupport,
+  AlignmentA,
+  AlignmentB
+> {
+
+  using ImplicitGemmBase = typename DefaultConv2dFprop<
+    ElementA, LayoutA,
+    ElementB, LayoutB,
+    ElementC, LayoutC,
+    ElementAccumulator,
+    arch::OpClassSimt,
+    ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
     EpilogueOutputOp,
     ThreadblockSwizzle,
     Stages,
-    Operator
-  >::GemmKernel;
+    MathOperatorTag,
+    IteratorAlgorithm,
+    StrideSupport,
+    AlignmentA,
+    AlignmentB
+  >::Kernel;
 
   // Define epilogue
-  using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithReductionVoltaTensorOp<
-    typename GemmBase::Epilogue::Shape,
-    typename GemmBase::Epilogue::WarpMmaOperator,
-    GemmBase::Epilogue::kPartitionsK,
-    ElementC_,
+  using Epilogue = typename cutlass::conv::kernel::detail::DefaultConvEpilogueWithBroadcastSimt<
+    ArchTag,
+    typename ImplicitGemmBase::Epilogue::Shape,
+    typename ImplicitGemmBase::Epilogue::WarpMmaOperator,
+    ElementC,
+    typename EpilogueOutputOp::ElementT,
+    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
-    EpilogueReductionOp,
-    GemmBase::Epilogue::kElementsPerAccess
+    ImplicitGemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
-  // Compose the GEMM kernel
-  using GemmKernel = GemmWithFusedEpilogue<
-    typename GemmBase::Mma,
+  // Define the kernel
+  using Kernel = cutlass::conv::kernel::ImplicitGemmConvolutionWithFusedEpilogue<
+    typename ImplicitGemmBase::Mma,
     Epilogue,
-    ThreadblockSwizzle
+    ThreadblockSwizzle,
+    conv::Operator::kFprop
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace kernel
-}  // namespace gemm
+}  // namespace conv
 }  // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h`

 * *Files 0% similar despite different names*

```diff
@@ -161,15 +161,15 @@
     >
 struct DefaultRank2KGrouped<ElementA, LayoutA, TransformA, kAlignmentA,
           ElementB, LayoutB, TransformB, kAlignmentB,
           ElementC, LayoutC,
           FillModeC, ElementAccumulator, OperatorClass, ArchTag, ThreadblockShape,
           WarpShape, InstructionShape, EpilogueOutputOp,
           ThreadblockSwizzle, Stages, Operator, BlasMode_, GroupScheduleMode_,
-          typename std::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
+          typename platform::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
 > {
   // If true, we must construct a 'transposed-and-exchanged' Rank2K operator.
   static bool const kInternalTranspose = platform::is_same<LayoutC, layout::ColumnMajor>::value;
 
   using MapArguments = kernel::detail::Rank2KMapArguments<
     ElementA,
     LayoutA,
@@ -279,15 +279,15 @@
     >
 struct DefaultRank2KGrouped<ElementA, LayoutA, TransformA, kAlignmentA,
           ElementB, LayoutB, TransformB, kAlignmentB,
           ElementC, LayoutC,
           FillModeC, ElementAccumulator, OperatorClass, ArchTag, ThreadblockShape,
           WarpShape, InstructionShape, EpilogueOutputOp,
           ThreadblockSwizzle, Stages, Operator, BlasMode_, GroupScheduleMode_,
-          typename std::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
+          typename platform::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
 > {
   // If true, we must construct a 'transposed-and-exchanged' Rank2K operator.
   static bool const kInternalTranspose = platform::is_same<LayoutC, layout::ColumnMajor>::value;
 
   using MapArguments = kernel::detail::Rank2KMapArguments<
     ElementA,
     LayoutA,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -179,15 +179,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   BlasMode::kSymmetric,
-  typename std::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultRank2Kkernel = typename kernel::DefaultRank2K<
     ElementA,
     LayoutA,
     kAlignmentA,
     ElementB,
@@ -297,15 +297,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   kBlasMode,
-  typename std::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultRank2Kkernel = typename kernel::DefaultRank2KComplex<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -161,15 +161,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   BlasMode::kSymmetric,
-  typename std::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultRankKkernel = typename kernel::DefaultRankK<
     ElementA,
     LayoutA,
     kAlignmentA,
     ElementC,
@@ -261,15 +261,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   kBlasMode,
-  typename std::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultRankKkernel = typename kernel::DefaultRankKComplex<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -178,15 +178,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   BlasMode::kSymmetric,
-  typename std::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultSymmkernel = typename kernel::DefaultSymm<
     ElementA,
     LayoutA,
     SideModeA,
     FillModeA,
@@ -294,15 +294,15 @@
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
   kBlasMode,
-  typename std::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultSymmkernel = typename kernel::DefaultSymmComplex<
     ElementA,
     LayoutA,
     SideModeA,
     FillModeA,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -186,15 +186,15 @@
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
-  typename std::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if< ! cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultTrmmKernel = typename kernel::DefaultTrmm<
     ElementA,
     LayoutA,
     kAlignmentA,
     ElementB,
@@ -307,15 +307,15 @@
   WarpShape,
   InstructionShape,
   EpilogueOutputOp,
   ThreadblockSwizzle,
   Stages,
   SplitKSerial,
   Operator,
-  typename std::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
+  typename platform::enable_if<cutlass::is_complex<ElementAccumulator>::value>::type
 > {
 
   using DefaultTrmmKernel = typename kernel::DefaultTrmmComplex<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h`

 * *Files 2% similar despite different names*

```diff
@@ -69,40 +69,38 @@
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   /// Parameters structure
   struct Params {
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorA::TensorRef ref_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Mma::IteratorB::TensorRef ref_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D;
-    typename OutputOp::Params output_op;
-    int *semaphore;
-    int gemm_k_iterations;
-    int gemm_k_size;
-    const int* ell_idx;
-    int ell_ncol;
-    int ell_blocksize;
-    int ell_base_idx;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorA::TensorRef ref_A{};
+    typename Mma::IteratorB::Params params_B{};
+    typename Mma::IteratorB::TensorRef ref_B{};
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_D{};
+    typename OutputOp::Params output_op{};
+    int *semaphore = nullptr;
+    int gemm_k_iterations{0};
+    int gemm_k_size{0};
+    const int* ell_idx = nullptr;
+    int ell_ncol{0};
+    int ell_blocksize{0};
+    int ell_base_idx{0};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params(): swizzle_log_tile(0), semaphore(0), gemm_k_iterations(0), gemm_k_size(0) { }
+   Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       cutlass::gemm::GemmCoord const & problem_size,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       typename Mma::IteratorA::TensorRef ref_A,
       typename Mma::IteratorB::TensorRef ref_B,
@@ -150,17 +148,15 @@
     };
     typename cutlass::transform::threadblock::ell::SharedStorage ell;
   };
 
   //
   // Methods
   //
-
-  CUTLASS_HOST_DEVICE
-  EllGemm() { }
+  EllGemm() = default;
 
   /// Determines whether kernel satisfies alignment
     static Status can_implement(
       cutlass::gemm::GemmCoord const & problem_size,
       typename Mma::IteratorA::TensorRef ref_A,
       typename Mma::IteratorB::TensorRef ref_B,
       typename Epilogue::OutputTileIterator::TensorRef ref_C,
@@ -454,40 +450,38 @@
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   /// Parameters structure
   struct Params {
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorA::TensorRef ref_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Mma::IteratorB::TensorRef ref_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D;
-    typename OutputOp::Params output_op;
-    int *semaphore;
-    int gemm_k_iterations;
-    int gemm_k_size;
-    const int* ell_idx;
-    int ell_ncol;
-    int ell_blocksize;
-    int ell_base_idx;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorA::TensorRef ref_A{};
+    typename Mma::IteratorB::Params params_B{};
+    typename Mma::IteratorB::TensorRef ref_B{};
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_D{};
+    typename OutputOp::Params output_op{};
+    int *semaphore = nullptr;
+    int gemm_k_iterations{0};
+    int gemm_k_size{0};
+    const int* ell_idx = nullptr;
+    int ell_ncol{0};
+    int ell_blocksize{0};
+    int ell_base_idx{0};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params(): swizzle_log_tile(0), semaphore(0), gemm_k_iterations(0), gemm_k_size(0) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       cutlass::gemm::GemmCoord const & problem_size,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       typename Mma::IteratorA::TensorRef ref_A,
       typename Mma::IteratorB::TensorRef ref_B,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h`

 * *Files 3% similar despite different names*

```diff
@@ -61,39 +61,37 @@
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   /// Parameters structure
   struct Params {
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorA::TensorRef ref_A;
-    int64_t stride_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Mma::IteratorB::TensorRef ref_B;
-    int64_t stride_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C;
-    int64_t stride_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D;
-    int64_t stride_D;
-    typename OutputOp::Params epilogue;
-    int batch_count;
-    int gemm_k_iterations;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorA::TensorRef ref_A{};
+    int64_t stride_A{0};
+    typename Mma::IteratorB::Params params_B{};
+    typename Mma::IteratorB::TensorRef ref_B{};
+    int64_t stride_B{0};
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_C{};
+    int64_t stride_C{0};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::OutputTileIterator::TensorRef ref_D{};
+    int64_t stride_D{0};
+    typename OutputOp::Params epilogue{};
+    int batch_count{1};
+    int gemm_k_iterations{0};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params() : swizzle_log_tile(0) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       cutlass::gemm::GemmCoord const & problem_size_,
       cutlass::gemm::GemmCoord const & grid_tiled_shape_,
       typename Mma::IteratorA::TensorRef ref_A_,
       int64_t stride_A_,
@@ -119,31 +117,27 @@
       ref_C(ref_C_),
       stride_C(stride_C_),
       params_D(ref_D_.layout()),
       ref_D(ref_D_),
       stride_D(stride_D_),
       epilogue(epilogue_),
       batch_count(batch_count_),
-      gemm_k_iterations((problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK) {
-
-    }
+      gemm_k_iterations((problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK) {}
   };
 
   /// Shared memory storage structure
   union SharedStorage {
     typename Mma::SharedStorage main_loop;
     typename Epilogue::SharedStorage epilogue;
   };
 
   //
   // Methods
   //
-
-  CUTLASS_HOST_DEVICE
-  GemmBatched() { } 
+  GemmBatched() = default;
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()(Params const &params, SharedStorage &shared_storage) {
 
     // Compute threadblock location
     ThreadblockSwizzle threadblock_swizzle;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h`

 * *Files 5% similar despite different names*

```diff
@@ -129,54 +129,40 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmCoord *problem_sizes;
-    int problem_count;
-    int threadblock_count;
-
-    typename EpilogueOutputOp::Params output_op;
-
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    GemmCoord *problem_sizes{nullptr};
+    int problem_count{0};
+    int threadblock_count{0};
+
+    typename EpilogueOutputOp::Params output_op{};
+
+    ElementA ** ptr_A{nullptr};
+    ElementB ** ptr_B{nullptr};
+    ElementC ** ptr_C{nullptr};
+    ElementC ** ptr_D{nullptr};
+
+    typename LayoutA::Stride::LongIndex *lda{nullptr};
+    typename LayoutB::Stride::LongIndex *ldb{nullptr};
+    typename LayoutC::Stride::LongIndex *ldc{nullptr};
+    typename LayoutC::Stride::LongIndex *ldd{nullptr};
 
     // Only used by device-level operator
-    GemmCoord *host_problem_sizes;
+    GemmCoord *host_problem_sizes{nullptr};
+
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments(): 
-      problem_count(0),
-      threadblock_count(0), 
-      ptr_A(nullptr), 
-      ptr_B(nullptr), 
-      ptr_C(nullptr), 
-      ptr_D(nullptr), 
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr),
-      host_problem_sizes(nullptr)
-    {
-
-    }
+    Arguments() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     Arguments(    
       GemmCoord *problem_sizes,
       int problem_count,
       int threadblock_count,
@@ -212,44 +198,34 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    typename ProblemVisitor::Params problem_visitor;
-    int threadblock_count;
+    typename ProblemVisitor::Params problem_visitor{};
+    int threadblock_count{0};
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    ElementA ** ptr_A{nullptr};
+    ElementB ** ptr_B{nullptr};
+    ElementC ** ptr_C{nullptr};
+    ElementC ** ptr_D{nullptr};
+
+    typename LayoutA::Stride::LongIndex *lda{nullptr};
+    typename LayoutB::Stride::LongIndex *ldb{nullptr};
+    typename LayoutC::Stride::LongIndex *ldc{nullptr};
+    typename LayoutC::Stride::LongIndex *ldd{nullptr};
 
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params():
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr)
-    { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(Arguments const &args,
           void *workspace = nullptr,
           int tile_count = 0):
       problem_visitor(args.problem_sizes, args.problem_count, workspace, tile_count),
       threadblock_count(args.threadblock_count),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h`

 * *Files 6% similar despite different names*

```diff
@@ -131,58 +131,41 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmCoord *problem_sizes;
-    int problem_count;
-    int threadblock_count;
-
-    typename EpilogueOutputOp::Params output_op;
-
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-    void ** ptr_norm;
-    void ** ptr_sum;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    GemmCoord *problem_sizes{nullptr};
+    int problem_count{0};
+    int threadblock_count{0};
+
+    typename EpilogueOutputOp::Params output_op{};
+
+    ElementA ** ptr_A{nullptr};
+    ElementB ** ptr_B{nullptr};
+    ElementC ** ptr_C{nullptr};
+    ElementC ** ptr_D{nullptr};
+    void ** ptr_norm{nullptr};
+    void ** ptr_sum{nullptr};
+
+    typename LayoutA::Stride::LongIndex *lda{nullptr};
+    typename LayoutB::Stride::LongIndex *ldb{nullptr};
+    typename LayoutC::Stride::LongIndex *ldc{nullptr};
+    typename LayoutC::Stride::LongIndex *ldd{nullptr};
 
     // Only used by device-level operator
-    GemmCoord *host_problem_sizes;
+    GemmCoord *host_problem_sizes{nullptr};
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments():
-      problem_count(0),
-      threadblock_count(0),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      ptr_norm(nullptr),
-      ptr_sum(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr),
-      host_problem_sizes(nullptr)
-    {
-
-    }
+    Arguments() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     Arguments(
       GemmCoord *problem_sizes,
       int problem_count,
       int threadblock_count,
@@ -222,49 +205,37 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    typename ProblemVisitor::Params problem_visitor;
-    int threadblock_count;
+    typename ProblemVisitor::Params problem_visitor{};
+    int threadblock_count{0};
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-
-    void ** ptr_norm;
-    void ** ptr_sum;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    ElementA ** ptr_A{nullptr};
+    ElementB ** ptr_B{nullptr};
+    ElementC ** ptr_C{nullptr};
+    ElementC ** ptr_D{nullptr};
+
+    void ** ptr_norm{nullptr};
+    void ** ptr_sum{nullptr};
+
+    typename LayoutA::Stride::LongIndex *lda{nullptr};
+    typename LayoutB::Stride::LongIndex *ldb{nullptr};
+    typename LayoutC::Stride::LongIndex *ldc{nullptr};
+    typename LayoutC::Stride::LongIndex *ldd{nullptr};
 
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params():
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      ptr_norm(nullptr),
-      ptr_sum(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr)
-    { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(Arguments const &args,
           void *workspace = nullptr,
           int tile_count = 0):
       problem_visitor(args.problem_sizes, args.problem_count, workspace, tile_count),
       threadblock_count(args.threadblock_count),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h`

 * *Files 2% similar despite different names*

```diff
@@ -107,67 +107,60 @@
   /// Argument structure
   struct Arguments : UniversalArgumentsBase
   {
     //
     // Data members
     //
 
-    typename EpilogueOutputOp::Params epilogue;
+    typename EpilogueOutputOp::Params epilogue{};
 
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_var;
-    void const * ptr_mean;
-    void const * ptr_gamma;
-    void const * ptr_beta;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_var;
-    int64_t batch_stride_mean;
-    int64_t batch_stride_gamma;
-    int64_t batch_stride_beta;
-    int64_t batch_stride_C;
-
-    typename LayoutA::Stride stride_a;
-    typename LayoutB::Stride stride_b;
-    typename LayoutScaleBias::Stride stride_var;
-    typename LayoutScaleBias::Stride stride_mean;
-    typename LayoutScaleBias::Stride stride_gamma;
-    typename LayoutScaleBias::Stride stride_beta;
-    typename LayoutC::Stride stride_c;
-    typename LayoutC::Stride stride_d;
-
-    typename LayoutA::Stride::LongIndex lda;
-    typename LayoutB::Stride::LongIndex ldb;
-    typename LayoutScaleBias::Stride::LongIndex ld_var;
-    typename LayoutScaleBias::Stride::LongIndex ld_mean;
-    typename LayoutScaleBias::Stride::LongIndex ld_gamma;
-    typename LayoutScaleBias::Stride::LongIndex ld_beta;
-    typename LayoutC::Stride::LongIndex ldc;
-    typename LayoutC::Stride::LongIndex ldd;
-
-    int const * ptr_gather_A_indices;
-    int const * ptr_gather_B_indices;
-    int const * ptr_scatter_D_indices;
+    void const * ptr_A{nullptr};
+    void const * ptr_B{nullptr};
+    void const * ptr_var{nullptr};
+    void const * ptr_mean{nullptr};
+    void const * ptr_gamma{nullptr};
+    void const * ptr_beta{nullptr};
+    void const * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_var{0};
+    int64_t batch_stride_mean{0};
+    int64_t batch_stride_gamma{0};
+    int64_t batch_stride_beta{0};
+    int64_t batch_stride_C{0};
+
+    typename LayoutA::Stride stride_a{};
+    typename LayoutB::Stride stride_b{};
+    typename LayoutScaleBias::Stride stride_var{};
+    typename LayoutScaleBias::Stride stride_mean{};
+    typename LayoutScaleBias::Stride stride_gamma{};
+    typename LayoutScaleBias::Stride stride_beta{};
+    typename LayoutC::Stride stride_c{};
+    typename LayoutC::Stride stride_d{};
+
+    typename LayoutA::Stride::LongIndex lda{};
+    typename LayoutB::Stride::LongIndex ldb{};
+    typename LayoutScaleBias::Stride::LongIndex ld_var{};
+    typename LayoutScaleBias::Stride::LongIndex ld_mean{};
+    typename LayoutScaleBias::Stride::LongIndex ld_gamma{};
+    typename LayoutScaleBias::Stride::LongIndex ld_beta{};
+    typename LayoutC::Stride::LongIndex ldc{};
+    typename LayoutC::Stride::LongIndex ldd{};
+
+    int const * ptr_gather_A_indices{nullptr};
+    int const * ptr_gather_B_indices{nullptr};
+    int const * ptr_scatter_D_indices{nullptr};
 
     //
     // Methods
     //
     
-    Arguments(): 
-      ptr_A(nullptr), ptr_B(nullptr), ptr_C(nullptr), ptr_D(nullptr),
-      ptr_var(nullptr), ptr_mean(nullptr),
-      ptr_gamma(nullptr), ptr_beta(nullptr),
-      ptr_gather_A_indices(nullptr),
-      ptr_gather_B_indices(nullptr),
-      ptr_scatter_D_indices(nullptr)
-    {}
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h`

 * *Files 10% similar despite different names*

```diff
@@ -66,54 +66,44 @@
   using MmaIteratorParams = typename cutlass::transform::threadblock::PredicatedTileAccessIteratorParams;  
   using EpilogueIteratorParams = typename cutlass::epilogue::threadblock::PredicatedTileIteratorParams;
 
   //
   // Data members
   //
 
-  cutlass::gemm::GemmCoord problem_size;
-  cutlass::gemm::GemmCoord grid_tiled_shape;
-  int swizzle_log_tile;
-
-  // Data members for Mma::Iterator::Params
-  MmaIteratorParams params_itr_a;
-  MmaIteratorParams params_itr_b;  
-
-  // Data member for Epilogue::OutputTileIterator::Params 
-  EpilogueIteratorParams params_itr_c;
-  EpilogueIteratorParams params_itr_d;
-
-
-  GemmUniversalMode mode;
-  int batch_count;
-  int gemm_k_size;
-
-  void * ptr_A;
-  void * ptr_B;
-  void * ptr_C;
-  void * ptr_D;
-
-  LongIndex lda; 
-  LongIndex ldb; 
-  LongIndex ldc; 
-  LongIndex ldd;
-
-  LongIndex batch_stride_A;
-  LongIndex batch_stride_B;
-  LongIndex batch_stride_C;
-  LongIndex batch_stride_D;
+  cutlass::gemm::GemmCoord problem_size{};
+  cutlass::gemm::GemmCoord grid_tiled_shape{};
+  int swizzle_log_tile{};
+
+  GemmUniversalMode mode{GemmUniversalMode::kGemm};
+  int batch_count{1};
+  int gemm_k_size{0};
+
+  void * ptr_A{nullptr};
+  void * ptr_B{nullptr};
+  void * ptr_C{nullptr};
+  void * ptr_D{nullptr};
+
+  LongIndex lda{0};
+  LongIndex ldb{0};
+  LongIndex ldc{0};
+  LongIndex ldd{0};
+
+  LongIndex batch_stride_A{0};
+  LongIndex batch_stride_B{0};
+  LongIndex batch_stride_C{0};
+  LongIndex batch_stride_D{0};
 
-  int *semaphore;
+  int *semaphore{nullptr};
 
   //
   // Methods
   //
 
-  CUTLASS_HOST_DEVICE
-  GemmParams()  {}
+  GemmParams() = default;
 
   CUTLASS_HOST_DEVICE
   GemmParams(
     cutlass::gemm::GemmCoord problem_size_,
     cutlass::gemm::GemmCoord grid_tiled_shape_,
     int swizzle_log_tile_,
     GemmUniversalMode mode_,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h`

 * *Files 2% similar despite different names*

```diff
@@ -108,59 +108,47 @@
   /// Argument structure
   struct Arguments : UniversalArgumentsBase
   {
     //
     // Data members
     //
 
-    typename EpilogueOutputOp::Params epilogue;
+    typename EpilogueOutputOp::Params epilogue{};
 
-    void const * ptr_A_real;
-    void const * ptr_A_imag;
-
-    void const * ptr_B_real;
-    void const * ptr_B_imag;
-
-    void const * ptr_C_real;
-    void const * ptr_C_imag;
-
-    void * ptr_D_real;
-    void * ptr_D_imag;
-
-    typename LayoutA::Stride::Index lda_real;
-    typename LayoutA::Stride::Index lda_imag;
-    typename LayoutB::Stride::Index ldb_real;
-    typename LayoutB::Stride::Index ldb_imag;
-    typename LayoutC::Stride::Index ldc_real;
-    typename LayoutC::Stride::Index ldc_imag;
-    typename LayoutC::Stride::Index ldd_real;
-    typename LayoutC::Stride::Index ldd_imag;
+    void const * ptr_A_real{nullptr};
+    void const * ptr_A_imag{nullptr};
+    void const * ptr_B_real{nullptr};
+    void const * ptr_B_imag{nullptr};
+    void const * ptr_C_real{nullptr};
+    void const * ptr_C_imag{nullptr};
+    void * ptr_D_real{nullptr};
+    void * ptr_D_imag{nullptr};
+
+    typename LayoutA::Stride::Index lda_real{};
+    typename LayoutA::Stride::Index lda_imag{};
+    typename LayoutB::Stride::Index ldb_real{};
+    typename LayoutB::Stride::Index ldb_imag{};
+    typename LayoutC::Stride::Index ldc_real{};
+    typename LayoutC::Stride::Index ldc_imag{};
+    typename LayoutC::Stride::Index ldd_real{};
+    typename LayoutC::Stride::Index ldd_imag{};
     
-    int64_t batch_stride_A;
-    int64_t batch_stride_A_imag;
-    int64_t batch_stride_B;
-    int64_t batch_stride_B_imag;
-    int64_t batch_stride_C;
-    int64_t batch_stride_C_imag;
-    int64_t batch_stride_D_imag;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_A_imag{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_B_imag{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_C_imag{0};
+    int64_t batch_stride_D_imag{0};
 
     //
     // Methods
     //
-    
-    Arguments() :
-      ptr_A_real(nullptr), 
-      ptr_A_imag(nullptr), 
-      ptr_B_real(nullptr), 
-      ptr_B_imag(nullptr), 
-      ptr_C_real(nullptr), 
-      ptr_C_imag(nullptr), 
-      ptr_D_real(nullptr),
-      ptr_D_imag(nullptr)
-    {}
+
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
@@ -256,42 +244,42 @@
       LayoutA,
       LayoutB>;
 
     //
     // Data members
     //
 
-    typename Mma::IteratorA::Params params_A_real;
-    typename Mma::IteratorA::Params params_A_imag;
-    typename Mma::IteratorB::Params params_B_real;
-    typename Mma::IteratorB::Params params_B_imag;
-    typename Epilogue::OutputTileIterator::Params params_C_real;
-    typename Epilogue::OutputTileIterator::Params params_C_imag;
-    typename Epilogue::OutputTileIterator::Params params_D_real;
-    typename Epilogue::OutputTileIterator::Params params_D_imag;
+    typename Mma::IteratorA::Params params_A_real{};
+    typename Mma::IteratorA::Params params_A_imag{};
+    typename Mma::IteratorB::Params params_B_real{};
+    typename Mma::IteratorB::Params params_B_imag{};
+    typename Epilogue::OutputTileIterator::Params params_C_real{};
+    typename Epilogue::OutputTileIterator::Params params_C_imag{};
+    typename Epilogue::OutputTileIterator::Params params_D_real{};
+    typename Epilogue::OutputTileIterator::Params params_D_imag{};
     
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    void * ptr_A_real;
-    void * ptr_A_imag;
-    void * ptr_B_real;
-    void * ptr_B_imag;
-    void * ptr_C_real;
-    void * ptr_C_imag;
-    void * ptr_D_real;
-    void * ptr_D_imag;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-
-    int64_t batch_stride_A_imag;
-    int64_t batch_stride_B_imag;
-    int64_t batch_stride_C_imag;
-    int64_t batch_stride_D_imag;
+    void * ptr_A_real{nullptr};
+    void * ptr_A_imag{nullptr};
+    void * ptr_B_real{nullptr};
+    void * ptr_B_imag{nullptr};
+    void * ptr_C_real{nullptr};
+    void * ptr_C_imag{nullptr};
+    void * ptr_D_real{nullptr};
+    void * ptr_D_imag{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+
+    int64_t batch_stride_A_imag{0};
+    int64_t batch_stride_B_imag{0};
+    int64_t batch_stride_C_imag{0};
+    int64_t batch_stride_D_imag{0};
 
     //
     // Host dispatch API
     //
 
     /// Default constructor
     Params() = default;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h`

 * *Files 4% similar despite different names*

```diff
@@ -108,58 +108,46 @@
   /// Argument structure
   struct Arguments : UniversalArgumentsBase
   {
     //
     // Data members
     //
 
-    typename EpilogueOutputOp::Params epilogue;
+    typename EpilogueOutputOp::Params epilogue{};
 
-    int const *ptr_M;
-    int const *ptr_N;
-    int const *ptr_K;
-
-    void const * const * ptr_A_real;
-    void const * const * ptr_A_imag;
-
-    void const * const * ptr_B_real;
-    void const * const * ptr_B_imag;
-
-    void const * const * ptr_C_real;
-    void const * const * ptr_C_imag;
-
-    void * const * ptr_D_real;
-    void * const * ptr_D_imag;
-
-    typename LayoutA::Stride::Index lda_real;
-    typename LayoutA::Stride::Index lda_imag;
-    typename LayoutB::Stride::Index ldb_real;
-    typename LayoutB::Stride::Index ldb_imag;
-    typename LayoutC::Stride::Index ldc_real;
-    typename LayoutC::Stride::Index ldc_imag;
-    typename LayoutC::Stride::Index ldd_real;
-    typename LayoutC::Stride::Index ldd_imag;
+    int const *ptr_M{nullptr};
+    int const *ptr_N{nullptr};
+    int const *ptr_K{nullptr};
+
+    void const * const * ptr_A_real{nullptr};
+    void const * const * ptr_A_imag{nullptr};
+
+    void const * const * ptr_B_real{nullptr};
+    void const * const * ptr_B_imag{nullptr};
+
+    void const * const * ptr_C_real{nullptr};
+    void const * const * ptr_C_imag{nullptr};
+
+    void * const * ptr_D_real{nullptr};
+    void * const * ptr_D_imag{nullptr};
+
+    typename LayoutA::Stride::Index lda_real{};
+    typename LayoutA::Stride::Index lda_imag{};
+    typename LayoutB::Stride::Index ldb_real{};
+    typename LayoutB::Stride::Index ldb_imag{};
+    typename LayoutC::Stride::Index ldc_real{};
+    typename LayoutC::Stride::Index ldc_imag{};
+    typename LayoutC::Stride::Index ldd_real{};
+    typename LayoutC::Stride::Index ldd_imag{};
 
     //
     // Methods
     //
-    
-    Arguments(): 
-      ptr_M(nullptr),
-      ptr_N(nullptr),
-      ptr_K(nullptr),
-      ptr_A_real(nullptr), 
-      ptr_A_imag(nullptr), 
-      ptr_B_real(nullptr), 
-      ptr_B_imag(nullptr), 
-      ptr_C_real(nullptr), 
-      ptr_C_imag(nullptr), 
-      ptr_D_real(nullptr),
-      ptr_D_imag(nullptr)
-    {}
+
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
       int const *ptr_M,
@@ -244,37 +232,37 @@
       LayoutA,
       LayoutB>;
 
     //
     // Data members
     //
 
-    typename Mma::IteratorA::Params params_A_real;
-    typename Mma::IteratorA::Params params_A_imag;
-    typename Mma::IteratorB::Params params_B_real;
-    typename Mma::IteratorB::Params params_B_imag;
-    typename Epilogue::OutputTileIterator::Params params_C_real;
-    typename Epilogue::OutputTileIterator::Params params_C_imag;
-    typename Epilogue::OutputTileIterator::Params params_D_real;
-    typename Epilogue::OutputTileIterator::Params params_D_imag;
-
-    typename EpilogueOutputOp::Params output_op;
-
-    int const *ptr_M;
-    int const *ptr_N;
-    int const *ptr_K;
-
-    void const * const * ptr_A_real;
-    void const * const * ptr_A_imag;
-    void const * const * ptr_B_real;
-    void const * const * ptr_B_imag;
-    void const * const * ptr_C_real;
-    void const * const * ptr_C_imag;
-    void * const * ptr_D_real;
-    void * const * ptr_D_imag;
+    typename Mma::IteratorA::Params params_A_real{};
+    typename Mma::IteratorA::Params params_A_imag{};
+    typename Mma::IteratorB::Params params_B_real{};
+    typename Mma::IteratorB::Params params_B_imag{};
+    typename Epilogue::OutputTileIterator::Params params_C_real{};
+    typename Epilogue::OutputTileIterator::Params params_C_imag{};
+    typename Epilogue::OutputTileIterator::Params params_D_real{};
+    typename Epilogue::OutputTileIterator::Params params_D_imag{};
+
+    typename EpilogueOutputOp::Params output_op{};
+
+    int const *ptr_M{nullptr};
+    int const *ptr_N{nullptr};
+    int const *ptr_K{nullptr};
+
+    void const * const * ptr_A_real{nullptr};
+    void const * const * ptr_A_imag{nullptr};
+    void const * const * ptr_B_real{nullptr};
+    void const * const * ptr_B_imag{nullptr};
+    void const * const * ptr_C_real{nullptr};
+    void const * const * ptr_C_imag{nullptr};
+    void * const * ptr_D_real{nullptr};
+    void * const * ptr_D_imag{nullptr};
 
     //
     // Host dispatch API
     //
 
     /// Default constructor
     Params() = default;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_streamk_with_fused_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_streamk_with_fused_epilogue.h`

 * *Files 2% similar despite different names*

```diff
@@ -25,15 +25,15 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Stream-K Gemm kernel compatible with fused epilogues 
+    \brief Stream-K Gemm kernel compatible with fused epilogues
     that broadcast a bias vector over the MMA output.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
@@ -61,15 +61,15 @@
   typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
   bool IsSingleSource = Epilogue_::kIsSingleSource
 >
 struct GemmStreamkWithFusedEpilogue;
 
 // GemmStreamkWithFusedEpilogue with two sources
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_    ///! Threadblock swizzling function
 >
 struct GemmStreamkWithFusedEpilogue<Mma_, Epilogue_, ThreadblockSwizzle_, false> {
   using Mma = Mma_;
   using Epilogue = Epilogue_;
   using EpilogueOutputOp = typename Epilogue::OutputOp;
@@ -122,63 +122,54 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_C1;
-    void const * ptr_C2;
-    void * ptr_D;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
+    GemmCoord problem_size{};
+    int batch_count{1};        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A{nullptr};
+    void const * ptr_B{nullptr};
+    void const * ptr_C1{nullptr};
+    void const * ptr_C2{nullptr};
+    void * ptr_D{nullptr};
 
     void * ptr_Vector;
     void * ptr_Tensor;
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C1;
-    int64_t batch_stride_C2;
-    int64_t batch_stride_D;
-    int64_t batch_stride_Vector;
-    int64_t batch_stride_Tensor;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc1;
-    typename LayoutC::Stride::Index ldc2;
-    typename LayoutC::Stride::Index ldd;
-    typename LayoutC::Stride::Index ldr;
-    typename LayoutC::Stride::Index ldt;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C1{0};
+    int64_t batch_stride_C2{0};
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_Vector{0};
+    int64_t batch_stride_Tensor{0};
+
+    typename LayoutA::Stride::Index lda{};
+    typename LayoutB::Stride::Index ldb{};
+    typename LayoutC::Stride::Index ldc1{};
+    typename LayoutC::Stride::Index ldc2{};
+    typename LayoutC::Stride::Index ldd{};
+    typename LayoutC::Stride::Index ldr{};
+    typename LayoutC::Stride::Index ldt{};
 
-    int avail_sms;          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
+    int avail_sms{-1};          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
 
 
     //
     // Methods
     //
-    
+
     /// Default Constructor
-    Arguments():
-      mode(GemmUniversalMode::kGemm),
-      batch_count(1),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C1(nullptr),
-      ptr_C2(nullptr),
-      ptr_D(nullptr),
-      avail_sms(-1)
-    {}
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_split,                              /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
       typename EpilogueOutputOp::Params epilogue,
@@ -204,22 +195,22 @@
       typename LayoutC::Stride::Index ldr,
       typename LayoutC::Stride::Index ldt,
       int avail_sms = -1)                           /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
     :
       mode(mode),
       problem_size(problem_size),
       batch_count(batch_split),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C1(ptr_C1), ptr_C2(ptr_C2), ptr_D(ptr_D), 
-      ptr_Vector(ptr_Vector), 
+      epilogue(epilogue),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C1(ptr_C1), ptr_C2(ptr_C2), ptr_D(ptr_D),
+      ptr_Vector(ptr_Vector),
       ptr_Tensor(ptr_Tensor),
-      batch_stride_A(batch_stride_A), 
-      batch_stride_B(batch_stride_B), 
-      batch_stride_C1(batch_stride_C1), 
-      batch_stride_C2(batch_stride_C2), 
+      batch_stride_A(batch_stride_A),
+      batch_stride_B(batch_stride_B),
+      batch_stride_C1(batch_stride_C1),
+      batch_stride_C2(batch_stride_C2),
       batch_stride_Vector(batch_stride_Vector),
       batch_stride_Tensor(batch_stride_Tensor),
       lda(lda), ldb(ldb), ldc1(ldc1), ldc2(ldc2), ldd(ldd), ldr(ldr), ldt(ldt), avail_sms(avail_sms)
     {
       CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Arguments::Arguments() - problem_size: " << problem_size);
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
@@ -247,50 +238,50 @@
   {
   public:
 
     //
     // Data members
     //
 
-    void * ptr_A;
-    void * ptr_B;
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
 
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
 
-    GemmUniversalMode mode;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
 
-    ThreadblockSwizzle block_mapping;
+    ThreadblockSwizzle block_mapping{};
 
-    void *barrier_workspace;
-    void *partials_workspace;
+    void *barrier_workspace{nullptr};
+    void *partials_workspace{nullptr};
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    void * ptr_C1;
-    void * ptr_C2;
-    void * ptr_D;
-    void * ptr_Tensor;
-    void * ptr_Vector;
+    void * ptr_C1{nullptr};
+    void * ptr_C2{nullptr};
+    void * ptr_D{nullptr};
+    void * ptr_Tensor{nullptr};
+    void * ptr_Vector{nullptr};
+
+    typename Epilogue::OutputTileIterator::Params params_C1{};
+    typename Epilogue::OutputTileIterator::Params params_C2{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::TensorTileIterator::Params params_Tensor{};
 
-    typename Epilogue::OutputTileIterator::Params params_C1;
-    typename Epilogue::OutputTileIterator::Params params_C2;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::TensorTileIterator::Params params_Tensor;
-
-    int64_t batch_stride_C1;
-    int64_t batch_stride_C2;
-    int64_t batch_stride_D;
-    int64_t batch_stride_Vector;
-    int64_t batch_stride_Tensor;
+    int64_t batch_stride_C1{0};
+    int64_t batch_stride_C2{0};
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_Vector{0};
+    int64_t batch_stride_Tensor{0};
 
-    typename LayoutC::Stride::Index ldr;
+    typename LayoutC::Stride::Index ldr{};
 
   protected:
 
     //
     // Host-only dispatch-utilities
     //
 
@@ -357,25 +348,25 @@
       batch_stride_C2(args.batch_stride_C2),
       batch_stride_D(args.batch_stride_D),
       batch_stride_Vector(args.batch_stride_Vector),
       batch_stride_Tensor(args.batch_stride_Tensor),
       barrier_workspace(nullptr),
       partials_workspace(nullptr)
     {
-      CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Params::Params() - problem_size: " << problem_size);
+      CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Params::Params()");
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << args.ldt);
-      CUTLASS_TRACE_HOST("  avail_sms: " << avail_sms);
 
       // Number of SMs to make available for StreamK decomposition
       int avail_sms = (args.avail_sms == -1) ?
                         device_sms :
                         fast_min(args.avail_sms, device_sms);
+      CUTLASS_TRACE_HOST("  avail_sms: " << avail_sms);
 
       // Initialize the block mapping structure
       block_mapping = ThreadblockSwizzle(
         args.mode,
         args.problem_size,
         {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
         args.batch_count,
@@ -400,15 +391,14 @@
     /// the memory allocated to workspace is at least as large as get_workspace_size().
     Status init_workspace(
       void *workspace,
       cudaStream_t stream = nullptr)
     {
       uint8_t *ptr = static_cast<uint8_t*>(workspace);
 
-
       // Establish partials workspace
       partials_workspace = nullptr;
       size_t partials_workspace_bytes = get_partials_workspace_size();
       if (partials_workspace_bytes > 0)
       {
         if (!workspace) {
           return Status::kErrorWorkspaceNull;
@@ -836,15 +826,15 @@
   {
     ElementC *ptr_C1 = static_cast<ElementC *>(params.ptr_C1);
     ElementC *ptr_C2 = static_cast<ElementC *>(params.ptr_C2);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     // Update pointers for batched/array mode(s)
     if (params.mode == GemmUniversalMode::kBatched) {
       ptr_C1 += tile_work.tiled_coord.k() * params.batch_stride_C1;
       if (ptr_C2) {
         ptr_C2 += tile_work.tiled_coord.k() * params.batch_stride_C2;
@@ -965,15 +955,15 @@
 
     ElementC *ptr_C1 = static_cast<ElementC *>(params.ptr_C1);
     ElementC *ptr_C2 = static_cast<ElementC *>(params.ptr_C2);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     // Tile iterator loading from residual1.
     typename Epilogue::OutputTileIterator iterator_C1(
         params.params_C1,
         ptr_C1,
         params.block_mapping.problem_size.mn(),
@@ -1252,15 +1242,15 @@
 
   }
 };
 
 
 // GemmStreamkWithFusedEpilogue with one source
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_    ///! Threadblock swizzling function
 >
 struct GemmStreamkWithFusedEpilogue<Mma_, Epilogue_, ThreadblockSwizzle_, true> {
   using Mma = Mma_;
   using Epilogue = Epilogue_;
   using EpilogueOutputOp = typename Epilogue::OutputOp;
@@ -1314,59 +1304,51 @@
   struct Arguments
   {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_C;
-    void * ptr_D;
-
-    void * ptr_Vector;
-    void * ptr_Tensor;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-    int64_t batch_stride_Vector;
-    int64_t batch_stride_Tensor;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc;
-    typename LayoutC::Stride::Index ldd;
-    typename LayoutC::Stride::Index ldr;
-    typename LayoutC::Stride::Index ldt;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
+    GemmCoord problem_size{};
+    int batch_count{1};        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A{nullptr};
+    void const * ptr_B{nullptr};
+    void const * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    void * ptr_Vector{nullptr};
+    void * ptr_Tensor{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_Vector{0};
+    int64_t batch_stride_Tensor{0};
+
+    typename LayoutA::Stride::Index lda{};
+    typename LayoutB::Stride::Index ldb{};
+    typename LayoutC::Stride::Index ldc{};
+    typename LayoutC::Stride::Index ldd{};
+    typename LayoutC::Stride::Index ldr{};
+    typename LayoutC::Stride::Index ldt{};
 
-    int avail_sms;          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
+    int avail_sms{-1};          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
 
 
     //
     // Methods
     //
-    
+
     /// Default Constructor
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm),
-      batch_count(1),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      avail_sms(-1)
-    {}
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_split,                              /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
       typename EpilogueOutputOp::Params epilogue,
@@ -1389,21 +1371,21 @@
       typename LayoutC::Stride::Index ldr,
       typename LayoutC::Stride::Index ldt,
       int avail_sms = -1)                           /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
     :
       mode(mode),
       problem_size(problem_size),
       batch_count(batch_split),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
-      ptr_Vector(ptr_Vector), 
+      epilogue(epilogue),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
+      ptr_Vector(ptr_Vector),
       ptr_Tensor(ptr_Tensor),
-      batch_stride_A(batch_stride_A), 
-      batch_stride_B(batch_stride_B), 
-      batch_stride_C(batch_stride_C), 
+      batch_stride_A(batch_stride_A),
+      batch_stride_B(batch_stride_B),
+      batch_stride_C(batch_stride_C),
       batch_stride_Vector(batch_stride_Vector),
       batch_stride_Tensor(batch_stride_Tensor),
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd), ldr(ldr), ldt(ldt), avail_sms(avail_sms)
     {
       CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Arguments::Arguments() - problem_size: " << problem_size);
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
@@ -1411,15 +1393,15 @@
       CUTLASS_TRACE_HOST("  ldt: " << this->ldt);
       CUTLASS_TRACE_HOST("  avail_sms: " << this->avail_sms);
     }
 
     /// Returns arguments for the transposed problem
     Arguments transposed_problem() const {
       Arguments args(*this);
-      
+
       std::swap(args.problem_size.m(), args.problem_size.n());
       std::swap(args.ptr_A, args.ptr_B);
       std::swap(args.lda, args.ldb);
       std::swap(args.batch_stride_A, args.batch_stride_B);
 
       return args;
     }
@@ -1432,48 +1414,47 @@
 
   public:
 
     //
     // Data members
     //
 
-    void * ptr_A;
-    void * ptr_B;
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
 
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
 
-    GemmUniversalMode mode;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
 
-    ThreadblockSwizzle block_mapping;
+    ThreadblockSwizzle block_mapping{};
 
-    void *barrier_workspace;
-    void *partials_workspace;
+    void *barrier_workspace{nullptr};
+    void *partials_workspace{nullptr};
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    void * ptr_C;
-    void * ptr_D;
-    void * ptr_Tensor;
-    void * ptr_Vector;
-
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::TensorTileIterator::Params params_Tensor;
+    void * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+    void * ptr_Tensor{nullptr};
+    void * ptr_Vector{nullptr};
 
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-    int64_t batch_stride_Vector;
-    int64_t batch_stride_Tensor;
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::TensorTileIterator::Params params_Tensor{};
 
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_Vector{0};
+    int64_t batch_stride_Tensor{0};
 
-    typename LayoutC::Stride::Index ldr;
+    typename LayoutC::Stride::Index ldr{};
 
   protected:
 
     //
     // Host-only dispatch-utilities
     //
 
@@ -1536,25 +1517,25 @@
       batch_stride_C(args.batch_stride_C),
       batch_stride_D(args.batch_stride_D),
       batch_stride_Vector(args.batch_stride_Vector),
       batch_stride_Tensor(args.batch_stride_Tensor),
       barrier_workspace(nullptr),
       partials_workspace(nullptr)
     {
-      CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Params::Params() - problem_size: " << problem_size);
+      CUTLASS_TRACE_HOST("GemmStreamkWithFusedEpilogue::Params::Params()");
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << args.ldt);
-      CUTLASS_TRACE_HOST("  avail_sms: " << avail_sms);
 
       // Number of SMs to make available for StreamK decomposition
       int avail_sms = (args.avail_sms == -1) ?
                         device_sms :
                         fast_min(args.avail_sms, device_sms);
+      CUTLASS_TRACE_HOST("  avail_sms: " << avail_sms);
 
       // Initialize the block mapping structure
       block_mapping = ThreadblockSwizzle(
         args.mode,
         args.problem_size,
         {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
         args.batch_count,
@@ -2014,15 +1995,15 @@
     AccumulatorTile &accumulator_tile)
   {
     ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     // Update pointers for batched/array mode(s)
     if (params.mode == GemmUniversalMode::kBatched) {
       ptr_C += tile_work.tiled_coord.k() * params.batch_stride_C;
       ptr_D += tile_work.tiled_coord.k() * params.batch_stride_D;
       if (ptr_Tensor) {
@@ -2127,15 +2108,15 @@
     );
 
     ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     // Tile iterator loading from source tensor.
     typename Epilogue::OutputTileIterator iterator_C(
         params.params_C,
         ptr_C,
         params.block_mapping.problem_size.mn(),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -26,15 +26,15 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief 
+    \brief
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 
 #include "cutlass/arch/arch.h"
@@ -173,16 +173,16 @@
       typename LayoutC::Stride stride_c,
       typename LayoutC::Stride stride_d,
       int const *ptr_gather_A_indices = nullptr,
       int const *ptr_gather_B_indices = nullptr,
       int const *ptr_scatter_D_indices = nullptr)
     :
       UniversalArgumentsBase(mode, problem_size, batch_count, batch_stride_D),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
+      epilogue(epilogue),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_C(batch_stride_C),
       stride_a(stride_a), stride_b(stride_b), stride_c(stride_c), stride_d(stride_d),
       ptr_gather_A_indices(ptr_gather_A_indices), ptr_gather_B_indices(ptr_gather_B_indices),
       ptr_scatter_D_indices(ptr_scatter_D_indices)
     {
       lda = 0;
       ldb = 0;
@@ -482,26 +482,26 @@
 
       return;
     }
 
     int offset_k = 0;
     int problem_size_k = params.problem_size.k();
 
-    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A); 
+    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A);
     ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
 
     //
     // Fetch pointers based on mode.
     //
-    if (params.mode == GemmUniversalMode::kGemm || 
+    if (params.mode == GemmUniversalMode::kGemm ||
       params.mode == GemmUniversalMode::kGemmSplitKParallel) {
 
       if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
 
-        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size;
       }
 
       offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
     }
     else if (params.mode == GemmUniversalMode::kBatched) {
       ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
       ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
@@ -562,18 +562,18 @@
     accumulators.clear();
 
     // Compute threadblock-scoped matrix multiply-add
     int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
     // Compute threadblock-scoped matrix multiply-add
     mma(
-      gemm_k_iterations, 
-      accumulators, 
-      iterator_A, 
-      iterator_B, 
+      gemm_k_iterations,
+      accumulators,
+      iterator_A,
+      iterator_B,
       accumulators);
 
     //
     // Epilogue
     //
 
     EpilogueOutputOp output_op(params.output_op);
@@ -588,29 +588,29 @@
     MatrixCoord threadblock_offset(
       threadblock_tile_offset.m() * Mma::Shape::kM,
       threadblock_tile_offset.n() * Mma::Shape::kN
     );
 
     int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
 
-    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C); 
+    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
 
     //
     // Fetch pointers based on mode.
     //
-    
+
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
     if (params.mode == GemmUniversalMode::kGemm) {
 
       // If performing a reduction via split-K, fetch the initial synchronization
       if (params.grid_tiled_shape.k() > 1) {
-        
+
         // Fetch the synchronization lock initially but do not block.
         semaphore.fetch();
 
         // Indicate which position in a serial reduction the output operator is currently updating
         output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
       }
     }
@@ -643,38 +643,38 @@
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset,
       params.ptr_scatter_D_indices
     );
 
     Epilogue epilogue(
-      shared_storage.epilogue, 
-      thread_idx, 
-      warp_idx, 
+      shared_storage.epilogue,
+      thread_idx,
+      warp_idx,
       lane_idx);
 
     // Wait on the semaphore - this latency may have been covered by iterator construction
     if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
-        
+
       // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
       if (threadblock_tile_offset.k()) {
         iterator_C = iterator_D;
       }
 
       semaphore.wait(threadblock_tile_offset.k());
     }
 
 
     // Execute the epilogue operator to update the destination tensor.
     epilogue(
-      output_op, 
-      iterator_D, 
-      accumulators, 
-      iterator_C); 
-    
+      output_op,
+      iterator_D,
+      accumulators,
+      iterator_C);
+
     //
     // Release the semaphore
     //
 
     if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
 
       int lock = 0;
@@ -683,15 +683,15 @@
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_offset.k() + 1;
       }
-      
+
       semaphore.release(lock);
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h`

 * *Files 2% similar despite different names*

```diff
@@ -118,57 +118,49 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride stride_a;
-    typename LayoutB::Stride stride_b;
-    typename LayoutC::Stride stride_c;
-    typename LayoutC::Stride stride_d;
-
-    typename LayoutA::Stride::LongIndex lda;
-    typename LayoutB::Stride::LongIndex ldb;
-    typename LayoutC::Stride::LongIndex ldc;
-    typename LayoutC::Stride::LongIndex ldd;
+    GemmUniversalMode mode = GemmUniversalMode::kGemm;
+    GemmCoord problem_size {};
+    int batch_count {1};        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A = nullptr;
+    void const * ptr_B = nullptr;
+    void const * ptr_C = nullptr;
+    void * ptr_D = nullptr;
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
+
+    typename LayoutA::Stride stride_a{0};
+    typename LayoutB::Stride stride_b{0};
+    typename LayoutC::Stride stride_c{0};
+    typename LayoutC::Stride stride_d{0};
+
+    typename LayoutA::Stride::LongIndex lda{0};
+    typename LayoutB::Stride::LongIndex ldb{0};
+    typename LayoutC::Stride::LongIndex ldc{0};
+    typename LayoutC::Stride::LongIndex ldd{0};
 
-    int avail_sms;          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
+    int avail_sms{-1};          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
 
 
     //
     // Methods
     //
 
     /// Default Constructor
-    Arguments():
-      mode(GemmUniversalMode::kGemm),
-      batch_count(1),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      avail_sms(-1)
-    {}
+    Arguments() = default;
 
     /// Constructor
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_split,                              /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
       typename EpilogueOutputOp::Params epilogue,
@@ -253,40 +245,40 @@
   {
   public:
 
     //
     // Data members
     //
 
-    void * ptr_A;
-    void * ptr_B;
+    void * ptr_A = nullptr;
+    void * ptr_B = nullptr;
 
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
 
-    GemmUniversalMode mode;
+    GemmUniversalMode mode = GemmUniversalMode::kGemm;
 
-    ThreadblockSwizzle block_mapping;
+    ThreadblockSwizzle block_mapping{};
 
-    void *barrier_workspace;
-    void *partials_workspace;
+    void *barrier_workspace = nullptr;
+    void *partials_workspace = nullptr;
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    void * ptr_D;
-    void * ptr_C;
+    void * ptr_D = nullptr;
+    void * ptr_C = nullptr;
 
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::Params params_C;
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::OutputTileIterator::Params params_C{};
 
-    int64_t batch_stride_D;
-    int64_t batch_stride_C;
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_C{0};
 
 
   protected:
 
     //
     // Host-only dispatch-utilities
     //
@@ -322,15 +314,14 @@
     //
     // Host dispatch API
     //
 
     /// Default constructor
     Params() = default;
 
-
     /// Constructor
     Params(
       Arguments const &args,  /// GEMM application arguments
       int device_sms,         /// Number of SMs on the device
       int sm_occupancy)       /// Kernel SM occupancy (in thread blocks)
     :
       params_A(args.lda ? make_Coord_with_padding<LayoutA::kStrideRank>(args.lda) : args.stride_a),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor_streamk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor_streamk.h`

 * *Files 1% similar despite different names*

```diff
@@ -125,43 +125,43 @@
   struct Params
   {
   public:
 
     //
     // Data members
     //
-    cute::Shape<int32_t,int32_t,int32_t> problem_shape;
+    cute::Shape<int32_t,int32_t,int32_t> problem_shape{};
 
-    void * ptr_A;
-    void * ptr_B;
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
 
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
 
-    GemmUniversalMode mode;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
 
-    ThreadblockSwizzle block_mapping;
+    ThreadblockSwizzle block_mapping{};
 
-    void *barrier_workspace;
-    void *partials_workspace;
+    void *barrier_workspace{nullptr};
+    void *partials_workspace{nullptr};
 
-    typename FusionCallbacks::Params output_op;
+    typename FusionCallbacks::Params output_op{};
 
 
-    void * ptr_D;
-    void * ptr_C;
+    void * ptr_D{nullptr};
+    void * ptr_C{nullptr};
 
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::Params params_C;
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename Epilogue::OutputTileIterator::Params params_C{};
 
-    int64_t batch_stride_D;
-    int64_t batch_stride_C;
+    int64_t batch_stride_D{0};
+    int64_t batch_stride_C{0};
 
 
   protected:
 
     //
     // Host-only dispatch-utilities
     //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h`

 * *Files 2% similar despite different names*

```diff
@@ -50,24 +50,24 @@
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
   bool IsSingleSource = Epilogue_::kIsSingleSource
 >
 struct GemmWithFusedEpilogue;
 
 // GemmWithFusedEpilogue with two sources
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_    ///! Threadblock swizzling function
 >
 struct GemmWithFusedEpilogue<Mma_, Epilogue_, ThreadblockSwizzle_, false> {
 public:
 
   using Mma = Mma_;
@@ -99,15 +99,15 @@
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   /// Split-K preserves splits that are 128b aligned
   static int const kSplitKAlignment = const_max(
-    128 / sizeof_bits<ElementA>::value, 
+    128 / sizeof_bits<ElementA>::value,
     128 / sizeof_bits<ElementB>::value
   );
 
   //
   // Structures
   //
 
@@ -143,16 +143,16 @@
     typename LayoutC::Stride::Index ldd;
     typename LayoutC::Stride::Index ldr;
     typename LayoutC::Stride::Index ldt;
 
     //
     // Methods
     //
-    
-    Arguments(): 
+
+    Arguments():
       ptr_A(nullptr),
       ptr_B(nullptr),
       ptr_C1(nullptr),
       ptr_C2(nullptr),
       ptr_D(nullptr)
     {}
 
@@ -181,37 +181,37 @@
       typename LayoutC::Stride::Index ldc1,
       typename LayoutC::Stride::Index ldc2,
       typename LayoutC::Stride::Index ldd,
       typename LayoutC::Stride::Index ldr,
       typename LayoutC::Stride::Index ldt)
     :
       UniversalArgumentsBase(mode, problem_size, batch_count, batch_stride_D),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C1(ptr_C1), ptr_C2(ptr_C2), ptr_D(ptr_D), 
-      ptr_Vector(ptr_Vector), 
+      epilogue(epilogue),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C1(ptr_C1), ptr_C2(ptr_C2), ptr_D(ptr_D),
+      ptr_Vector(ptr_Vector),
       ptr_Tensor(ptr_Tensor),
-      batch_stride_A(batch_stride_A), 
-      batch_stride_B(batch_stride_B), 
-      batch_stride_C1(batch_stride_C1), 
-      batch_stride_C2(batch_stride_C2), 
+      batch_stride_A(batch_stride_A),
+      batch_stride_B(batch_stride_B),
+      batch_stride_C1(batch_stride_C1),
+      batch_stride_C2(batch_stride_C2),
       batch_stride_Vector(batch_stride_Vector),
       batch_stride_Tensor(batch_stride_Tensor),
       lda(lda), ldb(ldb), ldc1(ldc1), ldc2(ldc2), ldd(ldd), ldr(ldr), ldt(ldt)
     {
       CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Arguments::Arguments() - problem_size: " << problem_size);
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << this->ldt);
     }
 
     /// Returns arguments for the transposed problem
     Arguments transposed_problem() const {
       Arguments args(*this);
-      
+
       std::swap(args.problem_size.m(), args.problem_size.n());
       std::swap(args.ptr_A, args.ptr_B);
       std::swap(args.lda, args.ldb);
       std::swap(args.batch_stride_A, args.batch_stride_B);
 
       return args;
     }
@@ -303,15 +303,15 @@
       batch_stride_A(args.batch_stride_A),
       batch_stride_B(args.batch_stride_B),
       batch_stride_C1(args.batch_stride_C1),
       batch_stride_C2(args.batch_stride_C2),
       batch_stride_Vector(args.batch_stride_Vector),
       batch_stride_Tensor(args.batch_stride_Tensor)
     {
-      CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Params::Params() - problem_size: " << problem_size);
+      CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Params::Params()");
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << args.ldt);
     }
 
     /// Lightweight update given a subset of arguments.
@@ -456,28 +456,28 @@
 
       return;
     }
 
     int offset_k = 0;
     int problem_size_k = params.problem_size.k();
 
-    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A); 
+    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A);
     ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
 
 
     #if SPLIT_K_ENABLED
     //
     // Fetch pointers based on mode.
     //
-    if (params.mode == GemmUniversalMode::kGemm || 
+    if (params.mode == GemmUniversalMode::kGemm ||
       params.mode == GemmUniversalMode::kGemmSplitKParallel) {
 
       if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
 
-        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size;
       }
 
       offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
     }
     else if (params.mode == GemmUniversalMode::kBatched) {
       ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
       ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
@@ -535,18 +535,18 @@
     accumulators.clear();
 
     // Compute threadblock-scoped matrix multiply-add
     int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
     // Compute threadblock-scoped matrix multiply-add
     mma(
-      gemm_k_iterations, 
-      accumulators, 
-      iterator_A, 
-      iterator_B, 
+      gemm_k_iterations,
+      accumulators,
+      iterator_A,
+      iterator_B,
       accumulators);
 
     //
     // Epilogue
     //
 
     EpilogueOutputOp output_op(params.output_op);
@@ -567,24 +567,24 @@
 
     ElementC *ptr_C1 = static_cast<ElementC *>(params.ptr_C1);
     ElementC *ptr_C2 = static_cast<ElementC *>(params.ptr_C2);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     //
     // Fetch pointers based on mode.
     //
-    
+
     //
     // Special path when split-K not enabled.
-    // 
+    //
 
     if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() == 1) {
 
       // Tile iterators loading from source tensors.
       typename Epilogue::OutputTileIterator iterator_C1(
         params.params_C1,
         ptr_C1,
@@ -617,17 +617,17 @@
           ptr_Tensor,
           params.problem_size.mn(),
           thread_idx,
           threadblock_offset);
 
       // Construct the epilogue
       Epilogue epilogue(
-        shared_storage.epilogue, 
-        thread_idx, 
-        warp_idx, 
+        shared_storage.epilogue,
+        thread_idx,
+        warp_idx,
         lane_idx);
 
       // Move to appropriate location for this output tile
       if (ptr_Vector) {
         ptr_Vector += threadblock_offset.column() + threadblock_tile_offset.m() * params.ldr;
       }
 
@@ -645,24 +645,24 @@
       return;
     }
 
     //
     // Slower path when split-K or batching is needed
     //
 
-      
+
     #if SPLIT_K_ENABLED
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
     if (params.mode == GemmUniversalMode::kGemm) {
 
       // If performing a reduction via split-K, fetch the initial synchronization
       if (params.grid_tiled_shape.k() > 1) {
-        
+
         // Fetch the synchronization lock initially but do not block.
         semaphore.fetch();
 
         // Indicate which position in a serial reduction the output operator is currently updating
         output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
       }
     }
@@ -735,23 +735,23 @@
             : ptr_Tensor,
         params.problem_size.mn(),
         thread_idx,
         threadblock_offset);
 
     // Construct the epilogue
     Epilogue epilogue(
-      shared_storage.epilogue, 
-      thread_idx, 
-      warp_idx, 
+      shared_storage.epilogue,
+      thread_idx,
+      warp_idx,
       lane_idx);
 
     #if SPLIT_K_ENABLED
     // Wait on the semaphore - this latency may have been covered by iterator construction
     if ((params.mode == GemmUniversalMode::kGemm) && params.grid_tiled_shape.k() > 1) {
-        
+
       // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
       if (threadblock_tile_offset.k()) {
         iterator_C1 = iterator_D;
       }
 
       semaphore.wait(threadblock_tile_offset.k());
 
@@ -779,36 +779,36 @@
              threadblock_offset);
 
     //
     // Release the semaphore
     //
 
     #if SPLIT_K_ENABLED
-    if ((params.mode == GemmUniversalMode::kGemm)  && params.grid_tiled_shape.k() > 1) { 
+    if ((params.mode == GemmUniversalMode::kGemm)  && params.grid_tiled_shape.k() > 1) {
 
       int lock = 0;
       if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
 
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_offset.k() + 1;
       }
-      
+
       semaphore.release(lock);
     }
     #endif
   }
 };
 
 // GemmWithFusedEpilogue with one source
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_    ///! Threadblock swizzling function
 >
 struct GemmWithFusedEpilogue<Mma_, Epilogue_, ThreadblockSwizzle_, true> {
 public:
 
   using Mma = Mma_;
@@ -840,15 +840,15 @@
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   /// Split-K preserves splits that are 128b aligned
   static int const kSplitKAlignment = const_max(
-    128 / sizeof_bits<ElementA>::value, 
+    128 / sizeof_bits<ElementA>::value,
     128 / sizeof_bits<ElementB>::value
   );
 
   //
   // Structures
   //
 
@@ -881,16 +881,16 @@
     typename LayoutC::Stride::Index ldd;
     typename LayoutC::Stride::Index ldr;
     typename LayoutC::Stride::Index ldt;
 
     //
     // Methods
     //
-    
-    Arguments(): 
+
+    Arguments():
       ptr_A(nullptr),
       ptr_B(nullptr),
       ptr_C(nullptr),
       ptr_D(nullptr)
     {}
 
     /// constructs an arguments structure
@@ -915,36 +915,36 @@
       typename LayoutB::Stride::Index ldb,
       typename LayoutC::Stride::Index ldc,
       typename LayoutC::Stride::Index ldd,
       typename LayoutC::Stride::Index ldr,
       typename LayoutC::Stride::Index ldt)
     :
       UniversalArgumentsBase(mode, problem_size, batch_count, batch_stride_D),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
-      ptr_Vector(ptr_Vector), 
+      epilogue(epilogue),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
+      ptr_Vector(ptr_Vector),
       ptr_Tensor(ptr_Tensor),
-      batch_stride_A(batch_stride_A), 
-      batch_stride_B(batch_stride_B), 
-      batch_stride_C(batch_stride_C), 
+      batch_stride_A(batch_stride_A),
+      batch_stride_B(batch_stride_B),
+      batch_stride_C(batch_stride_C),
       batch_stride_Vector(batch_stride_Vector),
       batch_stride_Tensor(batch_stride_Tensor),
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd), ldr(ldr), ldt(ldt)
     {
       CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Arguments::Arguments() - problem_size: " << problem_size);
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << this->ldt);
     }
 
     /// Returns arguments for the transposed problem
     Arguments transposed_problem() const {
       Arguments args(*this);
-      
+
       std::swap(args.problem_size.m(), args.problem_size.n());
       std::swap(args.ptr_A, args.ptr_B);
       std::swap(args.lda, args.ldb);
       std::swap(args.batch_stride_A, args.batch_stride_B);
 
       return args;
     }
@@ -1031,15 +1031,15 @@
       ptr_Tensor(args.ptr_Tensor),
       batch_stride_A(args.batch_stride_A),
       batch_stride_B(args.batch_stride_B),
       batch_stride_C(args.batch_stride_C),
       batch_stride_Vector(args.batch_stride_Vector),
       batch_stride_Tensor(args.batch_stride_Tensor)
     {
-      CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Params::Params() - problem_size: " << problem_size);
+      CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Params::Params()");
       CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << args.ldt);
     }
 
     /// Lightweight update given a subset of arguments.
@@ -1182,28 +1182,28 @@
 
       return;
     }
 
     int offset_k = 0;
     int problem_size_k = params.problem_size.k();
 
-    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A); 
+    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A);
     ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
 
 
     #if SPLIT_K_ENABLED
     //
     // Fetch pointers based on mode.
     //
-    if (params.mode == GemmUniversalMode::kGemm || 
+    if (params.mode == GemmUniversalMode::kGemm ||
       params.mode == GemmUniversalMode::kGemmSplitKParallel) {
 
       if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
 
-        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size;
       }
 
       offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
     }
     else if (params.mode == GemmUniversalMode::kBatched) {
       ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
       ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
@@ -1261,18 +1261,18 @@
     accumulators.clear();
 
     // Compute threadblock-scoped matrix multiply-add
     int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
     // Compute threadblock-scoped matrix multiply-add
     mma(
-      gemm_k_iterations, 
-      accumulators, 
-      iterator_A, 
-      iterator_B, 
+      gemm_k_iterations,
+      accumulators,
+      iterator_A,
+      iterator_B,
       accumulators);
 
     //
     // Epilogue
     //
 
     EpilogueOutputOp output_op(params.output_op);
@@ -1292,24 +1292,24 @@
     int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
 
     ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
     typename Epilogue::ElementTensor *ptr_Tensor = static_cast<typename Epilogue::ElementTensor *>(params.ptr_Tensor);
 
     // Define the reduction output pointer and move to the appropriate place
-    typename Epilogue::ElementVector *ptr_Vector = 
+    typename Epilogue::ElementVector *ptr_Vector =
       static_cast<typename Epilogue::ElementVector *>(params.ptr_Vector);
 
     //
     // Fetch pointers based on mode.
     //
-    
+
     //
     // Special path when split-K not enabled.
-    // 
+    //
 
     if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() == 1) {
 
       // Tile iterators loading from source tensors.
       typename Epilogue::OutputTileIterator iterator_C(
         params.params_C,
         ptr_C,
@@ -1334,17 +1334,17 @@
           ptr_Tensor,
           params.problem_size.mn(),
           thread_idx,
           threadblock_offset);
 
       // Construct the epilogue
       Epilogue epilogue(
-        shared_storage.epilogue, 
-        thread_idx, 
-        warp_idx, 
+        shared_storage.epilogue,
+        thread_idx,
+        warp_idx,
         lane_idx);
 
       // Move to appropriate location for this output tile
       if (ptr_Vector) {
         ptr_Vector += threadblock_offset.column() + threadblock_tile_offset.m() * params.ldr;
       }
 
@@ -1361,24 +1361,24 @@
       return;
     }
 
     //
     // Slower path when split-K or batching is needed
     //
 
-      
+
     #if SPLIT_K_ENABLED
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
     if (params.mode == GemmUniversalMode::kGemm) {
 
       // If performing a reduction via split-K, fetch the initial synchronization
       if (params.grid_tiled_shape.k() > 1) {
-        
+
         // Fetch the synchronization lock initially but do not block.
         semaphore.fetch();
 
         // Indicate which position in a serial reduction the output operator is currently updating
         output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
       }
     }
@@ -1437,23 +1437,23 @@
             : ptr_Tensor,
         params.problem_size.mn(),
         thread_idx,
         threadblock_offset);
 
     // Construct the epilogue
     Epilogue epilogue(
-      shared_storage.epilogue, 
-      thread_idx, 
-      warp_idx, 
+      shared_storage.epilogue,
+      thread_idx,
+      warp_idx,
       lane_idx);
 
     #if SPLIT_K_ENABLED
     // Wait on the semaphore - this latency may have been covered by iterator construction
     if ((params.mode == GemmUniversalMode::kGemm) && params.grid_tiled_shape.k() > 1) {
-        
+
       // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
       if (threadblock_tile_offset.k()) {
         iterator_C = iterator_D;
       }
 
       semaphore.wait(threadblock_tile_offset.k());
 
@@ -1480,27 +1480,27 @@
              threadblock_offset);
 
     //
     // Release the semaphore
     //
 
     #if SPLIT_K_ENABLED
-    if ((params.mode == GemmUniversalMode::kGemm)  && params.grid_tiled_shape.k() > 1) { 
+    if ((params.mode == GemmUniversalMode::kGemm)  && params.grid_tiled_shape.k() > 1) {
 
       int lock = 0;
       if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
 
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_offset.k() + 1;
       }
-      
+
       semaphore.release(lock);
     }
     #endif
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/params_sparse_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_sparse_base.h`

 * *Files 11% similar despite different names*

```diff
@@ -56,34 +56,32 @@
   typename TensorRefE>
 struct SparseParamsBase
 {
   //
   // Data members
   //
 
-  cutlass::gemm::GemmCoord problem_size;
-  cutlass::gemm::GemmCoord grid_tiled_shape;
+  cutlass::gemm::GemmCoord problem_size{};
+  cutlass::gemm::GemmCoord grid_tiled_shape{};
   int swizzle_log_tile;
-  ParamsA params_A;
-  TensorRefA ref_A;
-  ParamsB params_B;
-  TensorRefB ref_B;
-  ParamsE params_E;
-  TensorRefE ref_E;
-  int gemm_k_iterations;
-  int gemm_k_size;
+  ParamsA params_A{};
+  TensorRefA ref_A{};
+  ParamsB params_B{};
+  TensorRefB ref_B{};
+  ParamsE params_E{};
+  TensorRefE ref_E{};
+  int gemm_k_iterations{0};
+  int gemm_k_size{0};
 
   //
   // Host dispatch API
   //
 
   /// Default constructor
-  CUTLASS_HOST_DEVICE
-  SparseParamsBase() : swizzle_log_tile(0), gemm_k_iterations(0), gemm_k_size(0) { }
-
+  SparseParamsBase() = default;
 
   /// Constructor
   CUTLASS_HOST_DEVICE
   SparseParamsBase(
     cutlass::gemm::GemmCoord const & problem_size,
     cutlass::gemm::GemmCoord const & grid_tiled_shape,
     TensorRefA ref_A,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h`

 * *Files 2% similar despite different names*

```diff
@@ -50,44 +50,39 @@
 
 namespace util {
 
 template <class LayoutA, class LayoutB>
 CUTLASS_HOST_DEVICE
 static bool 
 is_continous_k_aligned(GemmCoord problem_size, size_t alignmentA, size_t alignmentB) {
-  return (std::is_same<LayoutA, layout::RowMajor>::value && (problem_size.k() % alignmentA) == 0) ||
-         (std::is_same<LayoutB, layout::ColumnMajor>::value && (problem_size.k() % alignmentB) == 0);
+  return (platform::is_same<LayoutA, layout::RowMajor>::value && (problem_size.k() % alignmentA) == 0) ||
+         (platform::is_same<LayoutB, layout::ColumnMajor>::value && (problem_size.k() % alignmentB) == 0);
 }
 
 }  // namespace util
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Argument structure
 struct UniversalArgumentsBase
 {
   //
   // Data members
   //
 
-  GemmUniversalMode mode;
-  GemmCoord problem_size;
-  int batch_count;
-
-  int64_t batch_stride_D;
+  GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+  GemmCoord problem_size{};
+  int batch_count{1};
+  int64_t batch_stride_D{0};
 
   //
   // Methods
   //
 
-  UniversalArgumentsBase() :
-    mode(GemmUniversalMode::kGemm),
-    batch_count(1),
-    batch_stride_D(0)
-  {}
+  UniversalArgumentsBase() = default;
 
   /// constructs an arguments structure
   UniversalArgumentsBase(
     GemmUniversalMode mode,
     GemmCoord problem_size,
     int batch_count,
     int64_t batch_stride_D)
@@ -113,35 +108,31 @@
   typename LayoutB>
 struct UniversalParamsBase
 {
   //
   // Data members
   //
 
-  GemmCoord problem_size;
-  GemmCoord grid_tiled_shape;
-  int swizzle_log_tile;
-
-  GemmUniversalMode mode;
-  int batch_count;
-  int gemm_k_size;
-
-  int64_t batch_stride_D;
-
-  int *semaphore;
+  GemmCoord problem_size{};
+  GemmCoord grid_tiled_shape{};
+  int swizzle_log_tile{0};
+  GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+  int batch_count {0};
+  int gemm_k_size {0};
+  int64_t batch_stride_D {0};
+  int *semaphore = nullptr;
 
 
   //
   // Host dispatch API
   //
 
   /// Default constructor
   UniversalParamsBase() = default;
 
-
   /// Constructor
   UniversalParamsBase(
     UniversalArgumentsBase const &args, /// GEMM application arguments
     int device_sms,                     /// Number of SMs on the device
     int sm_occupancy)                   /// Kernel SM occupancy (in thread blocks)
   :
     problem_size(args.problem_size),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h`

 * *Files 6% similar despite different names*

```diff
@@ -193,59 +193,42 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord *problem_sizes;
-    int problem_count;
-    int threadblock_count;
+    GemmUniversalMode mode = GemmUniversalMode::kGemm;
+    GemmCoord *problem_sizes = nullptr;
+    int problem_count{0};
+    int threadblock_count{0};
 
     typename EpilogueOutputOp::Params epilogue;
 
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    ElementA ** ptr_A = nullptr;
+    ElementB ** ptr_B = nullptr;
+    ElementC ** ptr_C = nullptr;
+    ElementC ** ptr_D = nullptr;
+
+    typename LayoutA::Stride::LongIndex *lda = nullptr;
+    typename LayoutB::Stride::LongIndex *ldb = nullptr;
+    typename LayoutC::Stride::LongIndex *ldc = nullptr;
+    typename LayoutC::Stride::LongIndex *ldd = nullptr;
 
     // Only used by device-level operator
-    GemmCoord *host_problem_sizes;
+    GemmCoord *host_problem_sizes = nullptr;
 
-    bool allow_early_exit;
+    bool allow_early_exit = false;
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments():
-      mode(GemmUniversalMode::kGemm),
-      problem_count(0),
-      threadblock_count(0),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr),
-      host_problem_sizes(nullptr),
-      allow_early_exit(false)
-    {
-
-    }
+    Arguments() = default;
 
     /// Ctor
     CUTLASS_HOST_DEVICE
     Arguments(
       GemmUniversalMode mode,
       GemmCoord *problem_sizes,
       int problem_count,
@@ -286,51 +269,39 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    typename ProblemVisitor::Params problem_visitor;
-    int threadblock_count;
+    typename ProblemVisitor::Params problem_visitor{};
+    int threadblock_count = 0;
 
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    GemmUniversalMode mode;
-    int batch_count;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    int batch_count = 0;
 
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
+    ElementA** ptr_A = nullptr;
+    ElementB** ptr_B = nullptr;
+    ElementC** ptr_C = nullptr;
+    ElementC** ptr_D = nullptr;
 
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    typename LayoutA::Stride::LongIndex* lda = nullptr;
+    typename LayoutB::Stride::LongIndex* ldb = nullptr;
+    typename LayoutC::Stride::LongIndex* ldc = nullptr;
+    typename LayoutC::Stride::LongIndex* ldd = nullptr;
 
-    bool allow_early_exit;
+    bool allow_early_exit = false;
 
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params():
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr),
-      allow_early_exit(false)
-    { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(Arguments const &args, void *workspace = nullptr, int tile_count = 0):
       problem_visitor(args.problem_sizes, args.problem_count, workspace, tile_count),
       threadblock_count(args.threadblock_count),
       output_op(args.epilogue),
       ptr_A(args.ptr_A),
@@ -376,16 +347,15 @@
 
 public:
 
   //
   // Methods
   //
 
-  CUTLASS_DEVICE
-  Rank2KGrouped() { }
+  Rank2KGrouped() = default;
 
   /// Determines whether kernel satisfies alignment
   static Status can_implement(cutlass::gemm::GemmCoord const & problem_size) {
     return Status::kSuccess;
   }
 
   static Status can_implement(Arguments const &args) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -115,46 +115,42 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc;
-    typename LayoutC::Stride::Index ldd;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    GemmCoord problem_size {};
+    int batch_count{1};
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A = nullptr;
+    void const * ptr_B = nullptr;
+    void const * ptr_C = nullptr;
+    void * ptr_D = nullptr;
+
+    int64_t batch_stride_A {0};
+    int64_t batch_stride_B {0};
+    int64_t batch_stride_C {0};
+    int64_t batch_stride_D {0};
+
+    typename LayoutA::Stride::Index lda{0};
+    typename LayoutB::Stride::Index ldb{0};
+    typename LayoutC::Stride::Index ldc{0};
+    typename LayoutC::Stride::Index ldd{0};
 
-    bool allow_early_exit;
+    bool allow_early_exit{false};
 
     //
     // Methods
     //
     
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm), 
-      batch_count(1), 
-      ptr_A(nullptr), ptr_B(nullptr), ptr_C(nullptr), ptr_D(nullptr),
-      allow_early_exit(false) { }
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
@@ -173,15 +169,16 @@
       bool allow_early_exit = false
     ):
       mode(mode), 
       problem_size(problem_size), 
       batch_count(batch_count),
       epilogue(epilogue), 
       ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
-      batch_stride_A(batch_stride_A), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
+      batch_stride_A(batch_stride_A), batch_stride_B(0),
+      batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd),
       allow_early_exit(allow_early_exit) {
 
       }
 
       /// Returns arguments for a the transposed problem
       Arguments transposed_problem() const {
@@ -199,75 +196,54 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
     
     // Mma1 Iterator A and B params
-    typename Mma1::IteratorA::Params params_A;
-    typename Mma1::IteratorB::Params params_BT;
+    typename Mma1::IteratorA::Params params_A{};
+    typename Mma1::IteratorB::Params params_BT{};
 
     // Mma2 Iterator A and B params 
-    typename Mma2::IteratorA::Params params_B;
-    typename Mma2::IteratorB::Params params_AT;
+    typename Mma2::IteratorA::Params params_B{};
+    typename Mma2::IteratorB::Params params_AT{};
 
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
     
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    GemmUniversalMode mode;
-    int batch_count;
-    int gemm_k_size;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    int batch_count{0};
+    int gemm_k_size{0};
 
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_C;
-    void * ptr_D;
+    void * ptr_A = nullptr;
+    void * ptr_B = nullptr;
+    void * ptr_C = nullptr;
+    void * ptr_D = nullptr;
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
 
-    int *semaphore;
+    int *semaphore = nullptr;
 
-    bool allow_early_exit;
+    bool allow_early_exit {false};
 
     //
     // Methods
     //
 
-    CUTLASS_HOST_DEVICE
-    Params():
-      swizzle_log_tile(0),
-      params_A(0),
-      params_BT(0),
-      params_B(0),
-      params_AT(0),
-      params_C(0),
-      params_D(0),
-      batch_count(0),
-      gemm_k_size(0),
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      batch_stride_A(0),
-      batch_stride_B(0),
-      batch_stride_C(0),
-      batch_stride_D(0),
-      semaphore(nullptr),
-      allow_early_exit(false) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       int gemm_k_size,
       void *workspace = nullptr
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -102,44 +102,40 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc;
-    typename LayoutC::Stride::Index ldd;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
+    GemmCoord problem_size{};
+    int batch_count{1};
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A{nullptr};
+    void const * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
+
+    typename LayoutA::Stride::Index lda{};
+    typename LayoutB::Stride::Index ldb{};
+    typename LayoutC::Stride::Index ldc{};
+    typename LayoutC::Stride::Index ldd{};
 
-    bool allow_early_exit;
+    bool allow_early_exit{false};
 
     //
     // Methods
     //
     
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm), 
-      batch_count(1), 
-      ptr_A(nullptr), ptr_C(nullptr), ptr_D(nullptr),
-      allow_early_exit(false) { }
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
@@ -156,81 +152,61 @@
     ):
       mode(mode), 
       problem_size(problem_size), 
       batch_count(batch_count),
       epilogue(epilogue), 
       ptr_A(ptr_A), ptr_C(ptr_C), ptr_D(ptr_D), 
       batch_stride_A(batch_stride_A), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
-      lda(lda), ldb(ldb), ldc(ldc), ldd(ldd),
+      lda(lda), ldb(0),
+      ldc(ldc), ldd(ldd),
       allow_early_exit(allow_early_exit) {
 
       }
 
   };
 
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
    
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    
-    typename EpilogueOutputOp::Params output_op;
-
-    GemmUniversalMode mode;
-    int batch_count;
-    int gemm_k_size;
-
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_C;
-    void * ptr_D;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
+    typename EpilogueOutputOp::Params output_op{};
+
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    int batch_count{0};
+    int gemm_k_size{0};
+
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
+    void * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
+    int *semaphore{nullptr};
 
-    int *semaphore;
-
-    bool allow_early_exit;
+    bool allow_early_exit{false};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params():
-      swizzle_log_tile(0),
-      params_A(0),
-      params_B(0),
-      params_C(0),
-      params_D(0),
-      batch_count(0),
-      gemm_k_size(0),
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      batch_stride_A(0),
-      batch_stride_B(0),
-      batch_stride_C(0),
-      batch_stride_D(0),
-      semaphore(nullptr),
-      allow_early_exit(false) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       int gemm_k_size,
       void *workspace = nullptr
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -112,18 +112,18 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -146,23 +146,24 @@
   static bool
   can_implement(Arguments const& args) {
     bool mode_implementable = args.mode == GemmUniversalMode::kGemm or
           (args.mode == GemmUniversalMode::kBatched && rank(ProblemShape{}) == 4);
     return mode_implementable && TileScheduler::can_implement(args.scheduler);
   }
 
-  static int
+  static size_t
   get_workspace_size(Arguments const& args) {
-    int workspace_size = 0;
+    size_t workspace_size = 0;
     return workspace_size;
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr, 
+    CudaHostAdapter* cuda_adapter = nullptr) {
     cutlass::Status status = Status::kSuccess;
 
     return status;
   }
 
   static dim3
   get_grid_shape(Params const& params) {
@@ -246,15 +247,14 @@
       gB,
       accumulators,
       k_tile_iter, k_tile_count,
       residue_mnk,
       thread_idx,
       smem_buf
     );
-
     // Epilogue and write to gD
     CollectiveEpilogue epilogue{params.epilogue};
     epilogue(
       problem_shape_MNKL,
       blk_shape,
       blk_coord_mnkl,
       accumulators,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_array_tma_warpspecialized_cooperative.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_array_tma_warpspecialized_cooperative.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -164,21 +164,21 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
-    KernelHardwareInfo hw_info;
-    TileSchedulerParams scheduler;
-    void* workspace;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerParams scheduler{};
+    void* workspace{nullptr};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -286,30 +286,31 @@
     workspace_size += CollectiveMainloop::get_workspace_size(args.problem_shape, args.mainloop, sm_count);
     workspace_size = round_nearest(workspace_size,  MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   static cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
     constexpr uint32_t NumEpilogueSubTiles = CollectiveEpilogue::get_store_pipe_increment(TileShape{});
 
     status = TileScheduler::template initialize_workspace<typename ProblemShape::UnderlyingProblemShape, ElementAccumulator>(
       args.scheduler, workspace_ptr + workspace_offset, stream, typename ProblemShape::UnderlyingProblemShape{}, args.hw_info, NumMmaWarpGroups, NumEpilogueSubTiles);
     workspace_offset += TileScheduler::template get_workspace_size<typename ProblemShape::UnderlyingProblemShape, ElementAccumulator>(
       args.scheduler, typename ProblemShape::UnderlyingProblemShape{}, args.hw_info, NumMmaWarpGroups, NumEpilogueSubTiles);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream);
+    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += CollectiveEpilogue::get_workspace_size(args.problem_shape, args.epilogue);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
 
     status = CollectiveMainloop::initialize_workspace(args.problem_shape, args.mainloop, workspace_ptr + workspace_offset, stream);
     workspace_offset += CollectiveMainloop::get_workspace_size(args.problem_shape, args.mainloop, args.hw_info.sm_count);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -137,18 +137,18 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -183,22 +183,23 @@
     implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
     implementable &= TileScheduler::can_implement(args.scheduler);
 
     return implementable;
   }
 
   static
-  int
+  size_t
   get_workspace_size(Arguments const& args) {
     return 0;
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return Status::kSuccess;
   }
 
   // Computes the kernel launch grid shape based on runtime parameters
   static dim3
   get_grid_shape(Params const& params) {
     auto cluster_shape = ClusterShape{};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_cooperative.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_cooperative.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -144,21 +144,21 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
-    KernelHardwareInfo hw_info;
-    TileSchedulerParams scheduler;
-    void* workspace;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerParams scheduler{};
+    void* workspace{nullptr};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -246,30 +246,31 @@
     workspace_size += CollectiveEpilogue::get_workspace_size(args.problem_shape, args.epilogue);
     workspace_size = round_nearest(workspace_size,  MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   static cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr, 
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
     constexpr uint32_t NumEpilogueSubTiles = CollectiveEpilogue::get_store_pipe_increment(TileShape{});
 
     status = TileScheduler::template initialize_workspace<ProblemShape, ElementAccumulator>(
       args.scheduler, workspace_ptr + workspace_offset, stream, args.problem_shape, args.hw_info, NumMmaWarpGroups, NumEpilogueSubTiles);
     workspace_offset += TileScheduler::template get_workspace_size<ProblemShape, ElementAccumulator>(
       args.scheduler, args.problem_shape, args.hw_info, NumMmaWarpGroups, NumEpilogueSubTiles);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream);
+    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += CollectiveEpilogue::get_workspace_size(args.problem_shape, args.epilogue);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_pingpong.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_pingpong.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -152,20 +152,20 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
-    KernelHardwareInfo hw_info;
-    TileSchedulerParams scheduler;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerParams scheduler{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -245,29 +245,30 @@
     workspace_size += CollectiveEpilogue::get_workspace_size(args.problem_shape, args.epilogue);
     workspace_size = round_nearest(workspace_size,  MinWorkspaceAlignment);
 
     return workspace_size;
   }
 
   static cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     Status status = Status::kSuccess;
     uint8_t* workspace_ptr = reinterpret_cast<uint8_t*>(workspace);
     size_t workspace_offset = 0;
 
     status = TileScheduler::template initialize_workspace<ProblemShape, ElementAccumulator>(
       args.scheduler, workspace_ptr + workspace_offset, stream, args.problem_shape, args.hw_info, NumMmaWarpGroups);
     workspace_offset += TileScheduler::template get_workspace_size<ProblemShape, ElementAccumulator>(
       args.scheduler, args.problem_shape, args.hw_info, NumMmaWarpGroups);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
-    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream);
+    status = CollectiveEpilogue::initialize_workspace(args.problem_shape, args.epilogue, workspace_ptr + workspace_offset, stream, cuda_adapter);
     workspace_offset += CollectiveEpilogue::get_workspace_size(args.problem_shape, args.epilogue);
     workspace_offset = round_nearest(workspace_offset,  MinWorkspaceAlignment);
     if (status != Status::kSuccess) {
       return status;
     }
 
     return status;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -141,18 +141,18 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -187,22 +187,23 @@
     implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
     implementable &= TileScheduler::can_implement(args.scheduler);
 
     return implementable;
   }
 
   static
-  int
+  size_t
   get_workspace_size(Arguments const& args) {
     return 0;
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return Status::kSuccess;
   }
 
   // Computes the kernel launch grid shape based on runtime parameters
   static dim3
   get_grid_shape(Params const& params) {
     auto cluster_shape = Shape<_1,_1,_1>{};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_cooperative.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_cooperative.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -65,15 +65,14 @@
 public:
   //
   // Type Aliases
   //
   using ProblemShape = ProblemShape_;
   static_assert(cute::rank(ProblemShape{}) == 3 or cute::rank(ProblemShape{}) == 4,
     "ProblemShape{} should be <M,N,K> or <M,N,K,L>");
-
   // Mainloop derived types
   using CollectiveMainloop = CollectiveMainloop_;
   using TileShape = typename CollectiveMainloop::TileShape;
   using TiledMma  = typename CollectiveMainloop::TiledMma;
   using ArchTag   = typename CollectiveMainloop::ArchTag;
   using ElementA  = typename CollectiveMainloop::ElementA;
   using StrideA   = typename CollectiveMainloop::StrideA;
@@ -142,20 +141,20 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
-    KernelHardwareInfo hw_info;
-    TileSchedulerParams scheduler;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerParams scheduler{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -209,24 +208,25 @@
     implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
     implementable &= TileScheduler::can_implement(args.scheduler);
 
     return implementable;
   }
 
   static
-  int
+  size_t
   get_workspace_size(Arguments const& args) {
     TileScheduler t;
     return t.template get_workspace_size<ProblemShape, ElementAccumulator>(
       args.scheduler, args.problem_shape, args.hw_info, NumMmaWarpGroups);
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     TileScheduler t;
     return t.template initialize_workspace<ProblemShape, ElementAccumulator>(
       args.scheduler, workspace, stream, args.problem_shape, args.hw_info, NumMmaWarpGroups);
   }
 
   // Computes the kernel launch grid shape based on runtime parameters
   static dim3
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_pingpong.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_pingpong.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -66,15 +66,14 @@
 public:
   //
   // Type Aliases
   //
   using ProblemShape = ProblemShape_;
   static_assert(cute::rank(ProblemShape{}) == 3 or cute::rank(ProblemShape{}) == 4,
     "ProblemShape{} should be <M,N,K> or <M,N,K,L>");
-
   // Mainloop derived types
   using CollectiveMainloop = CollectiveMainloop_;
   using TileShape = typename CollectiveMainloop::TileShape;
   using TiledMma  = typename CollectiveMainloop::TiledMma;
   using ArchTag   = typename CollectiveMainloop::ArchTag;
   using ElementA  = typename CollectiveMainloop::ElementA;
   using StrideA   = typename CollectiveMainloop::StrideA;
@@ -152,20 +151,20 @@
     EpilogueArguments epilogue{};
     KernelHardwareInfo hw_info{};
     TileSchedulerArguments scheduler{};
   };
 
   // Kernel entry point API
   struct Params {
-    GemmUniversalMode mode;
-    ProblemShape problem_shape;
-    MainloopParams mainloop;
-    EpilogueParams epilogue;
-    KernelHardwareInfo hw_info;
-    TileSchedulerParams scheduler;
+    GemmUniversalMode mode{};
+    ProblemShape problem_shape{};
+    MainloopParams mainloop{};
+    EpilogueParams epilogue{};
+    KernelHardwareInfo hw_info{};
+    TileSchedulerParams scheduler{};
   };
 
   //
   // Methods
   //
 
   // Convert to underlying arguments. In this case, a simple copy for the aliased type.
@@ -220,22 +219,23 @@
     implementable &= CollectiveEpilogue::can_implement(args.problem_shape, args.epilogue);
     implementable &= TileScheduler::can_implement(args.scheduler);
 
     return implementable;
   }
 
   static
-  int
+  size_t
   get_workspace_size(Arguments const& args) {
     return 0;
   }
 
   static
   cutlass::Status
-  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr) {
+  initialize_workspace(Arguments const& args, void* workspace = nullptr, cudaStream_t stream = nullptr,
+    CudaHostAdapter* cuda_adapter = nullptr) {
     return Status::kSuccess;
   }
 
   // Computes the kernel launch grid shape based on runtime parameters
   static dim3
   get_grid_shape(Params const& params) {
     // Given device SM count, set grid size s.t. we do not launch more thread blocks than we can run concurrently
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -54,19 +54,42 @@
   get_work_idx_m_and_n(
       uint64_t blk_per_grid_dim,
       FastDivmodU64Pow2 const& divmod_cluster_shape_major,
       FastDivmodU64Pow2 const& divmod_cluster_shape_minor,
       FastDivmodU64 const& divmod_cluster_blk_major,
       int32_t log_swizzle_size,
       RasterOrder raster_order) {
+    auto [cta_m_in_cluster, cta_n_in_cluster, _] = cute::block_id_in_cluster();
+    return get_work_idx_m_and_n(
+      blk_per_grid_dim,
+      divmod_cluster_shape_major,
+      divmod_cluster_shape_minor,
+      divmod_cluster_blk_major,
+      log_swizzle_size,
+      raster_order,
+      cta_m_in_cluster,
+      cta_n_in_cluster
+    );
+  }
+
+  static CUTLASS_DEVICE
+  cute::tuple<int32_t, int32_t>
+  get_work_idx_m_and_n(
+      uint64_t blk_per_grid_dim,
+      FastDivmodU64Pow2 const& divmod_cluster_shape_major,
+      FastDivmodU64Pow2 const& divmod_cluster_shape_minor,
+      FastDivmodU64 const& divmod_cluster_blk_major,
+      int32_t log_swizzle_size,
+      RasterOrder raster_order,
+      uint64_t cta_m_in_cluster,
+      uint64_t cta_n_in_cluster) {
 
     uint64_t cluster_id, cluster_major_offset = 0, cluster_minor_offset = 0;
     divmod_cluster_shape_major(cluster_id, cluster_major_offset, blk_per_grid_dim);
 
-    auto [cta_m_in_cluster, cta_n_in_cluster, _] = cute::block_id_in_cluster();
     if (raster_order == RasterOrder::AlongN) {
       cluster_minor_offset = cta_m_in_cluster;
     }
     else {
       cluster_minor_offset = cta_n_in_cluster;
     }
 
@@ -93,15 +116,15 @@
       return {major_work_idx, minor_work_idx};
     }
 
   }
 
   // The basic tile scheduler does not require any additional workspace
   template <class ProblemShape, class ElementAccumulator>
-  static int
+  static size_t
   get_workspace_size(Arguments const&, ProblemShape, KernelHardwareInfo const&, uint32_t, const uint32_t = 1) {
     return 0;
   }
 
   template <class ProblemShape, class ElementAccumulator>
   static cutlass::Status
   initialize_workspace(Arguments const&, void*, cudaStream_t, ProblemShape, KernelHardwareInfo const&,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_group.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_group.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -396,15 +396,15 @@
   static bool
   continue_current_work(WorkTileInfo&) {
     return false;
   }
 
   // The basic tile scheduler does not require any additional workspace
   template <class ProblemShape, class ElementAccumulator>
-  static int
+  static size_t
   get_workspace_size(Arguments const&, ProblemShape, KernelHardwareInfo const&, uint32_t, const uint32_t = 1) {
     return 0;
   }
 
   template <class ProblemShape, class ElementAccumulator>
   static cutlass::Status
   initialize_workspace(Arguments const&, void*, cudaStream_t, ProblemShape, KernelHardwareInfo const&,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_stream_k.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_stream_k.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -382,15 +382,16 @@
   CUTLASS_DEVICE
   static void
   fixup_helper(
     Params const& params,
     WorkTileInfo const& work_tile_info,
     FrgTensorC& accumulators,
     uint32_t num_barriers,
-    uint32_t barrier_idx) {
+    uint32_t barrier_idx,
+    uint32_t num_accumulator_mtxs = 1) {
 
     using ElementAccumulator = typename FrgTensorC::value_type;
 
     if (!requires_fixup(params, work_tile_info)) {
       return;
     }
     auto tile_idx = output_tile_index(params, work_tile_info);
@@ -408,15 +409,15 @@
       reduction_tile_idx *= Params::max_peers_per_tile(params.sk_units_, params.sk_tiles_);
       reduction_peer_offset = my_peer_id * cute::size<0>(TileShape{}) * cute::size<1>(TileShape{});
     }
 
     // Reductions use BlockStripedReduce with a width of BarrierManager::ThreadCount under the hood.
     // Thus, the start of the reduction space is the same across all threads in a warp group.
     int reduction_offset =
-      (cute::size<0>(TileShape{}) * cute::size<1>(TileShape{}) * reduction_tile_idx) +
+      (cute::size<0>(TileShape{}) * cute::size<1>(TileShape{}) * reduction_tile_idx * num_accumulator_mtxs) +
       reduction_peer_offset +
       (size(accumulators) * barrier_idx * BarrierManager::ThreadCount);
 
     ElementAccumulator* group_reduction_workspace = reinterpret_cast<ElementAccumulator*>(params.reduction_workspace_) + reduction_offset;
 
     using AccumulatorArrayT = Array<typename FrgTensorC::value_type, size(FrgTensorC{})>;
     using BlockStripedReduceT = BlockStripedReduce<BarrierManager::ThreadCount, AccumulatorArrayT>;
@@ -440,15 +441,15 @@
       reduction_tiles = params.sk_tiles_ * Params::max_peers_per_tile(params.sk_units_, params.sk_tiles_);
     }
     else {
       reduction_tiles = params.sk_tiles_;
     }
 
     auto reduction_workspace_size = Params::get_reduction_workspace_size(
-      reduction_tiles, to_gemm_coord(TileShape{}), sizeof_bits<ElementAccumulator>::value);
+      reduction_tiles, to_gemm_coord(TileShape{}), sizeof_bits<ElementAccumulator>::value, num_accumulator_mtxs);
     BarrierType* lock_workspace = reinterpret_cast<BarrierType*>(
       reinterpret_cast<uint8_t*>(params.reduction_workspace_) + reduction_workspace_size);
 
     if (work_tile_info.is_reduction_unit()) {
       plus<AccumulatorArrayT> add_fragments;
       auto peer_offset = size(accumulators) * num_barriers * BarrierManager::ThreadCount;
 
@@ -536,15 +537,15 @@
     );
 
     uint64_t tiles_mn = params.divmod_batch_.divisor;
     return tiles_mn * work_tile_info.L_idx + linear_idx_in_batch;
   }
 
   template <class ProblemShape, class ElementAccumulator>
-  static int
+  static size_t
   get_workspace_size(
     Arguments const& args,
     ProblemShape problem_shape,
     KernelHardwareInfo const& hw_info,
     uint32_t mma_warp_groups,
     const uint32_t epilogue_subtile = 1) {
 
@@ -832,15 +833,16 @@
 
     auto [work_idx_m, work_idx_n] = UnderlyingScheduler::get_work_idx_m_and_n(
                                           cta_per_grid_dim,
                                           params.divmod_cluster_shape_major_,
                                           params.divmod_cluster_shape_minor_,
                                           params.divmod_cluster_blk_major_,
                                           params.log_swizzle_size_,
-                                          params.raster_order_);
+                                          params.raster_order_
+                                        );
 
     // Set the M, N, and L block offsets
     work_tile_info.M_idx = work_idx_m;
     work_tile_info.N_idx = work_idx_n;
     work_tile_info.L_idx = static_cast<int32_t>(work_idx_l);
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_visitor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/static_tile_scheduler.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/static_tile_scheduler.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -330,16 +330,16 @@
       args.raster_order,
       /* truncate_by_problem_size = */true
     );
   }
 
   // Convert CTA-level work tile info to cluster-level tile coord
   CUTLASS_DEVICE
-  cute::Coord<int,int,int,int>
-  tile_info_to_coord_mnkl(WorkTileInfo work_tile_info) const {
+  auto
+  work_tile_to_cluster_coord_mnkl(WorkTileInfo work_tile_info) const {
     // TileScheduler works at CTA-level, kernel works at cluster-level
     int m_coord = idx2crd(work_tile_info.M_idx / scheduler_params.cluster_shape_m_,
                           scheduler_params.problem_tiles_m_);
     int n_coord = idx2crd(work_tile_info.N_idx / scheduler_params.cluster_shape_n_,
                           scheduler_params.problem_tiles_n_);
     int l_coord = idx2crd(work_tile_info.L_idx,
                           scheduler_params.problem_tiles_l_);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h`

 * *Files 6% similar despite different names*

```diff
@@ -115,43 +115,40 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc;
-    typename LayoutC::Stride::Index ldd;
+    GemmUniversalMode mode = GemmUniversalMode::kGemm;
+    GemmCoord problem_size{};
+    int batch_count{1};
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A{nullptr};
+    void const * ptr_B{nullptr};
+    void const * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_C{0};
+    int64_t batch_stride_D{0};
+
+    typename LayoutA::Stride::Index lda{0};
+    typename LayoutB::Stride::Index ldb{0};
+    typename LayoutC::Stride::Index ldc{0};
+    typename LayoutC::Stride::Index ldd{0};
 
     //
     // Methods
     //
     
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm), 
-      batch_count(1), 
-      ptr_A(nullptr), ptr_B(nullptr), ptr_C(nullptr), ptr_D(nullptr) { }
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
@@ -169,15 +166,16 @@
       typename LayoutC::Stride::Index ldd
     ):
       mode(mode), 
       problem_size(problem_size), 
       batch_count(batch_count),
       epilogue(epilogue), 
       ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
-      batch_stride_A(batch_stride_A), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
+      batch_stride_A(batch_stride_A), batch_stride_B(0),
+      batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd) {
 
       }
 
     /// Returns arguments for the transposed problem sizes
     Arguments transposed_problem_size() const {
       Arguments args(*this);
@@ -202,72 +200,51 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
     
     // Mma1 Iterator A and B params
-    typename Mma1::IteratorA::Params params_A_mma1;
-    typename Mma1::IteratorB::Params params_B_mma1;
+    typename Mma1::IteratorA::Params params_A_mma1{};
+    typename Mma1::IteratorB::Params params_B_mma1{};
 
     // Mma2 Iterator A and B params 
-    typename Mma2::IteratorA::Params params_A_mma2;
-    typename Mma2::IteratorB::Params params_B_mma2;
+    typename Mma2::IteratorA::Params params_A_mma2{};
+    typename Mma2::IteratorB::Params params_B_mma2{};
 
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
+    typename Epilogue::OutputTileIterator::Params params_C{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
     
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    GemmUniversalMode mode;
-    int batch_count;
-    int gemm_k_size;
-
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    int batch_count {0};
+    int gemm_k_size {0};
+
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
+    void * ptr_C{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A {0};
+    int64_t batch_stride_B {0};
+    int64_t batch_stride_C {0};
+    int64_t batch_stride_D {0};
 
-    int *semaphore;
+    int *semaphore{nullptr};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params():
-      swizzle_log_tile(0),
-      params_A_mma1(0),
-      params_B_mma1(0),
-      params_A_mma2(0),
-      params_B_mma2(0),
-      params_C(0),
-      params_D(0),
-      batch_count(0),
-      gemm_k_size(0),
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      batch_stride_A(0),
-      batch_stride_B(0),
-      batch_stride_C(0),
-      batch_stride_D(0),
-      semaphore(nullptr) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       int gemm_k_size,
       void *workspace = nullptr
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler_params.h`

 * *Files 3% similar despite different names*

```diff
@@ -31,24 +31,14 @@
 
 #pragma once
 
 /*! \file
     \brief Parameters structures for persistent tile schedulers
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #include "cutlass/coord.h"
 #include "cutlass/kernel_hardware_info.h"
 #include "cutlass/workspace.h"
 #include "cutlass/platform/platform.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm_coord.h"
 ////////////////////////////////////////////////////////////////////////////////
@@ -121,17 +111,17 @@
   initialize(
     dim3 problem_blocks,
     GemmCoord cluster_shape,
     KernelHardwareInfo const& hw_info,
     int max_swizzle_size,
     RasterOrderOptions raster_order_option
   ) {
-    
+
     CUTLASS_UNUSED(hw_info);
-    
+
     // Round up to nearest multiple of swizzle_size along each mode
     auto log_swizzle_size = get_log_swizzle_size(problem_blocks.x, problem_blocks.y, max_swizzle_size);
     auto problem_blocks_m = round_up(problem_blocks.x, (1 << log_swizzle_size) * cluster_shape.m());
     auto problem_blocks_n = round_up(problem_blocks.y, (1 << log_swizzle_size) * cluster_shape.n());
 
     problem_tiles_m_ = problem_blocks_m / cluster_shape.m();
     problem_tiles_n_ = problem_blocks_n / cluster_shape.n();
@@ -615,47 +605,37 @@
       cluster_shape,
       hw_info,
       max_swizzle,
       raster_order_option
     );
 
     uint64_t ctas_per_wave = grid.x * grid.y;
-
+    auto cluster_size = cluster_shape.m() * cluster_shape.n();
     // The number of output tiles to be computed in stream-K and data-parallel fashion, respectively.
-    uint32_t sk_tiles = get_num_sk_tiles(output_tiles, ctas_per_wave, k_tiles_per_output_tile, decomposition_mode);
+    uint32_t sk_tiles = get_num_sk_tiles(
+      output_tiles,
+      ctas_per_wave,
+      cluster_size,
+      k_tiles_per_output_tile,
+      decomposition_mode
+    );
     uint64_t dp_tiles = output_tiles - sk_tiles;
 
     // Calculate the number of work units covering the data-parallel and stream-K tiles.
     // A "work unit" is a single index in the linearized ID space used by the scheduler.
     // We distinguish it from a "block," which is typically tied to a hardware unit
     // (e.g., the callers into this scheduler will be persistent thread blocks).
     // A work unit can encompass multiple output tiles worth of work (as will be the
     // case for stream-K blocks).
     // Since splitting is not required for data-parallel tiles, only one data-parallel unit
     // is needed per data-parallel tile.
     uint64_t dp_units = dp_tiles;
 
-    // Number of k iterations computed by the stream-K units as a whole
-    uint64_t k_tiles_sk_total = k_tiles_per_output_tile * sk_tiles;
-
-    // If there are stream-K tiles to compute and a sufficiently large number of k iterations
-    // across them, they will be covered by a single wave of persistent threadblocks. Thus, there
-    // will be as many work units as there are threadblocks in a single wave.
-    //
-    // When the total k iterations across stream-K tiles is too small to justify distributing
-    // across an entire wave of blocks, we instead distribute the iterations over a smaller
-    // set of blocks.
-
-    // Calculate the number of stream-K units that would be needed if each stream-K unit
-    // computed the minimum allowable k iterations. Truncate this to be in units of clusters.
-    auto cluster_size = cluster_shape.m() * cluster_shape.n();
-    uint64_t min_sized_sk_units = (k_tiles_sk_total / min_iters_per_sk_unit_);
-    min_sized_sk_units = (min_sized_sk_units / cluster_size) * cluster_size;
-
-    uint64_t sk_units = platform::min(ctas_per_wave, min_sized_sk_units);
+    uint64_t ctas_per_sk_wave = ctas_per_wave;
+    uint64_t sk_units = get_num_sk_units(cluster_shape, ctas_per_sk_wave, sk_tiles, k_tiles_per_output_tile);
 
     if (decomposition_mode == DecompositionMode::DataParallel ||
         (decomposition_mode == DecompositionMode::Heuristic && sk_tiles == 0) ||
         sk_units == 0) {
       // Short circuit to basic data-parallel decomposition
       set_params_basic(
         underlying_params,
@@ -865,82 +845,100 @@
       /* truncate_by_problem_size = */false
     );
   }
 
   // Returns the number of stream-K tiles that will be computed amongst `output_tiles` total
   // output tiles on a device with `ctas_per_wave` CTAs in each wave.
   static uint32_t
-  get_num_sk_tiles(uint64_t output_tiles, uint64_t ctas_per_wave, uint32_t k_tiles_per_output_tile, DecompositionMode decomposition_mode) {
+  get_num_sk_tiles(
+    uint64_t output_tiles,
+    uint64_t ctas_per_wave,
+    uint64_t cluster_size,
+    uint32_t k_tiles_per_output_tile,
+    DecompositionMode decomposition_mode
+  ) {
     uint32_t full_waves = static_cast<uint32_t>(output_tiles / ctas_per_wave);
     uint32_t total_waves = static_cast<uint32_t>((output_tiles + ctas_per_wave - 1) / ctas_per_wave);
 
     if (decomposition_mode == DecompositionMode::DataParallel ||
         decomposition_mode == DecompositionMode::SplitK) {
       return 0;
     }
 
+    // If there is wave quantization, assign the first two waves worth of tiles to be
+    // covered by stream-K work and the remainder to be data-parallel. Since we know
+    // that full_waves == total_waves - 1 in this case, the number of data-parallel
+    // waves is simply full_waves-1 (unless full_waves == 0).
+    uint32_t dp_waves = full_waves > 1 ? full_waves - 1 : 0;
+    uint64_t dp_tiles = dp_waves * ctas_per_wave;
+    uint64_t sk_tiles = output_tiles - dp_tiles;
+
     if (decomposition_mode == DecompositionMode::Heuristic) {
       if (full_waves == total_waves || k_tiles_per_output_tile <= min_iters_per_sk_unit_) {
         // All tiles will be data-parallel tiles if there is either no quantization
         // or if there is no work to be split.
         return 0;
       }
 
       //
       // The final wave is not full. Perform some stream-K work.
       //
 
       // Rudimentary heuristic: prefer data-parallel decomposition if we have more than
       // one wave and the tail wave is more than half full. This is subject to change.
       uint64_t tail_tiles = output_tiles - (full_waves * ctas_per_wave);
-      if (tail_tiles >= (ctas_per_wave / 2)) {
+      if (2 * tail_tiles >= ctas_per_wave) {
         return 0;
       }
     }
 
-    // If there is wave quantization, assign the first two waves worth of tiles to be
-    // covered by stream-K work and the remainder to be data-parallel. Since we know
-    // that full_waves == total_waves - 1 in this case, the number of data-parallel
-    // waves is simply full_waves-1 (unless full_waves == 0).
-    uint32_t dp_waves = full_waves > 0 ? full_waves - 1 : 0;
-
-    uint64_t dp_tiles = dp_waves * ctas_per_wave;
-    return static_cast<uint32_t>(output_tiles - dp_tiles);
+    return static_cast<uint32_t>(sk_tiles);
   }
 
   CUTLASS_HOST_DEVICE
   static uint64_t
-  get_num_sk_units(GemmCoord cluster_shape, uint64_t ctas_per_wave, uint32_t sk_tiles, uint32_t k_tiles_per_output_tile) {
+  get_num_sk_units(GemmCoord cluster_shape, uint64_t ctas_per_sk_wave, uint32_t sk_tiles, uint32_t k_tiles_per_output_tile) {
+    // If there are stream-K tiles to compute and a sufficiently large number of k iterations
+    // across them, they will be covered by a single wave of persistent threadblocks. Thus, there
+    // will be as many work units as there are threadblocks in a single wave.
+    //
+    // When the total k iterations across stream-K tiles is too small to justify distributing
+    // across an entire wave of blocks, we instead distribute the iterations over a smaller
+    // set of blocks.
+
+    // Calculate the number of stream-K units that would be needed if each stream-K unit
+    // computed the minimum allowable k iterations. Truncate this to be in units of clusters.
+
     // Number of k iterations computed by the stream-K units as a whole
     uint64_t k_tiles_sk_total = k_tiles_per_output_tile * sk_tiles;
 
     // Calculate the number of stream-K units that would be needed if each stream-K unit
     // computed the minimum allowable k iterations. Truncate this to be in units of clusters.
     auto cluster_size = cluster_shape.m() * cluster_shape.n();
     uint64_t min_sized_sk_units = (k_tiles_sk_total / min_iters_per_sk_unit_);
     min_sized_sk_units = (min_sized_sk_units / cluster_size) * cluster_size;
 
-    uint64_t sk_units = platform::min(ctas_per_wave, min_sized_sk_units);
+    uint64_t sk_units = platform::min(ctas_per_sk_wave, min_sized_sk_units);
     return sk_units;
   }
 
   // Calculates the size of the workspace needed for holding reduction barriers
   CUTLASS_HOST_DEVICE
   static int
   get_barrier_workspace_size(uint64_t num_tiles, uint32_t mma_warp_groups, uint32_t barrier_bits) {
     auto workspace_bits = num_tiles * mma_warp_groups * barrier_bits;
     return round_up_to_l2_alignment(bits_to_bytes(static_cast<int>(workspace_bits)));
   }
 
   // Calculates the size of the workspace needed for holding partial outputs from splits
   CUTLASS_HOST_DEVICE
   static int
-  get_reduction_workspace_size(uint64_t num_tiles, GemmCoord tile_shape, uint32_t accumulator_bits) {
+  get_reduction_workspace_size(uint64_t num_tiles, GemmCoord tile_shape, uint32_t accumulator_bits, uint32_t num_accumulator_mtxs = 1) {
     auto output_tile_size = tile_shape.m() * tile_shape.n();
-    auto workspace_bits = accumulator_bits * output_tile_size * num_tiles;
+    auto workspace_bits = accumulator_bits * output_tile_size * num_tiles * num_accumulator_mtxs;
     return round_up_to_l2_alignment(bits_to_bytes(static_cast<int>(workspace_bits)));
   }
 
   #if !defined(__CUDACC_RTC__)
   static void
   get_workspace_component_sizes(
     dim3 problem_blocks,
@@ -953,15 +951,16 @@
     int splits,
     int max_swizzle,
     RasterOrderOptions raster_order_option,
     DecompositionMode decomposition_mode,
     uint32_t mma_warp_groups,
     uint32_t barrier_bits,
     uint32_t accumulator_bits,
-    uint32_t epilogue_subtile = 1) {
+    uint32_t epilogue_subtile = 1,
+    uint32_t num_accumulator_mtxs = 1) {
 
     auto log_swizzle_size = UnderlyingParams::get_log_swizzle_size(problem_blocks.x, problem_blocks.y, max_swizzle);
     problem_blocks.x = round_up(problem_blocks.x, (1 << log_swizzle_size) * cluster_shape.m());
     problem_blocks.y = round_up(problem_blocks.y, (1 << log_swizzle_size) * cluster_shape.n());
 
     // Workspace is needed only for output tiles that will be split. Thus, we first determine the number
     // of output tiles that will be split, and then calculate the workspace needed to cover these.
@@ -971,15 +970,15 @@
       barrier_workspace_size = 0;
       reduction_workspace_size = 0;
     }
     else if (decomposition_mode == DecompositionMode::SplitK ||
         (decomposition_mode == DecompositionMode::Heuristic && splits > 1)) {
       // Basic split-K variant requires workspace for all output tiles
       barrier_workspace_size = get_barrier_workspace_size(output_tiles, mma_warp_groups, barrier_bits);
-      reduction_workspace_size = get_reduction_workspace_size(output_tiles, tile_shape, accumulator_bits);
+      reduction_workspace_size = get_reduction_workspace_size(output_tiles, tile_shape, accumulator_bits, num_accumulator_mtxs);
     }
     else {
       KernelHardwareInfo new_hw_info;
       new_hw_info.device_id = hw_info.device_id;
       new_hw_info.sm_count = hw_info.sm_count;
       if (new_hw_info.sm_count <= 0) {
         CUTLASS_TRACE_HOST("  WARNING: Arguments do not include a valid SM count.\n"
@@ -991,16 +990,24 @@
         problem_blocks,
         cluster_shape,
         new_hw_info,
         max_swizzle,
         raster_order_option
       );
       uint64_t ctas_per_wave = grid.x * grid.y;
-      uint32_t sk_tiles = get_num_sk_tiles(output_tiles, ctas_per_wave, static_cast<uint32_t>(k_tiles_per_output_tile), decomposition_mode);
-      uint64_t sk_units = get_num_sk_units(cluster_shape, ctas_per_wave, sk_tiles, k_tiles_per_output_tile);
+      uint64_t cluster_size = cluster_shape.m() * cluster_shape.n();
+      uint32_t sk_tiles = get_num_sk_tiles(
+        output_tiles,
+        ctas_per_wave,
+        cluster_size,
+        static_cast<uint32_t>(k_tiles_per_output_tile),
+        decomposition_mode
+      );
+      uint64_t ctas_per_sk_wave = ctas_per_wave;
+      uint64_t sk_units = get_num_sk_units(cluster_shape, ctas_per_sk_wave, sk_tiles, k_tiles_per_output_tile);
       uint64_t dp_tiles = output_tiles - sk_tiles;
 
       uint64_t reduction_tiles = sk_tiles;
       if (should_perform_separate_reduction(epilogue_subtile, sk_units, sk_tiles, dp_tiles, ctas_per_wave)) {
         // In separate reduction, each peer writes to its own location in scratch space.
         // Thus, for separate reduction, we need as many reduction tiles per output tile
         // as there are the maximum number of peers that can collaborate on an output tile.
@@ -1008,15 +1015,15 @@
       }
 
       // Though separate reduction requires a larger reduction workspace, only one barrier
       // is needed per output tile. Each peer will increment the barrier by one once the peer has
       // written its accumulator to scratch space. The separate reduction unit will only begin
       // performing the reduction when the barrier has reached the number of peers for the output tile.
       barrier_workspace_size = get_barrier_workspace_size(sk_tiles, mma_warp_groups, barrier_bits);
-      reduction_workspace_size = get_reduction_workspace_size(reduction_tiles, tile_shape, accumulator_bits);
+      reduction_workspace_size = get_reduction_workspace_size(reduction_tiles, tile_shape, accumulator_bits, num_accumulator_mtxs);
     }
   }
   #endif // !defined(__CUDACC_RTC__)
 
   // Returns whether the kernel is configured in a manner for which separate reduction should be used
   CUTLASS_HOST_DEVICE
   static bool
@@ -1026,28 +1033,29 @@
     // multiple of sk_tiles, will choose basic split-k path instead of separate reduction for now.
     return (epilogue_subtile != 1) && (dp_tiles == 0) && (sk_units > 2u * sk_tiles) &&
            (sk_units + sk_tiles * epilogue_subtile <= ctas_per_wave);
   }
 
   // Get the amount of scratch workspace needed for the kernel. This variant of the method should only be used when
   // problem_shape and tile_shape contain modes of only rank 1.
-  static int
+  static size_t
   get_workspace_size(
     BatchedGemmCoord problem_shape,
     GemmCoord tile_shape,
     GemmCoord cluster_shape,
     KernelHardwareInfo const& hw_info,
     int splits,
     int max_swizzle,
     RasterOrderOptions raster_order_option,
     DecompositionMode decomposition_mode,
     uint32_t mma_warp_groups,
     uint32_t barrier_bits,
     uint32_t element_accumulator_bits,
-    uint32_t epilogue_subtile) {
+    uint32_t epilogue_subtile,
+    uint32_t num_accumulator_mtxs) {
 
     dim3 problem_blocks = UnderlyingParams::get_tiled_cta_shape_mnl(problem_shape, tile_shape, cluster_shape);
     uint32_t k_tiles_per_output_tile = (problem_shape.k() + tile_shape.k() - 1) / tile_shape.k();
 
     return get_workspace_size(
       problem_blocks,
       k_tiles_per_output_tile,
@@ -1057,36 +1065,38 @@
       splits,
       max_swizzle,
       raster_order_option,
       decomposition_mode,
       mma_warp_groups,
       barrier_bits,
       element_accumulator_bits,
-      epilogue_subtile
+      epilogue_subtile,
+      num_accumulator_mtxs
     );
   }
 
   // Version of get_workspace_size that takes in as input the number of CTAs in the M and N dimensions.
   // This is useful for calculating the tiled shape when a mode of problem and/or CTA shape has rank > 1,
   // for which using CuTe algebra for calculating tile shapes is easiest.
-  static int
+  static size_t
   get_workspace_size(
     dim3 problem_blocks,
     uint32_t k_tiles_per_output_tile,
     GemmCoord tile_shape,
     GemmCoord cluster_shape,
     KernelHardwareInfo const& hw_info,
     int splits,
     int max_swizzle,
     RasterOrderOptions raster_order_option,
     DecompositionMode decomposition_mode,
     uint32_t mma_warp_groups,
     uint32_t barrier_bits,
     uint32_t element_accumulator_bits,
-    uint32_t epilogue_subtile = 1) {
+    uint32_t epilogue_subtile = 1,
+    uint32_t num_accumulator_mtxs = 1) {
 
     int barrier_workspace_size = 0;
     int reduction_workspace_size = 0;
 
     #if !defined(__CUDACC_RTC__)
       get_workspace_component_sizes(
         problem_blocks,
@@ -1099,15 +1109,16 @@
         splits,
         max_swizzle,
         raster_order_option,
         decomposition_mode,
         mma_warp_groups,
         barrier_bits,
         element_accumulator_bits,
-        epilogue_subtile
+        epilogue_subtile,
+        num_accumulator_mtxs
       );
     #endif
 
     return barrier_workspace_size + reduction_workspace_size;
   }
 
   // Initialize the workspace to be used for the kernel. This variant of the method should only be used when
@@ -1166,15 +1177,16 @@
     int splits,
     int max_swizzle,
     RasterOrderOptions raster_order_option,
     DecompositionMode decomposition_mode,
     uint32_t mma_warp_groups,
     uint32_t barrier_bits,
     uint32_t element_accumulator_bits,
-    uint32_t epilogue_subtile = 1) {
+    uint32_t epilogue_subtile = 1,
+    uint32_t num_accumulator_mtxs = 1) {
 
     #if !defined(__CUDACC_RTC__)
       int barrier_workspace_size = 0;
       int reduction_workspace_size = 0;
 
       get_workspace_component_sizes(
         problem_blocks,
@@ -1187,15 +1199,16 @@
         splits,
         max_swizzle,
         raster_order_option,
         decomposition_mode,
         mma_warp_groups,
         barrier_bits,
         element_accumulator_bits,
-        epilogue_subtile
+        epilogue_subtile,
+        num_accumulator_mtxs
       );
 
       if (barrier_workspace_size > 0) {
         if (workspace == nullptr) {
           return Status::kErrorWorkspaceNull;
         }
 
@@ -1297,17 +1310,17 @@
     ProblemShape const* host_problem_shapes,
     GemmCoord cta_shape,
     GemmCoord cluster_shape,
     KernelHardwareInfo const& hw_info,
     int max_swizzle_size,
     RasterOrderOptions raster_order_option
   ) {
-    
+
     CUTLASS_UNUSED(hw_info);
-    
+
     // Round up to nearest multiple of swizzle_size along each mode
     auto log_swizzle_size = get_log_swizzle_size(problem_blocks.x, problem_blocks.y, max_swizzle_size);
     auto problem_blocks_m = round_up(problem_blocks.x, (1 << log_swizzle_size) * cluster_shape.m());
     auto problem_blocks_n = round_up(problem_blocks.y, (1 << log_swizzle_size) * cluster_shape.n());
 
     RasterOrder raster_order = get_rasterization_order(
       problem_blocks_m,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h`

 * *Files 3% similar despite different names*

```diff
@@ -106,40 +106,37 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_B;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldd;
+    GemmUniversalMode mode{GemmUniversalMode::kGemm};
+    GemmCoord problem_size{};
+    int batch_count{1};
+
+    typename EpilogueOutputOp::Params epilogue{};
+
+    void const * ptr_A{nullptr};
+    void const * ptr_B{nullptr};
+    void * ptr_D{nullptr};
+
+    int64_t batch_stride_A{0};
+    int64_t batch_stride_B{0};
+    int64_t batch_stride_D{0};
+
+    typename LayoutA::Stride::Index lda{0};
+    typename LayoutB::Stride::Index ldb{0};
+    typename LayoutC::Stride::Index ldd{0};
 
     //
     // Methods
     //
-    
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm), 
-      batch_count(1), 
-      ptr_A(nullptr), ptr_B(nullptr), ptr_D(nullptr) { }
+
+    Arguments() = default;
 
     /// constructs an arguments structure
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
       int batch_count,
       typename EpilogueOutputOp::Params epilogue,
@@ -157,15 +154,15 @@
       problem_size(problem_size),
       batch_count(batch_count),
       epilogue(epilogue), 
       ptr_A(ptr_A), ptr_B(ptr_B), ptr_D(ptr_D), 
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_D(batch_stride_D), 
       lda(lda), ldb(ldb), ldd(ldd) {
       }
-
+    
     /// Returns arguments for the transposed problem sizes
     Arguments transposed_problem_size() const {
       Arguments args(*this);
 
       std::swap(args.problem_size.m(), args.problem_size.n());
 
       return args;
@@ -186,58 +183,42 @@
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
+    cutlass::gemm::GemmCoord problem_size{};
+    cutlass::gemm::GemmCoord grid_tiled_shape{};
+    int swizzle_log_tile{0};
    
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Epilogue::OutputTileIterator::Params params_D;
+    typename Mma::IteratorA::Params params_A{};
+    typename Mma::IteratorB::Params params_B{};
+    typename Epilogue::OutputTileIterator::Params params_D{};
     
-    typename EpilogueOutputOp::Params output_op;
+    typename EpilogueOutputOp::Params output_op{};
 
-    GemmUniversalMode mode;
-    int batch_count;
-    int gemm_k_size;
+    GemmUniversalMode mode = cutlass::gemm::GemmUniversalMode::kGemm;
+    int batch_count {0};
+    int gemm_k_size {0};
 
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_D;
+    void * ptr_A{nullptr};
+    void * ptr_B{nullptr};
+    void * ptr_D{nullptr};
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_D;
+    int64_t batch_stride_A {0};
+    int64_t batch_stride_B {0};
+    int64_t batch_stride_D {0};
 
-    int *semaphore;
+    int *semaphore{nullptr};
 
     //
     // Methods
     //
-
-    CUTLASS_HOST_DEVICE
-    Params():
-      swizzle_log_tile(0),
-      params_A(0),
-      params_B(0),
-      params_D(0),
-      batch_count(0),
-      gemm_k_size(0),
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_D(nullptr),
-      batch_stride_A(0),
-      batch_stride_B(0),
-      batch_stride_D(0),
-      semaphore(nullptr) { }
+    Params() = default;
 
     CUTLASS_HOST_DEVICE
     Params(
       Arguments const &args,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       int gemm_k_size,
       void *workspace = nullptr
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h`

 * *Files 6% similar despite different names*

```diff
@@ -143,25 +143,23 @@
 
       CUTLASS_PRAGMA_UNROLL
       for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[n*Shape::kM/2 + m];
+            Array<half_t, 2> tmp { ptr_D[n*Shape::kM/2 + m] };
 
             mma(
                 tmp,
                 ptr_A[k*Shape::kM/2 + m],
                 ptr_B[n*Shape::kK + k],
                 tmp);
 
-            ptr_D[n*Shape::kM/2 + m] = ptr_tmp[0];
+            ptr_D[n*Shape::kM/2 + m] = tmp;
         }
       }
     }
   }
 };
 
 /////////////////////////////
@@ -235,29 +233,27 @@
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
           CUTLASS_PRAGMA_UNROLL
           for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[m*Shape::kN/2 + n];
+            Array<half_t, 2> tmp { ptr_D[m*Shape::kN/2 + n] };
 
             Array<half_t, 2> tmp_B;
             tmp_B[0] = ptr_B->at(2*n*Shape::kK + k);
             tmp_B[1] = ptr_B->at((2*n+1)*Shape::kK + k);
 
             mma(
                 tmp,
                 ptr_A[k*Shape::kM + m],
                 tmp_B,
                 tmp);
 
-            ptr_D[m*Shape::kN/2 + n] = ptr_tmp[0];
+            ptr_D[m*Shape::kN/2 + n] = tmp;
         }
       }
     }
   }
 };
 
 
@@ -331,26 +327,23 @@
 
         CUTLASS_PRAGMA_UNROLL
         for (int m = 0; m < Shape::kM / Mma::Shape::kM; ++m) {
 
           CUTLASS_PRAGMA_UNROLL
           for (int n = 0; n < Shape::kN / Mma::Shape::kN; ++n) {
 
-          Array<half_t, 2> tmp;
-          Array<half_t, 2> *ptr_tmp = &tmp;
-
-          ptr_tmp[0] = ptr_D[m + n * Shape::kM/2];
+          Array<half_t, 2> tmp { ptr_D[m + n * Shape::kM/2] };
 
           mma(
             tmp,
             ptr_A[m + k * Shape::kM/2],
             ptr_B[k * Shape::kN + n],
             tmp);
 
-          ptr_D[m + n * Shape::kM/2] = ptr_tmp[0];
+          ptr_D[m + n * Shape::kM/2] = tmp;
         }
       }
     }
   }
 };
 
 /////////////////////////////
@@ -424,25 +417,23 @@
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
           CUTLASS_PRAGMA_UNROLL
           for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[m*Shape::kN/2 + n];
+            Array<half_t, 2> tmp { ptr_D[m*Shape::kN/2 + n] };
 
             mma(
                 tmp,
                 ptr_A[k*Shape::kM + m],
                 ptr_B[k*Shape::kN/2 + n],
                 tmp);
 
-            ptr_D[m*Shape::kN/2 + n] = ptr_tmp[0];
+            ptr_D[m*Shape::kN/2 + n] = tmp;
         }
       }
     }
   }
 };
 
 
@@ -517,29 +508,27 @@
 
       CUTLASS_PRAGMA_UNROLL
       for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[n*Shape::kM/2 + m];
+            Array<half_t, 2> tmp { ptr_D[n*Shape::kM/2 + m] };
 
             Array<half_t, 2> tmp_A;
             tmp_A[0] = ptr_A->at(2*m*Shape::kK + k);
             tmp_A[1] = ptr_A->at((2*m+1)*Shape::kK + k);
 
             mma(
                 tmp,
                 tmp_A,
                 ptr_B[n*Shape::kK + k],
                 tmp);
 
-            ptr_D[n*Shape::kM/2 + m] = ptr_tmp[0];
+            ptr_D[n*Shape::kM/2 + m] = tmp;
         }
       }
     }
   }
 };
 
 /////////////////////////////
@@ -613,29 +602,27 @@
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
           CUTLASS_PRAGMA_UNROLL
           for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[m*Shape::kN/2 + n];
+            Array<half_t, 2> tmp { ptr_D[m*Shape::kN/2 + n] };
 
             Array<half_t, 2> tmp_B;
             tmp_B[0] = ptr_B->at(2*n*Shape::kK + k);
             tmp_B[1] = ptr_B->at((2*n+1)*Shape::kK + k);
 
             mma(
                 tmp,
                 ptr_A[m*Shape::kK + k],
                 tmp_B,
                 tmp);
 
-            ptr_D[m*Shape::kN/2 + n] = ptr_tmp[0];
+            ptr_D[m*Shape::kN/2 + n] = tmp;
         }
       }
     }
   }
 };
 
 /////////////////////////////
@@ -709,29 +696,27 @@
 
       CUTLASS_PRAGMA_UNROLL
       for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[n*Shape::kM/2 + m];
+            Array<half_t, 2> tmp { ptr_D[n*Shape::kM/2 + m] };
 
             Array<half_t, 2> tmp_A;
             tmp_A[0] = ptr_A->at(2*m*Shape::kK + k);
             tmp_A[1] = ptr_A->at((2*m+1)*Shape::kK + k);
 
             mma(
                 tmp,
                 tmp_A,
                 ptr_B[k*Shape::kN + n],
                 tmp);
 
-            ptr_D[n*Shape::kM/2 + m] = ptr_tmp[0];
+            ptr_D[n*Shape::kM/2 + m] = tmp;
         }
       }
     }
   }
 };
 
 
@@ -806,25 +791,23 @@
 
         CUTLASS_PRAGMA_UNROLL
         for(auto n=0; n < Shape::kN / Mma::Shape::kN; n++){
 
           CUTLASS_PRAGMA_UNROLL
           for(auto m=0; m < Shape::kM / Mma::Shape::kM; m++){
 
-            Array<half_t, 2> tmp;
-            Array<half_t, 2> *ptr_tmp = &tmp;
-            ptr_tmp[0] = ptr_D[m*Shape::kN/2 + n];
+            Array<half_t, 2> tmp { ptr_D[m*Shape::kN/2 + n] };
 
             mma(
                 tmp,
                 ptr_A[m*Shape::kK + k],
                 ptr_B[k*Shape::kN/2 + n],
                 tmp);
 
-            ptr_D[m*Shape::kN/2 + n] = ptr_tmp[0];
+            ptr_D[m*Shape::kN/2 + n] = tmp;
         }
       }
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h`

 * *Files 9% similar despite different names*

```diff
@@ -121,35 +121,52 @@
 
   /// Size of a threadblock-scoped access
   static int const kAccessSizeInBits = 128;
 
   /// Default Operator
   using Operator = Operator_;
 
+  // Warp thread arrangement
+  static int const kWarpThreadArrangementContiguousA =
+      platform::min(Shape::kM / (kAccessSizeInBits / sizeof_bits<ElementA>::value), 8);
+
+  static int const kWarpThreadArrangementStridedA =
+      kWarpSize / kWarpThreadArrangementContiguousA;
+
+  static int const kWarpThreadArrangementContiguousB =
+      platform::min(Shape::kN / (kAccessSizeInBits / sizeof_bits<ElementB>::value), 8);
+
+  static int const kWarpThreadArrangementStridedB =
+      kWarpSize / kWarpThreadArrangementContiguousB;
+
   //
   // Shared memory layouts
   //
-
+  static int const Crosswise_A = platform::min(int(128 / sizeof(ElementA)),
+                                               Shape::kM);
   using SmemLayoutA = 
     layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementA>::value, int(128 / sizeof(ElementA))>;
+      sizeof_bits<ElementA>::value, Crosswise_A>;
 
   // Shared memory layout
+  static int const Crosswise_B = platform::min(int(128 / sizeof(ElementB)),
+                                               Shape::kN);
   using SmemLayoutB = layout::RowMajorTensorOpMultiplicandCongruous<
-    sizeof_bits<ElementB>::value, int(128 / sizeof(ElementB))>;
+    sizeof_bits<ElementB>::value, Crosswise_B>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
     layout::PitchLinearShape<Shape::kM, Shape::kK>,
     kThreads,
-    layout::PitchLinearShape<8, 4>,
+    layout::PitchLinearShape<kWarpThreadArrangementContiguousA,
+                             kWarpThreadArrangementStridedA>,
     kAccessSizeInBits / sizeof_bits<ElementA>::value
   >;
 
   /// Shared memory iterator to A operand
   using SmemIteratorA = transform::threadblock::RegularTileIterator<
     MatrixShape<Shape::kM, Shape::kK>, 
     ElementA, 
@@ -158,15 +175,16 @@
     IteratorThreadMapA
   >;
 
   /// ThreadMap of iterator B
   using IteratorThreadMapB = transform::PitchLinearWarpRakedThreadMap<
     layout::PitchLinearShape<Shape::kN, Shape::kK>,
     kThreads,
-    layout::PitchLinearShape<8, 4>,
+    layout::PitchLinearShape<kWarpThreadArrangementContiguousB,
+                             kWarpThreadArrangementStridedB>,
     kAccessSizeInBits / sizeof_bits<ElementB>::value
   >;
 
   /// Shared memory iterator to B operand
   using SmemIteratorB = transform::threadblock::RegularTileIterator<
     MatrixShape<Shape::kK, Shape::kN>, 
     ElementB, 
@@ -410,24 +428,33 @@
   // Warp thread arrangement 
   static int const kWarpThreadArrangementContiguousA =
       Shape::kK / (kAccessSizeInBits / sizeof_bits<ElementA>::value);
 
   static int const kWarpThreadArrangementStridedA =
       kWarpSize / kWarpThreadArrangementContiguousA;
 
+  static int const kWarpThreadArrangementContiguousB =
+      platform::min(Shape::kN / (kAccessSizeInBits / sizeof_bits<ElementB>::value), 8);
+
+  static int const kWarpThreadArrangementStridedB =
+      kWarpSize / kWarpThreadArrangementContiguousB;
+
   //
   // Shared memory layouts
   //
 
   using SmemLayoutA = layout::RowMajorTensorOpMultiplicandCrosswise<
       sizeof_bits<ElementA>::value, Shape::kK>;
 
   // Shared memory layout
+  static int const Crosswise_B = platform::min(int(128 / sizeof(ElementB)),
+                                               Shape::kN);
+
   using SmemLayoutB = layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementB>::value, int(128 / sizeof(ElementB))>;
+      sizeof_bits<ElementB>::value, Crosswise_B>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
@@ -445,15 +472,16 @@
     IteratorThreadMapA
   >;
 
   /// ThreadMap of iterator B
   using IteratorThreadMapB = transform::PitchLinearWarpRakedThreadMap<
     layout::PitchLinearShape<Shape::kN, Shape::kK>,
     kThreads,
-    layout::PitchLinearShape<8, 4>,
+    layout::PitchLinearShape<kWarpThreadArrangementContiguousB,
+                             kWarpThreadArrangementStridedB>,
     kAccessSizeInBits / sizeof_bits<ElementB>::value
   >;
 
   /// Shared memory iterator to B operand
   using SmemIteratorB = transform::threadblock::RegularTileIterator<
     MatrixShape<Shape::kK, Shape::kN>, 
     ElementB, 
@@ -541,39 +569,47 @@
   /// Size of a threadblock-scoped access
   static int const kAccessSizeInBits = 128;
 
   /// Default Operator
   using Operator = Operator_; 
 
   // Warp thread arrangement 
+  static int const kWarpThreadArrangementContiguousA =
+      platform::min(Shape::kM / (kAccessSizeInBits / sizeof_bits<ElementA>::value), 8);
+
+  static int const kWarpThreadArrangementStridedA =
+      kWarpSize / kWarpThreadArrangementContiguousA;
+
   static int const kWarpThreadArrangementContiguousB =
       Shape::kK / (kAccessSizeInBits / sizeof_bits<ElementA>::value);
 
   static int const kWarpThreadArrangementStridedB =
       kWarpSize / kWarpThreadArrangementContiguousB;
 
   //
   // Shared memory layouts
   //
-
+  static int const Crosswise_A = platform::min(int(128 / sizeof(ElementA)),
+                                               Shape::kM);
   using SmemLayoutA = layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementA>::value, int(128 / sizeof(ElementA))>;
+      sizeof_bits<ElementA>::value, Crosswise_A>;
 
   // Shared memory layout
   using SmemLayoutB = layout::ColumnMajorTensorOpMultiplicandCrosswise<
       sizeof_bits<ElementB>::value, Shape::kK>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
       layout::PitchLinearShape<Shape::kM, Shape::kK>, kThreads,
-      layout::PitchLinearShape<8, 4>,
+      layout::PitchLinearShape<kWarpThreadArrangementContiguousA,
+                               kWarpThreadArrangementStridedA>,
       kAccessSizeInBits / sizeof_bits<ElementA>::value>;
 
   /// Shared memory iterator to A operand
   using SmemIteratorA = transform::threadblock::RegularTileIterator<
       MatrixShape<Shape::kM, Shape::kK>, ElementA, SmemLayoutA, 1,
       IteratorThreadMapA>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h`

 * *Files 1% similar despite different names*

```diff
@@ -1281,44 +1281,62 @@
 
   /// Size of a threadblock-scoped access
   static int const kAccessSizeInBits = 128;
 
   /// Default Operator
   using Operator = Operator_;
 
+  // Warp thread arrangement
+  static int const kWarpThreadArrangementContiguousA =
+      platform::min(Shape::kM / (kAccessSizeInBits / sizeof_bits<ElementA>::value), 8);
+
+  static int const kWarpThreadArrangementStridedA =
+      kWarpSize / kWarpThreadArrangementContiguousA;
+
+  static int const kWarpThreadArrangementContiguousB =
+      platform::min(Shape::kN / (kAccessSizeInBits / sizeof_bits<ElementB>::value), 8);
+
+  static int const kWarpThreadArrangementStridedB =
+      kWarpSize / kWarpThreadArrangementContiguousB;
+
   //
   // Shared memory layouts
   //
-
+  static int const Crosswise_A = platform::min(int(128 / sizeof(ElementA)),
+                                               Shape::kM);
   using SmemLayoutA = layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementA>::value, int(128 / sizeof(ElementA))>;
+      sizeof_bits<ElementA>::value, Crosswise_A>;
 
   // Shared memory layout
+  static int const Crosswise_B = platform::min(int(128 / sizeof(ElementB)),
+                                               Shape::kN);
   using SmemLayoutB = layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementB>::value, int(128 / sizeof(ElementB))>;
+      sizeof_bits<ElementB>::value, Crosswise_B>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
       layout::PitchLinearShape<Shape::kM, Shape::kK>, kThreads,
-      layout::PitchLinearShape<8, 4>,
+      layout::PitchLinearShape<kWarpThreadArrangementContiguousA,
+                               kWarpThreadArrangementStridedA>,
       kAccessSizeInBits / sizeof_bits<ElementA>::value>;
 
   /// Shared memory iterator to A operand
   using SmemIteratorA = transform::threadblock::RegularTileAccessIterator<
       MatrixShape<Shape::kM, Shape::kK>, ElementA, SmemLayoutA, 1,
       IteratorThreadMapA>;
 
   /// ThreadMap of iterator B
   using IteratorThreadMapB = transform::PitchLinearWarpRakedThreadMap<
       layout::PitchLinearShape<Shape::kN, Shape::kK>, kThreads,
-      layout::PitchLinearShape<8, 4>,
+      layout::PitchLinearShape<kWarpThreadArrangementContiguousB,
+                               kWarpThreadArrangementStridedB>,
       kAccessSizeInBits / sizeof_bits<ElementB>::value>;
 
   /// Shared memory iterator to B operand
   using SmemIteratorB = transform::threadblock::RegularTileAccessIterator<
       MatrixShape<Shape::kK, Shape::kN>, ElementB, SmemLayoutB, 0,
       IteratorThreadMapB>;
 
@@ -1545,39 +1563,47 @@
   /// Size of a threadblock-scoped access
   static int const kAccessSizeInBits = 128;
 
   /// Default Operator
   using Operator = Operator_;
 
   // Warp thread arrangement
+  static int const kWarpThreadArrangementContiguousA =
+      platform::min(Shape::kM / (kAccessSizeInBits / sizeof_bits<ElementA>::value), 8);
+
+  static int const kWarpThreadArrangementStridedA =
+      kWarpSize / kWarpThreadArrangementContiguousA;
+
   static int const kWarpThreadArrangementContiguousB =
       Shape::kK / (kAccessSizeInBits / sizeof_bits<ElementA>::value);
 
   static int const kWarpThreadArrangementStridedB =
       kWarpSize / kWarpThreadArrangementContiguousB;
 
   //
   // Shared memory layouts
   //
-
+  static int const Crosswise_A = platform::min(int(128 / sizeof(ElementA)),
+                                               Shape::kM);
   using SmemLayoutA = layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementA>::value, int(128 / sizeof(ElementA))>;
+      sizeof_bits<ElementA>::value, Crosswise_A>;
 
   // Shared memory layout
   using SmemLayoutB = layout::ColumnMajorTensorOpMultiplicandCrosswise<
       sizeof_bits<ElementB>::value, Shape::kK>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
       layout::PitchLinearShape<Shape::kM, Shape::kK>, kThreads,
-      layout::PitchLinearShape<8, 4>,
+      layout::PitchLinearShape<kWarpThreadArrangementContiguousA,
+                               kWarpThreadArrangementStridedA>,
       kAccessSizeInBits / sizeof_bits<ElementA>::value>;
 
   /// Shared memory iterator to A operand
   using SmemIteratorA = transform::threadblock::RegularTileAccessIterator<
       MatrixShape<Shape::kM, Shape::kK>, ElementA, SmemLayoutA, 1,
       IteratorThreadMapA>;
 
@@ -1682,24 +1708,32 @@
   // Warp thread arrangement
   static int const kWarpThreadArrangementContiguousA =
       Shape::kK / (kAccessSizeInBits / sizeof_bits<ElementA>::value);
 
   static int const kWarpThreadArrangementStridedA =
       kWarpSize / kWarpThreadArrangementContiguousA;
 
+  static int const kWarpThreadArrangementContiguousB =
+      platform::min(Shape::kN / (kAccessSizeInBits / sizeof_bits<ElementB>::value), 8);
+
+  static int const kWarpThreadArrangementStridedB =
+      kWarpSize / kWarpThreadArrangementContiguousB;
+
   //
   // Shared memory layouts
   //
 
   using SmemLayoutA = layout::RowMajorTensorOpMultiplicandCrosswise<
       sizeof_bits<ElementA>::value, Shape::kK>;
 
   // Shared memory layout
+  static int const Crosswise_B = platform::min(int(128 / sizeof(ElementB)),
+                                               Shape::kN);
   using SmemLayoutB = layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<ElementB>::value, int(128 / sizeof(ElementB))>;
+      sizeof_bits<ElementB>::value, Crosswise_B>;
 
   //
   // Iterators to write to shared memory
   //
 
   /// ThreadMap of iterator A
   using IteratorThreadMapA = transform::PitchLinearWarpRakedThreadMap<
@@ -1712,15 +1746,16 @@
   using SmemIteratorA = transform::threadblock::RegularTileAccessIterator<
       MatrixShape<Shape::kM, Shape::kK>, ElementA, SmemLayoutA, 0,
       IteratorThreadMapA>;
 
   /// ThreadMap of iterator B
   using IteratorThreadMapB = transform::PitchLinearWarpRakedThreadMap<
       layout::PitchLinearShape<Shape::kN, Shape::kK>, kThreads,
-      layout::PitchLinearShape<8, 4>,
+      layout::PitchLinearShape<kWarpThreadArrangementContiguousB,
+                               kWarpThreadArrangementStridedB>,
       kAccessSizeInBits / sizeof_bits<ElementB>::value>;
 
   /// Shared memory iterator to B operand
   using SmemIteratorB = transform::threadblock::RegularTileAccessIterator<
       MatrixShape<Shape::kK, Shape::kN>, ElementB, SmemLayoutB, 0,
       IteratorThreadMapB>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h`

 * *Files 8% similar despite different names*

```diff
@@ -25,31 +25,27 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Template for a pipelined softmax-GEMM kernel.
+    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/arch/arch.h"
 
 #include "cutlass/layout/matrix.h"
-#include "cutlass/gemm/threadblock/default_mma_core.h"
-#include "cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h"
-#include "cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h"
-#include "cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h"
-#include "cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h"
-#include "cutlass/gemm/warp/scale_bias_tile_iterator.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
+#include "cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h"
+#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
@@ -64,64 +60,57 @@
     int kAlignmentA,
     /// Element type for B matrix operand
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
     /// Access granularity of B matrix in units of elements
     int kAlignmentB,
-    /// Element type for Scale/Bias vectors
-    typename ElementScaleBias,
-    /// Layout type for Scale/Bias vectors
-    typename LayoutScaleBias,
     /// Element type for internal accumulation
     typename ElementAccumulator,
     /// Layout type for C and D matrix operands
     typename LayoutC,
     /// Operator class tag
     typename OperatorClass,
+    ///                                                                                               
+    bool ReduceKForA_,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape,
     /// Number of stages used in the pipelined mainloop
     int Stages,
-    /// Whether problem has been transformed. This determines to which operand
-    /// the softmax is applied.
-    bool InternalTranspose,
     /// Operation perfomed by GEMM
     typename Operator,
     /// Store the accumulators in row major or column major.  Row major is used
     /// when output layout is interleaved.
     bool AccumulatorsInRowMajor = false,
     /// Use zfill or predicate for SM80 out-of-bound cp.async 
     SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone
     >
-struct DefaultMmaSoftmaxMainloopFusion {
+struct DefaultMmaWithReduction {
 
   static cutlass::arch::CacheOperation::Kind const CacheOpA =
       ((sizeof_bits<ElementA>::value * kAlignmentA) == 128)
           ? cutlass::arch::CacheOperation::Global
           : cutlass::arch::CacheOperation::Always;
 
   static cutlass::arch::CacheOperation::Kind const CacheOpB =
       ((sizeof_bits<ElementB>::value * kAlignmentB) == 128)
           ? cutlass::arch::CacheOperation::Global
           : cutlass::arch::CacheOperation::Always;
 
-  static cutlass::arch::CacheOperation::Kind const CacheOpGammaBeta = CacheOpA;
-
   // Define the MmaCore components
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaWithReductionCore<
       ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
       ElementB, LayoutB, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
-      Stages, Operator, false, CacheOpA, CacheOpB>;
+      ReduceKForA_,  Stages, Operator, false, CacheOpA, CacheOpB>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
   using AccessTypeA = cutlass::Array<ElementA, kAlignmentA>;
   using IteratorA =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
@@ -131,28 +120,20 @@
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
   using AccessTypeB = cutlass::Array<ElementB, kAlignmentB>;
   using IteratorB =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
           ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
 
-  /// Define iterators over tiles from scale/bias vectors
-  using IteratorNormSum =
-      cutlass::transform::threadblock::PredicatedScaleBiasVectorIterator<
-          cutlass::MatrixShape<1, WarpShape::kN>,
-          ElementScaleBias,
-          LayoutScaleBias>;
-
   // Define the threadblock-scoped multistage matrix multiply
-  using ThreadblockMma = cutlass::gemm::threadblock::MmaSoftmaxMainloopFusionMultistage<
+  using ThreadblockMma = cutlass::gemm::threadblock::MmaWithReductionMultistage<
       typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
       MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
-      MmaCore::kCacheOpB, IteratorNormSum,
-      ElementAccumulator, layout::RowMajor,
-      typename MmaCore::MmaPolicy, Stages, InternalTranspose, SharedMemoryClear>;
+      MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
+      typename MmaCore::MmaPolicy, Stages, SharedMemoryClear>;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
 } // namespace gemm
 } // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h`

 * *Files 16% similar despite different names*

```diff
@@ -24,118 +24,136 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
+    \brief Template for a multistage GEMM kernel. Does not compute batching or support split-K.
 */
 
 #pragma once
 
+#include "cutlass/arch/arch.h"
 #include "cutlass/cutlass.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
 #include "cutlass/numeric_types.h"
-#include "cutlass/arch/arch.h"
-
-#include "cutlass/layout/matrix.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
-#include "cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h"
-#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
+#include "cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <
     /// Element type for A matrix operand
+    typename ElementA_,
+    /// Layout type for A matrix operand
+    typename LayoutA_,
+    /// Element type for B matrix operand
+    typename ElementB_,
+    /// Layout type for B matrix operand
+    typename LayoutB_,
+    /// Element type for internal accumulation
+    typename ElementAccumulator_,
+    /// Layout type for C and D matrix operands
+    typename LayoutC_,
+    /// Operator class tag
+    typename OperatorClass_,
+    /// Tag indicating architecture to tune for
+    typename ArchTag_,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape_,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape_,
+    /// Instruction-level tile size (concept: GemmShape)
+    typename InstructionShape_,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// Complex transformation on operand A
+    ComplexTransform TransformA = ComplexTransform::kNone,
+    /// Complex transformation on operand B
+    ComplexTransform TransformB = ComplexTransform::kNone,
+    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
+    typename Operator = arch::OpMultiplyAddComplex,
+    /// Store the accumulators in row major or column major.  Row major is used
+    /// when output layout is interleaved.
+    bool AccumulatorsInRowMajor = false>
+struct DefaultMultistageMmaComplex;
+
+////////////////////////////////////////////////////////////////////////////////
+
+/// Specialization for row-major output
+template <
+    /// Element type for A matrix operand
     typename ElementA,
     /// Layout type for A matrix operand
     typename LayoutA,
-    /// Access granularity of A matrix in units of elements
-    int kAlignmentA,
     /// Element type for B matrix operand
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
-    /// Access granularity of B matrix in units of elements
-    int kAlignmentB,
     /// Element type for internal accumulation
     typename ElementAccumulator,
-    /// Layout type for C and D matrix operands
-    typename LayoutC,
-    /// Operator class tag
+    /// Tag indicating architecture to tune for
     typename OperatorClass,
-    ///                                                                                               
-    bool ReduceKForA_,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape,
-    /// Number of stages used in the pipelined mainloop
+    /// Number of stages used in the multistage mainloop
     int Stages,
-    /// Operation perfomed by GEMM
-    typename Operator,
-    /// Store the accumulators in row major or column major.  Row major is used
-    /// when output layout is interleaved.
-    bool AccumulatorsInRowMajor = false,
-    /// Use zfill or predicate for SM80 out-of-bound cp.async 
-    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone
-    >
-struct DefaultMmaWithReduction {
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpA =
-      ((sizeof_bits<ElementA>::value * kAlignmentA) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpB =
-      ((sizeof_bits<ElementB>::value * kAlignmentB) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
+    /// Complex transformation on operand A
+    ComplexTransform TransformA,
+    /// Complex transformation on operand B
+    ComplexTransform TransformB,
+    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
+    typename Operator>
+struct DefaultMultistageMmaComplex<ElementA, LayoutA, ElementB, LayoutB,
+                            ElementAccumulator, layout::RowMajor, OperatorClass,
+                            ArchTag, ThreadblockShape, WarpShape,
+                            InstructionShape, Stages, TransformA, TransformB, Operator> {
   // Define the MmaCore components
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaWithReductionCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
-      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
-      ReduceKForA_,  Stages, Operator, false, CacheOpA, CacheOpB>;
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMultistageMmaComplexCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA, 
+      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, OperatorClass,
+      Stages, TransformA, TransformB, Operator>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using AccessTypeA = cutlass::Array<ElementA, kAlignmentA>;
+  using AccessTypeA = cutlass::Array<ElementA, ThreadMapA::kElementsPerAccess>;
   using IteratorA =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
           ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::Array<ElementB, kAlignmentB>;
+  using AccessTypeB = cutlass::Array<ElementB, ThreadMapB::kElementsPerAccess>;
   using IteratorB =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
           ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
 
   // Define the threadblock-scoped multistage matrix multiply
-  using ThreadblockMma = cutlass::gemm::threadblock::MmaWithReductionMultistage<
+  using ThreadblockMma = cutlass::gemm::threadblock::MmaMultistage<
       typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
       MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
       MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
-      typename MmaCore::MmaPolicy, Stages, SharedMemoryClear>;
+      typename MmaCore::MmaPolicy, Stages>;
 };
 
-////////////////////////////////////////////////////////////////////////////////
-
-} // namespace threadblock
-} // namespace gemm
-} // namespace cutlass 
+}  // namespace threadblock
+}  // namespace gemm
+}  // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h`

 * *Files 24% similar despite different names*

```diff
@@ -24,136 +24,185 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
-    \brief Template for a multistage GEMM kernel. Does not compute batching or support split-K.
+    \brief Template for a double-buffered threadblock-scoped GEMM kernel.
 */
 
 #pragma once
 
-#include "cutlass/arch/arch.h"
+#include "cutlass/aligned_buffer.h"
+#include "cutlass/arch/memory.h"
+#include "cutlass/array.h"
 #include "cutlass/cutlass.h"
-#include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/matrix_shape.h"
 #include "cutlass/numeric_types.h"
-#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
-#include "cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
+/// Structure to compute the matrix product targeting CUDA cores and SIMT math
+/// instructions.
 template <
-    /// Element type for A matrix operand
-    typename ElementA_,
-    /// Layout type for A matrix operand
-    typename LayoutA_,
-    /// Element type for B matrix operand
-    typename ElementB_,
-    /// Layout type for B matrix operand
-    typename LayoutB_,
-    /// Element type for internal accumulation
-    typename ElementAccumulator_,
-    /// Layout type for C and D matrix operands
-    typename LayoutC_,
-    /// Operator class tag
-    typename OperatorClass_,
-    /// Tag indicating architecture to tune for
-    typename ArchTag_,
-    /// Threadblock-level tile size (concept: GemmShape)
-    typename ThreadblockShape_,
-    /// Warp-level tile size (concept: GemmShape)
-    typename WarpShape_,
-    /// Instruction-level tile size (concept: GemmShape)
-    typename InstructionShape_,
-    /// Number of stages used in the pipelined mainloop
+    /// Size of the Gemm problem - concept: gemm::GemmShape<>
+    typename Shape_,
+    /// Policy describing tuning details (concept: MmaPolicy)
+    typename Policy_,
+    /// Number of stages,
     int Stages,
-    /// Complex transformation on operand A
-    ComplexTransform TransformA = ComplexTransform::kNone,
-    /// Complex transformation on operand B
-    ComplexTransform TransformB = ComplexTransform::kNone,
-    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
-    typename Operator = arch::OpMultiplyAddComplex,
-    /// Store the accumulators in row major or column major.  Row major is used
-    /// when output layout is interleaved.
-    bool AccumulatorsInRowMajor = false>
-struct DefaultMultistageMmaComplex;
-
-////////////////////////////////////////////////////////////////////////////////
+    /// Used for partial specialization
+    typename Enable = bool>
+class MmaPlanarComplexBase {
+ public:
+  ///< Size of the Gemm problem - concept: gemm::GemmShape<>
+  using Shape = Shape_;
+
+  ///< Policy describing tuning details
+  using Policy = Policy_;
+
+  //
+  // Dependent types
+  //
+
+  /// Warp-level Mma
+  using Operator = typename Policy::Operator;
+
+  /// Shape describing the overall GEMM computed from shared memory
+  /// by each warp.
+  using WarpGemm = typename Policy::Operator::Shape;
+
+  /// Shape describing the number of warps filling the CTA
+  using WarpCount = GemmShape<Shape::kM / WarpGemm::kM,
+                              Shape::kN / WarpGemm::kN,
+                              Shape::kK / WarpGemm::kK>;
+
+  /// Number of warp-level GEMM oeprations
+  static int const kWarpGemmIterations =
+      (WarpGemm::kK / Operator::Policy::MmaShape::kK);
+
+  /// Number of stages
+  static int const kStages = Stages;
+
+  /// Tensor reference to the A operand
+  using TensorRefA = TensorRef<typename Operator::ElementA, typename Operator::LayoutA>;
+
+  /// Tensor reference to the B operand
+  using TensorRefB = TensorRef<typename Operator::ElementB, typename Operator::LayoutB>;
+
+  //
+  // Nested structs
+  //
+
+  /// Shared storage object needed by threadblock-scoped GEMM
+  class SharedStorage {
+   public:
+    //
+    // Type definitions
+    //
+
+    /// Shape of the A matrix operand in shared memory
+    using ShapeA = MatrixShape<Shape::kM + Policy::SmemPaddingA::kRow,
+                               Shape::kK * kStages +
+                                   Policy::SmemPaddingA::kColumn>;
+
+    /// Stride to the imaginary part of the A operand
+    static int const kImaginaryStrideA = ShapeA::kCount;
+
+    /// Shape of the B matrix operand in shared memory
+    using ShapeB =
+        MatrixShape<Shape::kK * kStages + Policy::SmemPaddingB::kRow,
+                    Shape::kN + Policy::SmemPaddingB::kColumn>;
+
+    /// Stride to the imaginary part of the A operand
+    static int const kImaginaryStrideB = ShapeB::kCount;
+
+   public:
+    //
+    // Data members
+    //
+
+    /// Buffer for A operand
+    AlignedBuffer<typename Operator::ElementA, ShapeA::kCount + kImaginaryStrideA> operand_A;
+
+    /// Buffer for B operand
+    AlignedBuffer<typename Operator::ElementB, ShapeB::kCount + kImaginaryStrideB> operand_B;
+
+   public:
+
+    //
+    // Methods
+    //
+
+    /// Returns a layout object for the A matrix
+    CUTLASS_DEVICE
+    static typename Operator::LayoutA LayoutA() {
+      return Operator::LayoutA::packed({ShapeA::kRow, ShapeA::kColumn});
+    }
+
+    /// Returns a layout object for the B matrix
+    CUTLASS_HOST_DEVICE
+    static typename Operator::LayoutB LayoutB() {
+      return Operator::LayoutB::packed({ShapeB::kRow, ShapeB::kColumn});
+    }
+
+    /// Returns a TensorRef to the A operand
+    CUTLASS_HOST_DEVICE
+    TensorRefA operand_A_ref() {
+      return TensorRefA{operand_A.data(), LayoutA()};
+    }
+
+    /// Returns a TensorRef to the B operand
+    CUTLASS_HOST_DEVICE
+    TensorRefB operand_B_ref() {
+      return TensorRefB{operand_B.data(), LayoutB()};
+    }
+  };
+
+ protected:
+
+  //
+  // Data members
+  //
+
+  /// Iterator to load a warp-scoped tile of A operand from shared memory
+  typename Operator::IteratorA warp_tile_iterator_A_;
+
+  /// Iterator to load a warp-scoped tile of B operand from shared memory
+  typename Operator::IteratorB warp_tile_iterator_B_;
+
+public:
+
+  /// Construct from tensor references
+  CUTLASS_DEVICE
+  MmaPlanarComplexBase(
+      ///< Shared storage needed for internal use by threadblock-scoped GEMM
+      SharedStorage &shared_storage,
+      ///< ID within the threadblock
+      int thread_idx,
+      ///< ID of warp
+      int warp_idx,
+      ///< ID of each thread within a warp
+      int lane_idx
+    ):
+      warp_tile_iterator_A_(shared_storage.operand_A_ref(), lane_idx),
+      warp_tile_iterator_B_(shared_storage.operand_B_ref(), lane_idx) {
 
-/// Specialization for row-major output
-template <
-    /// Element type for A matrix operand
-    typename ElementA,
-    /// Layout type for A matrix operand
-    typename LayoutA,
-    /// Element type for B matrix operand
-    typename ElementB,
-    /// Layout type for B matrix operand
-    typename LayoutB,
-    /// Element type for internal accumulation
-    typename ElementAccumulator,
-    /// Tag indicating architecture to tune for
-    typename OperatorClass,
-    /// Tag indicating architecture to tune for
-    typename ArchTag,
-    /// Threadblock-level tile size (concept: GemmShape)
-    typename ThreadblockShape,
-    /// Warp-level tile size (concept: GemmShape)
-    typename WarpShape,
-    /// Instruction-level tile size (concept: GemmShape)
-    typename InstructionShape,
-    /// Number of stages used in the multistage mainloop
-    int Stages,
-    /// Complex transformation on operand A
-    ComplexTransform TransformA,
-    /// Complex transformation on operand B
-    ComplexTransform TransformB,
-    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
-    typename Operator>
-struct DefaultMultistageMmaComplex<ElementA, LayoutA, ElementB, LayoutB,
-                            ElementAccumulator, layout::RowMajor, OperatorClass,
-                            ArchTag, ThreadblockShape, WarpShape,
-                            InstructionShape, Stages, TransformA, TransformB, Operator> {
-  // Define the MmaCore components
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMultistageMmaComplexCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA, 
-      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, TransformA, TransformB, Operator>;
-
-  // Define iterators over tiles from the A operand
-  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using AccessTypeA = cutlass::Array<ElementA, ThreadMapA::kElementsPerAccess>;
-  using IteratorA =
-      cutlass::transform::threadblock::PredicatedTileAccessIterator<
-          cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-          ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
-
-  // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::Array<ElementB, ThreadMapB::kElementsPerAccess>;
-  using IteratorB =
-      cutlass::transform::threadblock::PredicatedTileAccessIterator<
-          cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-          ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
-
-  // Define the threadblock-scoped multistage matrix multiply
-  using ThreadblockMma = cutlass::gemm::threadblock::MmaMultistage<
-      typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
-      MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
-      MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
-      typename MmaCore::MmaPolicy, Stages>;
+  }
 };
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
 }  // namespace threadblock
 }  // namespace gemm
 }  // namespace cutlass
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -153,15 +153,15 @@
     static int const kAccessesPerGroupB =
         (AsyncCopyIterationsPerStageB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
     // Optional staged-accumulation (e.g., tf32x3 kernels) for improved numerical
     // accuracy, where each mainloop iteration first accumulates into a temporary
     // set of freshly-cleared accumulators, which are subsequently added to the
     // final accumulator set.
-    static bool const kStagedAccumulation = arch::UseStagedAccumulation<typename Operator::MathOperator>::value;
+    static bool const kStagedAccumulation = arch::detail::UseStagedAccumulation<Operator>::value;
   };
 
  private:
 
 
   // Structure encapsulating pipeline state live from one iteration to the next
   struct PipeState {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h`

 * *Files 4% similar despite different names*

```diff
@@ -28,24 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Implements streamk threadblock mapping blockIdx to GEMM problems.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/platform/platform.h"
 #include "cutlass/gemm/gemm_enumerated_types.h"
@@ -170,16 +160,15 @@
 
 
   //
   // Host+device interface
   //
 
   /// Constructor
-  CUTLASS_HOST_DEVICE
-  ThreadblockSwizzleStreamK() {}
+  ThreadblockSwizzleStreamK() = default;
 
   /// Returns the GEMM volume in thread block tiles
   CUTLASS_HOST_DEVICE
   GemmCoord tiled_shape() const
   {
     return GemmCoord(
         static_cast<int>(div_mod_tiled_shape_m),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h`

 * *Files 1% similar despite different names*

```diff
@@ -268,25 +268,25 @@
     "DefaultMmaTensorOp with arch::OpMultiplyAddMixedInputUpcast ElementA and ElementB cannot be of the same data type");
 
   // Data type used for internal computation - use the wider of the two data types for mma.sync operands
   using ElementOperand = typename platform::conditional<(sizeof(ElementA) > sizeof(ElementB)), 
                                                     ElementA, ElementB>::type;
 
   // Operand datatypes in the internal MMA instruction - use the wider of the two data types
-  using MmaElementA = ElementOperand;
-  using MmaElementB = ElementOperand;
+  using ElementAMma = ElementOperand;
+  using ElementBMma = ElementOperand;
   using MmaElementC = ElementC;
 
   // Uses 
   using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
       cutlass::arch::Mma<
         GemmShape<16, 8, 16>, 
         32, 
-        MmaElementA, cutlass::layout::RowMajor, 
-        MmaElementB, cutlass::layout::ColumnMajor,
+        ElementAMma, cutlass::layout::RowMajor, 
+        ElementBMma, cutlass::layout::ColumnMajor,
         MmaElementC, cutlass::layout::RowMajor, 
         arch::OpMultiplyAdd
       >,
       cutlass::MatrixShape<1, 1> >;
 
   // Define the warp-level tensor op
   using Type = cutlass::gemm::warp::MmaMixedInputTensorOp<
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/kernel/conv_universal.hpp`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,37 +24,40 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Templates exposing architecture support for warp-level multiply-add operations
-*/
-
 #pragma once
 
-#include "cutlass/cutlass.h"
+#include "cutlass/detail/dependent_false.hpp"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-namespace cutlass {
-namespace gemm {
-namespace warp {
+namespace cutlass::conv::kernel {
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-/// Query the number of threads per warp
-template <typename OperatorClass>
-struct WarpSize {
-  static int const value = 32;
+/*
+ * Stateless universal device CONV kernel type that treats CONV as
+ * a composition of a collective mainloop and a collective epilogue.
+**/
+template <
+  class CollectiveMainloop_,
+  class CollectiveEpilogue_,
+  class TileSchedulerTag_ = void,
+  class Enable = void
+>
+class ConvUniversal {
+  static_assert(cutlass::detail::dependent_false<Enable>,
+      "Could not find a valid specialization at the kernel layer to dispatch against.");
 };
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-} // namespace warp
-} // namespace gemm
-} // namespace cutlass
+} // namespace cutlass::conv::kernel
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
+#include "cutlass/conv/kernel/sm90_implicit_gemm_tma_warpspecialized.hpp"
+////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_mixed_input_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_mixed_input_tensor_op.h`

 * *Files 4% similar despite different names*

```diff
@@ -370,18 +370,18 @@
   /// Shape of the warp in units of thread (concept: MmaLanePolicySimt)
   using Policy = Policy_;
 
   /// Underlying matrix multiply operator (concept: arch::Mma)
   using ArchMmaOperator = typename Policy::Operator;
 
   /// Underlying arch::Mma instruction datatype for A operand
-  using MmaElementA = typename ArchMmaOperator::ElementA;
+  using ElementAMma = typename ArchMmaOperator::ElementA;
 
   /// Underlying arch::Mma instruction datatype for B operand
-  using MmaElementB = typename ArchMmaOperator::ElementB;
+  using ElementBMma = typename ArchMmaOperator::ElementB;
 
   /// Underlying arch::Mma instruction datatype for C operand
   using MmaElementC = typename ArchMmaOperator::ElementC;
 
   /// Indicates math operator 
   using MathOperator = typename ArchMmaOperator::Operator;
 
@@ -404,30 +404,30 @@
   static int const kThreadCount = 32;
 
   /// Number of partitions along K dimension
   static int const kPartitionsK = PartitionsK_;
 
   /// 
   // static int const kLoadShapeK = InstructionShape::kK * 
-  //  (sizeof_bits<MmaElementA>::value / sizeof_bits<ElementB>::value);
+  //  (sizeof_bits<ElementAMma>::value / sizeof_bits<ElementB>::value);
 
 public:
 
   /// Iterates over the A operand in Shared Memory
   using IteratorA = MmaTensorOpMultiplicandTileIterator<
      MatrixShape<Shape::kM, Shape::kK>, Operand::kA, ElementA, LayoutA,
      MatrixShape<ArchMmaOperator::Shape::kM, ArchMmaOperator::Shape::kK>,
      Policy::OpDelta::kRow, kThreadCount, kPartitionsK>;
 
   /// Storage for A tile in registers (loaded from Shared Memory)
   using FragmentA = typename IteratorA::Fragment;
 
   /// Storage for transformed A tile in registers (for use in Mma instruction)
   using TransformedFragmentA =
-      Array<MmaElementA, FragmentA::kElements>;
+      Array<ElementAMma, FragmentA::kElements>;
 
   /// Underlying arch::Mma instruction operand fragement for matrix A
   using MmaOperandA = typename ArchMmaOperator::FragmentA;
 
   /// Iterates over the B operand in Shared Memory
   using IteratorB = MmaTensorOpMultiplicandTileIterator<
       MatrixShape<Shape::kK, Shape::kN>, Operand::kB, ElementB, LayoutB,
@@ -435,15 +435,15 @@
       Policy::OpDelta::kRow, kThreadCount, kPartitionsK>;
 
   /// Storage for B tile in registers (loaded from Shared Memory)
   using FragmentB = typename IteratorB::Fragment;
 
   /// Storage for transformed B tile in registers (for use in Mma instruction)
   using TransformedFragmentB =
-      Array<MmaElementB, FragmentB::kElements>;
+      Array<ElementBMma, FragmentB::kElements>;
 
   /// Underlying arch::Mma instruction operand fragement for matrix B
   using MmaOperandB = typename ArchMmaOperator::FragmentB;
 
   /// Iterates over the C operand in memory
   using IteratorC = MmaTensorOpAccumulatorTileIterator<
      MatrixShape<Shape::kM, Shape::kN>, ElementC, LayoutC,
@@ -519,38 +519,38 @@
   /// Transform the operand warp fragment register to the required data types and layout 
   /// for the `cultass::arch::Mma`
   CUTLASS_DEVICE
   void transform(TransformedFragmentA &dst_A, TransformedFragmentB &dst_B,
                  FragmentA const &A, FragmentB const &B) const {
 
     // Shuffle data within warp to obtain the mma.sync operand layout
-    detail::FragmentShuffler<MmaElementB, ElementB, MmaIterations::kColumn, 
+    detail::FragmentShuffler<ElementBMma, ElementB, MmaIterations::kColumn, 
              FragmentB::kElements, MmaOperandB::kElements, Operand::kB> shuffler_B;
     FragmentB tmp_B; 
     tmp_B = shuffler_B(B);
 
     // Convert the B operand to the Mma Instruction operand type
-    detail::FragmentConverter<MmaElementB, ElementB, FragmentB::kElements> convert_B;
+    detail::FragmentConverter<ElementBMma, ElementB, FragmentB::kElements> convert_B;
     dst_B = convert_B(tmp_B);
 
     FragmentA tmp_A;
 
     Array<ElementA, FragmentA::kElements / 2> *
         ptr_tmp_A = reinterpret_cast<Array<ElementA,
                                              FragmentA::kElements / 2> *>(&tmp_A);
-    Array<MmaElementA, FragmentA::kElements / 2> *
-        ptr_dst_A = reinterpret_cast<Array<MmaElementA,
+    Array<ElementAMma, FragmentA::kElements / 2> *
+        ptr_dst_A = reinterpret_cast<Array<ElementAMma,
                                              FragmentA::kElements / 2> *>(&dst_A);
 
     // Shuffle data within warp to obtain the mma.sync operand layout
-    detail::FragmentShuffler<MmaElementA, ElementA, MmaIterations::kRow,
+    detail::FragmentShuffler<ElementAMma, ElementA, MmaIterations::kRow,
              FragmentA::kElements, MmaOperandA::kElements, Operand::kA> shuffler_A;
 
     // Convert the A operand to the Mma Instruction operand type
-    detail::FragmentConverter<MmaElementA, ElementA, FragmentA::kElements / 2> convert_A;
+    detail::FragmentConverter<ElementAMma, ElementA, FragmentA::kElements / 2> convert_A;
 
     tmp_A = shuffler_A(A);
     ptr_dst_A[0] = convert_A(ptr_tmp_A[0]);
 
     ptr_dst_A[1] = convert_A(ptr_tmp_A[1]);
   }
 };
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h`

 * *Files 8% similar despite different names*

```diff
@@ -230,15 +230,16 @@
 
   /// Constructor from TensorRef
   CUTLASS_DEVICE
   MmaTensorOpMultiplicandTileIterator(
     TensorRef const &ref, 
     int lane_id
   ):
-    stride_(ref.stride(0) / Layout::kElementsPerAccess), byte_offset_(0),
+    stride_(ref.stride(0) / Layout::kElementsPerAccess),
+    byte_offset_(0),
     k_group_idx_(0) {
       
     int quad_pair = (lane_id >> 3);
     int quad_quad = (lane_id >> 4);
     int lane_in_quad = (lane_id & 3);
     int lane_in_quad_pair = (lane_id & 7);
     int lane_in_quad_quad = (lane_id & 15);
@@ -252,16 +253,15 @@
       if (Policy::LdsmShape::kContiguous == 4) {
         // Matrix multiply 1688 A/B
         // Q0 Q1 Q2 Q3 (Q stands for 1 8x128bit block).
         // Four blocks are next to each other in the contiguous dimension.
         partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ i);
         access_contiguous_idx = (quad_pair ^ lane_in_quad);
         access_strided_idx = lane_in_quad_pair;
-      }
-      else if (Policy::LdsmShape::kContiguous == 2 &&
+      } else if (Policy::LdsmShape::kContiguous == 2 &&
                  kOperand == Operand::kA) {
         // Matrix multiply 16816 A
         // Q0 Q1
         // Q2 Q3
         partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ (i >> 1));
         access_contiguous_idx =
             (((quad_pair & 1) + ((i & 1) << 1)) ^ lane_in_quad);
@@ -276,17 +276,17 @@
         access_strided_idx = lane_in_quad_quad;
       } else if (Policy::LdsmShape::kContiguous == 1) {
         // Matrix multiply 16832.SP B
         // Q0
         // Q1
         // Q2
         // Q3
-        partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ (i >> 2)); 
-        access_contiguous_idx = ((i & 3) ^ lane_in_quad); 
-        access_strided_idx = lane_id; 
+        partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ (i >> 2));
+        access_contiguous_idx = ((i & 3) ^ lane_in_quad);
+        access_strided_idx = lane_id;
       }
 
       int access_contiguous =
           partition_contiguous_idx * Layout::PartitionShape::kContiguous +
           access_contiguous_idx;
 
       int access_strided = access_strided_idx;
@@ -838,14 +838,801 @@
   void set_kgroup_index(int k_group) {
     // no op
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
+/// This tile iterator is specialized for 32-thread TensorOps with 64B warp tile
+/// the contiguous dimension. This assumes Threadblock contiguous dimension has
+/// the same size as the warp tile.  It uses LDSM to load from shared
+/// memory and therefore must be initialized with a TensorRef to shared memory.
+///
+/// This specialization can be merged into the general one.  Most code is the same.
+///
+/// Satisfies:
+///   ReadableRandomAccessContiguousTileIteratorConcept
+///
+template <
+    /// Size of the matrix to load (concept: PitchLinearShape)
+    typename Shape_,
+    /// Identifies A or B multiplicand
+    Operand Operand_,
+    /// Data type of elements
+    typename Element_,
+    /// Shape of one matrix product operation (concept: PitchLinearShape)
+    typename InstructionShape_,
+    /// Interval between adjacent *MMA instructions (in units of MMA
+    /// instructions)
+    int OpDelta_,
+    /// Number of partitions along K dimension
+    int PartitionsK_>
+class MmaTensorOpMultiplicandTileIterator<
+    Shape_, Operand_, Element_,
+    cutlass::layout::TensorOpMultiplicandCongruous<16, 32>,
+    InstructionShape_, OpDelta_, 32, PartitionsK_> {
+ public:
+
+  /// Shape of tile to load (concept: PitchLinearShape)
+  using Shape = Shape_;
+
+  /// Operand tag
+  static Operand const kOperand = Operand_;
+
+  static_assert(kOperand == Operand::kA || kOperand== Operand::kB,
+    "MmaTensorOpMultiplicandIterator may only be instantiated for A or B operands to warp-level Mma.");
+
+  /// Element type
+  using Element = Element_;
+
+  /// Element number when the layout crosses
+  static int const kCrosswise = 32;
+
+  /// Layout of source tile
+  using Layout = cutlass::layout::TensorOpMultiplicandCongruous<
+      sizeof_bits<Element_>::value, kCrosswise>;
+
+  /// Shape of one matrix product operation (concept: GemmShape)
+  using InstructionShape = InstructionShape_;
+
+  /// Delta between *MMA operations (in units of *MMA operations, concept: MatrixShape)
+  static int const kOpDelta = OpDelta_;
+
+  /// Number of participating threads
+  static int const kThreads = 32;
+
+  /// Number of partitions along K dimension
+  static int const kPartitionsK = PartitionsK_;
+
+  /// TensorRef type for loading element from a tensor
+  using TensorRef = TensorRef<Element, Layout>;
+
+  /// Index type
+  using Index = typename TensorRef::Index;
+
+  /// Long Index type
+  using LongIndex = typename TensorRef::LongIndex;
+
+  /// Long Index type
+  using StrideIndex = typename TensorRef::Layout::Stride::Index;
+
+  /// Coordinate for an element in the tensor
+  using TensorCoord = typename TensorRef::TensorCoord;
+
+  /// Internal structure of iterator - made public to enable introspection
+  struct Policy {
+    static_assert(
+        !(Shape::kContiguous % InstructionShape::kContiguous),
+        "Shape of warp-level Mma must be divisible by operator shape.");
+
+    // Determine number of elements along outer dimension per individual LDSM op
+    static int const kLdsmOpOuter = Layout::kElementsPerAccess;
+    static int const kLdsmOpInner = 8;
+
+    static_assert(!(Shape::kContiguous % kLdsmOpOuter),
+      "Shape of warp-level mma must be divisible by LDSM's fundamental tile size.");
+
+    static_assert(!(Shape::kStrided % kLdsmOpInner),
+      "Shape of warp-level mma must be divisible by LDSM's fundamental tile size.");
+
+    /// Shape of one individual LDSM instruction
+    static int const LdsmShapeStrided =
+        InstructionShape::kStrided / kLdsmOpInner;
+    static int const LdsmShapeContiguous = 4 / LdsmShapeStrided;
+    using LdsmShape =
+        layout::PitchLinearShape<LdsmShapeContiguous, LdsmShapeStrided>;
+
+    /// Number and arrangement of LDSM instructions
+    using LdsmIterations = layout::PitchLinearShape<
+        Shape::kContiguous / Layout::kElementsPerAccess / LdsmShapeContiguous,
+        1>;
+
+    /// Number of groups for each tile
+    static int const kGroupsPerTile =
+        Shape::kStrided / InstructionShape::kStrided;
+  };
+
+private:
+
+  /// Not working on this feature at the moment.
+  static_assert(kOpDelta == 1,
+    "Alternative arrangements not supported at present.");
+
+  /// Number of internal pointers needed to reference shared memory
+  static int const kPointerCount =
+      Layout::TileShape::kContiguous / Policy::LdsmShape::kContiguous / Layout::kFactor;
+
+  /// Pointer type used for accesses
+  using AccessType = Array<Element, Layout::kElementsPerAccess>;
+
+  /// Internal counter used to jump to next K partition
+  int k_group_idx_;
+
+public:
+
+  //
+  // Derived quantities
+  //
+
+  /// Fragment object holding a thread's part of a tile
+ using Fragment =
+     Array<Element, Shape::kContiguous * InstructionShape::kStrided / kThreads>;
+
+private:
+
+  /// Layout object storing stride values
+  StrideIndex stride_;
+
+  /// Shared memory base pointers - not advanced
+  AccessType const *pointer_[kPointerCount];
+
+  /// Byte offset incremented as iterator advances
+  Index byte_offset_;
+
+public:
+  
+  /// Default ctor constructs null iterator
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator(): stride_(0), byte_offset_(0) { }
+
+  /// Constructor from TensorRef
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator(
+    TensorRef const &ref, 
+    int lane_id
+  ):
+    stride_(ref.stride(0) * Layout::kFactor / Layout::kElementsPerAccess),
+    byte_offset_(0),
+    k_group_idx_(0) {
+      
+    int quad_pair = (lane_id >> 3);
+    int quad_quad = (lane_id >> 4);
+    //int lane_in_quad = (lane_id & 3);
+    int lane_in_quad_pair = (lane_id & 7);
+    int lane_in_quad_quad = (lane_id & 15);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < kPointerCount; ++i) {
+      int partition_contiguous_idx = -1;
+      int access_contiguous_idx = -1;
+      int access_strided_idx = -1;
+
+      if (Policy::LdsmShape::kContiguous == 4) {
+        // Matrix multiply 1688 A/B
+        // Q0 Q1 Q2 Q3 (Q stands for 1 8x128bit block).
+        // Four blocks are next to each other in the contiguous dimension.
+        partition_contiguous_idx = (lane_id % Layout::kFactor);
+        access_contiguous_idx = quad_pair ^ (lane_in_quad_pair / Layout::kFactor);
+        access_strided_idx = lane_in_quad_pair / Layout::kFactor;
+      } else if (Policy::LdsmShape::kContiguous == 2 &&
+          kOperand == Operand::kA) {
+        // Matrix multiply 16816 A
+        // Q0 Q1
+        // Q2 Q3
+        partition_contiguous_idx = (lane_id % Layout::kFactor);
+        access_contiguous_idx =
+            (((quad_pair & 1) + i * 2) ^ (lane_in_quad_pair / Layout::kFactor));
+        access_strided_idx = (lane_in_quad_pair + (lane_id >> 4 << 3)) / 2;
+      } else if (Policy::LdsmShape::kContiguous == 2 &&
+                 kOperand == Operand::kB) {
+        // Matrix multiply 16816 B
+        // Q0 Q2
+        // Q1 Q3
+        partition_contiguous_idx = (lane_id % Layout::kFactor);
+        access_contiguous_idx = (quad_quad + i * 2) ^ (lane_in_quad_pair / Layout::kFactor);
+        access_strided_idx = (lane_in_quad_quad / Layout::kFactor);
+      }
+
+      int access_contiguous =
+          partition_contiguous_idx * Layout::PartitionShape::kContiguous +
+          access_contiguous_idx;
+
+      int access_strided = access_strided_idx;
+
+      pointer_[i] = reinterpret_cast<AccessType const *>(ref.data()) +
+                    access_contiguous + access_strided * stride_;
+    }
+  }
+
+  /// Adds a pointer offset to internal pointer(s) to advance through memory
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator &add_pointer_offset(LongIndex offset) {
+
+    byte_offset_ += offset * sizeof(Element);
+
+    return *this;
+  }
+
+  /// Advances an iterator along logical dimensions of matrix in units of whole tiles
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator &add_tile_offset(TensorCoord const &tile_offset) {
+
+    int contiguous_offset = tile_offset.contiguous();
+    if (Shape::kContiguous ==
+        Layout::PartitionShape::kContiguous * Layout::kElementsPerAccess) {
+      if (tile_offset.contiguous() % 2) {
+        CUTLASS_PRAGMA_UNROLL
+        for (int i = 0; i < kPointerCount / 2; ++i) {
+          AccessType const *tmp_pointer = pointer_[i];
+          pointer_[i] = pointer_[i + kPointerCount / 2];
+          pointer_[i + kPointerCount / 2] = tmp_pointer;
+        }
+      }
+      contiguous_offset = (tile_offset.contiguous() >> 1) << 1;
+    }
+
+    int offset = (tile_offset.strided() * InstructionShape::kStrided) *
+                     stride_ * Layout::kElementsPerAccess / Layout::kFactor +
+                 contiguous_offset * Shape::kContiguous;
+
+    add_pointer_offset(offset);
+
+    return *this;
+  }
+
+  /// Advances the iterator along the advance dimension
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator++() {
+
+    add_tile_offset({0, 1});
+
+    if (kPartitionsK > 1) {
+      ++k_group_idx_;
+      // Jump to next stage
+      if (k_group_idx_ == Policy::kGroupsPerTile) {
+        k_group_idx_ = 0;
+        add_tile_offset(
+            {0, ((kPartitionsK - 1) * Policy::kGroupsPerTile)});
+      }
+    }
+
+    return *this;
+  }
+
+  /// Advances the iterator along the opposite of the advance dimension
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator--() {
+    byte_offset_ -= stride_ * InstructionShape::kStrided * sizeof(Element) *
+                    Layout::kElementsPerAccess;
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator+=(TensorCoord const &tile_offset) {
+    add_tile_offset(tile_offset);
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator-=(TensorCoord const &tile_offset) {
+    add_tile_offset(-tile_offset);
+    return *this;
+  }
+
+  /// Loads a fragment from memory at the location pointed to by the iterator.
+  CUTLASS_HOST_DEVICE
+  void load(Fragment &frag) const {
+
+    load_with_byte_offset(frag, 0);
+  }
+
+  /// Loads a fragment from memory with additional logical offset
+  CUTLASS_DEVICE
+  void load_with_byte_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a linear offset in units of bytes
+      Index byte_offset) const {
+
+    Array<unsigned, Policy::LdsmShape::kCount> *fetch_ptr = 
+      reinterpret_cast<Array<unsigned, Policy::LdsmShape::kCount> *>(&frag);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int s = 0; s < Policy::LdsmIterations::kStrided; ++s) {
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int c = 0; c < Policy::LdsmIterations::kContiguous; ++c) {
+
+        int access_idx = c + s * Policy::LdsmIterations::kContiguous;
+
+        AccessType const *source_ptr =
+            pointer_[c % kPointerCount] +
+            Layout::TileShape::kContiguous * (c / kPointerCount) +
+            Policy::kLdsmOpInner * Policy::LdsmShape::kStrided * s * stride_ / Layout::kFactor;
+
+        char const *source_byte_ptr = reinterpret_cast<char const *>(source_ptr) + byte_offset + byte_offset_;
+
+        cutlass::arch::ldsm<layout::ColumnMajor, Policy::LdsmShape::kCount>(
+          fetch_ptr[access_idx],
+          source_byte_ptr
+        );
+      }
+    }
+  }
+
+  /// Loads a fragment from memory with additional logical offset
+  CUTLASS_DEVICE
+  void load_with_pointer_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a linear offset
+      Index pointer_offset) const {
+    load_with_byte_offset(frag, pointer_offset * sizeof(Element));
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset) const {
+    load_with_byte_offset(frag, tile_offset, 0);
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset,
+      /// loads a tile with a logical offset AND a pointer offset
+      Index pointer_offset) const {
+    load_with_byte_offset(frag, tile_offset, pointer_offset * sizeof(Element));
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load_with_byte_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset,
+      /// loads a tile with a logical offset AND a pointer offset
+      Index byte_offset) const {
+    Index pointer_offset = 
+      tile_offset.contiguous() * Shape::kContiguous / Layout::kElementsPerAccess + 
+      tile_offset.strided() * InstructionShape::kStrided * stride_ / Layout::kFactor;
+
+    byte_offset += sizeof(AccessType) * pointer_offset;
+
+    load_with_byte_offset(frag, byte_offset);
+  }
+
+  /// Notify the iterator which k-group it is currently pointing to.
+  ///
+  /// This does not advance the iterator. Rather, it overrides its internal
+  /// tracking with constant-valued k-group index to enable the compiler to
+  /// fold constants and achieve more efficient code.
+  ///
+  /// This is used by some nontrivial permuted layouts.
+  CUTLASS_DEVICE
+  void set_kgroup_index(int k_group) {
+    // no op
+  }
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+/// This tile iterator is specialized for 32-thread TensorOps with 32B warp tile
+/// the contiguous dimension. This assumes Threadblock contiguous dimension has
+/// the same size as the warp tile.  It uses LDSM to load from shared
+/// memory and therefore must be initialized with a TensorRef to shared memory.
+///
+/// This specialization can be merged into the general one.  Most code is the same.
+///
+/// Satisfies:
+///   ReadableRandomAccessContiguousTileIteratorConcept
+///
+template <
+    /// Size of the matrix to load (concept: PitchLinearShape)
+    typename Shape_,
+    /// Identifies A or B multiplicand
+    Operand Operand_,
+    /// Data type of elements
+    typename Element_,
+    /// Shape of one matrix product operation (concept: PitchLinearShape)
+    typename InstructionShape_,
+    /// Interval between adjacent *MMA instructions (in units of MMA
+    /// instructions)
+    int OpDelta_,
+    /// Number of partitions along K dimension
+    int PartitionsK_>
+class MmaTensorOpMultiplicandTileIterator<
+    Shape_, Operand_, Element_,
+    cutlass::layout::TensorOpMultiplicandCongruous<16, 16>,
+    InstructionShape_, OpDelta_, 32, PartitionsK_> {
+ public:
+
+  /// Shape of tile to load (concept: PitchLinearShape)
+  using Shape = Shape_;
+
+  /// Operand tag
+  static Operand const kOperand = Operand_;
+
+  static_assert(kOperand == Operand::kA || kOperand== Operand::kB,
+    "MmaTensorOpMultiplicandIterator may only be instantiated for A or B operands to warp-level Mma.");
+
+  /// Element type
+  using Element = Element_;
+
+  /// Element number when the layout crosses
+  static int const kCrosswise = 16;
+
+  /// Layout of source tile
+  using Layout = cutlass::layout::TensorOpMultiplicandCongruous<
+      sizeof_bits<Element_>::value, kCrosswise>;
+
+  /// Shape of one matrix product operation (concept: GemmShape)
+  using InstructionShape = InstructionShape_;
+
+  /// Delta between *MMA operations (in units of *MMA operations, concept: MatrixShape)
+  static int const kOpDelta = OpDelta_;
+
+  /// Number of participating threads
+  static int const kThreads = 32;
+
+  /// Number of partitions along K dimension
+  static int const kPartitionsK = PartitionsK_;
+
+  /// TensorRef type for loading element from a tensor
+  using TensorRef = TensorRef<Element, Layout>;
+
+  /// Index type
+  using Index = typename TensorRef::Index;
+
+  /// Long Index type
+  using LongIndex = typename TensorRef::LongIndex;
+
+  /// Long Index type
+  using StrideIndex = typename TensorRef::Layout::Stride::Index;
+
+  /// Coordinate for an element in the tensor
+  using TensorCoord = typename TensorRef::TensorCoord;
+
+  /// Internal structure of iterator - made public to enable introspection
+  struct Policy {
+    static_assert(
+        !(Shape::kContiguous % InstructionShape::kContiguous),
+        "Shape of warp-level Mma must be divisible by operator shape.");
+
+    // Determine number of elements along outer dimension per individual LDSM op
+    static int const kLdsmOpOuter = Layout::kElementsPerAccess;
+    static int const kLdsmOpInner = 8;
+
+    static_assert(!(Shape::kContiguous % kLdsmOpOuter),
+      "Shape of warp-level mma must be divisible by LDSM's fundamental tile size.");
+
+    static_assert(!(Shape::kStrided % kLdsmOpInner),
+      "Shape of warp-level mma must be divisible by LDSM's fundamental tile size.");
+
+    /// Shape of one individual LDSM instruction
+    static int const LdsmShapeStrided =
+        InstructionShape::kStrided / kLdsmOpInner;
+    static int const LdsmShapeContiguous = 4 / LdsmShapeStrided;
+    using LdsmShape =
+        layout::PitchLinearShape<LdsmShapeContiguous, LdsmShapeStrided>;
+
+    /// Number and arrangement of LDSM instructions
+    using LdsmIterations = layout::PitchLinearShape<
+        Shape::kContiguous / Layout::kElementsPerAccess / LdsmShapeContiguous,
+        1>;
+
+    /// Number of groups for each tile
+    static int const kGroupsPerTile =
+        Shape::kStrided / InstructionShape::kStrided;
+  };
+
+private:
+
+  /// Not working on this feature at the moment.
+  static_assert(kOpDelta == 1,
+    "Alternative arrangements not supported at present.");
+
+  /// Number of internal pointers needed to reference shared memory
+  static int const kPointerCount =
+      Layout::TileShape::kContiguous / Policy::LdsmShape::kContiguous / Layout::kFactor;
+
+  /// Pointer type used for accesses
+  using AccessType = Array<Element, Layout::kElementsPerAccess>;
+
+  /// Internal counter used to jump to next K partition
+  int k_group_idx_;
+
+public:
+
+  //
+  // Derived quantities
+  //
+
+  /// Fragment object holding a thread's part of a tile
+ using Fragment =
+     Array<Element, Shape::kContiguous * InstructionShape::kStrided / kThreads>;
+
+private:
+
+  /// Layout object storing stride values
+  StrideIndex stride_;
+
+  /// Shared memory base pointers - not advanced
+  AccessType const *pointer_[kPointerCount];
+
+  /// Byte offset incremented as iterator advances
+  Index byte_offset_;
+
+public:
+
+  /// Default ctor constructs null iterator
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator(): stride_(0), byte_offset_(0) { }
+
+  /// Constructor from TensorRef
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator(
+    TensorRef const &ref,
+    int lane_id
+  ):
+    stride_(ref.stride(0) * Layout::kFactor / Layout::kElementsPerAccess),
+    byte_offset_(0),
+    k_group_idx_(0) {
+
+    //int quad_pair = (lane_id >> 3);
+    int quad_quad = (lane_id >> 4);
+    int lane_in_pair = (lane_id & 1);
+    int lane_in_quad = (lane_id & 3);
+    int lane_in_quad_pair = (lane_id & 7);
+    int lane_in_quad_quad = (lane_id & 15);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int i = 0; i < kPointerCount; ++i) {
+      int partition_contiguous_idx = -1;
+      int access_contiguous_idx = -1;
+      int access_strided_idx = -1;
+
+      if (Policy::LdsmShape::kContiguous == 2 &&
+          kOperand == Operand::kA) {
+        // Matrix multiply 16816 A
+        // Q0 Q1
+        // Q2 Q3
+        partition_contiguous_idx = lane_in_quad / 2;
+        access_strided_idx = lane_in_quad_pair / Layout::kFactor + quad_quad * 2;
+        access_contiguous_idx =
+            ((lane_in_pair * 2 + ((lane_id & 8) >> 3)) ^
+             access_strided_idx);
+      } else if (Policy::LdsmShape::kContiguous == 2 &&
+                 kOperand == Operand::kB) {
+        // Matrix multiply 16816 B
+        // Q0 Q2
+        // Q1 Q3
+        partition_contiguous_idx = lane_in_quad / 2;
+        access_strided_idx = lane_in_quad_quad / Layout::kFactor;
+        access_contiguous_idx =
+            ((lane_in_pair * 2 + quad_quad) ^
+             access_strided_idx);
+      }
+
+      int access_contiguous =
+          partition_contiguous_idx * Layout::PartitionShape::kContiguous +
+          access_contiguous_idx;
+
+      int access_strided = access_strided_idx;
+
+      pointer_[i] = reinterpret_cast<AccessType const *>(ref.data()) +
+                    access_contiguous + access_strided * stride_;
+    }
+  }
+
+  /// Adds a pointer offset to internal pointer(s) to advance through memory
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator &add_pointer_offset(LongIndex offset) {
+
+    byte_offset_ += offset * sizeof(Element);
+
+    return *this;
+  }
+
+  /// Advances an iterator along logical dimensions of matrix in units of whole tiles
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator &add_tile_offset(TensorCoord const &tile_offset) {
+
+    int contiguous_offset = tile_offset.contiguous();
+    if (Shape::kContiguous ==
+        Layout::PartitionShape::kContiguous * Layout::kElementsPerAccess) {
+      if (tile_offset.contiguous() % 2) {
+        CUTLASS_PRAGMA_UNROLL
+        for (int i = 0; i < kPointerCount / 2; ++i) {
+          AccessType const *tmp_pointer = pointer_[i];
+          pointer_[i] = pointer_[i + kPointerCount / 2];
+          pointer_[i + kPointerCount / 2] = tmp_pointer;
+        }
+      }
+      contiguous_offset = (tile_offset.contiguous() >> 1) << 1;
+    }
+
+    int offset = (tile_offset.strided() * InstructionShape::kStrided) *
+                     stride_ * Layout::kElementsPerAccess / Layout::kFactor +
+                 contiguous_offset * Shape::kContiguous;
+
+    add_pointer_offset(offset);
+
+    return *this;
+  }
+
+  /// Advances the iterator along the advance dimension
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator++() {
+
+    add_tile_offset({0, 1});
+
+    if (kPartitionsK > 1) {
+      ++k_group_idx_;
+      // Jump to next stage
+      if (k_group_idx_ == Policy::kGroupsPerTile) {
+        k_group_idx_ = 0;
+        add_tile_offset(
+            {0, ((kPartitionsK - 1) * Policy::kGroupsPerTile)});
+      }
+    }
+
+    return *this;
+  }
+
+  /// Advances the iterator along the opposite of the advance dimension
+  CUTLASS_HOST_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator--() {
+    byte_offset_ -= stride_ * InstructionShape::kStrided * sizeof(Element) *
+                    Layout::kElementsPerAccess;
+
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator+=(TensorCoord const &tile_offset) {
+    add_tile_offset(tile_offset);
+    return *this;
+  }
+
+  ///< advances in units of whole tiles along the logical coordinate space of the tensor
+  CUTLASS_DEVICE
+  MmaTensorOpMultiplicandTileIterator & operator-=(TensorCoord const &tile_offset) {
+    add_tile_offset(-tile_offset);
+    return *this;
+  }
+
+  /// Loads a fragment from memory at the location pointed to by the iterator.
+  CUTLASS_HOST_DEVICE
+  void load(Fragment &frag) const {
+
+    load_with_byte_offset(frag, 0);
+  }
+
+  /// Loads a fragment from memory with additional logical offset
+  CUTLASS_DEVICE
+  void load_with_byte_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a linear offset in units of bytes
+      Index byte_offset) const {
+
+    Array<unsigned, Policy::LdsmShape::kCount> *fetch_ptr =
+      reinterpret_cast<Array<unsigned, Policy::LdsmShape::kCount> *>(&frag);
+
+    CUTLASS_PRAGMA_UNROLL
+    for (int s = 0; s < Policy::LdsmIterations::kStrided; ++s) {
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int c = 0; c < Policy::LdsmIterations::kContiguous; ++c) {
+
+        int access_idx = c + s * Policy::LdsmIterations::kContiguous;
+
+        AccessType const *source_ptr =
+            pointer_[c % kPointerCount] +
+            Layout::TileShape::kContiguous * (c / kPointerCount) +
+            Policy::kLdsmOpInner * Policy::LdsmShape::kStrided * s * stride_ / Layout::kFactor;
+
+        char const *source_byte_ptr = reinterpret_cast<char const *>(source_ptr) + byte_offset + byte_offset_;
+
+        cutlass::arch::ldsm<layout::ColumnMajor, Policy::LdsmShape::kCount>(
+          fetch_ptr[access_idx],
+          source_byte_ptr
+        );
+      }
+    }
+  }
+
+  /// Loads a fragment from memory with additional logical offset
+  CUTLASS_DEVICE
+  void load_with_pointer_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a linear offset
+      Index pointer_offset) const {
+    load_with_byte_offset(frag, pointer_offset * sizeof(Element));
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset) const {
+    load_with_byte_offset(frag, tile_offset, 0);
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset,
+      /// loads a tile with a logical offset AND a pointer offset
+      Index pointer_offset) const {
+    load_with_byte_offset(frag, tile_offset, pointer_offset * sizeof(Element));
+  }
+
+  /// Loads a fragment from memory with logical offset in units of whole tiles.
+  CUTLASS_DEVICE
+  void load_with_byte_offset(
+      /// fragment to load from the tensor
+      Fragment &frag,
+      /// loads a tile with a logical offset in units of whole tiles
+      TensorCoord const &tile_offset,
+      /// loads a tile with a logical offset AND a pointer offset
+      Index byte_offset) const {
+    Index pointer_offset =
+      tile_offset.contiguous() * Shape::kContiguous / Layout::kElementsPerAccess +
+      tile_offset.strided() * InstructionShape::kStrided * stride_ / Layout::kFactor;
+
+    byte_offset += sizeof(AccessType) * pointer_offset;
+
+    load_with_byte_offset(frag, byte_offset);
+  }
+
+  /// Notify the iterator which k-group it is currently pointing to.
+  ///
+  /// This does not advance the iterator. Rather, it overrides its internal
+  /// tracking with constant-valued k-group index to enable the compiler to
+  /// fold constants and achieve more efficient code.
+  ///
+  /// This is used by some nontrivial permuted layouts.
+  CUTLASS_DEVICE
+  void set_kgroup_index(int k_group) {
+    // no op
+  }
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
 /// This tile iterator is specialized for 32-thread TensorOps. It uses LDSM to load from shared
 /// memory and therefore must be initialized with a TensorRef to shared memory. 
 ///
 /// Satisfies:
 ///   ReadableRandomAccessContiguousTileIteratorConcept
 ///
 template <
@@ -856,20 +1643,22 @@
     /// Data type of elements
     typename Element_,
     /// Shape of one matrix product operation (concept: MatrixShape)
     typename InstructionShape_,
     /// Interval between adjacent *MMA instructions (in units of MMA
     /// instructions)
     int OpDelta_,
+    /// Element number when the layout crosses (in units of elements)
+    int Crosswise,
     /// Number of partitions along K dimension
     int PartitionsK_>
 class MmaTensorOpMultiplicandTileIterator<
     Shape_, Operand_, Element_,
     cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
-        sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>,
+        sizeof_bits<Element_>::value, Crosswise>,
     InstructionShape_, OpDelta_, 32, PartitionsK_> {
  public:
 
   /// Shape of tile to load (concept: PitchLinearShape)
   using Shape = Shape_;
 
   /// Operand tag
@@ -878,17 +1667,20 @@
   static_assert(kOperand == Operand::kA,
                 "MmaTensorOpMultiplicandIterator for ColumnMajor Congruous may "
                 "only be instantiated for A operand to warp-level Mma.");
 
   /// Element type
   using Element = Element_;
 
+  /// MBlock or NBlock size
+  static int const kCrosswise = Crosswise;
+
   /// Layout of source tile
   using Layout = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>;
+      sizeof_bits<Element_>::value, kCrosswise>;
 
   /// Shape of one matrix product operation (concept: MatrixShape)
   using InstructionShape = InstructionShape_;
 
   /// Delta between *MMA operations (in units of *MMA operations, concept: MatrixShape)
   static int const kOpDelta = OpDelta_;
 
@@ -910,15 +1702,15 @@
   /// Coordinate for an element in the tensor
   using TensorCoord = typename TensorRef::TensorCoord;
 
   /// Underlying tile iterator implementation
   using Base = MmaTensorOpMultiplicandTileIterator<
       layout::PitchLinearShape<Shape::kRow, Shape::kColumn>, kOperand, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element_))>,
+                                            kCrosswise>,
       layout::PitchLinearShape<InstructionShape::kRow,
                                InstructionShape::kColumn>,
       kOpDelta, kThreads, PartitionsK_>;
 
  public:
 
   //
@@ -1088,20 +1880,22 @@
     /// Data type of elements
     typename Element_,
     /// Shape of one matrix product operation (concept: MatrixShape)
     typename InstructionShape_,
     /// Interval between adjacent *MMA instructions (in units of MMA
     /// instructions)
     int OpDelta_,
+    /// Element number when the layout crosses (in units of elements)
+    int Crosswise,
     /// Number of partitions along K dimension
     int PartitionsK_>
 class MmaTensorOpMultiplicandTileIterator<
     Shape_, Operand_, Element_,
     cutlass::layout::RowMajorTensorOpMultiplicandCongruous<
-        sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>,
+        sizeof_bits<Element_>::value, Crosswise>,
     InstructionShape_, OpDelta_, 32, PartitionsK_> {
  public:
 
   /// Shape of tile to load (concept: PitchLinearShape)
   using Shape = Shape_;
 
   /// Operand tag
@@ -1110,17 +1904,20 @@
   static_assert(kOperand == Operand::kB,
                 "MmaTensorOpMultiplicandIterator for RowMajor Congruous may "
                 "only be instantiated for B operand to warp-level Mma.");
 
   /// Element type
   using Element = Element_;
 
+  /// Element number when the layout crosses
+  static int const kCrosswise = Crosswise;
+
   /// Layout of source tile
   using Layout = cutlass::layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>;
+      sizeof_bits<Element_>::value, kCrosswise>;
 
   /// Shape of one matrix product operation (concept: MatrixShape)
   using InstructionShape = InstructionShape_;
 
   /// Delta between *MMA operations (in units of *MMA operations, concept: MatrixShape)
   static int const kOpDelta = OpDelta_;
 
@@ -1139,15 +1936,15 @@
   /// Coordinate for an element in the tensor
   using TensorCoord = typename TensorRef::TensorCoord;
 
   /// Underlying tile iterator implementation
   using Base = MmaTensorOpMultiplicandTileIterator<
       layout::PitchLinearShape<Shape::kColumn, Shape::kRow>, kOperand, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element_))>,
+                                            kCrosswise>,
       layout::PitchLinearShape<InstructionShape::kColumn,
                                InstructionShape::kRow>,
       kOpDelta, kThreads, PartitionsK_>;
 
  public:
 
   //
@@ -1538,16 +2335,15 @@
         // Q1
         // Q2
         // Q3
         // Four blocks are next to each other in the strided dimension.
         partition_contiguous_idx = (lane_id % Layout::kFactor);
         access_contiguous_idx = (lane_in_quad_pair / Layout::kFactor);
         access_strided_idx = lane_id / Layout::kFactor;
-      }
-      else if (Policy::LdsmShape::kStrided ==
+      } else if (Policy::LdsmShape::kStrided ==
                      (Policy::LdsmShape::kCount / 2) &&
                  kOperand == Operand::kA) {
         // Matrix multiply 16816|1688.TF32 A
         // Q0 Q2
         // Q1 Q3
         partition_contiguous_idx = (lane_id % Layout::kFactor);
         access_contiguous_idx =
@@ -3831,26 +4627,26 @@
     LongIndex pq_rem;
 
     unsigned int pq_mul, pq_shr;
     find_divisor(pq_mul, pq_shr, pq);
 
     if(beta_ == 0.0f) {
       CUTLASS_PRAGMA_UNROLL
-      for(int i = 0; i < frag.size(); ++i) {
+      for(int i = 0; i < int(frag.size()); ++i) {
         output_frag_f[i] = frag[i];
       }
 
       if(InstructionShape::kM == Policy::kStridedPerSTG) {
         CUTLASS_PRAGMA_UNROLL
-        for(int i = 0; i < frag.size(); ++i) {
+        for(int i = 0; i < int(frag.size()); ++i) {
           output_frag[i] = (Element)(output_frag_f[i] * alpha_);
         }
       } else {
         CUTLASS_PRAGMA_UNROLL
-        for(int i = 0; i < frag.size(); ++i) {
+        for(int i = 0; i < int(frag.size()); ++i) {
           int map_i = (i / (16 * Policy::kPackedFactor)) * (16 * Policy::kPackedFactor)
                     + (i % (8 * Policy::kPackedFactor)) / 2 * 4
                     + (i % (8 * Policy::kPackedFactor)) % 2
                     + (i / (8 * Policy::kPackedFactor)) % 2 * 2;
           output_frag[i] = (Element)(output_frag_f[map_i] * alpha_);
         }
       }
@@ -3878,20 +4674,20 @@
             access_ptr[0] = frag_ptr[idx];
           }
         }
       }
     } else {
       if(InstructionShape::kM == Policy::kStridedPerSTG) {
         CUTLASS_PRAGMA_UNROLL
-        for(int i = 0; i < frag.size(); ++i) {
+        for(int i = 0; i < int(frag.size()); ++i) {
           output_frag_f[i] = frag[i];
         }
       } else {
         CUTLASS_PRAGMA_UNROLL
-        for(int i = 0; i < frag.size(); ++i) {
+        for(int i = 0; i < int(frag.size()); ++i) {
           int map_i = (i / (16 * Policy::kPackedFactor)) * (16 * Policy::kPackedFactor)
                     + (i % (8 * Policy::kPackedFactor)) / 2 * 4
                     + (i % (8 * Policy::kPackedFactor)) % 2
                     + (i / (8 * Policy::kPackedFactor)) % 2 * 2;
           output_frag_f[i] = frag[map_i];
         }
       }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm_coord.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/gemm_coord.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm_coord.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/half.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/half.h`

 * *Files 1% similar despite different names*

```diff
@@ -30,24 +30,14 @@
  **************************************************************************************************/
 /*!
     \file
     \brief Defines a class for using IEEE half-precision floating-point types in host or
       device code.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #ifndef CUTLASS_ENABLE_F16C
 #define CUTLASS_ENABLE_F16C 0
 #endif
 
 #if defined(__CUDACC_RTC__)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_hardware_info.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,63 +24,35 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#pragma once
-
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
+/*! \file
+    \brief Templates implementing the address computation of storing of tiles
+   from pitch-linear rank=2 tensors.
 */
 
-#if !defined(__CUDACC_RTC__)
-#include "cuda_runtime.h"
+#pragma once
+
+#include "cutlass/cutlass.h"
 
-#include "cutlass/trace.h"
-#endif
+////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
+namespace transform {
+namespace threadblock {
 
-struct KernelHardwareInfo {
-  //
-  // Data members
-  //
-  int device_id = 0;
-  int sm_count  = 0;
-
-  //
-  // Methods
-  //
-
-#if !defined(__CUDACC_RTC__)
-  static inline int
-  query_device_multiprocessor_count(int device_id = 0) {
-    cudaError_t result = cudaGetDevice(&device_id);
-    if (result != cudaSuccess) {
-      CUTLASS_TRACE_HOST(
-        "  cudaGetDevice() returned error "
-        << cudaGetErrorString(result));
-      return 0;
-    }
-    int multiprocessor_count;
-    result = cudaDeviceGetAttribute(&multiprocessor_count,
-      cudaDevAttrMultiProcessorCount, device_id);
-    if (result != cudaSuccess) {
-      CUTLASS_TRACE_HOST(
-        "  cudaDeviceGetAttribute() returned error "
-        << cudaGetErrorString(result));
-      return 0;
-    }
-    return multiprocessor_count;
-  }
-#endif
-};
+////////////////////////////////////////////////////////////////////////////////
 
-} // namespace cutlass
+template <typename Shape, typename Element, typename Layout, int AdvanceRank,
+          typename ThreadMap,
+          int Alignment =
+              sizeof_bits<Element>::value* ThreadMap::kElementsPerAccess / 8>
+class RegularTileAccessIterator;
+
+////////////////////////////////////////////////////////////////////////////////
+
+}  // namespace threadblock
+}  // namespace transform
+}  // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,12 +24,7 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-#pragma once
-
-// Simply import .h version of header so as to avoid breaking any existing CUTLASS builds
-// after .hpp was changed to .h
-#include "cutlass/kernel_hardware_info.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/kernel_launch.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_launch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/layout.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/matrix.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/matrix.h`

 * *Files 1% similar despite different names*

```diff
@@ -34,24 +34,14 @@
     Layout functions map logical coordinates to linear memory. They often require additional
     data to describe strides between elements.
 
     Layout functions must implement all members in the public interface of IdentityTensorLayout<>
     defined in cutlass/tensor_ref.h.
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/pitch_linear_coord.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/permute.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/permute.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/pitch_linear.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/thread/matrix.h`

 * *Files 26% similar despite different names*

```diff
@@ -25,135 +25,174 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Defines layout functions used by TensorRef and derived classes for pitch-linear memory.
+    \brief Defines a matrix object intended for storing data in registers and operations within
+      a CUDA thread.
 */
-
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/coord.h"
-#include "cutlass/pitch_linear_coord.h"
+#include "cutlass/array.h"
+#include "cutlass/matrix_coord.h"
 
 namespace cutlass {
-namespace layout {
-
-template <int Contiguous, int Strided>
-  using PitchLinearShape = cutlass::PitchLinearShape < Contiguous, Strided >;
-  using PitchLinearCoord = PitchLinearCoord;
+namespace thread {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Mapping function for pitch-linear memory
-class PitchLinear {
+/// Per-thread matrix object storing a packed matrix
+template <
+  typename Element,
+  int Rows,
+  int Columns,
+  typename Layout = layout::RowMajor
+>
+class Matrix : public Array<Element, Rows * Columns> {
 public:
-  /// Logical rank of tensor
+  
+  // Verify layout refers to a rank=2 matrix.
+  static_assert(
+    Layout::kRank == 2,
+    "Layout type must refer to a rank=2 matrix");
+
+  /// Base type
+  using Base = Array<Element, Rows * Columns>;
+
+  /// Element type
+  using Element = Element_;
+
+  /// Number of rows
+  static int const kRows = Rows;
+
+  /// Number of columns
+  static int const kColumns = Columns;
+
+  /// Layout within the array
+  using Layout = Layout_;
+
+  /// Reference type to an element
+  using Reference = Element &;
+
+  /// Logical rank of tensor index space
   static int const kRank = 2;
 
-  /// Rank of stride vector
-  static int const kStrideRank = 1;
+  /// Index type
+  using Index = typename Layout::Index;
+
+  /// Long index used for pointer offsets
+  using LongIndex = typename Layout::LongIndex;
 
-  /// Index type used for coordinates
-  using Index = int32_t;
+  /// Coordinate in logical tensor space
+  using TensorCoord = typename Layout::TensorCoord;
 
-  /// Long index type used for offsets
-  using LongIndex = int64_t;
+  /// Stride type
+  using Stride = typename Layout::Stride;
 
-  /// Logical coordinate
-  using TensorCoord = PitchLinearCoord;
+  /// TensorRef to matrix object
+  using TensorRef = TensorRef<Element, kRank, Layout>;
 
-  /// Stride vector
-  using Stride = Coord<kStrideRank, LongIndex>;
+  /// TensorRef to constant matrix object
+  using ConstTensorRef = typename TensorRef::ConstTensorRef;
+
+  /// TensorRef to matrix object
+  using TensorView = TensorView<Element, kRank, Layout>;
+
+  /// TensorRef to constant matrix object
+  using ConstTensorView = typename TensorView::ConstTensorView;
+
+  /// Diagonal vector
+  using Diagonal = Vector<Element, __NV_STD_MIN(kRows, kColumns)>;
 
 private:
-  //
-  // Data members
-  //
 
-  /// Stride data member
-  Stride stride_;
 
 public:
+
   //
   // Methods
   //
-  
-  /// Constructor
-  CUTLASS_HOST_DEVICE
-  PitchLinear(LongIndex ldm = 0): stride_(ldm) { }
 
-  /// Constructor
+  /// Returns the size of the object
   CUTLASS_HOST_DEVICE
-  PitchLinear(Stride _stride): stride_(_stride) { }
+  static MatrixCoord extent() {
+    return make_Coord(kRows, kColumns);
+  }
 
-  /// Helper returns a layout to a tightly packed tensor
+  /// Returns the layout object
   CUTLASS_HOST_DEVICE
-  static PitchLinear packed(TensorCoord const &extent) {
-    return PitchLinear(extent.contiguous());
+  static Layout layout() {
+    return Layout::packed(extent());
   }
 
-  /// Returns the offset of a coordinate in linear memory. 
-  /// Assumes coordinate has convention (contiguous, strided)
+  /// Ctor
+  CUTLASS_HOST_DEVICE
+  Matrix() { }
+
+  /// Ctor
   CUTLASS_HOST_DEVICE
-  LongIndex operator()(TensorCoord const &coord) const {
-    return LongIndex(coord.contiguous()) + LongIndex(coord.strided()) * LongIndex(stride_[0]);
+  Matrix(Diagonal const &diag) {
   }
 
-  /// Returns the logical coordinate given an offset.
+  /// Returns a TensorRef pointing to the first element of the tensor.
   CUTLASS_HOST_DEVICE
-  TensorCoord inverse(LongIndex index) const {
-    return make_Coord(
-      TensorCoord::Index(index % stride_[0]),
-      TensorCoord::Index(index / stride_[0])
-    );
+  TensorRef ref() {
+    return TensorRef(this->data(), layout());
   }
 
-  /// Returns the stride of the layout
+  /// Returns a TensorRef pointing to the first element of the tensor.
   CUTLASS_HOST_DEVICE
-  Stride stride() const {
-    return stride_;
+  ConstTensorRef const_ref() const {
+    return ConstTensorRef(this->data(), layout());
   }
 
-  /// Returns the stride of the layout
+  /// Returns a TensorRef pointing to the first element of the tensor.
   CUTLASS_HOST_DEVICE
-  Stride & stride() {
-    return stride_;
+  TensorView view() {
+    return TensorView(ref(), extent());
   }
 
-  /// Returns the stride of the layout
+  /// Returns a TensorView to const data
   CUTLASS_HOST_DEVICE
-  LongIndex stride(int rank) const {
-    return stride_[rank];
+  ConstTensorView const_view() const {
+    return ConstTensorView(const_ref(), extent());
   }
 
-  /// Returns the stride of the layout
+  /// Returns a reference to the element at a given Coord
   CUTLASS_HOST_DEVICE
-  LongIndex & stride(int rank) {
-    return stride_[rank];
+  Reference at(MatrixCoord const& coord) const {
+    typename Base::size_type offset_(layout().offset(coord));
+    return Base::at(offset_);
   }
 
-  /// Compute the number of contiguous elements needed to store a tensor with the given size
+  /// Returns the number of scalar elements needed to store tensor.
   CUTLASS_HOST_DEVICE
-  LongIndex capacity(TensorCoord const &extent) const {
-    return extent.strided() * stride_[0];
+  LongIndex capacity() const {
+    return LongIndex(Base::size());
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace layout
-} // namespace cutlass
+/// Column vector defined as a matrix with exactly one column
+template <
+  typename Element,
+  int Rows,
+  typename Layout = layout::ColumnMajor
+>
+using ColumnVector = Matrix<Element, Rows, 1, Layout>;
+
+/// Row vector defined as a matrix with exactly one row
+template <
+  typename Element,
+  int Columns,
+  typename Layout = layout::RowMajor
+>
+using RowVector = Matrix<Element, 1, Columns, Layout>;
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace thread
+} // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor.h`

 * *Files 1% similar despite different names*

```diff
@@ -56,14 +56,22 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
 // Defines data layouts of various tensor formats usable by TensorRef and other classes.
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
+/// Tag used for 3-D NWC tensors for 1D conv, only used in 3.x API
+class TensorNWC {};
+
+/// Tag used for n-D KCSRT tensors for nD conv, only used in 3.x API for wgrad output layouts
+class TensorKCS {};
+class TensorKCSR {};
+class TensorKCSRT {};
+
 /// Mapping function for 4-D NHWC tensors.
 class TensorNHWC {
 public:
   /// Logical rank of tensor
   static int const kRank = 4;
 
   /// Rank of stride vector
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h`

 * *Files 2% similar despite different names*

```diff
@@ -256,14 +256,16 @@
 
   //
   // Static constants
   //
 
   static int const kElementSize = Base::kElementSize;
   static int const kElementsPerAccess = Base::kElementsPerAccess;
+  static int const kCrosswise = Base::kCrosswise;
+  static int const kFactor = Base::kFactor;
   using PartitionCount =  typename Base::PartitionCount;
   using AccessCount = typename Base::AccessCount;
 
  private:
   //
   // Data members
   //
@@ -365,14 +367,16 @@
       PitchLinearShape<PartitionShape::kContiguous, PartitionShape::kStrided>;
 
   //
   // Static constants
   //
   static int const kElementSize = 32;
   static int const kElementsPerAccess = kAccessSize / kElementSize;
+  static int const kCrosswise = Crosswise;
+  static int const kFactor = 1;
 
  private:
   //
   // Data members
   //
 
   /// Stride data member.
@@ -467,14 +471,16 @@
 
   //
   // Static constants
   //
 
   static int const kElementSize = Base::kElementSize;
   static int const kElementsPerAccess = Base::kElementsPerAccess;
+  static int const kCrosswise = Base::kCrosswise;
+  static int const kFactor = Base::kFactor;
   using PartitionCount =  typename Base::PartitionCount;
   using AccessCount = typename Base::AccessCount;
 
 private:
 
   //
   // Data members
@@ -572,14 +578,16 @@
 
   //
   // Static constants
   //
 
   static int const kElementSize = Base::kElementSize;
   static int const kElementsPerAccess = Base::kElementsPerAccess;
+  static int const kCrosswise = Base::kCrosswise;
+  static int const kFactor = Base::kFactor;
   using PartitionCount =  typename Base::PartitionCount;
   using AccessCount = typename Base::AccessCount;
 
 private:
 
   //
   // Data members
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/layout/vector.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/layout/vector.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix_coord.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/matrix_shape.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/matrix_shape.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_conversion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_conversion.h`

 * *Files 2% similar despite different names*

```diff
@@ -29,24 +29,14 @@
  *
  **************************************************************************************************/
 /*!
     \file
     \brief Boost-like numeric conversion operator for CUTLASS numeric types
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #if !defined(__CUDACC_RTC__)
 #include <cfenv>
 #endif
 
 #include "cutlass/cutlass.h"
@@ -283,15 +273,15 @@
   }
 };
 
 #endif
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for float <= half_t
+/// Partial specialization for float <= cutlass::half_t
 template <typename T, FloatRoundStyle Round>
 struct NumericConverter<T, T, Round> {
 
   using result_type = T;
   using source_type = T;
   static FloatRoundStyle const round_style = Round;
 
@@ -305,24 +295,24 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for float <=> half_t
+// Partial specializations for float <=> cutlass::half_t
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for float <= half_t
+/// Partial specialization for float <= cutlass::half_t
 template <FloatRoundStyle Round>
-struct NumericConverter<float, half_t, Round> {
+struct NumericConverter<float, cutlass::half_t, Round> {
 
   using result_type = float;
-  using source_type = half_t;
+  using source_type = cutlass::half_t;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     result_type result = static_cast<float>(s);
 
@@ -333,114 +323,114 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Specialization for round-to-nearest
 template <>
-struct NumericConverter<half_t, float, FloatRoundStyle::round_to_nearest> {
+struct NumericConverter<cutlass::half_t, float, FloatRoundStyle::round_to_nearest> {
 
-  using result_type = half_t;
+  using result_type = cutlass::half_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
-    result_type result = static_cast<half_t>(s);
+    result_type result = static_cast<cutlass::half_t>(s);
 
     return result;
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Specialization for round-toward-zero
 template <>
-struct NumericConverter<half_t, float, FloatRoundStyle::round_toward_zero> {
+struct NumericConverter<cutlass::half_t, float, FloatRoundStyle::round_toward_zero> {
 
-  using result_type = half_t;
+  using result_type = cutlass::half_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_toward_zero;
 
   /// Round toward zero
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & flt) {
 
   #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 530)
-    return half_t(__float2half_rz(flt));
+    return cutlass::half_t(__float2half_rz(flt));
   #else
     // software implementation rounds toward nearest even
     unsigned const& s = reinterpret_cast<unsigned const &>(flt);
     uint16_t sign = uint16_t((s >> 16) & 0x8000);
     int32_t exp = int32_t((s >> 23) & 0xff) - 127;
     int mantissa = s & 0x7fffff;
     uint16_t u = 0;
 
     if ((s & 0x7fffffff) == 0) {
       // sign-preserving zero
-      return half_t::bitcast(sign);
+      return cutlass::half_t::bitcast(sign);
     }
 
     if (exp > 15) {
       if (exp == 128 && mantissa) {
         // not a number
         u = 0x7fff;
       } else {
         // overflow to infinity
         u = sign | 0x7c00;
       }
-      return half_t::bitcast(u);
+      return cutlass::half_t::bitcast(u);
     }
 
     if (exp >= -14) {
       // normal fp32 to normal fp16
       u = uint16_t((uint32_t(exp + 15) & 0x1f) << 10);
       u = uint16_t(u | (mantissa >> 13));
     } else {
-      // normal single-precision to subnormal half_t-precision representation
+      // normal single-precision to subnormal cutlass::half_t-precision representation
       int rshift = (-14 - exp);
       if (rshift < 32) {
         mantissa |= (1 << 23);
         mantissa = (mantissa >> rshift);
         u = (uint16_t(mantissa >> 13) & 0x3ff);
       } else {
         mantissa = 0;
         u = 0;
       }
     }
 
     u |= sign;
 
-    return half_t::bitcast(u);
+    return cutlass::half_t::bitcast(u);
 
   #endif // defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 530)
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for float <=> bfloat16_t
+// Partial specializations for float <=> cutlass::bfloat16_t
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for float <= bfloat16_t
+/// Partial specialization for float <= cutlass::bfloat16_t
 template <FloatRoundStyle Round>
-struct NumericConverter<float, bfloat16_t, Round> {
+struct NumericConverter<float, cutlass::bfloat16_t, Round> {
 
   using result_type = float;
-  using source_type = bfloat16_t;
+  using source_type = cutlass::bfloat16_t;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     return static_cast<float>(s);
   }
@@ -448,33 +438,33 @@
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<bfloat16_t, float, FloatRoundStyle::round_to_nearest> {
-  using result_type = bfloat16_t;
+struct NumericConverter<cutlass::bfloat16_t, float, FloatRoundStyle::round_to_nearest> {
+  using result_type = cutlass::bfloat16_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
-    return static_cast<bfloat16_t>(s);
+    return static_cast<cutlass::bfloat16_t>(s);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<bfloat16_t, float, FloatRoundStyle::round_half_ulp_truncate> {
-  using result_type = bfloat16_t;
+struct NumericConverter<cutlass::bfloat16_t, float, FloatRoundStyle::round_half_ulp_truncate> {
+  using result_type = cutlass::bfloat16_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_half_ulp_truncate;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
     uint32_t x32 = reinterpret_cast<uint32_t const &>(s);
 
@@ -485,56 +475,56 @@
     #else
     if (std::isfinite(s)) {
       x32 += 0x8000;
     }
     #endif
 
     uint16_t x16 = uint16_t((x32 >> 16) & 0xffff);
-    return bfloat16_t::bitcast(x16);
+    return cutlass::bfloat16_t::bitcast(x16);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<bfloat16_t, float, FloatRoundStyle::round_toward_zero> {
-  using result_type = bfloat16_t;
+struct NumericConverter<cutlass::bfloat16_t, float, FloatRoundStyle::round_toward_zero> {
+  using result_type = cutlass::bfloat16_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_toward_zero;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     uint32_t x32 = reinterpret_cast<uint32_t const &>(s);
     uint16_t x16 = uint16_t(x32 >> 16);
 
-    return bfloat16_t::bitcast(x16);
+    return cutlass::bfloat16_t::bitcast(x16);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for float <=> tfloat32_t
+// Partial specializations for float <=> cutlass::tfloat32_t
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for float <= tfloat32_t
+/// Partial specialization for float <= cutlass::tfloat32_t
 template <FloatRoundStyle Round>
-struct NumericConverter<float, tfloat32_t, Round> {
+struct NumericConverter<float, cutlass::tfloat32_t, Round> {
 
   using result_type = float;
-  using source_type = tfloat32_t;
+  using source_type = cutlass::tfloat32_t;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     return static_cast<float>(s);
   }
@@ -542,16 +532,16 @@
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<tfloat32_t, float, FloatRoundStyle::round_to_nearest> {
-  using result_type = tfloat32_t;
+struct NumericConverter<cutlass::tfloat32_t, float, FloatRoundStyle::round_to_nearest> {
+  using result_type = cutlass::tfloat32_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     unsigned storage = reinterpret_cast<unsigned const &>(s);
@@ -582,45 +572,45 @@
       // storage = (storage & ~0x1fff);
     }
     else if (storage & ~0xff800000) {
       storage = 0x7fffffff;
     }
 #endif
 
-    return tfloat32_t::bitcast(storage);
+    return cutlass::tfloat32_t::bitcast(storage);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<tfloat32_t, float, FloatRoundStyle::round_half_ulp_truncate> {
-  using result_type = tfloat32_t;
+struct NumericConverter<cutlass::tfloat32_t, float, FloatRoundStyle::round_half_ulp_truncate> {
+  using result_type = cutlass::tfloat32_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_half_ulp_truncate;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
-    return tfloat32_t::round_half_ulp_truncate(s);
+    return cutlass::tfloat32_t::round_half_ulp_truncate(s);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// This rounding operation is similar to half_ulp_truncate except it rounds denorms toward zero.
 /// It avoids predicated code, though it requires a temporary register.
 template <>
-struct NumericConverter<tfloat32_t, float, FloatRoundStyle::round_half_ulp_trunc_dntz> {
-  using result_type = tfloat32_t;
+struct NumericConverter<cutlass::tfloat32_t, float, FloatRoundStyle::round_half_ulp_trunc_dntz> {
+  using result_type = cutlass::tfloat32_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_half_ulp_trunc_dntz;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
 
     unsigned y = reinterpret_cast<unsigned const &>(s);
@@ -634,63 +624,63 @@
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 template <>
-struct NumericConverter<tfloat32_t, float, FloatRoundStyle::round_toward_zero> {
-  using result_type = tfloat32_t;
+struct NumericConverter<cutlass::tfloat32_t, float, FloatRoundStyle::round_toward_zero> {
+  using result_type = cutlass::tfloat32_t;
   using source_type = float;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_toward_zero;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & s) {
     uint32_t x = reinterpret_cast<uint32_t const &>(s);
-    return tfloat32_t::bitcast(x & 0xffffe000);
+    return cutlass::tfloat32_t::bitcast(x & 0xffffe000);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Conversion operator for float to tfloat32_t big and small values
+// Conversion operator for float to cutlass::tfloat32_t big and small values
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 template <
   FloatRoundStyle RoundBig = FloatRoundStyle::round_toward_zero,
   FloatRoundStyle RoundSmall = FloatRoundStyle::round_half_ulp_truncate
 >
 struct NumericConverterFastF32 {
 
-  // result_type holds big tfloat32_t at idx(0) and small tfloat32_t at idx(1)
-  using result_type = Array<tfloat32_t, 2>;
+  // result_type holds big cutlass::tfloat32_t at idx(0) and small cutlass::tfloat32_t at idx(1)
+  using result_type = Array<cutlass::tfloat32_t, 2>;
 
   // source data type
   using source_type = float;
 
   // rounding styles for big and small part
   static FloatRoundStyle const kRoundBig = RoundBig;
   static FloatRoundStyle const kRoundSmall = RoundSmall;
 
   CUTLASS_HOST_DEVICE
     static result_type convert(source_type const & source) {
 
     result_type result;
-    NumericConverter<tfloat32_t, float, kRoundBig> convert_big_;
-    NumericConverter<tfloat32_t, float, kRoundSmall> convert_small_;
+    NumericConverter<cutlass::tfloat32_t, float, kRoundBig> convert_big_;
+    NumericConverter<cutlass::tfloat32_t, float, kRoundSmall> convert_small_;
 
-    // convert and fill tfloat32_t big at idx 0
+    // convert and fill cutlass::tfloat32_t big at idx 0
     result[0] = convert_big_(source);
 
-    // convert and fill tfloat32_t small at idx 1
+    // convert and fill cutlass::tfloat32_t small at idx 1
     result[1] = convert_small_(source - static_cast<float>(result[0]));
 
     return result;
   }
 
   CUTLASS_HOST_DEVICE
     result_type operator()(source_type const &s) const {
@@ -727,17 +717,17 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-// This converter is needed to enable half_t output types when using int32_t accumulators.
+// This converter is needed to enable cutlass::half_t output types when using int32_t accumulators.
 // Since floating-point types do not require a clamp, this converter simply casts from
-// the source type to half_t.
+// the source type to cutlass::half_t.
 template <
   typename S
 >
 struct NumericConverterClamp<cutlass::half_t, S> {
 
   using result_type = cutlass::half_t;
   using source_type = S;
@@ -836,64 +826,69 @@
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Array<half, 2> <= Array<float, 2>, round to nearest
 template <>
-struct NumericArrayConverter<half_t, float, 2, FloatRoundStyle::round_to_nearest> {
+struct NumericArrayConverter<cutlass::half_t, float, 2, FloatRoundStyle::round_to_nearest> {
 
-  using result_type = Array<half_t, 2>;
+  using result_type = Array<cutlass::half_t, 2>;
   using source_type = Array<float, 2>;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
-
-    Array<half_t, 2> result;
-
     #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 530)
+      Array<cutlass::half_t, 2> result;
       reinterpret_cast<__half2 &>(result) = __float22half2_rn(reinterpret_cast<float2 const &>(source));
+      return result;
     #else
-      NumericConverter<half_t, float, round_style> convert_;
+      NumericConverter<cutlass::half_t, float, round_style> convert_;
+      // NOTE: cutlass::Array<half, N> is NOT an aggregate type and
+      //  below `{}` does NOT conduct zero initialization. Below `{}` will 
+      //  conduct default initialization (calling default ctr). We use this syntax
+      //  to resolve compiler warning on uninitialized member variable.
+      Array<cutlass::half_t, 2> result{};
       result[0] = convert_(source[0]);
       result[1] = convert_(source[1]);
+      return result;
     #endif
-
-    return result;
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<float, 2> <= Array<half_t, 2>, round to nearest
+/// Partial specialization for Array<float, 2> <= Array<cutlass::half_t, 2>, round to nearest
 template <FloatRoundStyle Round>
-struct NumericArrayConverter<float, half_t, 2, Round> {
+struct NumericArrayConverter<float, cutlass::half_t, 2, Round> {
 
   using result_type = Array<float, 2>;
-  using source_type = Array<half_t, 2>;
+  using source_type = Array<cutlass::half_t, 2>;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
 
-    Array<float, 2> result;
-
     #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 530)
-      reinterpret_cast<float2 &>(result) = __half22float2(reinterpret_cast<__half2 const &>(source));
+      float2 result2 = __half22float2(reinterpret_cast<__half2 const &>(source));
+      return {
+        float{result2.x},
+        float{result2.y}
+      };
     #else
-      NumericConverter<float, half_t, round_style> convert_;
-      result[0] = convert_(source[0]);
-      result[1] = convert_(source[1]);
+      NumericConverter<float, cutlass::half_t, round_style> convert_;
+      return {
+        convert_(source[0]),
+        convert_(source[1])
+      };
     #endif
-
-    return result;
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
@@ -901,29 +896,29 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Array<half> <= Array<float>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<half_t, float, N, Round> {
+struct NumericArrayConverter<cutlass::half_t, float, N, Round> {
 
-  using result_type = Array<half_t, N>;
+  using result_type = Array<cutlass::half_t, N>;
   using source_type = Array<float, N>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
 
-    NumericArrayConverter<half_t, float, 2, Round> convert_vector_;
-    NumericConverter<half_t, float, Round> convert_element_;
+    NumericArrayConverter<cutlass::half_t, float, 2, Round> convert_vector_;
+    NumericConverter<cutlass::half_t, float, Round> convert_element_;
 
     result_type result;
 
-    Array<half_t, 2> *result_ptr = reinterpret_cast<Array<half_t, 2> *>(&result);
+    Array<cutlass::half_t, 2> *result_ptr = reinterpret_cast<Array<cutlass::half_t, 2> *>(&result);
     Array<float, 2> const *source_ptr = reinterpret_cast<Array<float, 2> const *>(&source);
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < N / 2; ++i) {
       result_ptr[i] = convert_vector_(source_ptr[i]);
     }
 
@@ -942,30 +937,30 @@
 
 
 /// Partial specialization for Array<half> <= Array<float>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float, half_t, N, Round> {
+struct NumericArrayConverter<float, cutlass::half_t, N, Round> {
 
   using result_type = Array<float, N>;
-  using source_type = Array<half_t, N>;
+  using source_type = Array<cutlass::half_t, N>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
 
-    NumericArrayConverter<float, half_t, 2, Round> convert_vector_;
-    NumericConverter<float, half_t, Round> convert_element_;
+    NumericArrayConverter<float, cutlass::half_t, 2, Round> convert_vector_;
+    NumericConverter<float, cutlass::half_t, Round> convert_element_;
 
     result_type result;
 
     Array<float, 2> *result_ptr = reinterpret_cast<Array<float, 2> *>(&result);
-    Array<half_t, 2> const *source_ptr = reinterpret_cast<Array<half_t, 2> const *>(&source);
+    Array<cutlass::half_t, 2> const *source_ptr = reinterpret_cast<Array<cutlass::half_t, 2> const *>(&source);
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < N / 2; ++i) {
       result_ptr[i] = convert_vector_(source_ptr[i]);
     }
 
     if (N % 2) {
@@ -982,19 +977,19 @@
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Array<bfloat16_t, 2> <= Array<float, 2>, round to nearest
+/// Partial specialization for Array<cutlass::bfloat16_t, 2> <= Array<float, 2>, round to nearest
 template <>
-struct NumericArrayConverter<bfloat16_t, float, 2, FloatRoundStyle::round_to_nearest> {
+struct NumericArrayConverter<cutlass::bfloat16_t, float, 2, FloatRoundStyle::round_to_nearest> {
 
-  using result_type = Array<bfloat16_t, 2>;
+  using result_type = Array<cutlass::bfloat16_t, 2>;
   using source_type = Array<float, 2>;
   static FloatRoundStyle const round_style = FloatRoundStyle::round_to_nearest;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
 
     unsigned d;
@@ -1006,34 +1001,34 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<bfloat16_t> <= Array<float>
+/// Partial specialization for Array<cutlass::bfloat16_t> <= Array<float>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<bfloat16_t, float, N, Round> {
+struct NumericArrayConverter<cutlass::bfloat16_t, float, N, Round> {
 
-  using result_type = Array<bfloat16_t, N>;
+  using result_type = Array<cutlass::bfloat16_t, N>;
   using source_type = Array<float, N>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
 
-    NumericArrayConverter<bfloat16_t, float, 2, Round> convert_vector_;
-    NumericConverter<bfloat16_t, float, Round> convert_element_;
+    NumericArrayConverter<cutlass::bfloat16_t, float, 2, Round> convert_vector_;
+    NumericConverter<cutlass::bfloat16_t, float, Round> convert_element_;
 
     result_type result;
 
-    Array<bfloat16_t, 2> *result_ptr = reinterpret_cast<Array<bfloat16_t, 2> *>(&result);
+    Array<cutlass::bfloat16_t, 2> *result_ptr = reinterpret_cast<Array<cutlass::bfloat16_t, 2> *>(&result);
     Array<float, 2> const *source_ptr = reinterpret_cast<Array<float, 2> const *>(&source);
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < N / 2; ++i) {
       result_ptr[i] = convert_vector_(source_ptr[i]);
     }
 
@@ -1313,17 +1308,17 @@
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Array<float, 2> <= Array<float_e4m3_t, 2>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float, float_e4m3_t, 2, Round> {
+struct NumericArrayConverter<float, cutlass::float_e4m3_t, 2, Round> {
   using result_element = float;
-  using source_element = float_e4m3_t;
+  using source_element = cutlass::float_e4m3_t;
 
   using result_type = Array<result_element, 2>;
   using source_type = Array<source_element, 2>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1363,15 +1358,15 @@
 };
 
 /// Partial specialization for Array<float_e4m3_t, 2> <= Array<float, 2>
 template <
   FloatRoundStyle Round
 >
 struct NumericArrayConverter<float_e4m3_t, float, 2, Round> {
-  using result_element = float_e4m3_t;
+  using result_element = cutlass::float_e4m3_t;
   using source_element = float;
 
   using result_type = Array<result_element, 2>;
   using source_type = Array<source_element, 2>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
@@ -1406,17 +1401,17 @@
   }
 };
 
 /// Partial specialization for Array<float, 2> <= Array<float_e5m2_t, 2>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float, float_e5m2_t, 2, Round> {
+struct NumericArrayConverter<float, cutlass::float_e5m2_t, 2, Round> {
   using result_element = float;
-  using source_element = float_e5m2_t;
+  using source_element = cutlass::float_e5m2_t;
 
   using result_type = Array<result_element, 2>;
   using source_type = Array<source_element, 2>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1478,15 +1473,15 @@
 
     result_type result;
     NumericConverter<T, S, Round> convert_;
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < 4; ++i) {
       if (platform::is_same<Transform, cutlass::transform::thread::UnaryTransform::Identity>::value) {
         result[i] = convert_(s[i]);
-      } 
+      }
       else { // conjugate
         result[i] = conj(convert_(s[i]));
       }
     }
 
     return result;
   }
@@ -1497,17 +1492,17 @@
   }
 };
 
 /// Partial specialization for Array<float, 4> <= Array<float_e4m3_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float, float_e4m3_t, Round> {
+struct NumericArrayConverterPacked4Element<float, cutlass::float_e4m3_t, Round> {
   using result_element = float;
-  using source_element = float_e4m3_t;
+  using source_element = cutlass::float_e4m3_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1553,15 +1548,15 @@
 };
 
 /// Partial specialization for Array<float_e4m3_t, 4> <= Array<float, 4>
 template <
   FloatRoundStyle Round
 >
 struct NumericArrayConverterPacked4Element<float_e4m3_t, float, Round> {
-  using result_element = float_e4m3_t;
+  using result_element = cutlass::float_e4m3_t;
   using source_element = float;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
@@ -1606,17 +1601,17 @@
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Array<float, 4> <= Array<float_e5m2_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float, float_e5m2_t, Round> {
+struct NumericArrayConverterPacked4Element<float, cutlass::float_e5m2_t, Round> {
   using result_element = float;
-  using source_element = float_e5m2_t;
+  using source_element = cutlass::float_e5m2_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1662,15 +1657,15 @@
 };
 
 /// Partial specialization for Array<float_e5m2_t, 4> <= Array<float, 4>
 template <
   FloatRoundStyle Round
 >
 struct NumericArrayConverterPacked4Element<float_e5m2_t, float, Round> {
-  using result_element = float_e5m2_t;
+  using result_element = cutlass::float_e5m2_t;
   using source_element = float;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
@@ -1707,25 +1702,25 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for Array<half_t, 4> <=> Array<float_e4m3_t, 4>
+// Partial specializations for Array<cutlass::half_t, 4> <=> Array<float_e4m3_t, 4>
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Array<half_t, 4> <= Array<float_e4m3_t, 4>
+/// Partial specialization for Array<cutlass::half_t, 4> <= Array<float_e4m3_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<half_t, float_e4m3_t, Round> {
-  using result_element = half_t;
-  using source_element = float_e4m3_t;
+struct NumericArrayConverterPacked4Element<cutlass::half_t, cutlass::float_e4m3_t, Round> {
+  using result_element = cutlass::half_t;
+  using source_element = cutlass::float_e4m3_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1756,21 +1751,21 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<float_e4m3_t, 4> <= Array<half_t, 4>
+/// Partial specialization for Array<float_e4m3_t, 4> <= Array<cutlass::half_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e4m3_t, half_t, Round> {
-  using result_element = float_e4m3_t;
-  using source_element = half_t;
+struct NumericArrayConverterPacked4Element<float_e4m3_t, cutlass::half_t, Round> {
+  using result_element = cutlass::float_e4m3_t;
+  using source_element = cutlass::half_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1807,25 +1802,25 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for Array<half_t, 4> <=> Array<float_e5m2_t, 4>
+// Partial specializations for Array<cutlass::half_t, 4> <=> Array<float_e5m2_t, 4>
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Array<half_t, 4> <= Array<float_e5m2_t, 4>
+/// Partial specialization for Array<cutlass::half_t, 4> <= Array<float_e5m2_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<half_t, float_e5m2_t, Round> {
-  using result_element = half_t;
-  using source_element = float_e5m2_t;
+struct NumericArrayConverterPacked4Element<cutlass::half_t, cutlass::float_e5m2_t, Round> {
+  using result_element = cutlass::half_t;
+  using source_element = cutlass::float_e5m2_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1856,21 +1851,21 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<float_e5m2_t, 4> <= Array<half_t, 4>
+/// Partial specialization for Array<float_e5m2_t, 4> <= Array<cutlass::half_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e5m2_t, half_t, Round> {
-  using result_element = float_e5m2_t;
-  using source_element = half_t;
+struct NumericArrayConverterPacked4Element<float_e5m2_t, cutlass::half_t, Round> {
+  using result_element = cutlass::float_e5m2_t;
+  using source_element = cutlass::half_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1907,25 +1902,25 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for Array<bfloat16_t, 4> <=> Array<float_e4m3_t, 4>
+// Partial specializations for Array<cutlass::bfloat16_t, 4> <=> Array<float_e4m3_t, 4>
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Array<bfloat16_t, 4> <= Array<float_e4m3_t, 4>
+/// Partial specialization for Array<cutlass::bfloat16_t, 4> <= Array<float_e4m3_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<bfloat16_t, float_e4m3_t, Round> {
-  using result_element = bfloat16_t;
-  using source_element = float_e4m3_t;
+struct NumericArrayConverterPacked4Element<cutlass::bfloat16_t, cutlass::float_e4m3_t, Round> {
+  using result_element = cutlass::bfloat16_t;
+  using source_element = cutlass::float_e4m3_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -1959,21 +1954,21 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<float_e4m3_t, 4> <= Array<bfloat16_t, 4>
+/// Partial specialization for Array<float_e4m3_t, 4> <= Array<cutlass::bfloat16_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e4m3_t, bfloat16_t, Round> {
-  using result_element = float_e4m3_t;
-  using source_element = bfloat16_t;
+struct NumericArrayConverterPacked4Element<float_e4m3_t, cutlass::bfloat16_t, Round> {
+  using result_element = cutlass::float_e4m3_t;
+  using source_element = cutlass::bfloat16_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -2007,25 +2002,25 @@
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
-// Partial specializations for Array<bfloat16_t, 4> <=> Array<float_e5m2_t, 4>
+// Partial specializations for Array<cutlass::bfloat16_t, 4> <=> Array<float_e5m2_t, 4>
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for Array<bfloat16_t, 4> <= Array<float_e5m2_t, 4>
+/// Partial specialization for Array<cutlass::bfloat16_t, 4> <= Array<float_e5m2_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<bfloat16_t, float_e5m2_t, Round> {
-  using result_element = bfloat16_t;
-  using source_element = float_e5m2_t;
+struct NumericArrayConverterPacked4Element<cutlass::bfloat16_t, cutlass::float_e5m2_t, Round> {
+  using result_element = cutlass::bfloat16_t;
+  using source_element = cutlass::float_e5m2_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -2059,21 +2054,21 @@
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
-/// Partial specialization for Array<float_e5m2_t, 4> <= Array<bfloat16_t, 4>
+/// Partial specialization for Array<float_e5m2_t, 4> <= Array<cutlass::bfloat16_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e5m2_t, bfloat16_t, Round> {
-  using result_element = float_e5m2_t;
-  using source_element = bfloat16_t;
+struct NumericArrayConverterPacked4Element<float_e5m2_t, cutlass::bfloat16_t, Round> {
+  using result_element = cutlass::float_e5m2_t;
+  using source_element = cutlass::bfloat16_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -2115,17 +2110,17 @@
 //
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for Array<float_e4m3_t, 4> <= Array<float_e5m2_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e4m3_t, float_e5m2_t, Round> {
-  using result_element = float_e4m3_t;
-  using source_element = float_e5m2_t;
+struct NumericArrayConverterPacked4Element<float_e4m3_t, cutlass::float_e5m2_t, Round> {
+  using result_element = cutlass::float_e4m3_t;
+  using source_element = cutlass::float_e5m2_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -2146,17 +2141,17 @@
   }
 };
 
 /// Partial specialization for Array<float_e5m2_t, 4> <= Array<float_e4m3_t, 4>
 template <
   FloatRoundStyle Round
 >
-struct NumericArrayConverterPacked4Element<float_e5m2_t, float_e4m3_t, Round> {
-  using result_element = float_e5m2_t;
-  using source_element = float_e4m3_t;
+struct NumericArrayConverterPacked4Element<float_e5m2_t, cutlass::float_e4m3_t, Round> {
+  using result_element = cutlass::float_e5m2_t;
+  using source_element = cutlass::float_e4m3_t;
 
   using result_type = Array<result_element, 4>;
   using source_type = Array<source_element, 4>;
   static FloatRoundStyle const round_style = Round;
 
   CUTLASS_DEVICE
   static result_type convert(source_type const & source) {
@@ -2240,25 +2235,25 @@
 
 /// Partial specialization for Array<T, N> <= Array<float_e4m3_t, N>
 template <
   typename T,
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<T, float_e4m3_t, N, Round> :
-  public PackedNumericArrayConverter<T, float_e4m3_t, N, Round> {};
+struct NumericArrayConverter<T, cutlass::float_e4m3_t, N, Round> :
+  public PackedNumericArrayConverter<T, cutlass::float_e4m3_t, N, Round> {};
 
 /// Partial specialization for Array<T, N> <= Array<float_e5m2_t, N>
 template <
   typename T,
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<T, float_e5m2_t, N, Round> :
-  public PackedNumericArrayConverter<T, float_e5m2_t, N, Round> {};
+struct NumericArrayConverter<T, cutlass::float_e5m2_t, N, Round> :
+  public PackedNumericArrayConverter<T, cutlass::float_e5m2_t, N, Round> {};
 
 /// Partial specialization for Array<float_e4m3_t, N> <= Array<S, N>
 template <
   typename S,
   int N,
   FloatRoundStyle Round
 >
@@ -2275,78 +2270,188 @@
   public PackedNumericArrayConverter<float_e5m2_t, S, N, Round> {};
 
 /// Partial specialization for Array<float_e4m3_t, N> <= Array<float_e5m2_t, N>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float_e4m3_t, float_e5m2_t, N, Round> :
-  public PackedNumericArrayConverter<float_e4m3_t, float_e5m2_t, N, Round> {};
+struct NumericArrayConverter<float_e4m3_t, cutlass::float_e5m2_t, N, Round> :
+  public PackedNumericArrayConverter<float_e4m3_t, cutlass::float_e5m2_t, N, Round> {};
 
 /// Partial specialization for Array<float_e5m2_t, N> <= Array<float_e4m3_t, N>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float_e5m2_t, float_e4m3_t, N, Round> :
-  public PackedNumericArrayConverter<float_e5m2_t, float_e4m3_t, N, Round> {};
+struct NumericArrayConverter<float_e5m2_t, cutlass::float_e4m3_t, N, Round> :
+  public PackedNumericArrayConverter<float_e5m2_t, cutlass::float_e4m3_t, N, Round> {};
 
 /// Partial specialization for Array<float_e4m3_t, N> <= Array<float_e4m3_t, N>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float_e4m3_t, float_e4m3_t, N, Round> :
-  public PackedNumericArrayConverter<float_e4m3_t, float_e4m3_t, N, Round> {};
+struct NumericArrayConverter<float_e4m3_t, cutlass::float_e4m3_t, N, Round> :
+  public PackedNumericArrayConverter<float_e4m3_t, cutlass::float_e4m3_t, N, Round> {};
 
 /// Partial specialization for Array<float_e5m2_t, N> <= Array<float_e5m2_t, N>
 template <
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<float_e5m2_t, float_e5m2_t, N, Round> :
-  public PackedNumericArrayConverter<float_e5m2_t, float_e5m2_t, N, Round> {};
-
-
+struct NumericArrayConverter<float_e5m2_t, cutlass::float_e5m2_t, N, Round> :
+  public PackedNumericArrayConverter<float_e5m2_t, cutlass::float_e5m2_t, N, Round> {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-
 /// Partial specialization for Array<int8_t> <= Array<float>
 /// Conversion is performed with saturation regardless of setting of
 /// the `Round` template parameter.
 template <
+  FloatRoundStyle Round
+>
+struct NumericArrayConverter<int8_t, float, 1, Round> {
+
+  using result_type = Array<int8_t, 1>;
+  using source_type = Array<float, 1>;
+  static FloatRoundStyle const round_style = Round;
+
+  CUTLASS_HOST_DEVICE
+  static result_type convert(source_type const & source) {
+    // Convert to int to int8_t
+    NumericConverter<int8_t, float, Round> destination_converter;
+    result_type result;
+    result[0] = destination_converter(source[0]);
+    return result;
+  }
+
+  CUTLASS_HOST_DEVICE
+  result_type operator()(source_type const &s) const {
+    return convert(s);
+  }
+};
+
+// To convert a FP32 to Int that has less than 32 bits, we need to convert it to int32 first.
+template <
+  typename T,
   int N,
   FloatRoundStyle Round
 >
-struct NumericArrayConverter<int8_t, float, N, Round> {
+struct NumericArrayFP32ToIntConverter {
 
-  using result_type = Array<int8_t, N>;
+  using result_type = Array<T, N>;
   using source_type = Array<float, N>;
   static FloatRoundStyle const round_style = Round;
 
+  static_assert(platform::numeric_limits<T>::is_integer, "the dest type has to be int.");
+
   CUTLASS_HOST_DEVICE
   static result_type convert(source_type const & source) {
     // Convert float to int
     Array<int32_t, N> temporary;
 
-    NumericArrayConverter<int, float, N, Round> compute_converter;
+    NumericArrayConverter<int32_t, float, N, Round> compute_converter;
     temporary = compute_converter(source);
 
     // Convert to int to int8_t
-    NumericArrayConverter<int8_t, int32_t, N, Round> destination_converter;
+    NumericArrayConverter<T, int32_t, N, Round> destination_converter;
     return destination_converter(temporary);
   }
 
   CUTLASS_HOST_DEVICE
   result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
+
+template <
+  int N,
+  FloatRoundStyle Round
+>
+struct NumericArrayConverter<int8_t, float, N, Round> {
+
+  using result_type = Array<int8_t, N>;
+  using source_type = Array<float, N>;
+
+  CUTLASS_HOST_DEVICE
+  static result_type convert(source_type const & source) {
+    NumericArrayFP32ToIntConverter<int8_t, N, Round> converter;
+    return converter(source);
+  }
+
+  CUTLASS_HOST_DEVICE
+  result_type operator()(source_type const &s) const {
+    return convert(s);
+  }
+};
+
+template <
+  int N,
+  FloatRoundStyle Round
+>
+struct NumericArrayConverter<uint8_t, float, N, Round> {
+
+  using result_type = Array<uint8_t, N>;
+  using source_type = Array<float, N>;
+
+  CUTLASS_HOST_DEVICE
+  static result_type convert(source_type const & source) {
+    NumericArrayFP32ToIntConverter<uint8_t, N, Round> converter;
+    return converter(source);
+  }
+
+  CUTLASS_HOST_DEVICE
+  result_type operator()(source_type const &s) const {
+    return convert(s);
+  }
+};
+
+template <
+  int N,
+  FloatRoundStyle Round
+>
+struct NumericArrayConverter<int4b_t, float, N, Round> {
+
+  using result_type = Array<int4b_t, N>;
+  using source_type = Array<float, N>;
+
+  CUTLASS_HOST_DEVICE
+  static result_type convert(source_type const & source) {
+    NumericArrayFP32ToIntConverter<int4b_t, N, Round> converter;
+    return converter(source);
+  }
+
+  CUTLASS_HOST_DEVICE
+  result_type operator()(source_type const &s) const {
+    return convert(s);
+  }
+};
+
+template <
+  int N,
+  FloatRoundStyle Round
+>
+struct NumericArrayConverter<uint4b_t, float, N, Round> {
+
+  using result_type = Array<uint4b_t, N>;
+  using source_type = Array<float, N>;
+
+  CUTLASS_HOST_DEVICE
+  static result_type convert(source_type const & source) {
+    NumericArrayFP32ToIntConverter<uint4b_t, N, Round> converter;
+    return converter(source);
+  }
+
+  CUTLASS_HOST_DEVICE
+  result_type operator()(source_type const &s) const {
+    return convert(s);
+  }
+};
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 750) && \
     ((__CUDACC_VER_MAJOR__ > 10) ||                     \
      ((__CUDACC_VER_MAJOR__ >= 10) && (__CUDACC_VER_MINOR__ >= 2)))
 
 /// Partial specialization for Array<int4b_t, 8> <= Array<int, 8>
@@ -2504,15 +2609,15 @@
     */
   class VectorizedConverter {
   private:
     // Base case to handle remainder elements as scalars.
     template <int Offset, size_t ParentWidth, typename ArrayConverter>
     CUTLASS_DEVICE
     static void convert_helper(
-      typename ArrayConverter::result_type& result, 
+      typename ArrayConverter::result_type& result,
       typename ArrayConverter::source_type const& source) {
 
       using ElementRes = typename ArrayConverter::result_type::Element;
       using ElementSrc = typename ArrayConverter::source_type::Element;
       // If no more converters, handle the remaining elements as scalars.
       constexpr int total_elements = ArrayConverter::result_type::kElements;
       constexpr int remainder = total_elements - Offset;
@@ -2526,22 +2631,22 @@
     }
 
     template <int Offset, size_t ParentWidth, typename ArrayConverter, typename ResultVectorArray, typename SourceVectorArray, typename... OtherVectorArrays>
     CUTLASS_DEVICE
     static void convert_helper(typename ArrayConverter::result_type& result, typename ArrayConverter::source_type const& source) {
       static_assert(sizeof...(OtherVectorArrays) % 2 == 0, "Vector converters must come in {dst, src} pairs");
       static_assert(ResultVectorArray::kElements == SourceVectorArray::kElements, "Vector converters must have the same vector width");
-      static_assert(cutlass::platform::is_same<typename ArrayConverter::result_type::Element, typename ResultVectorArray::Element>::value, 
+      static_assert(cutlass::platform::is_same<typename ArrayConverter::result_type::Element, typename ResultVectorArray::Element>::value,
         "ResultVectorArray must have the same type ArrayConverter::result_type");
-      static_assert(cutlass::platform::is_same<typename ArrayConverter::source_type::Element, typename SourceVectorArray::Element>::value, 
+      static_assert(cutlass::platform::is_same<typename ArrayConverter::source_type::Element, typename SourceVectorArray::Element>::value,
         "SourceVectorArray must have the same type ArrayConverter::result_type");
       static_assert(Offset >= 0 && Offset <= ArrayConverter::result_type::kElements, "Offset must be between 0 and N");
 
       static_assert(ParentWidth == 0 || ParentWidth > ResultVectorArray::kElements, "Vector arrays must be given in decreasing order of width");
-      
+
       constexpr int vector_width = ResultVectorArray::kElements;
       static_assert(ispow2(vector_width), "Vector width must be a power of 2");
 
       using ElementRes = typename ArrayConverter::result_type::Element;
       using ElementSrc = typename ArrayConverter::source_type::Element;
 
       constexpr int vector_bits_res = vector_width * cutlass::sizeof_bits<ElementRes>::value;
@@ -2565,16 +2670,16 @@
       constexpr int new_offset = Offset + vector_width * groups_of_vec;
       // Recurse to handle other vector converters, or the scalar base case.
       convert_helper<new_offset, ResultVectorArray::kElements, ArrayConverter, OtherVectorArrays...>(result, source);
     }
 
   public:
     /*
-        A method to convert vectors of elements using the packed_convert method of the converter. 
-        
+        A method to convert vectors of elements using the packed_convert method of the converter.
+
         Converters using this class must implement packed convert and support 1 or more vector conversions.
       */
     template <typename ArrayConverter, typename ResultVectorArray, typename SourceVectorArray, typename... OtherVectorArrays>
     CUTLASS_DEVICE
     static void convert(typename ArrayConverter::result_type& result, typename ArrayConverter::source_type const& source) {
       convert_helper<0, 0, ArrayConverter, ResultVectorArray, SourceVectorArray, OtherVectorArrays...>(result, source);
     }
@@ -2647,15 +2752,15 @@
 
     const int iters = PackedSrcType::kElements / 4;
     #pragma unroll
     for (int ii = 0; ii < iters; ++ii, lut_idx >>=16, sign >>=16) {
       uint32_t final_prmt_idx = final_prmt_base | sign;
 
       // This uses a look up table to convert packed int4s to packed fp8s, using the int4 value
-      // as the index to prmt. 
+      // as the index to prmt.
       // It first select both the positive and negative candidates, then uses the sign bit to
       // select the correct candidate.
       asm volatile(
           "{\n"
           "  .reg .b32 pos_f8s, neg_f8s;\n"
           "  prmt.b32 pos_f8s, %1, %2, %5;\n"
           "  prmt.b32 neg_f8s, %3, %4, %5;\n"
@@ -2671,24 +2776,24 @@
   friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_8, source_type_packed_8, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_8, source_type_packed_8,
                                          result_type_packed_4, source_type_packed_4>(result, source);
 
     return result;
   }
 
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<float, N> <= Array<cutlass::int4b_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<float, cutlass::int4b_t, N, Round> {
@@ -2767,15 +2872,15 @@
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_8>::value &&
                    platform::is_same<PackedResultType, result_type_packed_8>::value),
                   "Invalid PackedSrcType/PackedResultType must be 1, 2, 4 or 8 to use private convert dispatch.");
-    
+
     // Hold output FP16s in reg. We need 1 reg for every 2 elements
     PackedResultType r;
 
     // View the input as reg
     uint32_t src_reg = to_reg(source);
     constexpr int total_elements = PackedResultType::kElements == 8 ? 4 : PackedResultType::kElements;
     packed_convert_vec<0, total_elements>(r, src_reg);
@@ -2784,31 +2889,31 @@
     if (PackedResultType::kElements == 8) {
       uint32_t src_reg_shifted = src_reg >> 16;
       packed_convert_vec<4, 4>(r, src_reg_shifted);
     }
     return r;
   }
 
-  friend class detail::VectorizedConverter; 
+  friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_8, source_type_packed_8, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_8, source_type_packed_8,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<float, N> <= Array<int8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<float, int8_t, N, Round> {
@@ -2840,15 +2945,15 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     PackedResultType r;
     // View the input as reg
     uint32_t src_reg = to_reg(source);
     static constexpr int fp32_base = 0x4B400000;
     uint32_t const prmt_indices[4] = {0x8880, 0x9991, 0xAAA2, 0xBBB3};
 
     int* result_as_int = reinterpret_cast<int*>(&r);
@@ -2871,23 +2976,23 @@
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
 
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<float, N> <= Array<uint8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<float, uint8_t, N, Round> {
@@ -2919,20 +3024,20 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     PackedResultType r;
     // View the input as reg
     uint32_t src_reg = to_reg(source);
 
-    // __byte_perm simulates the add.u32 0x4B000000 to every u8 element of u8x4 source and stores 
+    // __byte_perm simulates the add.u32 0x4B000000 to every u8 element of u8x4 source and stores
     // the result in r (without introducing extra cvt.u32.u8 instruction)
     uint32_t const prmt_indices[4] = {0x7650, 0x7651, 0x7652, 0x7653};
     uint32_t* result_as_int = reinterpret_cast<uint32_t*>(&r);
     for (int ii = 0; ii < PackedResultType::kElements; ++ii) {
       result_as_int[ii] = __byte_perm(src_reg, 0x4B000000, prmt_indices[ii]);
       // Subtract the magic number 0x4B000000 from tmp in floating-point arithmetic to obtain final result
       r[ii] -= 8388608.f;
@@ -2944,23 +3049,23 @@
   friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Partial specialization for Array<cutlass::half_t, N> <= Array<cutlass::int4b_t, N>
 template <FloatRoundStyle Round, int N>
@@ -3006,18 +3111,18 @@
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_8>::value &&
                    platform::is_same<PackedResultType, result_type_packed_8>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2, 4 or 8 to use private convert dispatch.");
-    
+
     // Hold output FP16s in reg. We need 1 reg for every 2 elements
     using RegArray = cutlass::AlignedArray<uint32_t, PackedResultType::kElements / 2, sizeof(PackedResultType)>;
-    RegArray r; 
+    RegArray r;
 
     // View the input as reg
     uint32_t src_reg = to_reg(source);
 
     // Below constructs the following temporary:
     // fp16s_01 = {0x00, i4_01, 0x00, i4_01}
     // fp16s_23 = {0x00, i4_23, 0x00, i4_23}
@@ -3030,15 +3135,15 @@
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile(
           "{\n"
           "  prmt.b32 %0, %1, %2, %3;\n"
           "}\n"
           : "=r"(r[ii])
-          : "r"(src_reg), "n"(0), "r"(prmt_indices[ii]));     
+          : "r"(src_reg), "n"(0), "r"(prmt_indices[ii]));
     }
 
     // The below XOR does the following:
     // 1) Sets the exponent bits of the FP16 to the correct value for the FP16 magic_num. We will be constructing
     //    1024 + x + 8 OR 1024 + 16 * (x + 8), then using hfma to subtract 1032 from that
     // 2) Adds 8 to the int4 value that we will process in the FP16 (for uint4, we can simply avoid this step)
     // The AND does the following:
@@ -3053,15 +3158,15 @@
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile(
           "{\n"
           "  lop3.b32 %0, %0, %1, %2, %3;\n"
           "}\n"
           : "+r"(r[ii])
-          : "n"(and_mask), "n"(xor_mask), "n"(immLut));     
+          : "n"(and_mask), "n"(xor_mask), "n"(immLut));
     }
 
     // We will issue 2 hfmas that do the following:
     // For the high FP16:
     //  Divide by 16 {packed as a operand} to get:
     //    64 + (x + 8)
     //    x + 72
@@ -3083,31 +3188,31 @@
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       half2& fp16x2_val = reinterpret_cast<__half2&>(r[ii]);
       fp16x2_val = __hfma2(hfma_scale, fp16x2_val, hfma_bias);
     }
     return reinterpret_cast<PackedResultType&>(r);
   }
 
-  friend class detail::VectorizedConverter; 
+  friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_8, source_type_packed_8, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_8, source_type_packed_8,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<cutlass::half_t, N> <= Array<int8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<cutlass::half_t, int8_t, N, Round> {
@@ -3141,18 +3246,18 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     // Hold output FP16s in reg. We need 1 reg for every 2 elements
     using RegArray = cutlass::AlignedArray<uint32_t, PackedResultType::kElements / 2, sizeof(PackedResultType)>;
-    RegArray r; 
+    RegArray r;
 
     #if 0 // Scalar conversion (Please keep this code for reference for vectorized version below)
     auto result = reinterpret_cast<PackedResultType&>(r);
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < PackedResultType::kElements; ++i) {
       int16_t tmp = source[i] + 26112 /* 0x6600 */;
       result[i] = reinterpret_cast<cutlass::half_t const &>(tmp) - 1536.0_hf;
@@ -3172,26 +3277,26 @@
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile("prmt.b32 %0,%1,%1,%2;\n" : "=r"(r[ii]) : "r"(src_reg), "r"(prmt_indices[ii]));
     }
 
     // In the absense of add.s16x2 instruction, use bit-wise operation to execute signed addition with magic numbers to achieve
     // the same result as add.s16x2 instruction.
     // (See https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#logic-and-shift-instructions-lop3)
-    // For a logical operation F(a, b, c) the value of kImmLut can be computed by applying the same operation to 
+    // For a logical operation F(a, b, c) the value of kImmLut can be computed by applying the same operation to
     // three predefined constant values as follows:
     //                                        ta = 0xF0;
     //                                        tb = 0xCC;
     //                                        tc = 0xAA;
     //                                   kImmLut = F(ta, tb, tc);
-    // If we want F = ((a & b) ^ c) then set kImmLut = (0xF0 & 0xCC) ^ 0xAA 
-    static constexpr uint32_t kImmLut = (0xF0 & 0xCC) ^ 0xAA; 
+    // If we want F = ((a & b) ^ c) then set kImmLut = (0xF0 & 0xCC) ^ 0xAA
+    static constexpr uint32_t kImmLut = (0xF0 & 0xCC) ^ 0xAA;
 
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       // The bit-wise operation executed below is `r[ii] = (r[ii] & 0x03FF03FF) ^ 0x66006600;`
-      asm volatile("lop3.b32 %0, %1, %2, %3, %4;\n" : 
+      asm volatile("lop3.b32 %0, %1, %2, %3, %4;\n" :
                                 "=r"(r[ii]) : "r"(r[ii]), "n"(0x03FF03FF), "n"(0x66006600), "n"(kImmLut));
     }
 
     static constexpr uint32_t bias_rep = 0x66006600;
     const half2& bias = reinterpret_cast<const half2&>(bias_rep);
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
@@ -3205,22 +3310,22 @@
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
 
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<cutlass::half_t, N> <= Array<uint8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<cutlass::half_t, uint8_t, N, Round> {
@@ -3252,19 +3357,19 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     // Hold output FP16s in reg. We need 1 reg for every 2 elements
     using RegArray = cutlass::AlignedArray<uint32_t, PackedResultType::kElements / 2, sizeof(PackedResultType)>;
-    RegArray r; 
-  
+    RegArray r;
+
     // View the input as reg
     uint32_t src_reg = to_reg(source);
     uint32_t const prmt_indices[2] = {0x5150, 0x5352};
     static constexpr uint32_t start_byte_for_fp16 = 0x64646464;
 
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile("prmt.b32 %0,%1,%2,%3;\n" : "=r"(r[ii]) : "r"(src_reg), "n"(start_byte_for_fp16), "r"(prmt_indices[ii]));
@@ -3285,23 +3390,23 @@
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
 
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Partial specialization for Array<cutlass::bfloat16_t, N> <= Array<cutlass::int4b_t, N>
@@ -3348,18 +3453,18 @@
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_8>::value &&
                    platform::is_same<PackedResultType, result_type_packed_8>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2, 4 or 8 to use private convert dispatch.");
-    
+
     // Hold output FP16s in reg. We need 1 reg for every 2 elements
     using RegArray = cutlass::AlignedArray<uint32_t, PackedResultType::kElements / 2, sizeof(PackedResultType)>;
-    RegArray r; 
+    RegArray r;
 
     // View the input as reg
     uint32_t src_reg = to_reg(source);
     uint32_t src_reg_shifted = src_reg >> 4;
 
     // Below constructs the following temporary:
     uint32_t const prmt_indices[4] = {0xF4F0, 0xF5F1, 0xF6F2, 0xF7F3};
@@ -3367,15 +3472,15 @@
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile(
           "{\n"
           "  prmt.b32 %0, %1, %2, %3;\n"
           "}\n"
           : "=r"(r[ii])
-          : "r"(src_reg), "r"(src_reg_shifted), "r"(prmt_indices[ii]));     
+          : "r"(src_reg), "r"(src_reg_shifted), "r"(prmt_indices[ii]));
     }
 
     // The below XOR does the following:
     // 1) Sets the exponent bits of the FP16 to the correct value for the FP16 magic_num. We will be constructing
     //    128 + (x + 8) and subtracting 136 to get x
     static constexpr uint32_t xor_mask = 0x43084308;
     static constexpr uint32_t and_mask = 0x000F000F;
@@ -3386,51 +3491,51 @@
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       asm volatile(
           "{\n"
           "  lop3.b32 %0, %0, %1, %2, %3;\n"
           "}\n"
           : "+r"(r[ii])
-          : "n"(and_mask), "n"(xor_mask), "n"(immLut));     
+          : "n"(and_mask), "n"(xor_mask), "n"(immLut));
     }
 
     // We will issue 2 bfmas that do the following:
     // high BF16:
     // hi_bf16 - 136, lo_bf16 - 136
 
     // This is the BF16 {136, 136} represented as an integer.
     static constexpr uint32_t bias_rep = 0x43084308;
     const __nv_bfloat162& bias = reinterpret_cast<const __nv_bfloat162&>(bias_rep);
-    
+
     CUTLASS_PRAGMA_UNROLL
     for (int ii = 0; ii < RegArray::kElements; ++ii) {
       __nv_bfloat162& bf16x2_val = reinterpret_cast<__nv_bfloat162&>(r[ii]);
       bf16x2_val = __hsub2(bf16x2_val, bias);
     }
 
     return reinterpret_cast<PackedResultType&>(r);
   }
 
-  friend class detail::VectorizedConverter; 
+  friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_8, source_type_packed_8, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_8, source_type_packed_8,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<cutlass::bfloat16_t, N> <= Array<int8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<cutlass::bfloat16_t, int8_t, N, Round> {
@@ -3462,38 +3567,38 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     NumericArrayConverter<float, int8_t, PackedResultType::kElements, Round> convert_int8_to_f32;
     Array<float, PackedResultType::kElements> tmp = convert_int8_to_f32(source);
     NumericArrayConverter<cutlass::bfloat16_t, float, PackedResultType::kElements, Round> convert_f32_to_bf16;
     return convert_f32_to_bf16(tmp);
   }
 
   friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
 
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 /// Partial specialization for Array<cutlass::bfloat16_t, N> <= Array<uint8_t, N>
 template <FloatRoundStyle Round, int N>
 struct NumericArrayConverter<cutlass::bfloat16_t, uint8_t, N, Round> {
@@ -3525,37 +3630,37 @@
   static PackedResultType packed_convert(PackedSrcType const &source) {
 
     static_assert((platform::is_same<PackedSrcType, source_type_packed_2>::value &&
                    platform::is_same<PackedResultType, result_type_packed_2>::value) ||
                   (platform::is_same<PackedSrcType, source_type_packed_4>::value &&
                    platform::is_same<PackedResultType, result_type_packed_4>::value),
                   "Invalid PackedSrcType/PackedResultType must be 2 or 4 to use private convert dispatch.");
-    
+
     NumericArrayConverter<float, uint8_t, PackedResultType::kElements, Round> convert_uint8_to_f32;
     Array<float, PackedResultType::kElements> tmp = convert_uint8_to_f32(source);
     NumericArrayConverter<cutlass::bfloat16_t, float, PackedResultType::kElements, Round> convert_f32_to_bf16_;
     return convert_f32_to_bf16_(tmp);
   }
 
   friend class detail::VectorizedConverter;
 
 public:
   CUTLASS_DEVICE
   static result_type convert(source_type const &source) {
     result_type result;
     using ConverterType = NumericArrayConverter<typename result_type::Element, typename source_type::Element, N, Round>;
-    detail::VectorizedConverter::convert<ConverterType, 
-                                         result_type_packed_4, source_type_packed_4, 
+    detail::VectorizedConverter::convert<ConverterType,
+                                         result_type_packed_4, source_type_packed_4,
                                          result_type_packed_2, source_type_packed_2>(result, source);
 
     return result;
   }
 
   CUTLASS_DEVICE
-  result_type operator()(source_type const &s) const { 
+  result_type operator()(source_type const &s) const {
     return convert(s);
   }
 };
 
 #endif // defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -3673,15 +3778,15 @@
 struct PreferredRoundingMode {
   static FloatRoundStyle const kRound = FloatRoundStyle::round_to_nearest;
 };
 
 #if defined(__CUDA_ARCH__) && __CUDA_ARCH__ < 900
 /// Defines preferred rounding mode for a pair of types
 template <>
-struct PreferredRoundingMode<tfloat32_t, float> {
+struct PreferredRoundingMode<cutlass::tfloat32_t, float> {
   static FloatRoundStyle const kRound = FloatRoundStyle::round_half_ulp_truncate;
 };
 #endif
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Packs predicates into an array.
@@ -3701,15 +3806,15 @@
     uint8_t *bytes = reinterpret_cast<uint8_t *>(packed.data());
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < N; ++i) {
       int word_idx = (i / kWordSize);
       int bit_idx = (i % kWordSize);
 
-      uint8_t mask = ((predicates[i] ? 1u : 0u) << bit_idx);
+      uint8_t mask = static_cast<uint8_t>((predicates[i] ? 1u : 0u) << bit_idx);
       bytes[word_idx] = (bytes[word_idx] | mask);
     }
     return packed;
   }
 };
 
 /// Packs predicates into an array
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_size.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/gemm/gemm_enumerated_types.h`

 * *Files 16% similar despite different names*

```diff
@@ -24,70 +24,57 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*!
-    \file
-    \brief Top-level include for all CUTLASS numeric types.
-*/
-
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
+/*! \file
+    \brief Defines common types used for all GEMM-like operators.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/coord.h"
+#include "cutlass/gemm_coord.h"
+#include "cutlass/layout/matrix.h"
 
 namespace cutlass {
+namespace gemm {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Defines the size of an element in bits
-template <typename T>
-struct sizeof_bits {
-  static int const value = int(sizeof(T) * 8);
+/// GEMM operand enumeration: D = A * B + C
+enum class Operand {
+  kA, /// A multiplicand
+  kB, /// B multiplicand
+  kC, /// Source accumulator
+  kD  /// Destination accumulator
 };
 
-template <typename T>
-struct sizeof_bits<T const>: sizeof_bits<T> {};
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-//
-// Definitions for 1-bit binary and 4-bit integer types
-//
-
-/// 1-bit binary type
-using bin1_t = bool;
-
-/// Defines the size of an element in bits - specialized for bin1_t
-template <>
-struct sizeof_bits<bin1_t> {
-  static int const value = 1;
+enum class GemmUniversalMode {
+  kGemm,
+  kGemmSplitKParallel,
+  kBatched,
+  kArray,
+  kGrouped,
+  kInvalid
 };
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-/// Returns the number of bytes required to hold a specified number of bits
-CUTLASS_HOST_DEVICE
-constexpr int
-bits_to_bytes(int bits) {
-  return (bits + 7) / 8;
-}
+/// Some options for clearing shared memory
+enum class SharedMemoryClearOption {
+  kNone,            ///< SMEM is in don't-care state
+  kZfill,           ///< Kernels fill out of bounds accesses with zeros
+  kClearLastStage   ///< Last SMEM stage is explicitly cleared. Mainloop uses 'kNone'
+};
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////
 
-}  // namespace cutlass
+} // namespace gemm
+} // namespace cutlass
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/numeric_types.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_types.h`

 * *Files 15% similar despite different names*

```diff
@@ -28,26 +28,18 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! 
     \file
     \brief Top-level include for all CUTLASS numeric types.
 */
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
 #pragma once
 
 #include "cutlass/cutlass.h"
+#include "cutlass/platform/platform.h"
 #include "cutlass/numeric_size.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -83,14 +75,14 @@
 } // namespace detail
 
 }  // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #include "cutlass/integer_subbyte.h"
-
 #include "cutlass/half.h"
 #include "cutlass/bfloat16.h"
 #include "cutlass/tfloat32.h"
 #include "cutlass/float8.h"
+#include "cutlass/uint128.h"
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/pipeline/pipeline.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pipeline/pipeline.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/pipeline/sm90_pipeline.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pipeline/sm90_pipeline.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -146,23 +146,28 @@
         index_ = 0;
         phase_ ^= 1;
       }
     }
   }
 
   CUTLASS_DEVICE
-  PipelineState& operator=(const PipelineState& other) {
+  PipelineState& operator+=(uint32_t num_iterations) {
+    return advance(num_iterations);
+  }
+
+  CUTLASS_DEVICE
+  PipelineState& operator=(PipelineState const& other) {
     index_ = other.index();
     phase_ = other.phase();
     count_ = other.count();
     return *this;
   }
 
   CUTLASS_DEVICE
-  PipelineState advance(uint32_t num_iterations) {
+  PipelineState& advance(uint32_t num_iterations) {
     if constexpr (Stages > 0) {
       // Number of iterations cross over the stage boundary => flipped phase
       if ((num_iterations < Stages) && (index_ + num_iterations) >= Stages ) {
         phase_ ^= 1;
       }
       // How many times number of iterations cross over the stage boundary and
       // end up on a odd number => flipped phase
@@ -177,15 +182,15 @@
 
   CUTLASS_DEVICE
   static PipelineState make_pipeline_state(PipelineState start_state, uint32_t num_iterations) {
     return start_state.advance(num_iterations);
   }
 };
 
-template<class Pipeline>  
+template<class Pipeline>
 CUTLASS_DEVICE
 PipelineState<Pipeline::Stages> make_producer_start_state() {
   // Producer starts with an opposite phase as the buffers are initially empty
   constexpr int InitialProducerStage = 0;
   constexpr uint32_t InitialProducerPhase = 1;
   constexpr uint32_t InitialProducerCount = 0;
   return {InitialProducerStage, InitialProducerPhase, InitialProducerCount};
@@ -255,15 +260,14 @@
     cutlass::arch::fence_barrier_init();
 
     // Logic to optimally schedule Empty Arrives
     // Goal : To divide SYNCS Empty Arrival duty equally amongst the Warp-Group (128 threads)
     dim3 block_id = cute::block_id_in_cluster();
     auto cluster_size = cute::size(cluster_shape);
     static constexpr int MaxClusterSize = 16;
-    static_assert(cluster_size <= MaxClusterSize, "ERROR : Cluster size too large !" );
 
     // STEP 1 : Use Cute Layout function to generate an optimal dst block-id (0-15)
     if (params_.num_consumers % NumThreadsPerWarpGroup == 0) {
       int thread_idx = threadIdx.x % NumThreadsPerWarpGroup;
       is_signalling_thread_ = (thread_idx % (NumThreadsPerWarpGroup / MaxClusterSize)) == 0;
       auto layout = cute::composition(Swizzle<2,0,-2>{},
                                       Layout<Shape<_4,_4>,Stride<_4,_1>>{});
@@ -286,15 +290,15 @@
       #endif
     }
 
     // STEP 2: Find if this dst block-id needs an arrival for this problem
     is_signalling_thread_ &= dst_blockid_ < cluster_size;
     is_signalling_thread_ &= is_same_row_or_col(dst_blockid_, block_id, cluster_shape);
   }
-  
+
   template <typename ClusterShape>
   CUTLASS_DEVICE
   bool is_same_row_or_col(int dst_block_id, dim3 block_id, ClusterShape cluster_shape) {
     return (((dst_block_id % cute::size<0>(cluster_shape)) == block_id.x) ||
             (
               ((dst_block_id / cute::size<0>(cluster_shape)) == block_id.y)
             ));
@@ -302,15 +306,15 @@
 
   ////////////////////
   // Producer APIs
   ////////////////////
   // Four member functions are always used in pairs:
   //
   // * producer_try_acquire and producer_acquire, and
-  // * consumer_try_wait and consumer_wait. 
+  // * consumer_try_wait and consumer_wait.
   //
   // The two functions with "try" in their names are called "try" functions,
   // and the other two are conceptually "finalize" functions.
   // The "try" function in each pair starts the process of waiting on the barrier to flip.
   // It opportunistically waits for an implementation-dependent timeout.
   // Whether or not the barrier has flipped yet, the try function will return a token.
   // If the token indicates that the barrier has not flipped,
@@ -336,15 +340,15 @@
   }
 
   // Prevents early exit of producer blocks in Cluster.
   // This should be called once before kernel exits.
   CUTLASS_DEVICE
   void producer_tail(PipelineState state) {
     for (int count = 0; count < Stages; ++count) {
-      producer_acquire(state, {BarrierStatus::WaitOnly});  
+      producer_acquire(state, {BarrierStatus::WaitOnly});
       ++state;
     }
   }
 
   CUTLASS_DEVICE
   ProducerBarrierType* producer_get_barrier(PipelineState state) {
     return producer_get_barrier(state.index());
@@ -358,15 +362,15 @@
     return consumer_try_wait(state.index(), state.phase(), skip_wait);
   }
 
   CUTLASS_DEVICE
   ConsumerToken consumer_test_wait(PipelineState state, uint32_t skip_wait = false) {
     return consumer_test_wait(state.index(), state.phase(), skip_wait);
   }
-  
+
   CUTLASS_DEVICE
   void consumer_wait(PipelineState state) {
     consumer_wait(state.index(), state.phase());
   }
 
   CUTLASS_DEVICE
   void consumer_wait(PipelineState state, ConsumerToken barrier_token) {
@@ -460,15 +464,15 @@
   ConsumerToken consumer_test_wait(uint32_t stage, uint32_t phase, uint32_t skip_wait) {
     if (skip_wait) {
       return {BarrierStatus::WaitDone};
     }
     uint32_t barrier_status = full_barrier_ptr_[stage].test_wait(phase);
     return {static_cast<BarrierStatus>(barrier_status)};
   }
-  
+
   // Wait for producer to commit transactions (done by TMA)
   CUTLASS_DEVICE
   void consumer_wait(uint32_t stage, uint32_t phase) {
     full_barrier_ptr_[stage].wait(phase);
   }
 
   // Wait for producer to commit transactions (done by TMA)
@@ -671,15 +675,15 @@
 
   ////////////////////
   // Producer APIs
   ////////////////////
   // Four member functions are always used in pairs:
   //
   // * producer_try_acquire and producer_acquire, and
-  // * consumer_try_wait and consumer_wait. 
+  // * consumer_try_wait and consumer_wait.
   //
   // The two functions with "try" in their names are called "try" functions,
   // and the other two are conceptually "finalize" functions.
   // The "try" function in each pair starts the process of waiting on the barrier to flip.
   // It opportunistically waits for an implementation-dependent timeout.
   // Whether or not the barrier has flipped yet, the try function will return a token.
   // If the token indicates that the barrier has not flipped,
@@ -710,15 +714,15 @@
   }
 
   // Prevents early exit of producer blocks in Cluster.
   // This should be called once before kernel exits.
   CUTLASS_DEVICE
   void producer_tail(PipelineState state) {
     for (int count = 0; count < Stages; ++count) {
-      producer_acquire(state);  
+      producer_acquire(state);
       ++state;
     }
   }
 
   CUTLASS_DEVICE
   ProducerBarrierType* producer_get_barrier(PipelineState state) {
     return producer_get_barrier(state.index());
@@ -732,15 +736,15 @@
     return consumer_try_wait(state.index(), state.phase(), skip_wait);
   }
 
   CUTLASS_DEVICE
   ConsumerToken consumer_test_wait(PipelineState state, uint32_t skip_wait = false) {
     return consumer_test_wait(state.index(), state.phase(), skip_wait);
   }
-  
+
   CUTLASS_DEVICE
   void consumer_wait(PipelineState state, ConsumerToken barrier_token = {BarrierStatus::WaitAgain}) {
     consumer_wait(state.index(), state.phase(), barrier_token);
   }
 
   CUTLASS_DEVICE
   void consumer_release(PipelineState state) {
@@ -797,15 +801,15 @@
   ConsumerToken consumer_test_wait(uint32_t stage, uint32_t phase, uint32_t skip_wait) {
     if (skip_wait) {
       return {BarrierStatus::WaitDone};
     }
     uint32_t barrier_status = full_barrier_ptr_[stage].test_wait(phase);
     return {static_cast<BarrierStatus>(barrier_status)};
   }
-  
+
   CUTLASS_DEVICE
   void consumer_wait(uint32_t stage, uint32_t phase, ConsumerToken barrier_token) {
     if (barrier_token == BarrierStatus::WaitAgain) {
       full_barrier_ptr_[stage].wait(phase);
     }
   }
 
@@ -879,15 +883,15 @@
 
   ////////////////////
   // Producer APIs
   ////////////////////
   // Four member functions are always used in pairs:
   //
   // * producer_try_acquire and producer_acquire, and
-  // * consumer_try_wait and consumer_wait. 
+  // * consumer_try_wait and consumer_wait.
   //
   // The two functions with "try" in their names are called "try" functions,
   // and the other two are conceptually "finalize" functions.
   // The "try" function in each pair starts the process of waiting on the barrier to flip.
   // It opportunistically waits for an implementation-dependent timeout.
   // Whether or not the barrier has flipped yet, the try function will return a token.
   // If the token indicates that the barrier has not flipped,
@@ -919,15 +923,15 @@
   }
 
   // Prevents early exit of producer blocks in Cluster.
   // This should be called once before kernel exits.
   CUTLASS_DEVICE
   void producer_tail(PipelineState state) {
     for (int count = 0; count < Stages; ++count) {
-      producer_acquire(state);  
+      producer_acquire(state);
       ++state;
     }
   }
 
   CUTLASS_DEVICE
   ProducerBarrierType* producer_get_barrier(PipelineState state) {
     return producer_get_barrier(state.index());
@@ -941,15 +945,15 @@
     return consumer_try_wait(state.index(), state.phase(), skip_wait);
   }
 
   CUTLASS_DEVICE
   ConsumerToken consumer_test_wait(PipelineState state, uint32_t skip_wait = false) {
     return consumer_test_wait(state.index(), state.phase(), skip_wait);
   }
-  
+
   CUTLASS_DEVICE
   void consumer_wait(PipelineState state, ConsumerToken barrier_token = {BarrierStatus::WaitAgain}) {
     consumer_wait(state.index(), state.phase(), barrier_token);
   }
 
   CUTLASS_DEVICE
   void consumer_release(PipelineState state) {
@@ -1000,15 +1004,15 @@
   ConsumerToken consumer_test_wait(uint32_t stage, uint32_t phase, uint32_t skip_wait) {
     if (skip_wait) {
       return {BarrierStatus::WaitDone};
     }
     uint32_t barrier_status = full_barrier_ptr_[stage].test_wait(phase);
     return {static_cast<BarrierStatus>(barrier_status)};
   }
-  
+
   CUTLASS_DEVICE
   void consumer_wait(uint32_t stage, uint32_t phase) {
     uint32_t done = full_barrier_ptr_[stage].test_wait(phase);
     if (!done) {
       full_barrier_ptr_[stage].wait(phase);
     }
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/pitch_linear_coord.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/pitch_linear_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/platform/platform.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/platform/platform.h`

 * *Files 2% similar despite different names*

```diff
@@ -91,24 +91,14 @@
  *           - \p aligned_storage
  *
  * The idea is that, as we drop support for older compilers, we can simply #define
  * the \p __NV_STD_XYZ macros and \p platform namespace to alias their C++
  * counterparts (or trivially find-and-replace their occurrences in code text).
  */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by `cutlass_test_unit_core_cpp11`.
-*/
-
 //-----------------------------------------------------------------------------
 // Dependencies
 //-----------------------------------------------------------------------------
 
 #if defined(__CUDACC_RTC__)
 #include <cuda/std/type_traits>
 #include <cuda/std/utility>
@@ -155,15 +145,15 @@
 #else
 #define CUTLASS_STL_NAMESPACE std
 #endif
 #endif
 
 /// builtin_unreachable
 #if !defined(CUTLASS_GCC_UNREACHABLE)
-#  if defined(__clang__) || defined(__GNUC__)
+#  if defined(__GNUC__)
 #    define CUTLASS_GCC_UNREACHABLE __builtin_unreachable()
 #  else
 #    define CUTLASS_GCC_UNREACHABLE
 #  endif
 #endif
 
 //-----------------------------------------------------------------------------
@@ -946,23 +936,21 @@
   CUTLASS_HOST_DEVICE
   static constexpr uint8_t lowest() noexcept { return 0;}
   CUTLASS_HOST_DEVICE
   static constexpr uint8_t max() noexcept { return 255U;}
   static constexpr bool is_integer = true;
 };
 
-#if !defined(__CUDACC_RTC__)
 template <>
 struct numeric_limits<float> {
   CUTLASS_HOST_DEVICE
   static constexpr float infinity() noexcept { return bit_cast<float, int32_t>(0x7f800000);}
   static constexpr bool is_integer = false;
   static constexpr bool has_infinity = true;
 };
-#endif
 
 /// std::float_round_style
 using CUTLASS_STL_NAMESPACE::float_round_style;
 using CUTLASS_STL_NAMESPACE::round_indeterminate;
 using CUTLASS_STL_NAMESPACE::round_toward_zero;
 using CUTLASS_STL_NAMESPACE::round_to_nearest;
 using CUTLASS_STL_NAMESPACE::round_toward_infinity;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/predicate_vector.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/predicate_vector.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/quaternion.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/quaternion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/real.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/real.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h`

 * *Files 2% similar despite different names*

```diff
@@ -67,33 +67,29 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    MatrixCoord problem_size;
-    int partitions;
-    size_t partition_stride;
-    WorkspaceTensorRef workspace;
-    OutputTensorRef destination;
-    OutputTensorRef source;
-    typename OutputOp::Params output;
-    typename ReductionOp::Params reduction;
+    MatrixCoord problem_size{0,0};
+    int partitions{1};
+    size_t partition_stride{0};
+    WorkspaceTensorRef workspace{};
+    OutputTensorRef destination{};
+    OutputTensorRef source{};
+    typename OutputOp::Params output{};
+    typename ReductionOp::Params reduction{};
 
     //
     // Methods
     //
 
     /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments() : 
-      problem_size(0, 0), 
-      partitions(1), 
-      partition_stride(0) { }
+    Arguments() = default;
    
     CUTLASS_HOST_DEVICE 
     Arguments(
       MatrixCoord const & problem_size
     ):
       problem_size(problem_size) { }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h`

 * *Files 1% similar despite different names*

```diff
@@ -67,22 +67,22 @@
 
   //
   // Arguments
   //
 
   struct Arguments {
 
-    cutlass::gemm::GemmCoord*  problem_sizes;
-    cutlass::gemm::GemmCoord   problem_size;
-    ElementNorm*               block_Norm;
-    ElementSum*                block_Sum;
-    int64_t*                   offset_Norm_Device;
-    int64_t*                   offset_Sum_Device;
-    int64_t                    batch_stride_Max;
-    int64_t                    batch_stride_Sum;
+    cutlass::gemm::GemmCoord*  problem_sizes{nullptr};
+    cutlass::gemm::GemmCoord   problem_size{};
+    ElementNorm*               block_Norm{nullptr};
+    ElementSum*                block_Sum{nullptr};
+    int64_t*                   offset_Norm_Device{nullptr};
+    int64_t*                   offset_Sum_Device{nullptr};
+    int64_t                    batch_stride_Max{0};
+    int64_t                    batch_stride_Sum{0};
 
     //
     // Methods
     //
     Arguments() { }
 
     // Non-grouped constructor without batching
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h`

 * *Files 1% similar despite different names*

```diff
@@ -258,15 +258,15 @@
     if (!params.inner_count) {
       return params.reduction_identity;
     }
 
     ComputeFragment accumulator;
     
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < accumulator.size(); ++i) {
+    for (int i = 0; i < int(accumulator.size()); ++i) {
       accumulator[i] = params.reduction_identity;
     }
     
     // Compute the coordinate of the first access    
     int64_t src_byte_offset = 0;
     Coord<kInnerRank> coord;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h`

 * *Files 0% similar despite different names*

```diff
@@ -254,15 +254,15 @@
     NumericArrayConverter<ElementCompute, ElementSource, VectorLength> convert_source;
     ReductionOp reduction_op(params.reduction_op);
 
     // Accumulated output
     ComputeFragment identity_frag;
 
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < identity_frag.size(); ++i) {
+    for (int i = 0; i < int(identity_frag.size()); ++i) {
       identity_frag[i] = params.reduction_identity;
     }
 
     if (!params.inner_count) {
       return identity_frag;
     }
     
@@ -532,15 +532,15 @@
 
     ReductionOp reduction_op(params.reduction_op);
 
     // Accumulated output
     ComputeFragment identity_frag;
     
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < identity_frag.size(); ++i) {
+    for (int i = 0; i < int(identity_frag.size()); ++i) {
       identity_frag[i] = params.reduction_identity;
     }
 
     ComputeFragment accumulator = identity_frag;
     ComputeFragment workspace_fragments[kBatchSize];
 
     // Partially unrolled loop
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/thread/reduce.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/relatively_equal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/relatively_equal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/semaphore.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/semaphore.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/subbyte_reference.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/subbyte_reference.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_coord.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_ref.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_ref.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_view.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_view.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/tfloat32.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/tfloat32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/trace.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/debug.h`

 * *Files 15% similar despite different names*

```diff
@@ -24,36 +24,33 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Helpers for optionally tracing through code when debugging.
-
-    This file is to be included after all other headers.
+/* \file
+   \brief
 */
 
 #pragma once
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
+#include <iostream>
 
-// Tracing options
-#ifndef CUTLASS_DEBUG_TRACE_LEVEL
-#define CUTLASS_DEBUG_TRACE_LEVEL 0
-#endif
+//#define report(x) { std::cout << "\033[31m" << __FILE__ << ":" << __LINE__ << "  " << x << "\033[0m" << std::endl; }
+//#define report(x) {}
 
-#if CUTLASS_DEBUG_TRACE_LEVEL
-#include <iostream>
-#include "cutlass/core_io.h"
-#if defined(__CUDA_ARCH__)
-#define CUTLASS_TRACE_HOST(x)
-#else
-#define CUTLASS_TRACE_HOST(x) { std::cout << __FILE__ << ":" << __LINE__ << "  " << x << std::endl; }
-#endif
-#else
-#define CUTLASS_TRACE_HOST(x)
-#endif
+// Enable/Disable Profiler debug prints
+//#define DEBUG_PROFILER 
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
+//RED    31m   // profiler prints debug messages in red
+//YELLOW 33m   // ir prints debug messages in yellow
 
+#ifndef DEBUG_PROFILER
+#define debugprof(...)
+#else
+#define debugprof(...) do { \
+          printf("\033[33m[DEBUG PROF]  %s:%d | ", __FILE__, __LINE__); \
+          printf(__VA_ARGS__); \
+          printf("\033[0m\n"); \
+      } while (0)
+#endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/collective/sm90_wgmma_transpose.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/collective/sm90_wgmma_transpose.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/thread/transpose.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/thread/transpose.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/thread/unary_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h`

 * *Files 4% similar despite different names*

```diff
@@ -28,24 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
   \brief 
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/array.h"
 #include "cutlass/detail/helper_macros.hpp"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/layout/pitch_linear.h"
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h`

 * *Files 6% similar despite different names*

```diff
@@ -25,34 +25,38 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Templates implementing the address computation of storing of tiles
-   from pitch-linear rank=2 tensors.
+    \brief Templates implementing storing of tiles from pitch-linear rank=2 tensors. 
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
+#include "cutlass/numeric_types.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace transform {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
-template <typename Shape, typename Element, typename Layout, int AdvanceRank,
-          typename ThreadMap,
-          int Alignment =
-              sizeof_bits<Element>::value* ThreadMap::kElementsPerAccess / 8>
-class RegularTileAccessIterator;
+template <
+  typename Shape,
+  typename Element,
+  typename Layout,
+  int AdvanceRank,
+  typename ThreadMap,
+  int Alignment = sizeof_bits<Element>::value * ThreadMap::kElementsPerAccess / 8
+>
+class RegularTileIterator;
 
 ////////////////////////////////////////////////////////////////////////////////
 
-}  // namespace threadblock
-}  // namespace transform
-}  // namespace cutlass
+} // namespace threadblock
+} // namespace transform
+} // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h`

 * *Files 3% similar despite different names*

```diff
@@ -56,33 +56,34 @@
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept |
 ///            ReadableContiguousTileIteratorConcept |
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileAccessIterator<
     Shape_, Element_,
     layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                          int(128 / sizeof(Element_))>,
+                                          Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
   static_assert(
       AdvanceRank == 0 || AdvanceRank == 1,
       "Specialization for pitch-linear iterator may along advance along the "
       "contiguous(rank=0) or strided(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout =
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element_))>;
+                                            Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
+  static int const kCrosswise = Crosswise;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
   using StrideIndex = typename Layout::Stride::Index;
 
   using TensorRef = TensorRef<Element, Layout>;
   using TensorCoord = typename Layout::TensorCoord;
@@ -130,15 +131,15 @@
 
  public:
   /// Construct a TileIterator with zero threadblock offset
   CUTLASS_HOST_DEVICE
   RegularTileAccessIterator(TensorRef ref,  ///< Pointer to start of tensor
                             int thread_id   ///< ID of each participating thread
                             )
-      : stride_(ref.stride(0) / Layout::kElementsPerAccess),
+      : stride_(ref.stride(0) * Layout::kFactor / Layout::kElementsPerAccess),
         byte_offset_(0) {
     layout::PitchLinearCoord thread_offset_base =
         ThreadMap::initial_offset(thread_id);
 
     CUTLASS_PRAGMA_UNROLL
     for (int i = 0; i < Detail::kPointerCount; ++i) {
       // This is the offset of a thread within a threadblock tile for a specific
@@ -171,15 +172,15 @@
 
   /// Returns a pointer
   CUTLASS_HOST_DEVICE
   AccessType *get() const {
     AccessType *access_ptr = pointer_[iteration_strided_ & 1];
     int stride_idx = (iteration_strided_ & ~1);
 
-    int access_offset = stride_idx * ThreadMap::Delta::kStrided * stride_ +
+    int access_offset = stride_idx * ThreadMap::Delta::kStrided * stride_ / Layout::kFactor +
                         iteration_contiguous_ * ThreadMap::Delta::kContiguous /
                             ThreadMap::kElementsPerAccess;
 
     char *access_byte_ptr =
         reinterpret_cast<char *>(access_ptr + access_offset);
     return reinterpret_cast<AccessType *>(access_byte_ptr + byte_offset_);
   }
@@ -216,46 +217,46 @@
 
     return prev;
   }
 
   /// Adds a tile offset
   CUTLASS_DEVICE
   void add_tile_offset(TensorCoord const &coord) {
-    add_pointer_offset(coord.contiguous() * Shape::kContiguous +
+    add_pointer_offset(coord.contiguous() * Shape::kContiguous * Layout::kFactor +
                        coord.strided() * Shape::kStrided * stride_ *
-                           Layout::kElementsPerAccess);
+                           Layout::kElementsPerAccess / Layout::kFactor);
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 /// Tile Iterator specialized for column-major congruous TensorOp formats.
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept |
 ///            ReadableContiguousTileIteratorConcept |
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileAccessIterator<
     Shape_, Element_,
     layout::ColumnMajorTensorOpMultiplicandCongruous<
-        sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>,
+        sizeof_bits<Element_>::value, Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
   static_assert(
       AdvanceRank == 0 || AdvanceRank == 1,
       "Specialization for column-major iterator may along advance along the "
       "columns(rank=0) or rows(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout = layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>;
+      sizeof_bits<Element_>::value, Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
 
   using TensorRef = TensorRef<Element, Layout>;
@@ -263,15 +264,15 @@
 
   using ThreadMap = ThreadMap_;
 
   /// Underlying iterator type
   using UnderlyingIterator = RegularTileAccessIterator<
       layout::PitchLinearShape<Shape::kRow, Shape::kColumn>, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element_))>,
+                                            Crosswise>,
       (kAdvanceRank == 0 ? 0 : 1), ThreadMap_>;
 
   using AccessType = typename UnderlyingIterator::AccessType;
 
  private:
   /// Underlying iterator
   UnderlyingIterator iterator_;
@@ -329,30 +330,30 @@
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept |
 ///            ReadableContiguousTileIteratorConcept |
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileAccessIterator<
     Shape_, Element_,
     layout::RowMajorTensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                                  int(128 / sizeof(Element_))>,
+                                                  Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
   static_assert(
       AdvanceRank == 0 || AdvanceRank == 1,
       "Specialization for row-major iterator may along advance along the "
       "columns(rank=0) or rows(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout = layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>;
+      sizeof_bits<Element_>::value, Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
 
   using TensorRef = TensorRef<Element, Layout>;
@@ -360,15 +361,15 @@
 
   using ThreadMap = ThreadMap_;
 
   /// Underlying iterator type
   using UnderlyingIterator = RegularTileAccessIterator<
       layout::PitchLinearShape<Shape::kColumn, Shape::kRow>, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element_))>,
+                                            Crosswise>,
       (kAdvanceRank == 0 ? 1 : 0), ThreadMap_>;
 
   using AccessType = typename UnderlyingIterator::AccessType;
 
  private:
   /// Underlying iterator
   UnderlyingIterator iterator_;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/conv/collective/collective_conv.hpp`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,39 +24,39 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Templates implementing storing of tiles from pitch-linear rank=2 tensors. 
-*/
-
 #pragma once
 
-#include "cutlass/cutlass.h"
-#include "cutlass/numeric_types.h"
+#include "cutlass/detail/dependent_false.hpp"
+#include "cutlass/conv/collective/detail.hpp"
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-namespace cutlass {
-namespace transform {
-namespace threadblock {
+namespace cutlass::conv::collective {
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-  typename Shape,
-  typename Element,
-  typename Layout,
-  int AdvanceRank,
-  typename ThreadMap,
-  int Alignment = sizeof_bits<Element>::value * ThreadMap::kElementsPerAccess / 8
+  class DispatchPolicy,
+  class TileShape,
+  class ElementA,
+  class ElementB,
+  class TiledMma,
+  class TileTraitsA,
+  class TileTraitsB
 >
-class RegularTileIterator;
+struct CollectiveConv {
+  static_assert(cutlass::detail::dependent_false<ElementA>, "Could not find a mainloop specialization.");
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace cutlass::conv::collective
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace threadblock
-} // namespace transform
-} // namespace cutlass
+#include "sm90_implicit_gemm_gmma_ss_warpspecialized.hpp"
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -49,31 +49,31 @@
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept | 
 ///            ReadableContiguousTileIteratorConcept | 
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileIterator<
     Shape_, Element_,
     layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                          int(128 / sizeof(Element_))>,
+                                          Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
 
   static_assert(AdvanceRank == 0 || AdvanceRank == 1, 
     "Specialization for pitch-linear iterator may along advance along the "
     "contiguous(rank=0) or strided(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout =
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element))>;
+                                            Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
 
   using TensorRef = TensorRef<Element, Layout>;
@@ -224,30 +224,30 @@
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept | 
 ///            ReadableContiguousTileIteratorConcept | 
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileIterator<
     Shape_, Element_,
     layout::ColumnMajorTensorOpMultiplicandCongruous<
-        sizeof_bits<Element_>::value, int(128 / sizeof(Element_))>,
+        sizeof_bits<Element_>::value, Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
 
   static_assert(AdvanceRank == 0 || AdvanceRank == 1, 
     "Specialization for column-major iterator may along advance along the "
     "columns(rank=0) or rows(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout = layout::ColumnMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element))>;
+      sizeof_bits<Element_>::value, Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
 
   using TensorRef = TensorRef<Element, Layout>;
@@ -255,15 +255,15 @@
 
   using ThreadMap = ThreadMap_;
 
   /// Underlying iterator type
   using UnderlyingIterator = RegularTileIterator<
       layout::PitchLinearShape<Shape::kRow, Shape::kColumn>, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element))>,
+                                            Crosswise>,
       (kAdvanceRank == 0 ? 0 : 1), ThreadMap_>;
 
  public:
 
   /// Fragment object to be loaded or stored
   using Fragment = Array<Element, UnderlyingIterator::Fragment::kElements>;
 
@@ -345,30 +345,30 @@
 ///
 ///
 /// Satisfies: ForwardTileIteratorConcept | 
 ///            ReadableContiguousTileIteratorConcept | 
 ///            WriteableContiguousTileIteratorConcept
 ///
 template <typename Shape_, typename Element_, int AdvanceRank,
-          typename ThreadMap_, int Alignment>
+          typename ThreadMap_, int Alignment, int Crosswise>
 class RegularTileIterator<
     Shape_, Element_,
     layout::RowMajorTensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                                  int(128 / sizeof(Element_))>,
+                                                  Crosswise>,
     AdvanceRank, ThreadMap_, Alignment> {
  public:
 
   static_assert(AdvanceRank == 0 || AdvanceRank == 1, 
     "Specialization for row-major iterator may along advance along the "
     "columns(rank=0) or rows(rank=1) dimension.");
 
   using Shape = Shape_;
   using Element = Element_;
   using Layout = layout::RowMajorTensorOpMultiplicandCongruous<
-      sizeof_bits<Element_>::value, int(128 / sizeof(Element))>;
+      sizeof_bits<Element_>::value, Crosswise>;
   static int const kAdvanceRank = AdvanceRank;
   static int const kAlignment = Alignment;
 
   using Index = typename Layout::Index;
   using LongIndex = typename Layout::LongIndex;
 
   using TensorRef = TensorRef<Element, Layout>;
@@ -376,15 +376,15 @@
 
   using ThreadMap = ThreadMap_;
 
   /// Underlying iterator type
   using UnderlyingIterator = RegularTileIterator<
       layout::PitchLinearShape<Shape::kColumn, Shape::kRow>, Element,
       layout::TensorOpMultiplicandCongruous<sizeof_bits<Element_>::value,
-                                            int(128 / sizeof(Element))>,
+                                            Crosswise>,
       (kAdvanceRank == 0 ? 1 : 0), ThreadMap_>;
 
  public:
 
   /// Fragment object to be loaded or stored
   using Fragment = Array<Element, UnderlyingIterator::Fragment::kElements>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/version.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/version.h`

 * *Files 2% similar despite different names*

```diff
@@ -31,16 +31,16 @@
 
 #pragma once
 
 #include <cstdint>
 #include <string>
 
 #define CUTLASS_MAJOR 3
-#define CUTLASS_MINOR 4
-#define CUTLASS_PATCH 1
+#define CUTLASS_MINOR 5
+#define CUTLASS_PATCH 0
 
 #ifdef CUTLASS_VERSIONS_GENERATED
 #include "cutlass/version_extended.h"
 #else
 #define CUTLASS_BUILD 0
 #define CUTLASS_REVISION ""
 #endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/wmma_array.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/wmma_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/include/cutlass/workspace.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/workspace.h`

 * *Files 5% similar despite different names*

```diff
@@ -28,35 +28,25 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Utilities for initializing workspaces
 */
 
-/*
-  Note:  CUTLASS 3x increases the host compiler requirements to C++17. However, certain
-         existing integrations of CUTLASS require C++11 host compilers.
-
-         Until this requirement can be lifted, certain headers with this annotation are required
-         to be remain consistent with C++11 syntax.
-
-         C++11 compatibility is enforced by this unit test: `cutlass_test_unit_core_cpp11`.
-*/
-
 #pragma once
 
 #if !defined(__CUDACC_RTC__)
 #include "cuda.h"
 #include "cuda_runtime.h"
 
 #include "cutlass/trace.h"
 #endif
 
 #include "cutlass.h"
-
+#include "cutlass/cuda_host_adapter.hpp"
 namespace cutlass {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 static constexpr int MinWorkspaceAlignment = 16;
 
 #if !defined(__CUDACC_RTC__)
@@ -80,24 +70,44 @@
   return Status::kSuccess;
 }
 #endif
 
 #if !defined(__CUDACC_RTC__)
 template <typename T>
 Status
-fill_workspace(void* workspace, T fill_value, size_t fill_count, cudaStream_t stream = nullptr) {
+fill_workspace(void* workspace, T fill_value, size_t fill_count, cudaStream_t stream = nullptr, CudaHostAdapter *cuda_adapter = nullptr) {
   static_assert(sizeof(T) == 4 || sizeof(T) == 2 || sizeof(T) == 1, "Unsupported fill type");
   if (fill_count > 0) {
     if (workspace == nullptr) {
       CUTLASS_TRACE_HOST("  error: device workspace must not be null");
       return Status::kErrorWorkspaceNull;
     }
 
     CUTLASS_TRACE_HOST("  filling workspace");
     CUdeviceptr d_workspace = reinterpret_cast<CUdeviceptr>(workspace);
+
+#if defined(CUTLASS_ENABLE_CUDA_HOST_ADAPTER) && CUTLASS_ENABLE_CUDA_HOST_ADAPTER
+
+    //
+    // Use the cuda host adapter
+    //
+    CUTLASS_ASSERT(cuda_adapter);
+    if (cuda_adapter) {
+      Status status = Status::kErrorInternal;
+
+      status = cuda_adapter->memsetDevice(workspace, fill_value, fill_count, stream);
+
+      if (status!=Status::kSuccess) {
+        return Status::kErrorInternal;
+      }
+    }
+    else {
+      return Status::kErrorInternal;
+    }
+#else
     CUresult result = CUDA_SUCCESS;
     if (sizeof(T) == 4) {
       result = cuMemsetD32Async(d_workspace, reinterpret_cast<uint32_t&>(fill_value), fill_count, stream);
     }
     else if (sizeof(T) == 2) {
       result = cuMemsetD16Async(d_workspace, reinterpret_cast<uint16_t&>(fill_value), fill_count, stream);
     }
@@ -112,14 +122,15 @@
         CUTLASS_TRACE_HOST("  cuMemsetD" << sizeof(T) * 8 << "Async() returned error " << *error_string_ptr);
       }
       else {
         CUTLASS_TRACE_HOST("  cuMemsetD" << sizeof(T) * 8 << "Async() returned unrecognized error");
       }
       return Status::kErrorInternal;
     }
+#endif
   }
 
   return Status::kSuccess;
 }
 #endif
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cluster_launch/cluster_launch.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cluster_launch/cluster_launch.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/common/cutlass_unit_test.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/common/cutlass_unit_test.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/common/filter_architecture.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/common/filter_architecture.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -113,18 +113,20 @@
   test_filters[] = {
     { "SM50*",                      50, kMaxDevice},
     { "SM60*",                      60, kMaxDevice},
     { "SM61*",                      61, kMaxDevice},
     { "SM70*",                      70, 75},
     { "SM75*",                      75, kMaxDevice},
     { "SM80*",                      80, kMaxDevice},
-    { "SM90*",                      90, 90        },
+    { "SM89*",                      89, 89},
+    { "SM90*",                      90, 90},
     { 0, 0, false }
   };
 
+
   // Set negative test filters
   std::stringstream ss;
   ss << "-";
   for (int i = 0, j = 0; test_filters[i].filter; ++i) {
 
     if (deviceMajorMinor < test_filters[i].min_compute_capability ||
         deviceMajorMinor > test_filters[i].max_compute_capability) {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/cache_testbed_output.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/cache_testbed_output.h`

 * *Files 2% similar despite different names*

```diff
@@ -118,22 +118,23 @@
   return out;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct CachedTestResult {
   uint32_t D;
-
   //
   // Methods
   //
 
-  CachedTestResult(): D() { }
+  CachedTestResult(): D()
+      { }
 
-  CachedTestResult(uint32_t D): D(D) { }
+  CachedTestResult(uint32_t D): D(D)
+      { }
 
   operator bool() const {
     return bool(D);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -253,14 +254,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 inline char const *EncodeOperator(cutlass::conv::Operator conv_op) {
     switch (conv_op) {
       case cutlass::conv::Operator::kFprop: return "fprop";
       case cutlass::conv::Operator::kDgrad: return "dgrad";
       case cutlass::conv::Operator::kWgrad: return "wgrad";
+      case cutlass::conv::Operator::kDeconv: return "deconv";
     }
     return "conv_unknown";
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Encode GemmCoord (Gemm problem size)
@@ -321,14 +323,42 @@
         break;
   }
 
   return out;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+// Encode 3.x ConvNd ProblemShape
+template <class ProblemShape>
+inline std::ostream &EncodeProblemSize(
+  std::ostream &out, 
+  ProblemShape const& problem_shape) {
+
+  out << problem_shape.shape_A << "_";
+  out << problem_shape.shape_B << "_";
+
+  out << "padl" << problem_shape.lower_padding << "_";
+  out << "padu" << problem_shape.upper_padding << "_";
+  out << "str"  << problem_shape.traversal_stride << "_";
+  out << "dil"  << problem_shape.dilation << "_";
+
+  switch (problem_shape.mode) {
+    case cutlass::conv::Mode::kCrossCorrelation:
+        out << "corr";
+        break;
+    case cutlass::conv::Mode::kConvolution:
+        out << "conv";
+        break;
+  }
+
+  return out;
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
 template <typename Element>
 inline std::string ElementTypeName() {
   return std::string(typeid(Element).name());
 }
 
 template <>
 inline std::string ElementTypeName<cutlass::half_t>() {
@@ -812,14 +842,64 @@
   key.types = ss_types.str();
 
   // Encode problem data
   CRC32 crc_hash;
   key.A = TensorHash(A, crc_hash);
   key.B = TensorHash(B, crc_hash);
   key.C = TensorHash(C, crc_hash);
+
+  return key;
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+template <
+  class ProblemShape,
+  typename ElementA,
+  typename ElementB,
+  typename ElementC,
+  typename ElementD
+>
+inline CachedTestKey CreateCachedConvNd3xTestKey(
+  cutlass::conv::Operator conv_operator,
+  ProblemShape const& problem_shape,
+  double alpha,
+  double beta,
+  thrust::universal_vector<ElementA> A,
+  thrust::universal_vector<ElementB> B,
+  thrust::universal_vector<ElementC> C
+) {
+
+  CachedTestKey key;
+ 
+  // Encode convNd operator and problem sizes
+  std::stringstream ss_op;
+  ss_op << "conv" << ProblemShape::RankS <<  "d";
+  key.op = ss_op.str();
+
+  std::stringstream ss_problem;
+  ss_problem << EncodeOperator(conv_operator) << "_";
+  EncodeProblemSize(ss_problem, problem_shape);
+  ss_problem << "_alpha" << EncodeScalar(alpha) << "_beta" << EncodeScalar(beta);
+  key.problem = ss_problem.str();
+
+  // Encode problem data types
+  std::stringstream ss_types;
+  EncodeTypes<
+        ElementA,
+        ElementB,
+        ElementC,
+        ElementD>(ss_types);
+  key.types = ss_types.str();
+
+  // Encode problem data
+  CRC32 crc_hash;
+  key.A = TensorHash(A, crc_hash);
+  key.B = TensorHash(B, crc_hash);
+  key.C = TensorHash(C, crc_hash);
 
   return key;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace test::conv::device
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -81,15 +81,15 @@
   using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
   /// Run all unit test sizes with device-level Conv2d instance
   EXPECT_TRUE(test::conv::device::TestAllConv2d<Conv2dFprop>());
 }
 
 ////////////////////////////////////////////////////////////////////////////////
-#if 0
+
 TEST(SM80_Device_Conv2d_Fprop_Precomputed_ImplicitGemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32,
   128x128_64x3_64x64x64) {
 
   /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
   using ElementA           = cutlass::half_t;
   using ElementB           = cutlass::half_t;
   using ElementC           = float;
@@ -112,19 +112,19 @@
       128 / cutlass::sizeof_bits<ElementC>::value,
       ElementAccumulator,
       ElementCompute
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     3,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::conv::IteratorAlgorithm::kOptimized
+    cutlass::conv::IteratorAlgorithm::kOptimized,
+    cutlass::conv::StrideSupport::kStrided
   >::Kernel;
 
   using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
   /// Run all unit test sizes with device-level Conv2d instance
   EXPECT_TRUE(test::conv::device::TestAllConv2d<Conv2dFprop>());
 }
-#endif
 
 ////////////////////////////////////////////////////////////////////////////////
 #endif  // CUTLASS_ARCH_MMA_SM80_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_problems.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h`

 * *Files 2% similar despite different names*

```diff
@@ -228,14 +228,83 @@
       {8, 7, 7, minimum_channel_size},   // filter size (KRSC)
       {1, 1, 1, 1},                      // padding (pad_h, _, pad_w, _)
       {1, 1},                            // stride (stride_h, stride_w)
       {1, 1}                             // dilation (dilation_h, dilation_w) 
     ));
 
     ////////////////////////////////////////////////////////////////////////////////////////////
+    // Small input size x stride (1,1) asymmetric paddings (1, 0, 1, 0)
+    // C < CTA::K and non-multiples of CTA::K. Typical CTA::K = {32, 64}
+    ////////////////////////////////////////////////////////////////////////////////////////////
+    
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize( 
+      {1, 1, 1, minimum_channel_size},   // input size  (NHWC)
+      {8, 1, 1, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize( 
+      {1, 1, 8, minimum_channel_size},   // input size  (NHWC)
+      {8, 1, 3, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize( 
+      {1, 7, 8, minimum_channel_size},   // input size  (NHWC)
+      {8, 3, 3, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize(
+      {1, 7, 9, minimum_channel_size},  // input size  (NHWC)
+      {8, 4, 4, minimum_channel_size},  // filter size (KRSC)
+      {1, 0, 1, 0},                     // padding (pad_h, _, pad_w, _)
+      {1, 1},                           // stride (stride_h, stride_w)
+      {1, 1}                            // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize(
+      {2, 7, 9, minimum_channel_size},   // input size  (NHWC)
+      {8, 5, 5, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize(
+      {3, 7, 9, minimum_channel_size},   // input size  (NHWC)
+      {8, 6, 5, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize(
+      {3, 7, 9, minimum_channel_size},   // input size  (NHWC)
+      {8, 6, 6, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize(
+      {3, 7, 9, minimum_channel_size},   // input size  (NHWC)
+      {8, 7, 7, minimum_channel_size},   // filter size (KRSC)
+      {1, 0, 1, 0},                      // padding (pad_h, _, pad_w, _)
+      {1, 1},                            // stride (stride_h, stride_w)
+      {1, 1}                             // dilation (dilation_h, dilation_w) 
+    ));
+
+    ////////////////////////////////////////////////////////////////////////////////////////////
     // Small input size x stride (2,2)
     // C < CTA::K and non-multiples of CTA::K. Typical CTA::K = {32, 64}
     ////////////////////////////////////////////////////////////////////////////////////////////
     conv2d_default_sizes.push_back(cutlass::conv::Conv2dProblemSize( 
       {1, 11, 7, minimum_channel_size},  // input size  (NHWC)
       {8, 1, 1, minimum_channel_size},    // filter size (KRSC)
       {0, 0, 0, 0},                       // padding (pad_h, _, pad_w, _)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_swizzling4_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 13% similar despite different names*

```diff
@@ -25,75 +25,88 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide Implicit GEMM interface with swizzling functor > 1
+    \brief Tests for device-wide Implicit GEMM interface
 */
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
 
 #include "cutlass/conv/kernel/default_conv2d_dgrad.h"
 #include "cutlass/conv/device/implicit_gemm_convolution.h"
 
 #include "conv2d_testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
-TEST(SM80_Device_Conv2d_Strided_Dgrad_Optimized_ImplicitGemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_swizzle4,
-  128x64_32x3_64x32x32) {
+
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Conv2d_Strided_Dgrad_Optimized_ImplicitGemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_align4,
+  64x64_32x5_32x32x32) {
 
   /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
-  using ElementA           = cutlass::half_t;
-  using ElementB           = cutlass::half_t;
-  using ElementC           = cutlass::half_t;
+  using ElementA           = cutlass::tfloat32_t;
+  using ElementB           = cutlass::tfloat32_t;
+  using ElementC           = float;
   using ElementAccumulator = float;
   using ElementCompute     = float;
 
   /// Device-level Conv2d instance
   using Conv2dDgradKernel = typename cutlass::conv::kernel::DefaultConv2dDgrad<
     ElementA, cutlass::layout::TensorNHWC,
     ElementB, cutlass::layout::TensorNHWC,
     ElementC, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<32, 32, 32>,
     cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
-      2,
+      4,
       ElementAccumulator,
       ElementCompute
     >,
-    cutlass::conv::threadblock::StridedDgradIdentityThreadblockSwizzle<4>,
-    3,
+    cutlass::conv::threadblock::StridedDgradIdentityThreadblockSwizzle<>,
+    5,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::conv::IteratorAlgorithm::kOptimized,
+    cutlass::conv::IteratorAlgorithm::kAnalytic,
     cutlass::conv::StrideSupport::kStrided,
-    8,
-    2
+    4,
+    4
   >::Kernel;
 
   using Conv2dDgrad = cutlass::conv::device::ImplicitGemmConvolution<Conv2dDgradKernel>;
 
 
   test::conv::device::Conv2dProblemVector problem_size_list;
 
+  // run specific problem size in the unit test first
+  problem_size_list.push_back(cutlass::conv::Conv2dProblemSize(
+    {1, 1, 1, 16},   // input size (NHWC)
+    {8, 3, 3, 16},     // filter size (KRSC)
+    {1, 1, 1, 1},     // padding (pad_h, _, pad_w, _)
+    {2, 1},           // stride (stride_h, stride_w)
+    {1, 1}            // dilation (dilation_h, dilation_w)
+  ));
 
   // run specific problem size in the unit test first
   problem_size_list.push_back(cutlass::conv::Conv2dProblemSize(
-    {1, 23, 56, 98},      // input size (NHWC)
-    {128, 3, 3, 98},      // filter size (KRSC)
-    {4, 0, 5, 0},         // padding (pad_h, _, pad_w, _)
-    {3, 3},               // stride (stride_h, stride_w)
-    {1, 1}                // dilation (dilation_h, dilation_w)
+    {1, 1, 1, 16},   // input size (NHWC)
+    {8, 3, 3, 16},     // filter size (KRSC)
+    {1, 1, 1, 1},     // padding (pad_h, _, pad_w, _)
+    {3, 3},           // stride (stride_h, stride_w)
+    {1, 1}            // dilation (dilation_h, dilation_w)
   ));
 
   /// Run all unit test sizes with device-level Conv2d instance
   EXPECT_TRUE(test::conv::device::TestAllConv2d<Conv2dDgrad>(problem_size_list));
 }
 
+////////////////////////////////////////////////////////////////////////////////
+
 #endif  // CUTLASS_ARCH_MMA_SM80_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 25% similar despite different names*

```diff
@@ -25,88 +25,113 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide Implicit GEMM interface
+    \brief Tests for device-wide TRMM interface
+
+  
 */
 
-#include "../../common/cutlass_unit_test.h"
-#include "cutlass/cutlass.h"
+#include <iostream>
 
-#include "cutlass/conv/kernel/default_conv2d_dgrad.h"
-#include "cutlass/conv/device/implicit_gemm_convolution.h"
+#include "../../common/cutlass_unit_test.h"
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/device/trmm.h"
+#include "cutlass/util/host_tensor.h"
+#include "cutlass/util/reference/host/trmm.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/tensor_view_io.h"
 
-#include "conv2d_testbed.h"
+#include "testbed_trmm_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Trmm_cf64n_cf64n_cf64t_ls_u_nu_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
-TEST(SM80_Device_Conv2d_Strided_Dgrad_Optimized_ImplicitGemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_align4,
-  64x64_32x5_32x32x32) {
+  using ElementOutput = cutlass::complex<double>;
+  using ElementAccumulator = cutlass::complex<double>;
 
-  /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
-  using ElementA           = cutlass::tfloat32_t;
-  using ElementB           = cutlass::tfloat32_t;
-  using ElementC           = float;
-  using ElementAccumulator = float;
-  using ElementCompute     = float;
-
-  /// Device-level Conv2d instance
-  using Conv2dDgradKernel = typename cutlass::conv::kernel::DefaultConv2dDgrad<
-    ElementA, cutlass::layout::TensorNHWC,
-    ElementB, cutlass::layout::TensorNHWC,
-    ElementC, cutlass::layout::TensorNHWC,
+  using Trmm = cutlass::gemm::device::Trmm<
+    cutlass::complex<double>,
+    cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kLeft,
+    cutlass::FillMode::kUpper,
+    cutlass::DiagType::kNonUnit,
+    cutlass::complex<double>,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<32, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      4,
+      ElementOutput,
+      1,
       ElementAccumulator,
-      ElementCompute
+      ElementAccumulator
     >,
-    cutlass::conv::threadblock::StridedDgradIdentityThreadblockSwizzle<>,
-    5,
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::conv::IteratorAlgorithm::kAnalytic,
-    cutlass::conv::StrideSupport::kStrided,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4,
-    4
-  >::Kernel;
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAddGaussianComplex,
+    cutlass::ComplexTransform::kNone
+  >;
 
-  using Conv2dDgrad = cutlass::conv::device::ImplicitGemmConvolution<Conv2dDgradKernel>;
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
+TEST(SM80_Device_Trmm_cf64h_cf64n_cf64t_ls_u_nu_tensor_op_f64_gaussian, 64x64x16_32x32x16) {
 
-  test::conv::device::Conv2dProblemVector problem_size_list;
+  using ElementOutput = cutlass::complex<double>;
+  using ElementAccumulator = cutlass::complex<double>;
 
-  // run specific problem size in the unit test first
-  problem_size_list.push_back(cutlass::conv::Conv2dProblemSize(
-    {1, 1, 1, 16},   // input size (NHWC)
-    {8, 3, 3, 16},     // filter size (KRSC)
-    {1, 1, 1, 1},     // padding (pad_h, _, pad_w, _)
-    {2, 1},           // stride (stride_h, stride_w)
-    {1, 1}            // dilation (dilation_h, dilation_w)
-  ));
-
-  // run specific problem size in the unit test first
-  problem_size_list.push_back(cutlass::conv::Conv2dProblemSize(
-    {1, 1, 1, 16},   // input size (NHWC)
-    {8, 3, 3, 16},     // filter size (KRSC)
-    {1, 1, 1, 1},     // padding (pad_h, _, pad_w, _)
-    {3, 3},           // stride (stride_h, stride_w)
-    {1, 1}            // dilation (dilation_h, dilation_w)
-  ));
+  using Trmm = cutlass::gemm::device::Trmm<
+    cutlass::complex<double>,
+    cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kLeft,
+    cutlass::FillMode::kUpper,
+    cutlass::DiagType::kNonUnit,
+    cutlass::complex<double>,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAddGaussianComplex,
+    cutlass::ComplexTransform::kConjugate
+  >;
 
-  /// Run all unit test sizes with device-level Conv2d instance
-  EXPECT_TRUE(test::conv::device::TestAllConv2d<Conv2dDgrad>(problem_size_list));
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif  // CUTLASS_ARCH_MMA_SM80_SUPPORTED
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -149,15 +149,14 @@
       }
       cutlass::reference::host::TensorFillRandomUniform(
         view, seed, scope, -scope, 0);
     } 
     else if (dist_kind == cutlass::Distribution::Identity) {
 
       cutlass::reference::host::TensorFillIdentity(view);
-
     } 
     else if (dist_kind == cutlass::Distribution::Gaussian) {
 
       cutlass::reference::host::TensorFillRandomGaussian(view, seed, 0, 0.5);
     }
     else if (dist_kind == cutlass::Distribution::Sequential) {
 
@@ -188,15 +187,15 @@
   }
 
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Conv2d::UnderlyingKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Conv2d::UnderlyingKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
@@ -485,15 +484,16 @@
 
     if (!passed) {
       std::stringstream fname;
 
       fname << "error_Conv2d_ImplicitGemm_device_"
         << (split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial_reduction_" : "parallel_reduction_")
         << (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kFprop ? "fprop_" :
-            (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" : "wgrad_"))
+            (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" :
+              (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDeconv ? "deconv_" : "wgrad_")))
         << ss_problem_size_text.str()
         << Conv2d::ThreadblockShape::kM << "x"  
         << Conv2d::ThreadblockShape::kN << "x"  
         << Conv2d::ThreadblockShape::kK << "_"
         << Conv2d::WarpShape::kM << "x"  
         << Conv2d::WarpShape::kN << "x"  
         << Conv2d::WarpShape::kK << ".txt";
@@ -631,16 +631,16 @@
     }
 
     //
     // Procedurally disable certain cases
     //
   
     // CUTLASS DGRAD's *unity* stride specialization only support stride {1, 1} 
-    if ((ImplicitGemm::kConvolutionalOperator == 
-          cutlass::conv::Operator::kDgrad) && 
+    if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+          ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) &&
         (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
           cutlass::conv::StrideSupport::kUnity)) {
       if (!((conv_problem.stride_h == 1) && (conv_problem.stride_w == 1))) {
         continue;
       }
     }
 
@@ -659,16 +659,16 @@
         continue;
       }
     }
 
     // CUTLASS DGRAD's *strided* stride specialization supports all stride {stride_h, stride_w} 
     // Although strided dgrad works for all stride combinations, we are only going 
     // to run strided dgrad for non-unity strides 
-    if ((ImplicitGemm::kConvolutionalOperator == 
-          cutlass::conv::Operator::kDgrad) && 
+    if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+          ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) &&
         (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
           cutlass::conv::StrideSupport::kStrided)) {
        if (((conv_problem.stride_h == 1) && (conv_problem.stride_w == 1))) {
          continue;
        }
     }
     
@@ -714,16 +714,16 @@
   if (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kIteratorAlgorithm ==
         cutlass::conv::IteratorAlgorithm::kFewChannels) {
 
     return true;
   }
 
   // CUTLASS DGRAD's *strided* specialization does not support split-k mode 
-  if ((ImplicitGemm::kConvolutionalOperator == 
-          cutlass::conv::Operator::kDgrad) && 
+    if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+          ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) &&
       (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
         cutlass::conv::StrideSupport::kStrided)) {
 
     passed = testbed.run(
       cutlass::conv::Conv2dProblemSize(
       {1, 56, 56, 8},   // input size (NHWC)
       {8, 1, 1, 8},     // filter size (KRSC)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h`

 * *Files 0% similar despite different names*

```diff
@@ -187,15 +187,15 @@
   }
 
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Conv2d::UnderlyingKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Conv2d::UnderlyingKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -250,15 +250,15 @@
   }
 
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Conv2d::UnderlyingKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Conv2d::UnderlyingKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
@@ -400,23 +400,23 @@
       beta_ref);
 
 #endif
     ReferenceOp reference_op;
 
     // compute tensor Z and tensor T
     for (int n = 0; n < problem_size.N; ++n) {
-      for (int p = 0; p < problem_size.P; ++p) {
-        for (int q = 0; q < problem_size.Q; ++q) {
-          for (int k = 0; k < problem_size.K; ++k) {
+      for (int p = 0; p < (kConvolutionalOperator == cutlass::conv::Operator::kFprop ? problem_size.P : problem_size.H); ++p) {
+        for (int q = 0; q < (kConvolutionalOperator == cutlass::conv::Operator::kFprop ? problem_size.Q : problem_size.W); ++q) {
+          for (int k = 0; k < (kConvolutionalOperator == cutlass::conv::Operator::kFprop ? problem_size.K : problem_size.C); ++k) {
   
-            ElementZ z;
-            ElementT t;
+            ElementZ z{};
+            ElementT t{};
     
             ElementCompute accum = tensor_Y_reference.at({n, p, q, k});
-	    ElementCompute bias = ElementCompute(tensor_Broadcast.at({0, 0, 0, k}));
+	          ElementCompute bias = ElementCompute(tensor_Broadcast.at({0, 0, 0, k}));
 
 
             if (kAddBroadcastFirst) {
               reference_op(z, t, accum + bias,
                            beta * ElementCompute(tensor_C_reference.at({n, p, q, k})));
             } else {
               reference_op(z, t, accum, bias);
@@ -445,15 +445,16 @@
 
     if (!passed) {
       std::stringstream fname;
 
       fname << "error_Conv2d_ImplicitGemm_device_"
         << (split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial_reduction_" : "parallel_reduction_")
         << (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kFprop ? "fprop_" :
-            (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" : "wgrad_")) 
+            (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" :
+              (Conv2d::kConvolutionalOperator == cutlass::conv::Operator::kDeconv ? "deconv_" : "wgrad_")))
         << "nhwc_"
         << problem_size.N << "x"
         << problem_size.H << "x"
         << problem_size.W << "x"
         << problem_size.C 
         << "_krsc_"
         << problem_size.K << "x"
@@ -495,14 +496,60 @@
         << "\nZ computed:\n" << tensor_Z_computed.host_view() << "\n";
     }
 
     return passed;
   }
 };
 
+
+/////////////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template <typename ImplicitGemm,
+          typename ReferenceOp = Conv2dWithBroadcastReferenceOp<ImplicitGemm>,
+          bool AddBroadcastFirst = false>
+bool TestSpecificConv2dWithBroadcast(
+  const Conv2dProblemVector & problem_sizes) {
+
+  bool passed = true;
+
+  //
+  // Testbed object
+  //
+
+  TestbedConv2dWithBroadcast<ImplicitGemm, ReferenceOp, AddBroadcastFirst> testbed;
+
+  // Sweep conv2d problem sizes (split-k-mode=kSerial, split-k-slice=1, alpha=1.0, beta=0.0)
+  for(auto conv_problem : problem_sizes) {
+
+    //
+    // Test
+    //
+
+    // test mode = xcross
+    passed = testbed.run(
+      conv_problem,
+      cutlass::conv::SplitKMode::kSerial);
+
+    if (!passed) {
+      return false;
+    }
+
+    // test mode = convolution
+    passed = testbed.run(
+      conv_problem.reset_mode(cutlass::conv::Mode::kConvolution),
+      cutlass::conv::SplitKMode::kSerial);
+
+    if (!passed) {
+      return false;
+    }
+  }
+
+  return true;
+}
+
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
 // Additionally, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename ImplicitGemm,
@@ -552,27 +599,27 @@
       }
 
       //
       // Procedurally disable certain cases
       //
   
       // CUTLASS DGRAD's *unity* stride specialization only support stride {1, 1} 
-      if ((ImplicitGemm::kConvolutionalOperator == 
-            cutlass::conv::Operator::kDgrad) && 
+      if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+            ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) && 
           (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
             cutlass::conv::StrideSupport::kUnity)) {
         if (!((conv_problem.stride_h == 1) && (conv_problem.stride_w == 1))) {
           continue;
         }
       }
 
 #if 0 // relax restrictions on analytic strided dgrad
       // CUTLASS DGRAD's *strided* specialization only support stride >= {2, 2} 
-      if ((ImplicitGemm::kConvolutionalOperator == 
-            cutlass::conv::Operator::kDgrad) && 
+      if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+            ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) && 
           (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
             cutlass::conv::StrideSupport::kStrided)) {
          if (((conv_problem.stride_h == 1) && (conv_problem.stride_w == 1))) {
            continue;
          }
       }
 #endif
@@ -600,16 +647,16 @@
       if (!passed) {
         return false;
       }
     }
   }
 
   // CUTLASS DGRAD's *strided* specialization does not support split-k mode 
-  if ((ImplicitGemm::kConvolutionalOperator == 
-          cutlass::conv::Operator::kDgrad) && 
+  if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+        ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) && 
       (ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
         cutlass::conv::StrideSupport::kStrided)) {
 
     passed = testbed.run(
       cutlass::conv::Conv2dProblemSize(
       {1, 56, 56, 8},   // input size (NHWC)
       {8, 1, 1, 8},     // filter size (KRSC)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -178,15 +178,15 @@
   }
 
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Conv2d::UnderlyingKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Conv2d::UnderlyingKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -107,15 +107,16 @@
       128 / cutlass::sizeof_bits<ElementC>::value,
       ElementAccumulator,
       ElementCompute
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::conv::IteratorAlgorithm::kOptimized
+    cutlass::conv::IteratorAlgorithm::kOptimized,
+    cutlass::conv::StrideSupport::kStrided
   >::Kernel;
 
   using Conv3dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv3dFpropKernel>;
 
   /// Run all unit test sizes with device-level Conv3d instance
   EXPECT_TRUE(test::conv::device::TestAllConv3d<Conv3dFprop>());
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_problems.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h`

 * *Files 4% similar despite different names*

```diff
@@ -113,26 +113,48 @@
     ));
 
     conv3d_default_sizes.push_back(cutlass::conv::Conv3dProblemSize(
       {1, 1, 1, 8, minimum_channel_size}, // input size  (NDHWC)
       {8, 1, 1, 3, minimum_channel_size},   // filter size (KTRSC)
       cutlass::Coord<3>({1, 1, 1}),         // padding (pad_d, pad_h, pad_w)
       cutlass::Coord<3>({1, 1, 1}),         // stride (stride_d, stride_h, stride_w)
+      cutlass::Coord<3>({1, 1, 1})          // dilation (dilation_d, dilation_h, dilation_w)
+    ));
+
+    conv3d_default_sizes.push_back(cutlass::conv::Conv3dProblemSize(
+      {1, 1, 1, 8, minimum_channel_size},   // input size  (NDHWC)
+      {8, 1, 1, 3, minimum_channel_size},   // filter size (KTRSC)
+      CUTLASS_STL_NAMESPACE::make_tuple(
+        cutlass::Coord<3>({1, 1, 1}),       // near padding (pad_d, pad_h, pad_w)
+        cutlass::Coord<3>({0, 0, 0})        // far padding (pad_d, pad_h, pad_w)
+      ),
+      cutlass::Coord<3>({1, 1, 1}),         // stride (stride_d, stride_h, stride_w)
       cutlass::Coord<3>({1, 1, 1})          // dilation (dilation_d, dilation_h, dilation_w) 
     ));
 
     conv3d_default_sizes.push_back(cutlass::conv::Conv3dProblemSize(
       {1, 8, 8, 8, minimum_channel_size}, // input size  (NDHWC)
       {8, 3, 3, 3, minimum_channel_size},   // filter size (KTRSC)
       cutlass::Coord<3>({1, 1, 1}),         // padding (pad_d, pad_h, pad_w)
       cutlass::Coord<3>({1, 1, 1}),         // stride (stride_d, stride_h, stride_w)
       cutlass::Coord<3>({1, 1, 1})          // dilation (dilation_d, dilation_h, dilation_w) 
     ));
 
     conv3d_default_sizes.push_back(cutlass::conv::Conv3dProblemSize(
+      {1, 8, 8, 8, minimum_channel_size},    // input size  (NDHWC)
+      {8, 3, 3, 3, minimum_channel_size},    // filter size (KTRSC)
+      CUTLASS_STL_NAMESPACE::make_tuple(
+        cutlass::Coord<3>({1, 1, 1}),       // near padding (pad_d, pad_h, pad_w)
+        cutlass::Coord<3>({0, 0, 0})        // far padding (pad_d, pad_h, pad_w)
+      ),
+      cutlass::Coord<3>({1, 1, 1}),          // stride (stride_d, stride_h, stride_w)
+      cutlass::Coord<3>({1, 1, 1})           // dilation (dilation_d, dilation_h, dilation_w) 
+    ));
+
+    conv3d_default_sizes.push_back(cutlass::conv::Conv3dProblemSize(
       {1, 16, 16, 16, minimum_channel_size}, // input size  (NDHWC)
       {8, 3, 3, 3, minimum_channel_size},   // filter size (KTRSC)
       cutlass::Coord<3>({1, 1, 1}),         // padding (pad_d, pad_h, pad_w)
       cutlass::Coord<3>({1, 1, 1}),         // stride (stride_d, stride_h, stride_w)
       cutlass::Coord<3>({1, 1, 1})          // dilation (dilation_d, dilation_h, dilation_w) 
     ));
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -165,30 +165,30 @@
     tensor_A.resize(implicit_gemm_tensor_a_extent(kConvolutionalOperator, problem_size));
     tensor_B.resize(implicit_gemm_tensor_b_extent(kConvolutionalOperator, problem_size));
     tensor_C.resize(implicit_gemm_tensor_c_extent(kConvolutionalOperator, problem_size));
     tensor_D_computed.resize(implicit_gemm_tensor_c_extent(kConvolutionalOperator, problem_size));
     tensor_D_reference.resize(implicit_gemm_tensor_c_extent(kConvolutionalOperator, problem_size));
 
     initialize_tensor(tensor_A.host_view(), init_A, seed); 
-    initialize_tensor(tensor_B.host_view(), init_B, seed * 17); 
+    initialize_tensor(tensor_B.host_view(), init_B, seed * 17);
     initialize_tensor(tensor_C.host_view(), init_C, seed * 39);
 
     tensor_A.sync_device();
     tensor_B.sync_device();
     tensor_C.sync_device();
     tensor_D_computed.sync_device();
     tensor_D_reference.sync_device();
   }
 
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Conv3d::UnderlyingKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Conv3d::UnderlyingKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
@@ -354,33 +354,33 @@
     //
     // Look for the cached key
     //
 
     bool cached_result_loaded = false;
     CachedTestResult cached_test_result;
 
-    std::string conv2d_result_cache_name = 
+    std::string conv3d_result_cache_name =
       std::string("cached_results_") + CUTLASS_TARGET_NAME + ".txt";
-    
+
     if (CUTLASS_TEST_ENABLE_CACHED_RESULTS) {
 
-      CachedTestResultListing cached_results(conv2d_result_cache_name);
+      CachedTestResultListing cached_results(conv3d_result_cache_name);
 
       auto cached = cached_results.find(cached_test_key);
 
       cached_result_loaded = cached.first;
       if (cached_result_loaded) {
         cached_test_result = cached.second;
       }
     }
 
     if (!cached_result_loaded) {
 
 #if CUTLASS_CONV_TEST_UNIT_REFERENCE_DEVICE_ENABLED
-    
+
     cutlass::reference::device::Conv3d<
       ElementA,
       LayoutA,
       ElementB,
       LayoutB,
       ElementC,
       LayoutC,
@@ -422,23 +422,22 @@
     );
 #endif
 
       if (CUTLASS_TEST_ENABLE_CACHED_RESULTS) {
 
         cached_test_result.D = TensorHash(tensor_D_reference.host_view());
 
-        CachedTestResultListing cached_results(conv2d_result_cache_name);
+        CachedTestResultListing cached_results(conv3d_result_cache_name);
 
         cached_results.append(cached_test_key, cached_test_result);
-        cached_results.write(conv2d_result_cache_name);
+        cached_results.write(conv3d_result_cache_name);
       }
     } // if (!cached_result_loaded)
 
     uint32_t tensor_D_hash = TensorHash(tensor_D_computed.host_view());
-    
     if (CUTLASS_TEST_ENABLE_CACHED_RESULTS) {
       passed = (tensor_D_hash == cached_test_result.D);
 
       EXPECT_EQ(tensor_D_hash, cached_test_result.D) 
         << "Hash-based comparison failed for key:" << "\n" << cached_test_key << "\n";
     }
     else {
@@ -452,15 +451,16 @@
 
     if (!passed) {
       std::stringstream fname;
 
       fname << "error_Conv3d_ImplicitGemm_device_"
         << (split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial_reduction_" : "parallel_reduction_")
         << (Conv3d::kConvolutionalOperator == cutlass::conv::Operator::kFprop ? "fprop_" :
-            (Conv3d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" : "wgrad_")) 
+            (Conv3d::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ? "dgrad_" :
+              (Conv3d::kConvolutionalOperator == cutlass::conv::Operator::kDeconv ? "deconv_" : "wgrad_")))
         << "ndhwc_"
         << problem_size.N << "x"
         << problem_size.D << "x"
         << problem_size.H << "x"
         << problem_size.W << "x"
         << problem_size.C 
         << "_ktrsc_"
@@ -567,16 +567,16 @@
       }
 
       //
       // Procedurally disable certain cases
       //
   
       // CUTLASS DGRAD's unity stride specialization only support stride {1, 1, 1} 
-      if ((ImplicitGemm::kConvolutionalOperator == 
-            cutlass::conv::Operator::kDgrad) && 
+      if ((ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDgrad ||
+            ImplicitGemm::kConvolutionalOperator == cutlass::conv::Operator::kDeconv) &&
           ((ImplicitGemm::UnderlyingKernel::Mma::IteratorA::kStrideSupport == 
             cutlass::conv::StrideSupport::kUnity) ||
            (ImplicitGemm::UnderlyingKernel::Mma::IteratorB::kStrideSupport == 
             cutlass::conv::StrideSupport::kUnity))) {
         if (!((conv_problem.stride_d == 1) &&
               (conv_problem.stride_h == 1) && 
               (conv_problem.stride_w == 1))
@@ -658,12 +658,53 @@
       }
     }
   }
 
   return passed;
 }
 
+template <typename ImplicitGemm>
+bool TestSpecificConv3d(
+  const Conv3dProblemVector & problem_sizes) {
+
+  bool passed = true;
+
+  //
+  // Testbed object
+  //
+
+  TestbedConv3d<ImplicitGemm> testbed;
+
+  // Sweep conv3d problem sizes (split-k-mode=kSerial, split-k-slice=1, alpha=1.0, beta=0.0)
+  for(auto conv_problem : problem_sizes) {
+
+    //
+    // Test
+    //
+
+    // test mode = xcross
+    passed = testbed.run(
+      conv_problem,
+      cutlass::conv::SplitKMode::kSerial);
+
+    if (!passed) {
+      return false;
+    }
+
+    // test mode = convolution
+    passed = testbed.run(
+      conv_problem.reset_mode(cutlass::conv::Mode::kConvolution),
+      cutlass::conv::SplitKMode::kSerial);
+
+    if (!passed) {
+      return false;
+    }
+  }
+
+  return true;
+}
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
 } // namespace conv
 } // namespace test
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -161,15 +161,15 @@
 
     result = cudaGetDeviceProperties(&properties, device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDeviceProperties() failed");
     }
 
-    if (properties.sharedMemPerBlockOptin < smem_size) {
+    if (properties.sharedMemPerBlockOptin < static_cast<size_t>(smem_size)) {
       return false;
     }
 
     return true;
   }
 
   /// Executes one test
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/array.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/array.cu`

 * *Files 2% similar despite different names*

```diff
@@ -113,16 +113,16 @@
 
   }
 
   /// Runs the test
   void run() {
 
     /// Device memory containing output
-    cutlass::device_memory::allocation< ArrayTy > output(kThreads);
-    std::vector< ArrayTy > output_host(kThreads);
+    cutlass::device_memory::allocation< ArrayTy > output(static_cast<size_t>(kThreads));
+    std::vector< ArrayTy > output_host(static_cast<size_t>(kThreads));
 
     dim3 grid(1,1);
     dim3 block(kThreads, 1, 1);
 
     test::core::test_array_clear<<< grid, block >>>(output.get());
 
     cudaError_t result = cudaDeviceSynchronize();
@@ -134,15 +134,15 @@
 
     cutlass::device_memory::copy_to_host(output_host.data(), output.get(), kThreads);
 
     result = cudaGetLastError();
     ASSERT_EQ(result, cudaSuccess) << "CUDA error: " << cudaGetErrorString(result);
 
     char const *ptr_host = reinterpret_cast<char const *>(output_host.data());
-    for (int i = 0; i < sizeof(ArrayTy) * kThreads; ++i) {
+    for (size_t i = 0; i < sizeof(ArrayTy) * kThreads; ++i) {
       EXPECT_FALSE(ptr_host[i]);
     }
 
     //
     // Verify each element contains the low bits of the thread Id
     //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/bfloat16.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/bfloat16.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/complex.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/complex.cu`

 * *Files 2% similar despite different names*

```diff
@@ -45,78 +45,78 @@
 
 TEST(complex, f64_to_f32_conversion) {
 
   cutlass::complex<double> source = {1.5, -1.25};
 
   cutlass::complex<float> dest = cutlass::complex<float>(source); // explicit conversion
 
-  EXPECT_TRUE(source.real() == 1.5 && source.imag() == -1.25 && 
+  EXPECT_TRUE(source.real() == 1.5 && source.imag() == -1.25 &&
     dest.real() == 1.5f && dest.imag() == -1.25f);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(complex, f32_to_f64_conversion) {
 
   cutlass::complex<float> source = {-1.5f, 1.25f};
 
   cutlass::complex<double> dest = source;  // implicit conversion
 
-  EXPECT_TRUE(source.real() == -1.5f && source.imag() == 1.25f && 
+  EXPECT_TRUE(source.real() == -1.5f && source.imag() == 1.25f &&
     dest.real() == -1.5 && dest.imag() == 1.25);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(complex, s32_to_f64_conversion) {
 
   cutlass::complex<int> source = {-2, 1};
 
   cutlass::complex<double> dest = source;  // implicit conversion
 
-  EXPECT_TRUE(source.real() == -2 && source.imag() == 1 && 
+  EXPECT_TRUE(source.real() == -2 && source.imag() == 1 &&
     dest.real() == -2 && dest.imag() == 1);
 }
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(complex, f16_to_f32_conversion) {
 
   cutlass::complex<cutlass::half_t> source = {1.5_hf, -1.25_hf};
 
   cutlass::complex<float> dest = cutlass::complex<float>(source); // explicit conversion
 
-  EXPECT_TRUE(source.real() == 1.5_hf && source.imag() == -1.25_hf && 
+  EXPECT_TRUE(source.real() == 1.5_hf && source.imag() == -1.25_hf &&
     dest.real() == 1.5f && dest.imag() == -1.25f);
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(complex, exp_f32) {
-  
+
   cutlass::complex<float> Z[] = {
     {1, 1},
     {2   ,  cutlass::constants::pi<float>()/2.0f   },
     {0.5f,  cutlass::constants::pi<float>()        },
     {0.25f,  cutlass::constants::pi<float>()*3/4.0f },
     {0, 0},
   };
 
   cutlass::complex<double> Expected[] = {
-    {1.4686939399158851, 2.2873552871788423}, 
+    {1.4686939399158851, 2.2873552871788423},
     {4.524491950137825e-16, 7.38905609893065},
-    {-1.6487212707001282, 2.019101226849069e-16}, 
+    {-1.6487212707001282, 2.019101226849069e-16},
     {-0.9079430793557842, 0.9079430793557843},
     {1, 0}
   };
 
   double tolerance = 0.00001;
 
-  for (int i = 0; cutlass::real(Z[i]); ++i) {
+  for (int i = 0; cutlass::real(Z[i]) != 0.0f; ++i) {
     double e_r = cutlass::real(Expected[i]);
     double e_i = cutlass::real(Expected[i]);
 
     cutlass::complex<float> got = cutlass::exp(Z[i]);
     float g_r = cutlass::real(got);
     float g_i = cutlass::real(got);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/fast_numeric_conversion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/fast_numeric_conversion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/float8.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/float8.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/functional.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/functional.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/half.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/half.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/matrix.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/matrix.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/matrix_coord.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/matrix_coord.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/numeric_conversion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/numeric_conversion.cu`

 * *Files 1% similar despite different names*

```diff
@@ -104,31 +104,31 @@
   cutlass::NumericArrayConverter<Destination, Source, Count> convert;
 
   *destination = convert(*source, *scale_factor);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-template <typename Destination, typename Source, typename ScaleFactor,  int Count, int Range = 4>
-void run_test_with_scalefactor(const char dest_name[], const char source_name[], const char scale_factor_name[]) {
+template <typename Destination, typename Source, typename ScaleFactor,  int Count>
+void run_test_with_scalefactor(const char dest_name[], const char source_name[], const char scale_factor_name[], const int range = 4, const int offset = 0) {
   const int kN = Count;
 
   dim3 grid(1, 1);
   dim3 block(1, 1);
 
   cutlass::HostTensor<Destination, cutlass::layout::RowMajor> destination({1, kN});
   cutlass::HostTensor<Source, cutlass::layout::RowMajor> source({1, kN});
   cutlass::HostTensor<ScaleFactor, cutlass::layout::RowMajor> scale_factor({1, kN});
   auto source_ref = source.host_ref();
   auto destination_ref = destination.host_ref();
   auto scale_factor_ref = scale_factor.host_ref();
 
 
   for (int i = 0; i < kN; ++i) {
-    source_ref.at({0, i}) = Source(i % Range);
+    source_ref.at({0, i}) = Source(i % range + offset);
   }
 
   for (int i = 0; i < kN; ++i) {
     scale_factor_ref.at({0, i}) = ScaleFactor(1 + i % 8);
   }
 
   source.sync_device();
@@ -140,18 +140,20 @@
     reinterpret_cast<cutlass::Array<ScaleFactor, kN> const *>(scale_factor.device_data())
   );
 
   destination.sync_host();
 
   for (int i = 0; i < kN; ++i) {
     float ref = float(source_ref.at({0, i})) / float(scale_factor_ref.at({0, i}));
-    EXPECT_TRUE(float(destination_ref.at({0, i})) == ref)
-      << "Destination type: " << dest_name << " "<< float(destination_ref.at({0, i}))
-      << ", Source type: " << source_name << " " << float(source_ref.at({0, i}))
-      << ", Count: " << Count;
+    bool pass = float(destination_ref.at({0, i})) == ref;
+    EXPECT_TRUE(pass) 
+      << "Destination type: " << dest_name << " "<< float(destination_ref.at({0, i})) << std::endl
+      << ", Source type: " << source_name << " " << float(source_ref.at({0, i})) << std::endl
+      << ", Scalefactor type: " << source_name << " " << float(scale_factor_ref.at({0, i})) << std::endl
+      << ", idx: " << i << std::endl;
   }
 }
 
 } // namespace kernel
 } // namespace core
 } // namespace test
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/predicate_vector.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/predicate_vector.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/quaternion.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/quaternion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/tensor_ref.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tensor_ref.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/tensor_view.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tensor_view.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/test_unit_core.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/test_unit.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -28,14 +28,14 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /** \file
     \brief Unit tests for CUTLASS core
 */
 
-#include "../common/cutlass_unit_test.h"
+#include "common/cutlass_unit_test.h"
 
 int main(int argc, char* arg[]) {
   FilterArchitecture();
   ::testing::InitGoogleTest(&argc, arg);
   return RUN_ALL_TESTS();
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/core/tfloat32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/core/tfloat32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/ampere/cp_async.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/ampere/ldsm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/array_subbyte.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/array_subbyte.cpp`

 * *Files 4% similar despite different names*

```diff
@@ -33,94 +33,95 @@
 
 #include <iostream>
 #include <iomanip>
 #include <utility>
 
 #include <cute/container/array_subbyte.hpp>
 #include <cute/tensor.hpp>
+#include <cute/numeric/numeric_types.hpp>
 
 TEST(CuTe_core, ArraySubbyte)
 {
   using namespace cute;
   {
-    array_subbyte<int4_t, 10> array0;
-    array_subbyte<int4_t,  5> array1;
+    array_subbyte<int4_t, 10> array0{};
+    array_subbyte<int4_t,  5> array1{};
     fill(array0, int4_t(0));
     fill(array1, int4_t(1));
 
-    for (int i = 0; i < array1.size(); ++i) {
+    for (size_t i = 0; i < array1.size(); ++i) {
       array0[i+5] = array1[i];
     }
     
     EXPECT_EQ(int4_t(array0.back()), int4_t(1));
 
-    for (int i = 0; i < array1.size(); ++i) {
-      EXPECT_EQ(int4_t(array0[i]), int4_t(i / 5));
+    for (size_t i = 0; i < array1.size(); ++i) {
+      EXPECT_EQ(int4_t(array0[i]), int4_t(int(i) / 5));
     }
   }
 
   {
-  array_subbyte<uint8_t, 14> a;
+  array_subbyte<uint8_t, 14> a{};
 
   //std::cout << sizeof_bits<decltype(a)>::value << std::endl;
-  EXPECT_EQ(sizeof_bits<decltype(a)>::value, 14*8);
+  EXPECT_EQ(cute::sizeof_bits_v<decltype(a)>, 14*8);
 
   fill(a, uint8_t(13));
   for (int i = 0; i < int(a.size()); ++i) {
     //std::cout << i << ": " << int(a[i]) << " -> ";
     EXPECT_EQ(a[i], uint8_t(13));
     a[i] = uint8_t(i);
     //std::cout << int(a[i]) << std::endl;
     EXPECT_EQ(a[i], uint8_t(i));
   }
 
   //std::cout << std::endl;
   }
 
   {
-  array_subbyte<int4_t, 14> a;
+  array_subbyte<int4_t, 14> a{};
 
   //std::cout << sizeof_bits<decltype(a)>::value << std::endl;
-  EXPECT_EQ(sizeof_bits<decltype(a)>::value, 14/2*8);
+  EXPECT_EQ(cute::sizeof_bits_v<decltype(a)>, 14/2*8);
 
   fill(a, int4_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     //std::cout << i << ": " << int4_t(a[i]) << " -> ";
     EXPECT_EQ(int4_t(a[i]), int4_t(-5));
     a[i] = int4_t(i);
     //std::cout << int4_t(a[i]) << std::endl;
     EXPECT_EQ(int4_t(a[i]), int4_t(i));
   }
 
   //std::cout << std::endl;
   }
 
   {
-  array_subbyte<uint2_t, 14> a;
+  array_subbyte<uint2_t, 14> a{};
 
   //std::cout << sizeof_bits<decltype(a)>::value << std::endl;
-  EXPECT_EQ(sizeof_bits<decltype(a)>::value, 4*8);
+  EXPECT_EQ(cute::sizeof_bits_v<decltype(a)>, 4*8);
 
   fill(a, uint2_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     //std::cout << i << ": " << uint2_t(a[i]) << " -> ";
     EXPECT_EQ(uint2_t(a[i]), uint2_t(-5));
     a[i] = uint2_t(i);
     //std::cout << uint2_t(a[i]) << std::endl;
     EXPECT_EQ(uint2_t(a[i]), uint2_t(i));
   }
 
   //std::cout << std::endl;
   }
 
   {
-  array_subbyte<bool, 14> a;
+  array_subbyte<bool, 14> a{};
 
   //std::cout << sizeof_bits<decltype(a)>::value << std::endl;
-  EXPECT_EQ(sizeof_bits<decltype(a)>::value, 2*8);
+  EXPECT_EQ(cute::sizeof_bits_v<decltype(a)>, 2*8);
 
   fill(a, bool(1));
   for (int i = 0; i < int(a.size()); ++i) {
     //std::cout << i << ": " << bool(a[i]) << " -> ";
     EXPECT_EQ(a[i], bool(1));
     a[i] = bool(i % 2);
     //std::cout << bool(a[i]) << std::endl;
@@ -131,54 +132,54 @@
 }
 
 TEST(CuTe_core, Subbyte_iterator)
 {
   using namespace cute;
 
   {
-  array_subbyte<uint8_t, 15> a;
+  array_subbyte<uint8_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<uint8_t>(a.raw_data()), make_shape(15));
 
   fill(a, uint8_t(13));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(uint8_t(tensor(i)), 13);
     tensor(i) = uint8_t(i);
     EXPECT_EQ(a[i], uint8_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<int4_t, 15> a;
+  array_subbyte<int4_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<int4_t>(a.raw_data()), make_shape(15));
 
   fill(a, int4_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(int4_t(tensor(i)), int4_t(-5));
     tensor(i) = int4_t(i);
     EXPECT_EQ(int4_t(a[i]), int4_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<uint2_t, 15> a;
+  array_subbyte<uint2_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<uint2_t>(a.raw_data()), make_shape(15));
 
   fill(a, uint2_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(uint2_t(tensor(i)), uint2_t(-5));
     tensor(i) = uint2_t(i);
     EXPECT_EQ(uint2_t(a[i]), uint2_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<bool, 15> a;
+  array_subbyte<bool, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<bool>(a.raw_data()), make_shape(15));
 
   fill(a, bool(1));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(bool(tensor(i)), bool(1));
     tensor(i) = bool(i % 2);
     EXPECT_EQ(a[i], bool(tensor(i)));
@@ -187,54 +188,54 @@
 }
 
 TEST(CuTe_core, Const_subbyte_iterator)
 {
   using namespace cute;
 
   {
-  array_subbyte<uint8_t, 15> a;
+  array_subbyte<uint8_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<uint8_t const>(a.raw_data()), make_shape(15));
 
   fill(a, uint8_t(13));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(uint8_t(tensor(i)), 13);
     a[i] = uint8_t(i);
     EXPECT_EQ(a[i], uint8_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<int4_t, 15> a;
+  array_subbyte<int4_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<int4_t const>(a.raw_data()), make_shape(15));
 
   fill(a, int4_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(int4_t(tensor(i)), int4_t(-5));
     a[i] = int4_t(i);
     EXPECT_EQ(int4_t(a[i]), int4_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<uint2_t, 15> a;
+  array_subbyte<uint2_t, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<uint2_t const>(a.raw_data()), make_shape(15));
 
   fill(a, uint2_t(-5));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(uint2_t(tensor(i)), uint2_t(-5));
     a[i] = uint2_t(i);
     EXPECT_EQ(uint2_t(a[i]), uint2_t(tensor(i)));
   }
 
   }
 
   {
-  array_subbyte<bool, 15> a;
+  array_subbyte<bool, 15> a{};
   auto tensor = make_tensor(subbyte_iterator<bool const>(a.raw_data()), make_shape(15));
 
   fill(a, bool(1));
   for (int i = 0; i < int(a.size()); ++i) {
     EXPECT_EQ(bool(tensor(i)), bool(1));
     a[i] = bool(i % 2);
     EXPECT_EQ(a[i], bool(tensor(i)));
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/bitfield.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/bitfield.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/coalesce.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/coalesce.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/compact_xmajor.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/compact_xmajor.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/compare.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/compare.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/complement.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/complement.cpp`

 * *Files 6% similar despite different names*

```diff
@@ -31,44 +31,44 @@
 
 #include "cutlass_unit_test.h"
 
 #include <cutlass/trace.h>
 
 #include <cute/tensor.hpp>
 
-template <class Layout, class CoSizeHi>
+template <class Layout, class CoTarget>
 void
-test_complement(Layout const& layout, CoSizeHi const& cosize_hi)
+test_complement(Layout const& layout, CoTarget const& cotarget)
 {
   using namespace cute;
 
-  auto result = complement(layout, cosize_hi);
+  auto result = complement(layout, cotarget);
 
-  CUTLASS_TRACE_HOST("complement(" << layout << ", " << cosize_hi << ")  =>  " << result);
+  CUTLASS_TRACE_HOST("complement(" << layout << ", " << cotarget << ")  =>  " << result);
 
   auto completed = make_layout(layout, result);
 
   // Lower-bound on the codomain size of the layout ++ complement (1)
-  EXPECT_GE(cosize(completed), cosize_hi);
+  EXPECT_GE(cosize(completed), size(cotarget));
   // Upper-bound on the codomain size of the complement (2)
-  EXPECT_LE(cosize(result), cute::round_up(cosize_hi, cosize(layout)));
+  EXPECT_LE(cosize(result), cute::round_up(size(cotarget), cosize(layout)));
 
   // Post-condition on the codomain of the complement
   for (int i = 1; i < size(result); ++i) {
     EXPECT_LT(result(i-1), result(i));         // Ordered (3)
     for (int j = 0; j < size(layout); ++j) {
       EXPECT_NE(result(i), layout(j));         // Disjoint (4)
     }
   }
 
   // Other observations
   EXPECT_LE(size(result), cosize(result));                        // As a result of the ordered condition (3)
-  EXPECT_GE(size(result), cosize_hi / size(filter(layout)));
+  EXPECT_GE(size(result), size(cotarget) / size(filter(layout)));
   EXPECT_LE(cosize(completed), cosize(result) + cosize(layout));
-  EXPECT_GE(cosize(result), cosize_hi / size(filter(layout)));            
+  EXPECT_GE(cosize(result), size(cotarget) / size(filter(layout)));
   if constexpr (is_static<decltype(stride(completed))>::value) {  // If we can apply complement again
     EXPECT_EQ(size(complement(completed)), 1);                    // There's no more codomain left over
   }
 }
 
 template <class Layout>
 void
@@ -86,29 +86,35 @@
   CUTLASS_TRACE_HOST("-------------------------------");
 
   {
   auto layout = Layout<_1,_0>{};
 
   test_complement(layout);
   test_complement(layout, Int<2>{});
+  test_complement(layout, Int<5>{});
+  test_complement(layout, make_shape(Int<2>{}, 2));
   }
 
   {
   auto layout = Layout<_1,_1>{};
 
   test_complement(layout);
   test_complement(layout, Int<2>{});
+  test_complement(layout, Int<5>{});
+  test_complement(layout, make_shape(Int<2>{}, 2));
   }
 
   {
   auto layout = Layout<_1,_2>{};
 
   test_complement(layout, Int<1>{});
   test_complement(layout, Int<2>{});
   test_complement(layout, Int<8>{});
+  test_complement(layout, Int<5>{});
+  test_complement(layout, make_shape(Int<2>{}, 2));
   }
 
   {
   auto layout = Layout<_4,_0>{};
 
   test_complement(layout, Int<1>{});
   test_complement(layout, Int<2>{});
@@ -126,22 +132,24 @@
   {
   auto layout = Layout<_4,_2>{};
 
   test_complement(layout, Int<1>{});
   test_complement(layout);
   test_complement(layout, Int<16>{});
   test_complement(layout, Int<19>{});
+  test_complement(layout, make_shape(Int<2>{}, 2));
   }
 
   {
   auto layout = Layout<_4,_4>{};
 
   test_complement(layout, Int<1>{});
   test_complement(layout);
   test_complement(layout, Int<17>{});
+  test_complement(layout, make_shape(Int<2>{}, 2));
   }
 
   {
   auto layout = Layout<Shape<_2,_4>>{};
 
   test_complement(layout);
   }
@@ -189,16 +197,16 @@
                             Stride<Stride<_1,_32>,Stride<_8,_4>>{});
 
   test_complement(layout);
   }
 
   // Fails due to non-injective layout
   // {
-  // auto layout = make_layout(Shape<Shape<_2,_2>,Shape<_2, _2>>{},
-  //                          Stride<Stride<_1,_8>,Stride<_8,_4>>{});
+  // auto layout = make_layout(Shape <Shape <_2,_2>,Shape <_2,_2>>{},
+  //                           Stride<Stride<_1,_8>,Stride<_8,_4>>{});
 
   // test_complement(layout);
   // }
 
   // Fails due to non-injective layout
   // {
   // auto layout = Layout<Shape<_2,_2>, Stride<_2,_3>>{};
@@ -285,8 +293,15 @@
 
   {
   auto layout = make_layout(make_shape(make_shape(2,2), make_shape(2,2)),
                             Stride<Stride<_1,_4>,Stride<_8,_32>>{});
 
   test_complement(layout);
   }
+
+  {
+  auto layout = make_layout(Int<64>{});
+
+  test_complement(layout, make_shape(Int<32>{}, Int<4>{}, Int<4>{}));
+  test_complement(layout, make_shape(Int<32>{}, Int<4>{}, 4));
+  }
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/composition.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/composition.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -208,21 +208,20 @@
   {
     auto a = make_layout(Shape<_4,_3>{});
     auto b = make_layout(Shape<_4,_3>{});
 
     test_composition(a, b);
   }
 
-  // FAILS due to b not "dividing into" a properly
-  //{
-  //  auto a = make_layout(Shape<_4,_3>{});
-  //  auto b = make_layout(Shape<_6>{});
+  {
+   auto a = make_layout(Shape<_4,_3>{});
+   auto b = make_layout(Shape<_6>{});
 
-  //  test_composition(a, b);
-  //}
+   test_composition(a, b);
+  }
 
   {
     auto a = make_layout(Shape<_4,_3>{});
     auto b = make_layout(Shape<_6>{}, Stride<_2>{});
 
     test_composition(a, b);
   }
@@ -230,21 +229,20 @@
   {
     auto a = make_layout(Shape<_4,_3>{});
     auto b = make_layout(Shape<_6,_2>{}, Stride<_2,_1>{});
 
     test_composition(a, b);
   }
 
-  // FAILS due to b not "dividing into" a properly
-  //{
-  //  auto a = make_layout(Shape<_4,_3>{});
-  //  auto b = make_layout(Shape<_4,_3>{}, Stride<_3,_1>{});
+  {
+   auto a = make_layout(Shape<_4,_3>{});
+   auto b = make_layout(Shape<_4,_3>{}, Stride<_3,_1>{});
 
-  //  test_composition(a, b);
-  //}
+   test_composition(a, b);
+  }
 
   {
     auto a = make_layout(Shape<_4,_3>{}, Stride<_3,_1>{});
     auto b = make_layout(Shape<_4,_3>{});
 
     test_composition(a, b);
   }
@@ -519,8 +517,25 @@
   {
     auto a = make_layout(Shape<_1,Shape<_2,_4>>{}, Stride<_0,Stride<_m1,_512>>{});
     auto b = make_layout(_4{}, _m1{});
 
     test_composition(a, b);
   }
 
+  CUTLASS_TRACE_HOST("-------------------------------");
+  CUTLASS_TRACE_HOST("BETA: Tuple strides"            );
+  CUTLASS_TRACE_HOST("-------------------------------");
+
+  {
+   auto a = make_layout(Shape<_4,_4>{}, Stride<_4,_1>{});
+   auto b = make_layout(Shape<_4,_4>{}, Stride<E<1>,E<0>>{});
+
+   test_composition(a, b);
+  }
+
+  {
+   auto a = make_layout(Shape<_4,Shape<_2,_3>>{}, Stride<_6,Stride<_3,_1>>{});
+   auto b = make_layout(Shape<_2,_4>{}, Stride<E<1,1>,E<0>>{});
+
+   test_composition(a, b);
+  }
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/constants.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/constants.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/core_unit.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/core_unit.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/int_tuple.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/int_tuple.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/inverse_left.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/inverse_right.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/logical_divide.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp`

 * *Files 12% similar despite different names*

```diff
@@ -223,31 +223,46 @@
   auto result = logical_divide(layout, tile);
   ASSERT_TRUE(decltype(shape<0>(result) == Int<48>{})::value);
   ASSERT_TRUE(decltype(stride<0>(result) == Int<1>{})::value);
   ASSERT_TRUE(shape<1>(result) == 1);
   ASSERT_TRUE(decltype(stride<1>(result) == Int<48>{})::value);
   }
 
-  // DISALLOWED
-  //{
-  //auto layout = make_layout(make_shape(128,4,3), make_stride(1,512,0));
-  //auto tile   = Layout<_32>{};
-
-  //test_logical_divide(layout, tile);
-  //}
-
-  //{
-  //auto layout = make_layout(make_shape(128,4,3), make_stride(1,512,0));
-  //auto tile   = Layout<_32,_2>{};
-
-  //CUTLASS_TRACE_HOST("complement: " << complement(tile, size(layout)));
-  //test_logical_divide(layout, tile);
-  //}
-
-  //{
-  //auto layout = make_layout(make_shape(16,4,3), make_stride(1,512,0));
-  //auto tile   = Layout<_32>{};
-
-  //CUTLASS_TRACE_HOST("complement: " << complement(tile, size(layout)));
-  //test_logical_divide(layout, tile);
-  //}
+  {
+  auto layout = make_layout(make_shape(Int<32>{}, Int<4>{}, 4));
+  auto tile   = Layout<_64>{};
+
+  test_logical_divide(layout, tile);
+
+  // Enforcement of result
+  auto result = logical_divide(layout, tile);
+  ASSERT_TRUE(bool( shape(result) == make_shape (_64{}, make_shape ( _2{},     4))));
+  ASSERT_TRUE(bool(stride(result) == make_stride( _1{}, make_stride(_64{},_128{}))));
+  }
+
+
+  //
+  // ALLOWED, but dangerous due to the dynamic lhs shapes
+  //   Consider disallowing...
+  //
+
+  {
+  auto layout = make_layout(make_shape(128,4,3), make_stride(1,512,0));
+  auto tile   = Layout<_32>{};
+
+  test_logical_divide(layout, tile);
+  }
+
+  {
+  auto layout = make_layout(make_shape(128,4,3), make_stride(1,512,0));
+  auto tile   = Layout<_32,_2>{};
+
+  test_logical_divide(layout, tile);
+  }
+
+  {
+  auto layout = make_layout(make_shape(16,4,3), make_stride(1,512,0));
+  auto tile   = Layout<_32>{};
+
+  test_logical_divide(layout, tile);
+  }
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/logical_product.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/logical_product.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/math.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/math.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/mixedbits.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/nullspace.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/nullspace.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/pointer.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/pointer.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/reverse.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/reverse.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/transform.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/transform.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/core/tuple.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/core/tuple.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/bulk_load.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/bulk_load.cu`

 * *Files 4% similar despite different names*

```diff
@@ -120,16 +120,16 @@
 }
 
 template <class T, class GLayout, class SLayout>
 void run_and_validate(GLayout gmem_layout,
                       SLayout smem_layout)
 {
   thrust::host_vector<T> h_in(cosize(gmem_layout));
-  for (int32_t i = 0; i < h_in.size(); ++i) {
-    h_in[i] = T(i);
+  for (size_t i = 0; i < h_in.size(); ++i) {
+    h_in[i] = static_cast<T>(int(i));
   }
 
   thrust::device_vector<T> d_in = h_in;
   thrust::device_vector<T> d_out(d_in.size(), T(-1));
 
   int32_t smem_size = static_cast<int32_t>(sizeof(SharedStorage<T, decltype(smem_layout)>));
   bulk_copy_test_device_cute<<<1, 128, smem_size>>>(thrust::raw_pointer_cast(d_in.data()),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/bulk_store.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/bulk_store.cu`

 * *Files 0% similar despite different names*

```diff
@@ -102,16 +102,16 @@
 }
 
 template <class T, class GLayout, class SLayout>
 void run_and_validate(GLayout gmem_layout,
                       SLayout smem_layout)
 {
   thrust::host_vector<T> h_in(cosize(gmem_layout));
-  for (int32_t i = 0; i < h_in.size(); ++i) {
-    h_in[i] = T(i);
+  for (size_t i = 0; i < h_in.size(); ++i) {
+    h_in[i] = static_cast<T>(int(i));
   }
 
   thrust::device_vector<T> d_in = h_in;
   thrust::device_vector<T> d_out(d_in.size(), T(-1));
 
   int32_t smem_size = static_cast<int32_t>(sizeof(SharedStorage<T, decltype(smem_layout)>));
   bulk_copy_test_device_cute<<<1, 128, smem_size>>>(thrust::raw_pointer_cast(d_in.data()),
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/stsm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/stsm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_load.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu`

 * *Files 0% similar despite different names*

```diff
@@ -40,24 +40,22 @@
 
 template <class T, class TmaType = T, class GMEM_Layout, class SMEM_Layout, class CTA_Tile>
 auto
 test_tma_load(GMEM_Layout const& gmem_layout,
               SMEM_Layout const& smem_layout,
               CTA_Tile    const& cta_tile)
 {
-  using namespace cute;
   return test_tma_load<T, TmaType>(SM90_TMA_LOAD{}, gmem_layout, smem_layout, cta_tile);
 }
 
 template <class T, class TmaType = T, class GMEM_Layout, class SMEM_Layout>
 auto
 test_tma_load(GMEM_Layout const& gmem_layout,
               SMEM_Layout const& smem_layout)
 {
-  using namespace cute;
   return test_tma_load<T, TmaType>(gmem_layout, smem_layout, product_each(shape(smem_layout)));
 }
 
 TEST(SM90_CuTe_Hopper, Tma_Load_1D)
 {
   {
     Layout smem_layout = Layout<_256, _1>{};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_load_testbed.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_load_testbed.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -30,27 +30,28 @@
  **************************************************************************************************/
 
 #pragma once
 
 #include "cutlass_unit_test.h"
 
 #include <iostream>
+#include <cstdint>
 
 #include <thrust/host_vector.h>
 #include <thrust/device_vector.h>
 
 #include <cute/tensor.hpp>
 
 namespace cutlass::test {
 
 template <class ElementType, class SmemLayout>
 struct SharedStorage
 {
   cute::ArrayEngine<ElementType, cute::cosize_v<SmemLayout>> smem;
-  cute::uint64_t tma_load_mbar[1];
+  alignas(16) cute::uint64_t tma_load_mbar[1];
 };
 
 #if CUDA_12_0_SM90_FEATURES_SUPPORTED
 
 template <class T, class TiledCopy, class CTA_Tiler, class GmemLayout, class SmemLayout>
 __global__ void
 tma_test_device_cute(T const* g_in, T* g_out,
@@ -142,22 +143,14 @@
     constexpr int kPhaseBit = 0;
     cute::wait_barrier(tma_load_mbar[0], kPhaseBit);
 
     //
     // Write out trivially smem -> gmem
     //
 
-    //if (thread0()) {
-    //  print_tensor(sA);
-    //}
-
-    // for (int i = threadIdx.x; i < size(sA); i += blockDim.x) {
-    //   tBgB(i,stage) = sA(i);
-    // }
-
     // Subbyte elements could cause race conditions, so be even more conservative
     if (thread0()) {
       copy(sA, tBgB(_,stage));
     }
 
     __syncthreads();
   }
@@ -170,21 +163,23 @@
               SMEM_Layout const& smem_layout,
               CTA_Tile    const& cta_tile)
 {
   using namespace cute;
 
   // Allocate and initialize host test data
   size_t N = ceil_div(cosize(gmem_layout) * sizeof_bits<T>::value, 8);
-  thrust::host_vector<char> h_in(N);
+  thrust::host_vector<uint8_t> h_in(N);
+  for (size_t i = 0; i < h_in.size(); ++i) {
+    h_in[i] = uint8_t(i % 13);
+  }
   Tensor hA_in  = make_tensor(recast_ptr<T>(h_in.data()), gmem_layout);
-  for (int i = 0; i < size(hA_in); ++i) { hA_in(i) = static_cast<T>(i % 13); }
 
   // Allocate and initialize device test data
-  thrust::device_vector<char> d_in = h_in;
-  thrust::device_vector<char> d_out(h_in.size(), char(-1));
+  thrust::device_vector<uint8_t> d_in = h_in;
+  thrust::device_vector<uint8_t> d_out(h_in.size(), uint8_t(-1)); // overflow uint
 
   // Create TMA for this device Tensor
   Tensor gA = make_tensor(make_gmem_ptr<T>(raw_pointer_cast(d_in.data())), gmem_layout);
   auto tma = make_tma_copy<TmaType>(copy_op, gA, smem_layout, cta_tile, Int<1>{});
   //print(tma);
 
   // Launch
@@ -193,20 +188,20 @@
     reinterpret_cast<T const*>(raw_pointer_cast(d_in.data())),
     reinterpret_cast<T*>      (raw_pointer_cast(d_out.data())),
     tma, cta_tile,
     gmem_layout,
     smem_layout);
 
   // Copy results back to host
-  thrust::host_vector<char> h_out = d_out;
+  thrust::host_vector<uint8_t> h_out = d_out;
   Tensor hA_out = make_tensor(recast_ptr<T>(h_out.data()), gmem_layout);
 
   // Validate the results. Print only the first 3 errors.
   int count = 3;
-  for (int i = 0; i < size(hA_out) && count > 0; ++i) {
+  for (int i = 0; i < int(size(hA_out)) && count > 0; ++i) {
     EXPECT_EQ(hA_in(i), hA_out(i));
     if (hA_in(i) != hA_out(i)) {
       --count;
     }
   }
 
   return tma;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_store.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/hopper/tma_store_testbed.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/hopper/tma_store_testbed.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -30,14 +30,15 @@
  **************************************************************************************************/
 
 #pragma once
 
 #include "cutlass_unit_test.h"
 
 #include <iostream>
+#include <cstdint>
 
 #include <thrust/host_vector.h>
 #include <thrust/device_vector.h>
 
 #include <cute/tensor.hpp>
 
 namespace cutlass::test {
@@ -118,19 +119,14 @@
 
   // Loop over the TMA stages, using smem as our buffer
   for (int stage = 0; stage < size<1>(tBgB); ++stage)
   {
     //
     // Read in trivially gmem -> smem
     //
-
-    // for (int i = threadIdx.x; i < size(sB); i += blockDim.x) {
-    //   sB(i) = tAgA(i,stage);
-    // }
-
     // Subbyte elements could cause race conditions, so be even more conservative
     if (thread0()) {
       copy(tAgA(_,stage), sB);
     }
 
     __syncthreads();
     cute::cp_async_wait<0>();
@@ -155,21 +151,23 @@
                SMEM_Layout const& smem_layout,
                CTA_Tile    const& cta_tile)
 {
   using namespace cute;
 
   // Allocate and initialize host test data
   size_t N = ceil_div(cosize(gmem_layout) * sizeof_bits<T>::value, 8);
-  thrust::host_vector<char> h_in(N);
+  thrust::host_vector<uint8_t> h_in(N);
+  for (size_t i = 0; i < h_in.size(); ++i) {
+    h_in[i] = uint8_t(i % 13);
+  }
   Tensor hA_in  = make_tensor(recast_ptr<T>(h_in.data()), gmem_layout);
-  for (int i = 0; i < size(hA_in); ++i) { hA_in(i) = static_cast<T>(i % 13); }
 
   // Allocate and initialize device test data
-  thrust::device_vector<char> d_in = h_in;
-  thrust::device_vector<char> d_out(h_in.size(), char(-1));
+  thrust::device_vector<uint8_t> d_in = h_in;
+  thrust::device_vector<uint8_t> d_out(h_in.size(), uint8_t(-1)); // overflow uint
 
   // Create TMA for this device Tensor
   Tensor gA = make_tensor(make_gmem_ptr<T>(raw_pointer_cast(d_out.data())), gmem_layout);
   auto tma = make_tma_copy<TmaType>(copy_op, gA, smem_layout, cta_tile, Int<1>{});
   //print(tma);
 
   // Launch
@@ -178,20 +176,20 @@
     reinterpret_cast<T const*>(raw_pointer_cast(d_in.data())),
     reinterpret_cast<T*>      (raw_pointer_cast(d_out.data())),
     tma, cta_tile,
     gmem_layout,
     smem_layout);
 
   // Copy results back to host
-  thrust::host_vector<char> h_out = d_out;
+  thrust::host_vector<uint8_t> h_out = d_out;
   Tensor hA_out = make_tensor(recast_ptr<T>(h_out.data()), gmem_layout);
 
   // Validate the results. Print only the first 3 errors.
   int count = 3;
-  for (int i = 0; i < size(hA_out) && count > 0; ++i) {
+  for (int i = 0; i < int(size(hA_out)) && count > 0; ++i) {
     EXPECT_EQ(hA_in(i), hA_out(i));
     if (hA_in(i) != hA_out(i)) {
       --count;
     }
   }
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/layout/layout_operator.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/msvc_compilation/tuple.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/msvc_compilation/tuple.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/cute/volta/vectorization_auto.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/cute/volta/vectorization_auto.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/activation.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/activation.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu`

 * *Files 0% similar despite different names*

```diff
@@ -179,15 +179,15 @@
   for (int i = 0; i < kCount; ++i) {
     accum.real[i] = Element(i * 2);
     accum.imag[i] = Element((i * 3 % 6) - 3);
     source.real[i] = ElementOutput((i * 7 % 9) - 4);
     source.imag[i] = ElementOutput(((i * 5 + 2) % 9) - 4);
   }
 
-  cutlass::ArrayPlanarComplex<ElementOutput, kCount> destination = linear_combination_op(accum, source);
+  cutlass::ArrayPlanarComplex<ElementOutput, kCount> destination{ linear_combination_op(accum, source) };
 
   // Verify each result
   for (int i = 0; i < kCount; ++i) {
     
     cutlass::complex<Element> expected = alpha * cutlass::complex<Element>(accum.real[i], accum.imag[i]) + 
       beta * cutlass::complex<Element>(Element(source.real[i]), Element(source.imag[i]));
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h`

 * *Files 3% similar despite different names*

```diff
@@ -129,37 +129,19 @@
   accumulators.clear();
   accumulator_iterator.load(accumulators);
 
 #if 0
   // For debugging, enable this block of code to fill each accumulator element with its
   // source thread ID.
   CUTLASS_PRAGMA_UNROLL
-  for (int i = 0; i < accumulators.size(); ++i) {
+  for (size_t i = 0; i < accumulators.size(); ++i) {
     typename Epilogue::WarpMmaOperator::ElementC x(threadIdx.x);
-    //typename Epilogue::WarpMmaOperator::ElementC x(i);
     accumulators[i] = x;
   }
 
-  /*
-  #pragma unroll 1
-  for (int tid = 0; tid < 32; ++tid) {
-    if (tid == thread_idx) {
-      printf("\nT%d: ", thread_idx);
-      CUTLASS_PRAGMA_UNROLL
-      for (int i = 0; i < accumulators.size(); ++i) {
-        printf("%d ", int(accumulators[i]));
-      }  
-    }
-  }
-
-  if (thread_idx == 0) {
-    printf("\n\n");  
-  }
-  */
-
   __syncthreads();
 
 #endif
 
   //
   // Perform the epilogue operation
   //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h`

 * *Files 3% similar despite different names*

```diff
@@ -38,14 +38,15 @@
 
 #include "../../common/cutlass_unit_test.h"
 
 #include "cutlass/aligned_buffer.h"
 #include "cutlass/half.h"
 #include "cutlass/complex.h"
 #include "cutlass/quaternion.h"
+#include "cutlass/platform/platform.h"
 #include "cutlass/epilogue/thread/linear_combination.h"
 
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/tensor_view_io.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -118,37 +119,19 @@
   accumulators.clear();
   accumulator_iterator.load(accumulators);
 
 #if 0
   // For debugging, enable this block of code to fill each accumulator element with its
   // source thread ID.
   CUTLASS_PRAGMA_UNROLL
-  for (int i = 0; i < accumulators.size(); ++i) {
+  for (size_t i = 0; i < accumulators.size(); ++i) {
     typename Epilogue::WarpMmaOperator::ElementC x(threadIdx.x);
-    //typename Epilogue::WarpMmaOperator::ElementC x(i);
     accumulators[i] = x;
   }
 
-  /*
-  #pragma unroll 1
-  for (int tid = 0; tid < 32; ++tid) {
-    if (tid == thread_idx) {
-      printf("\nT%d: ", thread_idx);
-      CUTLASS_PRAGMA_UNROLL
-      for (int i = 0; i < accumulators.size(); ++i) {
-        printf("%d ", int(accumulators[i]));
-      }  
-    }
-  }
-
-  if (thread_idx == 0) {
-    printf("\n\n");  
-  }
-  */
-
   __syncthreads();
 
 #endif
 
   //
   // Perform the epilogue operation
   //
@@ -207,23 +190,23 @@
     //
 
     uint64_t seed = 2019;
 
     cutlass::reference::host::TensorFillRandomUniform(
       accumulator_tensor.host_view(), 
       seed, 
-      20, 
-      -20, 
+      2,
+      -2,
       0);
 
     cutlass::reference::host::TensorFillRandomUniform(
       source_tensor.host_view(),
       seed + 2018, 
-      20, 
-      -20, 
+      2,
+      -2,
       0);
   }
 
   bool run_all() {
    
     double alpha_values[] = {1, 0, 2.25};
     double beta_values[] = {0, 1, -1.25};
@@ -314,15 +297,17 @@
         
         ElementOutput expected;
         if (coord.row() < problem_size.row() && coord.column() < problem_size.column()) {
           ElementCompute intermediate =
             output_params.alpha * ElementCompute(accumulator_tensor.at(coord)) + 
             output_params.beta * ElementCompute(source_tensor.at(coord));
           
-          if (std::numeric_limits<ElementOutput>::is_integer
+          if ((cutlass::platform::is_same<ElementOutput, cutlass::int4b_t>::value
+              || cutlass::platform::is_same<ElementOutput, cutlass::uint4b_t>::value
+              || std::numeric_limits<ElementOutput>::is_integer)
               && !std::numeric_limits<ElementCompute>::is_integer) {
             std::fesetround(FE_TONEAREST);
             expected = ElementOutput(std::nearbyint(float(cutlass::real(intermediate))));
           } else {
             expected = ElementOutput(intermediate);
           }
         } else {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu`

 * *Files 2% similar despite different names*

```diff
@@ -89,16 +89,16 @@
 
   cutlass::reference::host::TensorFill(accumulator_tensor.host_view(), ElementC(-1));
 
   for (int tid = 0; tid < 1; ++tid) {
     typename MmaTensorOp::IteratorC::Fragment accumulator_tile;
 
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < accumulator_tile.size(); ++i) {
-      accumulator_tile[i] = ElementC(i);
+    for (size_t i = 0; i < accumulator_tile.size(); ++i) {
+      accumulator_tile[i] = static_cast<ElementC>(int(i));
     }
 
     using FragmentIterator = cutlass::epilogue::warp::FragmentIteratorVoltaTensorOp<
       cutlass::gemm::GemmShape<64, 64, 4>,
       cutlass::gemm::GemmShape<32, 32, 4>,
       cutlass::half_t,
       cutlass::layout::RowMajor
@@ -110,15 +110,15 @@
 
     for (int iter = 0; iter < FragmentIterator::kIterations; ++iter) {
       frag_iterator.load(frag);
       ++frag_iterator;
 
     #if 0
       std::cout << "T" << tid << ": ";
-      for (int i = 0; i < frag.size(); ++i) {
+      for (size_t i = 0; i < frag.size(); ++i) {
         std::cout << "  " << frag[i];
       }
       std::cout << std::endl;
       #endif
     }
   }
 }
@@ -165,16 +165,16 @@
 
   cutlass::reference::host::TensorFill(accumulator_tensor.host_view(), ElementC(-1));
 
   for (int tid = 0; tid < 1; ++tid) {
     typename MmaTensorOp::IteratorC::Fragment accumulator_tile;
 
     CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < accumulator_tile.size(); ++i) {
-      accumulator_tile[i] = ElementC(i);
+    for (size_t i = 0; i < accumulator_tile.size(); ++i) {
+      accumulator_tile[i] = static_cast<ElementC>(i);
     }
 
     typename MmaTensorOp::IteratorC iterator_C(accumulator_tensor.host_ref(), tid);  
     iterator_C.store(accumulator_tile);
   }
 
   /*
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -48,24 +48,24 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 128x256x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x256x32_64x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 256, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -79,24 +79,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 256x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 256x128x32_64x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<256, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -110,24 +110,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 128x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x128x32_64x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -141,24 +141,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 64x128x32_32x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 64x128x32_32x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<64, 128, 32>,
     cutlass::gemm::GemmShape<32, 64, 32>,
@@ -172,24 +172,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 128x64x32_64x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x64x32_64x32x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 32, 32>,
@@ -203,24 +203,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16n_f16t_f16t_tensor_op_f16, 64x64x32_32x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 64x64x32_32x32x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<32, 32, 32>,
@@ -233,11 +233,10 @@
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 8% similar despite different names*

```diff
@@ -25,57 +25,71 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide GEMM interface
+    \brief Tests for device-wide SYRK interface
+  
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/cutlass.h"
-
-#include "cutlass/gemm/device/gemm_universal.h"
-
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/device/rank_k.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/rank_k_complex.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed.h"
-
-////////////////////////////////////////////////////////////////////////////////
+#include "testbed_rank_k_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_f16n_f16t_f32t_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM80_Device_Syrk_cf64n_cf64t_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementA = cutlass::complex<double>;
+  using LayoutA = cutlass::layout::ColumnMajor;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
-      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 32>,
-      cutlass::gemm::GemmShape<32, 32, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
-      cutlass::epilogue::thread::LinearCombination<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementAccumulator>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle, 10>;
+  using ElementC = cutlass::complex<double>;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = cutlass::complex<double>;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4,     // kStages 
+    1,     // AlignmentA
+    false, // SplitKSerial
+    cutlass::arch::OpMultiplyAddGaussianComplex,
+    cutlass::ComplexTransform::kNone,
+    cutlass::BlasMode::kSymmetric
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
-////////////////////////////////////////////////////////////////////////////////
-
-#endif  // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
-
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files 4% similar despite different names*

```diff
@@ -48,18 +48,18 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x256x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x256x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -79,18 +79,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 256x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 256x128x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -106,22 +106,22 @@
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
-
+  
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x128x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -141,18 +141,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 64x128x32_32x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 64x128x32_32x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -172,18 +172,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 128x64x32_64x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x64x32_64x32x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -203,18 +203,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f16t_tensor_op_f16, 64x64x32_32x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 64x64x32_32x32x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     ElementOutput,
@@ -233,10 +233,11 @@
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -48,24 +48,24 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x256x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x256x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 256, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -79,24 +79,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 256x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 256x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<256, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -106,28 +106,28 @@
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
-  
+
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -141,24 +141,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 64x128x32_32x64x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 64x128x32_32x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<64, 128, 32>,
     cutlass::gemm::GemmShape<32, 64, 32>,
@@ -172,24 +172,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 128x64x32_64x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x64x32_64x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 32, 32>,
@@ -203,24 +203,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16n_f32t_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 64x64x32_32x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm75,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<32, 32, 32>,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files 3% similar despite different names*

```diff
@@ -44,191 +44,191 @@
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x256x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 256, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 256x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<256, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
-
+  
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 64x128x32_32x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 128, 32>,
     cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 128x64x32_64x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM75_Device_Gemm_f16t_f16t_f32t_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
+    cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<32, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -236,8 +236,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif
+#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu`

 * *Files 13% similar despite different names*

```diff
@@ -26,218 +26,271 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
+    
 */
 
 #include <iostream>
 
+#include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
-
-#include "../../common/cutlass_unit_test.h"
-
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/tensor_view_io.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
+    
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+////////////////////////////////////////////////////////////////////////////////
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 32x64x8_32x64x1) {
+  
+  using Element = float;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  using Gemm = cutlass::gemm::device::Gemm<
+    Element, 
+    cutlass::layout::RowMajor,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 64, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
+    cutlass::epilogue::thread::LinearCombination<
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4
+  >;
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 64x64x8_32x64x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
+    Element, 
     cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 256, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
-
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x128x8_32x64x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
+    Element, 
     cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<256, 128, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM80_Device_Gemm_f32at_f32an_f32t_simt_f32, 128x128x8_32x64x1) {
+  
+  using Element = float;
+  using LayoutA = cutlass::layout::AffineRank2RowMajor;
+  using LayoutB = cutlass::layout::AffineRank2ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    Element, 
+    LayoutA,
+    Element, 
+    LayoutB,
+    Element,
+    LayoutC, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
+    cutlass::epilogue::thread::LinearCombination<
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
+  >;
+
+  typename LayoutA::Stride::Index stride_factor_A[] = {3, 4};
+  typename LayoutB::Stride::Index stride_factor_B[] = {5, 6};
+  typename LayoutC::Stride::Index stride_factor_C[] = {1};
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>( stride_factor_A, stride_factor_B, stride_factor_C ));
+}
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 64x128x8_32x64x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
+    Element, 
     cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 128, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
-  
+
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
-
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x64x8_64x32x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    Element, 
     cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 8>,
+    cutlass::gemm::GemmShape<64, 32, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
-
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x128x8_64x64x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
+    Element, 
     cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 8>,
+    cutlass::gemm::GemmShape<64, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
-
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x256x8_64x64x1) {
+  
+  using Element = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    Element, 
     cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<32, 32, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    Element, 
+    cutlass::layout::ColumnMajor,
+    Element,
+    cutlass::layout::RowMajor, 
+    Element,
+    cutlass::arch::OpClassSimt, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 256, 8>,
+    cutlass::gemm::GemmShape<64, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+        Element, 
+        1,
+        Element, 
+        Element>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32_sm80.cu`

 * *Files 11% similar despite different names*

```diff
@@ -26,318 +26,253 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
+    
 */
 
 #include <iostream>
 
+#include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm.h"
 
-#include "../../common/cutlass_unit_test.h"
+#include "cutlass/gemm/device/gemm_universal.h"
 
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/tensor_view_io.h"
 
-#include "testbed.h"
-
-#if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x256x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<128, 256, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      64 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x128x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<256, 128, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      64 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32_align8, 256x128x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<256, 128, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      8,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x128x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<128, 128, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      64 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x256x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<64, 256, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      64 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x64x128_64x64x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<256, 64, 128>,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      32 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
-
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x128x128_32x64x128) {
+#include "testbed_universal.h"
 
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+////////////////////////////////////////////////////////////////////////////////
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<64, 128, 128>,
-    cutlass::gemm::GemmShape<32, 64, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      64 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x64x128_64x32x128) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<128, 64, 128>,
-    cutlass::gemm::GemmShape<64, 32, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      32 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x128x64_64x64x64) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x128x32_64x64x32) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 64x128x32_32x64x32) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x32x32) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<64, 32, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    8,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 64x64x32_32x32x32) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<32, 32, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    8,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 16x128x32_16x64x32) {
+
+  using ElementA = cutlass::bfloat16_t;
+  using ElementB = int8_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<16, 128, 32>,
+    cutlass::gemm::GemmShape<16, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    8,  // Stages
+    8,  // AlignmentA
+    16, // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM75_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x64x128_32x32x128) {
-
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::int4b_t,
-    cutlass::layout::RowMajor,
-    cutlass::int4b_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm75,
-    cutlass::gemm::GemmShape<64, 64, 128>,
-    cutlass::gemm::GemmShape<32, 32, 128>,
-    cutlass::gemm::GemmShape<8, 8, 32>,
-    cutlass::epilogue::thread::LinearCombinationClamp<
-      ElementOutput,
-      32 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementCompute
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemmBasic<Gemm>());
-}
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-#endif
+////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu`

 * *Files 11% similar despite different names*

```diff
@@ -33,362 +33,329 @@
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
-#include "multistage_testbed.h"
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/reference/host/gemm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#if (CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "testbed.h"
+
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 ////////////////////////////////////////////////////////////////////////////////
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x256x256_64x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x256x128_64x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 256, 256>,
-      cutlass::gemm::GemmShape<64, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 256, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x128x256_64x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x128x128_64x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 256>,
-      cutlass::gemm::GemmShape<64, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 128, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x128x256_64x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x128x128_64x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 256>,
-      cutlass::gemm::GemmShape<64, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 128, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>,
+      cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x64x256_64x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x64x128_64x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 256>,
-      cutlass::gemm::GemmShape<64, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 64, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x256x256_64x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x256x128_64x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::ColumnMajor,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
       ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 256>,
-      cutlass::gemm::GemmShape<64, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::gemm::GemmShape<64, 256, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x128x256_32x64x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x128x128_32x64x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 128, 256>,
-      cutlass::gemm::GemmShape<32, 64, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 128, 128>,
+      cutlass::gemm::GemmShape<32, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x64x256_64x32x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x64x128_64x32x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 64, 256>,
-      cutlass::gemm::GemmShape<64, 32, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 64, 128>,
+      cutlass::gemm::GemmShape<64, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x64x256_32x32x256, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x64x128_32x32x128, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 256>,
-      cutlass::gemm::GemmShape<32, 32, 256>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 64, 128>,
+      cutlass::gemm::GemmShape<32, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x256x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x256x64_64x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::ColumnMajor,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
       ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::gemm::GemmShape<128, 256, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x128x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x128x64_64x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::ColumnMajor,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
       ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::gemm::GemmShape<256, 128, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32_align8, 256x128x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x128x64_64x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::ColumnMajor,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
       ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::gemm::GemmShape<128, 128, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 8, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x128x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x64x64_64x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::ColumnMajor,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
       ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 256x64x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::gemm::GemmShape<256, 64, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x256x128_64x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x256x64_64x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 256, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x128x128_32x64x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x128x64_32x64x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 128, 128>,
-      cutlass::gemm::GemmShape<32, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 128, 64>,
+      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 128x64x128_64x32x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x64x64_64x32x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 64, 128>,
-      cutlass::gemm::GemmShape<64, 32, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 64, 64>,
+      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s4t_s4n_s4t_tensor_op_s32, 64x64x128_32x32x128, {
-  using ElementOutput = cutlass::int4b_t;
+CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x64x64_32x32x64, {
+  using ElementOutput = int32_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = float;
+  using ElementCompute = int32_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      cutlass::int4b_t, cutlass::layout::RowMajor, cutlass::int4b_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::ColumnMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 128>,
-      cutlass::gemm::GemmShape<32, 32, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      int8_t, cutlass::layout::RowMajor, int8_t,
+      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 64, 64>,
+      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 32 / cutlass::sizeof_bits<ElementOutput>::value, ElementAccumulator, ElementCompute>,
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementCompute>,
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 6>;
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
 ////////////////////////////////////////////////////////////////////////////////
-#endif // #if (CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_f16t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_f16t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-/**************************************************************************************************
+/***************************************************************************************************
  * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
@@ -30,332 +30,511 @@
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
 */
 
 #include <iostream>
 
-#include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
+
+#include "../../common/cutlass_unit_test.h"
+
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/gemm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/gemm.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
-
-////////////////////////////////////////////////////////////////////////////////
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x256x128_64x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x128x128_64x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x128x128_64x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>,
-      cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x64x128_64x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x256x128_64x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x128x128_32x64x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 128, 128>,
-      cutlass::gemm::GemmShape<32, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x64x128_64x32x128, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 64, 128>,
-      cutlass::gemm::GemmShape<64, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
+#if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x64x128_32x32x128, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x256x64_64x64x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 128>,
-      cutlass::gemm::GemmShape<32, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x256x64_64x64x64, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
       cutlass::gemm::GemmShape<128, 256, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
+      cutlass::epilogue::thread::FastLinearCombinationClamp<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x128x64_64x64x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x128x64_64x64x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
       cutlass::gemm::GemmShape<256, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
+      cutlass::epilogue::thread::FastLinearCombinationClamp<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x128x64_64x64x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32_align8, 256x128x64_64x64x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
+      cutlass::gemm::GemmShape<256, 128, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
+      cutlass::epilogue::thread::FastLinearCombinationClamp<
+          ElementOutput, 8>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 256x64x64_64x64x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x128x64_64x64x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
+      cutlass::gemm::GemmShape<128, 128, 64>,
+      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
+      cutlass::epilogue::thread::FastLinearCombinationClamp<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x256x64_64x64x64, {
-  using ElementOutput = int32_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x128x64_32x64x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x128x64_32x64x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
       cutlass::gemm::GemmShape<64, 128, 64>,
-      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
-
+      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
+      cutlass::epilogue::thread::FastLinearCombinationClamp<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
+  
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 128x64x64_64x32x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x64x64_64x32x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
       cutlass::gemm::GemmShape<128, 64, 64>,
-      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
+      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
+
+  test::gemm::device::Testbed<Gemm> testbed;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-CUTLASS_TEST_L1(SM80_Device_Gemm_s8t_s8n_s32t_tensor_op_s32, 64x64x64_32x32x64, {
-  using ElementOutput = int32_t;
+CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x64x64_32x32x64, {
+  using ElementOutput = int8_t;
   using ElementAccumulator = int32_t;
-  using ElementCompute = int32_t;
+  using ElementCompute = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
       cutlass::gemm::GemmShape<64, 64, 64>,
-      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
+      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
       cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 6>;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
+
+  test::gemm::device::Testbed<Gemm> testbed;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 } )
 
-////////////////////////////////////////////////////////////////////////////////
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x32x64_16x16x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 32, 64>,
+    cutlass::gemm::GemmShape<16, 16, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      32 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x64x64_16x32x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 64, 64>,
+    cutlass::gemm::GemmShape<16, 32, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      64 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x128x64_16x64x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 128, 64>,
+    cutlass::gemm::GemmShape<16, 64, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x64x64_32x16x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 64, 64>,
+    cutlass::gemm::GemmShape<32, 16, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      32 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x128x64_32x32x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 128, 64>,
+    cutlass::gemm::GemmShape<32, 32, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      64 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 32x256x64_32x64x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<32, 256, 64>,
+    cutlass::gemm::GemmShape<32, 64, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x32x64_32x16x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<64, 32, 64>,
+    cutlass::gemm::GemmShape<32, 16, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      32 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x32x64_64x16x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<128, 32, 64>,
+    cutlass::gemm::GemmShape<64, 16, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      32 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x32x64_16x32x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<64, 32, 64>,
+    cutlass::gemm::GemmShape<16, 32, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      64 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x32x64_32x32x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<128, 32, 64>,
+    cutlass::gemm::GemmShape<32, 32, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      64 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x32x64_64x32x64) {
+
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    int8_t,
+    cutlass::layout::RowMajor,
+    int8_t,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm75,
+    cutlass::gemm::GemmShape<256, 32, 64>,
+    cutlass::gemm::GemmShape<64, 32, 64>,
+    cutlass::gemm::GemmShape<8, 8, 16>,
+    cutlass::epilogue::thread::LinearCombinationClamp<
+      ElementOutput,
+      64 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementCompute
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
+#endif
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -385,10 +385,30 @@
       cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 6>;
 
   test::gemm::device::MultistageTestbed<Gemm> testbed;
 
   EXPECT_TRUE(testbed.run_all());
 } )
 
+CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8n_tensor_op_s32, 256x64x128_64x64x128_align4, {
+  using ElementOutput = int8_t;
+  using ElementAccumulator = int32_t;
+  using ElementCompute = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
+      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
+      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 64, 128>,
+      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
+      cutlass::epilogue::thread::LinearCombinationClamp<
+          ElementOutput, 4, int32_t, float>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
+
+  test::gemm::device::MultistageTestbed<Gemm> testbed;
+
+  EXPECT_TRUE(testbed.run_all());
+} )
+
 ////////////////////////////////////////////////////////////////////////////////
 #endif // if (CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files 14% similar despite different names*

```diff
@@ -25,164 +25,213 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide GEMM interface
+    \brief Tests for device-wide SYRK interface
+  
 */
 
 #include <iostream>
 
-#include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm.h"
-
 #include "../../common/cutlass_unit_test.h"
-
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/device/rank_k.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/rank_k_complex.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/tensor_view_io.h"
+
+#include "testbed_rank_k_universal.h"
 
-#include "testbed.h"
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-#if defined(CUTLASS_ARCH_MMA_SM75_SUPPORTED)
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x256x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<128, 256, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<256, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32_align8, 256x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<256, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 8>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<128, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-
-} )
-
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x128x64_32x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<64, 128, 64>,
-      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-  
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
+TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
 
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x64x64_64x32x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<128, 64, 64>,
-      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
-
-  test::gemm::device::Testbed<Gemm> testbed;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
-
-CUTLASS_TEST_L0(SM75_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x64x64_32x32x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm75,
-      cutlass::gemm::GemmShape<64, 64, 64>,
-      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<8, 8, 16>,
-      cutlass::epilogue::thread::LinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
-          ElementAccumulator, ElementCompute>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 2>;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
 
-  test::gemm::device::Testbed<Gemm> testbed;
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-} )
+}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-#endif
+
+TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+
+  using ElementC = double;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+
+  using ElementC = double;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 16>,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syrk_f64n_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+
+  using ElementC = double;
+  using LayoutC = cutlass::layout::RowMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+
+}
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-/**************************************************************************************************
+/***************************************************************************************************
  * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
@@ -25,370 +25,459 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide GEMM interface
+    \brief Tests for grouped Rank2K interface
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm.h"
-#include "multistage_testbed.h"
+
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/kernel/rank_2k_grouped.h"
+#include "cutlass/gemm/kernel/default_rank_2k_grouped.h"
+#include "cutlass/gemm/device/rank_2k_grouped.h"
+
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/reference/host/gemm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#if (CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "testbed_grouped_rank_2k.h"
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-////////////////////////////////////////////////////////////////////////////////
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x256x128_64x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x128x128_64x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x128x128_64x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x64x128_64x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x256x128_64x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 128>,
-      cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x128x128_32x64x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 128, 128>,
-      cutlass::gemm::GemmShape<32, 64, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x64x128_64x32x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 64, 128>,
-      cutlass::gemm::GemmShape<64, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x64x128_32x32x128, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 128>,
-      cutlass::gemm::GemmShape<32, 32, 128>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x256x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 256, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32_align8, 256x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 8>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x128x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t,
-      cutlass::layout::ColumnMajor, ElementOutput, cutlass::layout::RowMajor,
-      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 128, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 256x64x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<256, 64, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x256x64_64x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 256, 64>,
-      cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 3>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x128x64_32x64x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 128, 64>,
-      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 128x64x64_64x32x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<128, 64, 64>,
-      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 4>;
-
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
-
-  EXPECT_TRUE(testbed.run_all());
-} )
-
-CUTLASS_TEST_L0(SM80_Device_Gemm_s8t_s8n_s8t_tensor_op_s32, 64x64x64_32x32x64, {
-  using ElementOutput = int8_t;
-  using ElementAccumulator = int32_t;
-  using ElementCompute = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-      int8_t, cutlass::layout::RowMajor, int8_t, cutlass::layout::ColumnMajor,
-      ElementOutput, cutlass::layout::RowMajor, ElementAccumulator,
-      cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
-      cutlass::gemm::GemmShape<64, 64, 64>,
-      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<16, 8, 32>,
-      cutlass::epilogue::thread::FastLinearCombinationClamp<
-          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value>,
-      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 6>;
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  test::gemm::device::MultistageTestbed<Gemm> testbed;
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 64x32x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 32x64x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 16>,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 64x64x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 64x32x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 32x64x16_32x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 128x64x16_64x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 128x128x16_32x64x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
+    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
+    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
+    ElementC, LayoutC, cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 16>,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3, // kStages
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+
+  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+
+  test::gemm::device::TestbedGrouped<Rank2K> testbed;
+  bool passed = testbed.run(24);
+  EXPECT_TRUE(passed);
+}
 
-  EXPECT_TRUE(testbed.run_all());
-} )
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-////////////////////////////////////////////////////////////////////////////////
-#endif // #if (CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -37,37 +37,36 @@
 #include <iostream>
 #include <fstream>
 #include <sstream>
 #include <algorithm>
 #include <random>
 
 #include "../../common/cutlass_unit_test.h"
-
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/tensor_view_io.h"
 #include "cutlass/util/distribution.h"
 #include "cutlass/util/packed_stride.hpp"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_norm.h"
 #include "cutlass/util/reference/host/gett.hpp"
 #include "cutlass/epilogue/collective/default_epilogue.hpp"
 #include "cutlass/epilogue/fusion/operations.hpp"
 #include "cutlass/complex.h"
-
 #include "testbed_utils.h"
 
 #include "cutlass/kernel_hardware_info.hpp"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/gemm/gemm.h"
 
 #include "cute/int_tuple.hpp"
 #include "cute/layout.hpp"
+#include "cute/numeric/int.hpp"
 
 namespace test {
 namespace gemm {
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -118,25 +117,25 @@
 // the order of arguments of the various run(...) functions in this file.
 class MaxSwizzleSize {
 public:
   MaxSwizzleSize() = default;
 
   template<class IntegralNotBool,
     __CUTE_REQUIRES((std::is_integral_v<IntegralNotBool> &&
-      !std::is_same_v<IntegralNotBool, bool>)) >
+      !cute::is_same_v<IntegralNotBool, bool>)) >
   explicit MaxSwizzleSize(IntegralNotBool max_swizzle_size) : max_swizzle_size_(max_swizzle_size) {}
   explicit operator int() const { return max_swizzle_size_; }
 private:
   int max_swizzle_size_ = 1;
 };
 
 template <typename T>
 auto make_iterator(T* ptr) {
   using namespace cute;
-  if constexpr (is_subbyte_v<T>) {
+  if constexpr (cute::is_subbyte_v<T>) {
     return subbyte_iterator<T>(ptr);
   }
   else {
     return ptr;
   }
 }
 
@@ -170,15 +169,15 @@
 // of function arguments.
 class Splits {
 public:
   Splits() = default;
 
   template<class IntegralNotBool,
     __CUTE_REQUIRES((std::is_integral_v<IntegralNotBool> &&
-      !std::is_same_v<IntegralNotBool, bool>)) >
+      !cute::is_same_v<IntegralNotBool, bool>)) >
   explicit Splits(IntegralNotBool splits) : splits_(splits) {}
   explicit operator int() const { return splits_; }
 private:
   int splits_ = 1;
 };
 
 // The number of iterations to test.
@@ -188,15 +187,15 @@
 // Iterations() picks the default number of iterations, 20.
 class Iterations {
 public:
   Iterations() = default;
 
   template<class IntegralNotBool,
     __CUTE_REQUIRES((std::is_integral_v<IntegralNotBool> &&
-      !std::is_same_v<IntegralNotBool, bool>)) >
+      !cute::is_same_v<IntegralNotBool, bool>)) >
   explicit Iterations(IntegralNotBool iterations) : iterations_(iterations) {}
   explicit operator int() const { return iterations_; }
 private:
   int iterations_ = 20;
 };
 
 template <typename Element, typename Layout>
@@ -210,20 +209,20 @@
     int bits_input = cutlass::sizeof_bits<Element>::value;
 
     if (bits_input == 1) {
       scope_max = 2;
       scope_min = 0;
     }
     else if (bits_input <= 8) {
-        scope_max = 2;
-        scope_min = -2;
+        scope_max = 1;
+        scope_min = -1;
     }
     else{
-      scope_max = 5;
-      scope_min = -5;
+      scope_max = 4;
+      scope_min = -4;
     }
     cutlass::reference::host::TensorFillRandomUniform(
       view, seed, scope_max, scope_min, 0);
   }
 
   else if (dist_kind == cutlass::Distribution::Identity) {
     cutlass::reference::host::TensorFillIdentity(view);
@@ -259,20 +258,24 @@
   return ((stride_0 == 1) || (stride_1 == 1)) && (depth == 1);
 }
 
 
 //
 // Default MMA input Operands : A , B
 //
-template<class ScheduleType_, class Gemm> 
+template<
+  class ScheduleType_, 
+  class Gemm, 
+  class ElementA_ = typename Gemm::GemmKernel::ElementA,
+  class ElementB_ = typename Gemm::GemmKernel::ElementB> 
 struct HostCollectiveMainloop {
   // Kernel data types
-  using ElementA = typename Gemm::GemmKernel::ElementA;
+  using ElementA = ElementA_;
   using StrideA  = typename Gemm::GemmKernel::StrideA;
-  using ElementB = typename Gemm::GemmKernel::ElementB;
+  using ElementB = ElementB_;
   using StrideB  = typename Gemm::GemmKernel::StrideB;
   using ScheduleType = typename Gemm::GemmKernel::CollectiveMainloop::DispatchPolicy::Schedule;
   using LayoutTagA = cutlass::detail::StrideToLayoutTagA_t<StrideA>;
   using LayoutTagB = cutlass::detail::StrideToLayoutTagB_t<StrideB>;
 
   using ElementAccumulator = typename Gemm::GemmKernel::ElementAccumulator;
   using ElementScalingFactor = ElementAccumulator;
@@ -291,37 +294,41 @@
   typename LayoutTagB::Stride stride_factor_B;
 
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
 
   cutlass::HostTensor<ElementA, LayoutTagA> tensor_A;
   cutlass::HostTensor<ElementB, LayoutTagB> tensor_B;
+  // Whether to use relative equality checks
+  CheckEquality check_relative_equality = CheckEquality::EXACT;
 
   uint64_t seed;
   static constexpr uint64_t kDefaultSeed = 4096;
 
   // Note: this limitation comes from testbed / not the library
   static_assert(is_row_or_col_major<StrideA>(),
     "ERROR : A Layout is neither Row / Column Major)");
   static_assert(is_row_or_col_major<StrideB>(),
     "ERROR : B Layout is neither Row / Column Major)");
 
   HostCollectiveMainloop(
+    CheckEquality check_relative_equality_ = CheckEquality::EXACT,
     cutlass::Distribution::Kind init_A_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_B_ = cutlass::Distribution::Uniform,
     uint64_t seed_ = kDefaultSeed,
     typename LayoutTagA::Stride stride_factor_A_ = typename LayoutTagA::Stride(),
     typename LayoutTagB::Stride stride_factor_B_ = typename LayoutTagB::Stride()
   ):
     stride_factor_A(stride_factor_A_),
     stride_factor_B(stride_factor_B_),
-    init_A(init_A_), init_B(init_B_), seed(seed_) { }
+    init_A(init_A_), init_B(init_B_), seed(seed_),
+    check_relative_equality(check_relative_equality_) { }
 
   template<class ProblemShapeType>
-  void initialize(ProblemShapeType problem_size) {
+  bool initialize(ProblemShapeType problem_size) {
     //
     // Allocate the GEMM workspace
     //
     auto problem_shape_MNKL = cute::append<4>(problem_size, 1);
     auto M = cute::size<0>(problem_shape_MNKL);
     auto N = cute::size<1>(problem_shape_MNKL);
     auto K = cute::size<2>(problem_shape_MNKL);
@@ -346,21 +353,25 @@
     // It is possible to randomly initialize to all zeros, so override this with non-zeros
     // in the upper left corner of each operand.
     tensor_A.host_view().at({0, 0}) = ElementA(1);
     tensor_B.host_view().at({0, 0}) = ElementB(1);
 
     tensor_A.sync_device();
     tensor_B.sync_device();
+
+    return true;
   }
 
   Arguments to_args() {
-    return {
-      tensor_A.device_data(), stride_a,
-      tensor_B.device_data(), stride_b
+
+    Arguments arguments = 
+    {
+      tensor_A.device_data(), stride_a, tensor_B.device_data(), stride_b
     };
+    return arguments;
   }
 
   auto to_host_args(ProblemShapeType problem_size) {
     using namespace cute;
     //
     // Allocate the GEMM workspace
     //
@@ -370,34 +381,71 @@
     auto K = cute::size<2>(problem_shape_MNKL);
     auto L = cute::size<3>(problem_shape_MNKL);
     auto A = make_tensor(make_iterator(tensor_A.host_data()),
           make_layout(make_shape(M, K, L), stride_a));
     auto B = make_tensor(make_iterator(tensor_B.host_data()),
         make_layout(make_shape(N, K, L), stride_b));
 
-    cutlass::reference::host::GettMainloopParams<ElementAccumulator, decltype(A), decltype(B)> mainloop_params{A, B, TransformA, TransformB};
+    cutlass::reference::host::GettMainloopParams<ElementAccumulator, 
+                                                 decltype(A), 
+                                                 decltype(B)
+                                                 > mainloop_params{};
+
+    mainloop_params.A = A;
+    mainloop_params.B = B;
+    mainloop_params.transform_A = TransformA;
+    mainloop_params.transform_B = TransformB;
+
     return mainloop_params;
   }
 
   void print_tensors(std::ofstream& file) {
     file << "A =\n" << tensor_A.host_view()
          << "\nB =\n" << tensor_B.host_view();
   }
 
+  template <
+    class Element,
+    class Layout
+  >
+  bool equality_check(
+    cutlass::TensorView<Element, Layout> const& lhs,
+    cutlass::TensorView<Element, Layout> const& rhs) const {
+
+    // Factors used for calculating relative equality. CUTLASS's relative-equality
+    // checks in include/cutlass/relatively_equal.h  are inspired by
+    // https://floating-point-gui.de/errors/comparison/. This reference suggests using
+    // the minimum normal value of a given type as the nonzero_floor.
+    Element epsilon(static_cast<Element>(0.1f));
+    Element nonzero_floor(std::numeric_limits<Element>::min());
+
+    if constexpr (!cutlass::is_complex<Element>::value) {
+      if (check_relative_equality == CheckEquality::RELATIVE) {
+        return cutlass::reference::host::TensorRelativelyEquals(
+          lhs, rhs, epsilon, nonzero_floor);
+      }
+      else {
+        return cutlass::reference::host::TensorEquals(lhs, rhs);
+      }
+    }
+    else {
+      return cutlass::reference::host::TensorEquals(lhs, rhs);
+    }
+  }
+
   bool compare_reference(
       cute::Shape<int,int,int,int> problem_shape_MNKL) {
-    auto [M, N, K, L] = problem_shape_MNKL;
-
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_A.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_B.host_view()), 0);
-    return true;
+
+    bool passed = true;
+    return passed;
   }
 };
 
-
 template<class Gemm>
 struct HostCollectiveDefaultEpilogue {
   // fusion types are potentially void if the fusion is not supported
   // helper so we don't try to construct HostTensor with void type
   template <typename T, typename U = uint8_t>
   using non_void_t = cute::conditional_t<cute::is_void_v<T>, U, T>;
 
@@ -470,15 +518,15 @@
     uint64_t seed_ = kDefaultSeed
   ): init_C(init_C_), seed(seed_), 
      stride_factor_C(typename LayoutTagC::Stride()), 
      stride_factor_D(typename LayoutTagD::Stride()),
      check_relative_equality(check_relative_equality_),
      use_device_scalars(use_device_scalars_){ }
 
-  void initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
+  bool initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
     // Initialize Epilogue tensors
     auto problem_shape_MNKL = cute::append<4>(problem_size, 1);
     auto [M, N, K, L] = problem_shape_MNKL;
 
     stride_c = cutlass::make_cute_packed_stride(StrideC{}, cute::make_shape(M, N, L));
     stride_d = cutlass::make_cute_packed_stride(StrideD{}, cute::make_shape(M, N, L));
 
@@ -492,29 +540,31 @@
 
     cutlass::reference::host::TensorCopy(reference_D.host_view(), tensor_C.host_view());
     tensor_C.sync_device();
     tensor_D.sync_device();
 
     alpha = alpha_;
     beta = beta_;
+
+    return true;
   }
 
   template <
     class Element,
     class Layout
   >
   bool equality_check(
     cutlass::TensorView<Element, Layout> const& lhs,
     cutlass::TensorView<Element, Layout> const& rhs) const {
 
     // Factors used for calculating relative equality. CUTLASS's relative-equality
     // checks in include/cutlass/relatively_equal.h  are inspired by
     // https://floating-point-gui.de/errors/comparison/. This reference suggests using
     // the minimum normal value of a given type as the nonzero_floor.
-    Element epsilon(0.1f);
+    Element epsilon(static_cast<Element>(0.1f));
     Element nonzero_floor(std::numeric_limits<Element>::min());
 
     if constexpr (!cutlass::is_complex<Element>::value) {
       if (check_relative_equality == CheckEquality::RELATIVE) {
         return cutlass::reference::host::TensorRelativelyEquals(
           lhs, rhs, epsilon, nonzero_floor);
       }
@@ -555,15 +605,14 @@
     file
     << "\nC =\n" << tensor_C.host_view()
     << "\n\nReference =\n" << reference_D.host_view()
     << "\n\nComputed =\n" << tensor_D.host_view();
   }
 
   Arguments to_args(ProblemShapeType problem_size) {
-    auto coord_0 = cutlass::make_Coord(0);
     Arguments arguments = 
       {
         {alpha, beta},
         tensor_C.device_data(), stride_c, tensor_D.device_data(), stride_d
       };
 
     return arguments;
@@ -689,14 +738,15 @@
   cutlass::HostTensor<ElementScalar, LayoutTagScalar> scale_A;
   cutlass::HostTensor<ElementScalar, LayoutTagScalar> scale_B;
   cutlass::HostTensor<ElementScalar, LayoutTagScalar> scale_C;
   cutlass::HostTensor<ElementScalar, LayoutTagScalar> scale_D;
   cutlass::HostTensor<ElementScalar, LayoutTagScalar> scale_Aux;
   cutlass::HostTensor<ElementBias  , LayoutTagVector> bias;
   cutlass::HostTensor<ElementC, LayoutTagC> tensor_C;
+  cutlass::HostTensor<ElementCompute, LayoutTagScalar> norm_constant;
 
   // Outputs
   cutlass::HostTensor<ElementAmax, LayoutTagScalar> abs_max_Aux;
   cutlass::HostTensor<ElementAmax, LayoutTagScalar> abs_max_D;
   cutlass::HostTensor<ElementAux , LayoutTagAux   > tensor_Aux;
   cutlass::gemm::TagToStrideC_t<   LayoutTagAux   > stride_Aux;
   cutlass::HostTensor<ElementD, LayoutTagD> tensor_D;
@@ -734,18 +784,21 @@
   ): init_scale(init_scale_), init_bias(init_bias_), 
      init_C(init_C_), seed(seed_), 
      stride_factor_C(typename LayoutTagC::Stride()), 
      stride_factor_D(typename LayoutTagD::Stride()),
      check_relative_equality(check_relative_equality_),
      use_device_scalars(use_device_scalars_){ }
 
-  void initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
+  bool initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
     // Initialize Epilogue tensors
     auto problem_shape_MNKL = cute::append<4>(problem_size, 1);
-    auto [M, N, K, L] = problem_shape_MNKL;
+    auto M = cute::size<0>(problem_shape_MNKL);
+    auto N = cute::size<1>(problem_shape_MNKL);
+    auto K = cute::size<2>(problem_shape_MNKL);
+    auto L = cute::size<3>(problem_shape_MNKL);
 
     stride_c = cutlass::make_cute_packed_stride(StrideC{}, cute::make_shape(M, N, L));
     stride_d = cutlass::make_cute_packed_stride(StrideD{}, cute::make_shape(M, N, L));
 
     // 2.x host tensor does not natively contain a batch stride or coord, so we spoof if by folding it into the outer mode
     auto c_coord = cutlass::make_Coord(M * L, N);
     tensor_C.resize(c_coord, cutlass::layout::Affine2Layout_Factory<LayoutTagC>::layout_factory(c_coord, stride_factor_C));
@@ -850,29 +903,30 @@
                                              CUTLASS_STL_NAMESPACE::numeric_limits<ElementAmax>::max());
         abs_max_Aux.sync_device();
         reference_abs_max_Aux.resize(scalar_coord);
         cutlass::reference::host::TensorFill(reference_abs_max_Aux.host_view(), ElementAmax(0));
       }
     }
 
+    return true;
   }
 
   template <
     class Element,
     class Layout
   >
   bool equality_check(
     cutlass::TensorView<Element, Layout> const& lhs,
     cutlass::TensorView<Element, Layout> const& rhs) const {
 
     // Factors used for calculating relative equality. CUTLASS's relative-equality
     // checks in include/cutlass/relatively_equal.h  are inspired by
     // https://floating-point-gui.de/errors/comparison/. This reference suggests using
     // the minimum normal value of a given type as the nonzero_floor.
-    Element epsilon(0.1f);
+    Element epsilon(static_cast<Element>(0.1f));
     Element nonzero_floor(std::numeric_limits<Element>::min());
 
     if constexpr (!cutlass::is_complex<Element>::value) {
       if (check_relative_equality == CheckEquality::RELATIVE) {
         return cutlass::reference::host::TensorRelativelyEquals(
           lhs, rhs, epsilon, nonzero_floor);
       }
@@ -885,16 +939,14 @@
     }
   }
 
   bool compare_reference(
       cute::Shape<int,int,int,int> problem_shape_MNKL,
       ElementScalar alpha,
       ElementScalar beta) {
-    auto [M, N, K, L] = problem_shape_MNKL;
-
     tensor_D.sync_host();
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_C.host_view()), 0);
 
     if (tensor_D.size() > 1) {
       EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_D.host_view()), 0);
     }
 
@@ -1165,21 +1217,23 @@
     return epilogue_params;
   }
 };
 
 template <
   typename Gemm,
   template <class T> class ActivationFunctor_ = cutlass::epilogue::thread::Identity,
-  bool force_legacy_epilogue = false
+  bool force_legacy_epilogue = false,
+  typename ElementA = typename Gemm::GemmKernel::ElementA,
+  typename ElementB = typename Gemm::GemmKernel::ElementB
 >
 struct TestbedImpl {
   // Kernel data types
   using ScheduleType = typename Gemm::GemmKernel::CollectiveMainloop::DispatchPolicy::Schedule;
   // All Collective MMA operands are defined by HostCollectiveMainloopType based on the schedule type
-  using HostCollectiveMainloopType = HostCollectiveMainloop<ScheduleType, Gemm>;
+  using HostCollectiveMainloopType = HostCollectiveMainloop<ScheduleType, Gemm, ElementA, ElementB>;
   using CollectiveEpilogue = cute::conditional_t<IsDefaultEpilogue<typename Gemm::GemmKernel::CollectiveEpilogue>::value || force_legacy_epilogue, 
                                                 HostCollectiveDefaultEpilogue<Gemm>, 
                                                 HostCollectiveEpilogue<Gemm>>;
   
   using ProblemShapeType = typename Gemm::GemmKernel::ProblemShape;
   using ElementAccumulator = typename Gemm::GemmKernel::ElementAccumulator;
   using ElementCompute = typename ElementComputeType<Gemm, ElementAccumulator>::Type;
@@ -1211,15 +1265,15 @@
     VectorBeta disable_vector_beta_ = VectorBeta::DISABLED,
     cutlass::Distribution::Kind init_A_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_B_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_C_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_scale_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_bias_ = cutlass::Distribution::Uniform,
     uint64_t seed_ = kDefaultSeed
-  ): collective_mma_inputs(HostCollectiveMainloopType(init_A_, init_B_, seed_)), 
+  ): collective_mma_inputs(HostCollectiveMainloopType(check_relative_equality_, init_A_, init_B_, seed_)), 
      collective_epilogue(CollectiveEpilogue(check_relative_equality_, use_device_scalars_, disable_vector_beta_, init_C_, init_scale_, init_bias_, seed_)) { }
 
   TestbedImpl(
     typename LayoutTagA::Stride stride_factor_A_,
     typename LayoutTagB::Stride stride_factor_B_,
     typename LayoutTagC::Stride stride_factor_C_,
     typename LayoutTagD::Stride stride_factor_D_,
@@ -1228,21 +1282,23 @@
     VectorBeta disable_vector_beta_ = VectorBeta::DISABLED,
     cutlass::Distribution::Kind init_A_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_B_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_C_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_scale_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_bias_ = cutlass::Distribution::Uniform,
     uint64_t seed_ = kDefaultSeed
-  ): collective_mma_inputs(HostCollectiveMainloopType(stride_factor_A_, stride_factor_B_, init_A_, init_B_, seed_)),
+  ): collective_mma_inputs(HostCollectiveMainloopType(check_relative_equality_, stride_factor_A_, stride_factor_B_, init_A_, init_B_, seed_)),
      collective_epilogue(CollectiveEpilogue(check_relative_equality_, use_device_scalars_, disable_vector_beta_, init_C_, init_scale_, init_bias_, seed_)) { }
 
   /// Initializes data structures
-  void initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
+  bool initialize(ProblemShapeType problem_size, ElementScalar alpha_=1.f, ElementScalar beta_=0.f) {
     collective_mma_inputs.initialize(problem_size);
     collective_epilogue.initialize(problem_size, alpha_, beta_);
+
+    return true;
   }
 
   /// Compares computed reference with device reference and outputs to a file if incorrect
   bool compare_reference(
       cute::Shape<int,int,int,int> problem_shape_MNKL,
       ElementScalar alpha,
       ElementScalar beta)
@@ -1276,16 +1332,14 @@
   bool verify(
       ProblemShapeType problem_size,
       ElementScalar alpha,
       ElementScalar beta)
   {
     using namespace cute;
     auto problem_shape_MNKL = cute::append<4>(problem_size, 1);
-    auto [M, N, K, L] = problem_shape_MNKL;
-
     auto mainloop_params = collective_mma_inputs.to_host_args(problem_size);
     auto epilogue_params = collective_epilogue.to_host_args(problem_size);
     
     cutlass::reference::host::Gemm3x(mainloop_params, epilogue_params);
 
     bool passed = compare_reference(problem_shape_MNKL, alpha, beta);
     return passed;
@@ -1293,15 +1347,15 @@
 
 	/// Determine if the CUDA device is sufficient to run the kernel
   bool sufficient() {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = Gemm::GemmKernel::SharedStorageSize;
+    size_t smem_size = static_cast<size_t>(Gemm::GemmKernel::SharedStorageSize);
 
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
     }
@@ -1367,24 +1421,28 @@
     ElementScalar alpha = ElementScalar(1),
     ElementScalar beta = ElementScalar(0),
     bool profiling = false,
     detail::Iterations iterations = detail::Iterations{},
     RasterOrderOptions raster_order = RasterOrderOptions::Heuristic,
     detail::MaxSwizzleSize max_swizzle = detail::MaxSwizzleSize{},
     detail::Splits splits = detail::Splits{},
-    DecompositionMode decomposition_mode = DecompositionMode::Heuristic)
+    DecompositionMode decomposition_mode = DecompositionMode::Heuristic
+    )
   {
 
     // Fail test if insufficient CUDA device
     if (!sufficient()) {
       std::cout << "Test failed due to insufficient CUDA device." << std::endl;
       return false;
     }
 
-    this->initialize(problem_size, alpha, beta);
+    if (!this->initialize(problem_size, alpha, beta)) {
+      std::cerr << "Initialization failed \n";
+      return false;
+    }
 
     //
     // Initialize the GEMM operator
     //
 
     typename Gemm::Arguments arguments;
     cutlass::KernelHardwareInfo hw_info;
@@ -1395,24 +1453,29 @@
     }
     else {
       this->sm_count = cutlass::KernelHardwareInfo::query_device_multiprocessor_count(hw_info.device_id);
       hw_info.sm_count = this->sm_count;
     }
 
     typename Gemm::GemmKernel::TileScheduler::Arguments scheduler_args;
-    if constexpr (std::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>) {
+    if constexpr (cute::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>) {
       scheduler_args = { static_cast<int>(splits), static_cast<int>(max_swizzle), raster_order, decomposition_mode };
     }
     else {
       scheduler_args = { static_cast<int>(max_swizzle), raster_order };
     }
-    arguments = {
+    typename HostCollectiveMainloopType::Arguments mainloop_args;
+
+    mainloop_args = collective_mma_inputs.to_args();
+
+    arguments =
+    {
       cutlass::gemm::GemmUniversalMode::kGemm,
       problem_size,
-      collective_mma_inputs.to_args(),
+      mainloop_args,
       collective_epilogue.to_args(problem_size),
       hw_info,
       scheduler_args
     };
 
 
     Gemm gemm_op;
@@ -1467,19 +1530,27 @@
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Gemm,
   template <class T> class ActivationFunctor = cutlass::epilogue::thread::Identity,
-  bool force_legacy_epilogue = false
+  bool force_legacy_epilogue = false,
+  typename ElementA = typename Gemm::GemmKernel::ElementA,
+  typename ElementB = typename Gemm::GemmKernel::ElementB
 >
 struct Testbed3x {
 
-  using TestBedImpl = typename detail::TestbedImpl<Gemm, ActivationFunctor, force_legacy_epilogue>;
+  using TestBedImpl = typename detail::TestbedImpl<
+                        Gemm, 
+                        ActivationFunctor, 
+                        force_legacy_epilogue, 
+                        ElementA, 
+                        ElementB
+                        >;
   using Kernel      = typename Gemm::GemmKernel;
   using Epilogue    = typename Gemm::GemmKernel::CollectiveEpilogue;
 
   using ElementAccumulator   = typename TestBedImpl::ElementAccumulator;
   using ElementCompute       = typename TestBedImpl::ElementCompute;
   using ElementScalar        = typename TestBedImpl::ElementScalar;
 
@@ -1510,15 +1581,16 @@
     ElementScalar alpha = ElementScalar(1),
     ElementScalar beta = ElementScalar(0),
     RasterOrderOptions raster_order = RasterOrderOptions::Heuristic,
     detail::MaxSwizzleSize max_swizzle = detail::MaxSwizzleSize{},
     detail::Splits splits = detail::Splits{},
     DecompositionMode decomposition_mode = DecompositionMode::Heuristic,
     bool profiling = false,
-    detail::Iterations iterations = detail::Iterations{})
+    detail::Iterations iterations = detail::Iterations{}
+    )
   {
     return impl_.run(
         problem_size, alpha, beta, profiling, iterations, raster_order, max_swizzle, splits, decomposition_mode
         );
   }
 };
 
@@ -1578,29 +1650,29 @@
 
   Testbed3x<Gemm, ActivationFunctor> testbed(check_relative_equality, ScalarLoc::ON_HOST, VectorBeta::DISABLED);
 
   int max_alignment = std::max(Gemm::kAlignmentA, Gemm::kAlignmentB);
   std::vector<int> problem_size_m = {max_alignment, 512 - 3 * max_alignment};
   std::vector<int> problem_size_n = {max_alignment, 512 - 2 * max_alignment};
 
-  if constexpr (std::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
+  if constexpr (cute::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
                 cutlass::gemm::KernelTmaWarpSpecializedPingpong>) {
     problem_size_m.push_back(768);
     problem_size_n.push_back(768);
   }
 
   constexpr int Stages = Gemm::GemmKernel::DispatchPolicy::Stages;
   constexpr int TileShapeK = cute::size<2>(typename Gemm::GemmKernel::TileShape{});
 
   std::vector<int> problem_size_k = {max_alignment, TileShapeK * (Stages + 1) - max_alignment};
 
   using DecompositionMode = typename cutlass::gemm::kernel::detail::PersistentTileSchedulerSm90StreamKParams::DecompositionMode;
   std::vector<DecompositionMode> decomposition_modes = {DecompositionMode::Heuristic};
   std::vector problem_splits = {detail::Splits{1}};
-  static constexpr bool UsesStreamKScheduler = std::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>;
+  static constexpr bool UsesStreamKScheduler = cute::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>;
   if constexpr (UsesStreamKScheduler) {
     problem_splits.push_back(detail::Splits{2});
     problem_splits.push_back(detail::Splits{3});
 
     decomposition_modes.push_back(DecompositionMode::DataParallel);
     decomposition_modes.push_back(DecompositionMode::SplitK);
     decomposition_modes.push_back(DecompositionMode::StreamK);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_evt.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_evt.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -159,22 +159,23 @@
 >
 class HostScalarBroadcast : public HostEVTNodeBase<Gemm> {
 public:
   using Base = HostEVTNodeBase<Gemm>;
   using ElementCompute = typename Base::ElementCompute;
 
   struct Arguments {
-    ElementCompute scalar[BroadcastCount];
-    ElementCompute const* scalar_ptrs[BroadcastCount];
-    cute::Stride<cute::_0,cute::_0,cute::_0> dScalar;
+    ElementCompute scalar[BroadcastCount] = {0};
+    ElementCompute const* scalar_ptrs[BroadcastCount] = { nullptr };
+    cute::Stride<cute::_0,cute::_0,cute::_0> dScalar{};
   };
 private:
-  ElementCompute _scalar;
+  ElementCompute _scalar{};
 public:
   HostScalarBroadcast(){}
+
   template<typename ProblemShapeType, typename TestBedImpl>
   HostScalarBroadcast(ProblemShapeType problem_size, TestBedImpl impl, bool check_relative_equality=false)
     : Base(check_relative_equality), _scalar(ElementCompute(Value)) {}
   
   template <class ElementAccumulator>
   ElementCompute visit(
     int64_t m, int64_t n, int64_t l, int m_b, int n_b,
@@ -1309,15 +1310,15 @@
     }
     else {
       impl_.sm_count = cutlass::KernelHardwareInfo::query_device_multiprocessor_count(hw_info.device_id);
       hw_info.sm_count = impl_.sm_count;
     }
 
     typename Gemm::GemmKernel::TileScheduler::Arguments scheduler_args;
-    if constexpr (std::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>) {
+    if constexpr (cute::is_same_v<typename Gemm::GemmKernel::TileSchedulerTag, cutlass::gemm::StreamKScheduler>) {
       scheduler_args = { splits };
     }
 
     /// Initializes data structures
     /// A/B/C/D Tensor
     initialize(problem_size);
 
@@ -1395,15 +1396,15 @@
 bool TestAllEVT(bool check_relative_equality=false) {
   using ProblemShapeType = typename Gemm::GemmKernel::ProblemShape;
 
   int max_alignment = std::max(Gemm::kAlignmentA, Gemm::kAlignmentB);
   std::vector<int> problem_size_m = {max_alignment, 512 - 3 * max_alignment};
   std::vector<int> problem_size_n = {max_alignment, 512 - 2 * max_alignment};
 
-  if constexpr (std::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
+  if constexpr (cute::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
         cutlass::gemm::KernelTmaWarpSpecializedPingpong>) {
   problem_size_m.push_back(768);
   problem_size_n.push_back(768);
   }
 
   constexpr int Stages = Gemm::GemmKernel::DispatchPolicy::Stages;
   constexpr int TileShapeK = cute::size<2>(typename Gemm::GemmKernel::TileShape{});
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_tensor_broadcast.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x_tensor_broadcast.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -435,15 +435,15 @@
   using ElementScalar = typename Gemm::GemmKernel::CollectiveEpilogue::ElementScalar;
   using ProblemShapeType = typename Gemm::GemmKernel::ProblemShape;
 
   int max_alignment = std::max(Gemm::kAlignmentA, Gemm::kAlignmentB);
   std::vector<int> problem_size_m = {max_alignment, 512 - 3 * max_alignment};
   std::vector<int> problem_size_n = {max_alignment, 512 - 2 * max_alignment};
 
-  if constexpr (std::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
+  if constexpr (cute::is_same_v<typename Gemm::GemmKernel::DispatchPolicy::Schedule,
                 cutlass::gemm::KernelTmaWarpSpecializedPingpong>) {
     problem_size_m.push_back(768);
     problem_size_n.push_back(768);
   }
 
   constexpr int Stages = Gemm::GemmKernel::DispatchPolicy::Stages;
   constexpr int TileShapeK = cute::size<2>(typename Gemm::GemmKernel::TileShape{});
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32_sm80.cu`

 * *Files 12% similar despite different names*

```diff
@@ -50,20 +50,18 @@
 #include "testbed_universal.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 ////////////////////////////////////////////////////////////////////////////////
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x128x64_64x64x64) {
 
-
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x128x64_64x64x64) {
-
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
@@ -77,29 +75,29 @@
     cutlass::gemm::GemmShape<64, 64, 64>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
     4,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    16,  // AlignmentA
+    8, // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x128x32_64x64x32) {
 
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
@@ -113,29 +111,29 @@
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
     4,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    16,  // AlignmentA
+    8, // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 64x128x32_32x64x32) {
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 64x128x32_32x64x32) {
 
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
@@ -149,30 +147,65 @@
     cutlass::gemm::GemmShape<32, 64, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
     4,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    16, // AlignmentA
+    8,  // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
 ////////////////////////////////////////////////////////////////////////////////
 
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 64x64x32_32x32x32) {
 
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x32x32) {
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
 
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<32, 32, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    8,  // Stages
+    16, // AlignmentA
+    8,  // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x32x32) {
+
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
@@ -185,89 +218,162 @@
     cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 32, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    8,   // Stages
+    16,  // AlignmentA
+    8,   // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x64x32) {
 
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
     cutlass::layout::ColumnMajor, 
     ElementOutput, 
     cutlass::layout::RowMajor,
     ElementAccumulator, 
     cutlass::arch::OpClassTensorOp, 
     cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<32, 32, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    8,   // Stages
+    16,  // AlignmentA
+    8,   // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
+
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_bf16t_s8n_bf16t_mixed_input_tensor_op_f32, 16x128x32_16x64x32) {
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x32x32_64x32x32) {
 
-  using ElementA = cutlass::bfloat16_t;
-  using ElementB = int8_t;
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
   using ElementOutput = cutlass::bfloat16_t;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::GemmUniversal<
     ElementA, 
     cutlass::layout::RowMajor, 
     ElementB,
     cutlass::layout::ColumnMajor, 
     ElementOutput, 
     cutlass::layout::RowMajor,
     ElementAccumulator, 
     cutlass::arch::OpClassTensorOp, 
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<16, 128, 32>,
-    cutlass::gemm::GemmShape<16, 64, 32>,
+    cutlass::gemm::GemmShape<128, 32, 32>,
+    cutlass::gemm::GemmShape<64, 32, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,  // Stages
-    8,  // AlignmentA
-    16, // AlignmentB
+    8,   // Stages
+    16,  // AlignmentA
+    8,   // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x16x32_64x16x32) {
+
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 16, 32>,
+    cutlass::gemm::GemmShape<64, 16, 32>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 4,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4,   // Stages
+    16,  // AlignmentA
+    8,   // AlignmentB
+    cutlass::arch::OpMultiplyAddMixedInputUpcast,
+    cutlass::ComplexTransform::kNone,
+    cutlass::ComplexTransform::kNone
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+}
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x16x64_64x16x64) {
+
+  using ElementA = int8_t;
+  using ElementB = cutlass::bfloat16_t;
+  using ElementOutput = cutlass::bfloat16_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::GemmUniversal<
+    ElementA, 
+    cutlass::layout::RowMajor, 
+    ElementB,
+    cutlass::layout::ColumnMajor, 
+    ElementOutput, 
+    cutlass::layout::RowMajor,
+    ElementAccumulator, 
+    cutlass::arch::OpClassTensorOp, 
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 16, 64>,
+    cutlass::gemm::GemmShape<64, 16, 64>,
+    cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 4,
+          ElementAccumulator, ElementAccumulator>,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
+    4,   // Stages
+    16,  // AlignmentA
+    8,   // AlignmentB
     cutlass::arch::OpMultiplyAddMixedInputUpcast,
     cutlass::ComplexTransform::kNone,
     cutlass::ComplexTransform::kNone
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_s8n_f16t_mixed_input_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_s8n_f16t_mixed_input_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_u8n_f16t_mixed_input_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16t_u8n_f16t_mixed_input_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu`

 * *Files 12% similar despite different names*

```diff
@@ -26,359 +26,281 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
-    
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
 
-#include "cutlass/gemm/device/gemm_universal.h"
+#include "cutlass/gemm/device/gemm.h"
 
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/reference/host/gemm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_universal.h"
+#include "testbed.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 ////////////////////////////////////////////////////////////////////////////////
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x128x64_64x64x64) {
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 64>,
-    cutlass::gemm::GemmShape<64, 64, 64>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 64x64x32_32x32x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 64, 32>,
+      cutlass::gemm::GemmShape<32, 32, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4,  // Stages
-    16,  // AlignmentA
-    8, // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 10>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 32x128x32_32x32x32) {
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<32, 128, 32>,
+      cutlass::gemm::GemmShape<32, 32, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4,  // Stages
-    16,  // AlignmentA
-    8, // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 64x128x32_32x64x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 32x256x32_32x64x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<32, 256, 32>,
+      cutlass::gemm::GemmShape<32, 64, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4,  // Stages
-    16, // AlignmentA
-    8,  // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 128x32x32_32x32x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<32, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 32, 32>,
+      cutlass::gemm::GemmShape<32, 32, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,  // Stages
-    16, // AlignmentA
-    8,  // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x32x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 256x32x32_64x32x32) {
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 32, 32>,
+      cutlass::gemm::GemmShape<64, 32, 32>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,   // Stages
-    16,  // AlignmentA
-    8,   // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x64x32_64x64x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 32x128x64_32x32x64) {
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<32, 128, 64>,
+      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,   // Stages
-    16,  // AlignmentA
-    8,   // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-////////////////////////////////////////////////////////////////////////////////
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 32x256x64_32x64x64) {
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x32x32_64x32x32) {
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 32, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<32, 256, 64>,
+      cutlass::gemm::GemmShape<32, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
       cutlass::epilogue::thread::LinearCombination<
           ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
           ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    8,   // Stages
-    16,  // AlignmentA
-    8,   // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x16x32_64x16x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 128x32x64_32x32x64) {
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 16, 32>,
-    cutlass::gemm::GemmShape<64, 16, 32>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
-      cutlass::epilogue::thread::LinearCombination<
-          ElementOutput, 4,
-          ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4,   // Stages
-    16,  // AlignmentA
-    8,   // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 32, 64>,
+      cutlass::gemm::GemmShape<32, 32, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
-////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_GemmUniversal_s8t_bf16n_bf16t_mixed_input_tensor_op_f32, 128x16x64_64x16x64) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 256x32x64_64x32x64) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 32, 64>,
+      cutlass::gemm::GemmShape<64, 32, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  using ElementA = int8_t;
-  using ElementB = cutlass::bfloat16_t;
-  using ElementOutput = cutlass::bfloat16_t;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::GemmUniversal<
-    ElementA, 
-    cutlass::layout::RowMajor, 
-    ElementB,
-    cutlass::layout::ColumnMajor, 
-    ElementOutput, 
-    cutlass::layout::RowMajor,
-    ElementAccumulator, 
-    cutlass::arch::OpClassTensorOp, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 16, 64>,
-    cutlass::gemm::GemmShape<64, 16, 64>,
-    cutlass::gemm::GemmShape<16, 8, 16>,
-      cutlass::epilogue::thread::LinearCombination<
-          ElementOutput, 4,
-          ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4,   // Stages
-    16,  // AlignmentA
-    8,   // AlignmentB
-    cutlass::arch::OpMultiplyAddMixedInputUpcast,
-    cutlass::ComplexTransform::kNone,
-    cutlass::ComplexTransform::kNone
-  >;
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 16x128x64_16x32x64) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<16, 128, 64>,
+      cutlass::gemm::GemmShape<16, 32, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 16x256x64_16x64x64) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<16, 256, 64>,
+      cutlass::gemm::GemmShape<16, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 128x16x64_32x16x64) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<128, 16, 64>,
+      cutlass::gemm::GemmShape<32, 16, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f32, 256x16x64_64x16x64) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = float;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+      cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t,
+      cutlass::layout::RowMajor, ElementOutput, cutlass::layout::RowMajor,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<256, 16, 64>,
+      cutlass::gemm::GemmShape<64, 16, 64>, cutlass::gemm::GemmShape<16, 8, 16>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 64 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 5>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemmUniversal<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 ////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif  // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_s8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_universal_u8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_u8t_f16n_f16t_mixed_input_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files 5% similar despite different names*

```diff
@@ -453,12 +453,44 @@
   >::GemmKernel;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   test::gemm::device::TestAllGemmWithBroadcast<Gemm, GemmWithBiasReluReferenceOp<Gemm> >();
 }
 
+TEST(SM80_Device_GemmWithBroadcast_RELU_f32n_f32n_f32n_tensor_op_f32, 64x64_16x10_32x32x16_16x8x8) {
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationBiasRelu<
+    float,
+    float,
+    float,
+    float,
+    4,
+    false
+  >;
+
+  using GemmKernel =
+    typename cutlass::gemm::kernel::DefaultGemmWithBroadcast<
+      float, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 4,    // transposed B operand
+      float, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 4,    // transposed A operand
+      float, cutlass::layout::RowMajor,
+      float,
+      cutlass::arch::OpClassTensorOp,
+      cutlass::arch::Sm80,
+      cutlass::gemm::GemmShape<64, 64, 16>,
+      cutlass::gemm::GemmShape<32, 32, 16>,
+      cutlass::gemm::GemmShape<16, 8, 8>,
+      EpilogueOutputOp,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+      10,
+      cutlass::arch::OpMultiplyAdd
+  >::GemmKernel;
+
+  using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
+
+  test::gemm::device::TestAllGemmWithBroadcast<Gemm, GemmWithBiasReluReferenceOp<Gemm> >();
+}
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #endif
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/gemv.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -109,15 +109,15 @@
 
   /// Waives test if CUDA device is insufficient
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h`

 * *Files 1% similar despite different names*

```diff
@@ -114,15 +114,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu`

 * *Files 16% similar despite different names*

```diff
@@ -25,272 +25,228 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide GEMM interface
-    
+    \brief Tests for device-wide TRMM interface
+
+  
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm.h"
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/device/trmm.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/trmm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed.h"
+#include "testbed_trmm_universal.h"
 
-    
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
-////////////////////////////////////////////////////////////////////////////////
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 32x64x8_32x64x1) {
-  
-  using Element = float;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 64, 8>,
-    cutlass::gemm::GemmShape<32, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    4
-  >;
+////////////////////////////////////////////Test name//////////////////////////////////////////////////
+//                             
+// SM80_Device_Trmm_{ElementA}{LayoutA}_{ElementB}{LayoutB}_{ElementC}{LayoutC}_{SideMode}_{FillMode}\
+//    _{DiagType}_tensor_op_{ElementAccumulator}_align{AlignmentA}_align{AlignmentB}
+//
+///////////////////////////////////////////////////////////////////////////////////////////////////////
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-}
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 64x64x8_32x64x1) {
-  
-  using Element = float;
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 8>,
-    cutlass::gemm::GemmShape<32, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x128x8_32x64x1) {
-  
-  using Element = float;
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 128x64x32_32x64x32) {
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 8>,
-    cutlass::gemm::GemmShape<32, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
-TEST(SM80_Device_Gemm_f32at_f32an_f32t_simt_f32, 128x128x8_32x64x1) {
-  
-  using Element = float;
-  using LayoutA = cutlass::layout::AffineRank2RowMajor;
-  using LayoutB = cutlass::layout::AffineRank2ColumnMajor;
-  using LayoutC = cutlass::layout::RowMajor;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    LayoutA,
-    Element, 
-    LayoutB,
-    Element,
-    LayoutC, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 8>,
-    cutlass::gemm::GemmShape<32, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
-
-  typename LayoutA::Stride::Index stride_factor_A[] = {3, 4};
-  typename LayoutB::Stride::Index stride_factor_B[] = {5, 6};
-  typename LayoutC::Stride::Index stride_factor_C[] = {1};
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>( stride_factor_A, stride_factor_B, stride_factor_C ));
-}
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 64x128x8_32x64x1) {
-  
-  using Element = float;
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 8>,
-    cutlass::gemm::GemmShape<32, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x64x8_64x32x1) {
-  
-  using Element = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 8>,
-    cutlass::gemm::GemmShape<64, 32, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-}
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x128x8_64x64x1) {
-  
-  using Element = float;
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 8>,
-    cutlass::gemm::GemmShape<64, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Gemm_f32t_f32n_f32t_simt_f32, 128x256x8_64x64x1) {
-  
-  using Element = float;
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 128x64x32_32x64x32) {
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    Element, 
-    cutlass::layout::RowMajor,
-    Element, 
-    cutlass::layout::ColumnMajor,
-    Element,
-    cutlass::layout::RowMajor, 
-    Element,
-    cutlass::arch::OpClassSimt, 
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 256, 8>,
-    cutlass::gemm::GemmShape<64, 64, 8>, 
-    cutlass::gemm::GemmShape<1, 1, 1>,
-    cutlass::epilogue::thread::LinearCombination<
-        Element, 
-        1,
-        Element, 
-        Element>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, 
-    3
-  >;
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::epilogue::thread::LinearCombination<
+      float,
+      1,
+      float,
+      float
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
+
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_evt_operations.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_evt_operations.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -190,20 +190,20 @@
 // else
 //   D = activation(Z)
 // if Aux is fp8
 //   amax_aux = max(abs(elements in Z))
 //   Aux = scale_aux * Z
 // else
 //   Aux = Z
-template <class Gemm, template <class> class ActivationFn, class ElementD>
+template <class Gemm, template <class> class ActivationFn, class ElementD, class ElementAux = ElementD>
 class HostScaledLinCombPerRowBiasEltActAmaxAux {
 public:
   template <typename T>
   using amax = cutlass::maximum_absolute_value_reduction<T, true>;
-  using EVTModule = HEVT<
+  using EVTModuleAuxFp8 = HEVT<
     HostAuxStore<Gemm, true>,
     HST<Gemm,
       // Z = scale_a * scale_b * alpha * acc + scale_c * beta * C + per-row bias
       HEVT<
         HostCompute<Gemm, cutlass::homogeneous_multiply_add>,
         HostScalarBroadcast<Gemm, 1, 2>, // scale_c * beta
         HostAuxLoad<Gemm, true>, // C
@@ -224,26 +224,60 @@
             HostAccumulator<Gemm> // Z
           >
         >,
         HostScalarBroadcast<Gemm, 1> // scale_d
       >,
       // Aux = Z * scale_aux, amax_aux = max(abs(elements in Aux))
       HEVT<
-        HostAuxStore<Gemm, false, ElementD, cutlass::layout::RowMajor>,
+        HostAuxStore<Gemm, false, ElementAux, cutlass::layout::RowMajor>,
         HEVT<
-          HostCompute<Gemm, cutlass::epilogue::fusion::detail::ScaleOutOp<ElementD>::template Op>,
+          HostCompute<Gemm, cutlass::multiplies>,
           HEVT<
             HostScalarReduce<Gemm, amax, float>,
             HostAccumulator<Gemm>
             >,
           HostScalarBroadcast<Gemm, 1>
         >
       >
     >
   >;
+
+  using EVTModuleAuxNotFp8 = HEVT<
+    // D = activation(Z) * scaled_d, amax_d = max(abs(elements in D))
+    HostAuxStore<Gemm, true>,
+      HEVT<
+        HostCompute<Gemm, cutlass::epilogue::fusion::detail::ScaleOutOp<ElementD>::template Op>,
+        HEVT<
+          HostScalarReduce<Gemm, amax, float>,
+          HEVT<
+            HostCompute<Gemm, ActivationFn>, //activation(Z) * scaled_d
+            HEVT<
+              // Aux = Z
+              HostAuxStore<Gemm, false, ElementAux, cutlass::layout::RowMajor>,
+              // Z = scale_a * scale_b * alpha * acc + scale_c * beta * C + per-row bias
+              HEVT<
+                HostCompute<Gemm, cutlass::homogeneous_multiply_add>,
+                HostScalarBroadcast<Gemm, 1, 2>, // scale_c * beta
+                HostAuxLoad<Gemm, true>, // C
+                HEVT<
+                  HostCompute<Gemm, cutlass::homogeneous_multiply_add>,
+                  HostScalarBroadcast<Gemm, 1, 3>, // scale_a * scale_b * alpha
+                  HostAccumulator<Gemm>,
+                  HostColBroadcast<Gemm, ElementD>
+                >
+              >
+            >
+          >
+        >,
+        HostScalarBroadcast<Gemm, 1> // scale_d
+      >
+    >;
+      
+  using EVTModule = cute::conditional_t<cutlass::epilogue::fusion::detail::is_fp8_v<ElementAux>, EVTModuleAuxFp8, EVTModuleAuxNotFp8>;
+
 };
 } // namespace test::gemm::device
 
 //////////////////////////////////////////////////////////////////////////////
 namespace cutlass::epilogue {
 namespace fusion {
 
@@ -396,15 +430,15 @@
   class CtaTileShapeMNK,
   class ElementOutput,
   class ElementCompute,
   class ElementScalar = ElementCompute,
   FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
 >
 using Sm90LinCombPerColumnReduce =
-  Sm90EVT<Sm90RowReduction<RegReduceFn, GmemReduceFn, 0, CtaTileShapeMNK, ElementReduce, ElementCompute, RoundStyle>, // per column reduce
+  Sm90EVT<Sm90RowReduction<RegReduceFn, RegReduceFn, GmemReduceFn, 0, CtaTileShapeMNK, ElementReduce, ElementCompute, RoundStyle>, // per column reduce
     Sm90EVT<Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>, // beta * C + alpha * acc
       Sm90ScalarBroadcast<ElementScalar>, // beta
       Sm90SrcFetch<ElementOutput>, // C
       Sm90EVT<Sm90Compute<multiplies, ElementCompute, ElementCompute, RoundStyle>, // alpha * acc
         Sm90ScalarBroadcast<ElementScalar>, // alpha
         Sm90AccFetch // acc
       >
@@ -421,15 +455,15 @@
   class CtaTileShapeMNK,
   class ElementOutput,
   class ElementCompute,
   class ElementScalar = ElementCompute,
   FloatRoundStyle RoundStyle = FloatRoundStyle::round_to_nearest
 >
 using Sm90LinCombPerRowReduce =
-  Sm90EVT<Sm90ColReduction<RegReduceFn, GmemReduceFn, 0, CtaTileShapeMNK, ElementReduce, ElementCompute, RoundStyle>, // per column reduce
+  Sm90EVT<Sm90ColReduction<RegReduceFn, RegReduceFn, GmemReduceFn, 0, CtaTileShapeMNK, ElementReduce, ElementCompute, RoundStyle>, // per column reduce
     Sm90EVT<Sm90Compute<homogeneous_multiply_add, ElementOutput, ElementCompute, RoundStyle>, // beta * C + alpha * acc
       Sm90ScalarBroadcast<ElementScalar>, // beta
       Sm90SrcFetch<ElementOutput>, // C
       Sm90EVT<Sm90Compute<multiplies, ElementCompute, ElementCompute, RoundStyle>, // alpha * acc
         Sm90ScalarBroadcast<ElementScalar>, // alpha
         Sm90AccFetch // acc
       >
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_pingpong.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32_warpspecialized_pingpong.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_pingpong.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op_f32_warpspecialized_pingpong.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative.cu`

 * *Files 0% similar despite different names*

```diff
@@ -792,15 +792,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -829,15 +829,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -866,15 +866,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -903,15 +903,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_load.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_load.cu`

 * *Files 1% similar despite different names*

```diff
@@ -94,15 +94,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -151,15 +151,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -208,15 +208,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_store.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_aux_store.cu`

 * *Files 2% similar despite different names*

```diff
@@ -26,15 +26,15 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for Sm90 f16_f16_f16 with cooperative EVT epilogue
-    D = alpha * acc + beta * c + aux_load 
+    D = alpha * acc + beta * c + aux_load
 */
 
 #include <iostream>
 
 #include "cutlass/cutlass.h"
 #include "cute/tensor.hpp"
 #include "cute/atom/mma_atom.hpp"
@@ -68,23 +68,23 @@
   using BinaryCompute0 = Sm90EVT<Sm90Compute<
                                    cutlass::multiplies,
                                    ElementCompute,
                                    ElementCompute,
                                    RoundStyle>,                          // alpha * acc
                             Sm90ScalarBroadcast<ElementAccumulator>,  // alpha
                             Sm90AccFetch                              // acc
-                         >;       
+                         >;
   if constexpr (IsCNeed) {
     using EVT_D = Sm90EVT<Sm90Compute<cutlass::homogeneous_multiply_add, ElementCompute, ElementCompute, RoundStyle>,
                     Sm90ScalarBroadcast<ElementAccumulator>,  // beta
                     Sm90SrcFetch<ElementCompute>,                             // C
                     BinaryCompute0>;
-    return *(EVT_D *)(nullptr);
+    return EVT_D{};
   } else {
-    return *(BinaryCompute0 *)(nullptr);
+    return BinaryCompute0{};
   }
 }
 
 template <class Gemm, class GemmWithoutD>
 bool testEVTAuxStoreWithoutD() {
   using ProblemShapeType = typename Gemm::GemmKernel::ProblemShape;
 
@@ -148,15 +148,15 @@
       },
       {   // Epilogue arguments
         {}, // thread
         has_c ? C_block.get() : nullptr, stride_C,
         D_block.get(), stride_D,
       },  // Epilogue arguments end
       /*hw_info=*/{},
-      /*scheduler_args=*/{} 
+      /*scheduler_args=*/{}
     };
 
     // check without D aux store
     // set D to be void and use Sm90AuxStore to write to D
     // and then the D is the same
     GemmWithoutD gemm_op;
 
@@ -271,15 +271,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::RowMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -288,15 +288,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -306,24 +306,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
@@ -341,15 +341,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::ColumnMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -358,15 +358,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -376,24 +376,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
@@ -411,15 +411,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::RowMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -428,15 +428,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -446,24 +446,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
@@ -481,15 +481,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::RowMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -498,15 +498,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -516,24 +516,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
@@ -551,15 +551,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::ColumnMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -568,15 +568,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -586,24 +586,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
@@ -621,15 +621,15 @@
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using EpilogueTileType = cutlass::epilogue::collective::EpilogueTileAuto;
 
   using EpilogueDescriptor = cutlass::epilogue::collective::detail::EpilogueDescriptor<
     TileShape_MNK, EpilogueTileType, cutlass::half_t, cutlass::half_t, EpilogueSchedule
-  >; 
+  >;
   using AuxStoreDescriptor = cutlass::epilogue::collective::detail::AuxStoreDescriptor<
     EpilogueDescriptor, cutlass::layout::RowMajor, cutlass::half_t
   >;
 
   using namespace cutlass::epilogue::fusion;
 
   constexpr auto RoundStyle = cutlass::FloatRoundStyle::round_to_nearest;
@@ -638,15 +638,15 @@
   using EVT_D = decltype(test::gemm::device::select_evt_d<cutlass::half_t, float, has_c>());
   using AuxStore = Sm90AuxStore<AuxStoreDescriptor::Stages, typename EpilogueDescriptor::EpilogueTile,
                      typename AuxStoreDescriptor::Element, RoundStyle,
                      typename AuxStoreDescriptor::Stride, typename AuxStoreDescriptor::SmemLayoutAtom,
                      typename AuxStoreDescriptor::CopyOpR2S>;
 
   constexpr auto select_kernel = [](auto has_c, auto has_d) {
-    using FusionCallbacks = 
+    using FusionCallbacks =
         cute::conditional_t<decltype(has_d){}, EVT_D, Sm90EVT<AuxStore, EVT_D>>;
     using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         TileShape_MNK, ClusterShape_MNK,
         EpilogueTileType,
         float, float,
         cute::conditional_t<decltype(has_c){}, cutlass::half_t, void>, LayoutC, 8,
@@ -656,24 +656,24 @@
       >::CollectiveOp;
     using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
         cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
         cutlass::half_t, LayoutA, 8,
         cutlass::half_t, LayoutB, 8,
         float,
         TileShape_MNK, ClusterShape_MNK,
-        cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+        cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
         cutlass::gemm::KernelTmaWarpSpecializedCooperative
       >::CollectiveOp;
 
     using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
         Shape<int,int,int,int>,
         CollectiveMainloop,
         CollectiveEpilogue>;
 
-    return *(GemmKernel *)(nullptr);
+    return GemmKernel{};
   };
 
   using GemmKernel = decltype(select_kernel(cute::C<has_c>{}, cute::C<true>{}));
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
 
   using GemmKernelWithoutD = decltype(select_kernel(cute::C<has_c>{}, cute::C<false>{}));
   using GemmWithoutD = cutlass::gemm::device::GemmUniversalAdapter<GemmKernelWithoutD>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_bias_elementwise.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_bias_elementwise.cu`

 * *Files 2% similar despite different names*

```diff
@@ -82,15 +82,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -130,15 +130,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -179,15 +179,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -223,15 +223,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -267,15 +267,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -312,15 +312,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -357,15 +357,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -402,15 +402,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -447,15 +447,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -493,15 +493,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -538,15 +538,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -583,15 +583,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_dag.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_dag.cu`

 * *Files 1% similar despite different names*

```diff
@@ -94,15 +94,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -147,15 +147,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_reduce.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_reduce.cu`

 * *Files 2% similar despite different names*

```diff
@@ -66,15 +66,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_256,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombPerColumnReduce<
-    cutlass::plus, cutlass::red, float, TileShape_MNK, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, TileShape_MNK, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -85,15 +85,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -112,15 +112,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_256,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombPerRowReduce<
-    cutlass::plus, cutlass::red, float, TileShape_MNK, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, TileShape_MNK, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -131,15 +131,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -158,15 +158,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_256,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecializedCooperative;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombScalarReduce<
-    cutlass::plus, cutlass::red, float, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -177,15 +177,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_row_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_cooperative_row_broadcast.cu`

 * *Files 2% similar despite different names*

```diff
@@ -90,15 +90,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -140,15 +140,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong.cu`

 * *Files 1% similar despite different names*

```diff
@@ -758,15 +758,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -804,15 +804,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -852,15 +852,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -898,15 +898,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -946,15 +946,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -992,15 +992,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1040,15 +1040,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1086,15 +1086,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 8,
       ElementB, LayoutB, 8,
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1129,15 +1129,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 16 / sizeof(ElementA),
       ElementB, LayoutB, 16 / sizeof(ElementB),
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       KernelSchedule
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1172,15 +1172,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 16 / sizeof(ElementA),
       ElementB, LayoutB, 16 / sizeof(ElementB),
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       KernelSchedule
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1215,15 +1215,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 16 / sizeof(ElementA),
       ElementB, LayoutB, 16 / sizeof(ElementB),
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       KernelSchedule
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -1258,15 +1258,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       ElementA, LayoutA, 16 / sizeof(ElementA),
       ElementB, LayoutB, 16 / sizeof(ElementB),
       ElementAccumulator,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       KernelSchedule
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_aux_load.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_aux_load.cu`

 * *Files 1% similar despite different names*

```diff
@@ -95,15 +95,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -150,15 +150,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -205,15 +205,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_bias_elementwise.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_bias_elementwise.cu`

 * *Files 4% similar despite different names*

```diff
@@ -82,15 +82,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -125,15 +125,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -169,15 +169,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -214,15 +214,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -259,15 +259,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -304,15 +304,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -349,15 +349,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -394,15 +394,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -439,15 +439,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -484,15 +484,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_dag.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_dag.cu`

 * *Files 1% similar despite different names*

```diff
@@ -94,15 +94,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -147,15 +147,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_reduce.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_reduce.cu`

 * *Files 2% similar despite different names*

```diff
@@ -66,15 +66,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_128,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecialized;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombPerColumnReduce<
-    cutlass::plus, cutlass::red, float, TileShape_MNK, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, TileShape_MNK, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -85,15 +85,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -112,15 +112,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_128,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecialized;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombPerRowReduce<
-    cutlass::plus, cutlass::red, float, TileShape_MNK, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, TileShape_MNK, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -131,15 +131,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -158,15 +158,15 @@
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
   using TileShape_MNK = Shape<_128,_128,_64>;
   using ClusterShape_MNK = Shape<_2,_2,_1>;
 
   using EpilogueSchedule = cutlass::epilogue::TmaWarpSpecialized;
   using FusionCallbacks = cutlass::epilogue::fusion::Sm90LinCombScalarReduce<
-    cutlass::plus, cutlass::red, float, cutlass::half_t, float, float>;
+    cutlass::plus, cutlass::atomic_add, float, cutlass::half_t, float, float>;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       TileShape_MNK, ClusterShape_MNK,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       cutlass::half_t, LayoutC, 8,
@@ -177,15 +177,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_row_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_pingpong_row_broadcast.cu`

 * *Files 3% similar despite different names*

```diff
@@ -90,15 +90,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -140,15 +140,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cooperative_stream_k.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cooperative_stream_k.cu`

 * *Files 1% similar despite different names*

```diff
@@ -829,15 +829,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue,
@@ -868,15 +868,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue,
@@ -907,15 +907,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue,
@@ -946,15 +946,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue,
@@ -990,15 +990,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::half_t, LayoutA, 8,
       cutlass::half_t, LayoutB, 8,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_tensor_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_tensor_broadcast.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_cooperative.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,128 +38,127 @@
 #include "cute/tensor.hpp"
 #include "cute/atom/mma_atom.hpp"
 
 #include "cutlass/numeric_types.h"
 
 #include "cutlass/gemm/device/gemm_universal_adapter.h"
 #include "cutlass/gemm/kernel/gemm_universal.hpp"
-#include "cutlass/epilogue/collective/collective_builder.hpp"
 #include "cutlass/gemm/collective/collective_builder.hpp"
+#include "cutlass/epilogue/collective/collective_builder.hpp"
 #include "cutlass/epilogue/collective/default_epilogue.hpp"
 #include "cutlass/epilogue/thread/linear_combination.h"
-#include "cutlass/gemm/dispatch_policy.hpp"
 
 #include "../../common/cutlass_unit_test.h"
 
 #include "gemm_testbed_3x.hpp"
 
 #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
 
 using namespace cute;
 
 ///////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Gemm_f32t_f32n_f32n_tensor_op_gmma_f32, 64x128x32_1x2x1) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align4_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
+  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      float, LayoutA, 4,
-      float, LayoutB, 4,
+      tfloat32_t, LayoutA, 4,
+      tfloat32_t, LayoutB, 4,
       float,
-      Shape<_64,_128,_128>, Shape<_1,_2,_1>,
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::collective::KernelScheduleAuto
+      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_64,_128,_128>, Shape<_1,_1,_1>,
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
-      cutlass::epilogue::collective::EpilogueScheduleAuto
+      cutlass::epilogue::NoSmemWarpSpecialized
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveMainloop,
+      CollectiveOp,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_f32t_f32t_f32n_tensor_op_gmma_f32, 64x128x32_1x1x1_pingpong) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align2_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
+  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::epilogue::collective::EpilogueTileAuto,
-      float, float,
-      float, LayoutC, 4,
-      float, LayoutC, 4,
-      cutlass::gemm::EpilogueTransposed
+      cutlass::tfloat32_t, LayoutA, 2,
+      cutlass::tfloat32_t, LayoutB, 2,
+      float,
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      cutlass::gemm::collective::StageCountAuto,
+      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
     >::CollectiveOp;
 
-  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
+  using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      float, LayoutA, 4,
-      float, LayoutB, 4,
-      float,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
-      cutlass::gemm::KernelTmaWarpSpecializedPingpong
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      cutlass::epilogue::collective::EpilogueTileAuto,
+      float, float,
+      float, LayoutC, 2,
+      float, LayoutC, 2,
+      cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveMainloop,
+      CollectiveOp,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_f32t_f32t_f32n_tensor_op_gmma_f32, 128x128x32_1x1x1_cooperative) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align1_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
+  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_128,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::epilogue::collective::EpilogueTileAuto,
-      float, float,
-      float, LayoutC, 4,
-      float, LayoutC, 4,
-      cutlass::gemm::EpilogueTransposed
+      cutlass::tfloat32_t, LayoutA, 1,
+      cutlass::tfloat32_t, LayoutB, 1,
+      float,
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      cutlass::gemm::collective::StageCountAuto,
+      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
     >::CollectiveOp;
 
-  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
+  using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      float, LayoutA, 4,
-      float, LayoutB, 4,
-      float,
-      Shape<_128,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
-      cutlass::gemm::KernelTmaWarpSpecializedCooperative
+      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      cutlass::epilogue::collective::EpilogueTileAuto,
+      float, float,
+      float, LayoutC, 1,
+      float, LayoutC, 1,
+      cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveMainloop,
+      CollectiveOp,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32_tensor_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32_tensor_broadcast.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32_evt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_bf16_tensor_op_fp32_evt.cu`

 * *Files 2% similar despite different names*

```diff
@@ -95,15 +95,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecialized
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -171,15 +171,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecialized
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative_evt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cluster_warpspecialized_cooperative_evt.cu`

 * *Files 1% similar despite different names*

```diff
@@ -95,15 +95,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -171,15 +171,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cooperative_stream_k.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_cooperative_stream_k.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_f32_rs_cluster_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_fp32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f32_tensor_op_fp32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32.cu`

 * *Files 1% similar despite different names*

```diff
@@ -50,14 +50,15 @@
 #include "../../common/cutlass_unit_test.h"
 
 #include "gemm_testbed_3x.hpp"
 
 #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
 
 using namespace cute;
+
 ///////////////////////////////////////////////////////////////////////////////
 //////////////////////////////// output: E4M3 /////////////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 ///////////////////////////////////////////////////////////////////////////////
 ///////////////////////////// e4m3 = e4m3 * e4m3 (TN) /////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
@@ -756,15 +757,16 @@
       EpilogueOp
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAllBiasElementwise<Gemm>());
 }
 
-
+// Use Hopper FP8+AUX from 12.1
+#if (!((__CUDACC_VER_MAJOR__ == 12) && (__CUDACC_VER_MINOR__ == 0)))
 
 ///////////////////////////////////////////////////////////////////////////////
 ///////////////////////// output: E4M3 + Aux Tensor ///////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 ///////////////////////////////////////////////////////////////////////////////
 ///////////////////////////// e4m3 = e4m3 * e4m3 (TN) /////////////////////////
@@ -804,14 +806,15 @@
       CollectiveOp,
       EpilogueOp
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAllBiasElementwise<Gemm>());
 }
+#endif
 
 ///////////////////////////////////////////////////////////////////////////////
 ////////////////////////////////// FP8 Accum  /////////////////////////////////
 ///////////////////////////// e5m2 = e4m3 * e4m3 (TN) /////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_e4m3t_e4m3n_e5m2n_tensor_op_gmma_f32, 64x128x128_2x4x1_persistent_fp8_fast_accum) {
@@ -986,14 +989,18 @@
       EpilogueOp
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAllBiasElementwise<Gemm>());
 }
 
+
+// Use Hopper FP8+AUX from 12.1
+#if (!((__CUDACC_VER_MAJOR__ == 12) && (__CUDACC_VER_MINOR__ == 0)))
+
 ///////////////////////////////////////////////////////////////////////////////
 ///////////////////// output: E4M3 + Aux Tensor + Bias/////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 ///////////////////////////////////////////////////////////////////////////////
 ///////////////////////////// e4m3 = e4m3 * e5m2 (TN) /////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
@@ -1138,14 +1145,16 @@
       EpilogueOp
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAllBiasElementwise<Gemm>());
 }
 
+#endif
+
 ///////////////////////////////////////////////////////////////////////////////
 //////////////////////////////// TMA epilogue /////////////////////////////////
 ///////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_e4m3t_e4m3n_e4m3n_tensor_op_gmma_f32, 64x128x128_tma_epilogue) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32_evt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f8_f8_f8_tensor_op_fp32_evt.cu`

 * *Files 1% similar despite different names*

```diff
@@ -95,15 +95,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecialized
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
@@ -171,15 +171,15 @@
 
   using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::float_e4m3_t, LayoutA, 16,
       cutlass::float_e4m3_t, LayoutB, 16,
       float,
       TileShape_MNK, ClusterShape_MNK,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecialized
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveMainloop,
       CollectiveEpilogue
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_cooperative.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_pingpong.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32_warpspecialized_pingpong.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu`

 * *Files 2% similar despite different names*

```diff
@@ -286,15 +286,15 @@
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       int8_t, LayoutA, 16,
       int8_t, LayoutB, 16,
       int32_t,
       Shape<_64,_128,_128>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
@@ -322,15 +322,15 @@
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       int8_t, LayoutA, 16,
       int8_t, LayoutB, 16,
       int32_t,
       Shape<_64,_128,_128>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
@@ -358,15 +358,15 @@
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       int8_t, LayoutA, 16,
       int8_t, LayoutB, 16,
       int32_t,
       Shape<_128,_128,_128>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
@@ -394,15 +394,15 @@
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       int8_t, LayoutA, 16,
       int8_t, LayoutB, 16,
       int32_t,
       Shape<_128,_128,_128>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAutoCarveout<sizeof(typename CollectiveEpilogue::SharedStorage)>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
       cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32_tensor_broadcast.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32_tensor_broadcast.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_stream_k_scheduler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_stream_k_scheduler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_cooperative.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_pingpong.cu`

 * *Files 8% similar despite different names*

```diff
@@ -53,27 +53,27 @@
 
 #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
 
 using namespace cute;
 
 ///////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align4_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align4_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       tfloat32_t, LayoutA, 4,
       tfloat32_t, LayoutB, 4,
       float,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
+      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
@@ -88,27 +88,27 @@
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align2_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align2_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::tfloat32_t, LayoutA, 2,
       cutlass::tfloat32_t, LayoutB, 2,
       float,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
+      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
@@ -123,27 +123,27 @@
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align1_tensor_op_gmma_f32_warpspecialized_cooperative, 128x64x32) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align1_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       cutlass::tfloat32_t, LayoutA, 1,
       cutlass::tfloat32_t, LayoutB, 1,
       float,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedCooperative
+      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       Shape<_128,_64,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32_warpspecialized_pingpong.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu`

 * *Files 19% similar despite different names*

```diff
@@ -51,116 +51,155 @@
 
 #include "gemm_testbed_3x.hpp"
 
 #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
 
 using namespace cute;
 
-///////////////////////////////////////////////////////////////////////////////
-
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align4_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
+TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_tensor_op_gmma_f32, 64x128x32) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      tfloat32_t, LayoutA, 4,
-      tfloat32_t, LayoutB, 4,
+      cutlass::tfloat32_t, LayoutA, 4,
+      cutlass::tfloat32_t, LayoutB, 4,
       float,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
+      cutlass::gemm::collective::KernelScheduleAuto
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
-      cutlass::epilogue::NoSmemWarpSpecialized
+      cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align2_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
-  using LayoutA = cutlass::layout::RowMajor;
+///////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_Device_Gemm_tf32n_tf32n_f32n_tensor_op_gmma_f32, 64x128x32) {
+  using LayoutA = cutlass::layout::ColumnMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 2,
-      cutlass::tfloat32_t, LayoutB, 2,
+      cutlass::tfloat32_t, LayoutA, 4,
+      cutlass::tfloat32_t, LayoutB, 4,
       float,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
+      cutlass::gemm::collective::KernelScheduleAuto
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
-      float, LayoutC, 2,
-      float, LayoutC, 2,
+      float, LayoutC, 4,
+      float, LayoutC, 4,
       cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_align1_tensor_op_gmma_f32_warpspecialized_pingpong, 128x64x32) {
-  using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::ColumnMajor;
+///////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_Device_Gemm_tf32n_tf32t_f32n_tensor_op_gmma_f32, 64x128x32) {
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 1,
-      cutlass::tfloat32_t, LayoutB, 1,
+      cutlass::tfloat32_t, LayoutA, 4,
+      cutlass::tfloat32_t, LayoutB, 4,
       float,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::KernelCpAsyncWarpSpecializedPingpong
+      cutlass::gemm::collective::KernelScheduleAuto
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_128,_64,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
-      float, LayoutC, 1,
-      float, LayoutC, 1,
+      float, LayoutC, 4,
+      float, LayoutC, 4,
       cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
       CollectiveOp,
       CollectiveEpilogue
   >;
+
+  using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
+  EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
+}
+
+///////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_Device_Gemm_tf32t_tf32t_f32n_tensor_op_gmma_f32, 64x128x32) {
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
+
+  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
+      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
+      cutlass::tfloat32_t, LayoutA, 4,
+      cutlass::tfloat32_t, LayoutB, 4,
+      float,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      cutlass::gemm::collective::StageCountAuto,
+      cutlass::gemm::collective::KernelScheduleAuto
+    >::CollectiveOp;
+
+  using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
+      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      cutlass::epilogue::collective::EpilogueTileAuto,
+      float, float,
+      float, LayoutC, 4,
+      float, LayoutC, 4,
+      cutlass::gemm::EpilogueTransposed
+    >::CollectiveOp;
+
+  using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
+      Shape<int,int,int,int>,
+      CollectiveOp,
+      CollectiveEpilogue
+  >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
 ///////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,166 +38,172 @@
 #include "cute/tensor.hpp"
 #include "cute/atom/mma_atom.hpp"
 
 #include "cutlass/numeric_types.h"
 
 #include "cutlass/gemm/device/gemm_universal_adapter.h"
 #include "cutlass/gemm/kernel/gemm_universal.hpp"
-#include "cutlass/gemm/collective/collective_builder.hpp"
 #include "cutlass/epilogue/collective/collective_builder.hpp"
+#include "cutlass/gemm/collective/collective_builder.hpp"
 #include "cutlass/epilogue/collective/default_epilogue.hpp"
 #include "cutlass/epilogue/thread/linear_combination.h"
+#include "cutlass/gemm/dispatch_policy.hpp"
 
 #include "../../common/cutlass_unit_test.h"
 
 #include "gemm_testbed_3x.hpp"
 
 #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
 
 using namespace cute;
 
-TEST(SM90_Device_Gemm_tf32t_tf32n_f32n_tensor_op_gmma_f32, 64x128x32) {
+///////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_Device_Gemm_f32t_f32n_f32n_tensor_op_gmma_f32, 64x128x32_1x2x1) {
   using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
+  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 4,
-      cutlass::tfloat32_t, LayoutB, 4,
+      float, LayoutA, 4,
+      float, LayoutB, 4,
       float,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_128>, Shape<_1,_2,_1>,
       cutlass::gemm::collective::StageCountAuto,
       cutlass::gemm::collective::KernelScheduleAuto
     >::CollectiveOp;
 
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      Shape<_64,_128,_128>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
       cutlass::epilogue::collective::EpilogueScheduleAuto
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveOp,
+      CollectiveMainloop,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-///////////////////////////////////////////////////////////////////////////////
-
-TEST(SM90_Device_Gemm_tf32n_tf32n_f32n_tensor_op_gmma_f32, 64x128x32) {
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using LayoutB = cutlass::layout::ColumnMajor;
+TEST(SM90_Device_Gemm_f32t_f32t_f32n_tensor_op_gmma_f32, 64x128x32_1x1x1_pingpong) {
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
-      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 4,
-      cutlass::tfloat32_t, LayoutB, 4,
-      float,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::collective::KernelScheduleAuto
-    >::CollectiveOp;
-
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
       Shape<_64,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
-      cutlass::epilogue::collective::EpilogueScheduleAuto
+      cutlass::gemm::EpilogueTransposed
+    >::CollectiveOp;
+
+  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
+      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
+      float, LayoutA, 4,
+      float, LayoutB, 4,
+      float,
+      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
+      cutlass::gemm::KernelTmaWarpSpecializedPingpong
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveOp,
+      CollectiveMainloop,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-///////////////////////////////////////////////////////////////////////////////
-
-TEST(SM90_Device_Gemm_tf32n_tf32t_f32n_tensor_op_gmma_f32, 64x128x32) {
-  using LayoutA = cutlass::layout::ColumnMajor;
+TEST(SM90_Device_Gemm_f32t_f32t_f32n_tensor_op_gmma_f32, 128x128x32_1x1x1_cooperative) {
+  using LayoutA = cutlass::layout::RowMajor;
   using LayoutB = cutlass::layout::RowMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
-      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 4,
-      cutlass::tfloat32_t, LayoutB, 4,
-      float,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::collective::KernelScheduleAuto
-    >::CollectiveOp;
-
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      Shape<_128,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
-      cutlass::epilogue::collective::EpilogueScheduleAuto
+      cutlass::gemm::EpilogueTransposed
+    >::CollectiveOp;
+
+  using CollectiveMainloop = typename cutlass::gemm::collective::CollectiveBuilder<
+      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
+      float, LayoutA, 4,
+      float, LayoutB, 4,
+      float,
+      Shape<_128,_128,_32>, Shape<_1,_1,_1>,
+      cutlass::gemm::collective::StageCountAutoCarveout<static_cast<int>(sizeof(typename CollectiveEpilogue::SharedStorage))>,
+      cutlass::gemm::KernelTmaWarpSpecializedCooperative
     >::CollectiveOp;
 
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveOp,
+      CollectiveMainloop,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
 
-///////////////////////////////////////////////////////////////////////////////
-
-TEST(SM90_Device_Gemm_tf32t_tf32t_f32n_tensor_op_gmma_f32, 64x128x32) {
+TEST(SM90_Device_Gemm_f32t_f32t_f32n_tensor_op_gmma_f32, 128x128x32_1x1x1_cooperative_narrow_wgmma) {
   using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
-  using CollectiveOp = typename cutlass::gemm::collective::CollectiveBuilder<
-      cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      cutlass::tfloat32_t, LayoutA, 4,
-      cutlass::tfloat32_t, LayoutB, 4,
-      float,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
-      cutlass::gemm::collective::StageCountAuto,
-      cutlass::gemm::collective::KernelScheduleAuto
-    >::CollectiveOp;
-
   using CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder<
       cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp,
-      Shape<_64,_128,_32>, Shape<_1,_1,_1>,
+      Shape<_128,_128,_32>, Shape<_1,_1,_1>,
       cutlass::epilogue::collective::EpilogueTileAuto,
       float, float,
       float, LayoutC, 4,
       float, LayoutC, 4,
-      cutlass::gemm::EpilogueTransposed
+      cutlass::epilogue::TmaWarpSpecializedCooperative
     >::CollectiveOp;
 
+  // Manually configure a half-tile wide MMA instruction
+  using CollectiveMainloop = cutlass::gemm::collective::CollectiveMma<
+      cutlass::gemm::MainloopSm90TmaGmmaWarpSpecialized<5, Shape<_1,_1,_1>, cutlass::gemm::KernelTmaWarpSpecializedCooperative>,
+      Shape<_128,_128,_32>,
+      float,
+      cutlass::detail::TagToStrideA_t<LayoutA>,
+      float,
+      cutlass::detail::TagToStrideB_t<LayoutB>,
+      decltype(cute::make_tiled_mma(cute::SM90_64x64x8_F32TF32TF32_SS_TN{}, Layout<Shape<_2,_1,_1>>{})),
+      cute::SM90_TMA_LOAD,
+      cute::GMMA::Layout_K_SW128_Atom<tfloat32_t>,
+      void,
+      cute::identity,
+      cute::SM90_TMA_LOAD,
+      cute::GMMA::Layout_K_SW128_Atom<tfloat32_t>,
+      void,
+      cute::identity
+    >;
+
   using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
       Shape<int,int,int,int>,
-      CollectiveOp,
+      CollectiveMainloop,
       CollectiveEpilogue
   >;
 
   using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
   EXPECT_TRUE(test::gemm::device::TestAll<Gemm>());
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32_gmma_rs_cluster_warpspecialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32_gmma_rs_cluster_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files 17% similar despite different names*

```diff
@@ -54,22 +54,22 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kLower,
     ElementAccumulator,
@@ -89,22 +89,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kLower,
     ElementAccumulator,
@@ -124,57 +124,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 64x32x16_32x32x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 32x64x16_32x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
-
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
-
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
-  EXPECT_TRUE(passed);
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 32x64x16_32x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kLower,
     ElementAccumulator,
@@ -194,22 +159,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kLower,
     ElementAccumulator,
@@ -229,22 +194,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kLower,
     ElementAccumulator,
@@ -264,22 +229,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kUpper,
     ElementAccumulator,
@@ -299,92 +264,22 @@
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 64x64x16_32x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
-
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
-
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
-  EXPECT_TRUE(passed);
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 64x32x16_32x32x16) {
+TEST(SM80_Device_Syr2kGrouped_f64t_f64t_u_tensor_op_f64, 32x64x16_32x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
-
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
-
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
-  EXPECT_TRUE(passed);
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 32x64x16_32x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
     ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
     ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
     ElementC, LayoutC, cutlass::FillMode::kUpper,
     ElementAccumulator,
@@ -395,84 +290,14 @@
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     3, // kStages
     cutlass::arch::OpMultiplyAdd,
     cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
-
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
-  EXPECT_TRUE(passed);
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 128x64x16_64x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
-
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
-
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
-  EXPECT_TRUE(passed);
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syr2kGrouped_f64n_f64n_u_tensor_op_f64, 128x128x16_32x64x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 16>,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
-
   using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
 
   test::gemm::device::TestbedGrouped<Rank2K> testbed;
   bool passed = testbed.run(24);
   EXPECT_TRUE(passed);
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f8nhwc_f8nhwc_f8nhwc_tensor_op_f32_sm89.cu`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,285 +24,345 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Tests for grouped Rank2K interface
+    \brief Tests for device-wide Conv2d fprop interface with:
+        A: NHWC, of type FE4M4 or FE5M2
+        B: NHWC, of type FE4M3 or FE5M2
+        C: NHWC, of FE4M3 or FE5M2
+        Accum: F32
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/cutlass.h"
-
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/kernel/rank_2k_grouped.h"
-#include "cutlass/gemm/kernel/default_rank_2k_grouped.h"
-#include "cutlass/gemm/device/rank_2k_grouped.h"
-
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/gemm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/epilogue/thread/activation.h"
+#include "cutlass/epilogue/thread/linear_combination_generic_with_scaling.h"
+#include "cutlass/conv/kernel/default_conv2d_fprop_with_absmax.h"
+#include "cutlass/conv/device/implicit_gemm_convolution.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_grouped_rank_2k.h"
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#include "conv2d_with_absmax_testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM89_SUPPORTED)
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM89_Device_Conv2d_Fprop_Analytic_ImplicitGemm_fe4m3nhwc_fe4mnhwc_fe4mnhwc_tensor_op_f32,
+  identity_128x256x64_64x3_64x64x64) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kAnalytic
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM89_Device_Conv2d_Fprop_Analytic_ImplicitGemm_fe5m2nhwc_fe4m3nhwc_fe4m3nhwc_tensor_op_f32,
+  identity_128x256x64_64x3_64x64x64) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
+  using ElementA = cutlass::float_e5m2_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
+
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kAnalytic
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM89_Device_Conv2d_Fprop_Analytic_ImplicitGemm_fe5m2nhwc_fe4m3nhwc_fe5m2nhwc_tensor_op_f32,
+  identity_128x256x64_64x3_64x64x64) {
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 32x64x16_32x32x16) {
+  using ElementA = cutlass::float_e5m2_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e5m2_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kAnalytic
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM89_Device_Conv2d_Fprop_Optimized_ImplicitGemm_fe4m3nhwc_fe4mnhwc_fe4mnhwc_tensor_op_f32,
+  identity_128x256x64_64x3_64x64x64) {
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kOptimized
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM89_Device_Conv2d_Fprop_Optimized_ImplicitGemm_fe4m3nhwc_fe4mnhwc_fe4mnhwc_tensor_op_f32,
+  relu_128x256x64_64x3_64x64x64) {
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::ReLu,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kLower,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 16>,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kOptimized
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::ReLu>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM89_Device_Conv2d_Fprop_Optimized_ImplicitGemm_fe4m3nhwc_fe4mnhwc_fe4mnhwc_tensor_op_f32,
+  identity_fastacc_128x256x64_64x3_64x64x64) {
+
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
-    cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    kStages,
+    cutlass::arch::OpMultiplyAddFastAccum,
+    cutlass::conv::IteratorAlgorithm::kOptimized
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>();
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM89_Device_Conv2d_Fprop_Optimized_ImplicitGemm_fe4m3nhwc_fe4mnhwc_fe4mnhwc_tensor_op_f32,
+  identity_noScale_128x256x64_64x3_64x64x64) {
 
-TEST(SM80_Device_Syr2kGrouped_f64t_f64t_u_tensor_op_f64, 32x64x16_32x32x16) {
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = cutlass::float_e4m3_t;
+  using ElementAuxOutput = ElementOutput;
+  using ElementAccumulator = float;;
+  static int const kStages = 3;
+
+  using EpilogueOutputOp = cutlass::epilogue::thread::LinearCombinationGenericWithScalingAndAbsMax<
+    cutlass::epilogue::thread::Identity,
+    ElementOutput,
+    ElementAuxOutput,
+    128 / cutlass::sizeof_bits<ElementOutput>::value,
+    ElementAccumulator,
+    ElementAccumulator
+  >;
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using Rank2Kkernel = typename cutlass::gemm::kernel::DefaultRank2KGrouped<
-    ElementA, LayoutA, cutlass::ComplexTransform::kNone, 1,
-    ElementB, LayoutB, cutlass::ComplexTransform::kNone, 1,
-    ElementC, LayoutC, cutlass::FillMode::kUpper,
+  using Conv2dFpropKernel = typename cutlass::conv::kernel::DefaultConv2dFpropWithAbsMax<
+    ElementA, cutlass::layout::TensorNHWC,
+    ElementB, cutlass::layout::TensorNHWC,
+    ElementOutput, cutlass::layout::TensorNHWC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<ElementC, 1, ElementAccumulator, ElementAccumulator>,
+    cutlass::arch::Sm89,
+    cutlass::gemm::GemmShape<128, 256, 64>,
+    cutlass::gemm::GemmShape<64, 64, 64>,
+    cutlass::gemm::GemmShape<16, 8, 32>,
+    EpilogueOutputOp,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3, // kStages
+    kStages,
     cutlass::arch::OpMultiplyAdd,
-    cutlass::BlasMode::kSymmetric>::Rank2Kkernel;
+    cutlass::conv::IteratorAlgorithm::kOptimized
+  >::Kernel;
 
-  using Rank2K = cutlass::gemm::device::Rank2KGrouped<Rank2Kkernel>;
+  using Conv2dFprop = cutlass::conv::device::ImplicitGemmConvolution<Conv2dFpropKernel>;
 
-  test::gemm::device::TestbedGrouped<Rank2K> testbed;
-  bool passed = testbed.run(24);
+  bool passed = test::conv::device::TestAllConv2dWithAbsmax<Conv2dFprop, cutlass::epilogue::thread::Identity>(
+    /* scaleA = */false,
+    /* scaleB = */false,
+    /* scaleC = */false
+  );
   EXPECT_TRUE(passed);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+////////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#endif  // CUTLASS_ARCH_MMA_SM89_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 22% similar despite different names*

```diff
@@ -43,53 +43,83 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank_k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
-
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_cf64n_cf64t_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
+TEST(SM90_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
 
-  using ElementA = cutlass::complex<double>;
+  using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
 
-  using ElementC = cutlass::complex<double>;
+  using ElementC = double;
   using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = cutlass::complex<double>;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm90,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_Device_Syrk_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::RowMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
+    cutlass::arch::Sm90,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4,     // kStages 
-    1,     // AlignmentA
-    false, // SplitKSerial
-    cutlass::arch::OpMultiplyAddGaussianComplex,
-    cutlass::ComplexTransform::kNone,
-    cutlass::BlasMode::kSymmetric
+    4
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 17% similar despite different names*

```diff
@@ -25,101 +25,102 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide SYRK interface
+    \brief Tests for device-wide TRMM interface
+
   
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/blas3.h"
-#include "cutlass/gemm/device/rank_k.h"
+#include "cutlass/gemm/device/trmm.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/rank_k_complex.h"
+#include "cutlass/util/reference/host/trmm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_rank_k_universal.h"
+#include "testbed_trmm_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+TEST(SM90_Device_Trmm_f64n_f64n_f64t_rs_l_nu_tensor_op_f64, 32x32x16_16x16x16) {
 
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using ElementOutput = double;
   using ElementAccumulator = double;
 
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
+  using Trmm = cutlass::gemm::device::Trmm<
+    double,
+    cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight,
     cutlass::FillMode::kLower,
+    cutlass::DiagType::kNonUnit,
+    double,
+    cutlass::layout::ColumnMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm90,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
     cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      ElementOutput,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
-
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Syrk_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM90_Device_Trmm_f64t_f64t_f64n_rs_l_nu_tensor_op_f64, 64x64x16_32x32x16) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementOutput = double;
   using ElementAccumulator = double;
 
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
+  using Trmm = cutlass::gemm::device::Trmm<
+    double,
+    cutlass::layout::RowMajor,
+    cutlass::SideMode::kRight,
     cutlass::FillMode::kLower,
+    cutlass::DiagType::kNonUnit,
+    double,
+    cutlass::layout::RowMajor,
+    ElementOutput,
+    cutlass::layout::ColumnMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm90,
+    cutlass::gemm::GemmShape<64, 64, 16>,
     cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
     cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      ElementOutput,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f32t_tensor_op_f32_sparse_sm89.cu`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,214 +24,131 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Tests for device-wide SYRK interface
-  
+    \brief Tests for device-wide sparse GEMM interface with:
+        A: row major, of type FE4M4 or FE5M2
+        B: column major, of type FE4M3 or FE5M2
+        C: row major, of type F32
+        Accum: F32
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/device/rank_k.h"
+#include "cutlass/cutlass.h"
+#include "cutlass/gemm/device/gemm_sparse.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/rank_k_complex.h"
+#include "cutlass/util/reference/host/gemm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_rank_k_universal.h"
-
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "testbed_sparse.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#if defined(CUTLASS_ARCH_MMA_SM89_SUPPORTED)
 
-TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using ElementC = double;
+TEST(SM89_Device_Sparse_Gemm_fe4m3t_fe4m3n_f32t_tensor_op_f32, 128x128x128_64x64x128) {
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+  static int const kStages = 3;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  using Gemm = cutlass::gemm::device::SparseGemm<
+      ElementA, LayoutA, ElementB, LayoutB, ElementOutput, LayoutC,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm89,
+      cutlass::gemm::GemmShape<128, 128, 128>, cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, kStages>;
 
+  EXPECT_TRUE(test::gemm::device::TestAllSparseGemm<Gemm>());
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+////////////////////////////////////////////////////////////////////////////////
 
-  using ElementC = double;
+TEST(SM89_Device_Sparse_Gemm_fe4m3t_fe5m2n_f32t_tensor_op_f32, 128x128x128_64x64x128) {
+  using ElementA = cutlass::float_e4m3_t;
+  using ElementB = cutlass::float_e5m2_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
+  static int const kStages = 3;
 
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  using Gemm = cutlass::gemm::device::SparseGemm<
+      ElementA, LayoutA, ElementB, LayoutB, ElementOutput, LayoutC,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm89,
+      cutlass::gemm::GemmShape<128, 128, 128>, cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, kStages>;
 
+  EXPECT_TRUE(test::gemm::device::TestAllSparseGemm<Gemm>());
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+////////////////////////////////////////////////////////////////////////////////
 
-  using ElementC = double;
+TEST(SM89_Device_Sparse_Gemm_fe5m2t_fe4m3n_f32t_tensor_op_f32, 128x128x128_64x64x128) {
+  using ElementA = cutlass::float_e5m2_t;
+  using ElementB = cutlass::float_e4m3_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
+  static int const kStages = 3;
 
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  using Gemm = cutlass::gemm::device::SparseGemm<
+      ElementA, LayoutA, ElementB, LayoutB, ElementOutput, LayoutC,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm89,
+      cutlass::gemm::GemmShape<128, 128, 128>, cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, kStages>;
 
+  EXPECT_TRUE(test::gemm::device::TestAllSparseGemm<Gemm>());
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-
-  using ElementC = double;
+TEST(SM89_Device_Sparse_Gemm_fe5m2t_fe5m2n_f32t_tensor_op_f32, 128x128x128_64x64x128) {
+  using ElementA = cutlass::float_e5m2_t;
+  using ElementB = cutlass::float_e5m2_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 16>,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3
-  >;
+  static int const kStages = 3;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  using Gemm = cutlass::gemm::device::SparseGemm<
+      ElementA, LayoutA, ElementB, LayoutB, ElementOutput, LayoutC,
+      ElementAccumulator, cutlass::arch::OpClassTensorOp, cutlass::arch::Sm89,
+      cutlass::gemm::GemmShape<128, 128, 128>, cutlass::gemm::GemmShape<64, 64, 128>, cutlass::gemm::GemmShape<16, 8, 64>,
+      cutlass::epilogue::thread::LinearCombination<
+          ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
+          ElementAccumulator, ElementAccumulator>,
+      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>, kStages>;
 
+  EXPECT_TRUE(test::gemm::device::TestAllSparseGemm<Gemm>());
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syrk_f64n_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
-
-  using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kUpper,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
-
-}
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif  // CUTLASS_ARCH_MMA_SM89_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -128,16 +128,16 @@
       int bits_input = cutlass::sizeof_bits<Element>::value;
       int bits_output = cutlass::sizeof_bits<typename Gemm::ElementC>::value;
 
       if (bits_input == 1) {
         scope_max = 2;
         scope_min = 0;
       } else if (bits_input <= 8) {
-        scope_max = 2;
-        scope_min = -2;
+        scope_max = 1;
+        scope_min = -1;
       } else if (bits_output == 16) {
         scope_max = 5;
         scope_min = -5;
       } else {
         scope_max = 8;
         scope_min = -8;
       }
@@ -293,15 +293,15 @@
 
 	/// Determine if the CUDA device is sufficient to run the kernel
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -111,15 +111,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
     
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
     
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
     
     if (result != cudaSuccess) {
     	throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h`

 * *Files 4% similar despite different names*

```diff
@@ -72,18 +72,23 @@
   typename OutputOp::ElementwiseOp elementwise_op;
 
   GemmWithBroadcastReferenceOp() { }
 
   void operator()(ElementZ &Z, ElementT &T, ElementCompute gemm, ElementCompute bias) {
 
     ElementCompute t_full = binary_op(gemm, bias);
-    T = ElementT(t_full);
 
-    ElementCompute z_full = elementwise_op(t_full);
-    Z = ElementZ(z_full);
+    if (OutputOp::kStoreT) {
+      T = ElementT(t_full);
+    }
+
+    if (OutputOp::kStoreZ) {
+      ElementCompute z_full = elementwise_op(t_full);
+      Z = ElementZ(z_full);
+    }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Fused testbed
 //
@@ -248,20 +253,24 @@
 
     tensor_Z.sync_host();
     tensor_T.sync_host();
 
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_A.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_B.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_C.host_view()), 0);
-    
-    EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_Z.host_view()), 0);
-    EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_T.host_view()), 0);
 
-    EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_Z_ref.host_view()), 0);
-    EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_T_ref.host_view()), 0);
+    if (OutputOp::kStoreZ) {
+      EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_Z.host_view()), 0);
+      EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_Z_ref.host_view()), 0);
+    }
+
+    if (OutputOp::kStoreT) {
+      EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_T.host_view()), 0);
+      EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_T_ref.host_view()), 0);
+    }
 
     bool passed = true;
     float norm_diff = 0;
 
     if (OutputOp::kStoreZ) {
       norm_diff = cutlass::reference::host::TensorNormDiff(tensor_Z_ref.host_view(), tensor_Z.host_view(), float());
       passed = (norm_diff <= 0.1f);
@@ -355,30 +364,35 @@
       for (int n = 0; n < problem_size.n(); ++n) {
 
         ElementZ z;
         ElementT t;
 
         reference_op(z, t, tensor_Y_ref.at({m, n}), tensor_Broadcast.at({m, 0}));
 
-        tensor_Z_ref.at({m, n}) = z;
-        tensor_T_ref.at({m, n}) = t;
+        if (OutputOp::kStoreZ) {
+          tensor_Z_ref.at({m, n}) = z;
+        }
+
+        if (OutputOp::kStoreT) {
+          tensor_T_ref.at({m, n}) = t;
+        }
       }
     }
 
     return compare_reference(problem_size, alpha, beta);
   }
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
 
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
@@ -448,15 +462,14 @@
 
     size_t workspace_size = Gemm::get_workspace_size(arguments);
 
     cutlass::device_memory::allocation<uint8_t> workspace(workspace_size);
 
     cutlass::Status status = gemm_op.initialize(arguments, workspace.get());
 
-
     EXPECT_TRUE(status == cutlass::Status::kSuccess) << to_string(status);
 
     //
     // Run the GEMM
     //
 
     status = gemm_op();
@@ -626,15 +639,15 @@
             passed = testbed.run(
               cutlass::gemm::GemmUniversalMode::kGemm,
               {M, N, K}, 
               1,
               cutlass::from_real<ElementAccumulator>(alpha), 
               cutlass::from_real<ElementAccumulator>(beta)
             );
-            
+
             EXPECT_TRUE(passed) 
               << "M: " << M << ", N: " << N << ", K: " << K << ", alpha: " << alpha << ", beta: " << beta;
 
             if (!passed) {
 
               return passed;
             }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -358,15 +358,15 @@
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
 
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h`

 * *Files 0% similar despite different names*

```diff
@@ -112,15 +112,15 @@
 
 	/// Waives test if CUDA device is insufficient
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h`

 * *Files 1% similar despite different names*

```diff
@@ -120,15 +120,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -281,15 +281,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Rank2K::Rank2Kkernel::SharedStorage));
+    size_t smem_size = sizeof(typename Rank2K::Rank2Kkernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -268,15 +268,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename RankK::RankKkernel::SharedStorage));
+    size_t smem_size = sizeof(typename RankK::RankKkernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h`

 * *Files 1% similar despite different names*

```diff
@@ -304,15 +304,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h`

 * *Files 1% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -307,15 +307,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Symm::SymmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Symm::SymmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -344,15 +344,15 @@
   
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Trmm::TrmmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Trmm::TrmmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_universal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -105,16 +105,16 @@
       int bits_output = cutlass::sizeof_bits<typename Gemm::ElementC>::value;
       bool is_unsigned_int = std::numeric_limits<Element>::is_integer && !std::numeric_limits<Element>::is_signed;
 
       if (bits_input == 1) {
         scope_max = 2;
         scope_min = 0;
       } else if (bits_input <= 8) {
-        scope_max = is_unsigned_int ? 4 : 2;
-        scope_min = is_unsigned_int ? 0 : -2;
+        scope_max = is_unsigned_int ? 2 : 1;
+        scope_min = is_unsigned_int ? 0 : -1;
       } else if (bits_output == 16) {
         scope_max = is_unsigned_int ? 10 : 5;
         scope_min = is_unsigned_int ? 0 : -5;
       } else {
         scope_max = 8;
         scope_min = -8;
       }
@@ -273,15 +273,15 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+    size_t smem_size = sizeof(typename Gemm::GemmKernel::SharedStorage);
 
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/testbed_utils.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu`

 * *Files 22% similar despite different names*

```diff
@@ -25,113 +25,116 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide TRMM interface
-
-  
+    \brief Unit tests for thread-level GEMM
 */
 
-#include <iostream>
-
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/device/trmm.h"
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/trmm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_trmm_universal.h"
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/warp/mma_simt.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "testbed.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_cf64n_cf64n_cf64t_ls_u_nu_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
+TEST(SM60_warp_gemm_f16_col_row, 8x4x1_1x1x1) {
 
-  using ElementOutput = cutlass::complex<double>;
-  using ElementAccumulator = cutlass::complex<double>;
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<1, 1, 1>
+  >;
 
-  using Trmm = cutlass::gemm::device::Trmm<
-    cutlass::complex<double>,
-    cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kLeft,
-    cutlass::FillMode::kUpper,
-    cutlass::DiagType::kNonUnit,
-    cutlass::complex<double>,
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<8, 4, 8>,
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
-    ElementOutput,
+    cutlass::half_t,
     cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAddGaussianComplex,
-    cutlass::ComplexTransform::kNone
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    Policy
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_cf64h_cf64n_cf64t_ls_u_nu_tensor_op_f64_gaussian, 64x64x16_32x32x16) {
+TEST(SM60_warp_gemm_f16_col_row, 16x8x1_2x2x1) {
 
-  using ElementOutput = cutlass::complex<double>;
-  using ElementAccumulator = cutlass::complex<double>;
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<2, 2, 1>
+  >;
 
-  using Trmm = cutlass::gemm::device::Trmm<
-    cutlass::complex<double>,
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<16, 8, 8>,
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kLeft,
-    cutlass::FillMode::kUpper,
-    cutlass::DiagType::kNonUnit,
-    cutlass::complex<double>,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
-    ElementOutput,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM60_warp_gemm_f16_col_row, 32x16x1_4x4x1) {
+
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<4, 4, 1>
+  >;
+
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<32, 16, 8>,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
     cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAddGaussianComplex,
-    cutlass::ComplexTransform::kConjugate
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    Policy
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM60_warp_gemm_f16_col_row, 64x16x1_8x4x1) {
+
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<8, 8, 1>
+  >;
+
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<64, 32, 8>,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,102 +25,118 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide TRMM interface
-
-  
+    \brief Tests for device-wide Implicit GEMM interface
 */
 
-#include <iostream>
-
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/device/trmm.h"
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/trmm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/tensor_view_io.h"
-
-#include "testbed_trmm_universal.h"
-
-#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM90_Device_Trmm_f64n_f64n_f64t_rs_l_nu_tensor_op_f64, 32x32x16_16x16x16) {
-
-  using ElementOutput = double;
-  using ElementAccumulator = double;
-
-  using Trmm = cutlass::gemm::device::Trmm<
-    double,
-    cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight,
-    cutlass::FillMode::kLower,
-    cutlass::DiagType::kNonUnit,
-    double,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+#include "cutlass/cutlass.h"
+
+#include "cutlass/conv/kernel/default_conv3d_dgrad.h"
+#include "cutlass/conv/device/implicit_gemm_convolution.h"
+
+#include "conv3d_testbed.h"
+
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+
+////////////////////////////////////////////////////////////////////////////////
+
+
+////////////////////////////////////////////////////////////////////////////////
+TEST(SM80_Device_Conv3d_Dgrad_Analytic_ImplicitGemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32,
+  128x128_8x4_32x64x8) {
+
+  /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
+  using ElementA           = float;
+  using ElementB           = float;
+  using ElementC           = float;
+  using ElementAccumulator = float;
+  using ElementCompute     = float;
+
+
+  /// Device-level Conv3d instance
+  using Conv3dDgradKernel = typename cutlass::conv::kernel::DefaultConv3dDgrad<
+    ElementA, 
+    cutlass::layout::TensorNDHWC,
+    ElementB, 
+    cutlass::layout::TensorNDHWC,
+    ElementC, 
+    cutlass::layout::TensorNDHWC,
     ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::arch::OpClassSimt,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 8>,
+    cutlass::gemm::GemmShape<32, 64, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
+      ElementC,
       1,
       ElementAccumulator,
-      ElementAccumulator
+      ElementCompute
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    4,
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::conv::IteratorAlgorithm::kAnalytic,
+    cutlass::conv::StrideSupport::kStrided
+  >::Kernel;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
-}
+  using Conv3dDgrad = cutlass::conv::device::ImplicitGemmConvolution<Conv3dDgradKernel>;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  /// Run all unit test sizes with device-level Conv3d instance
+  EXPECT_TRUE(test::conv::device::TestAllConv3d<Conv3dDgrad>());
 
-TEST(SM90_Device_Trmm_f64t_f64t_f64n_rs_l_nu_tensor_op_f64, 64x64x16_32x32x16) {
+}
 
-  using ElementOutput = double;
-  using ElementAccumulator = double;
 
-  using Trmm = cutlass::gemm::device::Trmm<
-    double,
-    cutlass::layout::RowMajor,
-    cutlass::SideMode::kRight,
-    cutlass::FillMode::kLower,
-    cutlass::DiagType::kNonUnit,
-    double,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::ColumnMajor,
+////////////////////////////////////////////////////////////////////////////////
+TEST(SM80_Device_Conv3d_Dgrad_Optimized_ImplicitGemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32,
+  128x128_8x4_64x32x8) {
+
+  /// Conv operation element types for the Gemm equivalent (ImplicitGemm)
+  using ElementA           = float;
+  using ElementB           = float;
+  using ElementC           = float;
+  using ElementAccumulator = float;
+  using ElementCompute     = float;
+
+
+  /// Device-level Conv3d instance
+  using Conv3dDgradKernel = typename cutlass::conv::kernel::DefaultConv3dDgrad<
+    ElementA, 
+    cutlass::layout::TensorNDHWC,
+    ElementB, 
+    cutlass::layout::TensorNDHWC,
+    ElementC, 
+    cutlass::layout::TensorNDHWC,
     ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::arch::OpClassSimt,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 8>,
+    cutlass::gemm::GemmShape<64, 32, 8>, 
+    cutlass::gemm::GemmShape<1, 1, 1>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
+      ElementC,
       1,
       ElementAccumulator,
-      ElementAccumulator
+      ElementCompute
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    4,
+    cutlass::arch::OpMultiplyAdd,
+    cutlass::conv::IteratorAlgorithm::kOptimized,
+    cutlass::conv::StrideSupport::kUnity
+  >::Kernel;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
-}
+  using Conv3dDgrad = cutlass::conv::device::ImplicitGemmConvolution<Conv3dDgradKernel>;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  /// Run all unit test sizes with device-level Conv3d instance
+  EXPECT_TRUE(test::conv::device::TestAllConv3d<Conv3dDgrad>());
+
+}
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
+////////////////////////////////////////////////////////////////////////////////
+#endif  // CUTLASS_ARCH_MMA_SM80_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu`

 * *Files 27% similar despite different names*

```diff
@@ -25,228 +25,271 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide TRMM interface
-
-  
+    \brief Unit tests for thread-level GEMM
 */
 
-#include <iostream>
-
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/device/trmm.h"
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/trmm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_trmm_universal.h"
+#include "cutlass/aligned_buffer.h"
+#include "cutlass/half.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "cutlass/gemm/warp/mma_tensor_op_sm70.h"
 
-////////////////////////////////////////////Test name//////////////////////////////////////////////////
-//                             
-// SM80_Device_Trmm_{ElementA}{LayoutA}_{ElementB}{LayoutB}_{ElementC}{LayoutC}_{SideMode}_{FillMode}\
-//    _{DiagType}_tensor_op_{ElementAccumulator}_align{AlignmentA}_align{AlignmentB}
-//
-///////////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/core_io.h"
+#include "cutlass/util/host_tensor.h"
+#include "cutlass/util/tensor_view_io.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/gemm.h"
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
+#include "testbed.h"
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
-}
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 128x64x32_32x64x32) {
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x16_64x64x16_16x16x4) {
+
+  using Shape = cutlass::gemm::GemmShape<64, 64, 16>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 16> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x64x4_64x64x4_16x16x4) {
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 64, 4> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x4_32x32x4_16x16x4) {
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 4> >().run();
 }
-/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 128x64x32_32x64x32) {
+TEST(SM70_warp_gemm_tensor_op_crosswise, 64x64x32_64x64x32_16x16x4) {
+  using Shape = cutlass::gemm::GemmShape<64, 64, 32>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::RowMajorVoltaTensorOpMultiplicandCrosswise<
+      cutlass::sizeof_bits<ElementA>::value, 32>;
+  using LayoutB = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCrosswise<
+      cutlass::sizeof_bits<ElementB>::value, 32>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::RowMajor,
+      ElementB,
+      cutlass::layout::ColumnMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<64, 64, 32> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_row_col, 64x64x16_64x64x4_8x8x4) {
+  
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::RowMajor,
+      ElementB,
+      cutlass::layout::ColumnMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<64, 64, 16> >()
+      .run();
+}
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_col_row, 64x64x16_64x64x4_8x8x4) {
+  
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      LayoutA,
+      ElementB,
+      LayoutB,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
+
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<64, 64, 16> >()
+      .run();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+
+#endif // CUTLASS_ARCH_MMA_SM70_SUPPORTED
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/thread/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/thread/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu`

 * *Files 1% similar despite different names*

```diff
@@ -35,14 +35,150 @@
 
 #include "mma_multistage_testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 ////////////////////////////////////////////////////////////////////////////////
 
+TEST(SM80_gemm_threadblock_congruous, tensor_op_16x128x64_16x32x64_16x8x16_3stage) {
+  using ElementA = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = cutlass::half_t;
+  using LayoutB = cutlass::layout::RowMajor;
+  using ElementC = float;
+  using LayoutC = cutlass::layout::ColumnMajor;
+
+  cutlass::gemm::GemmCoord problem_size(32, 256, 128);
+
+  using ThreadblockShape = cutlass::gemm::GemmShape<16, 128, 64>;
+  using WarpShape = cutlass::gemm::GemmShape<16, 32, 64>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+
+  float alpha = 1.f;
+  float beta = 0.0f;
+  int const Stages = 3;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementC, LayoutC,
+      cutlass::arch::OpClassTensorOp, Stages>;
+
+  dim3 grid(2, 2);
+  dim3 block(32, 4, 1);
+
+  test::gemm::threadblock::Testbed<MmaCore>(problem_size.m(), problem_size.n(),
+                                            problem_size.k(), alpha, beta)
+      .run(grid, block);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_gemm_threadblock_congruous, tensor_op_128x16x64_32x16x64_16x8x16_3stage) {
+  using ElementA = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = cutlass::half_t;
+  using LayoutB = cutlass::layout::RowMajor;
+  using ElementC = float;
+  using LayoutC = cutlass::layout::ColumnMajor;
+
+  cutlass::gemm::GemmCoord problem_size(256, 32, 128);
+
+  using ThreadblockShape = cutlass::gemm::GemmShape<128, 16, 64>;
+  using WarpShape = cutlass::gemm::GemmShape<32, 16, 64>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+
+  float alpha = 1.f;
+  float beta = 0.0f;
+  int const Stages = 3;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementC, LayoutC,
+      cutlass::arch::OpClassTensorOp, Stages>;
+
+  dim3 grid(2, 2);
+  dim3 block(32, 4, 1);
+
+  test::gemm::threadblock::Testbed<MmaCore>(problem_size.m(), problem_size.n(),
+                                            problem_size.k(), alpha, beta)
+      .run(grid, block);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_gemm_threadblock_congruous, tensor_op_32x128x32_32x32x32_16x8x16_3stage) {
+  using ElementA = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = cutlass::half_t;
+  using LayoutB = cutlass::layout::RowMajor;
+  using ElementC = float;
+  using LayoutC = cutlass::layout::ColumnMajor;
+
+  cutlass::gemm::GemmCoord problem_size(64, 256, 128);
+
+  using ThreadblockShape = cutlass::gemm::GemmShape<32, 128, 32>;
+  using WarpShape = cutlass::gemm::GemmShape<32, 32, 32>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+
+  float alpha = 1.f;
+  float beta = 0.0f;
+  int const Stages = 3;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementC, LayoutC,
+      cutlass::arch::OpClassTensorOp, Stages>;
+
+  dim3 grid(2, 2);
+  dim3 block(32, 4, 1);
+
+  test::gemm::threadblock::Testbed<MmaCore>(problem_size.m(), problem_size.n(),
+                                            problem_size.k(), alpha, beta)
+      .run(grid, block);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_gemm_threadblock_congruous, tensor_op_128x32x32_32x32x32_16x8x16_3stage) {
+  using ElementA = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = cutlass::half_t;
+  using LayoutB = cutlass::layout::RowMajor;
+  using ElementC = float;
+  using LayoutC = cutlass::layout::ColumnMajor;
+
+  cutlass::gemm::GemmCoord problem_size(256, 64, 128);
+
+  using ThreadblockShape = cutlass::gemm::GemmShape<128, 32, 32>;
+  using WarpShape = cutlass::gemm::GemmShape<32, 32, 32>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+
+  float alpha = 1.f;
+  float beta = 0.0f;
+  int const Stages = 3;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementC, LayoutC,
+      cutlass::arch::OpClassTensorOp, Stages>;
+
+  dim3 grid(2, 2);
+  dim3 block(32, 4, 1);
+
+  test::gemm::threadblock::Testbed<MmaCore>(problem_size.m(), problem_size.n(),
+                                            problem_size.k(), alpha, beta)
+      .run(grid, block);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
 TEST(SM80_gemm_threadblock_congruous,
      tensor_op_64x64x64_64x64x64_16x8x16_3stage) {
   using ElementA = cutlass::half_t;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = cutlass::half_t;
   using LayoutB = cutlass::layout::RowMajor;
   using ElementC = float;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_mixed_input_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_mixed_input_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu`

 * *Files 21% similar despite different names*

```diff
@@ -36,105 +36,163 @@
 
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/warp/mma_simt.h"
 
 #include "testbed.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM60_warp_gemm_f16_col_row, 8x4x1_1x1x1) {
+TEST(SM61_warp_gemm_int8_col_row, col_row_8x4x8_1x1x4) {
 
   using Policy = cutlass::gemm::warp::MmaSimtPolicy<
     cutlass::MatrixShape<8, 4>,
     cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<1, 1, 1>
+    cutlass::gemm::GemmShape<1, 1, 4>
   >;
 
   using Mma = cutlass::gemm::warp::MmaSimt<
     cutlass::gemm::GemmShape<8, 4, 8>,
-    cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
     Policy
   >;
 
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<8, 4, 8> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM60_warp_gemm_f16_col_row, 16x8x1_2x2x1) {
+TEST(SM61_warp_gemm_int8_col_row, col_row_8x4x4_1x1x4) {
 
   using Policy = cutlass::gemm::warp::MmaSimtPolicy<
     cutlass::MatrixShape<8, 4>,
     cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<2, 2, 1>
+    cutlass::gemm::GemmShape<1, 1, 4>
   >;
 
   using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    cutlass::gemm::GemmShape<8, 4, 8>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
     Policy
   >;
 
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 8> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM60_warp_gemm_f16_col_row, 32x16x1_4x4x1) {
+TEST(SM61_warp_gemm_int8_col_row, col_row_16x4x4_2x1x4) {
 
   using Policy = cutlass::gemm::warp::MmaSimtPolicy<
     cutlass::MatrixShape<8, 4>,
     cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<4, 4, 1>
+    cutlass::gemm::GemmShape<2, 1, 4>
   >;
 
   using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<32, 16, 8>,
-    cutlass::half_t,
+    cutlass::gemm::GemmShape<16, 4, 4>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<16, 4, 4> >().run();
+}
+
+TEST(SM61_warp_gemm_int8_col_row, col_row_16x4x4_2x2x4) {
+
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<2, 2, 4>
+  >;
+
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<16, 8, 4>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
     Policy
   >;
 
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<16, 8, 4> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+TEST(SM61_warp_gemm_int8_col_row, col_row_32x16x4_4x4x4) {
+
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<4, 4, 4>
+  >;
+
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<32, 16, 16>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
+    cutlass::layout::ColumnMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 16> >().run();
+}
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM60_warp_gemm_f16_col_row, 64x16x1_8x4x1) {
+TEST(SM61_warp_gemm_int8_col_row, col_row_128x64x4_16x16x4) {
 
   using Policy = cutlass::gemm::warp::MmaSimtPolicy<
     cutlass::MatrixShape<8, 4>,
     cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<8, 8, 1>
+    cutlass::gemm::GemmShape<16, 16, 4>
   >;
 
   using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<64, 32, 8>,
-    cutlass::half_t,
+    cutlass::gemm::GemmShape<128, 64, 4>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 4> >().run();
+}
+
+TEST(SM61_warp_gemm_int8_col_row, col_row_64x64x4_4x4x4) {
+
+  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
+    cutlass::MatrixShape<8, 4>,
+    cutlass::layout::ColumnMajorInterleaved<2>,
+    cutlass::gemm::GemmShape<4, 4, 4>
+  >;
+
+  using Mma = cutlass::gemm::warp::MmaSimt<
+    cutlass::gemm::GemmShape<64, 64, 8>,
+    int8_t,
+    cutlass::layout::ColumnMajorInterleaved<4>,
+    int8_t,
+    cutlass::layout::RowMajorInterleaved<4>,
+    int,
     cutlass::layout::ColumnMajor,
     Policy
   >;
 
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 128, 8> >().run();
+  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<64, 64, 8> >().run();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_gemm.cu`

 * *Files 26% similar despite different names*

```diff
@@ -30,169 +30,174 @@
  **************************************************************************************************/
 /*! \file
     \brief Unit tests for thread-level GEMM
 */
 
 #include "../../common/cutlass_unit_test.h"
 
-#include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/warp/mma_simt.h"
+#include "cutlass/gemm/thread/mma.h"
 
 #include "testbed.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-TEST(SM61_warp_gemm_int8_col_row, col_row_8x4x8_1x1x4) {
+#if 0
+int main() {
+  nvrtc::thread::Testbed<
+    cutlass::gemm::GemmShape<3, 4, 2>,
+    float,
+    cutlass::layout::ColumnMajor,
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run("cutlass::gemm::thread::Mma<cutlass::gemm::GemmShape<3, 4, 2>, float, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, float, cutlass::layout::ColumnMajor >");
+  return 0;
+}
+#endif
+
+TEST(SM50_Sgemm_thread_nvrtc, DISABLED_col_row_3x4x2) {
+
+  test::nvrtc::thread::Testbed<
+    cutlass::gemm::GemmShape<3, 4, 2>,
+    float,
+    cutlass::layout::ColumnMajor,
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run("cutlass::gemm::thread::Mma<cutlass::gemm::GemmShape<3, 4, 2>, float, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, float, cutlass::layout::ColumnMajor >");
+}
 
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<1, 1, 4>
-  >;
+/////////////////////////////////////////////////////////////////////////////////////////////////
+#if 0
+TEST(SM50_Sgemm_thread, col_row_3x4x2) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<8, 4, 8>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<3, 4, 2>,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<8, 4, 8> >().run();
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_8x4x4_1x1x4) {
-
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<1, 1, 4>
-  >;
+TEST(SM50_Sgemm_thread, col_row_4x4x2) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<8, 4, 8>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<4, 4, 2>,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 8> >().run();
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_16x4x4_2x1x4) {
+TEST(SM50_Sgemm_thread, row_col_4x4x2) {
 
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<2, 1, 4>
-  >;
-
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<16, 4, 4>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<4, 4, 2>,
+    float,
+    cutlass::layout::RowMajor,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<16, 4, 4> >().run();
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_16x4x4_2x2x4) {
-
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<2, 2, 4>
-  >;
+TEST(SM50_Sgemm_thread, col_row_4x5x3) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<16, 8, 4>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<4, 5, 3>,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<16, 8, 4> >().run();
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_32x16x4_4x4x4) {
-
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<4, 4, 4>
-  >;
+TEST(SM50_Sgemm_thread, col_row) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<32, 16, 16>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 16> >().run();
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
+TEST(SM50_Sgemm_thread, row_col) {
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_128x64x4_16x16x4) {
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
+}
 
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<16, 16, 4>
-  >;
+TEST(SM50_Sgemm_thread, col_col) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<128, 64, 4>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    float,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
+    float,
+    cutlass::layout::ColumnMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
+}
+
+TEST(SM50_Sgemm_thread, row_row) {
 
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<128, 64, 4> >().run();
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::RowMajor,
+    float,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
-TEST(SM61_warp_gemm_int8_col_row, col_row_64x64x4_4x4x4) {
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  using Policy = cutlass::gemm::warp::MmaSimtPolicy<
-    cutlass::MatrixShape<8, 4>,
-    cutlass::layout::ColumnMajorInterleaved<2>,
-    cutlass::gemm::GemmShape<4, 4, 4>
-  >;
+TEST(SM50_Dgemm_thread, col_row) {
 
-  using Mma = cutlass::gemm::warp::MmaSimt<
-    cutlass::gemm::GemmShape<64, 64, 8>,
-    int8_t,
-    cutlass::layout::ColumnMajorInterleaved<4>,
-    int8_t,
-    cutlass::layout::RowMajorInterleaved<4>,
-    int,
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    double,
     cutlass::layout::ColumnMajor,
-    Policy
-  >;
-
-  test::gemm::warp::Testbed<Mma, cutlass::gemm::GemmShape<64, 64, 8> >().run();
+    double,
+    cutlass::layout::RowMajor,
+    double,
+    cutlass::layout::ColumnMajor
+  >().run();
 }
 
+TEST(SM50_Dgemm_thread, row_col) {
+
+  test::gemm::thread::Testbed<
+    cutlass::gemm::GemmShape<8, 8, 1>,
+    double,
+    cutlass::layout::RowMajor,
+    double,
+    cutlass::layout::ColumnMajor,
+    double,
+    cutlass::layout::ColumnMajor
+  >().run();
+}
+#endif
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu`

 * *Files 19% similar despite different names*

```diff
@@ -24,272 +24,181 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Unit tests for thread-level GEMM
+/*! \file 
+
+    \brief Unit tests for thread-level GEMM with Hopper FP64
 */
 
 #include "../../common/cutlass_unit_test.h"
 
 #include "cutlass/aligned_buffer.h"
 #include "cutlass/half.h"
 
-#include "cutlass/gemm/warp/mma_tensor_op_sm70.h"
+#include "cutlass/gemm/warp/default_mma_tensor_op.h"
 
 #include "cutlass/core_io.h"
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 16x16x4_16x16x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<16, 16, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<16, 16, 4> >()
+      .run();
+}
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x16_64x64x16_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<64, 64, 16>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x16x4_32x16x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 16, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 16> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 16, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x64x4_64x64x4_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x32x4_32x32x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 64, 4> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 32, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x4_32x32x4_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x64x4_32x64x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 4> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 64, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_crosswise, 64x64x32_64x64x32_16x16x4) {
-  using Shape = cutlass::gemm::GemmShape<64, 64, 32>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::RowMajorVoltaTensorOpMultiplicandCrosswise<
-      cutlass::sizeof_bits<ElementA>::value, 32>;
-  using LayoutB = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCrosswise<
-      cutlass::sizeof_bits<ElementB>::value, 32>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::RowMajor,
-      ElementB,
-      cutlass::layout::ColumnMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 16x16x16_16x16x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<16, 16, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<64, 64, 32> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<16, 16, 16> >()
+      .run();
 }
 
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_row_col, 64x64x16_64x64x4_8x8x4) {
-  
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = float;
-  using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::ColumnMajor;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::RowMajor,
-      ElementB,
-      cutlass::layout::ColumnMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 32x32x16_32x32x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
   test::gemm::warp::Testbed<MmaTensorOp,
-                            cutlass::gemm::GemmShape<64, 64, 16> >()
+                            cutlass::gemm::GemmShape<32, 32, 16> >()
       .run();
 }
 
-TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_col_row, 64x64x16_64x64x4_8x8x4) {
-  
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = float;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using LayoutB = cutlass::layout::RowMajor;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      LayoutA,
-      ElementB,
-      LayoutB,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 64x32x16_64x32x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<64, 32, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
   test::gemm::warp::Testbed<MmaTensorOp,
-                            cutlass::gemm::GemmShape<64, 64, 16> >()
+                            cutlass::gemm::GemmShape<64, 32, 16> >()
       .run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 32x64x16_32x64x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 64, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-#endif // CUTLASS_ARCH_MMA_SM70_SUPPORTED
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 64, 16> >()
+      .run();
+}
+////////////////////////////////////////////////////////////////////////////////
+#endif // if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -113,14 +113,35 @@
   test::gemm::warp::Testbed<MmaTensorOp,
                             cutlass::gemm::GemmShape<128, 128, 32> >()
       .run();
 }
 
 ////////////////////////////////////////////////////////////////////////////////
 
+TEST(SM75_warp_gemm_tensor_op_congruous_f16, 32x32x32_32x32x32_16x8x8) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 32>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 8>;
+  using Element = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 32>;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 32>;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor>::Type;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 32, 32> >()
+      .run();
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
 TEST(SM75_warp_gemm_tensor_op_crosswise_f16, 128x128x32_64x64x32_16x8x8) {
   using Shape = cutlass::gemm::GemmShape<64, 64, 32>;
   using InstructionShape = cutlass::gemm::GemmShape<16, 8, 8>;
   using Element = cutlass::half_t;
   using ElementC = float;
   using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<
       cutlass::sizeof_bits<Element>::value, 32>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -512,14 +512,56 @@
   test::gemm::warp::Testbed<MmaTensorOp,
                             cutlass::gemm::GemmShape<128, 128, 32> >()
       .run();
 }
 
 ////////////////////////////////////////////////////////////////////////////////
 
+TEST(SM80_warp_gemm_tensor_op_congruous_f16, 16x16x32_16x16x32_16x8x16) {
+  using Shape = cutlass::gemm::GemmShape<16, 16, 32>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+  using Element = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 16>;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 16>;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor>::Type;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<16, 16, 32> >()
+      .run();
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_warp_gemm_tensor_op_congruous_f16, 32x32x32_32x32x32_16x8x16) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 32>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+  using Element = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 32>;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous<
+      cutlass::sizeof_bits<Element>::value, 32>;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor>::Type;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 32, 32> >()
+      .run();
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
 TEST(SM80_warp_gemm_tensor_op_congruous_f16, 128x128x64_64x64x64_16x8x16) {
   using Shape = cutlass::gemm::GemmShape<64, 64, 64>;
   using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
   using Element = cutlass::half_t;
   using ElementC = float;
   using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<
       cutlass::sizeof_bits<Element>::value, 64>;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -74,23 +74,23 @@
 
   __shared__ cutlass::AlignedBuffer<
     typename Mma::ElementB, ThreadblockShape::kN * ThreadblockShape::kK> smem_buffer_B;
 
   if (threadIdx.x == 0) {
     typename Mma::ElementA *smem_ptr_A = smem_buffer_A.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_A.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_A.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementA>::get(smem_ptr_A, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementA>::type>::get(input_A, i);
     }
 
     typename Mma::ElementB *smem_ptr_B = smem_buffer_B.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_B.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_B.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementB>::get(smem_ptr_B, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementB>::type>::get(input_B, i);
     }
   }
 
   __syncthreads();
@@ -620,23 +620,23 @@
 
   __shared__ cutlass::AlignedBuffer<
     typename Mma::ElementB, ThreadblockShape::kN * ThreadblockShape::kK> smem_buffer_B;
 
   if (threadIdx.x == 0) {
     typename Mma::ElementA *smem_ptr_A = smem_buffer_A.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_A.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_A.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementA>::get(smem_ptr_A, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementA>::type>::get(input_A, i);
     }
 
     typename Mma::ElementB *smem_ptr_B = smem_buffer_B.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_B.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_B.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementB>::get(smem_ptr_B, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementB>::type>::get(input_B, i);
     }
   }
 
   __syncthreads();
@@ -1175,31 +1175,31 @@
       smem_buffer_E;
   
   __syncthreads();
 
   if (threadIdx.x == 0) {
     typename Mma::ElementA *smem_ptr_A = smem_buffer_A.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_A.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_A.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementA>::get(smem_ptr_A, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementA>::type>::get(input_A, i);
     }
 
     typename Mma::ElementB *smem_ptr_B = smem_buffer_B.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_B.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_B.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementB>::get(smem_ptr_B, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementB>::type>::get(input_B, i);
     }
 
     typename Mma::ElementE *smem_ptr_E = smem_buffer_E.data();
     #pragma unroll 1
-    for (int i = 0; i < smem_buffer_E.size(); ++i) {
+    for (size_t i = 0; i < smem_buffer_E.size(); ++i) {
       cutlass::ReferenceFactory<typename Mma::ElementE>::get(smem_ptr_E, i) =
           cutlass::ReferenceFactory<typename cutlass::platform::remove_const<
               typename Mma::ElementE>::type>::get(input_E, i);
     }
   }
 
   __syncthreads();
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/layout/matrix.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/matrix.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/layout/tensor.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/tensor.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/layout/tensor_nhwc.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/thread/contraction.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/contraction.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h`

 * *Files 14% similar despite different names*

```diff
@@ -24,7 +24,19 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+#pragma once
+
+
+#include "cutlass/cutlass.h"
+
+// The contents of this file have been moved  to 'tensor_reduce' to cover other types of reductions.
+
+#include "cutlass/util/reference/host/tensor_reduce.h"
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_contraction.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/nvrtc_contraction.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/nvrtc/thread/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -271,15 +271,15 @@
     check_nvrtc_error(result_nvrtc);
 
     std::string gemm_kernel_instantiation =
       "test::nvrtc::kernel::thread::testbed_kernel< " + type_name + " >";
     nvrtcAddNameExpression(program, gemm_kernel_instantiation.c_str());
 
     const char *opts[] = {"--gpu-architecture=compute_75",
-                          "--std=c++11",
+                          "--std=c++17",
                           "--include-path=/usr/local/cuda-10.1/include"};
 
     result_nvrtc = nvrtcCompileProgram(program, 3, opts);
     if (result_nvrtc != NVRTC_SUCCESS) {
       size_t logSize;
       nvrtcGetProgramLogSize(program, &logSize);
       std::vector<char> log(logSize);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_async.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/pipeline/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/pipeline/testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -127,16 +127,16 @@
   }
 
   /// Run verification Gemm problem sizes
   bool verification() {
 
     std::array<uint32_t, 5> kNumIters;
 
-    for (int i = 0; i < kNumIters.size(); ++i) {
-      kNumIters[i] = (rand() % 1000) + 1;
+    for (size_t i = 0; i < kNumIters.size(); ++i) {
+      kNumIters[i] = static_cast<uint32_t>( (rand() % 1000) + 1 );
     }
 
     for (int n : kNumIters) {
       std::cout << "Stages = " << Pipeline::Stages << " kNumIters = " << n << "\n";
       run_test(n);
     }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/reduction/thread/testbed.h` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/reduction/thread/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/substrate/dependent_false.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/substrate/dependent_false.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/test_unit.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/main.cpp`

 * *Files 14% similar despite different names*

```diff
@@ -24,18 +24,30 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/** \file
-    \brief Unit tests for CUTLASS core
+/* \file
+   \brief 
 */
 
-#include "common/cutlass_unit_test.h"
+#include <iostream>
 
-int main(int argc, char* arg[]) {
-  FilterArchitecture();
-  ::testing::InitGoogleTest(&argc, arg);
-  return RUN_ALL_TESTS();
+#include "cutlass/profiler/options.h"
+
+#include "cutlass/profiler/cutlass_profiler.h"
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+int main(int argc, char const *arg[]) {
+
+  cutlass::CommandLine cmdline(argc, arg);
+  cutlass::profiler::Options options(cmdline);
+
+  cutlass::profiler::CutlassProfiler profiler(options);
+
+  return profiler();
 }
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu`

 * *Files 0% similar despite different names*

```diff
@@ -64,15 +64,15 @@
   Iterator dst_iterator(dst_params, dst_pointer, extent, threadIdx.x);
   Iterator src_iterator(src_params, src_pointer, extent, threadIdx.x);
 
   int iterations = (extent[1] + Iterator::Shape::kStrided - 1) / Iterator::Shape::kStrided;
 
   typename Iterator::Fragment frag;
 
-  for(int i = 0; i < frag.size(); i++)
+  for(size_t i = 0; i < frag.size(); i++)
     frag[i] = 0;
 
   src_iterator.load(frag);
   dst_iterator.store(frag);
 
   ++dst_iterator;
   ++src_iterator;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/util/cutlass_test_levels.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/util/rms_norm.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/rms_norm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/test/unit/util/tensor_reduce.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/test/unit/util/tensor_reduce.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h`

 * *Files 8% similar despite different names*

```diff
@@ -93,14 +93,19 @@
 };
 
 template <typename OperatorClass> struct ArchMap<arch::Sm86, OperatorClass> {
   static int const kMin = 86;
   static int const kMax = 1024;
 };
 
+template <typename OperatorClass> struct ArchMap<arch::Sm89, OperatorClass> {
+  static int const kMin = 89;
+  static int const kMax = 89;
+};
+
 template <typename OperatorClass> struct ArchMap<arch::Sm90, OperatorClass> {
   static int const kMin = 90;
   static int const kMax = 1024;
 };
 
 // Arch conditional WGMMA
 template <> struct ArchMap<arch::Sm90, arch::OpClassTensorOp> {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/descriptions.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/descriptions.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/handle.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/handle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/library.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/library.h`

 * *Files 14% similar despite different names*

```diff
@@ -117,526 +117,506 @@
 //
 // OperationKind: Gemm
 // GemmKind:      Gemm
 //
 struct GemmConfiguration {
 
   /// GEMM problem size
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of C matrix
-  int64_t ldc;
+  int64_t ldc{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
   /// Number of partitions of K dimension
-  int split_k_slices;
+  int split_k_slices{0};
 };
 
 /// Arguments for GEMM
 struct GemmArguments {
 
   /// Pointer to A matrix
-  void const *A;
+  void const *A{nullptr};
 
   /// Pointer to B matrix
-  void const *B;
+  void const *B{nullptr};
 
   /// Pointer to C matrix
-  void const *C;
+  void const *C{nullptr};
 
   /// Pointer to D matrix
-  void *D;
+  void *D{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
+  ScalarPointerMode pointer_mode{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for batched GEMM in which multiple matrix products are computed
 //
 // OperationKind: Gemm
 // GemmKind:      Batched
 
 struct GemmBatchedConfiguration {
 
   /// GEMM problem size
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of C matrix
-  int64_t ldc;
+  int64_t ldc{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
   /// Stride between instances of the A matrix in memory
-  int64_t batch_stride_A;
+  int64_t batch_stride_A{0};
 
   /// Stride between instances of the B matrix in memory
-  int64_t batch_stride_B;
+  int64_t batch_stride_B{0};
 
   /// Stride between instances of the C matrix in memory
-  int64_t batch_stride_C;
+  int64_t batch_stride_C{0};
 
   /// Stride between instances of the D matrix in memory
-  int64_t batch_stride_D;
+  int64_t batch_stride_D{0};
 
   /// Number of GEMMs in batch
-  int batch_count;
+  int batch_count{1};
 };
 
 /// Arguments to batched GEMM
 using GemmBatchedArguments = GemmArguments;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for batched GEMM in which multiple matrix products are computed
 //
 // OperationKind: Gemm
 // GemmKind:      Array
 
 struct GemmArrayConfiguration {
 
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of C matrix
-  int64_t ldc;
+  int64_t ldc{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
-  int batch_count;
+  int batch_count{1};
 };
 
 /// Arguments for GEMM - used by all the GEMM operations
 struct GemmArrayArguments {
-  void const * const *A;
-  void const * const *B;
-  void const * const *C;
-  void * const *D;
-  void const *alpha;
-  void const *beta;
-  ScalarPointerMode pointer_mode;
+  void const * const *A{nullptr};
+  void const * const *B{nullptr};
+  void const * const *C{nullptr};
+  void * const *D{nullptr};
+  void const *alpha{nullptr};
+  void const *beta{nullptr};
+  ScalarPointerMode pointer_mode{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Universal GEMM supporting multiple split-K modes, multiple batched modes, real and complex
 //
 // OperationKind: Gemm
 // GemmKind:      Universal
 
 struct GemmUniversalConfiguration {
 
-  GemmUniversalMode mode;
-  gemm::GemmCoord problem_size;
-  int batch_count;
-
-  int64_t lda;
-  int64_t ldb;
-  int64_t ldc;
-  int64_t ldd;
+  GemmUniversalMode mode{GemmUniversalMode::kGemm};
+  gemm::GemmCoord problem_size{};
+  int batch_count{1};
+
+  int64_t lda{0};
+  int64_t ldb{0};
+  int64_t ldc{0};
+  int64_t ldd{0};
 };
 
 struct GemmUniversalArguments {
   // NOTE: these are replicated for 3.0 interfaces
-  gemm::GemmCoord problem_size;
-  int batch_count;
+  gemm::GemmCoord problem_size{};
+  int batch_count{1};
 
-  void const *A;
-  void const *B;
-  void const *C;
-  void *D;
-
-  void const *alpha;
-  void const *beta;
-  ScalarPointerMode pointer_mode;
+  void const *A{nullptr};
+  void const *B{nullptr};
+  void const *C{nullptr};
+  void *D{nullptr};
+
+  void const *alpha{nullptr};
+  void const *beta{nullptr};
+  ScalarPointerMode pointer_mode{};
 
   // NOTE: these are replicated for 3.0 interfaces
-  int64_t lda;
-  int64_t ldb;
-  int64_t ldc;
-  int64_t ldd;
-
-  int64_t batch_stride_A;
-  int64_t batch_stride_B;
-  int64_t batch_stride_C;
-  int64_t batch_stride_D;
+  int64_t lda{0};
+  int64_t ldb{0};
+  int64_t ldc{0};
+  int64_t ldd{0};
+
+  int64_t batch_stride_A{0};
+  int64_t batch_stride_B{0};
+  int64_t batch_stride_C{0};
+  int64_t batch_stride_D{0};
 
   // Needed for some 3.x kernels
-  int sm_count;
+  int sm_count{0};
 
-  library::RasterOrder raster_order;
+  library::RasterOrder raster_order{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Complex valued GEMM in which real and imaginary parts are separated by a stride
 //
 // OperationKind: Gemm
 // GemmKind:      Planar complex
 
 struct GemmPlanarComplexConfiguration {
 
-  GemmUniversalMode mode;
-  gemm::GemmCoord problem_size;
-  int batch_count;
-
-  int64_t lda_real;
-  int64_t lda_imag;
-
-  int64_t ldb_real;
-  int64_t ldb_imag;
-
-  int64_t ldc_real;
-  int64_t ldc_imag;
-
-  int64_t ldd_real;
-  int64_t ldd_imag;
+  GemmUniversalMode mode{GemmUniversalMode::kGemm};
+  gemm::GemmCoord problem_size{};
+  int batch_count{1};
+  int64_t lda_real{0};
+  int64_t lda_imag{0};
+  int64_t ldb_real{0};
+  int64_t ldb_imag{0};
+  int64_t ldc_real{0};
+  int64_t ldc_imag{0};
+  int64_t ldd_real{0};
+  int64_t ldd_imag{0};
 };
 
 /// Arguments for planar complex GEMMs
 struct GemmPlanarComplexArguments {
 
-  void const *A_real;
-  void const *A_imag;
-
-  void const *B_real;
-  void const *B_imag;
-
-  void const *C_real;
-  void const *C_imag;
-
-  void *D_real;
-  void *D_imag;
-
-  void const *alpha;
-  void const *beta;
-  ScalarPointerMode pointer_mode;
-
-  int64_t batch_stride_A_real;
-  int64_t batch_stride_A_imag;
-
-  int64_t batch_stride_B_real;
-  int64_t batch_stride_B_imag;
-
-  int64_t batch_stride_C_real;
-  int64_t batch_stride_C_imag;
-
-  int64_t batch_stride_D_real;
-  int64_t batch_stride_D_imag;
+  void const *A_real{nullptr};
+  void const *A_imag{nullptr};
+  void const *B_real{nullptr};
+  void const *B_imag{nullptr};
+  void const *C_real{nullptr};
+  void const *C_imag{nullptr};
+  void *D_real{nullptr};
+  void *D_imag{nullptr};
+  void const *alpha{nullptr};
+  void const *beta{nullptr};
+  ScalarPointerMode pointer_mode{};
+
+  int64_t batch_stride_A_real{0};
+  int64_t batch_stride_A_imag{0};
+  int64_t batch_stride_B_real{0};
+  int64_t batch_stride_B_imag{0};
+  int64_t batch_stride_C_real{0};
+  int64_t batch_stride_C_imag{0};
+  int64_t batch_stride_D_real{0};
+  int64_t batch_stride_D_imag{0};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// This is a special form of planar complex which loads pointers and problem size
 /// from memory.
 struct GemmPlanarComplexArrayConfiguration {
 
-  gemm::GemmCoord problem_size;
-  int batch_count;
-
-  int64_t lda_real;
-  int64_t lda_imag;
-
-  int64_t ldb_real;
-  int64_t ldb_imag;
-
-  int64_t ldc_real;
-  int64_t ldc_imag;
+  gemm::GemmCoord problem_size{};
+  int batch_count{1};
 
-  int64_t ldd_real;
-  int64_t ldd_imag;
+  int64_t lda_real{0};
+  int64_t lda_imag{0};
+  int64_t ldb_real{0};
+  int64_t ldb_imag{0};
+  int64_t ldc_real{0};
+  int64_t ldc_imag{0};
+  int64_t ldd_real{0};
+  int64_t ldd_imag{0};
 };
 
 /// Arguments for planar complex GEMMs
 struct GemmPlanarComplexArrayArguments {
 
-  int const *M;
-  int const *N;
-  int const *K;
-
-  void const * const * A_real;
-  void const * const * A_imag;
-  void const * const * B_real;
-  void const * const * B_imag;
-  void const * const * C_real;
-  void const * const * C_imag;
-  void * const * D_real;
-  void * const * D_imag;
-
-  void const * alpha;
-  void const * beta;
-  ScalarPointerMode pointer_mode;
+  int const *M{nullptr};
+  int const *N{nullptr};
+  int const *K{nullptr};
+
+  void const * const * A_real{nullptr};
+  void const * const * A_imag{nullptr};
+  void const * const * B_real{nullptr};
+  void const * const * B_imag{nullptr};
+  void const * const * C_real{nullptr};
+  void const * const * C_imag{nullptr};
+  void * const * D_real{nullptr};
+  void * const * D_imag{nullptr};
+
+  void const * alpha{nullptr};
+  void const * beta{nullptr};
+  ScalarPointerMode pointer_mode{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Grouped GEMM supporting
 //
 // OperationKind: Gemm
 // GemmKind:      Grouped
 
 struct GemmGroupedConfiguration {
-
-  int problem_count;
-  int threadblock_count;
-
+  int problem_count{0};
+  int threadblock_count{0};
 };
 
 struct GemmGroupedArguments {
 
-  gemm::GemmCoord *problem_sizes;
+  gemm::GemmCoord *problem_sizes{nullptr};
 
-  void * ptr_A;
-  void * ptr_B;
-  void * ptr_C;
-  void * ptr_D;
-
-  int64_t *lda;
-  int64_t *ldb;
-  int64_t *ldc;
-  int64_t *ldd;
-
-  void const *alpha;
-  void const *beta;
-  ScalarPointerMode pointer_mode;
+  void * ptr_A{nullptr};
+  void * ptr_B{nullptr};
+  void * ptr_C{nullptr};
+  void * ptr_D{nullptr};
+
+  int64_t *lda{nullptr};
+  int64_t *ldb{nullptr};
+  int64_t *ldc{nullptr};
+  int64_t *ldd{nullptr};
+
+  void const *alpha{nullptr};
+  void const *beta{nullptr};
+  ScalarPointerMode pointer_mode{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
 // OperationKind: kSparseGemm
 //
 
 /// Computes GEMM assuming one of the inputs has 2:4 structured sparsity.
 struct SparseGemmConfiguration {
 
-  GemmUniversalMode mode;
-  gemm::GemmCoord problem_size;
-  int batch_count;                /// number of sparse matrix products in batch
-
-  int64_t lda;                    /// leading dimension of A operand
-  int64_t ldb;                    /// leading dimension of B operand
-  int64_t ldc;                    /// leading dimension of C operand
-  int64_t ldd;                    /// leading dimension of D operand
-  int64_t lde;                    /// leading dimension of E operand (metadata matrix)
-
-  int64_t batch_stride_A;         // stride between matrices
-  int64_t batch_stride_B;         // stride between matrices
-  int64_t batch_stride_C;         // stride between matrices
-  int64_t batch_stride_D;         // stride between matrices
-  int64_t batch_stride_E;         // stride between matrices
+  GemmUniversalMode mode{GemmUniversalMode::kGemm};
+  gemm::GemmCoord problem_size{};
+  int batch_count{1};         /// number of sparse matrix products in batch
+  int64_t lda{0};             /// leading dimension of A operand
+  int64_t ldb{0};             /// leading dimension of B operand
+  int64_t ldc{0};             /// leading dimension of C operand
+  int64_t ldd{0};             /// leading dimension of D operand
+  int64_t lde{0};             /// leading dimension of E operand (metadata matrix)
+  int64_t batch_stride_A{0};  // stride between matrices
+  int64_t batch_stride_B{0};  // stride between matrices
+  int64_t batch_stride_C{0};  // stride between matrices
+  int64_t batch_stride_D{0};  // stride between matrices
+  int64_t batch_stride_E{0};  // stride between matrices
 };
 
 /// Arguments for sparse GEMMs
 struct SparseGemmArguments {
-
-  void const *A;                    /// pointer to A matrix
-  void const *B;                    /// pointer to B matrix
-  void const *C;                    /// pointer to C matrix
-  void *D;                          /// pointer to D matrix
-  void const *E;                    /// pointer to E matrix (metadata)
-
-  void const *alpha;                /// pointer to alpha scalar
-  void const *beta;                 /// pointer to beta scalar
-  ScalarPointerMode pointer_mode;   /// enumerant indicating whether alpha/beta pointers are host
+  void const *A{nullptr};          /// pointer to A matrix
+  void const *B{nullptr};          /// pointer to B matrix
+  void const *C{nullptr};          /// pointer to C matrix
+  void *D{nullptr};                  /// pointer to D matrix
+  void const *E{nullptr};          /// pointer to E matrix (metadata)
+  void const *alpha{nullptr};      /// pointer to alpha scalar
+  void const *beta{nullptr};       /// pointer to beta scalar
+  ScalarPointerMode pointer_mode{}; /// enumerant indicating whether alpha/beta pointers are host
                                     ///   or device pointers.
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for basic Rank K update operations
 //
 // OperationKind: (Syrk, Herk, Syr2k, Her2k)
 // RankKKind:      Universal
 //
 struct RankKConfiguration {
 
   /// SYRK problem size
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of C matrix
-  int64_t ldc;
+  int64_t ldc{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
   /// Batch Count
-  int batch_count;
+  int batch_count{1};
 };
 
 /// Arguments for (Syrk, Herk, Syr2k, Her2k)
 struct RankKArguments {
 
   /// Pointer to A matrix
-  void const *A;
+  void const *A{nullptr};
 
   /// Pointer to B matrix (used only for Syr2k and Her2k)
-  void const *B;
+  void const *B{nullptr};
 
   /// Pointer to C matrix
-  void const *C;
+  void const *C{nullptr};
 
   /// Pointer to D matrix
-  void *D;
+  void *D{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
+  ScalarPointerMode pointer_mode{};
 
-  int64_t batch_stride_A;
-  int64_t batch_stride_B;
-  int64_t batch_stride_C;
-  int64_t batch_stride_D;
+  int64_t batch_stride_A{0};
+  int64_t batch_stride_B{0};
+  int64_t batch_stride_C{0};
+  int64_t batch_stride_D{0};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for basic TRMM operations
 //
 // OperationKind: Trmm
 // TrmmKind:      Universal
 //
 struct TrmmConfiguration {
 
   /// TRMM problem size
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
   /// Batch Count
-  int batch_count;
+  int batch_count{1};
 };
 
 /// Arguments for TRMM
 struct TrmmArguments {
 
   /// Pointer to A matrix
-  void const *A;
+  void const *A{nullptr};
 
   /// Pointer to B matrix
-  void const *B;
+  void const *B{nullptr};
 
   /// Pointer to D matrix
-  void *D;
+  void *D{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
+  ScalarPointerMode pointer_mode{};
 
-  int64_t batch_stride_A;
-  int64_t batch_stride_B;
-  int64_t batch_stride_D;
+  int64_t batch_stride_A{0};
+  int64_t batch_stride_B{0};
+  int64_t batch_stride_D{0};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for basic SYMM/HEMM update operations
 //
 // OperationKind: (Symm, Hemm)
 // SymmKind:      Universal
 //
 struct SymmConfiguration {
 
   /// SYMM/HEMM problem size
-  gemm::GemmCoord problem_size;
+  gemm::GemmCoord problem_size{};
 
   /// Leading dimension of A matrix
-  int64_t lda;
+  int64_t lda{0};
 
   /// Leading dimension of B matrix
-  int64_t ldb;
+  int64_t ldb{0};
 
   /// Leading dimension of C matrix
-  int64_t ldc;
+  int64_t ldc{0};
 
   /// Leading dimension of D matrix
-  int64_t ldd;
+  int64_t ldd{0};
 
   /// Batch Count
-  int batch_count;
+  int batch_count{1};
 };
 
 /// Arguments for (Symm, Hemm)
 struct SymmArguments {
 
   /// Pointer to A matrix
-  void const *A;
+  void const *A{nullptr};
 
   /// Pointer to B matrix
-  void const *B;
+  void const *B{nullptr};
 
   /// Pointer to C matrix
-  void const *C;
+  void const *C{nullptr};
 
   /// Pointer to D matrix
-  void *D;
+  void *D{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
+  ScalarPointerMode pointer_mode{};
 
-  int64_t batch_stride_A;
-  int64_t batch_stride_B;
-  int64_t batch_stride_C;
-  int64_t batch_stride_D;
+  int64_t batch_stride_A{0};
+  int64_t batch_stride_B{0};
+  int64_t batch_stride_C{0};
+  int64_t batch_stride_D{0};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Two dimensional convolution
 //
@@ -645,51 +625,51 @@
 struct Conv2dConfiguration {
 
   conv::SplitKMode split_k_mode;
 
   /// Conv2d problem size
   //  contains strictly conv2d size (N,H,W,C,K,R,S,P,Q,padding,stride,dilation,mode)
   //  also includes (split_k_slices, groups)
-  conv::Conv2dProblemSize problem_size;
+  conv::Conv2dProblemSize problem_size{};
 
   // stride of operand A
-  std::vector<int64_t> stride_a;
+  std::vector<int64_t> stride_a{};
 
   // stride of operand B
-  std::vector<int64_t> stride_b;
+  std::vector<int64_t> stride_b{};
 
   // stride of operand C
-  std::vector<int64_t> stride_c;
+  std::vector<int64_t> stride_c{};
 };
 
 
 /// Three dimensional convolution
 //
 // OperationKind: Conv3d
 //
 struct Conv3dConfiguration {
 
-  conv::SplitKMode split_k_mode;
+  conv::SplitKMode split_k_mode{};
 
   /// Conv2d problem size
   //  contains strictly conv2d size (N,D,H,W,C,K,T,R,S,Z,P,Q,padding,stride,dilation,mode)
   //  also includes (split_k_slices, groups)
-  conv::Conv3dProblemSize problem_size;
+  conv::Conv3dProblemSize problem_size{};
 
   /// Layout object for activations tensor
-  layout::TensorNDHWC layout_activations;
+  layout::TensorNDHWC layout_activations{};
 
   /// Layout object for filters tensor
-  layout::TensorNDHWC layout_filters;
+  layout::TensorNDHWC layout_filters{};
 
   /// Layout object for source tensor
-  layout::TensorNDHWC layout_source;
+  layout::TensorNDHWC layout_source{};
 
   /// Layout object for output tensor
-  layout::TensorNDHWC layout_output;
+  layout::TensorNDHWC layout_output{};
 
   //
   // Methods
   //
 
   // Mapping functions (A,B,C -> activation,filter,output)
   layout::TensorNDHWC layout_a(library::ConvKind const &conv_kind) const {
@@ -723,88 +703,87 @@
 /// Arguments for CONV
 struct ConvArguments {
 
   /////////////////////////////////////////////////////////
   /// ImplicitGemm matrices A, B, C, D
   /////////////////////////////////////////////////////////
   /// pointer to implicit gemm matrix A
-  void const *A;
+  void const *A{nullptr};
 
   /// pointer to implicit gemm matrix B
-  void const *B;
+  void const *B{nullptr};
 
   /// pointer to reordered matrix B
-  void const *reordered_B;
+  void const *reordered_B{nullptr};
 
   /// pointer to implicit gemm matrix C
-  void const *C;
+  void const *C{nullptr};
 
   /// pointer to implicit gemm destination matrix D
-  void *D;
+  void *D{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
-
+  ScalarPointerMode pointer_mode{};
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Configuration for Reduction operations
 //
 // OperationKind: Reduction
 //
 struct ReductionConfiguration {
 
   /// Reduction problem size
-  MatrixCoord problem_size;
+  MatrixCoord problem_size{};
 
   /// Number of partitions to reduce
-  int partitions;
+  int partitions{0};
 
   /// Number of elements between each partition
-  int64_t partition_stride;
+  int64_t partition_stride{0};
 
   /// leading dimension of 'w'orkspace operand
-  int64_t ldw;
+  int64_t ldw{0};
 
   /// leading dimension of 's'ource operand
-  int64_t lds;
+  int64_t lds{0};
 
   /// leading dimension of 'd'estination operand
-  int64_t ldd;
+  int64_t ldd{0};
 };
 
 /// Arguments for Reduction
 struct ReductionArguments {
 
   /// Pointer to workspace matrix
-  void const *workspace;
+  void const *workspace{nullptr};
 
   /// Pointer to source matrix
-  void const *source;
+  void const *source{nullptr};
 
   /// Pointer to destination matrix
-  void *destination;
+  void *destination{nullptr};
 
   /// pointer to reference matrix
-  void *reference;
+  void *reference{nullptr};
 
   /// Host or device pointer to alpha scalar
-  void const *alpha;
+  void const *alpha{nullptr};
 
   /// Host or device pointer to beta scalar
-  void const *beta;
+  void const *beta{nullptr};
 
   /// Enumerant indicating whether alpha/beta point to host or device memory
-  ScalarPointerMode pointer_mode;
+  ScalarPointerMode pointer_mode{};
 };
 
 } // namespace library
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/manifest.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h`

 * *Files 2% similar despite different names*

```diff
@@ -105,15 +105,15 @@
     layout_C(layout_C),
     element_D(element_D),
     layout_D(layout_D)
   { }
 
   inline
   bool operator==(GemmFunctionalKey const &rhs) const {
-    return 
+    return
       (provider == rhs.provider) &&
       (gemm_kind == rhs.gemm_kind) &&
       (element_compute == rhs.element_compute) &&
       (element_scalar == rhs.element_scalar) &&
       (element_A == rhs.element_A) &&
       (layout_A == rhs.layout_A) &&
       (transform_A == rhs.transform_A) &&
@@ -161,24 +161,24 @@
 
 /// Hash function for GemmFunctionalKey
 struct GemmFunctionalKeyHasher {
   using IntHash = std::hash<int>;
 
   inline
   static size_t rotl(size_t key, int shl) {
-    return (key << shl) | (key >> (sizeof(key)*8 - shl));
+    return (key << shl) | (key >> (sizeof(key)*8u - static_cast<size_t>(shl)));
   }
 
   inline
   size_t operator()(GemmFunctionalKey const &key) const {
     IntHash hash;
 
     return
-      rotl(hash(int(key.provider)),        1) ^ 
-      rotl(hash(int(key.gemm_kind)),       2) ^ 
+      rotl(hash(int(key.provider)),        1) ^
+      rotl(hash(int(key.gemm_kind)),       2) ^
       rotl(hash(int(key.element_compute)), 3) ^
       rotl(hash(int(key.element_scalar)),  4) ^
       rotl(hash(int(key.element_A)),       5) ^
       rotl(hash(int(key.layout_A)),        6) ^
       rotl(hash(int(key.transform_A)),     7) ^
       rotl(hash(int(key.element_B)),       8) ^
       rotl(hash(int(key.layout_B)),        9) ^
@@ -203,15 +203,15 @@
   //
 
   GemmPreferenceKey(): compute_capability(), alignment() { }
 
   GemmPreferenceKey(int cc, int alignment): compute_capability(cc), alignment(alignment) { }
 
   bool operator<(GemmPreferenceKey const &rhs) const {
-    return (compute_capability < rhs.compute_capability) || 
+    return (compute_capability < rhs.compute_capability) ||
       ((compute_capability == rhs.compute_capability) && (alignment < rhs.alignment));
   }
 
   bool operator==(GemmPreferenceKey const &rhs) const {
     return compute_capability == rhs.compute_capability;
   }
 };
@@ -284,32 +284,32 @@
     layout_A(layout_A),
     element_B(element_B),
     layout_B(layout_B),
     element_C(element_C),
     layout_C(layout_C),
     element_accumulator(element_accumulator),
     element_compute(element_compute)
-  { } 
+  { }
 
-  inline 
+  inline
   bool operator==(ConvFunctionalKey const &rhs) const {
     return
       (provider == rhs.provider) &&
       (conv_kind == rhs.conv_kind) &&
       (element_A == rhs.element_A) &&
       (layout_A == rhs.layout_A) &&
       (element_B == rhs.element_B) &&
       (layout_B == rhs.layout_B) &&
       (element_C == rhs.element_C) &&
       (layout_C == rhs.layout_C) &&
       (element_accumulator == rhs.element_accumulator) &&
       (element_compute == rhs.element_compute);
   }
 
-  inline 
+  inline
   bool operator!=(ConvFunctionalKey const &rhs) const {
     return !(*this == rhs);
   }
 };
 /////////////////////////////////////////////////////////////////////////////////////////////////
 inline
 std::ostream& operator<< (std::ostream& out, const cutlass::library::ConvFunctionalKey& key) {
@@ -321,32 +321,32 @@
       << "element_B: " << to_string(key.element_B) << std::endl
       << "layout_B: " << to_string(key.layout_B) << std::endl
       << "element_C: " << to_string(key.element_C) << std::endl
       << "layout_C: " << to_string(key.layout_C) << std::endl
       << "element_accumulator: " << to_string(key.element_accumulator) << std::endl
       << "element_compute: " << to_string(key.element_compute) << std::endl
       << "}";
-  
+
   return out;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 struct ConvFunctionalKeyHasher {
   using IntHash = std::hash<int>;
 
   inline
   static size_t rotl(size_t key, int shl) {
-    return (key << shl) | (key >> (sizeof(key)*8 - shl));
+    return (key << shl) | (key >> (sizeof(key)*8u - static_cast<size_t>(shl)));
   }
 
   inline
   size_t operator()(ConvFunctionalKey const &key) const {
     IntHash hash;
 
-    return 
+    return
       rotl(hash(int(key.provider)), 1) ^
       rotl(hash(int(key.conv_kind)), 2) ^
       rotl(hash(int(key.element_A)), 3) ^
       rotl(hash(int(key.layout_A)), 4) ^
       rotl(hash(int(key.element_B)), 5) ^
       rotl(hash(int(key.layout_B)), 6) ^
       rotl(hash(int(key.element_C)), 7) ^
@@ -366,19 +366,19 @@
 
   //
   // Methods
   //
 
   ConvPreferenceKey(): compute_capability(), iterator_algorithm() { }
 
-  ConvPreferenceKey(int cc, IteratorAlgorithmID iterator_algorithm): 
+  ConvPreferenceKey(int cc, IteratorAlgorithmID iterator_algorithm):
     compute_capability(cc), iterator_algorithm(iterator_algorithm) { }
 
   bool operator<(ConvPreferenceKey const &rhs) const {
-    return (compute_capability < rhs.compute_capability) || 
+    return (compute_capability < rhs.compute_capability) ||
       ((compute_capability == rhs.compute_capability) && (iterator_algorithm < rhs.iterator_algorithm));
   }
 
   bool operator==(ConvPreferenceKey const &rhs) const {
     return (compute_capability == rhs.compute_capability) &&
           (iterator_algorithm == rhs.iterator_algorithm);
   }
@@ -429,48 +429,48 @@
     provider(provider),
     element_workspace(element_workspace),
     element_accumulator(element_accumulator),
     element_output(element_output),
     element_compute(element_compute),
     reduce_math_op(reduce_math_op),
     epilogue_math_op(epilogue_math_op)
-  { } 
+  { }
 
-  inline 
+  inline
   bool operator==(ReductionFunctionalKey const &rhs) const {
     return
       (provider == rhs.provider) &&
       (element_workspace == rhs.element_workspace) &&
       (element_accumulator == rhs.element_accumulator) &&
       (element_output == rhs.element_output) &&
       (element_compute == rhs.element_compute) &&
       (reduce_math_op == rhs.reduce_math_op) &&
       (epilogue_math_op == rhs.epilogue_math_op);
   }
 
-  inline 
+  inline
   bool operator!=(ReductionFunctionalKey const &rhs) const {
     return !(*this == rhs);
   }
 };
 
 
 struct ReductionFunctionalKeyHasher {
   using IntHash = std::hash<int>;
 
   inline
   static size_t rotl(size_t key, int shl) {
-    return (key << shl) | (key >> (sizeof(key)*8 - shl));
+    return (key << shl) | (key >> (sizeof(key)*8u - static_cast<size_t>(shl)));
   }
 
   inline
   size_t operator()(ReductionFunctionalKey const &key) const {
     IntHash hash;
 
-    return 
+    return
       rotl(hash(int(key.provider)), 1) ^
       rotl(hash(int(key.element_workspace)), 2) ^
       rotl(hash(int(key.element_accumulator)), 3) ^
       rotl(hash(int(key.element_output)), 4) ^
       rotl(hash(int(key.element_compute)), 5) ^
       rotl(hash(int(key.reduce_math_op)), 6) ^
       rotl(hash(int(key.epilogue_math_op)), 7);
@@ -501,27 +501,27 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Table of cutlass::library::Operation instances
 class OperationTable {
 public:
 
-  /// Map of all operations of type kGemm 
+  /// Map of all operations of type kGemm
   // provider (kCUTLASS)
   GemmOperationFunctionalMap gemm_operations;
 
-  /// Map of all operations of type kConv2d 
+  /// Map of all operations of type kConv2d
   // provider (kCUTLASS, kReferenceHost, kReferenceDevice)
   ConvOperationFunctionalMap conv2d_operations;
 
-  /// Map of all operations of type kConv3d 
+  /// Map of all operations of type kConv3d
   // provider (kCUTLASS, kReferenceHost, kReferenceDevice)
   ConvOperationFunctionalMap conv3d_operations;
 
-  /// Map of all operations of type kConv2d 
+  /// Map of all operations of type kConv2d
   // provider (kCUTLASS)
   ReductionOperationFunctionalMap reduction_operations;
 
 public:
 
   void append(Manifest const &manifest);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/singleton.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/types.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/types.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/include/cutlass/library/util.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/include/cutlass/library/util.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/conv2d_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/conv2d_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/conv3d_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/conv3d_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/gemm_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/gemm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -33,14 +33,16 @@
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/library/library.h"
 #include "library_internal.h"
+#include "cutlass/gemm/dispatch_policy.hpp"
+#include <unordered_map>
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::library {
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -59,15 +61,14 @@
   using LayoutD = typename Operator::LayoutD;
   // assuming all tensors use same type for StrideIndex
   using StrideIndex = typename Operator::LayoutA::Index;
   using ElementAccumulator = typename Operator::ElementAccumulator;
   using ElementCompute = typename Operator::EpilogueOutputOp::ElementCompute;
 
 private:
-
   GemmDescription description_;
 
 public:
 
   /// Constructor
   GemmOperation3xBase(char const *name = "unknown_gemm", GemmKind gemm_kind_ = GemmKind::kGemm) {
 
@@ -211,15 +212,16 @@
         return Status::kErrorInvalidProblem;
       }
     }
   };
 
   /// Constructs the arguments structure given the configuration and arguments
   static Status update_arguments_(
-      OperatorArguments &operator_args, GemmUniversalArguments const *arguments) {
+      OperatorArguments &operator_args,
+      GemmUniversalArguments const *arguments) {
     Status status = Status::kSuccess;
 
     status = UpdateFusionArgs<decltype(operator_args.epilogue.thread)>::update_(
       operator_args.epilogue.thread, *arguments);
     if (status != Status::kSuccess) {
       return status;
     }
@@ -257,24 +259,23 @@
         case RasterOrder::kAlongM:
           operator_args.scheduler.raster_order = Enum_t::AlongM;
           break;
         default:
           operator_args.scheduler.raster_order = Enum_t::Heuristic;
       }
     }
-    
+
     return status;
   }
 
 public:
 
   /// Returns success if the operation can proceed
   Status can_implement(
       void const *configuration_ptr, void const *arguments_ptr) const override {
-
     GemmUniversalConfiguration const *configuration =
       static_cast<GemmUniversalConfiguration const *>(configuration_ptr);
     GemmUniversalArguments const *arguments =
       static_cast<GemmUniversalArguments const *>(arguments_ptr);
 
     OperatorArguments args;
     auto status = update_arguments_(args, arguments);
@@ -284,15 +285,14 @@
 
     // can_implement rules may need access to problem shape
     args.problem_shape = cute::make_shape(
       configuration->problem_size.m(),
       configuration->problem_size.n(),
       configuration->problem_size.k(),
       configuration->batch_count);
-
     return Operator::can_implement(args);
   }
 
   /// Gets the host-side workspace
   uint64_t get_host_workspace_size(void const *configuration) const override {
     return sizeof(Operator);
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/handle.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/handle.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/library_internal.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/library_internal.h`

 * *Files 0% similar despite different names*

```diff
@@ -148,14 +148,15 @@
   static NumericTypeID const kId = NumericTypeID::kBF16;
 };
 
 template <> struct NumericTypeMap<cutlass::tfloat32_t> {
   static NumericTypeID const kId = NumericTypeID::kTF32;
 };
 
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename T> struct MathOperationMap {
   static MathOperationID const kId = MathOperationID::kInvalid;
 };
 
 template <> struct MathOperationMap<cutlass::arch::OpMultiplyAdd> {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/manifest.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/manifest.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/operation_table.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/operation_table.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/rank_2k_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/rank_2k_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/rank_k_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/rank_k_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/reduction_device.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reduction/reduction_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv2d.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv2d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv3d.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv3d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e4m3out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e4m3out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e5m2out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e4m3a_e5m2out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e4m3out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e4m3out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e5m2out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_e5m2a_e5m2out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp32out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp32out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_bf16out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_bf16out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp16out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp16out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp32out.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp8in_fp32out.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp_mixed_input.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp_mixed_input.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_fp_other.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_fp_other.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int4.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int4.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_canonical.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_canonical.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_32.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_64.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_int8_interleaved_64.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/singleton.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/singleton.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/symm_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/symm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/trmm_operation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/trmm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/library/src/util.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/library/src/util.cu`

 * *Files 1% similar despite different names*

```diff
@@ -418,14 +418,16 @@
   }
 
   return Status::kInvalid;
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
 static struct {
   char const *text;
   char const *pretty;
   NumericTypeID enumerant;
 }
 NumericTypeID_enumerants[] = {
   {"unknown", "<unknown>", NumericTypeID::kUnknown},
@@ -1198,15 +1200,15 @@
   ss << int_value;
   return ss.str();
 }
 
 /// Lexical cast TO a string FROM a byte array. Returns true if cast is successful or false if invalid.
 std::string lexical_cast(std::vector<uint8_t> &bytes, NumericTypeID type) {
 
-  int size_bytes = sizeof_bits(type) / 8;
+  size_t size_bytes = sizeof_bits(type) / 8;
 
   if (!size_bytes || size_bytes != bytes.size()) {
     return "<invalid>";
   }
 
   bytes.resize(size_bytes, 0);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv2d_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv2d_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv3d_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/conv3d_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cublas_helpers.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cublas_helpers.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cudnn_helpers.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cudnn_helpers.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/cutlass_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/cutlass_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/debug.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/gpu_timer.h`

 * *Files 16% similar despite different names*

```diff
@@ -25,32 +25,48 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief
+   \brief Defines a math function
 */
 
 #pragma once
 
-#include <iostream>
+#include <cuda_runtime.h>
+#include "cutlass/cutlass.h"
 
-//#define report(x) { std::cout << "\033[31m" << __FILE__ << ":" << __LINE__ << "  " << x << "\033[0m" << std::endl; }
-//#define report(x) {}
+namespace cutlass {
+namespace profiler {
 
-// Enable/Disable Profiler debug prints
-//#define DEBUG_PROFILER 
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-//RED    31m   // profiler prints debug messages in red
-//YELLOW 33m   // ir prints debug messages in yellow
-
-#ifndef DEBUG_PROFILER
-#define debugprof(...)
-#else
-#define debugprof(...) do { \
-          printf("\033[33m[DEBUG PROF]  %s:%d | ", __FILE__, __LINE__); \
-          printf(__VA_ARGS__); \
-          printf("\033[0m\n"); \
-      } while (0)
-#endif 
+struct GpuTimer {
+
+  cudaEvent_t events[2];
+
+  //
+  // Methods
+  //
+  
+  GpuTimer();
+  ~GpuTimer();
+
+  /// Records a start event in the stream
+  void start(cudaStream_t stream = nullptr);
+
+  /// Records a stop event in the stream
+  void stop(cudaStream_t stream = nullptr);
+
+  /// Records a stop event in the stream and synchronizes on the stream
+  void stop_and_wait(cudaStream_t stream = nullptr);
+
+  /// Returns the duration in milliseconds
+  double duration(int iterations = 1) const;
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace profiler
+} // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_allocation.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_allocation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_context.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/device_context.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/enumerated_types.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/enumerated_types.h`

 * *Files 1% similar despite different names*

```diff
@@ -154,16 +154,16 @@
 using DispositionMap = std::map<library::Provider, Disposition>;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 // Print vector for the report
 template <typename T>
 std::ostream& operator<< (std::ostream& out, const std::vector<T>& v) {
-  for(int i = 0; i < v.size(); ++i) {
-    out << to_string(v[i], true) << (i+1 != v.size() ? "," : "");
+  for (size_t i = 0; i < v.size(); ++i) {
+    out << to_string(v[i], true) << (i + 1u != v.size() ? "," : "");
   }
   return out;
 }
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace profiler
 } // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/gemm_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/gemm_operation_profiler.h`

 * *Files 4% similar despite different names*

```diff
@@ -25,15 +25,15 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief Defines a math function
+   \brief Gemm Profiler
 */
 
 #pragma once
 
 #include <vector>
 #include <string>
 #include <memory>
@@ -63,53 +63,41 @@
 /// Abstract base class for each math function
 class GemmOperationProfiler : public OperationProfiler {
 public:
 
   /// Problem structure obtained from problem space
   struct GemmProblem {
 
-    cutlass::library::GemmUniversalMode mode;
+    cutlass::library::GemmUniversalMode mode{library::GemmUniversalMode::kGemm};
 
-    int64_t m;
-    int64_t n;
-    int64_t k;
-    
-    int64_t lda;
-    int64_t ldb;
-    int64_t ldc;
+    int64_t m{16};
+    int64_t n{16};
+    int64_t k{16};
+
+    int64_t lda{0};
+    int64_t ldb{0};
+    int64_t ldc{0};
     std::vector<uint8_t> alpha;
     std::vector<uint8_t> beta;
 
-    cutlass::library::SplitKMode split_k_mode;
-    int split_k_slices;
-    int batch_count;
+    cutlass::library::SplitKMode split_k_mode{library::SplitKMode::kNone};
+    int split_k_slices{1};
+    int batch_count{1};
 
-    cutlass::library::RasterOrder raster_order;
+    cutlass::library::RasterOrder raster_order{cutlass::library::RasterOrder::kHeuristic};
     // gemm with parallel interleaved reduction
     // gemm epilogue (alpha, beta) = (1.0, 0.0)
     // reduction epilogue (alpha, beta) = (GemmProblem::alpha, GemmProblem::beta)
     std::vector<uint8_t> alpha_one;
     std::vector<uint8_t> beta_zero;
 
     //
     // Methods
     //
 
-    GemmProblem():
-      mode(library::GemmUniversalMode::kGemm),
-      m(16), 
-      n(16), 
-      k(16),
-      lda(0), 
-      ldb(0), 
-      ldc(0), 
-      split_k_slices(1), 
-      batch_count(1),
-      raster_order(cutlass::library::RasterOrder::kHeuristic){ }
-
     /// Parses the problem
     Status parse(
       library::GemmDescription const &operation_desc,
       ProblemSpace const &problem_space,
       ProblemSpace::Problem const &problem);
 
     /// Total number of bytes loaded
@@ -124,23 +112,23 @@
       library::GemmDescription const &operation_desc,
       ProblemSpace const &problem_space);
   };
 
   /// Workspace used
   struct GemmWorkspace {
 
-    DeviceAllocation *A;
-    DeviceAllocation *B;
-    DeviceAllocation *C;
-    DeviceAllocation *Computed;
-    DeviceAllocation *Reference;
+    DeviceAllocation *A{nullptr};
+    DeviceAllocation *B{nullptr};
+    DeviceAllocation *C{nullptr};
+    DeviceAllocation *Computed{nullptr};
+    DeviceAllocation *Reference{nullptr};
 
     /// Number of copies of the problem workspace which are visited sequentially during
     /// profiling to avoid camping in the last level cache.
-    int problem_count;
+    int problem_count{1};
 
     library::GemmUniversalConfiguration configuration;
     library::GemmUniversalArguments arguments;
 
     /// Buffer used for the operation's host workspace
     std::vector<uint8_t> host_workspace;
 
@@ -149,21 +137,14 @@
 
     /// Library configuration and arguments for reduction operator
     library::ReductionConfiguration reduction_configuration;
     library::ReductionArguments reduction_arguments;
 
     /// Buffer used for the cutlass reduction operations' host workspace
     std::vector<uint8_t> reduction_host_workspace;
-
-    //
-    // Methods
-    //
-
-    GemmWorkspace():
-      A(nullptr), B(nullptr), C(nullptr), Computed(nullptr), Reference(nullptr), problem_count(1) { }
   };
 
 protected:
 
   //
   // Data members
   //
@@ -253,15 +234,17 @@
   /// Verifies CUTLASS against host and device references
   bool verify_with_reference_(
     Options const &options,
     PerformanceReport &report,
     DeviceContext &device_context,
     library::Operation const *operation,
     ProblemSpace const &problem_space,
-    ProblemSpace::Problem const &problem);
+    ProblemSpace::Problem const &problem,
+    cutlass::library::NumericTypeID element_A,
+    cutlass::library::NumericTypeID element_B);
 
   /// Method to profile a CUTLASS Operation
   Status profile_cutlass_(
     double &runtime,
     Options const &options,
     library::Operation const *operation,
     void *arguments,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/gpu_timer.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,49 +24,44 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/* \file
-   \brief Defines a math function
-*/
 
 #pragma once
 
 #include <cuda_runtime.h>
-#include "cutlass/cutlass.h"
 
-namespace cutlass {
-namespace profiler {
+struct GPU_Clock
+{
+  GPU_Clock() {
+    cudaEventCreate(&start_);
+    cudaEventCreate(&stop_);
+    cudaEventRecord(start_);
+  }
+
+  ~GPU_Clock() {
+    cudaEventDestroy(start_);
+    cudaEventDestroy(stop_);
+  }
+
+  void start() {
+    cudaEventRecord(start_);
+  }
+
+  float milliseconds() {
+    cudaEventRecord(stop_);
+    cudaEventSynchronize(stop_);
+    float time;
+    cudaEventElapsedTime(&time, start_, stop_);
+    return time;
+  }
+
+  float seconds() {
+    return milliseconds() * float(1e-3);
+  }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-struct GpuTimer {
-
-  cudaEvent_t events[2];
-
-  //
-  // Methods
-  //
-  
-  GpuTimer();
-  ~GpuTimer();
-
-  /// Records a start event in the stream
-  void start(cudaStream_t stream = nullptr);
-
-  /// Records a stop event in the stream
-  void stop(cudaStream_t stream = nullptr);
-
-  /// Records a stop event in the stream and synchronizes on the stream
-  void stop_and_wait(cudaStream_t stream = nullptr);
-
-  /// Returns the duration in milliseconds
-  double duration(int iterations = 1) const;
+ private:
+  cudaEvent_t start_, stop_;
 };
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-} // namespace profiler
-} // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/options.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/options.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_report.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_report.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_result.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/performance_result.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/problem_space.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/problem_space.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_2k_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_2k_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_k_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/rank_k_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/reduction_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/reduction_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/sparse_gemm_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/sparse_gemm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/symm_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/symm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/include/cutlass/profiler/trmm_operation_profiler.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/include/cutlass/profiler/trmm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cublas_helpers.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu`

 * *Files 7% similar despite different names*

```diff
@@ -38,28 +38,28 @@
 // Profiler includes
 #include "cutlass/profiler/cutlass_profiler.h"
 #include "cutlass/profiler/gemm_operation_profiler.h"
 #include "cutlass/profiler/rank_k_operation_profiler.h"
 #include "cutlass/profiler/rank_2k_operation_profiler.h"
 #include "cutlass/profiler/trmm_operation_profiler.h"
 #include "cutlass/profiler/symm_operation_profiler.h"
-#include "cutlass/profiler/conv2d_operation_profiler.h"          
-#include "cutlass/profiler/conv3d_operation_profiler.h"          
+#include "cutlass/profiler/conv2d_operation_profiler.h"
+#include "cutlass/profiler/conv3d_operation_profiler.h"
 #include "cutlass/profiler/sparse_gemm_operation_profiler.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace profiler {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 CutlassProfiler::CutlassProfiler(
   Options const &options
-): 
+):
   options_(options) {
 
   operation_profilers_.emplace_back(new GemmOperationProfiler(options));
 
   operation_profilers_.emplace_back(new SparseGemmOperationProfiler(options));
 
   operation_profilers_.emplace_back(new Conv2dOperationProfiler(options));
@@ -141,15 +141,14 @@
 }
 
 /// Profiles all operations
 int CutlassProfiler::profile_() {
 
   int result = 0;
   DeviceContext device_context;
-
   // For all profilers
   for (auto & profiler : operation_profilers_) {
 
     if (options_.operation_kind == library::OperationKind::kInvalid ||
       options_.operation_kind == profiler->kind()) {
 
       result = profiler->profile_all(options_, library::Singleton::get().manifest, device_context);
@@ -189,16 +188,16 @@
   }
 
   out << "\n\nFor details about a particular function, specify the function name with --help.\n\nExample:\n\n"
     << "  $ cutlass_profiler --operation=Gemm --help\n\n"
     << "  $ cutlass_profiler --operation=RankK --help\n\n"
     << "  $ cutlass_profiler --operation=Trmm --help\n\n"
     << "  $ cutlass_profiler --operation=Symm --help\n\n"
-    << "  $ cutlass_profiler --operation=Conv3d --help\n\n"         
-    << "  $ cutlass_profiler --operation=Conv2d --help\n\n"         
+    << "  $ cutlass_profiler --operation=Conv3d --help\n\n"
+    << "  $ cutlass_profiler --operation=Conv2d --help\n\n"
     << "  $ cutlass_profiler --operation=SparseGemm --help\n\n"
   ;
 }
 
 /// Prints usage
 void CutlassProfiler::print_options_(std::ostream &out) {
   options_.print_options(out);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/device_allocation.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/device_allocation.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/device_context.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/device_context.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/enumerated_types.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu`

 * *Files 1% similar despite different names*

```diff
@@ -32,14 +32,15 @@
    \brief Execution environment
 */
 
 #include <iostream>
 #include <stdexcept>
 #include <iomanip>
 #include <ios>
+#include <vector>
 
 #include "cutlass/core_io.h"
 
 #include "cutlass/profiler/cublas_helpers.h"
 #include "cutlass/profiler/gemm_operation_profiler.h"
 #include "cutlass/profiler/gpu_timer.h"
 #include "cutlass/library/singleton.h"
@@ -163,15 +164,15 @@
     this->n = 1024;
   }
 
   if (!arg_as_int(this->k, "k", problem_space, problem)) {
     // default value
     this->k = 1024;
   }
-  
+
   if (!arg_as_SplitKModeID(this->split_k_mode, "split_k_mode", problem_space, problem)) {
     // default value
     this->split_k_mode = library::SplitKMode::kSerial;
   }
 
   this->mode = library::GemmUniversalMode::kGemm;
   if (this->split_k_mode == library::SplitKMode::kParallel) {
@@ -417,14 +418,15 @@
 
 }
 
 /// Initialize reduction problem dimensions and library::Operation
 bool GemmOperationProfiler::initialize_reduction_configuration_(
   library::Operation const *operation,
   ProblemSpace::Problem const &problem) {
+
   library::GemmDescription const &gemm_desc =
     static_cast<library::GemmDescription const&>(operation->description());
 
   if (!cast_from_double(problem_.alpha_one, gemm_desc.element_epilogue, 1)) {
     return false;
   }
 
@@ -573,15 +575,14 @@
   // Initialize the CUTLASS operation
   //
   Status status = Status::kSuccess;
 
   if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
     if (options.execution_mode != ExecutionMode::kDryRun) {
-
       uint64_t workspace_size = underlying_operation->get_host_workspace_size(&gemm_workspace_.configuration);
       gemm_workspace_.host_workspace.resize(workspace_size, 0);
 
       workspace_size = underlying_operation->get_device_workspace_size(&gemm_workspace_.configuration,
                                                             &gemm_workspace_.arguments);
       gemm_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
 
@@ -616,15 +617,14 @@
     results_.back().op_kind = library::OperationKind::kGemm;
     results_.back().disposition = Disposition::kNotRun;
 
     for (auto provider : verification_providers_) {
       results_.back().verification_map[provider] = Disposition::kNotRun;
     }
   }
-
   return status;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Verifies CUTLASS against references
 bool GemmOperationProfiler::verify_cutlass(
@@ -742,15 +742,21 @@
       else {
         // set verification map for cublas to not supported
         results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotSupported;
       }
     }
 #endif // #if CUTLASS_ENABLE_CUBLAS
 
-    bool verification_status = verify_with_reference_(options, report, device_context, operation, problem_space, problem);
+    library::GemmDescription const &gemm_desc =
+      static_cast<library::GemmDescription const &>(operation->description());
+
+
+    cutlass::library::NumericTypeID element_A = gemm_desc.A.element;
+    cutlass::library::NumericTypeID element_B = gemm_desc.B.element;
+    bool verification_status = verify_with_reference_(options, report, device_context, operation, problem_space, problem, element_A, element_B);
 
     // Update disposition to worst case verification outcome among all
     // verification providers which are supported
     bool is_any_verification_run_passed = false;
     for (auto &m : results_.back().verification_map) {
       if (m.second == Disposition::kFailed || m.second == Disposition::kIncorrect) {
         results_.back().disposition = m.second;
@@ -790,15 +796,14 @@
   Options const &options,
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
-
 #if CUTLASS_ENABLE_CUBLAS
 
   library::GemmDescription const &gemm_desc =
     static_cast<library::GemmDescription const &>(operation->description());
 
   //
   // Construct cuBLAS operators
@@ -909,16 +914,18 @@
 /// Verifies CUTLASS against host and device references
 bool GemmOperationProfiler::verify_with_reference_(
   Options const &options,
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
-
+  ProblemSpace::Problem const &problem, 
+  cutlass::library::NumericTypeID element_A, 
+  cutlass::library::NumericTypeID element_B) 
+{
   library::GemmDescription const &gemm_desc =
     static_cast<library::GemmDescription const &>(operation->description());
 
   //
   // Initialize state
   //
 
@@ -973,21 +980,21 @@
       gemm_workspace_.configuration.problem_size.n(),
       gemm_workspace_.configuration.problem_size.k(),
       gemm_desc.tile_description.math_instruction.element_accumulator,
       gemm_desc.element_epilogue,
 
       problem_.alpha.data(),
 
-      gemm_desc.A.element,
+      element_A,
       gemm_desc.A.layout,
       gemm_desc.transform_A,
       ptr_A,
       int(gemm_workspace_.configuration.lda),
 
-      gemm_desc.B.element,
+      element_B,
       gemm_desc.B.layout,
       gemm_desc.transform_B,
       ptr_B,
       int(gemm_workspace_.configuration.ldb),
 
       problem_.beta.data(),
 
@@ -1007,15 +1014,14 @@
       gemm_workspace_.C->batch_stride(),
       gemm_workspace_.Reference->batch_stride());
 
     if (status != Status::kSuccess) {
       results_.back().verification_map[provider] = Disposition::kNotRun;
       continue;
     }
-
     results_.back().status = status;
 
     if (provider == library::Provider::kReferenceHost) {
       gemm_workspace_.Reference->copy_from_host(ptr_D);
     }
 
     //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/gpu_timer.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/main.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/performance_result.cu`

 * *Files 16% similar despite different names*

```diff
@@ -25,29 +25,37 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief 
+   \brief
 */
 
-#include <iostream>
+#pragma once
 
-#include "cutlass/profiler/options.h"
+#include <vector>
 
-#include "cutlass/profiler/cutlass_profiler.h"
+#include "cutlass/cutlass.h"
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+// CUTLASS Profiler includes
+#include "cutlass/profiler/enumerated_types.h"
+#include "cutlass/profiler/performance_result.h"
 
-int main(int argc, char const *arg[]) {
+// CUTLASS Library includes
+#include "cutlass/library/library.h"
+#include "cutlass/library/util.h"
 
-  cutlass::CommandLine cmdline(argc, arg);
-  cutlass::profiler::Options options(cmdline);
+namespace cutlass {
+namespace profiler {
 
-  cutlass::profiler::CutlassProfiler profiler(options);
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  return profiler();
-}
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace profiler
+} // namespace cutlass
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu`

 * *Files 18% similar despite different names*

```diff
@@ -25,683 +25,694 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief Defines a math function
+   \brief Execution environment
+
+  
 */
 
-#include <algorithm>
+#include <iostream>
 #include <stdexcept>
 #include <iomanip>
-#include <cstring>
-#include <fstream>
-#include <sstream>
-
-#ifdef __unix__
-#include <unistd.h>
-#elif defined(_WIN32) || defined(WIN32)
-#include <windows.h>
-#else
-// sleep not supported
-#endif
+#include <ios>
+
+#include "cutlass/core_io.h"
 
-#include "cutlass/profiler/options.h"
-#include "cutlass/profiler/operation_profiler.h"
+#include "cutlass/profiler/cublas_helpers.h"
+#include "cutlass/profiler/rank_k_operation_profiler.h"
 #include "cutlass/profiler/gpu_timer.h"
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace profiler {
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
 
-OperationProfiler::OperationProfiler(): kind_(library::OperationKind::kInvalid) { }
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Ctor
-OperationProfiler::OperationProfiler(
-  Options const &options,
-  library::OperationKind kind,
-  ArgumentDescriptionVector const &arguments,
-  ProviderVector const & verification_providers
-): 
-  kind_(kind), arguments_(arguments) {
-
-  ArgumentDescriptionVector tile_description_arguments{
-    {ArgumentTypeID::kEnumerated, {"op_class", "opcode-class"}, "Class of math instruction (simt, tensorop, wmmatensorop, wmma)"},
-    {ArgumentTypeID::kEnumerated, {"accum", "accumulator-type"}, "Math instruction accumulator data type"},
-    {ArgumentTypeID::kInteger, {"cta_m", "threadblock-shape::m"}, "Threadblock shape in the M dimension"},
-    {ArgumentTypeID::kInteger, {"cta_n", "threadblock-shape::n"}, "Threadblock shape in the N dimension"},
-    {ArgumentTypeID::kInteger, {"cta_k", "threadblock-shape::k"}, "Threadblock shape in the K dimension"},
-    {ArgumentTypeID::kInteger, {"cluster_m", "cluster-shape::m"}, "Cluster shape in the M dimension"},
-    {ArgumentTypeID::kInteger, {"cluster_n", "cluster-shape::n"}, "Cluster shape in the N dimension"},
-    {ArgumentTypeID::kInteger, {"cluster_k", "cluster-shape::k"}, "Cluster shape in the K dimension"},
-    {ArgumentTypeID::kInteger, {"stages", "threadblock-stages"}, "Number of stages of threadblock-scoped matrix multiply"},
-    {ArgumentTypeID::kInteger, {"warps_m", "warp-count::m"}, "Number of warps within threadblock along the M dimension"},
-    {ArgumentTypeID::kInteger, {"warps_n", "warp-count::n"}, "Number of warps within threadblock along the N dimension"},
-    {ArgumentTypeID::kInteger, {"warps_k", "warp-count::k"}, "Number of warps within threadblock along the K dimension"},
-    {ArgumentTypeID::kInteger, {"inst_m", "instruction-shape::m"}, "Math instruction shape in the M dimension"},
-    {ArgumentTypeID::kInteger, {"inst_n", "instruction-shape::n"}, "Math instruction shape in the N dimension"},
-    {ArgumentTypeID::kInteger, {"inst_k", "instruction-shape::k"}, "Math instruction shape in the K dimension"},
-    {ArgumentTypeID::kInteger, {"min_cc", "minimum-compute-capability"}, "Minimum device compute capability"},
-    {ArgumentTypeID::kInteger, {"max_cc", "maximum-compute-capability"}, "Maximum device compute capability"}
-  };
-
-  arguments_.insert(arguments_.end(), tile_description_arguments.begin(), tile_description_arguments.end());
-
-  for (auto provider : verification_providers) {
-    if (std::find(
-      options.verification.providers.begin(), 
-      options.verification.providers.end(), 
-      provider) != options.verification.providers.end()) {
-
-      verification_providers_.push_back(provider);
-    }
-  }
-
+RankKOperationProfiler::RankKOperationProfiler(Options const &options): 
+  OperationProfiler(
+    options,
+    library::OperationKind::kRankK,
+    {
+      {ArgumentTypeID::kEnumerated, {"rank_k_kind"}, "Variant of RankK (universal)"},
+      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the RankK problem space"},
+      {ArgumentTypeID::kInteger, {"k", "problem-size::k"}, "K dimension of the RankK problem space"},
+      {ArgumentTypeID::kTensor, {"A"}, "Tensor storing the A operand"},
+      {ArgumentTypeID::kTensor, {"C"}, "Tensor storing the C operand"},
+      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for RankK kernel (lower or upper)"},
+      {ArgumentTypeID::kEnumerated, {"blas_mode"}, "Blas Mode for RankK kernel (symmetric or hermitian)"},
+      {ArgumentTypeID::kScalar, {"alpha", "epilogue::alpha"}, "Epilogue scalar alpha"},
+      {ArgumentTypeID::kScalar, {"beta", "epilogue::beta"}, "Epilogue scalar beta"},
+      {ArgumentTypeID::kInteger, {"split_k_slices", "split-k-slices"}, "Number of partitions of K dimension"},
+      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of RankK computed in one batch"},
+    },
+    { library::Provider::kCUBLAS}
+  ) {
+  description_ = "      Rank-k Update. D = alpha * A*A^T + beta * C (symmetric) or D = alpha * A*A^H + beta * C (hermitian)";
 }
 
 /// Destructor
-OperationProfiler::~OperationProfiler() {}
+RankKOperationProfiler::~RankKOperationProfiler() {
 
-/// Gets the schema description
-std::string const & OperationProfiler::description() const {
-  return description_;
 }
 
 /// Prints usage statement for the math function
-void OperationProfiler::print_usage(std::ostream &out) const {
-  for (auto const & desc : arguments_) {
+void RankKOperationProfiler::print_usage(std::ostream &out) const {
+  out << "RankK" << "\n\n";
 
-    size_t const kAliasStart = 10;
+  OperationProfiler::print_usage(out);
+}
+
+/// Prints examples
+void RankKOperationProfiler::print_examples(std::ostream &out) const {
 
-    size_t columns = 0;
+  out << "\nExamples:\n\n"
+    << "Profile a particular problem size Syrk kernel:\n"
+    << "  $ cutlass_profiler --operation=rank_k --blas_mode=symmetric --n=1024 --k=128\n\n"
     
-    std::string type_str = to_string(desc.type);
-    columns += type_str.size();
+    << "Profile a particular problem size Herk kernel:\n"
+    << "  $ cutlass_profiler --operation=rank_k --blas_mode=hermitian --n=1024 --k=128\n\n"
 
-    out << "  [" << type_str << "]";
+    << "Schmoo over problem size and beta:\n"
+    << "  $ cutlass_profiler --operation=rank_k --n=1024:4096:256 --k=128:8192:128 --beta=0,1,2.5\n\n"
 
-    if (columns < kAliasStart) {
-      out << std::string(kAliasStart - columns, ' ');  
-    }
+    << "Schmoo over accumulator types:\n"
+    << "  $ cutlass_profiler --operation=rank_k --accumulator-type=f16,f32\n\n"
 
-    columns = 0;
+    << "Schmoo over fill modees:\n"
+    << "  $ cutlass_profiler --operation=rank_k --fill_mode=lower/upper\n\n"
 
-    int j = 0;
-    for (auto const & alias : desc.aliases) {
-      columns += alias.size() + (j ? 1 : 0) + 2;
+    << "Run when A is f16 with column-major or A is any datatype with row-major (For column major, use column, col, or n. For row major use, row or t):\n"
+    << "  $ cutlass_profiler --operation=rank_k --A=f16:column or --A=*:row\n\n"
 
-      out << (j++ ? "," : "") << "--" << alias;
-    }
+    << "Using various input value distribution:\n"
+    << "  $ cutlass_profiler --operation=rank_k --dist=uniform,min:0,max:3\n"
+    << "  $ cutlass_profiler --operation=rank_k --dist=gaussian,mean:0,stddev:3\n"
+    << "  $ cutlass_profiler --operation=rank_k --dist=sequential,start:0,delta:1\n\n"
+
+    << "Run a kernel with cta tile size of 256x128x32 and save workspace if results are incorrect (note that --cta-tile::k=32 is default cta-tile size):\n"
+    << " $ cutlass_profiler --operation=rank_k --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
+    
+    << "Test your changes to rank_k kernels with a quick functional test and save results in functional-test.csv:\n"
+    << " $ cutlass_profiler  --operation=rank_k \\ \n"
+    << "   --n=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
+    << "   --k=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
+    << "   --beta=0,1,2 --profiling-iterations=1 \\ \n"
+    << "   --providers=cutlass --output=functional-test.csv\n\n";
+}
 
-    size_t const kTotalColumns = 50;
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-    if (columns < kTotalColumns) {
-      out << std::string(kTotalColumns - columns, ' ');
-    }
+#if 0
+// used this for debugging
+static std::string byte_string(std::vector<uint8_t> const &bytes) {
+  std::stringstream ss;
+
+  ss << "0x";
 
-    out << desc.description << "\n";
+  for (size_t idx = bytes.size(); idx > 0; --idx) {
+    ss << std::hex << std::setw(2) << std::setfill('0') << uint32_t(bytes.at(idx - 1));
   }
-}
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+  return ss.str();
+}
+#endif
 
-/// Returns true if the current operation description satisfies the problem space
-bool OperationProfiler::satisfies(
-  library::OperationDescription const &op_desc,
+Status RankKOperationProfiler::RankKProblem::parse(
+  library::RankKDescription const &operation_desc,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
-
-  library::OpcodeClassID opcode_class;
-  if (arg_as_OpcodeClassID(opcode_class, "op_class", problem_space, problem)) {
-    if (opcode_class != op_desc.tile_description.math_instruction.opcode_class) {
-      return false;
-    }
+  
+  if (!arg_as_int(this->n, "n", problem_space, problem)) {
+    // default value
+    this->n = 1024;
   }
   
-  int64_t int_value;
-
-  if (arg_as_int(int_value, "inst_m", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.m()) != int_value) {
-      return false;
-    }
+  if (!arg_as_int(this->k, "k", problem_space, problem)) {
+    // default value
+    this->k = 1024;
   }
-
-  if (arg_as_int(int_value, "inst_n", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.n()) != int_value) {
-      return false;
-    }
+  
+  if (!arg_as_int(this->split_k_slices, "split_k_slices", problem_space, problem)) {
+    // default value
+    this->split_k_slices = 1;
   }
-
-  if (arg_as_int(int_value, "inst_k", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.k()) != int_value) {
-      return false;
-    }
+  
+  if (!arg_as_int(this->batch_count, "batch_count", problem_space, problem)) {
+    // default value
+    this->batch_count = 1;
   }
 
-  if (arg_as_int(int_value, "cta_m", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.threadblock_shape.m()) != int_value) {
-      return false;
-    }
+  if (this->split_k_slices > 1 && this->batch_count > 1) {
+    // At least one of these must be one
+    return Status::kErrorInvalidProblem;
   }
 
-  if (arg_as_int(int_value, "cta_n", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.threadblock_shape.n()) != int_value) {
-      return false;
-    }
+  if (!tensor_description_satisfies(operation_desc.A, "A", problem_space, problem)) {
+    return Status::kErrorInvalidProblem;
   }
 
-  if (arg_as_int(int_value, "cta_k", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.threadblock_shape.k()) != int_value) {
-      return false;
-    }
+  if (!tensor_description_satisfies(operation_desc.C, "C", problem_space, problem)) {
+    return Status::kErrorInvalidProblem;
   }
 
-  if (arg_as_int(int_value, "cluster_m", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.cluster_shape.m()) != int_value) {
-      return false;
-    }
-  }
+  if (!arg_as_scalar(
+    this->alpha, 
+    operation_desc.element_epilogue, 
+    "alpha", 
+    problem_space, 
+    problem)) {
 
-  if (arg_as_int(int_value, "cluster_n", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.cluster_shape.n()) != int_value) {
-      return false;
+    if (!cast_from_double(this->alpha, operation_desc.element_epilogue, 1)) {
+      return Status::kErrorInternal;
     }
   }
-
-  if (arg_as_int(int_value, "cluster_k", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.cluster_shape.k()) != int_value) {
-      return false;
+  
+  if (!arg_as_scalar(
+    this->beta, 
+    operation_desc.element_epilogue, 
+    "beta", 
+    problem_space, 
+    problem)) {
+    
+    if (!cast_from_double(this->beta, operation_desc.element_epilogue, 0)) {
+      return Status::kErrorInternal;
     }
   }
+  
+  this->lda = DeviceAllocation::get_packed_layout(
+    operation_desc.A.layout, {int(this->n), int(this->k)}).front();
 
-  if (arg_as_int(int_value, "stages", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.threadblock_stages) != int_value) {
-      return false;
-    }
-  }
+  this->ldc = DeviceAllocation::get_packed_layout(
+    operation_desc.C.layout, {int(this->n), int(this->n)}).front();
 
-  if (arg_as_int(int_value, "warps_m", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.warp_count.m()) != int_value) {
-      return false;
-    }
-  }
+  return Status::kSuccess;
+}
 
-  if (arg_as_int(int_value, "warps_n", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.warp_count.n()) != int_value) {
-      return false;
-    }
-  }
+/// Total number of bytes loaded
+int64_t RankKOperationProfiler::RankKProblem::bytes(library::RankKDescription const &operation_desc) const {
+  // Input bytes read and Output bytes written for the gemm problem
+  int64_t bytes =
+    int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * k +
+    int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * k +
+    // Half matrix including the diagonal will have (N*(N+1))/2 elements
+    int64_t(library::sizeof_bits(operation_desc.C.element) * n / 8) * (n+1) / 2;
 
-  if (arg_as_int(int_value, "warps_k", problem_space, problem)) {
-    if (int64_t(op_desc.tile_description.warp_count.k()) != int_value) {
-      return false;
-    }
-  }
+  // Set is_beta_zero true if beta is zero
+  bool is_beta_zero = std::all_of(beta.begin(), beta.end(), [](uint8_t i) { return i==0; });
 
-  library::NumericTypeID numeric_type;
-  if (arg_as_NumericTypeID(numeric_type, "accum", problem_space, problem)) {
-    if (numeric_type != op_desc.tile_description.math_instruction.element_accumulator) {
-      return false;
-    }
+  // Output bytes read for the gemm problem for non-zero beta values
+  if (!is_beta_zero) {
+    bytes += int64_t(library::sizeof_bits(operation_desc.C.element) * n / 8) * (n+1) / 2;
   }
 
-  return true;
+  bytes *= batch_count;
+
+  return bytes;
 }
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/// Total number of flops computed
+int64_t RankKOperationProfiler::RankKProblem::flops(library::RankKDescription const &operation_desc) const {
 
-/// Entry point to profile all operations in the manifest
-int OperationProfiler::profile_all(
-  Options const &options, 
-  library::Manifest const &manifest, 
-  DeviceContext &device_context) {
-  
-  ProblemSpace problem_space(arguments_, options.cmdline);
-
-  // 1. Construct performance report
-  PerformanceReport report(options, problem_space.argument_names(), kind_);
-
-  // 2. For each problem in problem space
-  ProblemSpace::Iterator problem_it = problem_space.begin();
-  ProblemSpace::Iterator problem_end = problem_space.end();
-
-  bool continue_profiling = true;
-  int retval = 0;
-
-  // For each problem in problem space
-  for (; continue_profiling && problem_it != problem_end; ++problem_it) {
-    ProblemSpace::Problem problem = problem_it.at();
-    report.next_problem();
-
-    // For each operation in manifest
-    int matched_operation_count = 0;
-    for (auto const& operation_ptr : manifest) {
-
-      library::Operation const *operation = operation_ptr.get();
-
-      auto min_cc = operation->description().tile_description.minimum_compute_capability;
-      auto max_cc = operation->description().tile_description.maximum_compute_capability;
-
-      // Clear named allocations
-      device_context.free();
-
-      // Execute compatible cutlass operations if they satisfy the current device's compute capability
-      if (operation->description().kind == kind_ &&
-          operation->description().provider == library::Provider::kCUTLASS &&
-          options.device.compute_capability() >= min_cc &&
-          options.device.compute_capability() <= max_cc) {
-
-        std::string operation_name(operation->description().name);
-
-        // Filter kernels by name
-        bool filtered_by_name = options.operation_names.empty();
-        if (!filtered_by_name) {
-          
-          for (auto const & op_name : options.operation_names) {
-            if (find_string_matches_(op_name, operation_name)) {
-              filtered_by_name = true;
-              break;
-            }
-          } 
-        }
+  // FLOPs = 2 * n(n+1)k/2 [mma] + 2 * n(n+1)/2 [epilogue]
+  // FLOPs = n(n+1)(k + 1)
+  int64_t flops_ = n * (n + 1) * (k + 1);
 
-        for (auto const & op_name : options.excluded_operation_names) {
-          if (find_string_matches_(op_name, operation_name)) {
-            filtered_by_name = false;
-            break;
-          }
-        }
+  // complex-valued support
+  switch (operation_desc.tile_description.math_instruction.math_operation) {
+  case library::MathOperationID::kMultiplyAddComplex:
+    flops_ *= 4;
+    break;
 
-        if (!filtered_by_name || !satisfies(operation->description(), problem_space, problem)) {
-          continue;
-        }
+  case library::MathOperationID::kMultiplyAddComplexFastF32:
+    flops_ *= 4;
+    break;
+    
+  case library::MathOperationID::kMultiplyAddGaussianComplex:
+    flops_ *= 3;
+    break;
 
-        // we have found a kernel match, so increment the counter for match kernels
-        ++matched_operation_count;
+  default: break;
+  }
 
-        // A. Initialize configuration
-        Status status = this->initialize_configuration(
-          options,
-          report,
-          device_context,
-          operation,
-          problem_space,
-          problem);
+  return flops_;
+}
 
-        if (status == Status::kErrorInternal) {
-          
-          // If there was an internal error, consume the CUDA error and move to the next operation.
-          (void)cudaGetLastError();
-          
-          report.append_results(results_);
-          continue;
-        }
-        else if (status != Status::kSuccess) {
-          // If the workspace could not be initialized for any other reason, continue to
-          // the next operation.
-          continue;
-        }
+/// Initializes a performance result
+void RankKOperationProfiler::RankKProblem::initialize_result(
+  PerformanceResult &result,
+  library::RankKDescription const &operation_desc,
+  ProblemSpace const &problem_space) {
 
-        if (continue_profiling) {
+  result.arguments.resize(problem_space.rank());
 
-          if (options.report.print_kernel_before_running) {
-            std::cout << "Profiling kernel for JUnit test " << options.report.junit_output_path << ": "
-                      << operation_name << std::endl;
-          }
-
-          status = this->initialize_workspace(
-            options,
-            report,
-            device_context,
-            operation,
-            problem_space,
-            problem);
-
-          if (status == Status::kErrorInternal) {
-
-            // If there was an internal error, consume the CUDA error and move to the next operation.
-            (void)cudaGetLastError();
-
-            report.append_results(results_);
-            continue;
-          }
-          else if (status != Status::kSuccess) {
-            // If the workspace could not be initialized for any other reason, continue to
-            // the next operation.
-            continue;
-          }
-        }
+  set_argument(result, "rank_k_kind", problem_space, library::to_string(operation_desc.rank_k_kind));
 
-        //
-        // Profile CUTLASS if it is enabled
-        //
-
-        // B. Verify CUTLASS
-        if (continue_profiling && options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
-
-          continue_profiling = this->verify_cutlass(
-            options,
-            report, 
-            device_context, 
-            operation, 
-            problem_space,
-            problem);
+  set_argument(result, "A", problem_space,
+    std::string(library::to_string(operation_desc.A.element)) + ":" + library::to_string(operation_desc.A.layout));
 
-          retval |= (not continue_profiling);
-        }
+  set_argument(result, "C", problem_space,
+    std::string(library::to_string(operation_desc.C.element)) + ":" + library::to_string(operation_desc.C.layout));
 
-        if (options.execution_mode == ExecutionMode::kDryRun) {
-          report.append_results(results_);
-          results_.clear();
-          continue;
-        }
-
-        //
-        // C. Optionally save workspace
-        //
-
-        if (options.verification.save_workspace == SaveWorkspace::kAlways) {
-          save_workspace(
-            device_context,
-            options,
-            operation->description(),
-            library::Provider::kCUTLASS);
-        }
+  set_argument(result, "fill_mode", problem_space, library::to_string(operation_desc.fill_mode));
 
-        //
-        // D. Profile
-        //
-
-        if (continue_profiling && options.profiling.enabled) {
-
-          continue_profiling = this->profile(
-            options, 
-            report, 
-            device_context, 
-            operation, 
-            problem_space,
-            problem);
-        }
+  set_argument(result, "blas_mode", problem_space, library::to_string(operation_desc.blas_mode));
 
-        report.append_results(results_);
-        results_.clear();
-      }
+  set_argument(result, "n", problem_space, n);
+  set_argument(result, "k", problem_space, k);
 
-      if (!continue_profiling) {
-        break;
-      }
-    }
+  set_argument(result, "split_k_slices", problem_space, split_k_slices);
+  set_argument(result, "batch_count", problem_space, batch_count);
 
-    // If we did not find any kernels that match our filters and error_on_no_match was set, report an error
-    if (options.profiling.error_on_no_match && matched_operation_count <= 0) {
-      #if !NDEBUG
-      std::cout << "Error: No matching kernels found with kernel selection filters [--error_on_no_match]" << std::endl;
-      #endif
-      retval = 1;
-    }
-  }
+  set_argument(result, "alpha", problem_space,
+    library::lexical_cast(alpha, operation_desc.element_epilogue));
 
-  return retval;
+  set_argument(result, "beta", problem_space,
+    library::lexical_cast(beta, operation_desc.element_epilogue));
 }
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Sleep for a given duration in ms
-void OperationProfiler::sleep(int sleep_duration) {
-  if (sleep_duration) {
-    #ifdef __unix__
-    usleep(sleep_duration * 1000);
-    #elif defined(_WIN32) || defined(WIN32)
-    SleepEx(sleep_duration, false);
-    #else
-    // sleep not supported
-    #endif 
-  }
-}
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
+/// Extracts the problem dimensions
+Status RankKOperationProfiler::initialize_configuration(
+  Options const &options,  
+  PerformanceReport &report,
+  DeviceContext &device_context,
+  library::Operation const *operation,
+  ProblemSpace const &problem_space,
+  ProblemSpace::Problem const &problem) {
 
-/// Compares tensors for equality
-Disposition OperationProfiler::compare_tensors(
-  Options const &options,
-  DeviceAllocation &experimental,
-  DeviceAllocation &reference,
-  int64_t count) {
+  library::RankKDescription const &operation_desc = 
+    static_cast<library::RankKDescription const &>(operation->description());
 
-  if (experimental.type() != reference.type()) {
-    return Disposition::kIncorrect;
+  if (operation_desc.rank_k_kind != library::RankKKind::kUniversal) {
+    return Status::kErrorInvalidProblem;
   }
 
-  bool passed = false;
-
-  if (count == 0) {
-    count = reference.capacity();
+  Status status = problem_.parse(operation_desc, problem_space, problem);
+  
+  if (status != Status::kSuccess) {
+    return status;
   }
 
-  if (options.verification.epsilon == 0) {
+  rank_k_workspace_.configuration.problem_size.m() = int(problem_.n);
+  rank_k_workspace_.configuration.problem_size.n() = int(problem_.n);
+  rank_k_workspace_.configuration.problem_size.k() = int(problem_.k);
+  rank_k_workspace_.configuration.lda = problem_.lda;
+  rank_k_workspace_.configuration.ldc = problem_.ldc;
+  rank_k_workspace_.configuration.ldd = problem_.ldc;
+  //rank_k_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
+  rank_k_workspace_.configuration.batch_count = int(problem_.split_k_slices);
+
+  rank_k_workspace_.arguments.A = nullptr;
+  rank_k_workspace_.arguments.C = nullptr;
+  rank_k_workspace_.arguments.D = nullptr;
+  rank_k_workspace_.arguments.alpha = problem_.alpha.data();
+  rank_k_workspace_.arguments.beta = problem_.beta.data();
+  rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
-    // bit-level equality
-    passed = DeviceAllocation::block_compare_equal(
-      experimental.type(), 
-      experimental.data(),
-      reference.data(),
-      count);
-  }
-  else {
+  initialize_result_(this->model_result_, options, operation_desc, problem_space);
+  
+  return operation->can_implement(&rank_k_workspace_.configuration, &rank_k_workspace_.arguments);
+}
 
-    // relative error function
-    passed = DeviceAllocation::block_compare_relatively_equal(
-      experimental.type(), 
-      experimental.data(),
-      reference.data(),
-      count,
-      options.verification.epsilon,
-      options.verification.nonzero_floor);
-  }
+/// Initializes the performance result
+void RankKOperationProfiler::initialize_result_(
+  PerformanceResult &result,
+  Options const &options,  
+  library::RankKDescription const &operation_desc,
+  ProblemSpace const &problem_space) {
 
-  return passed ? Disposition::kPassed : Disposition::kIncorrect;
-}
+  result.provider = library::Provider::kCUTLASS;
+  result.disposition = Disposition::kNotRun;
+  result.status = Status::kSuccess;
+  result.operation_name = operation_desc.name;
+  
+  problem_.initialize_result(result, operation_desc, problem_space);
 
-/// Saves the workspace
-void OperationProfiler::save_workspace(
-  DeviceContext &device_context,
-  Options const &options,
-  library::OperationDescription const &desc,
-  library::Provider provider,
-  library::Provider verification_provider) {
+  OperationProfiler::initialize_result_(result, operation_desc, problem_space);
 
-  for (auto const & named_allocation : device_context) {
 
-    DeviceAllocation *allocation = named_allocation.second;
-    
-    std::stringstream filename;
+  result.bytes = problem_.bytes(operation_desc);
+  result.flops = problem_.flops(operation_desc);
 
-    filename << desc.name << "_" << library::to_string(provider) << "_";
+  result.runtime = 0;
 
-    if (verification_provider != library::Provider::kInvalid) {
-      filename << "verified_by_" << library::to_string(verification_provider) << "_";
-    }
+  // complex-valued support
+  switch (operation_desc.tile_description.math_instruction.math_operation) {
+  case library::MathOperationID::kMultiplyAddComplex:
+    result.flops *= 4;
+    break;
+     
+  case library::MathOperationID::kMultiplyAddComplexFastF32:
+    result.flops *= 4;
+    break;
 
-    filename << named_allocation.first + ".mat";
+  default: break;
+  }
 
-    std::ofstream out(filename.str());
+}
 
-    allocation->write_tensor_csv(out);
-    out << "\n";
+/// Initializes workspace
+Status RankKOperationProfiler::initialize_workspace(
+  Options const &options,  
+  PerformanceReport &report,
+  DeviceContext &device_context,
+  library::Operation const *operation,
+  ProblemSpace const &problem_space,
+  ProblemSpace::Problem const &problem) {
+  
+  library::RankKDescription const &operation_desc = 
+    static_cast<library::RankKDescription const &>(operation->description());
 
-    if (options.report.verbose) {
-      std::cout << "wrote '" << filename.str() << "'" << std::endl;
+  if (options.execution_mode != ExecutionMode::kDryRun) {
+    int seed_shift = 0;
+    rank_k_workspace_.A = device_context.allocate_tensor(
+      options,
+      "A",
+      operation_desc.A.element,
+      operation_desc.A.layout,
+      {int(problem_.n), int(problem_.k)},
+      {int(problem_.lda)},
+      1, // batch_count
+      seed_shift++
+    );
+
+    rank_k_workspace_.C = device_context.allocate_tensor(
+      options,
+      "C",
+      operation_desc.C.element,
+      operation_desc.C.layout,
+      {int(problem_.n), int(problem_.n)},
+      {int(problem_.ldc)},
+      1, // batch_count
+      seed_shift++
+    );
+
+    rank_k_workspace_.Computed = device_context.allocate_tensor(
+      "D",
+      operation_desc.C.element,
+      operation_desc.C.layout,
+      {int(problem_.n), int(problem_.n)},
+      {int(problem_.ldc)}
+    );
+
+    rank_k_workspace_.Reference = device_context.allocate_tensor(
+      "Reference",
+      operation_desc.C.element,
+      operation_desc.C.layout,
+      {int(problem_.n), int(problem_.n)},
+      {int(problem_.ldc)}
+    );
+
+    rank_k_workspace_.Computed->copy_from_device(rank_k_workspace_.C->data());
+    rank_k_workspace_.Reference->copy_from_device(rank_k_workspace_.C->data());
+  }
+
+
+  //
+  // Initialize the CUTLASS operation
+  //
+  Status status = Status::kSuccess;
+
+  if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
+
+    if (options.execution_mode != ExecutionMode::kDryRun) {
+
+      uint64_t workspace_size = operation->get_host_workspace_size(&rank_k_workspace_.configuration);
+      rank_k_workspace_.host_workspace.resize(workspace_size, 0);
+
+      workspace_size = operation->get_device_workspace_size(&rank_k_workspace_.configuration);
+      rank_k_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
+
+      status = operation->initialize(
+        &rank_k_workspace_.configuration,
+        rank_k_workspace_.host_workspace.data(),
+        rank_k_workspace_.device_workspace.data());
+    }
+
+    //
+    // If CUTLASS is enabled, generate a result for it
+    //
+    results_.push_back(model_result_);
+    results_.back().provider = library::Provider::kCUTLASS;
+    results_.back().op_kind = library::OperationKind::kRankK;
+    results_.back().disposition = Disposition::kNotRun;
+
+    for(auto provider : verification_providers_) {
+      results_.back().verification_map[provider] = Disposition::kNotRun;
     }
-  } 
-}
+  }
 
+  return status;
+}
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Method to profile a CUTLASS Operation
-Status OperationProfiler::profile_cutlass_(
-  double &runtime,
-  Options const &options,
+/// Verifies CUTLASS against references
+bool RankKOperationProfiler::verify_cutlass(
+  Options const &options,  
+  PerformanceReport &report,
+  DeviceContext &device_context,
   library::Operation const *operation,
-  void *arguments,
-  void *host_workspace,
-  void *device_workspace) {
+  ProblemSpace const &problem_space,
+  ProblemSpace::Problem const &problem) {
 
-  GpuTimer timer;
+  if (!options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
+    return true;
+  }
 
-  //
-  // Optional sleep to limit power consumption and thermals
-  //
+  if (options.execution_mode == ExecutionMode::kDryRun) {
+    return true;
+  }
 
-  sleep(options.profiling.sleep_duration);
+  // Initialize structure containing RankK arguments
+  rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
+  rank_k_workspace_.arguments.C = rank_k_workspace_.C->data();
+  rank_k_workspace_.arguments.D = rank_k_workspace_.Computed->data();
+  rank_k_workspace_.arguments.alpha = problem_.alpha.data();
+  rank_k_workspace_.arguments.beta = problem_.beta.data();
+  rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   //
-  // Warmup loop
+  // Run the CUTLASS operation
   //
 
-  Status status;
-
-  for (int iteration = 0; iteration < options.profiling.warmup_iterations; ++iteration) {
+  results_.back().status = operation->run(
+    &rank_k_workspace_.arguments, 
+    rank_k_workspace_.host_workspace.data(),
+    rank_k_workspace_.device_workspace.data());
 
-    status = operation->run(
-      arguments,
-      host_workspace,
-      device_workspace);
+  if (results_.back().status != Status::kSuccess) {
+    results_.back().disposition = Disposition::kFailed;
+    return false;
+  }
 
-    if (status != Status::kSuccess) {
-      return status;
-    }
+  cudaError_t result = cudaDeviceSynchronize();
+  if (result != cudaSuccess) {
+    results_.back().disposition = Disposition::kFailed;
+    return false;
   }
-  
-  //
-  // Initialize GPU timer
-  //
 
-  timer.start();
+  // CUTLASS op ran the but not yet verified against any verification provider
+  results_.back().disposition = Disposition::kNotVerified;
 
   //
-  // Profiling loop
+  // Run verification providers
   //
 
-  int Iterations = options.profiling.iterations;
+  if (options.verification.enabled) {
+
+#if CUTLASS_ENABLE_CUBLAS
+    if (options.verification.provider_enabled(library::Provider::kCUBLAS)) {
+
+      // Guard against unsupported cases
+      auto const & rank_k_desc = static_cast<library::RankKDescription const &>(operation->description());
+
+      if (cublas_satisfies(rank_k_desc) == Status::kSuccess) {
+
+        // call cublas verification if supported
+        verify_with_cublas_(
+          options,
+          report,
+          device_context,
+          operation,
+          problem_space,
+          problem);
+        }
 
-  int iteration = 0;
-  for (; iteration < Iterations; ++iteration) {
+      else {
+        // set verification map for cublas to not supported
+        results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotSupported;
+      }
+    }
+#endif // #if CUTLASS_ENABLE_CUBLAS
     
-    status = operation->run(
-      arguments,
-      host_workspace,
-      device_workspace);
+    // Update disposition to worst case verification outcome among all 
+    // verification providers which are supported
+    bool is_any_verification_run_passed = false;
+    for(auto &m : results_.back().verification_map) {
+      if(m.second == Disposition::kFailed || m.second == Disposition::kIncorrect) {
+        results_.back().disposition = m.second;
+        return true;
+      }
+      if(!is_any_verification_run_passed && m.second == Disposition::kPassed) {
+        is_any_verification_run_passed = true;
+      }
+    }
 
-    if (status != Status::kSuccess) {
-      return status;
+    if(is_any_verification_run_passed) {
+      results_.back().disposition = Disposition::kPassed;
     }
   }
 
+  // Return true means continue profiling
+  return true;
+}
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Verifies CUTLASS against references
+bool RankKOperationProfiler::verify_with_cublas_(
+  Options const &options,  
+  PerformanceReport &report,
+  DeviceContext &device_context,
+  library::Operation const *operation,
+  ProblemSpace const &problem_space,
+  ProblemSpace::Problem const &problem) {
+
+
+#if CUTLASS_ENABLE_CUBLAS
+
+  library::RankKDescription const &rank_k_desc = 
+    static_cast<library::RankKDescription const &>(operation->description());
+
   //
-  // Wait for completion
+  // Construct cuBLAS operators
   //
+    
+  CublasCreate handle;
+  cublasStatus_t status = handle.get_cublas_create_status();
+
+  if (status != CUBLAS_STATUS_SUCCESS) {
 
-  timer.stop_and_wait();
+    results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
+    return true;
+  }
 
   //
-  // Update performance result
+  // Initialize state
   //
-  
-  runtime = timer.duration(iteration);
 
-  return status;
-}
+  try {
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+    //
+    // Construct dispatcher to cublas<t>Syrk()
+    //
 
-/// Sets operation description 
-void OperationProfiler::initialize_result_(
-  PerformanceResult &result,
-  library::OperationDescription const &operation_desc,
-  ProblemSpace const &problem_space) {
+    // Initialize structure containing RankK arguments
+    rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
+    rank_k_workspace_.arguments.C = rank_k_workspace_.Reference->data();
+    rank_k_workspace_.arguments.D = rank_k_workspace_.Reference->data();
+    rank_k_workspace_.arguments.alpha = problem_.alpha.data();
+    rank_k_workspace_.arguments.beta = problem_.beta.data();
+    rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
-  set_argument(result, "op_class", problem_space,
-    library::to_string(operation_desc.tile_description.math_instruction.opcode_class));
+    detail::cublasRankKDispatcher rank_k_op( 
+      rank_k_desc, 
+      rank_k_workspace_.configuration,
+      rank_k_workspace_.arguments
+    );
 
-  set_argument(result, "accum", problem_space,
-    library::to_string(operation_desc.tile_description.math_instruction.element_accumulator));
+    if (rank_k_op.status != Status::kSuccess) {
+      results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotRun;
+      return true;
+    }
 
-  set_argument(result, "cta_m", problem_space, operation_desc.tile_description.threadblock_shape.m());
-  set_argument(result, "cta_n", problem_space, operation_desc.tile_description.threadblock_shape.n());
-  set_argument(result, "cta_k", problem_space, operation_desc.tile_description.threadblock_shape.k());
-  set_argument(result, "cluster_m", problem_space, operation_desc.tile_description.cluster_shape.m());
-  set_argument(result, "cluster_n", problem_space, operation_desc.tile_description.cluster_shape.n());
-  set_argument(result, "cluster_k", problem_space, operation_desc.tile_description.cluster_shape.k());
-  set_argument(result, "stages", problem_space, operation_desc.tile_description.threadblock_stages);
-  set_argument(result, "warps_m", problem_space, operation_desc.tile_description.warp_count.m());
-  set_argument(result, "warps_n", problem_space, operation_desc.tile_description.warp_count.n());
-  set_argument(result, "warps_k", problem_space, operation_desc.tile_description.warp_count.k());
-  set_argument(result, "inst_m", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.m());
-  set_argument(result, "inst_n", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.n());
-  set_argument(result, "inst_k", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.k());
-  set_argument(result, "min_cc", problem_space, operation_desc.tile_description.minimum_compute_capability);
-  set_argument(result, "max_cc", problem_space, operation_desc.tile_description.maximum_compute_capability);
-}
+    results_.back().status = Status::kSuccess;
 
-/// Helper
-void OperationProfiler::set_argument(
-  PerformanceResult &result,
-  char const *name,
-  ProblemSpace const &problem_space,
-  std::string const &value) {
+    status = rank_k_op(handle);
 
-  result.arguments.at(problem_space.argument_index(name)) = make_pair(std::string(name), value);
-}
+    // Handle errors
+    if (status != CUBLAS_STATUS_SUCCESS) {
 
-void OperationProfiler::set_argument(  
-  PerformanceResult &result,
-  char const *name,
-  ProblemSpace const &problem_space,
-  int64_t value) {
+      results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
+      return true;
+    }
 
-  result.arguments.at(problem_space.argument_index(name)) = make_pair(std::string(name), library::lexical_cast(value));
-}
+    //
+    // Verify results
+    //
 
+    results_.back().verification_map[library::Provider::kCUBLAS] = compare_tensors(
+      options,
+      *rank_k_workspace_.Computed,
+      *rank_k_workspace_.Reference
+    );
 
-/// finds string matches filter_string in operation_name
-bool OperationProfiler::find_string_matches_(
-  std::string const &filter_string, 
-  std::string const &operation_name) {
-  // Returns true if all substrings appear in the operation_name in order
-  
-  // Split filter_string of the format "gemm*f32*nt" to tokens ["gemm", "f32", "nt"]
-  std::string item;  
-  std::istringstream iss(filter_string);
-  std::vector<std::string> filter_tokens;
-  while (std::getline(iss, item, '*')) {
-    filter_tokens.push_back(item);
-  }
-
-  // Search filter_tokens in operation_name in order
-  size_t start = 0, idx = 0;
-  for (auto & token : filter_tokens) {
-    // Check if characters left to be parsed in operation_name
-    if (start < operation_name.length()) {
-      // Find token in operation_name[start:]
-      idx = operation_name.substr(start).find(token);
-      if (idx == std::string::npos) {
-        return false;
-      }
+    // Save workspace if incorrect
+    if (options.verification.save_workspace == SaveWorkspace::kIncorrect && 
+      results_.back().verification_map[library::Provider::kCUBLAS] == Disposition::kIncorrect) {
+
+      save_workspace(
+        device_context,
+        options,
+        rank_k_desc,
+        library::Provider::kCUTLASS,
+        library::Provider::kCUBLAS);
     }
-    start += (idx + token.length()); 
+  }
+  catch (...) {
+    results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
   }
 
-  // All tokens in filter_string found in operation_name
+#endif
+
+  // Return true means continue profiling
   return true;
 }
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Measures performance results
+bool RankKOperationProfiler::profile(
+  Options const &options,  
+  PerformanceReport &report,
+  DeviceContext &device_context,
+  library::Operation const *operation,
+  ProblemSpace const &problem_space,
+  ProblemSpace::Problem const &problem) {
+
+  if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
+
+    // Initialize structure containing RankK arguments
+    rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
+    rank_k_workspace_.arguments.C = rank_k_workspace_.C->data();
+    rank_k_workspace_.arguments.D = rank_k_workspace_.Computed->data();
+    rank_k_workspace_.arguments.alpha = problem_.alpha.data();
+    rank_k_workspace_.arguments.beta = problem_.beta.data();
+    rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+
+    results_.back().status = profile_cutlass_(
+      results_.back().runtime,
+      options,
+      operation,
+      &rank_k_workspace_.arguments,
+      rank_k_workspace_.host_workspace.data(),
+      rank_k_workspace_.device_workspace.data()
+    );
+  }
+  return true;
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace profiler
 } // namespace cutlass
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/options.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/options.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/performance_report.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/performance_report.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/performance_result.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp`

 * *Files 16% similar despite different names*

```diff
@@ -25,37 +25,77 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief
+  \brief Provides several functions for filling tensors with data.
 */
 
 #pragma once
 
-#include <vector>
+// Standard Library includes
+#include <utility>
+#include <cstdlib>
+#include <cmath>
 
+// Cute includes
+#include "cute/tensor.hpp"
+
+// Cutlass includes
 #include "cutlass/cutlass.h"
+#include "cutlass/complex.h"
+#include "cutlass/quaternion.h"
+#include "cutlass/array.h"
+#include "cutlass/numeric_types.h"
 
-// CUTLASS Profiler includes
-#include "cutlass/profiler/enumerated_types.h"
-#include "cutlass/profiler/performance_result.h"
-
-// CUTLASS Library includes
-#include "cutlass/library/library.h"
-#include "cutlass/library/util.h"
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
-namespace profiler {
+namespace reference {
+namespace host {
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
+/// Returns true if two tensor views are equal.
+template <
+  typename TensorL,
+  typename TensorR
+>
+bool TensorEquals(
+  TensorL lhs,
+  TensorR rhs) {
+
+  // Extents must be identical
+  if (cute::size(lhs) != cute::size(rhs)) {
+    return false;
+  }
+
+  for (int64_t idx = 0; idx < cute::size(lhs); ++idx) {
+    if (lhs(idx) != rhs(idx)) {
+      return false;
+    }
+  }
+
+  return true;
+}
+
+/// Returns true if two tensor views are NOT equal.
+template <
+  typename TensorL,
+  typename TensorR
+>
+bool TensorNotEquals(
+  TensorL lhs,
+  TensorR rhs) {
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  return TensorEquals(lhs, rhs);
+}
 
-} // namespace profiler
-} // namespace cutlass
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+} // namespace host
+} // namespace reference
+} // namespace cutlass
 
+///////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/problem_space.cpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/problem_space.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu`

 * *Files 12% similar despite different names*

```diff
@@ -38,94 +38,99 @@
 #include <stdexcept>
 #include <iomanip>
 #include <ios>
 
 #include "cutlass/core_io.h"
 
 #include "cutlass/profiler/cublas_helpers.h"
-#include "cutlass/profiler/rank_k_operation_profiler.h"
+#include "cutlass/profiler/symm_operation_profiler.h"
 #include "cutlass/profiler/gpu_timer.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace profiler {
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Ctor
-RankKOperationProfiler::RankKOperationProfiler(Options const &options): 
+SymmOperationProfiler::SymmOperationProfiler(Options const &options): 
   OperationProfiler(
     options,
-    library::OperationKind::kRankK,
+    library::OperationKind::kSymm,
     {
-      {ArgumentTypeID::kEnumerated, {"rank_k_kind"}, "Variant of RankK (universal)"},
-      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the RankK problem space"},
-      {ArgumentTypeID::kInteger, {"k", "problem-size::k"}, "K dimension of the RankK problem space"},
+      {ArgumentTypeID::kEnumerated, {"symm_kind"}, "Variant of Symm (universal)"},
+      {ArgumentTypeID::kInteger, {"m", "problem-size::m"}, "M dimension of the Symm problem space"},
+      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the Symm problem space"},
       {ArgumentTypeID::kTensor, {"A"}, "Tensor storing the A operand"},
+      {ArgumentTypeID::kTensor, {"B"}, "Tensor storing the B operand"},
       {ArgumentTypeID::kTensor, {"C"}, "Tensor storing the C operand"},
-      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for RankK kernel (lower or upper)"},
-      {ArgumentTypeID::kEnumerated, {"blas_mode"}, "Blas Mode for RankK kernel (symmetric or hermitian)"},
+      {ArgumentTypeID::kEnumerated, {"side_mode"}, "Side Mode for Symm kernel (left or right)"},
+      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for Symm kernel (lower or upper)"},
+      {ArgumentTypeID::kEnumerated, {"blas_mode"}, "Blas Mode for Symm kernel (symmetric or hermitian)"},
       {ArgumentTypeID::kScalar, {"alpha", "epilogue::alpha"}, "Epilogue scalar alpha"},
       {ArgumentTypeID::kScalar, {"beta", "epilogue::beta"}, "Epilogue scalar beta"},
       {ArgumentTypeID::kInteger, {"split_k_slices", "split-k-slices"}, "Number of partitions of K dimension"},
-      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of RankK computed in one batch"},
+      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of Symm computed in one batch"},
     },
-    { library::Provider::kCUBLAS}
+    { library::Provider::kCUBLAS }
   ) {
-  description_ = "      Rank-k Update. D = alpha * A*A^T + beta * C (symmetric) or D = alpha * A*A^H + beta * C (hermitian)";
+  description_ = "      Symmetric Matrix-Matrix Multiplication. D = alpha * A * B OR alpha * B * A + beta * C (where A is symmetric/hermitian)";
 }
 
 /// Destructor
-RankKOperationProfiler::~RankKOperationProfiler() {
+SymmOperationProfiler::~SymmOperationProfiler() {
 
 }
 
 /// Prints usage statement for the math function
-void RankKOperationProfiler::print_usage(std::ostream &out) const {
-  out << "RankK" << "\n\n";
+void SymmOperationProfiler::print_usage(std::ostream &out) const {
+  out << "Symm" << "\n\n";
 
   OperationProfiler::print_usage(out);
 }
 
 /// Prints examples
-void RankKOperationProfiler::print_examples(std::ostream &out) const {
+void SymmOperationProfiler::print_examples(std::ostream &out) const {
 
   out << "\nExamples:\n\n"
-    << "Profile a particular problem size Syrk kernel:\n"
-    << "  $ cutlass_profiler --operation=rank_k --blas_mode=symmetric --n=1024 --k=128\n\n"
+    << "Profile a particular problem size SYMM kernel:\n"
+    << "  $ cutlass_profiler --operation=Symm --blas_mode=symmetric --m=1024 --n=128\n\n"
     
-    << "Profile a particular problem size Herk kernel:\n"
-    << "  $ cutlass_profiler --operation=rank_k --blas_mode=hermitian --n=1024 --k=128\n\n"
+    << "Profile a particular problem size HEMM kernel:\n"
+    << "  $ cutlass_profiler --operation=Symm --blas_mode=hermitian --m=1024 --n=128\n\n"
 
     << "Schmoo over problem size and beta:\n"
-    << "  $ cutlass_profiler --operation=rank_k --n=1024:4096:256 --k=128:8192:128 --beta=0,1,2.5\n\n"
+    << "  $ cutlass_profiler --operation=Symm --m=1024:4096:256 --n=128:8192:128 --beta=0,1,2.5\n\n"
 
     << "Schmoo over accumulator types:\n"
-    << "  $ cutlass_profiler --operation=rank_k --accumulator-type=f16,f32\n\n"
+    << "  $ cutlass_profiler --operation=Symm --accumulator-type=f16,f32\n\n"
+
+    << "Schmoo over side modees:\n"
+    << "  $ cutlass_profiler --operation=Symm --side_mode=left/right\n\n"
 
     << "Schmoo over fill modees:\n"
-    << "  $ cutlass_profiler --operation=rank_k --fill_mode=lower/upper\n\n"
+    << "  $ cutlass_profiler --operation=Symm --fill_mode=lower/upper\n\n"
 
     << "Run when A is f16 with column-major or A is any datatype with row-major (For column major, use column, col, or n. For row major use, row or t):\n"
-    << "  $ cutlass_profiler --operation=rank_k --A=f16:column or --A=*:row\n\n"
+    << "  $ cutlass_profiler --operation=Symm --A=f16:column or --A=*:row\n\n"
 
     << "Using various input value distribution:\n"
-    << "  $ cutlass_profiler --operation=rank_k --dist=uniform,min:0,max:3\n"
-    << "  $ cutlass_profiler --operation=rank_k --dist=gaussian,mean:0,stddev:3\n"
-    << "  $ cutlass_profiler --operation=rank_k --dist=sequential,start:0,delta:1\n\n"
+    << "  $ cutlass_profiler --operation=Symm --dist=uniform,min:0,max:3\n"
+    << "  $ cutlass_profiler --operation=Symm --dist=gaussian,mean:0,stddev:3\n"
+    << "  $ cutlass_profiler --operation=Symm --dist=sequential,start:0,delta:1\n\n"
 
     << "Run a kernel with cta tile size of 256x128x32 and save workspace if results are incorrect (note that --cta-tile::k=32 is default cta-tile size):\n"
-    << " $ cutlass_profiler --operation=rank_k --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
+    << " $ cutlass_profiler --operation=Symm --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
     
-    << "Test your changes to rank_k kernels with a quick functional test and save results in functional-test.csv:\n"
-    << " $ cutlass_profiler  --operation=rank_k \\ \n"
-    << "   --n=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
-    << "   --k=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
+    << "Test your changes to symm kernels with a quick functional test and save results in functional-test.csv:\n"
+    << " $ cutlass_profiler  --operation=Symm \\ \n"
+    << "   --m=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
+    << "   --n=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
     << "   --beta=0,1,2 --profiling-iterations=1 \\ \n"
     << "   --providers=cutlass --output=functional-test.csv\n\n";
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #if 0
@@ -139,27 +144,27 @@
     ss << std::hex << std::setw(2) << std::setfill('0') << uint32_t(bytes.at(idx - 1));
   }
 
   return ss.str();
 }
 #endif
 
-Status RankKOperationProfiler::RankKProblem::parse(
-  library::RankKDescription const &operation_desc,
+Status SymmOperationProfiler::SymmProblem::parse(
+  library::SymmDescription const &operation_desc,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
   
-  if (!arg_as_int(this->n, "n", problem_space, problem)) {
+  if (!arg_as_int(this->m, "m", problem_space, problem)) {
     // default value
-    this->n = 1024;
+    this->m = 1024;
   }
   
-  if (!arg_as_int(this->k, "k", problem_space, problem)) {
+  if (!arg_as_int(this->n, "n", problem_space, problem)) {
     // default value
-    this->k = 1024;
+    this->n = 1024;
   }
   
   if (!arg_as_int(this->split_k_slices, "split_k_slices", problem_space, problem)) {
     // default value
     this->split_k_slices = 1;
   }
   
@@ -173,14 +178,18 @@
     return Status::kErrorInvalidProblem;
   }
 
   if (!tensor_description_satisfies(operation_desc.A, "A", problem_space, problem)) {
     return Status::kErrorInvalidProblem;
   }
 
+  if (!tensor_description_satisfies(operation_desc.B, "B", problem_space, problem)) {
+    return Status::kErrorInvalidProblem;
+  }
+
   if (!tensor_description_satisfies(operation_desc.C, "C", problem_space, problem)) {
     return Status::kErrorInvalidProblem;
   }
 
   if (!arg_as_scalar(
     this->alpha, 
     operation_desc.element_epilogue, 
@@ -201,285 +210,324 @@
     problem)) {
     
     if (!cast_from_double(this->beta, operation_desc.element_epilogue, 0)) {
       return Status::kErrorInternal;
     }
   }
   
-  this->lda = DeviceAllocation::get_packed_layout(
-    operation_desc.A.layout, {int(this->n), int(this->k)}).front();
+  if (operation_desc.side_mode == SideMode::kLeft) {
+    this->lda = DeviceAllocation::get_packed_layout(
+      operation_desc.A.layout, {int(this->m), int(this->m)}).front();
+  }
+  else if (operation_desc.side_mode == SideMode::kRight) {
+    this->lda = DeviceAllocation::get_packed_layout(
+      operation_desc.A.layout, {int(this->n), int(this->n)}).front();
+  }
+
+  this->ldb = DeviceAllocation::get_packed_layout(
+    operation_desc.B.layout, {int(this->m), int(this->n)}).front();
 
   this->ldc = DeviceAllocation::get_packed_layout(
-    operation_desc.C.layout, {int(this->n), int(this->n)}).front();
+    operation_desc.C.layout, {int(this->m), int(this->n)}).front();
 
   return Status::kSuccess;
 }
 
 /// Total number of bytes loaded
-int64_t RankKOperationProfiler::RankKProblem::bytes(library::RankKDescription const &operation_desc) const {
+int64_t SymmOperationProfiler::SymmProblem::bytes(library::SymmDescription const &operation_desc) const {
+  int64_t bytes = 0;
   // Input bytes read and Output bytes written for the gemm problem
-  int64_t bytes =
-    int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * k +
-    int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * k +
-    // Half matrix including the diagonal will have (N*(N+1))/2 elements
-    int64_t(library::sizeof_bits(operation_desc.C.element) * n / 8) * (n+1) / 2;
-
+  // Half matrix including the diagonal will have (X*(X+1))/2 elements
+  if (operation_desc.side_mode == SideMode::kLeft) {
+    bytes =
+      int64_t(library::sizeof_bits(operation_desc.A.element) * m / 8) * (m + 1) / 2 +
+      int64_t(library::sizeof_bits(operation_desc.B.element) * m / 8) * n + 
+      int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
+  } else if (operation_desc.side_mode == SideMode::kRight) {
+    bytes =
+      int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * (n + 1) / 2 +
+      int64_t(library::sizeof_bits(operation_desc.B.element) * m / 8) * n + 
+      int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
+  }
   // Set is_beta_zero true if beta is zero
   bool is_beta_zero = std::all_of(beta.begin(), beta.end(), [](uint8_t i) { return i==0; });
 
   // Output bytes read for the gemm problem for non-zero beta values
   if (!is_beta_zero) {
-    bytes += int64_t(library::sizeof_bits(operation_desc.C.element) * n / 8) * (n+1) / 2;
+    bytes += int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
   }
 
   bytes *= batch_count;
 
   return bytes;
 }
 
 /// Total number of flops computed
-int64_t RankKOperationProfiler::RankKProblem::flops(library::RankKDescription const &operation_desc) const {
+int64_t SymmOperationProfiler::SymmProblem::flops(library::SymmDescription const &operation_desc) const {
 
-  // FLOPs = 2 * n(n+1)k/2 [mma] + 2 * n(n+1)/2 [epilogue]
-  // FLOPs = n(n+1)(k + 1)
-  int64_t flops_ = n * (n + 1) * (k + 1);
+  // FLOPs for first TRMM kernel (with diagonal) = 2 * [ ( M * (M+1)/2 * N ) ] // Beta is zero
+  // FLOPs for second TRMM kernel (with diagonal) = 2 * [ ( M * (M-1)/2 * N ) ] // Beta is zero
+  // FLOPs = m*(m+1)*n [mma1] + m*(m-1)*n [mma2] + 2*m*n [epilogue]
+  // FLOPs = 2*m*n(m+1) for left side mode
+  // FLOPs can also be calculated to be same as GEMM with correct value for 'k' as below.
+  int64_t k = (operation_desc.side_mode == SideMode::kLeft) ? int64_t(m) : int64_t(n);
+  int64_t flops_ = (int64_t(m) * n * k + m * n) * 2;
 
   // complex-valued support
   switch (operation_desc.tile_description.math_instruction.math_operation) {
   case library::MathOperationID::kMultiplyAddComplex:
     flops_ *= 4;
     break;
-
+    
   case library::MathOperationID::kMultiplyAddComplexFastF32:
     flops_ *= 4;
     break;
-    
+
   case library::MathOperationID::kMultiplyAddGaussianComplex:
     flops_ *= 3;
     break;
 
   default: break;
   }
 
   return flops_;
 }
 
 /// Initializes a performance result
-void RankKOperationProfiler::RankKProblem::initialize_result(
+void SymmOperationProfiler::SymmProblem::initialize_result(
   PerformanceResult &result,
-  library::RankKDescription const &operation_desc,
+  library::SymmDescription const &operation_desc,
   ProblemSpace const &problem_space) {
 
   result.arguments.resize(problem_space.rank());
 
-  set_argument(result, "rank_k_kind", problem_space, library::to_string(operation_desc.rank_k_kind));
+  set_argument(result, "symm_kind", problem_space, library::to_string(operation_desc.symm_kind));
 
   set_argument(result, "A", problem_space,
     std::string(library::to_string(operation_desc.A.element)) + ":" + library::to_string(operation_desc.A.layout));
 
+  set_argument(result, "B", problem_space,
+    std::string(library::to_string(operation_desc.B.element)) + ":" + library::to_string(operation_desc.B.layout));
+
   set_argument(result, "C", problem_space,
     std::string(library::to_string(operation_desc.C.element)) + ":" + library::to_string(operation_desc.C.layout));
 
+  set_argument(result, "side_mode", problem_space, library::to_string(operation_desc.side_mode));
+
   set_argument(result, "fill_mode", problem_space, library::to_string(operation_desc.fill_mode));
 
   set_argument(result, "blas_mode", problem_space, library::to_string(operation_desc.blas_mode));
 
+  set_argument(result, "m", problem_space, m);
   set_argument(result, "n", problem_space, n);
-  set_argument(result, "k", problem_space, k);
 
   set_argument(result, "split_k_slices", problem_space, split_k_slices);
   set_argument(result, "batch_count", problem_space, batch_count);
 
   set_argument(result, "alpha", problem_space,
     library::lexical_cast(alpha, operation_desc.element_epilogue));
 
   set_argument(result, "beta", problem_space,
     library::lexical_cast(beta, operation_desc.element_epilogue));
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Extracts the problem dimensions
-Status RankKOperationProfiler::initialize_configuration(
+Status SymmOperationProfiler::initialize_configuration(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
-  library::RankKDescription const &operation_desc = 
-    static_cast<library::RankKDescription const &>(operation->description());
+  library::SymmDescription const &operation_desc = 
+    static_cast<library::SymmDescription const &>(operation->description());
 
-  if (operation_desc.rank_k_kind != library::RankKKind::kUniversal) {
+  if (operation_desc.symm_kind != library::SymmKind::kUniversal) {
     return Status::kErrorInvalidProblem;
   }
 
   Status status = problem_.parse(operation_desc, problem_space, problem);
   
   if (status != Status::kSuccess) {
     return status;
   }
 
-  rank_k_workspace_.configuration.problem_size.m() = int(problem_.n);
-  rank_k_workspace_.configuration.problem_size.n() = int(problem_.n);
-  rank_k_workspace_.configuration.problem_size.k() = int(problem_.k);
-  rank_k_workspace_.configuration.lda = problem_.lda;
-  rank_k_workspace_.configuration.ldc = problem_.ldc;
-  rank_k_workspace_.configuration.ldd = problem_.ldc;
-  //rank_k_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
-  rank_k_workspace_.configuration.batch_count = int(problem_.split_k_slices);
-
-  rank_k_workspace_.arguments.A = nullptr;
-  rank_k_workspace_.arguments.C = nullptr;
-  rank_k_workspace_.arguments.D = nullptr;
-  rank_k_workspace_.arguments.alpha = problem_.alpha.data();
-  rank_k_workspace_.arguments.beta = problem_.beta.data();
-  rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+  symm_workspace_.configuration.problem_size.m() = int(problem_.m);
+  symm_workspace_.configuration.problem_size.n() = int(problem_.n);
+  symm_workspace_.configuration.problem_size.k() = (operation_desc.side_mode == SideMode::kLeft) 
+                                                    ? int(problem_.m) : int(problem_.n);
+  symm_workspace_.configuration.lda = problem_.lda;
+  symm_workspace_.configuration.ldb = problem_.ldb;
+  symm_workspace_.configuration.ldc = problem_.ldc;
+  symm_workspace_.configuration.ldd = problem_.ldc;
+  //symm_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
+  symm_workspace_.configuration.batch_count = int(problem_.split_k_slices);
+
+  symm_workspace_.arguments.A = nullptr;
+  symm_workspace_.arguments.B = nullptr;
+  symm_workspace_.arguments.C = nullptr;
+  symm_workspace_.arguments.D = nullptr;
+  symm_workspace_.arguments.alpha = problem_.alpha.data();
+  symm_workspace_.arguments.beta = problem_.beta.data();
+  symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   initialize_result_(this->model_result_, options, operation_desc, problem_space);
   
-  return operation->can_implement(&rank_k_workspace_.configuration, &rank_k_workspace_.arguments);
+  return operation->can_implement(&symm_workspace_.configuration, &symm_workspace_.arguments);
 }
 
 /// Initializes the performance result
-void RankKOperationProfiler::initialize_result_(
+void SymmOperationProfiler::initialize_result_(
   PerformanceResult &result,
   Options const &options,  
-  library::RankKDescription const &operation_desc,
+  library::SymmDescription const &operation_desc,
   ProblemSpace const &problem_space) {
 
   result.provider = library::Provider::kCUTLASS;
   result.disposition = Disposition::kNotRun;
   result.status = Status::kSuccess;
   result.operation_name = operation_desc.name;
   
   problem_.initialize_result(result, operation_desc, problem_space);
 
   OperationProfiler::initialize_result_(result, operation_desc, problem_space);
 
 
   result.bytes = problem_.bytes(operation_desc);
   result.flops = problem_.flops(operation_desc);
-
   result.runtime = 0;
 
-  // complex-valued support
-  switch (operation_desc.tile_description.math_instruction.math_operation) {
-  case library::MathOperationID::kMultiplyAddComplex:
-    result.flops *= 4;
-    break;
-     
-  case library::MathOperationID::kMultiplyAddComplexFastF32:
-    result.flops *= 4;
-    break;
-
-  default: break;
-  }
 
 }
 
 /// Initializes workspace
-Status RankKOperationProfiler::initialize_workspace(
+Status SymmOperationProfiler::initialize_workspace(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
   
-  library::RankKDescription const &operation_desc = 
-    static_cast<library::RankKDescription const &>(operation->description());
+  library::SymmDescription const &operation_desc = 
+    static_cast<library::SymmDescription const &>(operation->description());
 
   if (options.execution_mode != ExecutionMode::kDryRun) {
     int seed_shift = 0;
-    rank_k_workspace_.A = device_context.allocate_tensor(
+    if (operation_desc.side_mode == SideMode::kLeft) {
+      symm_workspace_.A = device_context.allocate_tensor(
+        options,
+        "A",
+        operation_desc.A.element,
+        operation_desc.A.layout,
+        {int(problem_.m), int(problem_.m)},
+        {int(problem_.lda)},
+        1, // batch_count
+        seed_shift++
+      );
+    } else if (operation_desc.side_mode == SideMode::kRight) {
+      symm_workspace_.A = device_context.allocate_tensor(
+        options,
+        "A",
+        operation_desc.A.element,
+        operation_desc.A.layout,
+        {int(problem_.n), int(problem_.n)},
+        {int(problem_.lda)},
+        1, // batch_count
+        seed_shift++
+      );
+    }
+
+    symm_workspace_.B = device_context.allocate_tensor(
       options,
-      "A",
-      operation_desc.A.element,
-      operation_desc.A.layout,
-      {int(problem_.n), int(problem_.k)},
-      {int(problem_.lda)},
+      "B",
+      operation_desc.B.element,
+      operation_desc.B.layout,
+      {int(problem_.m), int(problem_.n)},
+      {int(problem_.ldb)},
       1, // batch_count
       seed_shift++
     );
 
-    rank_k_workspace_.C = device_context.allocate_tensor(
+    symm_workspace_.C = device_context.allocate_tensor(
       options,
       "C",
       operation_desc.C.element,
       operation_desc.C.layout,
-      {int(problem_.n), int(problem_.n)},
+      {int(problem_.m), int(problem_.n)},
       {int(problem_.ldc)},
       1, // batch_count
       seed_shift++
     );
 
-    rank_k_workspace_.Computed = device_context.allocate_tensor(
+    symm_workspace_.Computed = device_context.allocate_tensor(
       "D",
       operation_desc.C.element,
       operation_desc.C.layout,
-      {int(problem_.n), int(problem_.n)},
+      {int(problem_.m), int(problem_.n)},
       {int(problem_.ldc)}
     );
 
-    rank_k_workspace_.Reference = device_context.allocate_tensor(
+    symm_workspace_.Reference = device_context.allocate_tensor(
       "Reference",
       operation_desc.C.element,
       operation_desc.C.layout,
-      {int(problem_.n), int(problem_.n)},
+      {int(problem_.m), int(problem_.n)},
       {int(problem_.ldc)}
     );
 
-    rank_k_workspace_.Computed->copy_from_device(rank_k_workspace_.C->data());
-    rank_k_workspace_.Reference->copy_from_device(rank_k_workspace_.C->data());
+    symm_workspace_.Computed->copy_from_device(symm_workspace_.C->data());
+    symm_workspace_.Reference->copy_from_device(symm_workspace_.C->data());
   }
 
 
   //
   // Initialize the CUTLASS operation
   //
   Status status = Status::kSuccess;
 
   if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
     if (options.execution_mode != ExecutionMode::kDryRun) {
 
-      uint64_t workspace_size = operation->get_host_workspace_size(&rank_k_workspace_.configuration);
-      rank_k_workspace_.host_workspace.resize(workspace_size, 0);
+      uint64_t workspace_size = operation->get_host_workspace_size(&symm_workspace_.configuration);
+      symm_workspace_.host_workspace.resize(workspace_size, 0);
 
-      workspace_size = operation->get_device_workspace_size(&rank_k_workspace_.configuration);
-      rank_k_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
+      workspace_size = operation->get_device_workspace_size(&symm_workspace_.configuration);
+      symm_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
 
       status = operation->initialize(
-        &rank_k_workspace_.configuration,
-        rank_k_workspace_.host_workspace.data(),
-        rank_k_workspace_.device_workspace.data());
+        &symm_workspace_.configuration,
+        symm_workspace_.host_workspace.data(),
+        symm_workspace_.device_workspace.data());
     }
 
     //
     // If CUTLASS is enabled, generate a result for it
     //
     results_.push_back(model_result_);
     results_.back().provider = library::Provider::kCUTLASS;
-    results_.back().op_kind = library::OperationKind::kRankK;
+    results_.back().op_kind = library::OperationKind::kSymm;
     results_.back().disposition = Disposition::kNotRun;
 
     for(auto provider : verification_providers_) {
       results_.back().verification_map[provider] = Disposition::kNotRun;
     }
   }
 
   return status;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Verifies CUTLASS against references
-bool RankKOperationProfiler::verify_cutlass(
+bool SymmOperationProfiler::verify_cutlass(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
@@ -487,30 +535,31 @@
     return true;
   }
 
   if (options.execution_mode == ExecutionMode::kDryRun) {
     return true;
   }
 
-  // Initialize structure containing RankK arguments
-  rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
-  rank_k_workspace_.arguments.C = rank_k_workspace_.C->data();
-  rank_k_workspace_.arguments.D = rank_k_workspace_.Computed->data();
-  rank_k_workspace_.arguments.alpha = problem_.alpha.data();
-  rank_k_workspace_.arguments.beta = problem_.beta.data();
-  rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+  // Initialize structure containing Symm arguments
+  symm_workspace_.arguments.A = symm_workspace_.A->data();
+  symm_workspace_.arguments.B = symm_workspace_.B->data();
+  symm_workspace_.arguments.C = symm_workspace_.C->data();
+  symm_workspace_.arguments.D = symm_workspace_.Computed->data();
+  symm_workspace_.arguments.alpha = problem_.alpha.data();
+  symm_workspace_.arguments.beta = problem_.beta.data();
+  symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   //
   // Run the CUTLASS operation
   //
 
   results_.back().status = operation->run(
-    &rank_k_workspace_.arguments, 
-    rank_k_workspace_.host_workspace.data(),
-    rank_k_workspace_.device_workspace.data());
+    &symm_workspace_.arguments, 
+    symm_workspace_.host_workspace.data(),
+    symm_workspace_.device_workspace.data());
 
   if (results_.back().status != Status::kSuccess) {
     results_.back().disposition = Disposition::kFailed;
     return false;
   }
 
   cudaError_t result = cudaDeviceSynchronize();
@@ -528,17 +577,17 @@
 
   if (options.verification.enabled) {
 
 #if CUTLASS_ENABLE_CUBLAS
     if (options.verification.provider_enabled(library::Provider::kCUBLAS)) {
 
       // Guard against unsupported cases
-      auto const & rank_k_desc = static_cast<library::RankKDescription const &>(operation->description());
+      auto const & symm_desc = static_cast<library::SymmDescription const &>(operation->description());
 
-      if (cublas_satisfies(rank_k_desc) == Status::kSuccess) {
+      if (cublas_satisfies(symm_desc) == Status::kSuccess) {
 
         // call cublas verification if supported
         verify_with_cublas_(
           options,
           report,
           device_context,
           operation,
@@ -574,27 +623,27 @@
   // Return true means continue profiling
   return true;
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Verifies CUTLASS against references
-bool RankKOperationProfiler::verify_with_cublas_(
+bool SymmOperationProfiler::verify_with_cublas_(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
 
 #if CUTLASS_ENABLE_CUBLAS
 
-  library::RankKDescription const &rank_k_desc = 
-    static_cast<library::RankKDescription const &>(operation->description());
+  library::SymmDescription const &symm_desc = 
+    static_cast<library::SymmDescription const &>(operation->description());
 
   //
   // Construct cuBLAS operators
   //
     
   CublasCreate handle;
   cublasStatus_t status = handle.get_cublas_create_status();
@@ -608,65 +657,66 @@
   //
   // Initialize state
   //
 
   try {
 
     //
-    // Construct dispatcher to cublas<t>Syrk()
+    // Construct dispatcher to cublas<t>Symm()
     //
 
-    // Initialize structure containing RankK arguments
-    rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
-    rank_k_workspace_.arguments.C = rank_k_workspace_.Reference->data();
-    rank_k_workspace_.arguments.D = rank_k_workspace_.Reference->data();
-    rank_k_workspace_.arguments.alpha = problem_.alpha.data();
-    rank_k_workspace_.arguments.beta = problem_.beta.data();
-    rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
-
-    detail::cublasRankKDispatcher rank_k_op( 
-      rank_k_desc, 
-      rank_k_workspace_.configuration,
-      rank_k_workspace_.arguments
+    // Initialize structure containing Symm arguments
+    symm_workspace_.arguments.A = symm_workspace_.A->data();
+    symm_workspace_.arguments.B = symm_workspace_.B->data();
+    symm_workspace_.arguments.C = symm_workspace_.Reference->data();
+    symm_workspace_.arguments.D = symm_workspace_.Reference->data();
+    symm_workspace_.arguments.alpha = problem_.alpha.data();
+    symm_workspace_.arguments.beta = problem_.beta.data();
+    symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+
+    detail::cublasSymmDispatcher symm_op( 
+      symm_desc, 
+      symm_workspace_.configuration,
+      symm_workspace_.arguments
     );
 
-    if (rank_k_op.status != Status::kSuccess) {
+    if (symm_op.status != Status::kSuccess) {
       results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotRun;
       return true;
     }
 
     results_.back().status = Status::kSuccess;
 
-    status = rank_k_op(handle);
+    status = symm_op(handle);
 
     // Handle errors
     if (status != CUBLAS_STATUS_SUCCESS) {
 
       results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
       return true;
     }
 
     //
     // Verify results
     //
 
     results_.back().verification_map[library::Provider::kCUBLAS] = compare_tensors(
       options,
-      *rank_k_workspace_.Computed,
-      *rank_k_workspace_.Reference
+      *symm_workspace_.Computed,
+      *symm_workspace_.Reference
     );
 
     // Save workspace if incorrect
     if (options.verification.save_workspace == SaveWorkspace::kIncorrect && 
       results_.back().verification_map[library::Provider::kCUBLAS] == Disposition::kIncorrect) {
 
       save_workspace(
         device_context,
         options,
-        rank_k_desc,
+        symm_desc,
         library::Provider::kCUTLASS,
         library::Provider::kCUBLAS);
     }
   }
   catch (...) {
     results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
   }
@@ -676,39 +726,40 @@
   // Return true means continue profiling
   return true;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Measures performance results
-bool RankKOperationProfiler::profile(
+bool SymmOperationProfiler::profile(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
   if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
-    // Initialize structure containing RankK arguments
-    rank_k_workspace_.arguments.A = rank_k_workspace_.A->data();
-    rank_k_workspace_.arguments.C = rank_k_workspace_.C->data();
-    rank_k_workspace_.arguments.D = rank_k_workspace_.Computed->data();
-    rank_k_workspace_.arguments.alpha = problem_.alpha.data();
-    rank_k_workspace_.arguments.beta = problem_.beta.data();
-    rank_k_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+    // Initialize structure containing Symm arguments
+    symm_workspace_.arguments.A = symm_workspace_.A->data();
+    symm_workspace_.arguments.B = symm_workspace_.B->data();
+    symm_workspace_.arguments.C = symm_workspace_.C->data();
+    symm_workspace_.arguments.D = symm_workspace_.Computed->data();
+    symm_workspace_.arguments.alpha = problem_.alpha.data();
+    symm_workspace_.arguments.beta = problem_.beta.data();
+    symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
     results_.back().status = profile_cutlass_(
       results_.back().runtime,
       options,
       operation,
-      &rank_k_workspace_.arguments,
-      rank_k_workspace_.host_workspace.data(),
-      rank_k_workspace_.device_workspace.data()
+      &symm_workspace_.arguments,
+      symm_workspace_.host_workspace.data(),
+      symm_workspace_.device_workspace.data()
     );
   }
   return true;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu`

 * *Files 8% similar despite different names*

```diff
@@ -38,99 +38,90 @@
 #include <stdexcept>
 #include <iomanip>
 #include <ios>
 
 #include "cutlass/core_io.h"
 
 #include "cutlass/profiler/cublas_helpers.h"
-#include "cutlass/profiler/symm_operation_profiler.h"
+#include "cutlass/profiler/trmm_operation_profiler.h"
 #include "cutlass/profiler/gpu_timer.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace profiler {
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Ctor
-SymmOperationProfiler::SymmOperationProfiler(Options const &options): 
+TrmmOperationProfiler::TrmmOperationProfiler(Options const &options): 
   OperationProfiler(
     options,
-    library::OperationKind::kSymm,
+    library::OperationKind::kTrmm,
     {
-      {ArgumentTypeID::kEnumerated, {"symm_kind"}, "Variant of Symm (universal)"},
-      {ArgumentTypeID::kInteger, {"m", "problem-size::m"}, "M dimension of the Symm problem space"},
-      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the Symm problem space"},
+      {ArgumentTypeID::kEnumerated, {"trmm_kind"}, "Variant of TRMM (universal)"},
+      {ArgumentTypeID::kInteger, {"m", "problem-size::m"}, "M dimension of the TRMM problem space"},
+      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the TRMM problem space"},
       {ArgumentTypeID::kTensor, {"A"}, "Tensor storing the A operand"},
+      {ArgumentTypeID::kEnumerated, {"side_mode"}, "Side Mode for TRMM (left, right)"},
+      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for TRMM (lower, upper)"},
+      {ArgumentTypeID::kEnumerated, {"diag_type"}, "Diag Type for TRMM (nonunit, unit)"},
       {ArgumentTypeID::kTensor, {"B"}, "Tensor storing the B operand"},
-      {ArgumentTypeID::kTensor, {"C"}, "Tensor storing the C operand"},
-      {ArgumentTypeID::kEnumerated, {"side_mode"}, "Side Mode for Symm kernel (left or right)"},
-      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for Symm kernel (lower or upper)"},
-      {ArgumentTypeID::kEnumerated, {"blas_mode"}, "Blas Mode for Symm kernel (symmetric or hermitian)"},
+      {ArgumentTypeID::kTensor, {"D"}, "Tensor storing the D operand"},
       {ArgumentTypeID::kScalar, {"alpha", "epilogue::alpha"}, "Epilogue scalar alpha"},
       {ArgumentTypeID::kScalar, {"beta", "epilogue::beta"}, "Epilogue scalar beta"},
       {ArgumentTypeID::kInteger, {"split_k_slices", "split-k-slices"}, "Number of partitions of K dimension"},
-      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of Symm computed in one batch"},
+      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of TRMMs computed in one batch"},
     },
-    { library::Provider::kCUBLAS }
+    { library::Provider::kCUBLAS}
   ) {
-  description_ = "      Symmetric Matrix-Matrix Multiplication. D = alpha * A * B OR alpha * B * A + beta * C (where A is symmetric/hermitian)";
+  description_ = "      Triangular Matrix-Multiplication. D = alpha * A * B or alpha * B * A";
 }
 
 /// Destructor
-SymmOperationProfiler::~SymmOperationProfiler() {
+TrmmOperationProfiler::~TrmmOperationProfiler() {
 
 }
 
 /// Prints usage statement for the math function
-void SymmOperationProfiler::print_usage(std::ostream &out) const {
-  out << "Symm" << "\n\n";
+void TrmmOperationProfiler::print_usage(std::ostream &out) const {
+  out << "TRMM" << "\n\n";
 
   OperationProfiler::print_usage(out);
 }
 
 /// Prints examples
-void SymmOperationProfiler::print_examples(std::ostream &out) const {
+void TrmmOperationProfiler::print_examples(std::ostream &out) const {
 
   out << "\nExamples:\n\n"
-    << "Profile a particular problem size SYMM kernel:\n"
-    << "  $ cutlass_profiler --operation=Symm --blas_mode=symmetric --m=1024 --n=128\n\n"
-    
-    << "Profile a particular problem size HEMM kernel:\n"
-    << "  $ cutlass_profiler --operation=Symm --blas_mode=hermitian --m=1024 --n=128\n\n"
+    << "Profile a particular problem size:\n"
+    << "  $ cutlass_profiler --operation=Trmm --n=1024 --m=128\n\n"
 
     << "Schmoo over problem size and beta:\n"
-    << "  $ cutlass_profiler --operation=Symm --m=1024:4096:256 --n=128:8192:128 --beta=0,1,2.5\n\n"
+    << "  $ cutlass_profiler --operation=Trmm --n=1024:4096:256 --m=128:8192:128 --beta=0,1,2.5\n\n"
 
     << "Schmoo over accumulator types:\n"
-    << "  $ cutlass_profiler --operation=Symm --accumulator-type=f16,f32\n\n"
-
-    << "Schmoo over side modees:\n"
-    << "  $ cutlass_profiler --operation=Symm --side_mode=left/right\n\n"
-
-    << "Schmoo over fill modees:\n"
-    << "  $ cutlass_profiler --operation=Symm --fill_mode=lower/upper\n\n"
+    << "  $ cutlass_profiler --operation=Trmm --accumulator-type=f16,f32\n\n"
 
     << "Run when A is f16 with column-major or A is any datatype with row-major (For column major, use column, col, or n. For row major use, row or t):\n"
-    << "  $ cutlass_profiler --operation=Symm --A=f16:column or --A=*:row\n\n"
+    << "  $ cutlass_profiler --operation=Trmm --A=f16:column or --A=*:row\n\n"
 
     << "Using various input value distribution:\n"
-    << "  $ cutlass_profiler --operation=Symm --dist=uniform,min:0,max:3\n"
-    << "  $ cutlass_profiler --operation=Symm --dist=gaussian,mean:0,stddev:3\n"
-    << "  $ cutlass_profiler --operation=Symm --dist=sequential,start:0,delta:1\n\n"
+    << "  $ cutlass_profiler --operation=Trmm --dist=uniform,min:0,max:3\n"
+    << "  $ cutlass_profiler --operation=Trmm --dist=gaussian,mean:0,stddev:3\n"
+    << "  $ cutlass_profiler --operation=Trmm --dist=sequential,start:0,delta:1\n\n"
 
     << "Run a kernel with cta tile size of 256x128x32 and save workspace if results are incorrect (note that --cta-tile::k=32 is default cta-tile size):\n"
-    << " $ cutlass_profiler --operation=Symm --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
+    << " $ cutlass_profiler --operation=Trmm --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
     
-    << "Test your changes to symm kernels with a quick functional test and save results in functional-test.csv:\n"
-    << " $ cutlass_profiler  --operation=Symm \\ \n"
-    << "   --m=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
-    << "   --n=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
+    << "Test your changes to trmm kernels with a quick functional test and save results in functional-test.csv:\n"
+    << " $ cutlass_profiler  --operation=Trmm \\ \n"
+    << "   --n=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
+    << "   --k=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
     << "   --beta=0,1,2 --profiling-iterations=1 \\ \n"
     << "   --providers=cutlass --output=functional-test.csv\n\n";
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #if 0
@@ -144,16 +135,16 @@
     ss << std::hex << std::setw(2) << std::setfill('0') << uint32_t(bytes.at(idx - 1));
   }
 
   return ss.str();
 }
 #endif
 
-Status SymmOperationProfiler::SymmProblem::parse(
-  library::SymmDescription const &operation_desc,
+Status TrmmOperationProfiler::TrmmProblem::parse(
+  library::TrmmDescription const &operation_desc,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
   
   if (!arg_as_int(this->m, "m", problem_space, problem)) {
     // default value
     this->m = 1024;
   }
@@ -182,15 +173,15 @@
     return Status::kErrorInvalidProblem;
   }
 
   if (!tensor_description_satisfies(operation_desc.B, "B", problem_space, problem)) {
     return Status::kErrorInvalidProblem;
   }
 
-  if (!tensor_description_satisfies(operation_desc.C, "C", problem_space, problem)) {
+  if (!tensor_description_satisfies(operation_desc.D, "D", problem_space, problem)) {
     return Status::kErrorInvalidProblem;
   }
 
   if (!arg_as_scalar(
     this->alpha, 
     operation_desc.element_epilogue, 
     "alpha", 
@@ -222,104 +213,44 @@
     this->lda = DeviceAllocation::get_packed_layout(
       operation_desc.A.layout, {int(this->n), int(this->n)}).front();
   }
 
   this->ldb = DeviceAllocation::get_packed_layout(
     operation_desc.B.layout, {int(this->m), int(this->n)}).front();
 
-  this->ldc = DeviceAllocation::get_packed_layout(
-    operation_desc.C.layout, {int(this->m), int(this->n)}).front();
+  this->ldd = DeviceAllocation::get_packed_layout(
+    operation_desc.D.layout, {int(this->m), int(this->n)}).front();
 
   return Status::kSuccess;
 }
 
-/// Total number of bytes loaded
-int64_t SymmOperationProfiler::SymmProblem::bytes(library::SymmDescription const &operation_desc) const {
-  int64_t bytes;
-  // Input bytes read and Output bytes written for the gemm problem
-  // Half matrix including the diagonal will have (X*(X+1))/2 elements
-  if (operation_desc.side_mode == SideMode::kLeft) {
-    bytes =
-      int64_t(library::sizeof_bits(operation_desc.A.element) * m / 8) * (m + 1) / 2 +
-      int64_t(library::sizeof_bits(operation_desc.B.element) * m / 8) * n + 
-      int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
-  } else if (operation_desc.side_mode == SideMode::kRight) {
-    bytes =
-      int64_t(library::sizeof_bits(operation_desc.A.element) * n / 8) * (n + 1) / 2 +
-      int64_t(library::sizeof_bits(operation_desc.B.element) * m / 8) * n + 
-      int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
-  }
-  // Set is_beta_zero true if beta is zero
-  bool is_beta_zero = std::all_of(beta.begin(), beta.end(), [](uint8_t i) { return i==0; });
-
-  // Output bytes read for the gemm problem for non-zero beta values
-  if (!is_beta_zero) {
-    bytes += int64_t(library::sizeof_bits(operation_desc.C.element) * m / 8) * n;
-  }
-
-  bytes *= batch_count;
-
-  return bytes;
-}
-
-/// Total number of flops computed
-int64_t SymmOperationProfiler::SymmProblem::flops(library::SymmDescription const &operation_desc) const {
-
-  // FLOPs for first TRMM kernel (with diagonal) = 2 * [ ( M * (M+1)/2 * N ) ] // Beta is zero
-  // FLOPs for second TRMM kernel (with diagonal) = 2 * [ ( M * (M-1)/2 * N ) ] // Beta is zero
-  // FLOPs = m*(m+1)*n [mma1] + m*(m-1)*n [mma2] + 2*m*n [epilogue]
-  // FLOPs = 2*m*n(m+1) for left side mode
-  // FLOPs can also be calculated to be same as GEMM with correct value for 'k' as below.
-  int64_t k = (operation_desc.side_mode == SideMode::kLeft) ? int64_t(m) : int64_t(n);
-  int64_t flops_ = (int64_t(m) * n * k + m * n) * 2;
-
-  // complex-valued support
-  switch (operation_desc.tile_description.math_instruction.math_operation) {
-  case library::MathOperationID::kMultiplyAddComplex:
-    flops_ *= 4;
-    break;
-    
-  case library::MathOperationID::kMultiplyAddComplexFastF32:
-    flops_ *= 4;
-    break;
-
-  case library::MathOperationID::kMultiplyAddGaussianComplex:
-    flops_ *= 3;
-    break;
-
-  default: break;
-  }
-
-  return flops_;
-}
-
 /// Initializes a performance result
-void SymmOperationProfiler::SymmProblem::initialize_result(
+void TrmmOperationProfiler::TrmmProblem::initialize_result(
   PerformanceResult &result,
-  library::SymmDescription const &operation_desc,
+  library::TrmmDescription const &operation_desc,
   ProblemSpace const &problem_space) {
 
   result.arguments.resize(problem_space.rank());
 
-  set_argument(result, "symm_kind", problem_space, library::to_string(operation_desc.symm_kind));
+  set_argument(result, "trmm_kind", problem_space, library::to_string(operation_desc.trmm_kind));
 
   set_argument(result, "A", problem_space,
     std::string(library::to_string(operation_desc.A.element)) + ":" + library::to_string(operation_desc.A.layout));
 
-  set_argument(result, "B", problem_space,
-    std::string(library::to_string(operation_desc.B.element)) + ":" + library::to_string(operation_desc.B.layout));
-
-  set_argument(result, "C", problem_space,
-    std::string(library::to_string(operation_desc.C.element)) + ":" + library::to_string(operation_desc.C.layout));
-
   set_argument(result, "side_mode", problem_space, library::to_string(operation_desc.side_mode));
 
   set_argument(result, "fill_mode", problem_space, library::to_string(operation_desc.fill_mode));
 
-  set_argument(result, "blas_mode", problem_space, library::to_string(operation_desc.blas_mode));
+  set_argument(result, "diag_type", problem_space, library::to_string(operation_desc.diag_type));
+
+  set_argument(result, "B", problem_space,
+    std::string(library::to_string(operation_desc.B.element)) + ":" + library::to_string(operation_desc.B.layout));
+
+  set_argument(result, "D", problem_space,
+    std::string(library::to_string(operation_desc.D.element)) + ":" + library::to_string(operation_desc.D.layout));
 
   set_argument(result, "m", problem_space, m);
   set_argument(result, "n", problem_space, n);
 
   set_argument(result, "split_k_slices", problem_space, split_k_slices);
   set_argument(result, "batch_count", problem_space, batch_count);
 
@@ -329,205 +260,217 @@
   set_argument(result, "beta", problem_space,
     library::lexical_cast(beta, operation_desc.element_epilogue));
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Extracts the problem dimensions
-Status SymmOperationProfiler::initialize_configuration(
+Status TrmmOperationProfiler::initialize_configuration(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
-  library::SymmDescription const &operation_desc = 
-    static_cast<library::SymmDescription const &>(operation->description());
+  library::TrmmDescription const &operation_desc = 
+    static_cast<library::TrmmDescription const &>(operation->description());
 
-  if (operation_desc.symm_kind != library::SymmKind::kUniversal) {
+  if (operation_desc.trmm_kind != library::TrmmKind::kUniversal) {
     return Status::kErrorInvalidProblem;
   }
 
   Status status = problem_.parse(operation_desc, problem_space, problem);
   
   if (status != Status::kSuccess) {
     return status;
   }
 
-  symm_workspace_.configuration.problem_size.m() = int(problem_.m);
-  symm_workspace_.configuration.problem_size.n() = int(problem_.n);
-  symm_workspace_.configuration.problem_size.k() = (operation_desc.side_mode == SideMode::kLeft) 
+  trmm_workspace_.configuration.problem_size.m() = int(problem_.m);
+  trmm_workspace_.configuration.problem_size.n() = int(problem_.n);
+  trmm_workspace_.configuration.problem_size.k() = (operation_desc.side_mode == SideMode::kLeft) 
                                                     ? int(problem_.m) : int(problem_.n);
-  symm_workspace_.configuration.lda = problem_.lda;
-  symm_workspace_.configuration.ldb = problem_.ldb;
-  symm_workspace_.configuration.ldc = problem_.ldc;
-  symm_workspace_.configuration.ldd = problem_.ldc;
-  //symm_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
-  symm_workspace_.configuration.batch_count = int(problem_.split_k_slices);
-
-  symm_workspace_.arguments.A = nullptr;
-  symm_workspace_.arguments.B = nullptr;
-  symm_workspace_.arguments.C = nullptr;
-  symm_workspace_.arguments.D = nullptr;
-  symm_workspace_.arguments.alpha = problem_.alpha.data();
-  symm_workspace_.arguments.beta = problem_.beta.data();
-  symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+  trmm_workspace_.configuration.lda = problem_.lda;
+  trmm_workspace_.configuration.ldb = problem_.ldb;
+  trmm_workspace_.configuration.ldd = problem_.ldd;
+  //trmm_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
+  trmm_workspace_.configuration.batch_count = int(problem_.split_k_slices);
+
+  trmm_workspace_.arguments.A = nullptr;
+  trmm_workspace_.arguments.B = nullptr;
+  trmm_workspace_.arguments.D = nullptr;
+  trmm_workspace_.arguments.alpha = problem_.alpha.data();
+  trmm_workspace_.arguments.beta = problem_.beta.data();
+  trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   initialize_result_(this->model_result_, options, operation_desc, problem_space);
   
-  return operation->can_implement(&symm_workspace_.configuration, &symm_workspace_.arguments);
+  return operation->can_implement(&trmm_workspace_.configuration, &trmm_workspace_.arguments);
 }
 
 /// Initializes the performance result
-void SymmOperationProfiler::initialize_result_(
+void TrmmOperationProfiler::initialize_result_(
   PerformanceResult &result,
   Options const &options,  
-  library::SymmDescription const &operation_desc,
+  library::TrmmDescription const &operation_desc,
   ProblemSpace const &problem_space) {
 
   result.provider = library::Provider::kCUTLASS;
   result.disposition = Disposition::kNotRun;
   result.status = Status::kSuccess;
   result.operation_name = operation_desc.name;
   
   problem_.initialize_result(result, operation_desc, problem_space);
 
   OperationProfiler::initialize_result_(result, operation_desc, problem_space);
 
+  if (operation_desc.side_mode == SideMode::kLeft) {
+    // Input bytes read and Output bytes written for the trmm problem
+    result.bytes = 
+      // Half matrix including the diagonal will have (M*(M+1))/2 elements
+      int64_t(library::sizeof_bits(operation_desc.A.element) * problem_.m / 8) * (problem_.m + 1) / 2 +
+      int64_t(library::sizeof_bits(operation_desc.B.element) * problem_.m / 8) * problem_.n + 
+      int64_t(library::sizeof_bits(operation_desc.D.element) * problem_.m / 8) * problem_.n;
+  } else if (operation_desc.side_mode == SideMode::kRight) {
+    // Input bytes read and Output bytes written for the trmm problem
+    result.bytes = 
+      // Half matrix including the diagonal will have (N*(N+1))/2 elements
+      int64_t(library::sizeof_bits(operation_desc.A.element) * problem_.n / 8) * (problem_.n + 1) / 2 +
+      int64_t(library::sizeof_bits(operation_desc.B.element) * problem_.m / 8) * problem_.n + 
+      int64_t(library::sizeof_bits(operation_desc.D.element) * problem_.m / 8) * problem_.n;
+  }
 
-  result.bytes = problem_.bytes(operation_desc);
-  result.flops = problem_.flops(operation_desc);
-  result.runtime = 0;
+  // FLOPs = 2 * [ ( M * (M+1)/2 * N ) ] // Beta is zero
+  result.flops = problem_.m * (problem_.m + 1) * problem_.n;
+ 
+   result.runtime = 0;
 
+  // complex-valued support
+  switch (operation_desc.tile_description.math_instruction.math_operation) {
+  case library::MathOperationID::kMultiplyAddComplex:
+    result.flops *= 4;
+    break;
+    
+  case library::MathOperationID::kMultiplyAddComplexFastF32:
+    result.flops *= 4;
+    break;
+ 
+  default: break;
+  }
 
 }
 
 /// Initializes workspace
-Status SymmOperationProfiler::initialize_workspace(
+Status TrmmOperationProfiler::initialize_workspace(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
   
-  library::SymmDescription const &operation_desc = 
-    static_cast<library::SymmDescription const &>(operation->description());
+  library::TrmmDescription const &operation_desc = 
+    static_cast<library::TrmmDescription const &>(operation->description());
 
   if (options.execution_mode != ExecutionMode::kDryRun) {
     int seed_shift = 0;
     if (operation_desc.side_mode == SideMode::kLeft) {
-      symm_workspace_.A = device_context.allocate_tensor(
+      trmm_workspace_.A = device_context.allocate_tensor(
         options,
         "A",
         operation_desc.A.element,
         operation_desc.A.layout,
         {int(problem_.m), int(problem_.m)},
         {int(problem_.lda)},
         1, // batch_count
         seed_shift++
       );
     } else if (operation_desc.side_mode == SideMode::kRight) {
-      symm_workspace_.A = device_context.allocate_tensor(
+      trmm_workspace_.A = device_context.allocate_tensor(
         options,
         "A",
         operation_desc.A.element,
         operation_desc.A.layout,
         {int(problem_.n), int(problem_.n)},
         {int(problem_.lda)},
         1, // batch_count
         seed_shift++
       );
     }
 
-    symm_workspace_.B = device_context.allocate_tensor(
+    trmm_workspace_.B = device_context.allocate_tensor(
       options,
       "B",
       operation_desc.B.element,
       operation_desc.B.layout,
       {int(problem_.m), int(problem_.n)},
       {int(problem_.ldb)},
       1, // batch_count
       seed_shift++
     );
 
-    symm_workspace_.C = device_context.allocate_tensor(
-      options,
-      "C",
-      operation_desc.C.element,
-      operation_desc.C.layout,
-      {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldc)},
-      1, // batch_count
-      seed_shift++
-    );
-
-    symm_workspace_.Computed = device_context.allocate_tensor(
+    trmm_workspace_.Computed = device_context.allocate_tensor(
       "D",
-      operation_desc.C.element,
-      operation_desc.C.layout,
+      operation_desc.D.element,
+      operation_desc.D.layout,
       {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldc)}
+      {int(problem_.ldd)}
     );
 
-    symm_workspace_.Reference = device_context.allocate_tensor(
+    trmm_workspace_.Reference = device_context.allocate_tensor(
       "Reference",
-      operation_desc.C.element,
-      operation_desc.C.layout,
+      operation_desc.D.element,
+      operation_desc.D.layout,
       {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldc)}
+      {int(problem_.ldd)}
     );
 
-    symm_workspace_.Computed->copy_from_device(symm_workspace_.C->data());
-    symm_workspace_.Reference->copy_from_device(symm_workspace_.C->data());
   }
 
-
   //
   // Initialize the CUTLASS operation
   //
   Status status = Status::kSuccess;
 
   if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
     if (options.execution_mode != ExecutionMode::kDryRun) {
 
-      uint64_t workspace_size = operation->get_host_workspace_size(&symm_workspace_.configuration);
-      symm_workspace_.host_workspace.resize(workspace_size, 0);
+      uint64_t workspace_size = operation->get_host_workspace_size(&trmm_workspace_.configuration);
+      trmm_workspace_.host_workspace.resize(workspace_size, 0);
 
-      workspace_size = operation->get_device_workspace_size(&symm_workspace_.configuration);
-      symm_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
+      workspace_size = operation->get_device_workspace_size(&trmm_workspace_.configuration);
+      trmm_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
 
       status = operation->initialize(
-        &symm_workspace_.configuration,
-        symm_workspace_.host_workspace.data(),
-        symm_workspace_.device_workspace.data());
+        &trmm_workspace_.configuration,
+        trmm_workspace_.host_workspace.data(),
+        trmm_workspace_.device_workspace.data());
     }
 
     //
     // If CUTLASS is enabled, generate a result for it
     //
     results_.push_back(model_result_);
     results_.back().provider = library::Provider::kCUTLASS;
-    results_.back().op_kind = library::OperationKind::kSymm;
+    results_.back().op_kind = library::OperationKind::kTrmm;
     results_.back().disposition = Disposition::kNotRun;
 
     for(auto provider : verification_providers_) {
       results_.back().verification_map[provider] = Disposition::kNotRun;
     }
   }
 
   return status;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Verifies CUTLASS against references
-bool SymmOperationProfiler::verify_cutlass(
+bool TrmmOperationProfiler::verify_cutlass(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
@@ -535,31 +478,30 @@
     return true;
   }
 
   if (options.execution_mode == ExecutionMode::kDryRun) {
     return true;
   }
 
-  // Initialize structure containing Symm arguments
-  symm_workspace_.arguments.A = symm_workspace_.A->data();
-  symm_workspace_.arguments.B = symm_workspace_.B->data();
-  symm_workspace_.arguments.C = symm_workspace_.C->data();
-  symm_workspace_.arguments.D = symm_workspace_.Computed->data();
-  symm_workspace_.arguments.alpha = problem_.alpha.data();
-  symm_workspace_.arguments.beta = problem_.beta.data();
-  symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+  // Initialize structure containing TRMM arguments
+  trmm_workspace_.arguments.A = trmm_workspace_.A->data();
+  trmm_workspace_.arguments.B = trmm_workspace_.B->data();
+  trmm_workspace_.arguments.D = trmm_workspace_.Computed->data();
+  trmm_workspace_.arguments.alpha = problem_.alpha.data();
+  trmm_workspace_.arguments.beta = problem_.beta.data();
+  trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   //
   // Run the CUTLASS operation
   //
 
   results_.back().status = operation->run(
-    &symm_workspace_.arguments, 
-    symm_workspace_.host_workspace.data(),
-    symm_workspace_.device_workspace.data());
+    &trmm_workspace_.arguments, 
+    trmm_workspace_.host_workspace.data(),
+    trmm_workspace_.device_workspace.data());
 
   if (results_.back().status != Status::kSuccess) {
     results_.back().disposition = Disposition::kFailed;
     return false;
   }
 
   cudaError_t result = cudaDeviceSynchronize();
@@ -577,17 +519,17 @@
 
   if (options.verification.enabled) {
 
 #if CUTLASS_ENABLE_CUBLAS
     if (options.verification.provider_enabled(library::Provider::kCUBLAS)) {
 
       // Guard against unsupported cases
-      auto const & symm_desc = static_cast<library::SymmDescription const &>(operation->description());
+      auto const & trmm_desc = static_cast<library::TrmmDescription const &>(operation->description());
 
-      if (cublas_satisfies(symm_desc) == Status::kSuccess) {
+      if (cublas_satisfies(trmm_desc) == Status::kSuccess) {
 
         // call cublas verification if supported
         verify_with_cublas_(
           options,
           report,
           device_context,
           operation,
@@ -623,27 +565,27 @@
   // Return true means continue profiling
   return true;
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Verifies CUTLASS against references
-bool SymmOperationProfiler::verify_with_cublas_(
+bool TrmmOperationProfiler::verify_with_cublas_(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
 
 #if CUTLASS_ENABLE_CUBLAS
 
-  library::SymmDescription const &symm_desc = 
-    static_cast<library::SymmDescription const &>(operation->description());
+  library::TrmmDescription const &trmm_desc = 
+    static_cast<library::TrmmDescription const &>(operation->description());
 
   //
   // Construct cuBLAS operators
   //
     
   CublasCreate handle;
   cublasStatus_t status = handle.get_cublas_create_status();
@@ -657,66 +599,64 @@
   //
   // Initialize state
   //
 
   try {
 
     //
-    // Construct dispatcher to cublas<t>Symm()
+    // Construct dispatcher to cublas<t>Trmm()
     //
 
-    // Initialize structure containing Symm arguments
-    symm_workspace_.arguments.A = symm_workspace_.A->data();
-    symm_workspace_.arguments.B = symm_workspace_.B->data();
-    symm_workspace_.arguments.C = symm_workspace_.Reference->data();
-    symm_workspace_.arguments.D = symm_workspace_.Reference->data();
-    symm_workspace_.arguments.alpha = problem_.alpha.data();
-    symm_workspace_.arguments.beta = problem_.beta.data();
-    symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
-
-    detail::cublasSymmDispatcher symm_op( 
-      symm_desc, 
-      symm_workspace_.configuration,
-      symm_workspace_.arguments
+    // Initialize structure containing TRMM arguments
+    trmm_workspace_.arguments.A = trmm_workspace_.A->data();
+    trmm_workspace_.arguments.B = trmm_workspace_.B->data();
+    trmm_workspace_.arguments.D = trmm_workspace_.Reference->data();
+    trmm_workspace_.arguments.alpha = problem_.alpha.data();
+    trmm_workspace_.arguments.beta = problem_.beta.data();
+    trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+
+    detail::cublasTrmmDispatcher trmm_op( 
+      trmm_desc, 
+      trmm_workspace_.configuration,
+      trmm_workspace_.arguments
     );
 
-    if (symm_op.status != Status::kSuccess) {
+    if (trmm_op.status != Status::kSuccess) {
       results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotRun;
       return true;
     }
 
     results_.back().status = Status::kSuccess;
 
-    status = symm_op(handle);
+    status = trmm_op(handle);
 
     // Handle errors
     if (status != CUBLAS_STATUS_SUCCESS) {
 
       results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
       return true;
     }
 
     //
     // Verify results
     //
-
     results_.back().verification_map[library::Provider::kCUBLAS] = compare_tensors(
       options,
-      *symm_workspace_.Computed,
-      *symm_workspace_.Reference
+      *trmm_workspace_.Computed,
+      *trmm_workspace_.Reference
     );
 
     // Save workspace if incorrect
     if (options.verification.save_workspace == SaveWorkspace::kIncorrect && 
       results_.back().verification_map[library::Provider::kCUBLAS] == Disposition::kIncorrect) {
 
       save_workspace(
         device_context,
         options,
-        symm_desc,
+        trmm_desc,
         library::Provider::kCUTLASS,
         library::Provider::kCUBLAS);
     }
   }
   catch (...) {
     results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
   }
@@ -726,40 +666,39 @@
   // Return true means continue profiling
   return true;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Measures performance results
-bool SymmOperationProfiler::profile(
+bool TrmmOperationProfiler::profile(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
 
   if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
-    // Initialize structure containing Symm arguments
-    symm_workspace_.arguments.A = symm_workspace_.A->data();
-    symm_workspace_.arguments.B = symm_workspace_.B->data();
-    symm_workspace_.arguments.C = symm_workspace_.C->data();
-    symm_workspace_.arguments.D = symm_workspace_.Computed->data();
-    symm_workspace_.arguments.alpha = problem_.alpha.data();
-    symm_workspace_.arguments.beta = problem_.beta.data();
-    symm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+    // Initialize structure containing TRMM arguments
+    trmm_workspace_.arguments.A = trmm_workspace_.A->data();
+    trmm_workspace_.arguments.B = trmm_workspace_.B->data();
+    trmm_workspace_.arguments.D = trmm_workspace_.Computed->data();
+    trmm_workspace_.arguments.alpha = problem_.alpha.data();
+    trmm_workspace_.arguments.beta = problem_.beta.data();
+    trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
     results_.back().status = profile_cutlass_(
       results_.back().runtime,
       options,
       operation,
-      &symm_workspace_.arguments,
-      symm_workspace_.host_workspace.data(),
-      symm_workspace_.device_workspace.data()
+      &trmm_workspace_.arguments,
+      trmm_workspace_.host_workspace.data(),
+      trmm_workspace_.device_workspace.data()
     );
   }
   return true;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/profiler/src/operation_profiler.cu`

 * *Files 21% similar despite different names*

```diff
@@ -25,684 +25,780 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief Execution environment
-
-  
+   \brief Defines a math function
 */
 
-#include <iostream>
+#include <algorithm>
 #include <stdexcept>
 #include <iomanip>
-#include <ios>
-
-#include "cutlass/core_io.h"
+#include <cstring>
+#include <fstream>
+#include <sstream>
+
+#ifdef __unix__
+#include <unistd.h>
+#elif defined(_WIN32) || defined(WIN32)
+#include <windows.h>
+#else
+// sleep not supported
+#endif
 
-#include "cutlass/profiler/cublas_helpers.h"
-#include "cutlass/profiler/trmm_operation_profiler.h"
+#include "cutlass/profiler/options.h"
+#include "cutlass/profiler/operation_profiler.h"
 #include "cutlass/profiler/gpu_timer.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/trace.h"
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace profiler {
 
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+OperationProfiler::OperationProfiler(): kind_(library::OperationKind::kInvalid) { }
 
 /// Ctor
-TrmmOperationProfiler::TrmmOperationProfiler(Options const &options): 
-  OperationProfiler(
-    options,
-    library::OperationKind::kTrmm,
-    {
-      {ArgumentTypeID::kEnumerated, {"trmm_kind"}, "Variant of TRMM (universal)"},
-      {ArgumentTypeID::kInteger, {"m", "problem-size::m"}, "M dimension of the TRMM problem space"},
-      {ArgumentTypeID::kInteger, {"n", "problem-size::n"}, "N dimension of the TRMM problem space"},
-      {ArgumentTypeID::kTensor, {"A"}, "Tensor storing the A operand"},
-      {ArgumentTypeID::kEnumerated, {"side_mode"}, "Side Mode for TRMM (left, right)"},
-      {ArgumentTypeID::kEnumerated, {"fill_mode"}, "Fill Mode for TRMM (lower, upper)"},
-      {ArgumentTypeID::kEnumerated, {"diag_type"}, "Diag Type for TRMM (nonunit, unit)"},
-      {ArgumentTypeID::kTensor, {"B"}, "Tensor storing the B operand"},
-      {ArgumentTypeID::kTensor, {"D"}, "Tensor storing the D operand"},
-      {ArgumentTypeID::kScalar, {"alpha", "epilogue::alpha"}, "Epilogue scalar alpha"},
-      {ArgumentTypeID::kScalar, {"beta", "epilogue::beta"}, "Epilogue scalar beta"},
-      {ArgumentTypeID::kInteger, {"split_k_slices", "split-k-slices"}, "Number of partitions of K dimension"},
-      {ArgumentTypeID::kInteger, {"batch_count", "batch-count"}, "Number of TRMMs computed in one batch"},
-    },
-    { library::Provider::kCUBLAS}
-  ) {
-  description_ = "      Triangular Matrix-Multiplication. D = alpha * A * B or alpha * B * A";
+OperationProfiler::OperationProfiler(
+  Options const &options,
+  library::OperationKind kind,
+  ArgumentDescriptionVector const &arguments,
+  ProviderVector const & verification_providers
+):
+  kind_(kind), arguments_(arguments) {
+
+  ArgumentDescriptionVector tile_description_arguments{
+    {ArgumentTypeID::kEnumerated, {"op_class", "opcode-class"}, "Class of math instruction (simt, tensorop, wmmatensorop, wmma)"},
+    {ArgumentTypeID::kEnumerated, {"accum", "accumulator-type"}, "Math instruction accumulator data type"},
+    {ArgumentTypeID::kInteger, {"cta_m", "threadblock-shape::m"}, "Threadblock shape in the M dimension"},
+    {ArgumentTypeID::kInteger, {"cta_n", "threadblock-shape::n"}, "Threadblock shape in the N dimension"},
+    {ArgumentTypeID::kInteger, {"cta_k", "threadblock-shape::k"}, "Threadblock shape in the K dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_m", "cluster-shape::m"}, "Cluster shape in the M dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_n", "cluster-shape::n"}, "Cluster shape in the N dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_k", "cluster-shape::k"}, "Cluster shape in the K dimension"},
+    {ArgumentTypeID::kInteger, {"stages", "threadblock-stages"}, "Number of stages of threadblock-scoped matrix multiply"},
+    {ArgumentTypeID::kInteger, {"warps_m", "warp-count::m"}, "Number of warps within threadblock along the M dimension"},
+    {ArgumentTypeID::kInteger, {"warps_n", "warp-count::n"}, "Number of warps within threadblock along the N dimension"},
+    {ArgumentTypeID::kInteger, {"warps_k", "warp-count::k"}, "Number of warps within threadblock along the K dimension"},
+    {ArgumentTypeID::kInteger, {"inst_m", "instruction-shape::m"}, "Math instruction shape in the M dimension"},
+    {ArgumentTypeID::kInteger, {"inst_n", "instruction-shape::n"}, "Math instruction shape in the N dimension"},
+    {ArgumentTypeID::kInteger, {"inst_k", "instruction-shape::k"}, "Math instruction shape in the K dimension"},
+    {ArgumentTypeID::kInteger, {"min_cc", "minimum-compute-capability"}, "Minimum device compute capability"},
+    {ArgumentTypeID::kInteger, {"max_cc", "maximum-compute-capability"}, "Maximum device compute capability"}
+  };
+
+  arguments_.insert(arguments_.end(), tile_description_arguments.begin(), tile_description_arguments.end());
+
+  for (auto provider : verification_providers) {
+    if (std::find(
+      options.verification.providers.begin(),
+      options.verification.providers.end(),
+      provider) != options.verification.providers.end()) {
+
+      verification_providers_.push_back(provider);
+    }
+  }
+
 }
 
 /// Destructor
-TrmmOperationProfiler::~TrmmOperationProfiler() {
+OperationProfiler::~OperationProfiler() {}
 
+/// Gets the schema description
+std::string const & OperationProfiler::description() const {
+  return description_;
 }
 
 /// Prints usage statement for the math function
-void TrmmOperationProfiler::print_usage(std::ostream &out) const {
-  out << "TRMM" << "\n\n";
+void OperationProfiler::print_usage(std::ostream &out) const {
+  for (auto const & desc : arguments_) {
 
-  OperationProfiler::print_usage(out);
-}
+    size_t const kAliasStart = 10;
 
-/// Prints examples
-void TrmmOperationProfiler::print_examples(std::ostream &out) const {
+    size_t columns = 0;
 
-  out << "\nExamples:\n\n"
-    << "Profile a particular problem size:\n"
-    << "  $ cutlass_profiler --operation=Trmm --n=1024 --m=128\n\n"
+    std::string type_str = to_string(desc.type);
+    columns += type_str.size();
 
-    << "Schmoo over problem size and beta:\n"
-    << "  $ cutlass_profiler --operation=Trmm --n=1024:4096:256 --m=128:8192:128 --beta=0,1,2.5\n\n"
+    out << "  [" << type_str << "]";
 
-    << "Schmoo over accumulator types:\n"
-    << "  $ cutlass_profiler --operation=Trmm --accumulator-type=f16,f32\n\n"
+    if (columns < kAliasStart) {
+      out << std::string(kAliasStart - columns, ' ');
+    }
 
-    << "Run when A is f16 with column-major or A is any datatype with row-major (For column major, use column, col, or n. For row major use, row or t):\n"
-    << "  $ cutlass_profiler --operation=Trmm --A=f16:column or --A=*:row\n\n"
+    columns = 0;
 
-    << "Using various input value distribution:\n"
-    << "  $ cutlass_profiler --operation=Trmm --dist=uniform,min:0,max:3\n"
-    << "  $ cutlass_profiler --operation=Trmm --dist=gaussian,mean:0,stddev:3\n"
-    << "  $ cutlass_profiler --operation=Trmm --dist=sequential,start:0,delta:1\n\n"
+    int j = 0;
+    for (auto const & alias : desc.aliases) {
+      columns += alias.size() + (j ? 1 : 0) + 2;
 
-    << "Run a kernel with cta tile size of 256x128x32 and save workspace if results are incorrect (note that --cta-tile::k=32 is default cta-tile size):\n"
-    << " $ cutlass_profiler --operation=Trmm --cta_m=256 --cta_n=128  --cta_k=32 --save-workspace=incorrect\n\n"
-    
-    << "Test your changes to trmm kernels with a quick functional test and save results in functional-test.csv:\n"
-    << " $ cutlass_profiler  --operation=Trmm \\ \n"
-    << "   --n=8,56,120,136,256,264,512,520,1024,1032,4096,8192,16384 \\ \n"
-    << "   --k=8,16,32,64,128,256,288,384,504,512,520 \\ \n"
-    << "   --beta=0,1,2 --profiling-iterations=1 \\ \n"
-    << "   --providers=cutlass --output=functional-test.csv\n\n";
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+      out << (j++ ? "," : "") << "--" << alias;
+    }
 
-#if 0
-// used this for debugging
-static std::string byte_string(std::vector<uint8_t> const &bytes) {
-  std::stringstream ss;
+    size_t const kTotalColumns = 50;
 
-  ss << "0x";
+    if (columns < kTotalColumns) {
+      out << std::string(kTotalColumns - columns, ' ');
+    }
 
-  for (size_t idx = bytes.size(); idx > 0; --idx) {
-    ss << std::hex << std::setw(2) << std::setfill('0') << uint32_t(bytes.at(idx - 1));
+    out << desc.description << "\n";
   }
-
-  return ss.str();
 }
-#endif
 
-Status TrmmOperationProfiler::TrmmProblem::parse(
-  library::TrmmDescription const &operation_desc,
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Returns true if the current operation description satisfies the problem space
+bool OperationProfiler::satisfies(
+  library::OperationDescription const &op_desc,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
-  
-  if (!arg_as_int(this->m, "m", problem_space, problem)) {
-    // default value
-    this->m = 1024;
+
+  library::OpcodeClassID opcode_class;
+  if (arg_as_OpcodeClassID(opcode_class, "op_class", problem_space, problem)) {
+    if (opcode_class != op_desc.tile_description.math_instruction.opcode_class) {
+      return false;
+    }
   }
-  
-  if (!arg_as_int(this->n, "n", problem_space, problem)) {
-    // default value
-    this->n = 1024;
+  int64_t int_value;
+
+  if (arg_as_int(int_value, "inst_m", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.m()) != int_value) {
+      return false;
+    }
   }
-  
-  if (!arg_as_int(this->split_k_slices, "split_k_slices", problem_space, problem)) {
-    // default value
-    this->split_k_slices = 1;
+
+  if (arg_as_int(int_value, "inst_n", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.n()) != int_value) {
+      return false;
+    }
   }
-  
-  if (!arg_as_int(this->batch_count, "batch_count", problem_space, problem)) {
-    // default value
-    this->batch_count = 1;
+
+  if (arg_as_int(int_value, "inst_k", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.math_instruction.instruction_shape.k()) != int_value) {
+      return false;
+    }
   }
 
-  if (this->split_k_slices > 1 && this->batch_count > 1) {
-    // At least one of these must be one
-    return Status::kErrorInvalidProblem;
+  if (arg_as_int(int_value, "cta_m", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.threadblock_shape.m()) != int_value) {
+      return false;
+    }
   }
 
-  if (!tensor_description_satisfies(operation_desc.A, "A", problem_space, problem)) {
-    return Status::kErrorInvalidProblem;
+  if (arg_as_int(int_value, "cta_n", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.threadblock_shape.n()) != int_value) {
+      return false;
+    }
   }
 
-  if (!tensor_description_satisfies(operation_desc.B, "B", problem_space, problem)) {
-    return Status::kErrorInvalidProblem;
+  if (arg_as_int(int_value, "cta_k", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.threadblock_shape.k()) != int_value) {
+      return false;
+    }
   }
 
-  if (!tensor_description_satisfies(operation_desc.D, "D", problem_space, problem)) {
-    return Status::kErrorInvalidProblem;
+  if (arg_as_int(int_value, "cluster_m", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.m()) != int_value) {
+      return false;
+    }
   }
 
-  if (!arg_as_scalar(
-    this->alpha, 
-    operation_desc.element_epilogue, 
-    "alpha", 
-    problem_space, 
-    problem)) {
+  if (arg_as_int(int_value, "cluster_n", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.n()) != int_value) {
+      return false;
+    }
+  }
 
-    if (!cast_from_double(this->alpha, operation_desc.element_epilogue, 1)) {
-      return Status::kErrorInternal;
+  if (arg_as_int(int_value, "cluster_k", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.k()) != int_value) {
+      return false;
     }
   }
-  
-  if (!arg_as_scalar(
-    this->beta, 
-    operation_desc.element_epilogue, 
-    "beta", 
-    problem_space, 
-    problem)) {
-    
-    if (!cast_from_double(this->beta, operation_desc.element_epilogue, 0)) {
-      return Status::kErrorInternal;
+
+  if (arg_as_int(int_value, "stages", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.threadblock_stages) != int_value) {
+      return false;
     }
   }
-  
-  if (operation_desc.side_mode == SideMode::kLeft) {
-    this->lda = DeviceAllocation::get_packed_layout(
-      operation_desc.A.layout, {int(this->m), int(this->m)}).front();
+
+  if (arg_as_int(int_value, "warps_m", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.warp_count.m()) != int_value) {
+      return false;
+    }
   }
-  else if (operation_desc.side_mode == SideMode::kRight) {
-    this->lda = DeviceAllocation::get_packed_layout(
-      operation_desc.A.layout, {int(this->n), int(this->n)}).front();
+
+  if (arg_as_int(int_value, "warps_n", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.warp_count.n()) != int_value) {
+      return false;
+    }
   }
 
-  this->ldb = DeviceAllocation::get_packed_layout(
-    operation_desc.B.layout, {int(this->m), int(this->n)}).front();
+  if (arg_as_int(int_value, "warps_k", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.warp_count.k()) != int_value) {
+      return false;
+    }
+  }
 
-  this->ldd = DeviceAllocation::get_packed_layout(
-    operation_desc.D.layout, {int(this->m), int(this->n)}).front();
+  library::NumericTypeID numeric_type;
+  if (arg_as_NumericTypeID(numeric_type, "accum", problem_space, problem)) {
+    if (numeric_type != op_desc.tile_description.math_instruction.element_accumulator) {
+      return false;
+    }
+  }
 
-  return Status::kSuccess;
+  return true;
 }
 
-/// Initializes a performance result
-void TrmmOperationProfiler::TrmmProblem::initialize_result(
-  PerformanceResult &result,
-  library::TrmmDescription const &operation_desc,
-  ProblemSpace const &problem_space) {
+#if defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
+
+std::ostream& operator<<(std::ostream& out, library::Provider provider) {
+  if (provider == library::Provider::kNone) {
+    out << "kNone";
+  }
+  else if (provider == library::Provider::kCUTLASS) {
+    out << "kCUTLASS";
+  }
+  else if (provider == library::Provider::kReferenceHost) {
+    out << "kReferenceHost";
+  }
+  else if (provider == library::Provider::kReferenceDevice) {
+    out << "kReferenceDevice";
+  }
+  else if (provider == library::Provider::kCUBLAS) {
+    out << "kCUBLAS";
+  }
+  else if (provider == library::Provider::kCUDNN) {
+    out << "kCUDNN";
+  }
+  else {
+    out << "kInvalid";
+  }
 
-  result.arguments.resize(problem_space.rank());
+  return out;
+}
 
-  set_argument(result, "trmm_kind", problem_space, library::to_string(operation_desc.trmm_kind));
+std::ostream& operator<<(std::ostream& out, library::OperationKind provider) {
+  if (provider == library::OperationKind::kGemm) {
+    out << "kGemm";
+  }
+  else if (provider == library::OperationKind::kRankK) {
+    out << "kRankK";
+  }
+  else if (provider == library::OperationKind::kRank2K) {
+    out << "kRank2K";
+  }
+  else if (provider == library::OperationKind::kTrmm) {
+    out << "kTrmm";
+  }
+  else if (provider == library::OperationKind::kSymm) {
+    out << "kSymm";
+  }
+  else if (provider == library::OperationKind::kConv2d) {
+    out << "kConv2d";
+  }
+  else if (provider == library::OperationKind::kConv3d) {
+    out << "kConv3d";
+  }
+  else if (provider == library::OperationKind::kEqGemm) {
+    out << "kEqGemm";
+  }
+  else if (provider == library::OperationKind::kSparseGemm) {
+    out << "kSparseGemm";
+  }
+  else if (provider == library::OperationKind::kReduction) {
+    out << "kReduction";
+  }
+  else {
+    out << "kInvalid";
+  }
 
-  set_argument(result, "A", problem_space,
-    std::string(library::to_string(operation_desc.A.element)) + ":" + library::to_string(operation_desc.A.layout));
+  return out;
+}
 
-  set_argument(result, "side_mode", problem_space, library::to_string(operation_desc.side_mode));
+#endif // defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
 
-  set_argument(result, "fill_mode", problem_space, library::to_string(operation_desc.fill_mode));
+/// Entry point to profile all operations in the manifest
+int OperationProfiler::profile_all(
+  Options const &options,
+  library::Manifest const &manifest,
+  DeviceContext &device_context) {
+  ProblemSpace problem_space(arguments_, options.cmdline);
 
-  set_argument(result, "diag_type", problem_space, library::to_string(operation_desc.diag_type));
+  // 1. Construct performance report
+  PerformanceReport report(options, problem_space.argument_names(), kind_);
 
-  set_argument(result, "B", problem_space,
-    std::string(library::to_string(operation_desc.B.element)) + ":" + library::to_string(operation_desc.B.layout));
+  // 2. For each problem in problem space
+  ProblemSpace::Iterator problem_it = problem_space.begin();
+  ProblemSpace::Iterator problem_end = problem_space.end();
 
-  set_argument(result, "D", problem_space,
-    std::string(library::to_string(operation_desc.D.element)) + ":" + library::to_string(operation_desc.D.layout));
+  bool continue_profiling = true;
+  int retval = 0;
 
-  set_argument(result, "m", problem_space, m);
-  set_argument(result, "n", problem_space, n);
+  // For each problem in problem space
+  for (; continue_profiling && problem_it != problem_end; ++problem_it) {
+    ProblemSpace::Problem problem = problem_it.at();
+    report.next_problem();
 
-  set_argument(result, "split_k_slices", problem_space, split_k_slices);
-  set_argument(result, "batch_count", problem_space, batch_count);
+    // For each operation in manifest
+    int matched_operation_count = 0;
+    for (auto const& operation_ptr : manifest) {
 
-  set_argument(result, "alpha", problem_space,
-    library::lexical_cast(alpha, operation_desc.element_epilogue));
+      library::Operation const *operation = operation_ptr.get();
+#if defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
+      std::cerr << "  Operation: " << typeid(*operation).name() << "\n"
+                << "    name: " << operation->description().name << "\n"
+                << "    kind: " << operation->description().kind << "\n"
+                << "    provider: " << operation->description().provider << "\n";
+#endif // CUTLASS_DEBUG_TRACE_LEVEL
 
-  set_argument(result, "beta", problem_space,
-    library::lexical_cast(beta, operation_desc.element_epilogue));
-}
+      auto min_cc = operation->description().tile_description.minimum_compute_capability;
+      auto max_cc = operation->description().tile_description.maximum_compute_capability;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#if defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
+      std::cerr << "    min_cc: " << min_cc << "\n";
+      std::cerr << "    max_cc: " << min_cc << "\n";
+#endif
 
-/// Extracts the problem dimensions
-Status TrmmOperationProfiler::initialize_configuration(
-  Options const &options,  
-  PerformanceReport &report,
-  DeviceContext &device_context,
-  library::Operation const *operation,
-  ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
+      // Clear named allocations
+      device_context.free();
 
-  library::TrmmDescription const &operation_desc = 
-    static_cast<library::TrmmDescription const &>(operation->description());
+#if defined(CUTLASS_DEBUG_TRACE_LEVEL) && (CUTLASS_DEBUG_TRACE_LEVEL > 1)
+      if (operation->description().kind != kind_) {
+        std::cerr << "    @ kind " << operation->description().kind
+                  << " != kind_ " << kind_ << "\n";
+      }
+      if (operation->description().provider != library::Provider::kCUTLASS) {
+        std::cerr << "    @ provider " << operation->description().provider
+                  << " != library::Provider::kCUTLASS\n";
+      }
+      if (options.device.compute_capability() < min_cc) {
+        std::cerr << "    @ compute_capability "
+                  << options.device.compute_capability()
+                  << " < min_cc " << min_cc << "\n";
+      }
+      if (options.device.compute_capability() > max_cc) {
+        std::cerr << "    @ compute_capability "
+                  << options.device.compute_capability()
+                  << " > max_cc " << max_cc << "\n";
+      }
+#endif
 
-  if (operation_desc.trmm_kind != library::TrmmKind::kUniversal) {
-    return Status::kErrorInvalidProblem;
-  }
+      // Execute compatible cutlass operations if they satisfy the current device's compute capability
+      if (operation->description().kind == kind_ &&
+          operation->description().provider == library::Provider::kCUTLASS &&
+          options.device.compute_capability() >= min_cc &&
+          options.device.compute_capability() <= max_cc) {
+
+        std::string operation_name(operation->description().name);
+        // Filter kernels by name
+        bool filtered_by_name = options.operation_names.empty();
+        if (!filtered_by_name) {
+
+          for (auto const & op_name : options.operation_names) {
+            if (find_string_matches_(op_name, operation_name)) {
+              filtered_by_name = true;
+              break;
+            }
+          }
+        }
 
-  Status status = problem_.parse(operation_desc, problem_space, problem);
-  
-  if (status != Status::kSuccess) {
-    return status;
-  }
-
-  trmm_workspace_.configuration.problem_size.m() = int(problem_.m);
-  trmm_workspace_.configuration.problem_size.n() = int(problem_.n);
-  trmm_workspace_.configuration.problem_size.k() = (operation_desc.side_mode == SideMode::kLeft) 
-                                                    ? int(problem_.m) : int(problem_.n);
-  trmm_workspace_.configuration.lda = problem_.lda;
-  trmm_workspace_.configuration.ldb = problem_.ldb;
-  trmm_workspace_.configuration.ldd = problem_.ldd;
-  //trmm_workspace_.configuration.split_k_slices = int(problem_.split_k_slices);
-  trmm_workspace_.configuration.batch_count = int(problem_.split_k_slices);
-
-  trmm_workspace_.arguments.A = nullptr;
-  trmm_workspace_.arguments.B = nullptr;
-  trmm_workspace_.arguments.D = nullptr;
-  trmm_workspace_.arguments.alpha = problem_.alpha.data();
-  trmm_workspace_.arguments.beta = problem_.beta.data();
-  trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
-
-  initialize_result_(this->model_result_, options, operation_desc, problem_space);
-  
-  return operation->can_implement(&trmm_workspace_.configuration, &trmm_workspace_.arguments);
-}
+        for (auto const & op_name : options.excluded_operation_names) {
+          if (find_string_matches_(op_name, operation_name)) {
+            filtered_by_name = false;
+            break;
+          }
+        }
 
-/// Initializes the performance result
-void TrmmOperationProfiler::initialize_result_(
-  PerformanceResult &result,
-  Options const &options,  
-  library::TrmmDescription const &operation_desc,
-  ProblemSpace const &problem_space) {
+        if (!filtered_by_name || !satisfies(operation->description(), problem_space, problem)) {
+          continue;
+        }
 
-  result.provider = library::Provider::kCUTLASS;
-  result.disposition = Disposition::kNotRun;
-  result.status = Status::kSuccess;
-  result.operation_name = operation_desc.name;
-  
-  problem_.initialize_result(result, operation_desc, problem_space);
-
-  OperationProfiler::initialize_result_(result, operation_desc, problem_space);
-
-  if (operation_desc.side_mode == SideMode::kLeft) {
-    // Input bytes read and Output bytes written for the trmm problem
-    result.bytes = 
-      // Half matrix including the diagonal will have (M*(M+1))/2 elements
-      int64_t(library::sizeof_bits(operation_desc.A.element) * problem_.m / 8) * (problem_.m + 1) / 2 +
-      int64_t(library::sizeof_bits(operation_desc.B.element) * problem_.m / 8) * problem_.n + 
-      int64_t(library::sizeof_bits(operation_desc.D.element) * problem_.m / 8) * problem_.n;
-  } else if (operation_desc.side_mode == SideMode::kRight) {
-    // Input bytes read and Output bytes written for the trmm problem
-    result.bytes = 
-      // Half matrix including the diagonal will have (N*(N+1))/2 elements
-      int64_t(library::sizeof_bits(operation_desc.A.element) * problem_.n / 8) * (problem_.n + 1) / 2 +
-      int64_t(library::sizeof_bits(operation_desc.B.element) * problem_.m / 8) * problem_.n + 
-      int64_t(library::sizeof_bits(operation_desc.D.element) * problem_.m / 8) * problem_.n;
-  }
-
-  // FLOPs = 2 * [ ( M * (M+1)/2 * N ) ] // Beta is zero
-  result.flops = problem_.m * (problem_.m + 1) * problem_.n;
- 
-   result.runtime = 0;
-
-  // complex-valued support
-  switch (operation_desc.tile_description.math_instruction.math_operation) {
-  case library::MathOperationID::kMultiplyAddComplex:
-    result.flops *= 4;
-    break;
-    
-  case library::MathOperationID::kMultiplyAddComplexFastF32:
-    result.flops *= 4;
-    break;
- 
-  default: break;
-  }
+        // we have found a kernel match, so increment the counter for match kernels
+        ++matched_operation_count;
 
-}
+        // A. Initialize configuration
+        Status status = this->initialize_configuration(
+          options,
+          report,
+          device_context,
+          operation,
+          problem_space,
+          problem);
 
-/// Initializes workspace
-Status TrmmOperationProfiler::initialize_workspace(
-  Options const &options,  
-  PerformanceReport &report,
-  DeviceContext &device_context,
-  library::Operation const *operation,
-  ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
-  
-  library::TrmmDescription const &operation_desc = 
-    static_cast<library::TrmmDescription const &>(operation->description());
-
-  if (options.execution_mode != ExecutionMode::kDryRun) {
-    int seed_shift = 0;
-    if (operation_desc.side_mode == SideMode::kLeft) {
-      trmm_workspace_.A = device_context.allocate_tensor(
-        options,
-        "A",
-        operation_desc.A.element,
-        operation_desc.A.layout,
-        {int(problem_.m), int(problem_.m)},
-        {int(problem_.lda)},
-        1, // batch_count
-        seed_shift++
-      );
-    } else if (operation_desc.side_mode == SideMode::kRight) {
-      trmm_workspace_.A = device_context.allocate_tensor(
-        options,
-        "A",
-        operation_desc.A.element,
-        operation_desc.A.layout,
-        {int(problem_.n), int(problem_.n)},
-        {int(problem_.lda)},
-        1, // batch_count
-        seed_shift++
-      );
-    }
-
-    trmm_workspace_.B = device_context.allocate_tensor(
-      options,
-      "B",
-      operation_desc.B.element,
-      operation_desc.B.layout,
-      {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldb)},
-      1, // batch_count
-      seed_shift++
-    );
-
-    trmm_workspace_.Computed = device_context.allocate_tensor(
-      "D",
-      operation_desc.D.element,
-      operation_desc.D.layout,
-      {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldd)}
-    );
-
-    trmm_workspace_.Reference = device_context.allocate_tensor(
-      "Reference",
-      operation_desc.D.element,
-      operation_desc.D.layout,
-      {int(problem_.m), int(problem_.n)},
-      {int(problem_.ldd)}
-    );
-
-  }
-
-  //
-  // Initialize the CUTLASS operation
-  //
-  Status status = Status::kSuccess;
-
-  if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
-
-    if (options.execution_mode != ExecutionMode::kDryRun) {
-
-      uint64_t workspace_size = operation->get_host_workspace_size(&trmm_workspace_.configuration);
-      trmm_workspace_.host_workspace.resize(workspace_size, 0);
-
-      workspace_size = operation->get_device_workspace_size(&trmm_workspace_.configuration);
-      trmm_workspace_.device_workspace.reset(library::NumericTypeID::kU8, workspace_size);
-
-      status = operation->initialize(
-        &trmm_workspace_.configuration,
-        trmm_workspace_.host_workspace.data(),
-        trmm_workspace_.device_workspace.data());
-    }
-
-    //
-    // If CUTLASS is enabled, generate a result for it
-    //
-    results_.push_back(model_result_);
-    results_.back().provider = library::Provider::kCUTLASS;
-    results_.back().op_kind = library::OperationKind::kTrmm;
-    results_.back().disposition = Disposition::kNotRun;
+        if (status == Status::kErrorInternal) {
+
+          // If there was an internal error, consume the CUDA error and move to the next operation.
+          (void)cudaGetLastError();
 
-    for(auto provider : verification_providers_) {
-      results_.back().verification_map[provider] = Disposition::kNotRun;
+          report.append_results(results_);
+          continue;
+        }
+        else if (status != Status::kSuccess) {
+          // If the workspace could not be initialized for any other reason, continue to
+          // the next operation.
+          continue;
+        }
+
+        if (continue_profiling) {
+
+          if (options.report.print_kernel_before_running) {
+            std::cout << "Profiling kernel for JUnit test " << options.report.junit_output_path << ": "
+                      << operation_name << std::endl;
+          }
+
+          status = this->initialize_workspace(
+            options,
+            report,
+            device_context,
+            operation,
+            problem_space,
+            problem);
+
+          if (status == Status::kErrorInternal) {
+
+            // If there was an internal error, consume the CUDA error and move to the next operation.
+            (void)cudaGetLastError();
+
+            report.append_results(results_);
+            continue;
+          }
+          else if (status != Status::kSuccess) {
+            // If the workspace could not be initialized for any other reason, continue to
+            // the next operation.
+            continue;
+          }
+        }
+
+        //
+        // Profile CUTLASS if it is enabled
+        //
+
+        // B. Verify CUTLASS
+        if (continue_profiling && options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
+
+          continue_profiling = this->verify_cutlass(
+            options,
+            report,
+            device_context,
+            operation,
+            problem_space,
+            problem);
+
+          retval |= (not continue_profiling);
+        }
+
+        if (options.execution_mode == ExecutionMode::kDryRun) {
+          report.append_results(results_);
+          results_.clear();
+          continue;
+        }
+
+        //
+        // C. Optionally save workspace
+        //
+
+        if (options.verification.save_workspace == SaveWorkspace::kAlways) {
+          save_workspace(
+            device_context,
+            options,
+            operation->description(),
+            library::Provider::kCUTLASS);
+        }
+
+        //
+        // D. Profile
+        //
+
+        if (continue_profiling && options.profiling.enabled) {
+
+          continue_profiling = this->profile(
+            options,
+            report,
+            device_context,
+            operation,
+            problem_space,
+            problem);
+        }
+
+        report.append_results(results_);
+        results_.clear();
+      }
+
+      if (!continue_profiling) {
+        break;
+      }
+    }
+
+    // If we did not find any kernels that match our filters and error_on_no_match was set, report an error
+    if (options.profiling.error_on_no_match && matched_operation_count <= 0) {
+      #if !NDEBUG
+      std::cout << "Error: No matching kernels found with kernel selection filters [--error_on_no_match]" << std::endl;
+      #endif
+      retval = 1;
     }
   }
 
-  return status;
+  return retval;
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Verifies CUTLASS against references
-bool TrmmOperationProfiler::verify_cutlass(
-  Options const &options,  
-  PerformanceReport &report,
-  DeviceContext &device_context,
-  library::Operation const *operation,
-  ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-  if (!options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
-    return true;
+/// Sleep for a given duration in ms
+void OperationProfiler::sleep(int sleep_duration) {
+  if (sleep_duration) {
+    #ifdef __unix__
+    usleep(sleep_duration * 1000);
+    #elif defined(_WIN32) || defined(WIN32)
+    SleepEx(sleep_duration, false);
+    #else
+    // sleep not supported
+    #endif
   }
+}
 
-  if (options.execution_mode == ExecutionMode::kDryRun) {
-    return true;
-  }
 
-  // Initialize structure containing TRMM arguments
-  trmm_workspace_.arguments.A = trmm_workspace_.A->data();
-  trmm_workspace_.arguments.B = trmm_workspace_.B->data();
-  trmm_workspace_.arguments.D = trmm_workspace_.Computed->data();
-  trmm_workspace_.arguments.alpha = problem_.alpha.data();
-  trmm_workspace_.arguments.beta = problem_.beta.data();
-  trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+/// Compares tensors for equality
+Disposition OperationProfiler::compare_tensors(
+  Options const &options,
+  DeviceAllocation &experimental,
+  DeviceAllocation &reference,
+  int64_t count) {
 
-  //
-  // Run the CUTLASS operation
-  //
+  if (experimental.type() != reference.type()) {
+    return Disposition::kIncorrect;
+  }
 
-  results_.back().status = operation->run(
-    &trmm_workspace_.arguments, 
-    trmm_workspace_.host_workspace.data(),
-    trmm_workspace_.device_workspace.data());
+  bool passed = false;
 
-  if (results_.back().status != Status::kSuccess) {
-    results_.back().disposition = Disposition::kFailed;
-    return false;
+  if (count == 0) {
+    count = reference.capacity();
   }
 
-  cudaError_t result = cudaDeviceSynchronize();
-  if (result != cudaSuccess) {
-    results_.back().disposition = Disposition::kFailed;
-    return false;
+  if (options.verification.epsilon == 0) {
+
+    // bit-level equality
+    passed = DeviceAllocation::block_compare_equal(
+      experimental.type(),
+      experimental.data(),
+      reference.data(),
+      count);
   }
+  else {
 
-  // CUTLASS op ran the but not yet verified against any verification provider
-  results_.back().disposition = Disposition::kNotVerified;
+    // relative error function
+    passed = DeviceAllocation::block_compare_relatively_equal(
+      experimental.type(),
+      experimental.data(),
+      reference.data(),
+      count,
+      options.verification.epsilon,
+      options.verification.nonzero_floor);
+  }
 
-  //
-  // Run verification providers
-  //
+  return passed ? Disposition::kPassed : Disposition::kIncorrect;
+}
 
-  if (options.verification.enabled) {
+/// Saves the workspace
+void OperationProfiler::save_workspace(
+  DeviceContext &device_context,
+  Options const &options,
+  library::OperationDescription const &desc,
+  library::Provider provider,
+  library::Provider verification_provider) {
 
-#if CUTLASS_ENABLE_CUBLAS
-    if (options.verification.provider_enabled(library::Provider::kCUBLAS)) {
+  for (auto const & named_allocation : device_context) {
 
-      // Guard against unsupported cases
-      auto const & trmm_desc = static_cast<library::TrmmDescription const &>(operation->description());
+    DeviceAllocation *allocation = named_allocation.second;
 
-      if (cublas_satisfies(trmm_desc) == Status::kSuccess) {
+    std::stringstream filename;
 
-        // call cublas verification if supported
-        verify_with_cublas_(
-          options,
-          report,
-          device_context,
-          operation,
-          problem_space,
-          problem);
-        }
+    filename << desc.name << "_" << library::to_string(provider) << "_";
 
-      else {
-        // set verification map for cublas to not supported
-        results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotSupported;
-      }
-    }
-#endif // #if CUTLASS_ENABLE_CUBLAS
-    
-    // Update disposition to worst case verification outcome among all 
-    // verification providers which are supported
-    bool is_any_verification_run_passed = false;
-    for(auto &m : results_.back().verification_map) {
-      if(m.second == Disposition::kFailed || m.second == Disposition::kIncorrect) {
-        results_.back().disposition = m.second;
-        return true;
-      }
-      if(!is_any_verification_run_passed && m.second == Disposition::kPassed) {
-        is_any_verification_run_passed = true;
-      }
+    if (verification_provider != library::Provider::kInvalid) {
+      filename << "verified_by_" << library::to_string(verification_provider) << "_";
     }
 
-    if(is_any_verification_run_passed) {
-      results_.back().disposition = Disposition::kPassed;
+    filename << named_allocation.first + ".mat";
+
+    std::ofstream out(filename.str());
+
+    allocation->write_tensor_csv(out);
+    out << "\n";
+
+    if (options.report.verbose) {
+      std::cout << "wrote '" << filename.str() << "'" << std::endl;
     }
   }
-
-  // Return true means continue profiling
-  return true;
 }
 
+
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Verifies CUTLASS against references
-bool TrmmOperationProfiler::verify_with_cublas_(
-  Options const &options,  
-  PerformanceReport &report,
-  DeviceContext &device_context,
+/// Method to profile a CUTLASS Operation
+Status OperationProfiler::profile_cutlass_(
+  double &runtime,
+  Options const &options,
   library::Operation const *operation,
-  ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
+  void *arguments,
+  void *host_workspace,
+  void *device_workspace) {
 
+  GpuTimer timer;
 
-#if CUTLASS_ENABLE_CUBLAS
+  //
+  // Optional sleep to limit power consumption and thermals
+  //
 
-  library::TrmmDescription const &trmm_desc = 
-    static_cast<library::TrmmDescription const &>(operation->description());
+  sleep(options.profiling.sleep_duration);
 
   //
-  // Construct cuBLAS operators
+  // Warmup loop
   //
-    
-  CublasCreate handle;
-  cublasStatus_t status = handle.get_cublas_create_status();
 
-  if (status != CUBLAS_STATUS_SUCCESS) {
+  Status status;
+
+  for (int iteration = 0; iteration < options.profiling.warmup_iterations; ++iteration) {
+
+    status = operation->run(
+      arguments,
+      host_workspace,
+      device_workspace);
 
-    results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
-    return true;
+    if (status != Status::kSuccess) {
+      return status;
+    }
   }
 
   //
-  // Initialize state
+  // Initialize GPU timer
   //
 
-  try {
+  timer.start();
+
+  //
+  // Profiling loop
+  //
 
-    //
-    // Construct dispatcher to cublas<t>Trmm()
-    //
+  int Iterations = options.profiling.iterations;
 
-    // Initialize structure containing TRMM arguments
-    trmm_workspace_.arguments.A = trmm_workspace_.A->data();
-    trmm_workspace_.arguments.B = trmm_workspace_.B->data();
-    trmm_workspace_.arguments.D = trmm_workspace_.Reference->data();
-    trmm_workspace_.arguments.alpha = problem_.alpha.data();
-    trmm_workspace_.arguments.beta = problem_.beta.data();
-    trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
+  int iteration = 0;
+  for (; iteration < Iterations; ++iteration) {
 
-    detail::cublasTrmmDispatcher trmm_op( 
-      trmm_desc, 
-      trmm_workspace_.configuration,
-      trmm_workspace_.arguments
-    );
+    status = operation->run(
+      arguments,
+      host_workspace,
+      device_workspace);
 
-    if (trmm_op.status != Status::kSuccess) {
-      results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kNotRun;
-      return true;
+    if (status != Status::kSuccess) {
+      return status;
     }
+  }
 
-    results_.back().status = Status::kSuccess;
+  //
+  // Wait for completion
+  //
 
-    status = trmm_op(handle);
+  timer.stop_and_wait();
 
-    // Handle errors
-    if (status != CUBLAS_STATUS_SUCCESS) {
+  //
+  // Update performance result
+  //
 
-      results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
-      return true;
-    }
+  runtime = timer.duration(iteration);
 
-    //
-    // Verify results
-    //
-    results_.back().verification_map[library::Provider::kCUBLAS] = compare_tensors(
-      options,
-      *trmm_workspace_.Computed,
-      *trmm_workspace_.Reference
-    );
+  return status;
+}
 
-    // Save workspace if incorrect
-    if (options.verification.save_workspace == SaveWorkspace::kIncorrect && 
-      results_.back().verification_map[library::Provider::kCUBLAS] == Disposition::kIncorrect) {
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-      save_workspace(
-        device_context,
-        options,
-        trmm_desc,
-        library::Provider::kCUTLASS,
-        library::Provider::kCUBLAS);
-    }
-  }
-  catch (...) {
-    results_.back().verification_map[library::Provider::kCUBLAS] = Disposition::kFailed;
-  }
+/// Sets operation description
+void OperationProfiler::initialize_result_(
+  PerformanceResult &result,
+  library::OperationDescription const &operation_desc,
+  ProblemSpace const &problem_space) {
 
-#endif
+  set_argument(result, "op_class", problem_space,
+    library::to_string(operation_desc.tile_description.math_instruction.opcode_class));
 
-  // Return true means continue profiling
-  return true;
+  set_argument(result, "accum", problem_space,
+    library::to_string(operation_desc.tile_description.math_instruction.element_accumulator));
+
+  set_argument(result, "cta_m", problem_space, operation_desc.tile_description.threadblock_shape.m());
+  set_argument(result, "cta_n", problem_space, operation_desc.tile_description.threadblock_shape.n());
+  set_argument(result, "cta_k", problem_space, operation_desc.tile_description.threadblock_shape.k());
+  set_argument(result, "cluster_m", problem_space, operation_desc.tile_description.cluster_shape.m());
+  set_argument(result, "cluster_n", problem_space, operation_desc.tile_description.cluster_shape.n());
+  set_argument(result, "cluster_k", problem_space, operation_desc.tile_description.cluster_shape.k());
+  set_argument(result, "stages", problem_space, operation_desc.tile_description.threadblock_stages);
+  set_argument(result, "warps_m", problem_space, operation_desc.tile_description.warp_count.m());
+  set_argument(result, "warps_n", problem_space, operation_desc.tile_description.warp_count.n());
+  set_argument(result, "warps_k", problem_space, operation_desc.tile_description.warp_count.k());
+  set_argument(result, "inst_m", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.m());
+  set_argument(result, "inst_n", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.n());
+  set_argument(result, "inst_k", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.k());
+  set_argument(result, "min_cc", problem_space, operation_desc.tile_description.minimum_compute_capability);
+  set_argument(result, "max_cc", problem_space, operation_desc.tile_description.maximum_compute_capability);
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+/// Helper
+void OperationProfiler::set_argument(
+  PerformanceResult &result,
+  char const *name,
+  ProblemSpace const &problem_space,
+  std::string const &value) {
 
-/// Measures performance results
-bool TrmmOperationProfiler::profile(
-  Options const &options,  
-  PerformanceReport &report,
-  DeviceContext &device_context,
-  library::Operation const *operation,
+  result.arguments.at(problem_space.argument_index(name)) = make_pair(std::string(name), value);
+}
+
+void OperationProfiler::set_argument(
+  PerformanceResult &result,
+  char const *name,
   ProblemSpace const &problem_space,
-  ProblemSpace::Problem const &problem) {
+  int64_t value) {
+
+  result.arguments.at(problem_space.argument_index(name)) = make_pair(std::string(name), library::lexical_cast(value));
+}
 
-  if (options.profiling.provider_enabled(library::Provider::kCUTLASS)) {
 
-    // Initialize structure containing TRMM arguments
-    trmm_workspace_.arguments.A = trmm_workspace_.A->data();
-    trmm_workspace_.arguments.B = trmm_workspace_.B->data();
-    trmm_workspace_.arguments.D = trmm_workspace_.Computed->data();
-    trmm_workspace_.arguments.alpha = problem_.alpha.data();
-    trmm_workspace_.arguments.beta = problem_.beta.data();
-    trmm_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
-
-    results_.back().status = profile_cutlass_(
-      results_.back().runtime,
-      options,
-      operation,
-      &trmm_workspace_.arguments,
-      trmm_workspace_.host_workspace.data(),
-      trmm_workspace_.device_workspace.data()
-    );
+/// finds string matches filter_string in operation_name
+bool OperationProfiler::find_string_matches_(
+  std::string const &filter_string,
+  std::string const &operation_name) {
+  // Returns true if all substrings appear in the operation_name in order
+
+  // Split filter_string of the format "gemm*f32*nt" to tokens ["gemm", "f32", "nt"]
+  std::string item;
+  std::istringstream iss(filter_string);
+  std::vector<std::string> filter_tokens;
+  while (std::getline(iss, item, '*')) {
+    filter_tokens.push_back(item);
+  }
+
+  // Search filter_tokens in operation_name in order
+  size_t start = 0, idx = 0;
+  for (auto & token : filter_tokens) {
+    // Check if characters left to be parsed in operation_name
+    if (start < operation_name.length()) {
+      // Find token in operation_name[start:]
+      idx = operation_name.substr(start).find(token);
+      if (idx == std::string::npos) {
+        return false;
+      }
+    }
+    start += (idx + token.length());
   }
+
+  // All tokens in filter_string found in operation_name
   return true;
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace profiler
 } // namespace cutlass
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+///////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.h`

 * *Files 18% similar despite different names*

```diff
@@ -24,44 +24,53 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 #pragma once
 
-#include <cuda_runtime.h>
+#if !defined(__CUDACC_RTC__)
+#include "cuda_runtime.h"
 
-struct GPU_Clock
-{
-  GPU_Clock() {
-    cudaEventCreate(&start_);
-    cudaEventCreate(&stop_);
-    cudaEventRecord(start_);
-  }
+#include "cutlass/trace.h"
+#endif
 
-  ~GPU_Clock() {
-    cudaEventDestroy(start_);
-    cudaEventDestroy(stop_);
-  }
-
-  void start() {
-    cudaEventRecord(start_);
-  }
+namespace cutlass {
 
-  float milliseconds() {
-    cudaEventRecord(stop_);
-    cudaEventSynchronize(stop_);
-    float time;
-    cudaEventElapsedTime(&time, start_, stop_);
-    return time;
+struct KernelHardwareInfo {
+  //
+  // Data members
+  //
+  int device_id = 0;
+  int sm_count  = 0;
+
+  //
+  // Methods
+  //
+
+#if !defined(__CUDACC_RTC__)
+  static inline int
+  query_device_multiprocessor_count(int device_id = 0) {
+    cudaError_t result = cudaGetDevice(&device_id);
+    if (result != cudaSuccess) {
+      CUTLASS_TRACE_HOST(
+        "  cudaGetDevice() returned error "
+        << cudaGetErrorString(result));
+      return 0;
+    }
+    int multiprocessor_count;
+    result = cudaDeviceGetAttribute(&multiprocessor_count,
+      cudaDevAttrMultiProcessorCount, device_id);
+    if (result != cudaSuccess) {
+      CUTLASS_TRACE_HOST(
+        "  cudaDeviceGetAttribute() returned error "
+        << cudaGetErrorString(result));
+      return 0;
+    }
+    return multiprocessor_count;
   }
-
-  float seconds() {
-    return milliseconds() * float(1e-3);
-  }
-
- private:
-  cudaEvent_t start_, stop_;
+#endif
 };
+
+} // namespace cutlass
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/command_line.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h`

 * *Files 1% similar despite different names*

```diff
@@ -117,15 +117,15 @@
     }
   }
 
   /**
    * Returns the commandline parameter for a given index (not including flags)
    */
   template <typename value_t>
-  void get_cmd_line_argument(int index, value_t& val) const {
+  void get_cmd_line_argument(size_t index, value_t& val) const {
     using namespace std;
     if (index < args.size()) {
       istringstream str_stream(args[index]);
       str_stream >> val;
     }
   }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -59,15 +59,15 @@
 using ComplexDouble = cuda::std::complex<double>;
 }
 #endif // BLAM_COMPLEX_TYPES
 
 // User could potentially define Half instead of cute::
 #ifndef BLAM_HALF_TYPE
 #define BLAM_HALF_TYPE 1
-#include <cute/numeric/half.hpp>
+#include <cute/numeric/numeric_types.hpp>
 namespace blam {
 using Half = cute::half_t;
 }
 #endif // BLAM_HALF_TYPE
 
 namespace blam
 {
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/debug.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/debug.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h`

 * *Files 1% similar despite different names*

```diff
@@ -65,15 +65,15 @@
              total_threads);
 
     __syncthreads();
 
     return;
   }
 
-  int total_elements = frag.size();
+  int total_elements = int(frag.size());
 
   if (M < 0 || M > total_elements) {
     if (thread_id == 0 && block_id == 0)
       printf("Element number M = %d should between [1, %d].\n", M,
              total_elements);
 
     __syncthreads();
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_rmsnorm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_rmsnorm.h`

 * *Files 1% similar despite different names*

```diff
@@ -38,16 +38,16 @@
 #include "cutlass/tensor_ref.h"
 #include "cutlass/util/device_utils.h"
 #include <float.h>
 
 namespace cutlass {
 
 __global__ void rmsnorm_twoPassAlgo_e8(float4 *output, const float4 *input,
-				       const float4 *weight,
-				       const int m, const int n, float epsilon) {
+                                       const float4 *weight,
+                                       const int m, const int n, float epsilon) {
   const int m_idx = blockIdx.x;
   const int tid = threadIdx.x;
   const int bdimx = blockDim.x;
   __shared__ float s_mean;
   float local_sums[1] = {0.0f};
   const int n_8 = n / 8;
   int offset = m_idx * n_8;
@@ -111,17 +111,17 @@
 
     output[index] = tmp;
   }
 }
 
 template<typename T>
 __global__ void rmsnorm_twoPassAlgo_e1(T* output,
-				       const T* input,
-				       const T* weight,
-				       const int m, const int n,
+                                       const T* input,
+                                       const T* weight,
+                                       const int m, const int n,
                                        float epsilon)
 {
   const int m_idx = blockIdx.x;
   const int tid = threadIdx.x;
   const int bdimx = blockDim.x;
   __shared__ float s_mean;
   float local_sums[1] = {0.0f};
@@ -152,15 +152,15 @@
 }
 
 template <typename T>
 void rmsnorm(cutlass::MatrixCoord tensor_size,
              TensorRef<T, layout::RowMajor> ref_output,
              TensorRef<T, layout::RowMajor> ref_input,
              TensorRef<T, layout::RowMajor> ref_weight,
-             cudaStream_t stream, float epsilon = 1e-5){
+             cudaStream_t stream, float epsilon = 1e-5f){
   const int m = tensor_size.row();
   const int n = tensor_size.column();
   T* output = ref_output.data();
   const T* input = ref_input.data();
   const T* weight = ref_weight.data();
   dim3 grid(m);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/distribution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/gett_commandline.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/gett_commandline.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h`

 * *Files 2% similar despite different names*

```diff
@@ -108,17 +108,21 @@
   /// kBitsStoredVec          : The bits of store vec that could be divisiable by the element
   /// kElementsPerStoredVec   : The number of elements could be stored in per store vec
   /// kNumStoragePerStoredVec : How much storage(i.e. sizeof(element storage)) the store vec needs to consume.
   ///                           Usually the element storage of subbyte is uint8_t.
   /// Example
   ///  int2:  kBitsStoredVec = 8; kElementsPerStoredVec = 4; kNumStoragePerStoredVec = 1 uint8_t;
   ///  int4:  kBitsStoredVec = 8; kElementsPerStoredVec = 2; kNumStoragePerStoredVec = 1 uint8_t;
-  static int const kBitsStoredVec        = (sizeof_bits<Element>::value < 8) ? cutlass::lcm(static_cast<int>(sizeof_bits<Element>::value), 8) : sizeof_bits<Element>::value; 
-  static int const kElementsPerStoredVec = kBitsStoredVec / sizeof_bits<Element>::value;
-  static int const kNumStoragePerStoredVec = kBitsStoredVec / (sizeof(Element) * 8);
+  static constexpr int kBitsStoredVec        = (sizeof_bits<Element>::value < 8) ? cutlass::lcm(sizeof_bits<Element>::value, 8) : sizeof_bits<Element>::value; 
+  static constexpr int kElementsPerStoredVec = kBitsStoredVec / sizeof_bits<Element>::value;
+  static constexpr int kNumStoragePerStoredVec = kBitsStoredVec / (sizeof(Element) * 8);
+
+  static_assert(kBitsStoredVec != 0, "kBitsStoredVec can not be zero");
+  static_assert(kElementsPerStoredVec != 0, "kElementsPerStoredVec can not be zero");
+  static_assert(kNumStoragePerStoredVec != 0, "kNumStoragePerStoredVec can not be zero");
 
  private:
 
   //
   // Data members
   //
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cutlass/numeric_size.h`

 * *Files 20% similar despite different names*

```diff
@@ -24,15 +24,59 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+/*!
+    \file
+    \brief Top-level include for all CUTLASS numeric types.
+*/
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/numeric_types.h"
 
-// integer_sequence moved to cutlass/numeric_types.h
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
+namespace cutlass {
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Defines the size of an element in bits
+template <typename T>
+struct sizeof_bits {
+  static constexpr int value = int(sizeof(T) * 8);
+};
+
+template <typename T>
+struct sizeof_bits<T const>: sizeof_bits<T> {};
+
+template <>
+struct sizeof_bits<void> {
+  static constexpr int value = 0;
+};
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Returns the number of bytes required to hold a specified number of bits
+CUTLASS_HOST_DEVICE
+CUTLASS_CONSTEXPR_IF_CXX17
+int
+bits_to_bytes(int bits) {
+  return (bits + 7) / 8;
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+template <class T>
+struct is_subbyte {
+  static constexpr bool value = sizeof_bits<T>::value < 8;
+};
+
+template <class T>
+struct is_subbyte<T const> : is_subbyte<T> {};
+
+}  // namespace cutlass
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp`

 * *Files 10% similar despite different names*

```diff
@@ -36,16 +36,17 @@
 #include <cmath>
 #include <iostream>
 #include <type_traits>
 
 #include <cute/util/type_traits.hpp>
 #include <cute/tensor.hpp>
 
-#include <cute/numeric/half.hpp>
+#include <cute/numeric/numeric_types.hpp>
 #include <cute/numeric/complex.hpp>
+
 #include <cutlass/layout/layout.h>
 
 // The computed infinity norm does not include
 // any NaN column absolute-value sums.
 struct matrix_inf_norm_result {
   // Accumulate errors in double, as this is generally
   // the highest precision that the examples use.
@@ -57,83 +58,103 @@
 // and thus passed by value (as std::span or std::string_view would be).
 // However, generic cute::Tensor are more like containers
 // and thus are best passed by reference or const reference.
 template <typename EngineType, typename LayoutType>
 matrix_inf_norm_result
 matrix_inf_norm(cute::Tensor<EngineType, LayoutType> const& host_matrix)
 {
-  using std::abs;
   using error_type = decltype(std::declval<matrix_inf_norm_result>().inf_norm);
   using element_type = typename EngineType::value_type;
 
   error_type inf_norm = 0.0;
   bool found_nan = false;
 
   // Computing the infinity norm requires that we be able
   // to treat the input as a matrix, with rows and columns.
   const int64_t num_rows = cute::size<0>(host_matrix);
   const int64_t num_cols = cute::size<1>(host_matrix);
 
-  for(int64_t i = 0; i < num_rows; ++i) {
+  auto abs_fn = [] (element_type A_ij) {
+    if constexpr (not std::is_unsigned_v<element_type>) {
+      using std::abs;
+      return abs(A_ij);
+    }
+    else {
+      return A_ij;
+    }
+  };
+
+  for (int64_t i = 0; i < num_rows; ++i) {
     error_type row_abs_sum = 0.0;
     for(int64_t j = 0; j < num_cols; ++j) {
-      row_abs_sum += abs(host_matrix(i, j));
+      row_abs_sum += abs_fn(host_matrix(i, j));
     }
-    if(std::isnan(row_abs_sum)) {
+    if (std::isnan(row_abs_sum)) {
       found_nan = true;
-    } else {
+    }
+    else {
       inf_norm = row_abs_sum > inf_norm ? row_abs_sum : inf_norm;
     }
   }
 
   return {inf_norm, found_nan};
 }
 
 // Infinity norm of (X - Y).
 template <typename EngineType, typename LayoutType>
 matrix_inf_norm_result
 matrix_diff_inf_norm(cute::Tensor<EngineType, LayoutType> const& X,
                      cute::Tensor<EngineType, LayoutType> const& Y)
 {
-  using std::abs;
   using error_type = decltype(std::declval<matrix_inf_norm_result>().inf_norm);
   using element_type = typename EngineType::value_type;
 
+  auto abs_fn = [] (element_type A_ij) {
+    if constexpr (not std::is_unsigned_v<element_type>) {
+      using std::abs;
+      return abs(A_ij);
+    }
+    else {
+      return A_ij;
+    }
+  };
+
   assert(cute::size<0>(X) == cute::size<0>(Y));
   assert(cute::size<1>(X) == cute::size<1>(Y));
 
   // Computing the infinity norm requires that we be able
   // to treat the input as a matrix, with rows and columns.
   const int64_t num_rows = cute::size<0>(X);
   const int64_t num_cols = cute::size<1>(X);
 
   error_type inf_norm = 0.0;
   bool found_nan = false;
 
-  for(int64_t i = 0; i < num_rows; ++i) {
+  for (int64_t i = 0; i < num_rows; ++i) {
     error_type row_abs_sum = 0.0;
-    for(int64_t j = 0; j < num_cols; ++j) {
-      row_abs_sum += error_type(abs(element_type(X(i,j)) - 
-                                    element_type(Y(i,j))));
+    for (int64_t j = 0; j < num_cols; ++j) {
+      row_abs_sum += error_type(abs_fn(element_type(X(i,j)) -
+                                       element_type(Y(i,j))));
     }
-    if(std::isnan(row_abs_sum)) {
+    if (std::isnan(row_abs_sum)) {
       found_nan = true;
-    } else {
+    }
+    else {
       inf_norm = row_abs_sum > inf_norm ? row_abs_sum : inf_norm;
     }
   }
 
   return {inf_norm, found_nan};
 }
 
 template <typename EngineType_A, typename LayoutType_A,
           typename EngineType_B, typename LayoutType_B,
           typename EngineType_C, typename LayoutType_C,
           typename EngineType_C_ref, typename LayoutType_C_ref>
-void
+auto
 print_matrix_multiply_mollified_relative_error(
   char const A_value_type_name[],
   cute::Tensor<EngineType_A, LayoutType_A> const& A,
   char const B_value_type_name[],
   cute::Tensor<EngineType_B, LayoutType_B> const& B,
   char const C_value_type_name[],
   cute::Tensor<EngineType_C, LayoutType_C> const& C,
@@ -153,46 +174,47 @@
   // Printing the infinity norm of C is a way to check
   // that both the function being tested (C)
   // and the reference implementation (C_ref)
   // don't just do nothing (or fill with zeros).
   using std::cout;
   using cute::shape;
   cout << "Matrix A: " << shape<0>(A) << "x" << shape<1>(A) << " of " << A_value_type_name << '\n'
-       << "Matrix B: " << shape<0>(B) << "x" << shape<1>(B) << " of " << B_value_type_name << '\n'
-       << "Matrix C: " << shape<0>(C) << "x" << shape<1>(C) << " of " << C_value_type_name << '\n'
-       << std::scientific
-       << "Infinity norm of A: " << A_norm << '\n'
-       << "Infinity norm of B: " << B_norm << '\n'
-       << "Infinity norm of C: " << C_norm << '\n'
-       << "Infinity norm of (C - C_ref): " << diff_norm << '\n';
+      << "Matrix B: " << shape<0>(B) << "x" << shape<1>(B) << " of " << B_value_type_name << '\n'
+      << "Matrix C: " << shape<0>(C) << "x" << shape<1>(C) << " of " << C_value_type_name << '\n'
+      << std::scientific
+      << "Infinity norm of A: " << A_norm << '\n'
+      << "Infinity norm of B: " << B_norm << '\n'
+      << "Infinity norm of C: " << C_norm << '\n'
+      << "Infinity norm of (C - C_ref): " << diff_norm << '\n';
 
   if(A_norm_times_B_norm == 0.0) {
     cout << "Mollified relative error: " << relative_error << '\n';
   } else {
     cout << "Relative error: " << relative_error << '\n';
   }
 
   if (A_has_nan || B_has_nan || C_has_nan || diff_has_nan) {
-    cout << "Did we encounter NaN in A? " << (A_has_nan ? "yes" : "no") << '\n' 
-         << "Did we encounter NaN in B? " << (B_has_nan ? "yes" : "no") << '\n'
-         << "Did we encounter NaN in C? " << (C_has_nan ? "yes" : "no") << '\n'
-         << "Did we encounter NaN in (C - C_ref)? " << (diff_has_nan ? "yes" : "no") << '\n';
+    cout << "Did we encounter NaN in A? " << (A_has_nan ? "yes" : "no") << '\n'
+        << "Did we encounter NaN in B? " << (B_has_nan ? "yes" : "no") << '\n'
+        << "Did we encounter NaN in C? " << (C_has_nan ? "yes" : "no") << '\n'
+        << "Did we encounter NaN in (C - C_ref)? " << (diff_has_nan ? "yes" : "no") << '\n';
   }
+  return relative_error;
 }
 
 template <typename EngineType, typename LayoutType>
-void
+auto
 print_matrix_multiply_mollified_relative_error(
   const char value_type_name[],
   const cute::Tensor<EngineType, LayoutType>& A,
   const cute::Tensor<EngineType, LayoutType>& B,
   const cute::Tensor<EngineType, LayoutType>& C_computed,
   const cute::Tensor<EngineType, LayoutType>& C_expected)
 {
-  print_matrix_multiply_mollified_relative_error(value_type_name, A, value_type_name, B,
+  return print_matrix_multiply_mollified_relative_error(value_type_name, A, value_type_name, B,
                                                  value_type_name, C_computed, C_expected);
 }
 
 // Take a CUTLASS HostTensor (or the like) as input,
 // and return a const CuTe Tensor.
 // This is useful for use with the above error printing functions.
 // This implicitly "transposes" if the layout is RowMajor.
@@ -229,15 +251,16 @@
 template <typename T1, typename T2>
 int
 print_relative_error(
     std::size_t n,
     T1 const& data,
     T2 const& reference,
     bool print_verbose = false,
-    bool print_error = true) {
+    bool print_error = true,
+    double error_margin = 0.00001) {
   using std::abs; using std::sqrt;
 
   // Use either double or complex<double> for error computation
   using value_type = cute::remove_cvref_t<decltype(reference[0])>;
   using error_type = std::conditional_t<cute::is_complex<value_type>::value,
                                         cute::complex<double>,
                                         double>;
@@ -248,46 +271,71 @@
 
   double eps = 1e-200;
 
   double tot_error_sq = 0;
   double tot_norm_sq = 0;
   double tot_ind_rel_err = 0;
   double max_ind_rel_err = 0;
-  for (std::size_t i = 0; i < n; ++i)
-  {
+  double max_diff = 0;
+  for (std::size_t i = 0; i < n; ++i) {
     error_type val = data[i];
     error_type ref = reference[i];
 
     double aref = abs(ref);
     double diff = abs(ref - val);
     double rel_error = diff / (aref + eps);
 
     // Individual relative error
     tot_ind_rel_err += rel_error;
 
     // Maximum relative error
     max_ind_rel_err  = std::max(max_ind_rel_err, rel_error);
 
+    // Maximum delta in value error
+    max_diff = std::max(max_diff, diff);
+
     // Total relative error
     tot_error_sq += diff * diff;
     tot_norm_sq  += aref * aref;
 
     if (print_verbose) {
       std::cout << i << ":\t" << val << "\t" << ref << "\t" << rel_error << std::endl;
     }
   }
 
-  printf("Vector reference  norm: [%.5e]\n", sqrt(tot_norm_sq));
+  double ave_rel_err = tot_ind_rel_err / double(n);
+  if (print_error) {
+    printf("Average relative error: %.3e\n", ave_rel_err);
+  }
+
+  if (print_error) {
+    printf("Maximum relative error: %.3e\n", max_ind_rel_err);
+  }
+
+  if (print_error) {
+    printf("Maximum difference    : %.3e\n", max_diff);
+  }
 
   double tot_rel_err = sqrt(tot_error_sq/(tot_norm_sq+eps));
-  if (print_error)
-    printf("Vector  relative error: [%.5e]\n", tot_rel_err);
+  if (print_error) {
+    printf("Vector relative error:  %.3e\n", tot_rel_err);
+  }
 
-  double ave_rel_err = tot_ind_rel_err / double(n);
-  if (print_error)
-    printf("Average relative error: [%.5e]\n", ave_rel_err);
+  printf("Vector reference  norm: %.3e\n", sqrt(tot_norm_sq));
 
-  if (print_error)
-    printf("Maximum relative error: [%.5e]\n", max_ind_rel_err);
+  return (tot_rel_err <= error_margin) ? EXIT_SUCCESS : EXIT_FAILURE;
+}
 
-  return (tot_rel_err == 0.0) ? EXIT_SUCCESS : EXIT_FAILURE;
+// Overload for cute::Tensor<>
+template <class Engine, class Layout>
+int
+print_relative_error(
+    cute::Tensor<Engine, Layout> data,
+    cute::Tensor<Engine, Layout> reference,
+    bool print_verbose = false,
+    bool print_error = true,
+    double error_margin = 0.00001) {
+  assert(size(data) == size(reference));
+  return print_relative_error(static_cast<std::size_t>(size(data)),
+                              data, reference,
+                              print_verbose, print_error, error_margin);
 }
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h`

 * *Files 4% similar despite different names*

```diff
@@ -64,15 +64,15 @@
   }
 };
 
 template <int Rank>
 struct LinearToCoordinateHelper<Rank, 0> {
 
   CUTLASS_HOST_DEVICE
-  void operator()(Coord<Rank> &coord, int64_t idx, Coord<Rank> const &extent) const {
+  void operator()(Coord<Rank> &coord, int64_t idx, Coord<Rank> const &) const {
     coord[Rank - 1] = int(idx);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <int Rank>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gett.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gett.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h`

 * *Files 1% similar despite different names*

```diff
@@ -130,17 +130,16 @@
       int int_scale_ = -1
     ):
       seed(seed_), 
       mean(static_cast<FloatType>(mean_)), 
       stddev(static_cast<FloatType>(stddev_)), 
       int_scale(int_scale_) {
 
-      float_scale_up = FloatType(IntType(1) << int_scale);
-      float_scale_up += FloatType(0.5) * float_scale_up;
-      float_scale_down = FloatType(1) / FloatType(IntType(1) << int_scale);
+      float_scale_up = FloatType(IntType(2) << int_scale); // scale up to clamp low order bits
+      float_scale_down = FloatType(1) / FloatType(IntType(2) << int_scale);
     }
   };
 
   //
   // Data members
   //
 
@@ -168,16 +167,16 @@
   Element operator()() {
 
     FloatType rnd = random_normal_float<FloatType>(&rng_state);
     rnd = params.mean + params.stddev * rnd;
 
     Element result;
     if (params.int_scale >= 0) {
-      rnd = FloatType(IntType(rnd * params.float_scale_up));
-      result = Element(rnd * params.float_scale_down);
+      rnd = FloatType(IntType(std::llround(rnd * params.float_scale_up)));
+      result = Element(IntType(rnd * params.float_scale_down));
     }
     else {
       result = Element(rnd);
     }
 
     return result;
   }
@@ -444,17 +443,16 @@
       int int_scale_ = -1
     ):
       seed(seed_), 
       range(static_cast<FloatType>(max_ - min)), 
       max(static_cast<FloatType>(max_)),
       int_scale(int_scale_) {
 
-      float_scale_up = FloatType(IntType(1) << int_scale);
-      float_scale_up += FloatType(0.5) * float_scale_up;
-      float_scale_down = FloatType(1) / FloatType(IntType(1) << int_scale);
+      float_scale_up = FloatType(IntType(2) << int_scale); // scale up to clamp low order bits
+      float_scale_down = FloatType(1) / FloatType(IntType(2) << int_scale);
     }
   };
 
   //
   // Data members
   //
 
@@ -485,16 +483,16 @@
     rnd = params.max - params.range * rnd;
 
     // Random values are cast to integer after scaling by a power of two to facilitate error
     // testing
     Element result;
 
     if (params.int_scale >= 0) {
-      rnd = FloatType(IntType(rnd * params.float_scale_up));
-      result = Element(rnd * params.float_scale_down);
+      rnd = FloatType(IntType(std::llround(rnd * params.float_scale_up)));
+      result = Element(IntType(rnd * params.float_scale_down));
     }
     else {
       result = Element(rnd);
     }
 
     return result;
   }
@@ -770,17 +768,21 @@
       uint64_t seed_ = 0, 
       int MetaSizeInBits_ = 2 
     ):
       seed(seed_), 
       MetaSizeInBits(MetaSizeInBits_) {
       if (MetaSizeInBits_ == 2) {
         range = 6;
-      } else if (MetaSizeInBits_ == 4) {
+      }
+      else if (MetaSizeInBits_ == 4) {
         range = 2;
       }
+      else {
+        throw std::invalid_argument("Invalid MetaSizeInBits");
+      }
     }
   };
 
   //
   // Data members
   //
 
@@ -1157,42 +1159,18 @@
   typedef typename TensorView::TensorCoord TensorCoord;
 
   /// 
   static_assert((Layout::kRank == 2), "TensorClearPartial is only supported for matrices");
 
   /// Parameters structure
   struct Params {
-
-    //
-    // Data members
-    //
-
-    TensorView view;
-    Element element;
-    FillMode fill_mode;
-    int alignment;
-
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Params(): fill_mode(FillMode::kNone) { }
-
-    //
-    // Methods
-    //
-
-    /// Construction of Gaussian RNG functor.
-    Params(
-      TensorView view_,
-      Element element_,
-      FillMode fill_mode_,
-      int alignment_
-    ):
-      view(view_), element(element_), fill_mode(fill_mode_), alignment(alignment_) {
-
-    }
+    TensorView view{};
+    Element element{};
+    FillMode fill_mode{FillMode::kNone};
+    int alignment{0};
   };
 
   //
   // Data members
   //
 
   /// Parameters object
@@ -1303,15 +1281,15 @@
   cudaStream_t stream = nullptr) {
 
   typedef detail::TensorClearPartialFunc<Element, Layout> Func;
   typedef typename Func::Params Params;
 
   TensorForEach<Func, Layout::kRank, Params>(
     view.extent(),
-    Params(view, element, fill_mode, alignment),
+    Params{view, element, fill_mode, alignment},
     /*grid_size*/0, /*block_size*/0,
     stream
   );
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -1731,15 +1709,15 @@
   Element s = Element(0)) {
 
   using Layout = layout::PackedVectorLayout;
   Layout::TensorCoord size(static_cast<Layout::Index>(capacity)); // -Wconversion
   Layout layout = Layout::packed(size);
   TensorView<Element, Layout> view(ptr, layout, size);
 
-  Array<Element, Layout::kRank> c;
+  Array<Element, Layout::kRank> c{};
   c[0] = v;
 
   TensorFillLinear(view, c, s);
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 ///////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h`

 * *Files 0% similar despite different names*

```diff
@@ -116,15 +116,15 @@
   TensorView<Element, Layout> view_B,   /// View of the tensor to reduce over
   ComputeType identity,                 /// Identity element of the reduction operation
   ReduceOp reduce,                      /// Reduces an accumulated value with a transformed element: f(ComputeType, ComputeType) => ComputeType
   TransformOp transform,                /// Transforms the tensor element to ComputeType: g(Element) => ComputeType
   ComputeType *workspace) {             /// Device-side workspace for accumulating partial results. The reduced element is stored in workspace[0]
   
   int64_t idx = threadIdx.x + blockIdx.x * blockDim.x;
-  int64_t size = view_A.size();
+  auto size = static_cast<int64_t>(view_A.size());
 
   __shared__ ComputeType scratchpad[kBlockSize];
 
   for (; idx < size; idx += blockDim.x * gridDim.x) {
 
     // Map linear thread ID onto tensor coordinate
     typename Layout::TensorCoord coord;
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h`

 * *Files 2% similar despite different names*

```diff
@@ -193,15 +193,15 @@
         }
       }
     }
   }
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
-/// Dgrad
+/// Dgrad / Deconv
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// dx = dgrad(dy, w)
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
@@ -217,15 +217,16 @@
 void Conv2dDgrad(
   cutlass::conv::Conv2dProblemSize problem_size,
   TensorRef<ElementA, LayoutA> tensor_dy,
   TensorRef<ElementB, LayoutB> tensor_w,
   TensorRef<ElementC, LayoutC> tensor_dx_in,
   TensorRef<ElementD, LayoutC> tensor_dx_out,
   ElementCompute alpha,
-  ElementCompute beta) {
+  ElementCompute beta,
+  bool is_deconv = false) {
 
   ConvertOp convert_op;
   InnerProductOp inner_product_op;
 
   // Apply MMA and accumulate ElementAccumulator
   for (int n = 0; n < problem_size.N; ++n) {
     for (int h = 0; h < problem_size.H; ++h) {
@@ -268,15 +269,16 @@
                   << s << ") [" 
                   << ((p < problem_size.P && q < problem_size.Q) ? "true":"false") << "]"        
                   << std::endl;
 #endif
                   if (p < problem_size.P && q < problem_size.Q) {
 
                     ElementA a = tensor_dy.at(cutlass::make_Coord(n, p, q, k));
-                    ElementB b = tensor_w.at(cutlass::make_Coord(k, r, s, c));
+                    ElementB b = is_deconv ? tensor_w.at(cutlass::make_Coord(c, r, s, k))
+                        : tensor_w.at(cutlass::make_Coord(k, r, s, c));
 
                     acc = inner_product_op(ElementAccumulator(a), ElementAccumulator(b), acc);
                   }
                 }
 
               } // for (K)
             } // for (S)
@@ -416,24 +418,25 @@
       ElementCompute,
       ElementAccumulator,
       ElementD,
       ConvertOp, InnerProductOp
     >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta);
     break;
 
+  case conv::Operator::kDeconv:
   case conv::Operator::kDgrad:
     Conv2dDgrad<
       ElementA, LayoutA,
       ElementB, LayoutB,
       ElementC, LayoutC,
       ElementCompute,
       ElementAccumulator,
       ElementD,
       ConvertOp, InnerProductOp
-    >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta);
+    >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta, (convolutional_operator == conv::Operator::kDeconv));
     break;
 
   case conv::Operator::kWgrad:
     Conv2dWgrad<
       ElementA, LayoutA,
       ElementB, LayoutB,
       ElementC, LayoutC,
@@ -533,15 +536,15 @@
         }
       }
     }
   }
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
-/// Dgrad
+/// Dgrad / Deconv
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// dx = dgrad(dy, w)
 template <
   typename ElementA,
   typename LayoutA,
   typename ElementB,
@@ -556,15 +559,16 @@
 void Conv3dDgrad(
   cutlass::conv::Conv3dProblemSize problem_size,
   TensorRef<ElementA, LayoutA> tensor_dy,
   TensorRef<ElementB, LayoutB> tensor_w,
   TensorRef<ElementC, LayoutC> tensor_dx_in,
   TensorRef<ElementC, LayoutC> tensor_dx_out,
   ElementCompute alpha,
-  ElementCompute beta) {
+  ElementCompute beta,
+  bool is_deconv = false) {
 
   ConvertOp convert_op;
   InnerProductOp inner_product_op;
 
   // Apply MMA and accumulate ElementAccumulator
   for (int n = 0; n < problem_size.N; ++n) {
     for (int d = 0; d < problem_size.D; ++d) {
@@ -600,16 +604,16 @@
                       z = z / problem_size.stride_d;
                       p = p / problem_size.stride_h;
                       q = q / problem_size.stride_w;
                       
                       if (z < problem_size.Z && p < problem_size.P && q < problem_size.Q) {
 
                         ElementA a = tensor_dy.at(cutlass::make_Coord(n, z, p, q, k));
-                        ElementB b = tensor_w.at(cutlass::make_Coord(k, t, r, s, c));
-
+                        ElementB b = is_deconv ? tensor_w.at(cutlass::make_Coord(c, t, r, s, k))
+                            : tensor_w.at(cutlass::make_Coord(k, t, r, s, c));
                         acc = inner_product_op(ElementAccumulator(a), ElementAccumulator(b), acc);
                       }
                     }
 
                   } // for (K)
                 } // for (S)
               } // for (R)
@@ -756,23 +760,24 @@
       ElementC, LayoutC,
       ElementCompute,
       ElementAccumulator,
       ConvertOp, InnerProductOp
     >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta);
     break;
 
+  case conv::Operator::kDeconv:
   case conv::Operator::kDgrad:
     Conv3dDgrad<
       ElementA, LayoutA,
       ElementB, LayoutB,
       ElementC, LayoutC,
       ElementCompute,
       ElementAccumulator, 
       ConvertOp, InnerProductOp
-    >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta);
+    >(problem_size, tensor_A, tensor_B, tensor_C, tensor_D, alpha, beta, (convolutional_operator == conv::Operator::kDeconv));
     break;
 
   case conv::Operator::kWgrad:
     Conv3dWgrad<
       ElementA, LayoutA,
       ElementB, LayoutB,
       ElementC, LayoutC,
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -31,18 +31,19 @@
 /*! \file
     \brief Reference implementation for GETT in host-side code.
 */
 
 #pragma once
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
+#include "cutlass/gemm/gemm.h"
 #include "cutlass/complex.h"
 #include "cutlass/numeric_conversion.h"
 #include "cutlass/epilogue/thread/activation.h"
+#include "cutlass/relatively_equal.h"
 
 #include "cute/tensor.hpp"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass::reference::host {
 
@@ -111,15 +112,14 @@
   using ActivationFunctor = ActivationFunctor_;
   using BiasBinaryOp = BiasBinaryOp_;
 
   using EngineC = typename TensorC::engine_type;
   using LayoutC = typename TensorC::layout_type;
   using EngineD =  typename TensorD::engine_type;
   using LayoutD = typename TensorD::layout_type;
-
   static constexpr bool PerColumnBias = PerColumnBias_;
 
   ElementScalar alpha = ElementScalar(1);
   ElementScalar beta = ElementScalar(0);
 
   TensorC C{};
   TensorD D{};
@@ -232,14 +232,15 @@
 
     // do compute
     for (int m_b = 0; m_b < kBlockM; ++m_b) {
       for (int n_b = 0; n_b < kBlockN; ++n_b) {
         acc[m_b][n_b] = fma_op(a_frag[m_b], b_frag[n_b], acc[m_b][n_b]);
       }
     }
+
   }
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// GETT - Epilogue
 template <class EpilogueParams, class ElementAccumulator, int kBlockM, int kBlockN>
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/numeric/numeric_types.hpp`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,78 +24,52 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/* \file
-  \brief Provides several functions for filling tensors with data.
-*/
-
 #pragma once
 
-// Standard Library includes
-#include <utility>
-#include <cstdlib>
-#include <cmath>
-
-// Cute includes
-#include "cute/tensor.hpp"
-
-// Cutlass includes
-#include "cutlass/cutlass.h"
-#include "cutlass/complex.h"
-#include "cutlass/quaternion.h"
-#include "cutlass/array.h"
-#include "cutlass/numeric_types.h"
-
-///////////////////////////////////////////////////////////////////////////////////////////////////
-
-namespace cutlass {
-namespace reference {
-namespace host {
-
-///////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Returns true if two tensor views are equal.
-template <
-  typename TensorL,
-  typename TensorR
->
-bool TensorEquals(
-  TensorL lhs,
-  TensorR rhs) {
-
-  // Extents must be identical
-  if (cute::size(lhs) != cute::size(rhs)) {
-    return false;
-  }
-
-  for (int64_t idx = 0; idx < cute::size(lhs); ++idx) {
-    if (lhs(idx) != rhs(idx)) {
-      return false;
-    }
-  }
-
-  return true;
-}
-
-/// Returns true if two tensor views are NOT equal.
-template <
-  typename TensorL,
-  typename TensorR
->
-bool TensorNotEquals(
-  TensorL lhs,
-  TensorR rhs) {
-
-  return TensorEquals(lhs, rhs);
-}
-
-///////////////////////////////////////////////////////////////////////////////////////////////////
-
-} // namespace host
-} // namespace reference
-} // namespace cutlass
+#include <vector_types.h>
+#include <cutlass/numeric_types.h>
+#include <cutlass/numeric_size.h>
+
+#include <cute/numeric/int.hpp>
+#include <cute/numeric/real.hpp>
+
+namespace cute {
+
+template <typename T>
+struct sizeof_bits : public cutlass::sizeof_bits<T> {};
+
+// DO NOT change auto to int, sizeof_bits<sparse_elem> use integral_ratio instead of int 
+template <class T>
+static constexpr auto sizeof_bits_v = sizeof_bits<T>::value;
+
+using cutlass::bits_to_bytes;
+
+using cutlass::is_subbyte;
+
+template <class T>
+static constexpr auto is_subbyte_v = is_subbyte<T>::value;
+
+using cutlass::half_t;
+using cutlass::bfloat16_t;
+
+using cutlass::tfloat32_t;
+
+// Umbrella floating-point 8-bit data type : type_erased_dynamic_float8_t
+// This umbrella datatype can be enabled when a user provides a specific
+// datatype in runtime argument list.
+using cutlass::type_erased_dynamic_float8_t;
+using cutlass::float_e4m3_t;
+using cutlass::float_e5m2_t;
+
+using cutlass::uint1b_t;
+using cutlass::int2b_t;
+using cutlass::uint2b_t;
+using cutlass::int4b_t;
+using cutlass::uint4b_t;
+using cutlass::bin1_t;
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+} // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h`

 * *Files 0% similar despite different names*

```diff
@@ -35,14 +35,15 @@
 #pragma once
 
 // Standard Library includes
 #include <utility>
 #include <cstdlib>
 #include <cmath>
 #include <random>
+#include <stdexcept>
 
 // Cutlass includes
 #include "cutlass/cutlass.h"
 #include "cutlass/complex.h"
 #include "cutlass/quaternion.h"
 #include "cutlass/array.h"
 #include "cutlass/numeric_types.h"
@@ -192,15 +193,15 @@
     std::mt19937 bernoulli_rnd(rnd_device());
     std::bernoulli_distribution bernoulli_dist(pnz / 100);
     bool bernoulli_result = bernoulli_dist(bernoulli_rnd);
 
     // Sample from the Gaussian distribution for a nonzero element
     if (bernoulli_result) {
       if (int_scale >= 0) {
-        rnd = double(int64_t(rnd * double(1 << int_scale))) / double(1 << int_scale);
+        rnd = double(std::llround(rnd * double(1 << int_scale))) / double(1 << int_scale);
         result = static_cast<Element>(rnd);
       }
       else {
         result = static_cast<Element>(rnd);
       }
     }
     else {
@@ -563,15 +564,15 @@
 
     rnd = min + range * rnd;
 
     // Random values are cast to integer after scaling by a power of two to facilitate error
     // testing
     Element result;
     if (int_scale >= 0) {
-      rnd = double(int64_t(rnd * double(1 << int_scale))) / double(1 << int_scale);
+      rnd = double(std::llround(rnd * double(1 << int_scale))) / double(1 << int_scale);
       result = static_cast<Element>(Real(rnd));
     }
     else {
       result = static_cast<Element>(Real(rnd));
     }
 
     return result;
@@ -1377,17 +1378,21 @@
     uint64_t seed_ = 0, 
     int MetaSizeInBits_ = 2
   ):
     seed(seed_), MetaSizeInBits(MetaSizeInBits_) {
       std::srand((unsigned)seed);
       if (MetaSizeInBits_ == 2) {
         range = 6;
-      } else if (MetaSizeInBits_ == 4) {
+      }
+      else if (MetaSizeInBits_ == 4) {
         range = 2;
       }
+      else {
+        throw std::invalid_argument("Invalid MetaSizeInBits");
+      }
     }
 
   /// Compute random value and update RNG state
   Element operator()() const {
     Element FourToTwoMeta[6] = {0x4, 0x8, 0x9, 0xc, 0xd, 0xe};
     Element TwoToOneMeta[2] = {0x4, 0xe};
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/include/cute/atom/copy_traits_sm50.hpp`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2024 - 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,17 +26,33 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 #pragma once
 
+#include <cute/arch/copy_sm50.hpp>
+#include <cute/atom/copy_traits.hpp>
 
-#include "cutlass/cutlass.h"
+#include <cute/layout.hpp>
 
-// The contents of this file have been moved  to 'tensor_reduce' to cover other types of reductions.
-
-#include "cutlass/util/reference/host/tensor_reduce.h"
-
-///////////////////////////////////////////////////////////////////////////////////////////////////
+namespace cute
+{
 
+template <>
+struct Copy_Traits<SM50_Shuffle_U32_2x2Trans>
+{
+  // Logical thread id to thread idx (one-thread)
+  using ThrID = Layout<_32>;
+
+  // Map from (src-thr,src-val) to bit
+  using SrcLayout = Layout<Shape <_32,_64>,
+                           Stride<_64, _1>>;
+  // Map from (dst-thr,dst-val) to bit
+  using DstLayout = Layout<Shape <Shape < _2,  _16>,Shape <_32,  _2>>,
+                           Stride<Stride<_32, _128>,Stride< _1, _64>>>;
+
+  // Reference map from (thr,val) to bit
+  using RefLayout = SrcLayout;
+};
 
+} // end namespace cute
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h`

 * *Files 2% similar despite different names*

```diff
@@ -57,15 +57,15 @@
 ComputeType TensorTransformReduce(
   TensorView<Element, Layout> view,
   ComputeType identity,
   ReduceOp reduce,
   TransformOp transform
 ) {
 
-  for (int64_t idx = 0; idx < view.size(); ++idx) {
+  for (int64_t idx = 0; idx < int64_t(view.size()); ++idx) {
     typename Layout::TensorCoord coord;
     cutlass::reference::detail::LinearToCoordinate<Layout::kRank>()(coord, idx, view.extent());
 
     if (view.contains(coord)) {
       Element x = view.at(coord);
       identity = reduce(identity, transform(x));
     }
@@ -90,15 +90,15 @@
   ReduceOp reduce,
   TransformOp transform) {
   
   if (view_A.extent() != view_B.extent()) {
     throw std::runtime_error("Tensor extents must match.");
   }
 
-  for (int64_t idx = 0; idx < view_A.size(); ++idx) {
+  for (int64_t idx = 0; idx < int64_t(view_A.size()); ++idx) {
 
     typename Layout::TensorCoord coord;
     cutlass::reference::detail::LinearToCoordinate<Layout::kRank>()(coord, idx, view_A.extent());
 
     if (view_A.contains(coord)) {
       Element a = view_A.at(coord);
       Element b = view_B.at(coord);
```

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h` & `flash_attn-2.5.9.post1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/flash_api.cpp` & `flash_attn-2.5.9.post1/csrc/flash_attn/flash_api.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/alibi.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/alibi.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/block_info.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/block_info.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/dropout.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/dropout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_kernel.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_kernel.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 /***************************************************************************************************
  * Copyright (c) 2024, Tri Dao.
  ******************************************************************************/
 
 #pragma once
 
-#include <cute/algorithm/copy.hpp>
+#include <cute/tensor.hpp>
 
 #include <cutlass/cutlass.h>
 #include <cutlass/array.h>
 #include <cutlass/numeric_types.h>
 
 #include "block_info.h"
 #include "kernel_traits.h"
```

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_launch_template.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_launch_template.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash_bwd_preprocess_kernel.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_bwd_preprocess_kernel.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 /***************************************************************************************************
  * Copyright (c) 2024, Tri Dao.
  ******************************************************************************/
 
 #pragma once
 
-#include <cute/algorithm/copy.hpp>
+#include <cute/tensor.hpp>
 
 #include <cutlass/cutlass.h>
 #include <cutlass/array.h>
 #include <cutlass/numeric_types.h>
 
 #include "block_info.h"
 #include "kernel_traits.h"
```

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_kernel.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_kernel.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 /******************************************************************************
  * Copyright (c) 2024, Tri Dao.
  ******************************************************************************/
 
 #pragma once
 
-#include <cute/algorithm/copy.hpp>
+#include <cute/tensor.hpp>
 
 #include <cutlass/cutlass.h>
 #include <cutlass/array.h>
 #include <cutlass/numeric_types.h>
 
 #include "block_info.h"
 #include "kernel_traits.h"
```

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/flash_fwd_launch_template.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/flash_fwd_launch_template.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/kernel_traits.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/kernel_traits.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 /******************************************************************************
  * Copyright (c) 2024, Tri Dao.
  ******************************************************************************/
 
 #pragma once
 
-#include "cute/algorithm/copy.hpp"
+#include "cute/tensor.hpp"
 
 #include "cutlass/cutlass.h"
 #include "cutlass/layout/layout.h"
 #include <cutlass/numeric_types.h>
 
 using namespace cute;
```

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/mask.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/mask.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/philox.cuh` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/philox.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/rotary.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/rotary.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 /******************************************************************************
  * Copyright (c) 2024, Tri Dao.
  ******************************************************************************/
 
 #pragma once
 
-#include <cute/algorithm/copy.hpp>
+#include <cute/tensor.hpp>
 
 #include "utils.h"
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace flash {
```

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/softmax.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/static_switch.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/static_switch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/flash_attn/src/utils.h` & `flash_attn-2.5.9.post1/csrc/flash_attn/src/utils.h`

 * *Files 0% similar despite different names*

```diff
@@ -10,16 +10,15 @@
 
 #include <cuda_fp16.h>
 
 #if defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 800
 #include <cuda_bf16.h>
 #endif
 
-#include <cute/algorithm/copy.hpp>
-#include <cute/algorithm/gemm.hpp>
+#include <cute/tensor.hpp>
 
 #include <cutlass/array.h>
 #include <cutlass/cutlass.h>
 #include <cutlass/numeric_conversion.h>
 #include <cutlass/numeric_types.h>
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-2.5.8/csrc/ft_attention/cuda_bf16_fallbacks.cuh` & `flash_attn-2.5.9.post1/csrc/ft_attention/cuda_bf16_fallbacks.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/cuda_bf16_wrapper.h` & `flash_attn-2.5.9.post1/csrc/ft_attention/cuda_bf16_wrapper.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention.cu` & `flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention.h` & `flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp` & `flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/decoder_masked_multihead_attention_utils.h` & `flash_attn-2.5.9.post1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/ft_attention/ft_attention.cpp` & `flash_attn-2.5.9.post1/csrc/ft_attention/ft_attention.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_dense_lib/fused_dense.cpp` & `flash_attn-2.5.9.post1/csrc/fused_dense_lib/fused_dense.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_dense_lib/fused_dense_cuda.cu` & `flash_attn-2.5.9.post1/csrc/fused_dense_lib/fused_dense_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/fused_softmax.cpp` & `flash_attn-2.5.9.post1/csrc/fused_softmax/fused_softmax.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/scaled_masked_softmax.h` & `flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/scaled_masked_softmax_cuda.cu` & `flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h` & `flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu` & `flash_attn-2.5.9.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/fused_softmax/type_shim.h` & `flash_attn-2.5.9.post1/csrc/fused_softmax/type_shim.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln.h` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_api.cpp` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_api.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1024.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1280.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_1536.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_2048.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_256.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_2560.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_3072.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_4096.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_512.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_5120.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_6144.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_7168.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_768.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_8192.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_bwd_kernels.cuh` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_bwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1024.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1280.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_1536.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_2048.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_256.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_2560.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_3072.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_4096.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_512.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_5120.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_6144.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_7168.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_768.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_8192.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_fwd_kernels.cuh` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_fwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_kernel_traits.h` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_kernel_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1024.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1280.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_1536.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_2048.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_256.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_2560.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_3072.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_4096.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_512.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_5120.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_6144.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_7168.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_768.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_bwd_8192.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_bwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1024.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1280.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_1536.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_2048.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_256.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_2560.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_3072.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_4096.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_512.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_5120.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_6144.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_7168.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_768.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_fwd_8192.cu` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_fwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/ln_utils.cuh` & `flash_attn-2.5.9.post1/csrc/layer_norm/ln_utils.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/layer_norm/static_switch.h` & `flash_attn-2.5.9.post1/csrc/layer_norm/static_switch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/rotary/rotary.cpp` & `flash_attn-2.5.9.post1/csrc/rotary/rotary.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/rotary/rotary_cuda.cu` & `flash_attn-2.5.9.post1/csrc/rotary/rotary_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/xentropy/interface.cpp` & `flash_attn-2.5.9.post1/csrc/xentropy/interface.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/csrc/xentropy/xentropy_kernel.cu` & `flash_attn-2.5.9.post1/csrc/xentropy/xentropy_kernel.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/bert_padding.py` & `flash_attn-2.5.9.post1/flash_attn/bert_padding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/flash_attn_interface.py` & `flash_attn-2.5.9.post1/flash_attn/flash_attn_interface.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/flash_attn_triton.py` & `flash_attn-2.5.9.post1/flash_attn/flash_attn_triton.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/flash_attn_triton_og.py` & `flash_attn-2.5.9.post1/flash_attn/flash_attn_triton_og.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/flash_blocksparse_attention.py` & `flash_attn-2.5.9.post1/flash_attn/flash_blocksparse_attention.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/flash_blocksparse_attn_interface.py` & `flash_attn-2.5.9.post1/flash_attn/flash_blocksparse_attn_interface.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/fused_softmax.py` & `flash_attn-2.5.9.post1/flash_attn/fused_softmax.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/layers/patch_embed.py` & `flash_attn-2.5.9.post1/flash_attn/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/layers/rotary.py` & `flash_attn-2.5.9.post1/flash_attn/layers/rotary.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/losses/cross_entropy.py` & `flash_attn-2.5.9.post1/flash_attn/losses/cross_entropy.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/baichuan.py` & `flash_attn-2.5.9.post1/flash_attn/models/baichuan.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/bert.py` & `flash_attn-2.5.9.post1/flash_attn/models/bert.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/bigcode.py` & `flash_attn-2.5.9.post1/flash_attn/models/bigcode.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/btlm.py` & `flash_attn-2.5.9.post1/flash_attn/models/btlm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/falcon.py` & `flash_attn-2.5.9.post1/flash_attn/models/falcon.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/gpt.py` & `flash_attn-2.5.9.post1/flash_attn/models/gpt.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/gpt_neox.py` & `flash_attn-2.5.9.post1/flash_attn/models/gpt_neox.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/gptj.py` & `flash_attn-2.5.9.post1/flash_attn/models/gptj.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/llama.py` & `flash_attn-2.5.9.post1/flash_attn/models/llama.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/opt.py` & `flash_attn-2.5.9.post1/flash_attn/models/opt.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/models/vit.py` & `flash_attn-2.5.9.post1/flash_attn/models/vit.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/modules/block.py` & `flash_attn-2.5.9.post1/flash_attn/modules/block.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/modules/embedding.py` & `flash_attn-2.5.9.post1/flash_attn/modules/embedding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/modules/mha.py` & `flash_attn-2.5.9.post1/flash_attn/modules/mha.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/modules/mlp.py` & `flash_attn-2.5.9.post1/flash_attn/modules/mlp.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/activations.py` & `flash_attn-2.5.9.post1/flash_attn/ops/activations.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/fused_dense.py` & `flash_attn-2.5.9.post1/flash_attn/ops/fused_dense.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/layer_norm.py` & `flash_attn-2.5.9.post1/flash_attn/ops/layer_norm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/rms_norm.py` & `flash_attn-2.5.9.post1/flash_attn/ops/rms_norm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/cross_entropy.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/cross_entropy.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,13 @@
 # Copyright (c) 2023, Tri Dao.
 
 from typing import Tuple, Optional, Union
 
 import torch
 
-from einops import rearrange
-
 import triton
 import triton.language as tl
 
 # `all_gather_into_tensor` and `reduce_scatter_tensor` are new placeholders for
 # `_all_gather_base` and `_reduce_scatter_base`. They require the most recent
 # version of PyTorch. The following 2 lines are for backward compatibility with
 # older PyTorch.
```

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/k_activations.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/k_activations.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/layer_norm.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/layer_norm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/linear.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/linear.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/mlp.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/mlp.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/ops/triton/rotary.py` & `flash_attn-2.5.9.post1/flash_attn/ops/triton/rotary.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/utils/benchmark.py` & `flash_attn-2.5.9.post1/flash_attn/utils/benchmark.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/utils/distributed.py` & `flash_attn-2.5.9.post1/flash_attn/utils/distributed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/utils/generation.py` & `flash_attn-2.5.9.post1/flash_attn/utils/generation.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn/utils/pretrained.py` & `flash_attn-2.5.9.post1/flash_attn/utils/pretrained.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.5.8/flash_attn.egg-info/PKG-INFO` & `flash_attn-2.5.9.post1/flash_attn.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: flash-attn
-Version: 2.5.8
+Version: 2.5.9.post1
 Summary: Flash Attention: Fast and Memory-Efficient Exact Attention
 Home-page: https://github.com/Dao-AILab/flash-attention
 Author: Tri Dao
 Author-email: trid@cs.stanford.edu
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Operating System :: Unix
```

### Comparing `flash_attn-2.5.8/flash_attn.egg-info/SOURCES.txt` & `flash_attn-2.5.9.post1/flash_attn.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -160,55 +160,64 @@
 csrc/cutlass/examples/49_hopper_gemm_with_collective_builder/49_collective_builder.cu
 csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
 csrc/cutlass/examples/51_hopper_gett/51_hopper_gett.cu
 csrc/cutlass/examples/51_hopper_gett/gett_kernel.cuh
 csrc/cutlass/examples/52_hopper_gather_scatter_fusion/52_hopper_gather_scatter_fusion.cu
 csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_gemm.hpp
 csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_kernel.cuh
-csrc/cutlass/examples/52_hopper_gather_scatter_fusion/gather_tensor.hpp
 csrc/cutlass/examples/52_hopper_gather_scatter_fusion/scatter_epilogue.hpp
 csrc/cutlass/examples/53_hopper_gemm_permute/53_hopper_gemm_permute.cu
 csrc/cutlass/examples/53_hopper_gemm_permute/permute_kernel.cuh
 csrc/cutlass/examples/53_hopper_gemm_permute/permute_traits.hpp
 csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/54_hopper_fp8_warp_specialized_gemm.cu
 csrc/cutlass/examples/54_hopper_fp8_warp_specialized_gemm/hopper_fp8_commandline.hpp
 csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/55_hopper_mixed_dtype_gemm.cu
 csrc/cutlass/examples/55_hopper_mixed_dtype_gemm/unfused_weight_dequantize.hpp
 csrc/cutlass/examples/56_hopper_ptr_array_batched_gemm/56_hopper_ptr_array_batched_gemm.cu
 csrc/cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu
+csrc/cutlass/examples/58_ada_fp8_gemm/ada_fp8_gemm.cu
+csrc/cutlass/examples/59_ampere_gather_scatter_conv/ampere_conv_kernel.h
+csrc/cutlass/examples/59_ampere_gather_scatter_conv/ampere_gather_scatter_conv.cu
 csrc/cutlass/examples/60_cutlass_import/main.cpp
+csrc/cutlass/examples/common/gather_tensor.hpp
 csrc/cutlass/examples/common/helper.h
-csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
+csrc/cutlass/examples/cute/tutorial/sgemm_1.cu
+csrc/cutlass/examples/cute/tutorial/sgemm_2.cu
+csrc/cutlass/examples/cute/tutorial/sgemm_sm70.cu
+csrc/cutlass/examples/cute/tutorial/sgemm_sm80.cu
 csrc/cutlass/examples/cute/tutorial/tiled_copy.cu
 csrc/cutlass/include/cute/config.hpp
 csrc/cutlass/include/cute/int_tuple.hpp
 csrc/cutlass/include/cute/layout.hpp
 csrc/cutlass/include/cute/layout_composed.hpp
 csrc/cutlass/include/cute/pointer.hpp
 csrc/cutlass/include/cute/pointer_base.hpp
 csrc/cutlass/include/cute/pointer_flagged.hpp
 csrc/cutlass/include/cute/pointer_swizzle.hpp
 csrc/cutlass/include/cute/stride.hpp
 csrc/cutlass/include/cute/swizzle.hpp
 csrc/cutlass/include/cute/swizzle_layout.hpp
 csrc/cutlass/include/cute/tensor.hpp
 csrc/cutlass/include/cute/tensor_predicate.hpp
-csrc/cutlass/include/cute/tile.hpp
 csrc/cutlass/include/cute/underscore.hpp
 csrc/cutlass/include/cute/algorithm/axpby.hpp
 csrc/cutlass/include/cute/algorithm/clear.hpp
+csrc/cutlass/include/cute/algorithm/cooperative_copy.hpp
+csrc/cutlass/include/cute/algorithm/cooperative_gemm.hpp
 csrc/cutlass/include/cute/algorithm/copy.hpp
 csrc/cutlass/include/cute/algorithm/fill.hpp
 csrc/cutlass/include/cute/algorithm/functional.hpp
 csrc/cutlass/include/cute/algorithm/gemm.hpp
 csrc/cutlass/include/cute/algorithm/prefer.hpp
+csrc/cutlass/include/cute/algorithm/prefetch.hpp
 csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp
 csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp
 csrc/cutlass/include/cute/arch/cluster_sm90.hpp
 csrc/cutlass/include/cute/arch/copy.hpp
+csrc/cutlass/include/cute/arch/copy_sm50.hpp
 csrc/cutlass/include/cute/arch/copy_sm75.hpp
 csrc/cutlass/include/cute/arch/copy_sm80.hpp
 csrc/cutlass/include/cute/arch/copy_sm90.hpp
 csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp
 csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp
 csrc/cutlass/include/cute/arch/mma.hpp
 csrc/cutlass/include/cute/arch/mma_sm61.hpp
@@ -217,17 +226,19 @@
 csrc/cutlass/include/cute/arch/mma_sm80.hpp
 csrc/cutlass/include/cute/arch/mma_sm90.hpp
 csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp
 csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp
 csrc/cutlass/include/cute/arch/util.hpp
 csrc/cutlass/include/cute/atom/copy_atom.hpp
 csrc/cutlass/include/cute/atom/copy_traits.hpp
+csrc/cutlass/include/cute/atom/copy_traits_sm50.hpp
 csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp
 csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp
 csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp
+csrc/cutlass/include/cute/atom/copy_traits_sm90_im2col.hpp
 csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp
 csrc/cutlass/include/cute/atom/copy_traits_sm90_tma_swizzle.hpp
 csrc/cutlass/include/cute/atom/mma_atom.hpp
 csrc/cutlass/include/cute/atom/mma_traits.hpp
 csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp
 csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp
 csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp
@@ -239,27 +250,22 @@
 csrc/cutlass/include/cute/container/array_aligned.hpp
 csrc/cutlass/include/cute/container/array_subbyte.hpp
 csrc/cutlass/include/cute/container/bit_field.hpp
 csrc/cutlass/include/cute/container/cuda_types.hpp
 csrc/cutlass/include/cute/container/tuple.hpp
 csrc/cutlass/include/cute/container/type_list.hpp
 csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp
-csrc/cutlass/include/cute/numeric/bfloat.hpp
 csrc/cutlass/include/cute/numeric/complex.hpp
-csrc/cutlass/include/cute/numeric/float8.hpp
-csrc/cutlass/include/cute/numeric/half.hpp
 csrc/cutlass/include/cute/numeric/int.hpp
 csrc/cutlass/include/cute/numeric/integer_sequence.hpp
-csrc/cutlass/include/cute/numeric/integer_subbyte.hpp
 csrc/cutlass/include/cute/numeric/integral_constant.hpp
 csrc/cutlass/include/cute/numeric/integral_ratio.hpp
 csrc/cutlass/include/cute/numeric/math.hpp
+csrc/cutlass/include/cute/numeric/numeric_types.hpp
 csrc/cutlass/include/cute/numeric/real.hpp
-csrc/cutlass/include/cute/numeric/tfloat.hpp
-csrc/cutlass/include/cute/numeric/uint128.hpp
 csrc/cutlass/include/cute/util/debug.hpp
 csrc/cutlass/include/cute/util/print.hpp
 csrc/cutlass/include/cute/util/type_traits.hpp
 csrc/cutlass/include/cutlass/aligned_buffer.h
 csrc/cutlass/include/cutlass/array.h
 csrc/cutlass/include/cutlass/array_planar_complex.h
 csrc/cutlass/include/cutlass/array_subbyte.h
@@ -320,49 +326,67 @@
 csrc/cutlass/include/cutlass/arch/mma.h
 csrc/cutlass/include/cutlass/arch/mma_sm50.h
 csrc/cutlass/include/cutlass/arch/mma_sm60.h
 csrc/cutlass/include/cutlass/arch/mma_sm61.h
 csrc/cutlass/include/cutlass/arch/mma_sm70.h
 csrc/cutlass/include/cutlass/arch/mma_sm75.h
 csrc/cutlass/include/cutlass/arch/mma_sm80.h
+csrc/cutlass/include/cutlass/arch/mma_sm89.h
 csrc/cutlass/include/cutlass/arch/mma_sm90.h
 csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h
+csrc/cutlass/include/cutlass/arch/mma_sparse_sm89.h
 csrc/cutlass/include/cutlass/arch/reg_reconfig.h
 csrc/cutlass/include/cutlass/arch/simd.h
 csrc/cutlass/include/cutlass/arch/simd_sm60.h
 csrc/cutlass/include/cutlass/arch/simd_sm61.h
 csrc/cutlass/include/cutlass/arch/wmma.h
 csrc/cutlass/include/cutlass/arch/wmma_sm70.h
 csrc/cutlass/include/cutlass/arch/wmma_sm72.h
 csrc/cutlass/include/cutlass/arch/wmma_sm75.h
 csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h
 csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h
+csrc/cutlass/include/cutlass/conv/convnd_problem_shape.hpp
 csrc/cutlass/include/cutlass/conv/convolution.h
+csrc/cutlass/include/cutlass/conv/dispatch_policy.hpp
+csrc/cutlass/include/cutlass/conv/collective/collective_builder.hpp
+csrc/cutlass/include/cutlass/conv/collective/collective_conv.hpp
+csrc/cutlass/include/cutlass/conv/collective/detail.hpp
+csrc/cutlass/include/cutlass/conv/collective/sm90_implicit_gemm_gmma_ss_warpspecialized.hpp
+csrc/cutlass/include/cutlass/conv/device/conv_universal_adapter.hpp
 csrc/cutlass/include/cutlass/conv/device/direct_convolution.h
 csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
 csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
+csrc/cutlass/include/cutlass/conv/kernel/conv_universal.hpp
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
+csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_absmax.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
+csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_with_broadcast.h
 csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
+csrc/cutlass/include/cutlass/conv/kernel/default_deconv2d.h
+csrc/cutlass/include/cutlass/conv/kernel/default_deconv2d_with_broadcast.h
+csrc/cutlass/include/cutlass/conv/kernel/default_deconv3d.h
+csrc/cutlass/include/cutlass/conv/kernel/default_deconv3d_with_broadcast.h
 csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
 csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h
 csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
 csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
 csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
+csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_absmax.h
 csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
+csrc/cutlass/include/cutlass/conv/kernel/sm90_implicit_gemm_tma_warpspecialized.hpp
 csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
 csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
@@ -438,14 +462,15 @@
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
+csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic_with_scaling.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
 csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
@@ -459,14 +484,15 @@
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
+csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_absmax.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
@@ -477,33 +503,35 @@
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_streamk_with_broadcast.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
+csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_absmax.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor_callbacks.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
+csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_conv.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
-csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
+csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_linear.h
 csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_2x.hpp
 csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_compute.hpp
 csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_load.hpp
 csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitor_store.hpp
 csrc/cutlass/include/cutlass/epilogue/threadblock/fusion/visitors.hpp
 csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
 csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
@@ -543,20 +571,22 @@
 csrc/cutlass/include/cutlass/gemm/device/gemm.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_array.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h
+csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_sparse_with_visitor.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_universal_streamk_with_broadcast.h
+csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
 csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
 csrc/cutlass/include/cutlass/gemm/device/gemv.h
 csrc/cutlass/include/cutlass/gemm/device/rank_2k.h
 csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
 csrc/cutlass/include/cutlass/gemm/device/rank_k.h
 csrc/cutlass/include/cutlass/gemm/device/symm.h
@@ -565,19 +595,21 @@
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
+csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse_with_visitor.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_streamk_with_broadcast.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal_with_visitor.h
+csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
 csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
@@ -607,14 +639,15 @@
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_streamk_with_fused_epilogue.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_with_visitor_streamk.h
+csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemv.h
 csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
 csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
 csrc/cutlass/include/cutlass/gemm/kernel/params_sparse_base.h
 csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
@@ -632,14 +665,15 @@
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_cooperative.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_warpspecialized_pingpong.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_group.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler_stream_k.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
+csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_absmax.h
 csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm_with_visitor.h
 csrc/cutlass/include/cutlass/gemm/kernel/static_tile_scheduler.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h
 csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler.hpp
 csrc/cutlass/include/cutlass/gemm/kernel/tile_scheduler_params.h
 csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
 csrc/cutlass/include/cutlass/gemm/thread/mma.h
@@ -798,24 +832,26 @@
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f8nhwc_f8nhwc_f8nhwc_tensor_op_f32_sm89.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_simt_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_problems.h
 csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_swizzling4_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
@@ -825,50 +861,90 @@
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv2d_with_absmax_testbed.h
 csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
 csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
 csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv3d_fprop_with_broadcast_simt_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv3d_problems.h
 csrc/cutlass/test/unit/conv/device/conv3d_testbed.h
 csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
 csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
 csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/conv3d_with_broadcast_testbed.h
+csrc/cutlass/test/unit/conv/device/deconv2d_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/deconv2d_with_broadcast_simt_sm80.cu
+csrc/cutlass/test/unit/conv/device/deconv3d_implicit_gemm_f32ndhwc_f32ndhwc_f32ndhwc_simt_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device/deconv3d_with_broadcast_simt_sm80.cu
 csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
 csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+csrc/cutlass/test/unit/conv/device_3x/conv_problem_sizes.hpp
+csrc/cutlass/test/unit/conv/device_3x/testbed_conv.hpp
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv1d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv1d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv2d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv2d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv3d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/dgrad/sm90_conv3d_dgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv1d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv2d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_s8_s8_s32_tensorop_s32.cu
+csrc/cutlass/test/unit/conv/device_3x/fprop/sm90_conv3d_fprop_implicit_gemm_tf32_tf32_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv1d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv1d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv2d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv2d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv3d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f16.cu
+csrc/cutlass/test/unit/conv/device_3x/wgrad/sm90_conv3d_wgrad_implicit_gemm_f16_f16_f32_tensorop_f32.cu
 csrc/cutlass/test/unit/core/array.cu
 csrc/cutlass/test/unit/core/bfloat16.cu
 csrc/cutlass/test/unit/core/complex.cu
-csrc/cutlass/test/unit/core/cpp11.cu
 csrc/cutlass/test/unit/core/fast_numeric_conversion.cu
 csrc/cutlass/test/unit/core/float8.cu
 csrc/cutlass/test/unit/core/functional.cu
 csrc/cutlass/test/unit/core/half.cu
 csrc/cutlass/test/unit/core/matrix.cu
 csrc/cutlass/test/unit/core/matrix_coord.cu
 csrc/cutlass/test/unit/core/numeric_conversion.cu
 csrc/cutlass/test/unit/core/predicate_vector.cu
 csrc/cutlass/test/unit/core/quaternion.cu
 csrc/cutlass/test/unit/core/tensor_ref.cu
 csrc/cutlass/test/unit/core/tensor_view.cu
 csrc/cutlass/test/unit/core/test_unit_core.cpp
 csrc/cutlass/test/unit/core/tfloat32.cu
+csrc/cutlass/test/unit/core/uint128.cu
+csrc/cutlass/test/unit/cute/cooperative_gemm_common.hpp
+csrc/cutlass/test/unit/cute/ampere/cooperative_gemm.cu
 csrc/cutlass/test/unit/cute/ampere/cp_async.cu
 csrc/cutlass/test/unit/cute/ampere/ldsm.cu
+csrc/cutlass/test/unit/cute/ampere/tiled_cp_async.cu
+csrc/cutlass/test/unit/cute/ampere/tiled_cp_async_testbed.hpp
 csrc/cutlass/test/unit/cute/core/array_subbyte.cpp
 csrc/cutlass/test/unit/cute/core/bitfield.cpp
 csrc/cutlass/test/unit/cute/core/coalesce.cpp
 csrc/cutlass/test/unit/cute/core/compact_xmajor.cpp
 csrc/cutlass/test/unit/cute/core/compare.cpp
 csrc/cutlass/test/unit/cute/core/complement.cpp
 csrc/cutlass/test/unit/cute/core/composition.cpp
@@ -887,18 +963,23 @@
 csrc/cutlass/test/unit/cute/core/transform.cpp
 csrc/cutlass/test/unit/cute/core/tuple.cpp
 csrc/cutlass/test/unit/cute/hopper/bulk_load.cu
 csrc/cutlass/test/unit/cute/hopper/bulk_store.cu
 csrc/cutlass/test/unit/cute/hopper/stsm.cu
 csrc/cutlass/test/unit/cute/hopper/tma_load.cu
 csrc/cutlass/test/unit/cute/hopper/tma_load_testbed.hpp
+csrc/cutlass/test/unit/cute/hopper/tma_mcast_load.cu
+csrc/cutlass/test/unit/cute/hopper/tma_mcast_load_testbed.hpp
 csrc/cutlass/test/unit/cute/hopper/tma_store.cu
 csrc/cutlass/test/unit/cute/hopper/tma_store_testbed.hpp
 csrc/cutlass/test/unit/cute/layout/layout_operator.cu
 csrc/cutlass/test/unit/cute/msvc_compilation/tuple.cpp
+csrc/cutlass/test/unit/cute/turing/cooperative_gemm.cu
+csrc/cutlass/test/unit/cute/volta/cooperative_copy.cu
+csrc/cutlass/test/unit/cute/volta/cooperative_gemm.cu
 csrc/cutlass/test/unit/cute/volta/vectorization_auto.cu
 csrc/cutlass/test/unit/epilogue/thread/activation.cu
 csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu
 csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
 csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
 csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
 csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
@@ -974,14 +1055,16 @@
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f32_sm75.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
@@ -1006,14 +1089,18 @@
 csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f32t_tensor_op_f32_sm89.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f32t_tensor_op_f32_sparse_sm89.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f8t_tensor_op_f32_sm89.cu
+csrc/cutlass/test/unit/gemm/device/gemm_f8t_f8n_f8t_tensor_op_f32_sparse_sm89.cu
 csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
 csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
 csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
 csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
 csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
@@ -1267,14 +1354,15 @@
 csrc/cutlass/test/unit/gemm/device/testbed_sanity.h
 csrc/cutlass/test/unit/gemm/device/testbed_sparse.h
 csrc/cutlass/test/unit/gemm/device/testbed_splitk.h
 csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h
 csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
 csrc/cutlass/test/unit/gemm/device/testbed_universal.h
 csrc/cutlass/test/unit/gemm/device/testbed_utils.h
+csrc/cutlass/test/unit/gemm/device/testbed_with_absmax.h
 csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
 csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
 csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
 csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
 csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
 csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
 csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
@@ -1371,14 +1459,15 @@
 csrc/cutlass/tools/library/include/cutlass/library/manifest.h
 csrc/cutlass/tools/library/include/cutlass/library/operation_table.h
 csrc/cutlass/tools/library/include/cutlass/library/singleton.h
 csrc/cutlass/tools/library/include/cutlass/library/types.h
 csrc/cutlass/tools/library/include/cutlass/library/util.h
 csrc/cutlass/tools/library/src/conv2d_operation.h
 csrc/cutlass/tools/library/src/conv3d_operation.h
+csrc/cutlass/tools/library/src/conv_operation_3x.hpp
 csrc/cutlass/tools/library/src/gemm_operation.h
 csrc/cutlass/tools/library/src/gemm_operation_3x.hpp
 csrc/cutlass/tools/library/src/handle.cu
 csrc/cutlass/tools/library/src/library_internal.h
 csrc/cutlass/tools/library/src/manifest.cpp
 csrc/cutlass/tools/library/src/operation_table.cu
 csrc/cutlass/tools/library/src/rank_2k_operation.h
@@ -1492,14 +1581,15 @@
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
+csrc/cutlass/tools/util/include/cutlass/util/reference/host/conv.hpp
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
```

### Comparing `flash_attn-2.5.8/setup.py` & `flash_attn-2.5.9.post1/setup.py`

 * *Files 0% similar despite different names*

```diff
@@ -278,15 +278,15 @@
 
             impl_tag, abi_tag, plat_tag = self.get_tag()
             archive_basename = f"{self.wheel_dist_name}-{impl_tag}-{abi_tag}-{plat_tag}"
 
             wheel_path = os.path.join(self.dist_dir, archive_basename + ".whl")
             print("Raw wheel path", wheel_path)
             os.rename(wheel_filename, wheel_path)
-        except urllib.error.HTTPError:
+        except (urllib.error.HTTPError, urllib.error.URLError):
             print("Precompiled wheel not found. Building from source...")
             # If the wheel could not be downloaded, build from source
             super().run()
 
 
 class NinjaBuildExtension(BuildExtension):
     def __init__(self, *args, **kwargs) -> None:
@@ -340,14 +340,14 @@
     else {
         "bdist_wheel": CachedWheelsCommand,
     },
     python_requires=">=3.7",
     install_requires=[
         "torch",
         "einops",
-        "packaging",
-        "ninja",
     ],
     setup_requires=[
-        "psutil"
+        "packaging",
+        "psutil",
+        "ninja",
     ],
 )
```

